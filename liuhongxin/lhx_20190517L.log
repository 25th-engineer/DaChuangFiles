	lhx 0517 周五
spark环境的搭建：
	１）安装配置JDK1.8.0_201
	２）安装配置Hadoop-2.6.0
	３）配置yarn环境
	４）安装配置Hive-1.1.0
	５）安装配置scala-2.11.8
	６）安装配置spark-2.1.0
Hadoop的学习:
	hdfs的基本概念、架构、文件配置、启动/停止hdfs等
	yarn的基本概念、架构、执行流程、提交作业等
	hive的基本概念、架构、基本使用等
