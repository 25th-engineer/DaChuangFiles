## 21. 举例说明偏差和方差

考虑我们的猫分类任务。 一个“理想”的分类器（比如人）在这项任务中可能会取得近乎完美的表现。

假设你的算法表现如下：

- 训练集误差 = 1%
- 开发集误差 = 11%

从上边的数据能看出什么问题吗？应用前一节的定义，我们估计该分类器的偏差为1%，同时方差为10%（11%-1%=10%）。因此，它存在高方差(High Variance)问题。分类器的训练集误差很小，但未能把在训练集上完美表现推广到开发集中，这也被称为“过拟合”(Overfitting)。

现在，算法表现变成了下列所示：

- 训练集误差 = 15%
- 开发集误差 = 16%

我们估计该分类器的偏差达到了15%，方差是1%。这个分类器对训练集的拟合效果很差，误差居然有15%，但是它在开发集上的误差和训练集上相当（也有16%）。因此该分类器存在高偏差(High Bias​​)问题，这也被称为“欠拟合”(Underfitting)。

再来看一种情况：

- 训练集误差 = 15%
- 开发集误差 = 30%

我们估计偏差为15%，方差也达到了15%。该分类器同时存在高偏差和高方差问题：训练集的表现效果很差，因此偏差很大，同时他在开发集的表现更差，因此方差也很大。这是由于分类器模型设计的有问题，属于最糟糕的情况，欠拟合/过拟合的优化技术很难应用到这类情况中来。

再来看最后一种情况：

- 训练集误差 = 0.5%
- 开发集误差 = 1%

这个分类器表现完美，同时拥有低方差和低偏差，祝贺你取得了这样的成绩。