## 7. 开发集/测试集多大合适？

开发集应该足够大，大到能够检测出你在尝试的不同算法之间的差异。比如，如果分类器A的准确率有90%，分类器B的准确率有90.1%，那么只有100个样本的开发集是无法检测到这0.1%的差异的。与我所见过的机器学习问题相比，100样本大小的开发集着实很小。样本规模在1000-10000之间的开发集很常见，通过10000样本大小的开发集，你才有更大的可能性检测出这0.1%的提高 [1]。

>[1].理论上，我们还可以在开发集上测试算法的改变能否产生统计意义上的显著差异。事实上，大多数团队不会为此而操心（除非他们正在准备发表学术论文），而且我通常没有发现对测量中期进展有用的统计显着性检验。

对于那些成熟的，重要的应用来说，比如那些广告、搜索引擎和产品推荐等，我也看到过为了提升那0.01%而不懈努力的团队，这个努力将直接影响公司的利润。在这种情况下，为了能够检测到更加小算法性能改进，开发集的大小可能远大于10000。

那么测试集的大小多少合适呢？他也应该足够大，大到能够为系统的整体性能提供很高的可信度。一种流行的启发性方法就是将数据集的30%用于训练集，这适用于一个具有中等大小规模（100-10000个样本）的数据集。但是在大数据时代，我们所面临的可能是有着数十亿样本的机器学习问题，分配给开发/测试集的数据比例一直在降低，但是开发/测试集的数据量却是不断递增的。总之，在给开发/测试集分配数据时，没有必要分配超出评估算法性能所需的数据量。