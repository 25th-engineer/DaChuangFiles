第一集、机器学习与数据基础知识
1、什么是机器学习？
对于有些问题，我们无法用确定的逻辑编程实现。如图像识别，语音识别，垃圾邮件分类
机器学习的核心思想是模拟人的学习能力
从样本数据中学习，得到经验/模型，然后进行预测，这是一种数据驱动的方法。
2、机器学习的基本概念
样本-机器学习算法处理的数据
特征向量-人工构造的用于描述一个样本的向量，如颜色、形状等
预测函数-实现从样本的特征向量到预测值得映射
目标函数
训练时使用，目的是确定模型的参数
3、有监督学习的一般流程
4、机器学习算法的分类
监督信号
人工为样本打上的标签(label),如图像的分类，是26个英文字母中的哪一个
按照样本是否有标签值，将机器学习算法分为有监督学习与无监督学习。有监督学习事先用带有标签的样本进行训练，然后用得到的模型预测。无监督学习直接对数据进行预测，样本不带有人工标注的标签值
有监督学习
根据样本学习得到一个映射函数
分类问题-确定样本的类别，如人脸识别，字符识别，语音识别。类别标签是整数编号
回归问题-确定一个实数值，如根据一个人的学历、工作年限、行业等信息预测他/她的收入
无监督学习
聚类问题-将一批样本分成多个类，即多个不相交的子集，每个样本属于其中的一个子集。类别没有事先定义，而是由算法确定。
数据降维问题-将一个向量变换到低维空间中
强化学习
根据当前的状态确定要执行的动作，以达到某一目标，抽象的来说，是最大累计回报。
5、需要哪些数学知识？
微积分
现行代数
概率论
最优化方法
6、导数的定义？
函数在点x处的导数定义为
左导数与右导数-从左边与右边趋于x时的导数
可导函数-左右极限都存在，并且相等
导数的几何意义-函数在某一点处切线的斜率
导数的物理意义-瞬时速度
在各点处的导数构成的函数成为导函数，简称导数
导数在机器学习和深度学习中的应用是求解目标函数的极值。
重要的求导公式
7、高阶导数
8、导数与函数的性质
一阶导数决定函数的单调性，导数大于0，函数单调增；导数小于0，函数单调减
极值定理
一个导函数在极值点处导数必定为0，导数为0的点成为函数的驻点
二阶导函数决定函数的凹凸性
二阶导数大于0，函数为凸函数，二阶导数小于0，函数为凹函数。
二阶导数为0的点为函数的拐点。
9、一阶函数的极值判别法则
如果在x点处导数为0，即为函数的驻点，则
如果二阶导数大于0，x为函数的极小值点
如果二阶导数小于0，x为函数的极大值点
如果二阶导数等于0，则情况不定。例如y = x^3
10、向量及其运算
向量为n个数组成的一个值，每个数成为向量的分量。与其对应的是标量。
编程语言中的一维数组即为向量。
力，速度等都是向量
行向量、列向量
数学中一般把向量表示成列向量，编程语言中一般把向量表示成行向量，即按行存储
向量的运算
加法，数乘，减法，内积，转置
11、向量的范数
12、矩阵及其运算
矩阵
方阵：行数和列数相等，记为n阶方阵
主对角线：行列下标相等的位置
对称矩阵：关于主对角线对称 Aij = Aji
单位矩阵
矩阵的运算
加法，数乘，减法，转置，乘法
逆矩阵
13、特征值与特征向量 QR算法
14、二次型
15、张量
16、偏导数
17、高阶偏导数
18、梯度
19、雅克比矩阵
20、Hessian矩阵
21、多元函数的极值判别法则
如果Hessian矩阵正定，函数在该点有极小值        相当于一元函数二阶导数>0
如果Hessian矩阵负定，函数在该点有极大值
如果Hessian矩阵不定，则为鞍点，不是极值点
矩阵正定的定义
矩阵正定的判别法则
矩阵的特征值全大于0
矩阵的所有顺序主子式都大于0
矩阵合同于单位矩阵
22、多元函数泰勒展开
23、几个重要的矩阵和向量求导公式
24、随机事件与概率
25、条件概率和贝叶斯公式
26、随机事件的独立性
27、随机变量
28、边缘概率与边缘密度
29、随机变量的独立性
30、协方差
31、常用的多维分布
32、最大似然估计
33、最优化的基本概念
34、为什么要用迭代法
35、梯度下降法
36、数值优化算法面临的问题
37、生成模型与判别模型
38、准确率与回归误差
39、精度与召回率
40、ROC曲线
41、交叉验证
42、欠拟合与过拟合
43、正则化
44、Logistic回归
45、softmax回归
46、主成分分析