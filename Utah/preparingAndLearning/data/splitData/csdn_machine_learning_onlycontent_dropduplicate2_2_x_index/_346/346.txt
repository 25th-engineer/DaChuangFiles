本章概括
本章介绍模型评估与选择，包括：
1. 误差产生：过拟合和欠拟合
2. 评估方法：给定数据集后如何产生训练集和测试集
3. 性能度量：建立衡量模型泛化能力的评价标准
4. 比较检验：从统计角度比较机器学习性能
5. 偏差与方差：解释学习算法泛化性能的一种工具
第2章 模型评估与选择
经验误差与过拟合
评估方法
性能度量
错误率与精度
查准率查全率与F1
ROC与AUC
代价敏感错误率与代价曲线
比较检验
假设检验
偏差与方差
第2章 模型评估与选择
经验误差与过拟合
一般来说，学习器的预测输出和实际真实的输出是有差异的，称为误差。
如果学习器学的太差，对训练样本的一般性质没学好，则称为欠拟合underfitting。
相反，如果学的「太好」，把训练样本自身的一些特点当成了所有潜在样本都具有的一般性质，这种情况称为过拟合overfitting。
欠拟合比较容易克服，往往因为学习器学习能力太强大导致的过拟合很难处理，实际上过拟合是机器学习面临的关键障碍。首先必须认识到，过拟合无法避免，我们需要做的是降低或者缓解。
从理论上讲，
机器学习面临的问题通常是NP难或者更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了
P=NP
P=NP。因此只要相信
P≠NP
P\neq NP，过拟合就不可避免。
评估方法
评估方法主要考虑的是在给定了数据集D后如何产生训练集S和测试集T。
一般方法有留出法hold-out，交叉验证法和自助法。
留出法也即
S∪T=D,S∩T=∅
S\cup T = D, S \cap T = \varnothing 。
交叉验证法也就是将数据集划分为
k
k个大小相似的数据集，即
D1∪...∪Dk=D,D1∩...∩Dk=∅
D_1\cup ...\cup D_k=D, D_1\cap ...\cap D_k=\varnothing。然后取其中一份为测试集，其余为训练集，进行
k
k次训练和测试，即可得到平均结果。
自助法以自助采样为基础，假设数据集D有m个样本，对数据集D做
m
m次独立放回的采样得到数据集
D′
D'。
简单分析一下m次都没被去到概率是
(1−1m)m
(1-\dfrac{1}{m})^m，对m取极限可知D中约有36.8%的样本不会出现在
D′
D'中。这样，就可以把
D′
D'当做训练集，
D∖D′
D\backslash D'就是测试集了。
如何选择方法？
一般来说自助法比较适合数据集较小，难以有效划分训练/测试集的情况。而如果初始数据集比较足够时，留出法和交叉验证法更常用。
性能度量
一句话总结，性能度量就是建立衡量模型泛化能力的评价标准。
回归任务最常用的性能度量是均方误差mean squared error
E(f;D)=1m∑i=1m(f(xi)−yi)2
E(f; D) = \dfrac{1}{m}\sum_{i=1}^m(f(x_i)-y_i)^2
以下介绍分类任务常用的性能度量。
1. 错误率与精度
2. 查准率precision、查全率recall与F1
3. ROC与AUC
4. 代价敏感错误率与代价曲线
错误率与精度
错误率与精度自然就是算比例，最简单。
不过不能满足所有的任务需求，比如挑瓜，错误率相当于是有多少比例的瓜被判别错误。但如果需要知道挑出来的瓜有多少比例是好瓜，或者所有好瓜中有多少比例被挑了出来，就需要第二个性能度量了。
查准率、查全率与F1
所谓的查准率P和查全率R分别定义为：
P=TPTP+FP,R=TPTP+FN
P=\dfrac{TP}{TP+FP}, R=\dfrac{TP}{TP+FN}
变量是分类结果的混淆矩阵confusion matrix，表示为下表：
真实情况
预测结果正例
预测结果反例
正例
TP（真正例）
FN（反正例）
反例
FP（假正例）
TN（真反例）
所以它适用于二分类问题。查准率也就是在所有预测结果为正例的情况下的真实比例。查全率是所有真实情况为正例的情况下预测正确的比例。
P和R是一对矛盾度量，所以一般会综合两方面考量学习器的好坏，找到最佳平衡点BEP（Break-Even Point）。衡点定义是查全率等于查准率时的取值。
BEP过于简化，更常用的是F1变量，本质上是P和R的调和平均。
1F1=12(1P+1R)
\dfrac{1}{F1} = \dfrac{1}{2}(\dfrac{1}{P}+\dfrac{1}{R})
具体应用中可能对P和R有不同的倚重。比如商品推荐中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，这时候查准率更重要。而在逃犯检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要。
F1度量的一般形式
Fβ
F_{\beta}就可以表达这种偏好。
1Fβ=11+β2(1P+β2R)
\dfrac{1}{F_\beta} = \dfrac{1}{1+\beta^2}(\dfrac{1}{P}+\dfrac{\beta^2}{R})
也即是
Fβ=(1+β2)PRβ2P+R
F_{\beta}=\dfrac{(1+\beta^2)PR}{\beta^2P+R}
当
β>1
\beta>1意味着P占比重更大，反之则是R。
ROC与AUC
考虑样本预测排序，见书P33-35
代价敏感错误率与代价曲线
本质上就是为权衡不同类型错误所造成的不同损失，可为错误赋予非均等代价unequal cost。
比较检验
比较机器学习的性能不能直接通过度量值比较得出结果。统计假设检验为机器学习性能比较提供重要依据。
简单来说，若在测试集上观察到学习器A比B好，基于假设检验结果则能知道A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。
统计检验有四种方法：假设检验、交叉验证t检验、McNemar检验、Friedman检验与Nemenyi后续检验。
以下介绍假设检验，其余方法见书P40-44。
假设检验
以错误率为性能度量，假设测试错误率为
ϵ̂
\hat{\epsilon}，泛化错误率为
ϵ
\epsilon。由二项分布（独立采样基础上）知，泛化错误率为
ϵ
\epsilon的学习器被测得测试错误率为
ϵ̂
\hat{\epsilon}的概率为：
P(ϵ̂ ;ϵ)=Cϵ̂ xmmϵϵ̂ xm(1−ϵ)m−ϵ̂ xm
P(\hat{\epsilon};\epsilon)=C_m^{\hat{\epsilon}xm}\epsilon^{\hat{\epsilon}xm}(1-\epsilon)^{m-\hat{\epsilon}xm}
概率函数对
ϵ
\epsilon求导可知当
ϵ̂ =ϵ
\hat{\epsilon}=\epsilon是概率最大。
假设检验需要做的就是假设
ϵ≤ϵ0
\epsilon\leq\epsilon_0在
α
\alpha的显著度下能否被拒绝。
ϵ0
\epsilon_0是给定的一个概率值，意味着泛化错误率不能小于
ϵ0
\epsilon_0，
α
\alpha也是一个值，常用取值是0.05。如果不能被拒绝，也就意味着有95%的置信度认为学习器的泛化错误率不大于
ϵ0
\epsilon_0。
比如
ϵ0=0.3
\epsilon_0=0.3，根据二项分布，如果是10个样本，那么有3个错误分类的概率最大。
具体计算时只需把错误样本数大于3的概率求和，看是否小于
α
\alpha即可。
偏差与方差
通过实验可以估计学习算法的泛化性能，另一方面通过偏差与方差可以了解为什么具有这样的性能，偏差-方差分解bias-variance decomposition就是用来解释学习算法泛化性能的一种工具，试图拆解期望泛化错误率。
对测试样本x，定义
1.
yD
y_D为x在数据集中的标记，
y
y为x的真实标记（有可能出现噪声使得两者不等）
2. f(x;D)为训练集D上学的模型f在x上的预测输出
3. 噪声
ϵ2=ED[(yD−y)2]
\epsilon^2=E_D[(y_D-y)^2]，这里假设噪声期望为零，即
ED[yD−y]=0
E_D[y_D-y]=0
4. 偏差：期望输出与真实标记的差别
bias2(x)=(f¯(x)−y)2
bias^2(x)=(\bar f(x)-y)^2
5. 使用样本数相同的不同训练集产生的方差
var(x)=ED[(f(x;D)−f¯(x))2]
var(x)=E_D[(f(x;D)-\bar f(x))^2]
以回归任务为例，学习算法的期望预测为
f(x)=ED[f(x);D]
f(x)=E_D[f(x);D]
通过多项式展开合并，可将算法的期望泛化误差拆解为偏差、方差和噪声之和。（推导见书P45）
也即有
E(f;D)=bias2(x)+var(x)+ϵ2
E(f;D)=bias^2(x)+var(x)+\epsilon^2
回顾三者的定义，
1. 偏差：度量学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力
2. 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响
3. 噪声：表达了当前任务下任何学习算法所能达到的期望泛化误差的下限，即刻画了学习问题本身的难度
当学习器刚开始学习时，因为学习程度不足，偏差会主导泛化错误率，随着学习器拟合能力逐渐增强，数据集发生的扰动会被学习到，这时方差开始主导泛化错误率。在最后拟合能力非常强的情况下训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。