基本方程：Ax=b
本质上讲，机器学习需要基于算法系统，通过‘优化’去让等式的误差达到最小。
这里关注参数向量（权重）x的变化，直到找到一组适当的x值，使模型输出最接近真实输出。
当损失函数计算结果后，x就再次调整，缩小损失，直到极值点。
一个描述每个权重所带来的误差的误差矩阵会与权重矩阵本身相乘。
SDG是最基本的优化算法。
正则化和学习率属于模型的超参数，超参数的设置常常需要经验。
一些基本概念，描述了机器学习/深度学习可以干什么：
回归Regression：指通过自变量去估计因变量，预测真实值。简单讲就是预测。
回归解决“多少”的问题。
常见的是线性回归模型，如Ax=b.
矩阵形式：y = a + Bx ， a为函数图形与Y轴交点到原点距离
扩展形式：y = a + b0 * x0 + b1 * x1 + . . . + bn * xn
以散点图表示，预测的直线表示与所有的点的距离最短。
拟合Fitting：指用预测值f(x)去尽可能的接近真实值y. 相关的概念还有过拟合和欠拟合。
在Ax=b中，想求出x，有三个组件：
1. 内乘
2. 成本函数，常见的用（预测-实际）的平方。
3. 更新函数，即成本函数的导数。
非线性回归模型：
线性回归模型中，x的指数是1，非线性回归模型处理x指数大于1的情况，因而机器学习常被称为曲线拟合。
但完美的曲线拟合往往意味着过拟合，没有泛化和预测能力。
分类Classification：
分类解决“是什么”的问题。如5个苹果，“5个”是回归模型，“苹果”（而不是梨子）是分类问题。
分类基于输入的特征(features)，去回答是什么的问题。
基础的分类是2值分类。在0-1分类中，以0.5为分界。  单输出NN模型
N值分类中，可以为每个值打分。 多输出NN模型。
分类可应用于推荐系统，基于用户的相拟性或物品的相拟性。
最有名的是亚马逊的协作过滤(Collaborative Filtering)推荐算法，算是分类的变体。
聚类Clustering：
属于无监督学习算法，汉语上分类和聚类正好相反。但都是处理分类的问题，只是方法上不太一样。
它首先对每个样本有个距离的度量，距离相拟的样本是相拟的。然后迭代的移动这些样本，让它们靠得更近，结果形成了N个堆堆。
K-means算法是聚类的一个变体。