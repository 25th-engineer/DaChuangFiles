1、机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型（model）”的算法，即学习算法（learning algorithm）。有了学习算法，我们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供相应的判断。可以说，机器学习是研究关于“学习算法”的学问。
2、学得模型适用于新样本的能力，称为泛化（generalization）能力。具有强泛化能力的模型能够很好地适用于整个样本空间。
3、通常我们假设样本空间中的全体样本服从一个未知的分布（distribution），我们获得的每个样本都是独立地从这个分布上采样获得的。即独立同分布。关于这个采样样本与全体样本是独立同分布的关系是非常重要的，没有这个先验假设，后面的诸如卡方检验，t-检验，以及训练集，测试集的划分之类的就无从谈起。
4、关于归纳偏好
机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳偏好”（inductive bias）。
如果说，一个样本有三个特征(或者说“属性值”)，且这三个特征的不同取值都会影响到该样本的最终类别判定。那么我们应该能想到，这三个特征的不同取值对于类别判定的影响是有差别的。或许特征1对类别判定的影响更大些，又或许特征2对类别判定的影响更大些。我们可以简单的认为，每个特征前面都有一个权重参数w（在机器学习中，关于这一块的内容涉及到特征选择（feature selection），而特征选择有涉及到对样本的数据分析）。
我们需要知道的是，任何一个有效的机器学习算法，都必须尤其归纳偏好，否则他将无法产生确定的学习结果。
如下图所示一样。这里的每个训练样本都是图中的一个点（x，y）。要学得一个与训练集一致的模型，相当于找到一条穿过所有训练样本点的曲线。那么很显然，这条线不止一条。如果说，我们没有归纳偏好的话，那么我们就无法确定哪一条曲线才是正确的模型了。
那么，有没有一般性的原则来引导学习算法确立“正确的”偏好呢？奥卡姆剃刀（Occam’s razor）是一种常用的、自然科学中最基本的原则，即“若有多个假设与观察一致，则选最简单的那个。”
在上图中，很明显曲线A比曲线B更平滑，更符号奥卡姆剃刀原则，因此，我们自然地会更偏好曲线A。
然而，理想很美好，现实很骨感。奥卡姆剃刀只能说是在宏观意义上，作为一个指导性的一般原则，它并不一定适用于任何具体的问题。
事实上，归纳偏好对应了学习算法本身所作出的关于“什么样的模型更好”的假设（只是一个假设），在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能够取得好的性能。
如下图所示，我们就能看到，更符号测试样本的曲线B明显不符合奥卡姆剃刀原则。
所以，我们应该能够认识到，脱离具体问题来空谈哪个算法更好是毫无意义的。因为我们知道，算法就是为了解决问题而存在的，没有问题，哪里来得算法？
关于这一块，还有一个有趣的NFL（No Free Lunch）定理。该定理最最重要的寓意，就是让我们清楚的意识到，脱离具体问题空谈“什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所有的学习算法都一样好（宏观意义上）。要谈论算法的相对优劣，必须要针对具体的学习问题；在某些问题上表现良好的学习算法，在另一些问题上却可能不尽如人意。学习算法自身的归纳偏好与问题是否相匹配，往往会起到决定性作用。
5、我们实际希望的，是在新样本上能表现得很好的学习器，为了达到这个目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”。然后，当学习器把训练样本学得太好了的时候，很可能把训练样本中的一些局部性质当成了所有潜在样本都会具有的一般性质，这样就会导致学习器的泛化性能下降。这种现象在机器学习中被称为“过拟合（overfitting）”。与过拟合相对的是“欠拟合（underfitting）”，这是指对训练样本的一般性质尚未学好。有多种情况可以导致过拟合和欠拟合。其中欠拟合的问题很多解决，无非就是算法优化的问题，但是过拟合的问题就比较难解决了。可以说，这是机器学习所面临的关键障碍。虽然说，各种机器学习算法都会有针对过拟合的措施，然而，我们必须认识到，过拟合是无法避免的。我们所做的只能是“缓解”它带来的影响。这很好理解，因为毕竟我们是从样本数据中来学习的，所以无可避免的会携带有样本数据的特征。就像我们一个徒弟是师傅带出来的一样，徒弟也无可避免的会有师傅的影子一样。
6、通常我们认为测试样本也是从样本真实分布中独立同分布采样而得（同样本与总体一样）。在划分训练集与测试集的时候，需要注意两点。一是，测试集应该尽可能地与训练集互斥，即测试样本尽量不在训练集中出现，未在训练集中使用过。二是，训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，即尽可能的等比缩放数据集。
然而，实际上我们知道，要完全的，完美的做到这两点几乎是不可能的。所以，才产生了多种策略来划分数据集，包括留出法、交叉验证法、自助法等。
7、为了比较两个学习器的性能孰优孰劣，我们引入了多个指标，如错误率、精度、查准率、查全率、F1等，并且为了更直观的体现这个比较，我们引入了多种图来表示，如P-R曲线，ROC等。P31
8、在绘制ROC的时候，我们可以将测试样本进行排序，“最可能”是正例的排在最前面，“最不可能”是正例的排在最后面。这样，分类过程就相当于在这个排序中以某个截断点将样本分为两部分，前一部分作正例，后一部分则作反例。这样做的好处是，在不同的应用任务中，我们可根据任务需求来采用不同的截断点，若我们更重视查准率，则可选择排序中靠前的位置进行阶段；若更重视查全率，则可选择靠后的位置进行截断。
9、考虑到“代价敏感错误率”这一指标，我们希望选取最小化“总体代价”的学习器。而在这种非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，因此，我们引入了代价曲线（cost curve），P35
10、
实际上，在比较两个模型的性能这件事情上远比大家想象的复杂得多。
因为这涉及到几个重要的因素：首先，我们希望比较的是泛化性能，然后通过实验评估方法我们获得的只是测试集上的性能，两者的对比结果可能未必相同；第二，测试集上的性能与测试集本身的选择有很大关系。且不论使用不同大小的测试集会得到不同的结果，即便使用相同大小的测试集，若包含的测试样例不同，测试结果也会不同。第三，很多算法实际上都是有一定的随机性的，即便使用相同的的参数设置，在同一个测试集上运行多次，其结果也会有不同。
因此，正因为有这么多的无法确定的因素，所以我们才要在统计学上去寻求帮助
一般来说，我们首先要在统计意义上去验证单个学习期的度量指标是否是统计意义上可靠的，然后还需要在统计意义上去验证是否学习器A比学习器B在统计意义上性能优异些。
为了确定两个模型之间存在真正的差别，我们需要进行统计显著性检验。最后我们希望得到的是类似这样一个陈述：经检验，A分类器确实比B分类器好，且该论断的误差在正负4%以内。
总的来说，因为我们为了这样那样的目的（主要是考虑到计算开销），导致了我们使用的训练集并不是全体数据集。因此，这带了这样那样的问题（拟合问题，不独立同分布问题等），因此我们提出了这样那样的“补救措施（各种划分数据的方法，各种算法的改进）”。可以这样说，我们通过训练集得到的一系列参数，并不一定能够完全反映整体数据集，也就是说，这些参数不一定是可信的。
因此，我们在实际根据参数评估之前，要确定这些评估参数是可信的！！！
其思想是建立在评估参数有可能是错误的基础上的。
11、线性模型形式简单，易于建模，但却蕴含机器学习中一些重要的基本思想。许多功能更强大的非线性模型可在线性模型的基础上通过引入层级结构或高维映射而得。
线性模型一般用向量形式写成这样：f(x)=wTx+b，例如：f好瓜=0.2*X色泽+0.5*X根蒂+0.3*X敲声+1
12、对于离散的标称属性连续化时，考虑两种情况。一是，若属性值直接存在“序（order）”关系，则可以通过连续化将其转化为连续值。如｛高，矮｝可以转化为｛1.0,0.0｝。二是，若属性值间不存在序关系，则通常转化为K维向量。如｛西瓜，南瓜，黄瓜｝可转化为｛1,0,0｝，｛0,1,0｝，｛0,0,1｝。
13、线性回归（linear regression）试图学得一个线性模型，以尽可能准确地预测实值输出标记。均方误差是回归任务中最常用的性能度量（因为均方误差有非常好的几何意义）。我们求一个线性回归模型，通常就是取均方误差最小的那个。基于均方误差最小化来进行模型求解的方法称为“最小二乘法”。当然，最小二乘法的用途很广，不仅限于线性回归。
在线性回归中，最小二乘法就是试图找到一条直线，使所有样本到直线上的欧式距离之和最小。
14、处理类别不平衡问题的策略
目前我们已经学习到的分类学习方法都有一个共同的基本假设，那就是不同类别的训练样例数目相当。如果说，不同类别的训练样例数目稍有差别，那么通常影响不大。但若差别很大，则会对学习过程造成困扰。如在异常检测中，可能正常的数据占99%，而异常的数据只占1%。但恰恰是这1%的异常数据是有价值的而99%的数据是没有价值的。因此，如果我们直接那这样的训练集去跑，那么势必学习出来的模型没有任何价值。因为你没有提供给学习器足够的样例去学习，当然你可以说这个算法不行，但是针对这种类别不平衡的问题，目前学习算法也并没有很好的解决措施。所以我们只能想办法从数据方面来进行改进了。
类别不平衡学习的一个基本策略就是再缩放。其实就是我们通过对训练集进行一些人为的调整（增加或删除样例），來使得训练集中的样本类别达到平衡。
我们知道，理想的假设是：“训练集是真实样本总体的无偏采样”，然而，这个假设在现实生活中往往是不成立的。因此，目前处理这类问题的技术一般来说就是：过采样（增加一些正例，使得正、反例数目接近）和欠采样（去除一些反例使得正、反例数目接近）。
欠采样的时间开销通常远小于过采样法。因为它丢弃了很多反例，使得分类器的训练集远小于初始训练集，而过采样法增加了很多正例，使得分类器的训练集大于初始集。
这里需要注意的是，过采样法不能简单地对初始正例样本进行重复采样，这样做会导致严重的过拟合。正确做法是，通过对训练集里的正例进行插值来产生额外的正例；而欠采样也不能随机的丢弃反例，因为这样可能会丢失一些重要信息。正确做法是，采用集成学习。把一大份的反例分成一小份小份的，分别供不同的学习器使用。
15.机器学习的现实情况：
1、除非对每个可能的数据进行训练，否则总会存在多个假设使得真实错误率不为0，即学习器无法保证和目标函数完全一致
2、训练样本是随机选取的，训练样本总有一定的误导性
因此，任何机器学习算法都无法保证百分之百的精确，所以我们引入概率。
我们对一个学习器的要求为：
1、我们不要求学习器输出零错误率的假设，只要求错误率被限制在某常数ε范围内，ε可为任意小。
2、不要求学习器对所有任意抽取的数据都能成功预测，只要求其失败的概率被限定在某个常数μ的范围内，μ可取任意小。
简而言之，我们只要求学习器可能学习到一个近似正确的假设，故得到了“可能近似正确学习”或PAC学习（这是计算学习里面的内容）
一个可PAC学习的学习器要满足两个条件：
1、学习器必须以任意高的概率输出一个错误率任意低的假设
2、学习过程的时间最多以多项式方式增长
对于PAC来说，训练样本的数量和学习所需的计算资源是密切相关的
概括的说，我们知道机器学习不可能做到哲学意义上找到完美，但我们可以做到概率上的适用。根本上的原因是因为我们使用的数据集不可能就是真正的完整的数据集。我们能拿到的数据集只能看作是一种独立同分布的抽样数据集（而且这个独立同分布也不是完全意义上的就是，同样是概率），因为才会有PAC来保证说，我们这个机器学习在概率上是可行的，同时为了尽可能的消除这种影响，在具体的算法中，你才会看到很多措施。
最后多说一句，PAC可以看作是在理论上为机器学习打下了一个框架和基础。这个理论有点古老且富有争议，但现在仍然有很多人坚持做这个。
参考文章：
机器学习基石-台大林轩田
机器学习-周志华