弗雷德·贾里尼克（IBM语音研究组的领导）说过一句著名的俏皮话：“每开除一名语言学家，我的语音识别系统的错误率就降低一个百分点。”
《终极算法：机器学习和人工智能如何重塑世界》
([美]佩德罗·多明戈斯)
比尔·盖茨年度荐书！佩德罗·多明戈斯著的《终极算法机器学习和人工智能如何重塑世界精》是近20年人工智能领域具轰动性的著作！本书揭秘机器学习的终极逻辑，全景勾勒人工智能的商业未来。《乔布斯传》作者沃尔特·艾萨克森、图灵奖得主朱迪亚·珀尔、中国大数据领航人车品觉、今日头条首席算法架构师曹欢欢倾力推荐！
本文章内容摘自上书，有兴趣的请自行查阅原书。
所有知识，无论是过去的、现在的还是未来的，都有可能通过单个通用学习算法来从数据中获得。我将该学习算法称为“终极算法”。如果这种算法成为可能，它的发明将成为人类最伟大的科学成就之一。实际上，终极算法是我们最不愿意发明的东西，因为一旦对其放松，它会继续发明一切有可能发明的东西。我们要做的，就是为它提供足够、适当的数据，通过这些数据，它会发现相应的知识：给它视频流，它就会观看；给它图书馆，它就会阅读；给它物理实验结果，它就会发现物理定律；给它DNA晶体学数据，它就会发现DNA的结构。
机器学习的五个学派
机器学习主要有5个学派，我们会对每个学派分别介绍：
符号学派
将学习看作逆向演绎，并从哲学、心理学、逻辑学中寻求洞见；
联结学派
对大脑进行逆向分析，灵感来源于神经科学和物理学；
进化学派
在计算机上模拟进化，并利用遗传学和进化生物学知识；
贝叶斯学派
认为学习是一种概率推理形式，理论根基在于统计学；
类推学派
通过对相似性判断的外推来进行学习，并受心理学和数学最优化的影响。
五个学派各自算法特点
机器学习的5个学派都有自己的主算法，利用这种万能学习算法，原则上，你可以通过任何领域的数据来挖掘知识：
符号学派
主算法是逆向演绎
联结学派
主算法是反向传播
进化学派
主算法是遗传编程
贝叶斯学派
主算法是贝叶斯推理
类推学派
主算法是支持向量机
在实践中，这些算法可能在有些工作中可用，而在其他工作中不可用。我们真正想要寻找的是能够综合这5种算法的终极算法。虽然有些人认为这难以实现，但对机器学习领域的人来说，这个梦想赋予我们力量，促使我们夜以继日地工作。
机器学习的商业用途
如果你的主要兴趣是机器学习的商业用途，那么本书至少能通过6种方法帮助你：
成为分析学中更精明的消费者；
充分利用你的数据专家；
减少许多数据挖掘项目的隐患；
看看如果不买手写编码软件，你能让什么进行自动操作；
降低信息系统的僵硬度；
期待正朝你走来的新技术。
机器学习的形势
机器学习有许多不同的形式，也会涉及许多不同的名字：模式识别、统计建模、数据挖掘、知识发现、预测分析、数据科学、适应系统、自组织系统等。这些概念供不同群体使用，拥有不同的联系。有些有很长的半衰期，有些则较短。
学习算法
例如，朴素贝叶斯算法就是一个可以用短方程来表达的学习算法。只要提供患者病历的数据库，包括病人的症状、检查结果，或者他们是否有什么特殊情况，朴素贝叶斯算法就可在一秒之内做出诊断，而且往往比那些花几年在医学院学习的医生还要强，甚至它还可打败花费数千小时构建的医学专家系统。该算法还可应用于学习垃圾邮件过滤器，乍一看，这和医疗诊断毫无关系。另外一个简单的学习算法就是最近邻算法，它的用途十分广泛，从笔迹识别到控制机器人手，以及推荐你可能喜欢的书籍或者电影。决策树学习算法也同样擅长决定你的信用卡申请是否应被通过、寻找DNA中的绞接点，以及下棋时指导下一步该怎么走。
实际上，对所有主要的学习算法——包括最近邻算法、决策树学习算法以及贝叶斯网络（朴素贝叶斯的概括）——来说，如果你为学习算法提供足够、适当的数据，该算法可以实现任一功能（对学习任何东西来说，都与数学相关）。需要注意的是，“足够数据”也有可能无限。学习无限数据需要做出假设，如我们会看到的那样，而且不同的学习算法会有不同的假设。
各个学派的核心理念和关注的特定问题
我们寻找终极算法的过程是复杂且活跃的，因为在机器学习领域存在不同思想的学派，主要学派包括符号学派、联结学派、进化学派、贝叶斯学派、类推学派。每个学派都有其核心理念以及其关注的特定问题。在综合几个学派理念的基础上，每个学派都已经找到该问题的解决方法，而且有体现本学派的主算法。
对于符号学派来说，所有的信息都可以简化为操作符号，就像数学家那样，为了解方程，会用其他表达式来代替本来的表达式。符号学者明白你不能从零开始学习：除了数据，你还需要一些原始的知识。他们已经弄明白，如何把先前存在的知识并入学习中，如何结合动态的知识来解决新问题。他们的主算法是逆向演绎，逆向演绎致力于弄明白，为了使演绎进展顺利，哪些知识被省略了，然后弄明白是什么让主算法变得越来越综合。
对于联结学派来说，学习就是大脑所做的事情，因此我们要做的就是对大脑进行逆向演绎。大脑通过调整神经元之间连接的强度来进行学习，关键问题是找到哪些连接导致了误差，以及如何纠正这些误差。联结学派的主算法是反向传播学习算法，该算法将系统的输出与想要的结果相比较，然后连续一层一层地改变神经元之间的连接，目的是为了使输出的东西接近想要的东西。
进化学派认为，所有形式的学习都源于自然选择。如果自然选择造就我们，那么它就可以造就一切，我们要做的，就是在计算机上对它进行模仿。进化主义解决的关键问题是学习结构：不只是像反向传播那样调整参数，它还创造大脑，用来对参数进行微调。进化学派的主算法是基因编程，和自然使有机体交配和进化那样，基因编程也对计算机程序进行配对和提升。
贝叶斯学派最关注的问题是不确定性。所有掌握的知识都有不确定性，而且学习知识的过程也是一种不确定的推理形式。那么问题就变成，在不破坏信息的情况下，如何处理嘈杂、不完整甚至自相矛盾的信息。解决的办法就是运用概率推理，而主算法就是贝叶斯定理及其衍生定理。贝叶斯定理告诉我们，如何将新的证据并入我们的信仰中，而概率推理算法尽可能有效地做到这一点。
对于类推学派来说，学习的关键就是要在不同场景中认识到相似性，然后由此推导出其他相似性。如果两个病人有相似的症状，那么也许他们患有相同的疾病。问题的关键是，如何判断两个事物的相似程度。类推学派的主算法是支持向量机，主算法找出要记忆的经历，以及弄明白如何将这些经历结合起来，用来做新的预测。
每个学派对其中心问题的解决方法都是一个辉煌、来之不易的进步，但真正的终极算法应该把5个学派的5个问题都解决，而不是只解决一个。
联结学派与符号学派
联结学派对符号学派尤其不满。根据他们的观点，你能通过逻辑规则来定义的概念仅仅是冰山一角，其实表面之下还有很多东西是形式推理无法看到的。而同样的道理，我们脑子里所想的东西也是潜意识的。你不能仅靠构造一个空洞的机械化科学家，就想让他把所有有意义的事情完成，你首先得给他点什么东西，例如一个真正的大脑，能和真实的感觉相连，在真实世界中成长，甚至可能要常常绊他的脚。你怎样才能构造这样的大脑呢？通过逆向分析。如果想对一辆车进行逆向分析，你就应看看发动机盖下面。如果想对大脑进行逆向分析，你就要看看脑壳里面。
逆向演绎
逆向演绎就像一个超级科学家，系统查看论据，思考可行的归纳法，整理最有利的证据，然后将这些和其他论据一起，进一步提出假设——所有过程都基于计算机的速度。逆向演绎简洁而美观，至少符合符号学者的品位。此外，逆向演绎也有一些严重的缺点。可行的归纳法数量广泛，除非我们和最初知识保持亲密关系，否则很容易在空间中迷失。逆向演绎容易被噪声迷惑：我们怎样才能知道，哪些演绎步骤被漏掉了，如果前提或者结论本身就已出错？最严重的是，真正的概念很少能通过一个规则集来定义。它们不是黑，也不是白，比如垃圾邮件和非垃圾邮件之间有一片很大的灰色区域。要获取真正的概念，就得权衡并收集有弱点的论据，直到出现清晰的定义。疾病的诊断，涉及把重点放在一些症状上面，然后放弃那些不完整的论据。还没有人能只学习一个规则组，就能通过观看图片的像素来认出一只猫，而且可能以后也没人能做到。
零碎
玻尔兹曼机器
玻尔兹曼机器原则上可以解决赞誉分布问题，但在实践中，学习这个行为非常缓慢且痛苦，对大多数应用来说，玻尔兹曼机器有点不切实际。下一个突破会涉及解决麦卡洛克和皮茨时期的另外一个过度简化（oversimplication）问题。
S形曲线
S形曲线作为一个独立的模型，不仅很重要，它还是数学的万事通。如果放大它的中段部位，你会发现它近似一条直线。很多我们认为是线性的现象，其实都是S形曲线，因为没有什么能够毫无限制地增长下去。
S形曲线是线性函数非智能性和阶跃函数难解性的完美中转站。
朴素贝叶斯
一个基本的搜索引擎也会利用与朴素贝叶斯法极相似的算法来决定显示哪些页面来回应你的搜索。主要的区别在于：它会预测相关或非相关，而不是垃圾邮件或非垃圾邮件。运用朴素贝叶斯法来解决预测问题的例子几乎数不胜数。彼得·诺尔维格（谷歌的研究主任）一度告诉我，这是谷歌应用最为广泛的算法，谷歌的机器学习在每个角落都利用了该算法的功能。为什么朴素贝叶斯法会在谷歌员工中流行起来？这个问题不难回答。除了惊人的准确度，它的测量能力也很强。学习朴素贝叶斯分类器的原理，也仅相当于数出每个属性与每个类别出现的次数，花的时间不比从硬盘读取数据的时间长。
HMM
HMM还是计算生物学家最为喜爱的工具。一个蛋白质分子是一个氨基酸序列，而DNA则是一个碱基序列。举个例子，如果我们想预测一个蛋白质分子怎样才能形成三维形状，我们可以把氨基酸当作观察值，把每个点的褶皱类型当作隐藏状态。同样，我们可以用一个HMM来确定DNA中基因开始转录的地点，还可以确定其他许多属性。 如果状态和观察值都是连续而非离散变量，那么HMM就变成人们熟知的卡尔曼滤波器。经济学家利用卡尔曼滤波器来从数量的时间序列中消除冗余，比如GDP（国内生产总值）、通货膨胀、失业率。“真正的”GDP值属于隐藏的状态；在每一个时间点上，真值应该与观察值相似，同时也与之前的真值相似，因为经济很少会突然跳跃式增长。卡尔曼滤波器会交替使用这两者，同时会生成流畅的曲线，仍与观察值一致。当导弹巡航到目的地时，就是卡尔曼滤波器使它保持在轨道上。没有卡尔曼滤波器，人类就无法登上月球。
马尔可夫链蒙特卡洛理论-MCMC
最受人青睐的选择就是借酒浇愁，喝得酩酊大醉，然后整夜都在跌跌撞撞。该选择的技术术语为“马尔可夫链蒙特卡洛理论”（Markov chain Monte Carlo，MCMC）：有“蒙特卡洛”这个部分，是因为这个方法涉及机遇，比如到同名的赌场去，有“马尔可夫链”部分，是因为它涉及采取一系列措施，每个措施只能依赖于前一个措施。MCMC中的思想就是随便走走，就像众所周知的醉汉那样，以这样的方式从网络的这个状态跳到另一个状态。这样长期下来，每个状态受访的次数就与它的概率成正比。比如，接下来我们可以估算盗窃案的概率为我们访问某个状态的时间段，在这个状态中有一起盗窃案。一条“守规矩的”马尔可夫链会收敛到稳定分布中，所以过一会儿它总会给出大致一样的答案。
稀疏自动编码器
网络现在有比之前多很多的参数，那么你所处的超空间会有更多的维度，而你也有更多的方法来逃出局部最大值的困境。这就叫作稀疏自动编码器，而它是一个诀窍。
类比
类比在机器学习中扮演重要角色就不足为奇了。刚开始它进展缓慢，甚至被神经网络夺走了光芒。它的第一个算法的化身出现在一份写于1951年、名不见经传的技术报告中，作者是两位伯克利的统计学家——伊夫琳·菲克斯和乔·霍奇斯。这篇报告几十年之后才发表于主流期刊中。但同时，关于菲克斯和霍奇斯的算法的论文也开始出现，后来逐渐增加，直到它成为计算机科学界中受到研究最多的文章之一。最近邻算法，正如其名，是我们类比学习法之旅的第一站。第二站是支持向量机，这是世纪之交风靡机器学习领域的原理，但最近风头被深度学习掩盖。第三站也是最后一站，是成熟的类比推理法，几十年来是心理学和人工智能的重要组成部分，也是几十年来机器学习领域的背景主题。 5个学派中，类推学派是最不具有凝聚力的一个学派。
在机器学习中，相似性是核心思想之一，而类推学派会以各种伪装的方式来保护它。也许在未来10年，机器学习会被深度类比统治，在某种算法中，与最近邻法的高效、支持向量机的数学精密性、类比推理的力量和灵活性结合（瞧，我又泄露了自己的一个秘密研究计划）。
最近邻算法
最近邻算法的基础是找到相似物体，而在高维度情况下，相似性的概念就会无效。超空间就像过渡区域。在三维空间里的直觉不再适用，怪异离奇的事开始发生。想想一个橘子：一层薄薄的外壳包裹着好吃的果肉。比如橘子90%的半径是果肉，剩下的10%则是果壳，这意味着橘子73%的体积是果肉（0.93）。现在想象一个超级橘子：90%的半径还是果肉，但它在100个维度的空间中。那么果肉的体积已经缩小到超级橘子体积（0.9100 ）的1/3000。这个超级橘子全都是皮，而并且你绝对无法将其剥开。
零零碎碎
因表达水平概括起来，变成几条途径。心理学家已经发现，个性可以简化为5个维度（外向、随和、尽责、神经质、开放性），他们可以通过你的推特文章和博客帖子来进行推断（黑猩猩可能还有一个维度——反应性，但推特数据对它们并不适用）。
为了真正了解面部，以及世界上的大部分形状，我们需要另一样东西——非线性降维算法。
组块算法。
算法概括成通用形式——所有应用都需要知道该形式。
人类竞赛奖
2004年，他们创立一年一度的“人类竞争奖”（Humie Awards），来认可“人类竞赛”相关的遗传编程创作。迄今为止，已经颁发39个奖项。
思考
最重要的是，机器学习的目标是尽可能找到最好的学习算法，利用一切可能的方法，而进化和大脑不可能提供学习算法。进化的产物有很多明显的错误。例如，哺乳动物的视觉神经和视网膜前端而不是后端相连，这样会引起不必要的（而且异乎寻常的）盲点，就在中心凹旁边，而这里是视觉最敏锐的地方。活细胞的分子生物学原理非常混乱，分子生物学家常常自嘲道，只有对分子生物学一点也不懂的人才会相信智能设计。大脑的构造很有可能有相似的错误（大脑有许多计算机没有的限制，比如非常有限的短期记忆），而且没有理由待在这些限制里。另外，我们听说过许多这样的情形，人类似乎坚持做错误的事情，正如丹尼尔·卡尼曼在他的书《思考，快与慢》里详细说明的那样。
元学习
事实证明，要将许多不同的学习算法结合成一个并不难，利用的就是元学习。
网飞奖获得者利用元学习来结合数百个不同的学习算法；沃森利用它来从备选项中选择最终的答案；内特·希尔也以相似的方式将投票与预测选举结果结合起来。 这种类型的元学习被称为“堆叠”，是大卫·沃尔珀特的创见，在第三章中我们提到过他，他是“天下没有免费的午餐”定理的创造者。
元学习算法是“装袋”算法。
最聪明的元学习算法之一就是推进，由两位学习领域的理论家约阿夫·弗罗因德和罗伯·夏皮尔创造。
总结
你已经看到机器学习的五大学派以及它们的主算法：符号学派和逆向演绎，联结学派和逆向传播，进化学派和遗传算法，贝叶斯学派和概率推理，类推学派和支持向量机。
总结：学习就是你拥有的数据的数量和你所做假设数量之间的较量。
附录
本书的文后包含了一些文献和学习资料（英文版），有兴趣可以去了解下。
视频地址
作者佩德罗·多明戈斯的视频 - 点击跳转
安德鲁·恩格的课程 - 点击跳转
亚瑟·阿布·穆斯塔法的课程 - 点击跳转
开源软件包
Weka（www.cs.waikato.ac.nz/ml/weka）
可以作为教材的书籍
《Tom Mitchell的Machine Learning （McGraw–Hill, 1997）》
《Machine Learning: A Probabilistic Perspective》
麻省理工出版社，2012
作者：Kevin Murphy
《An Introduction to Statistical Learning with Application in R》
作者是：Gareth James、Daniela Witten、Trevor Hastie、Rob Tibshirani，Springer, 2013
《Machine Learning 》
《Journal of Machine Learning Research 》
作者的文章
“A few useful things to know about machine learning ”（Communications of the ACM, 2012）
机器学习会议
机器学习国际会议
International Conference on Machine Learning
国际神经信息处理大会
Conference on Neural Information Processing Systems
国际学术和技术开发研讨会
International Conference on Knowledge Discovery and Data Mining
机器学习网站
www.KDnuggets.com