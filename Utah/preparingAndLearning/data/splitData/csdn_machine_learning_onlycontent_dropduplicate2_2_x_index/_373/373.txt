机器学习常见评价指标：AUC、Precision、Recall、F-measure、Accuracy
主要内容
AUC的计算
Precision、Recall、F-measure、Accuracy的计算
1、AUC的计算
AUC是一个模型评价指标，用于二分类模型的评价。AUC是“Area under Curve（曲线下的面积）”的英文缩写，而这条“Curve（曲线）”就是ROC曲线。
为什么要用AUC作为二分类模型的评价指标呢？为什么不直接通过计算准确率来对模型进行评价呢？答案是这样的：机器学习中的很多模型对于分类问题的预测结果大多是概率，即属于某个类别的概率，如果计算准确率的话，就要把概率转化为类别，这就需要设定一个阈值，概率大于某个阈值的属于一类，概率小于某个阈值的属于另一类，而阈值的设定直接影响了准确率的计算。使用AUC可以解决这个问题，接下来详细介绍AUC的计算。
例如，数据集一共有5个样本，真实类别为（1，0，0，1，0）；二分类机器学习模型，得到的预测结果为（0.5，0.6，0.4，0.7，0.3）。将预测结果转化为类别——预测结果降序排列，以每个预测值（概率值）作为阈值，即可得到类别。计算每个阈值下的“True Positive Rate”、“False Positive Rate”。以“True Positive Rate”作为纵轴，以“False Positive Rate”作为横轴，画出ROC曲线，ROC曲线下的面积，即为AUC的值。
那么什么是“True Positive Rate”、“False Positive Rate”？
首先，我们看如下的图示：
然后，我们计算两个指标的值：
TruePositiveRate=TPTP+FN
True Positive Rate = \frac{TP}{TP+FN}，代表将真实正将本划分为正样本的概率
FalsePositiveRate=FPFP+TN
False Positive Rate = \frac{FP}{FP+TN}，代表将真实负样本划分为正样本的概率
接着，我们以“True Positive Rate”作为纵轴，以“False Positive Rate”作为横轴，画出ROC曲线，ROC曲线下的面积，即为AUC的值。类似下图：
2、Precision、Recall、F-measure、Accuracy的计算
首先，我们看如下图示（与上边的图示相同）：
精确率（Precision）：
Precision=TPTP+FP
Precision=\frac{TP}{TP+FP}
召回率（Recall）：
Recall=TPTP+FN
Recall=\frac{TP}{TP+FN}
F-measure：
F−measure=2×Precision×RecallPrecision+Recall
F-measure=\frac{2\times Precision\times Recall}{Precision+Recall}
准确率（Accuracy）：
Accuracy=TP+TNTP+TN+FP+FN
Accuracy=\frac{TP+TN}{TP+TN+FP+FN}
关于聚类的评价指标可以参考文章：
Clustering Algorithms and Evaluations
Evaluation of clustering
F-measure、RI 的计算