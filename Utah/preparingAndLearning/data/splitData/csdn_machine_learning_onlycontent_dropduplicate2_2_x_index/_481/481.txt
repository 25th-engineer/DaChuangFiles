说明
csdn传图麻烦，直接放github代码地址
感兴趣的伙伴直接跑一下代码就好
此外 本文是在用机器学习玩转恶意URL检测 的改进版本，推荐先阅读前文后来看本文。
课题要求：
识别恶意url，即将url分为正常的url和恶意url。属于机器学习中的二分类问题。
课题实现思路：
模型建立的整体思路如下：
1. 分别拿到正常请求和恶意请求的数据集。
2. 对无规律的数据集进行处理得到特征矩阵。
3. 选择机器学习的算法，使用特征矩阵训练检测模型。
4. 最后计算模型的准确度，并使用检测模型判断未知URL 请求是恶意的还是正常的。
做二分类机器学习的算法有很多，常见的有逻辑回归和svm。本次课题选择这两种分类模型探究识别恶意url的课题。
算法介绍：
逻辑回归的算法：
Logistic回归是一种广义线性回归（generalized linear model），目的是从特征学习出一个0/1分类模型，而这个模型是将特性的线性组合作为自变量，由于自变量的取值范围是负无穷到正无穷。因此，使用logistic函数（或称作sigmoid函数）将自变量映射到(0,1)上，映射后的值被认为是属于y=1的概率。
Logistic回归模型的适用条件二分类问题 所以选择逻辑回归做url分类.
支持向量机:
支持向量机（英语：Support Vector Machine，常简称为SVM，又名支持向量网络）是在分类与回归分析中分析数据的监督式学习模型与相关的学习算法。给定一组训练实例，每个训练实例被标记为属于两个类别中的一个或另一个，SVM训练算法创建一个将新的实例分配给两个类别之一的模型，使其成为非概率二元线性分类器。SVM模型是将实例表示为空间中的点，这样映射就使得单独类别的实例被尽可能宽的明显的间隔分开。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。
课题实现流程：
首先训练逻辑回归分类器。
数据集来源：
收集某系统网络访问日志，随机选择一天的日志，对日志预处理：去重和提取状态码为200的url和参数，写入到good_fromE.txt作为监督学习的正样本。
而恶意攻击的url样本比较难获取，选择从互联网上收集。结合github上一些知名仓库的payload，一共整理出 48126 条恶意请求作为恶意的数据集。
数据向量化
机器学习的算法需要输入一个固定结构的向量，而每一条url都没有特定的结构。故需要将每条url的文本特征转化成固定的数字特征。这里可以借鉴文本处理中将文本向量化的常用方法：TD-IDF.
TD-IDF 是一种用于资讯检索与文本挖掘的常用加权技术，被经常用于描述文本特征。
TF 词频（Term Frequency），表示词条在某文档中出现的频率。
IDF 逆向文件频率（Inverse Document Frequency）,作用在于如果包含词条的文档越少，则 IDF越大，说明该词条具有很好的类别区分能力。TF-IDF 倾向于过滤掉常见的词语，保留重要的词语。
TD-IDF输入的是文本的词语，需要将url分词。我们选择通过长度为N的滑动窗口将文本分割为N-Gram序列。n越大 ，产生的字母组合种类越多（256^n），产生的向量维度会更大，运算开销会增大，考虑到本机的性能，这里我们选择n=2。
经过TD-IDF处理，得到url的特征矩阵，由于很多特征向为0 ，所以该矩阵利用稀疏矩阵保存。输出格式是：
(0, 31445) 0.0739022819816 (0, 62475) 0.0629894240925 (0, 46832) 0.0589025342739 (0, 77623) 0.0717033170552 (0, 35908) 0.0882896248394 : 省略 :
[(i,j) weight] 表示第i行j列的词语权重为weight
逻辑回归模型
得到了url的特征矩阵后，我们需要将数据集分为训练集和测试集。
训练集用于训练模型，测试集则是根据训练集的训练结果来评判最终的训练效果。一般而言，测试集应该和训练集尽可能保持互斥。这里我们使用sklearn.cross_validation中的train_test_split方法。之后将训练集输入分类器，训练完成之后就可以进行预测。
预测结果：
这里我们使用sql恶意注入的日志作为预测的数据。得到结果：
可见逻辑分类模型将注入的url全部识别。可以说明在注入这块的识别效果不错。
用负样本进行判断：
表现不错。
在读取另外一天正常访问的url：
存在一定的误报。但总体效果可以说比较理想。
总结：
基于逻辑回归的恶意 URL 检测很依赖于训练数据集，有必要保证原始数据集尽可能的减少噪点（异常数据），以及每条数据之间尽可能的减少关联性。
若能拿到自身业务中确定正常或者威胁的请求数据作为训练数据集训练出的模型应该也更加适用于当前环境的检测。
同时作为监督式学习，可以定期把检测出确定威胁的请求放入原始数据集中，对检测模型进行优化，效果会更好。
支持向量机
下面测试svm分类的效果。
svm模型训练过程和逻辑回归模型类似，代码复用，只需将self.classifier 改成 svm.SVC()即可。
预测结果
训练模型的正确率远远低于逻辑分类模型，训练时间也长于逻辑分类器。虽然在于识别错误上也一样全部识别出，不过该分类器的误报率太高，识别出来的结果没有说服力。
经查阅资料，svm对数据的异常点比较敏感，因为其训练只需要支持向量，有效样本本来就不高，一旦被干扰，预测结果难以预料。一般输入svm的数据维度不宜太高，我们训练的数据集有4117维，故我们决定在处理前加入降维模块。
我们选择用kmeans降维。该算法的主要思想是通过迭代过程把数据集划分为不同的类别，使得评价聚类性能的准则函数达到最优，从而使生成的每个聚类内紧凑，类间独立。
我们选择降维到80维度
加入降维后：
可见，对数据降维后svm运行的速度和正确率都大大提升了
错误url也能全部识别：
那是不是说明逻辑分类算法加入kmeans效果也会提升呢？
对此我们做了一个实验：
相对于原来的正确率有所下降，可见不同算法都有不同的适用场景。
总结
逻辑回归判断和svm都是常见的分类算法，从目标函数来看，区别在于逻辑回归采用的是logistical loss，svm采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。两者的根本目的都是一样。所以在很多实验中，两种算法的结果是很接近的。
但是逻辑回归相对来说模型更简单，好理解，实现起来，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些。但是SVM的理论基础更加牢固，有一套结构化风险最小化的理论基础，虽然一般使用的人不太会去关注。还有很重要的一点，SVM转化为对偶问题后，分类只需要计算与少数几个支持向量的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算量。
课题总结：
本课题属于机器学习在信息安全方面的应用。难点和挑战在于对信息安全常见攻击的熟悉程度，机器学习算法的了解以及对大数据的处理。通过第一周的学习我们了解了常见的攻击形式，第二周学习了机器学习算法的应用，第三周结合前面所学完成了这个url分类的程序。
在完成课题遇到的问题有：
内存错误。由于机器性能所限制，学习的样本量不能很大，曾尝试过用一百万条url来训练分类器，跑了几个小时后抛出了memory error
代码效率低下。本程序第一版完成时在小样本数据中可以顺利跑完，而当给予数据量比较大时（）10000）跑了基本一天才完成。一句句debug后发现性能瓶颈在于自己实现的transform函数，此函数利用矩阵的行加法（newWeight[label[i]] += weight[j]）实现kmeans聚类后的同类合并。通过Why are lil_matrix and dok_matrix so slow compared to common dict of dicts? 了解不同稀疏矩阵的存储操作效率不同，最好的合并方式还是通过构建Python内置的对象来实现稀疏矩阵的行加法。最后时间从原先1个多小时到现在只需要1秒钟。
课题局限：
本课题使用的是监督学习下的二分类器。需要标定的数据集。然而在现实环境中，由于攻击方式的多样性，很难获得覆盖全面的恶意攻击url数据集，导致在面对零日攻击这类比较新的攻击url具有一定的脆弱性。
此外本次课题由于硬件的限制，样本数据集还没有到达百万集，准确度会受到影响。
改进思路：
在探寻改进方式时，我们找到了一篇发表在Elsevier Science上的论文 McPAD：A Multiple Classifier System for Accurate Payload-based Anomaly Detection
该论文指出，由于我们只有大量白样本，可以考虑通过单分类模型，学习单类样本的最小边界，边界之外的则识别为异常。通俗的讲，就是与其学习攻击的url特征，不如直接学习正常url的特征，拒绝所有不符合正常特征的url，以不变应万变。
这里简单介绍论文实现的思路：
mcpad通过训练多个svm单分类器同时判断url是否正常，来提高系统的精确度。
为了训练多个不同分类器，需要不同的样本，通过ngram中n取不同值的方式来将url划分成不同的向量是一种解决方案，然而此举会导致特征空间成指数性增长（特征空间=256^n）增加计算的复杂度和空间开销。论文提出2ν-gram的向量化方式，ν代表所取两个字母间的间隔。通过数学验证了该方法既不会损失信息也不会增加运算的复杂度。使用kmeans对数据进行降维后训练出多个单分类器来进行url的判断。单分类器的组合方式：Average, product, maximum and minimum probabilities， major voting
该图为不同参数下的识别效率。
该论文为我们提供了一种新颖的向量化url的方法，值得我们后续改进时借鉴。