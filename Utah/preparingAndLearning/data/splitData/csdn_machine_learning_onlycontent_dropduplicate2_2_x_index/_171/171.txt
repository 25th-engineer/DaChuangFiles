人工智能行业如火如荼，想要入门人工智能，吴恩达老师的机器学习课程绝对是不二之选（当然，这不是我说的，是广大网友共同认为的）
教程的地址链接：
Coursera吴恩达机器学习教程
有的同学可能进不去这个网站，解决办法参照如下链接：
无法打开Coursera观看教程的解决办法
这个办法本人亲测有效，因为我看的时候也打不开（囧！！）
要是这个办法也不行，那就只能退而且其次，请直接移步到bilibili网站上去看吧~
bilibili上的吴恩达机器学习教程
言归正传，在这门课程的开头，吴老师举了很多个机器学习的例子，比如垃圾邮件筛选，人脸识别，推荐系统以及他的直升机自主飞行实验，举了这么多个例子，其实就是想说为啥需要机器学习？？ 答：因为有些问题依靠传统的编程方法很难解决或者没法解决。比如音乐推荐系统，面对海量用户，不可能针对每个用户都写一个适合他们喜好的音乐推荐程序，所以就需要机器学习。那大概要怎么办呢？就是通过获取每个用户的音乐选择信息，然后给音乐贴上标签，告诉计算机这是啥类型的音乐，通过不断滴告诉计算机每个用户喜欢的音乐类型是什么，计算机就可以根据这些经验，来给用户自动推荐他们喜欢的音乐。
那么上面的描述就已经包含了机器学习的定义了，机器学习就是通过给计算机输入某个任务的经验，来让计算机更好地完成该任务，音乐推荐就是任务，获取用户的音乐类型信息就是经验，最终计算机通过得到的经验更好的完成音乐推荐任务。
接着，吴老师又讲了监督学习，他举了两个例子，一个是房价预测，另一个是肿瘤性质判定。第一个案例就是说给定一些房房子的每平米价格，然后让你根据这些数据判定一个房子每平米大约能卖多少钱，这其实有点像初中学习的求取函数式问题，只不过那时候只有几个点，函数式就那么几个，现在不一样了，函数式很多，用这个好像可以，用那个好像也行。就像他视频课图里画的：
用直线可以描述，用曲线也可以描述，得到的结果也不大一样，所以给这个问题起一个比较高大上的名字，回归问题。这类问题的特点就是给定一些正确的数据作为训练集，然后用这些数据集拟合出来一个公式，然后用这个公式再去预测未知的问题，比如房价，股票价格等等
第二个案例是判定肿瘤性质的，就是根据肿瘤的大小来判定肿瘤是恶性还是良性，直接看图吧~
这个图中蓝色的是良性，红色的是恶性，粉色的是要咱们根据这些数据来预测的，我的预测结果是可能良性也可能恶性（感觉和没说一样......）。的确，只根据这么一个特征的确不好判断，所以吴老师又给出了其他特征，如下图所示：
在这个图里，又加入了患者的年龄特征，然后又重新给出了数据集，然后一刀切，下面的就是良性，上面的就是恶性，虽然还有例外，但是也比较真实了。如果还想让预测结果更加准确，那就得加更多的特征（比如肿瘤形状），用更好的数据集来训练了。更准确的说，这其实是个分类问题，同案例一一样，用正确的数据来训练，只不过把预测结果分成了两类（当然，实际问题可能不止两类），不像案例一中的房价有好多情况。
总而言之，监督学习就是用正确、已知、既定事实的数据来给未知的问题做预测，其中回归问题得到的结果有很多，类似于函数式的输出，输出是连续的，而分类问题的结果就那么几种，输出结果是离散的。
然后呢，吴老师又讲了无监督学习，无监督学习的概念就是给出的数据都没有任何特征，需要使用某种聚类算法使数据能自动分成多类。就像下面这张图
图里面的数据表面上看都是一样的，但是通过聚类算法，可以将上述数据分成两类，如下所示
也就是说，聚类算法的作用就是将一堆事先没有任何特征的数据做分类。还拿音乐推荐系统为例，当得到一堆用户数据之后，使用通过用户常听的音乐对用户进行聚类，然后就可以知道某些用户喜欢哪种类型的音乐，然后将这些用户划分为一类，最后由计算机向该类型用户推荐对应的音乐
还有一个应用就是查看社交软件上用户的常用联系人，通过聊天频度对用户进行聚类，然后就可以知道哪些人是你的常用联系人。类似的例子还有很多，大家自行谷歌百度。当然，聚类只是无监督学习的一种。非聚类的无监督学习的一个很经典的例子就是鸡尾酒会算法，就是让机器在一片嘈杂的环境中辨别或是提取出某种特定的声音
所以，无监督学习就是就是通过算法并根据数据中的变量关系来将数据进行分类
到这里呢，lecture one就讲完了。
课件在这里：课件链接
密码：3pme
如果连接失效，请在下方留言告诉我