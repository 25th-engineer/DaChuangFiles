本文档记录了《机器学习》第 15 章规则学习相关内容
基本概念
形式化定义
⊕←f1∧f2∧...∧fL
\oplus\leftarrow\mathbf{f}_1\wedge\mathbf{f}_2\wedge...\wedge\mathbf{f}_L
左侧称为规则头
右侧称为规则体
L
L 为规则的长度
解决规则冲突
投票法：判别相同的规则数最多的结果作为最终结果
排序法：在规则集合上定义一个顺序->带序规则学习/优先级规则学习
元规则法：定义关于规则的规则指导使用规则集
规则分类
命题规则：原子命题+逻辑连接词
一阶规则：原子公式，谓词、量词
一阶规则比（逻辑规则？？？）强很多，能表达复杂的关系，称为关系型规则，其语义层面与人类的语义层面一致。
序贯覆盖
关键
如何从训练集学出单条规则
学习规则的方法
穷尽搜索
从空规则开始，将正例类别作为规则头，逐个遍历训练集中的每个属性及取值。\
在属性和候选值较多时会存在组合爆炸的问题。
自顶向下
从比较一般的规则开始，逐条添加新文字以缩小规则覆盖范围
生成-测试法
规则逐渐特化
对噪声的鲁棒性较强，适用于命题规则学习
先考虑规则的准确性，然后考虑覆盖的样本数，然后考虑属性次序等等
自底向上
从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范围
数据驱动法
规则逐渐泛化
适用于假设空间较复杂的任务，如一阶规则学习
剪枝优化
统计显著性检验
CN2——似然率统计量LRS
LRS=2⋅(m̂ +log2(m̂ +m̂ ++m̂ −)(m+m++m−)+m̂ −log2(m̂ −m̂ ++m̂ −)(m−m++m−))
\text{LRS}=2\cdot(\hat{m}_+\text{log}_2\frac{(\frac{\hat{m}_+}{\hat{m}_++\hat{m}_-})}{(\frac{m_+}{m_++m_-})}+\hat{m}_-\text{log}_2\frac{(\frac{\hat{m}_-}{\hat{m}_++\hat{m}_-})}{(\frac{m_-}{m_++m_-})})
LRS越大，采用规则集进行预测与直接使用训练集正、反例比例进行猜测的差别越大。
LRS越小，规则集的效果越可能是偶然现象。
后剪枝
减错剪枝REP
一次训练集学习规则集

\mathcal{R}
多轮剪枝：每轮穷举所有可能的简直操作，然后用验证集对剪枝产生的所有候选规则集进行评估，保留最好者
循环多次
设训练样本数为
m
m，时间复杂度
O(m4)
O(m^4)
Incremental REP
在REP上改进
每次生成一条规则
r
r立即在验证集上进行剪枝得到规则
r′
r'，并将覆盖样例去除
时间复杂度
O(mlog2m)
O(m\log^2m)
RIPPER
使用IREP*剪枝机制生成规则集

\mathcal{R}
对
r∈
r\in\mathcal{R}，生成：
r′
r'：基于
r
r的覆盖样例，通过IREP*生成的替换规则
r″
r''：对
r
r增加文字进行特化，然后IREP*生成的修订规则
将原规则集（
r
r）和新规则（替换为
r′
r'和
r″
r''）分别进行评估，留下最好的
循环上述过程
一阶规则学习
命题规则学习的缺陷：难以处理对象之间的关系。
引入领域知识
在现有属性基础上构造新的属性
基于领域知识设计某种函数机制约束假设空间
First-Order Inductive Learner（FOIL）
特点
序贯覆盖
自顶向下（泛化到特化的过程）
FOIL增益
FGain=m̂ +×(log2m̂ +m̂ ++m̂ −−log2m+m++m−)
\text{F}_\text{Gain}=\hat{m}_+\times(\log_2\frac{\hat{m}_+}{\hat{m}_++\hat{m}_-}-\log_2\frac{m_+}{m_++m_-})
m̂ +
\hat{m}_+和
m̂ +
\hat{m}_+分别表示增加候选文字后新规则所覆盖的正负样本数
m+
m_+和
m+
m_+分别表示原本规则所覆盖的正负样本数
因为关系数据中的不平衡性，仅考虑正例的信息量
总结
FOIL可以被看做是命题规则学习和归纳逻辑程序设计之间的过渡，但其自顶向下的规则生成过程不支持嵌套，所以表达能力仍有不足。
归纳逻辑程序设计（Inductive Logic Programming，ILP）
目标：完备的学习一阶规则
自底向上——特化到泛化的过程，每次学习单条规则
与普通一阶规则学习相比引入了函数和逻辑表达式的嵌套
最小一般泛化（Least General Generalization，LGG）
给定一阶公式
r1
r_1和
r2
r_2
找出涉及相同谓词的文字
常量替换
在两个公式中出现位置相同——保持
不同则将它们替换为同一个新变量
忽略两条公式中不含共同谓词的文字
R(elative)LGG：初始规则选择方法，考虑所有背景知识。
逆归结
演绎（Deduction）和归纳（Induction）
演绎：从一般性规律出发来探讨具体事物（对应特化）
归纳：从个别事物出发概括出一般性规律（对应泛化）
归结和逆归结
归结：将貌似复杂的逻辑规则与背景知识联系起来化繁为简
逆归结：基于背景知识发明新的概念和关系
逆归结形式化定义
设两个逻辑表达式
C1
C_1、
C2
C_2成立，且分别包含互补项
L1
L_1和
L2
L_2，可令
L=L1=¬L2,C1=A∨L,C2=B∨¬L
L=L_1=\neg L_2,C_1=A\vee L,C_2=B\vee\neg L，可以通过归结原理得到归结项
C=A∨B
C=A\vee B。
与该过程相反，逆归结是研究在已知
C
C和某个
Ci
C_i的情况下如何得到其余
Cj
C_j：
C2=(C−(C1−{L}))∨{¬L}
C_2=(C-(C_1-\{L\}))\vee\{\neg L\}
逆归结的四种操作
吸收
辨识
内构
互构
（×）蕴含、置换和合一（-）
蕴含：
X/Y
X/Y
置换：用某些项来替换逻辑表达式中的变量
e.g.
用
θ=1/X,2/Y
\theta={1/X,2/Y}置换
C=r1(X,Y)∧r2(X,Y)
C=r_1(X,Y)\wedge r_2(X,Y)，可得
C′=Cθ=r1(1,2)∧r2(1,2)
C'=C\theta=r_1(1,2)\wedge r_2(1,2)
其中
X,Y
{X,Y}称为
θ
\theta的作用域。
合一：用一种变量置换令两个或多个逻辑表达式相等
e.g.
令
A=r1(1,X),B=r1(Y,2)
A=r_1(1,X),B=r_1(Y,2)，可以使用
θ=2/X,1/Y
\theta={2/X,1/Y}得到
Aθ=Bθ=r1(1,2)
A\theta=B\theta=r_1(1,2)，在此情况下称
A
A和
B
B是可合一的，
θ
\theta为合一化子。
（×）一阶逻辑中利用合一操作搜索互补项
自动发明新谓词