人工智能、机器学习和数据将推动未来生产力的发展
http://note.youdao.com/share/index.html?id=9874d468e9dece80bcc23819232438fd&type=note&from=timeline&isappinstalled=0#/
人工智能是信息时代的尖端技术。在最新的“创新简介”系列文件中，我们研究机器学习和深度学习的进步如何与更强大的计算和不断扩大的数据库相结合，为跨行业的公司带来人工智能变革。人工智能服务的发展有可能开辟新的市场，破坏云计算的竞争环境。 我们相信，如何更好地利用人工智能将成为未来几年公司竞争优势的决定因素，并将带来生产力的复苏。
目录
投资组合经理总结………………………………………………3
什么是人工智能？…………………………………………….. 8
价值创造的关键驱动力………………………………………10
推动生产力的未来……14
人工智能和生产力的悖论：专访Jan Hatzius…..17
生态\云服务\开源人工智能投资周期的受益者.. 20
农业………………………. 43
金融………………………..53
医疗保健…………………63
能源………………………. 82
推动者…………………….90
附录………………………. 97
投资组合经理总结
人工智能（AI）是信息时代的尖端技术。从人类告诉计算机如何操作到计算机学着如何自主操作是计算机运作领域一次巨大的飞跃，对每一个行业都有着重要的意义。虽然现在可能被视为人工智能寒冬前最新一轮的承诺和失望，这些投资和新技术将至少留给我们机器学习所生产的有形的经济效益。
与此同时，人工智能和自动驾驶已经上升到了流行文化的前沿，甚至是政治话题，但是我们过去一年以来的研究让我们相信，这不是一个错误的开始，而是一个拐点。本报告将深入探讨这个拐点，从明显的更多更快的计算以及数据爆炸到更微妙的深度学习、显著进步专业硬件和开源的兴起。
其中一个更令人兴奋的人工智能方面的拐点是，“现实世界”的使用案例比比皆是。而深度学习使得计算机视觉和自然语言处理等技术不断进步，大幅提升了苹果的Siri，亚马逊的Alexa的质量和谷歌的图片识别，人工智能不仅仅是技术的技术。大数据集与强大的技术相结合创造了价值，也获得了竞争优势。
例如，在医疗保健中，图像识别技术可以提高癌症诊断的准确性。在农业中，农民和种子生产者可以利用深度学习技术来提高作物产量。在药物方面，深度学习用于药物发现。在能源领域，勘探效率和设备可用性逐步提高。在金融服务中，通过打开了新的数据集，成本降低收益增加，分析比以前更快。人工智能的运用善且处于非常早期的阶段，必要的技术通过基于云的服务，我们相信创新的浪潮的创新将滚滚而来，创造出各行各业新的赢家和输家。
人工智能的广泛适用性也让我们得出这样的结论：它是一个针移动技术，为全球经济和生产力提供驱动力，并结束美国生产率增长的停滞期。根据高盛首席经济学家Jan Hatzius的研究，我们的框架目前停滞在资本深化及其对美国生产力的相关影响。我们认为，人工智能技术驱动对生产力的改进将与20世纪90年代相似，带动企业投入更多的资本和劳动密集型项目，来加快发展，提高盈利能力和扩大股权估值。
启示
虽然我们看到人工智能影响每一个公司，行业和细分经济的时间，其中有四个最为显著的对投资者的启示。
生产力。人工智能和机器学习有可能掀起一个循环的生产率增长从而有利于经济增长，企业盈利，资本回报和资产估值。根据高盛首席经济学家Jan Hatzius“原则上，人工智能看起来确实像可能用数据捕获得更为准确，相较于人工智能所能达到的最后一拨创新浪潮去降低高附加值生产类型的成本和劳动力投入。例如在商业部门的为了节约成本的创新是统计学家比起增加iPhone应用程序的多样性和可用性而言更好地去捕获。在商业部门里，人工智能对成本结构有深远基础的影响，我相信它将被统计学家所接受，并且会显示在整体生产力数据中。
高级技术。人工智能的速度和机器学习的价值有可能扭转在构建数据中心和网络时更便宜的商品硬件的趋势。我们认为这可能推动硬件，软件和服务支出的市场份额大幅度转变。例如，在标准数据中心瞬时计算上运行的AWS工作负载只需要0.0065 美元每小时，而对于为人工智能优化的GPU成本为0.900美元每小时。
竞争优势。我们看到了人工智能和机器学习重新整理每个行业的竞争秩序的潜力。管理团队未能投资和传递这些技术风险给受益于战略情报、生产所得以及创造的资本效率的竞争者。在第41页开始的小插曲中，我们将研究如何在医疗保健，能源，零售，金融和农业领域发展这些竞争优势。
创建新公司。我们在过去10年人工智能和机器学习领域创立的企业中确定了150多家私人公司（附录69-75）。虽然我们相信，人工智能大部分的价值将会积累于大公司的资源，数据和投资能力，我们期望风险资本家，企业家和技术专家将继续推动创建新的公司，反过来，驱动实质创新和价值创造至少是并购虽然我们当然不会排除人工智能中的“谷歌或Facebook”的出现。
在下面的内容中，我们深入探讨了人工智能的技术，历史，机器学习的生态系统，以及这些技术在行业和领先公司的应用。
什么是人工智能？
人工智能是使智能机器和计算机程序能够以通常需要人类智能的方式学习和解决问题的科学和工程。通常，这些包括自然语言处理和翻译，视觉感知和模式识别以及决策，但应用程序的数量和复杂性正在迅速扩大。
在本报告中，我们将大部分分析集中在作为人工智能一个分支的机器学习，以及作为机器学习的一个分支的深度学习。我们强调两个要点：
1.简单来说，机器学习是从例子和经验（即数据集）学习而不是依赖于硬编码和预定义规则的算法。换句话说，不是开发者告诉程序如何区分苹果和橙子，算法被数据“训练”并且自己学习如何区分苹果和橙子。
2.深度学习的主要进展是当前AI拐点背后的驱动力之一。深度学习是机器学习的一个子集。在大多数传统的机器学习方法中，特征（即可以预测的输入或属性）由人设计。特征工程是一个瓶颈，需要大量的专业知识。在无监督深度学习中，重要特征不是由人类预定义的，而是由算法学习和创建的。
要明确的是，我们还没有专注于那种真正的，强大的，或通常的人工智能，那种为了复制独立的人类智力，这往往是人工智能通俗和流行的文化释义。虽然有一定的潜在的突破，如谷歌DeepMind的alphago系统，不仅击败了围棋世界冠军，也用了没有人用的下棋方式，我们专注于更直接的经济实体的发展领域中的人工智能。
为何人工智能发展在加速？
在深入学习能力的重大飞跃一直是目前人工智能拐点的背后催化剂之一。神经网络，深层学习背后的技术框架，已经存在了几十年，但在过去的五到十年中，有三件事情发生了变化。
1.数据。越来越多无处不在的连接设备、机器和系统在全球范围内创造了非结构化数据量的巨大增长。神经网络变得更加有效随着他们有了更多的数据，这意味着随着数据量增加的问题，机器学习可以解决使用的数据增加。移动，物联网，和成熟的低成本数据存储和处理技术（通常在云中）创造了可用数据集的数量，规模和结构的大规模增长。例如，特斯拉已经聚集78，000万英里的驾驶数据，加上另一个每十小时百万英里通过其连接的汽车，而蟑螂合唱团（由思科月2016美元14亿收购）有一个平台供电的机器对多个汽车制造商和电信公司进行通信。Verizon公司在八月也有类似的投资，宣布将收购Fleetmatics，通过无线网络云软件连接在车辆远程传感器越来越快。5G的推出只会加快数据生成和发送的速度。年度数据生成有望在2020年前达到44泽字节（万亿GB），根据IDC的数字宇宙报告，超过五年的复合增长率达到了141%，这表明我们正开始将这些技术应用。
：年度数据生成有望在2020年前达到44泽字节（万亿GB）
2.更快的硬件。图形处理单元（GPU）的再利用，低成本的计算能力的通用性，特别是通过云服务，并建立神经网络模型大大提高了速度和精度可以产生神经网络的结果。GPU及其并行体系结构更快地训练了机器学习系统与传统的中央处理单元（CPU）为基础的数据中心架构。再利用图形芯片的网络可以让迭代速度更快，在更短的时间内进行更准确的培训。在同一时间，专业硅的发展，如正在使用现场可编程门阵列的微软和百度，受过训练的深度学习系统允许更快的推论。更广泛地说，超级计算机的原始计算能力自1993以来呈指数级增长（）。2016，一个高端的NVIDIA显卡，对于游戏PC具有足够的计算能力已列为2002年前世界上最强大的超级计算机。
：超级计算机的原始计算能力自1993以来呈指数级增长
业绩成本也大幅下降。NVIDIA的GPU（GTX 1080）提供9tflops表现为大约700美元，这意味着它的每一个GFLOPS价格大约8美分。1961年结合足够的IBM 17世纪20年代到提供一个单一的GFLOPS需要超过9兆美元（经通胀调整）。
：每单位计算的价格随着时间的推移急剧下降
3.更好和更广泛的可用算法。更好的输入（计算和数据）驱动更多的算法研发，以支持深度学习用例。开源框架，如伯克利的咖啡，谷歌的tensorflow，和火炬（用于脸谱网）允许开发者通过依靠测试的基础库复合个人的贡献度。拿TensorFlow举例，在不到一年的时间里，已成为GitHub上最大最活跃的开发商合作网站。虽然不是所有的人工智能都发生在一个广泛可用的开源框架下，（苹果在这一领域的秘密是众所周知的），他们的可用性肯定加快了更先进的开源工具的发展。
看看周边
虽然本报告的重点是人工智能，以及公司如何往这条路发展，重要的是要意识到人工智能已经影响我们的生活的程度。
在线搜索。就在一年前，谷歌透露，它已经开始相当数量的搜索rankbrain，一个人工智能系统，与链接和内容一起成为谷歌搜索算法中三个最重要的信号之一。
推荐引擎。Netflix、Amazon和潘多拉都利用人工智能来推荐电影、产品突出和歌曲播放。5月，亚马逊的开放源码DSSTNE，深度可伸缩的稀疏张量网络引擎，简称“命运”，它使用生产产品的建议，以便它可以超越语言理解和目标识别。
面部识别。谷歌（facenet）和脸谱网（DeepFace）已投入巨资来发展必需的技术确定接近百分之百的准确度来识别照片中的面孔。一月，苹果进一步收购Emotient，人工智能启动读取面部表情来判断情绪状态。显然，这些技术远远超过标记照片。
虽然有无数的个人助理的消费者例子，比如苹果的Siri，信贷和保险风险评分，甚至天气预报，在接下来的内容中我们考察企业利用这些技术来加速增长，降低成本以及控制风险。这些技术和应用的速度本身也在发展，充其量是一个快照的时间，为公司和投资者在他们的竞争者中一路领先提供了方向。
什么是人工智能？
人工智能是描述计算机模拟智能行为的科学。它需要使计算机表现出人的行为特征，包括知识，推理，常识，学习和决策。
什么是机器学习？机器学习是人工智能的一个分支，它使计算机能够从数据中学习而不需要显式编程。为了提供简单的背景，一台计算机可以以编程来识别照片中的火车，但如果它看到只有一个对象的照片，类似火车（如博物馆内建一个旧火车，玩具火车），一台机器可能会错误地识别它作为一列火车。在这种情况下，机器学习将使计算机学习一大组火车的例子和对象，使其能够更好地识别实际列车（从而实现人工智能水平）。
机器学习有许多现实世界的应用。例如，Netflix使用机器学习算法来生成个性化的建议，为用户提供基于其海量用户行为数据，Zendesk使用客户交互数据来预测客户可能满意的倾向。
什么是神经网络？人工智能/机器学习的背景下的神经网络描述了一种类型的计算机体系结构，人工智能/机器学习程序可以建立在模拟人类大脑的结构上。它由连接在一起的节点组成，可以解决更复杂的问题并学习，就像人脑中的神经元一样。
：神经网络
多个隐藏层将是深度学习的特点
什么是深度学习？深度学习是一种机器学习，需要训练一个层次结构的“深层”的大型神经网络，每个层解决问题的不同方面，使系统能够解决更复杂的问题。使用上面给出的火车例子，深学习系统将包含不同层级，每一层标识不同的列车特性。例如，底层将识别对象是否有窗口。如果答案是肯定的，下一层将寻找轮子。下一步将寻找矩形车，等等，直到层集体确定图片作为火车或拒绝假设。深度学习作为一种提高机器学习能力的方法已经越来越受欢迎，技术的进步开始允许大神经网络的训练。
什么是监督学习？什么是无监督学习？监督和无监督学习是机器学习的两种类型。在监督学习中，系统给出了一组“正确答案”的例子，根据这些例子，系统将根据正确的答案学习并正确地预测输出。监督学习的实际应用包括垃圾邮件检测（例如，系统可能有一堆标记为“垃圾邮件”的电子邮件，学会正确地识别垃圾邮件）和手写识别。在无监督学习中系统没有给出正确的答案，但有未标记的例子，留在自己的发现模式。一个例子包括将客户按一定的特征（例如购买频率）进行分组基于从一组大客户数据发现的模式。
机器学习有哪几种？
l 分类。将电子邮件分类为垃圾邮件，识别欺诈，面部识别，语音识别等。
l 聚类。比较图像，文本或语音找到类似的项目，确定集群的异常行为。
l 预测。基于Web活动和其他元数据预测客户或员工流失的可能性；基于可穿戴数据预测健康问题。
什么是一般的，强大的或真正的人工智能？一般的，强大的，或真正的人工智能的术语用于机器智能，充分复制人类的智慧，包括自主学习和决策。虽然全脑仿真技术服务于通常意义的人工智能目标，所需的计算能力的金额仍然远远超出了目前的技术，这使一般的人工智能在很大程度上仍然停留在理论阶段。
价值创造的关键驱动力
我们相信，人工智能主题相关的利润池创建（和销毁）分析最好首先通过四个关键输入：人才，数据，基础设施和硅。这些投入也有双重障碍。
人才
人工智能（特别是深度学习）很难。我们与风投和公司在空间里的对话，造成了大型互联网和云计算厂商中的人才短缺和人才之间的竞争，如。人工智能人才有极大的需求，并购化仍然获得必需的人才的一种常用手段。随着技术和工具的成熟，人才可能成为一个瓶颈。然而，我们相信人才将迁移到有趣的，差异化的数据集。由于这一点，我们相信大差异化的数据集是最有可能的驱动增长和利润提高，我们迈入了以人工智能为中心的世界。
：并购推动人工智能人才稀缺化
数据
数据是人工智能的关键输入。深入学习的有效性与较大的数据集特别相关，较大的数据集防止模型变得过度拟合。例如，麻省医院放射科和哈佛医学院的研究人员使用卷积神经网络来识别CT图像，根据训练数据大小评估神经网络的准确性。随着训练规模越来越大，精度提高（）。
：医学成像（部分身体图像识别）
培训规模与精度相关：0=最不准确，100=最准确
现在大多数学习是监督或半监督，这意味着所有或一些用于训练模型的数据必须被人所标记。无监督机器学习是目前人工智能的“圣杯”，因为原始的未标记数据可以用来训练模型。广泛采用深度学习可能会与大数据集的增长（这是发生在移动和物联网）和无监督机器学习的进展相挂钩。然而，我们相信大分化的数据集（电子健康记录，组学数据、地质数据、气象数据等）将有可能成为下一个十年的利润池创建的一个核心驱动力。
信息量在全球范围内预计将以36%的年复合成长率增长，根据IDC的预测到2020将达到44泽字节（440亿GB）。越来越多的连接设备（消费者和工业），机到机通信和远程传感器的结合，用来创建大数据集，从而理解和训练自适应算法。数据的可用性在过去十年也急剧增加，普查，劳动，天气，甚至基因组等大量数据在线免费。
我们也看到卫星图像的可用性，这需要大量的计算和充分分析。美国地质调查局Landsat 7卫星和Landsat 8卫星每8天勘测整个地球图像，美国地质调查局让这些图像免费，即使压缩后超高清晰度的图像也大约有1GB那么大。其他公司，如轨道洞察在聚合图像数据，并在多个行业创造商业解决方案。
基础配件
硬件和基础软件对人工智能而言是必要的。我们认为支持人工智能的基础配件将迅速商品化。这种观点是基于以下两点提出的：1）云计算供应商很好地拓展他们的产品，以进入人工智能基础配件领域，2）开源（TensorFlow、、火花，等等）已经成为人工智能软件创新的主要驱动力。为了鼓励人工智能，我们相信大型云厂商将继续增强开放源代码基础配件的能力，限制潜在的利润池创建。
：互联网巨头（如谷歌）正在通过开源技术推动人工智能（如Tensorflow）
硅
深度学习的GPU再利用已经成为我们当前的“人工智能的春天”的关键驱动因素。在人工智能/机器学习生态系统，有两个主要的应用程序，确定每个需要不同资源设置的神经网络的性能。首先是一个训练算法的构造和使用。训练算法利用一个大的（通常是更大的，更好的）数据集发现相关性，并建立一个模型，给定一个新的输入就可以确定输出的概率。培训是资源密集型的，最现代化的培训是基于GPU的供电系统的。
训练的模型和算法的使用称为推理。推理需要极少的计算能力，通常通过更小的，增量的数据输入集。而一些GPU优化推理（例如NVIDIA的P4系列和M4系列）给出推理的单一目的性，专业的硅因专门的应用程序而开发，称为FPGAs（现场可编程门阵列）和ASIC（专用集成电路）。这种集成电路最初是为原型的CPU开发的，但越来越多地用于人工智能推理。谷歌的张量处理单元，是一个ASIC专用的人工智能和机器学习的例子。微软也一直使用FPGA芯片推理。英特尔2015年收购FPGA的制造商——Altera公司，2020年之前，三分之一的数据中心可以利用FPGA做专业用途。赛灵思率先在上世纪80年代商业使用FPGA，指出了云计算和大数据中心是公司增长和前进的重要途径，也宣布了与百度的战略客户关系。数据中心中在Xilinx公司的目前收入中约占5%。
：人工智能变革：1950年-现在
推动生产力的未来
在过去十年的缓慢增长和上世纪90年代中后期显著增长后，美国的劳动生产率增长近年来停滞。我们相信，机器学习和人工智能的发展已经戏剧性地改变了全球产业的潜在生产力，在某种程度上类似于上世纪90年代的互联网技术大范围运用的影响。
在所有行业中，我们看到了自动化让劳动小时约减少了0.5% - 1.5%，人工智能/机器学习技术提高了效率，2025年前能达到+ 51-154个基点的生产率增长。我们希望A人工智能/机器学习随着时间的推移提高生产力的分子和分母，我们认为最重要的早期影响是低工资的自动化工作–驱动类似水平的产出增长的自动化向较少的劳动时间发展。人工智能/机器学习驱动改善97个基点就意味着2025年技术对生产力增长的贡献为1.61%，或者比 1995-2004年高11个基点（、10）。
：生产力分析
百万美元，假定名义名义GDP增长超过2019
科技和生产力增长
上世纪90年代的科技繁荣让我们看到了生产力的两个主要组成部分的异常扩增，资本深化以及多因素生产率（MFP），与上升的股票估值密切相关。
资本深化。高盛经济学家Jan Hatzius提供了最近的反周期趋势资本深化（每劳动小时的资本存量），历史上往往在扩张时期没有资本存量的时候劳动时间增加（见Jan的报告：“生产率悖论v2.0重游”，发表于 2016年2月9日）。在上世纪九十年代，资本深化明显增加，突出了典型的资本投资增加超过经济增长的劳动力市场。
多因素生产率（MFP）。2013年3月，由David Byrne等人进行的联邦储备研究表明，上世纪九十年代技术同时扩散到IT生产和一般业务流程有助于创造三倍的增长（每劳动时间的产出），从1995年到2004年期间IT生产部门贡献了最多的年平均增长达49％的年生产率增长（）。
：90年代后期：生产部门贡献了近一半的生产力增长
失去价值，在科技繁荣中增长
千年停滞。在过去十年中，与IT应用（计算机硬件，软件和电信）相关的资本深化增长停滞不前。相对于更广泛的市场资本，IT资本对这一组成部分的总体增长的贡献比在科技热潮期间甚至在之前的平均贡献更小。总劳动时间一直在增加，但资本强度对生产力的贡献大大低于20世纪90年代。引入越来越复杂的消费性机器学习和人工智能可能是使资本强度回到之前的催化剂，在我们看来，显著提高劳动生产率，类似于我们在20世纪90年代看到的循环。
我们在MFP方面更加乐观。 高盛经济学家已经强调（生产力悖论v2.0重新审视2016年9月2日），ICT价格的向上偏差和对未货币化产出（免费在线内容，后端流程等）的投入增加，增加了对实际GDP和生产率增长的低估。脸谱网和谷歌这样的互联网巨头的演变表明：复杂的投入劳动力和资本不一定转化为标准生产力指标中传统消费品的货币化。
人工智能/机器学习诱导生产力从而可能影响投资
我们认为，人工智能/机器学习提高生产力的潜在影响之一可能是公司分配资本的方式的转变。 自2011年中期以来，股息和股票回购的增长已显著超过资本支出增长，因为管理团队对基建项目投资仍处于经济衰退之后的不情愿的态度。
生产力的提高有可能重振管理的信心，鼓励公司类似于20世纪90年代那样投资生产资本，其中由我们的高盛资本开支跟踪器衡量的年度资本开支增长一直超过由耶鲁教授罗伯特•希勒教授的标准普尔500分析得到的年分红增长（）。我们进一步相信，投资者会在生产力提高的情况下重视这种转变。在资本支出投资和相关生产率增长期间，经周期调整的市盈率经历了显著的通货膨胀，而目前的估值刚刚达到了衰退前的水平（）。
人工智能和生产力的悖论：专访Jan Hatzius
高盛互联网研究分析师Health Terry和首席经济学家Jan Hatzius讨论了人工智能和机器学习对提高滞后劳动生产率的作用。
Health Terry：在过去的十年中，什么导致了生产力增长的不足？
Jan Hatzius：一个好的起点是20世纪90年代，在那时我们有一个相当规模的的生产力加速，主要是技术驱动。科技部门的规模越来越大，科技产出增长速度非常快，这足以使经济整体加速增长。最近，或在过去的10年左右，我们已经看到了生产增长率又一次减速，低至20世纪70年代和80年代的水平，甚至可能更低。
我认为不止一个驱动力，但我认为有三个因素阻碍了生产力增长。一个是周期性的影响。我们在经济衰退中仍有一些后遗症，资本积累速度相对缓慢，投资水平相对较低，就业增长相对较快。由于生产力是衡量每工作小时的产出，当劳动力市场正在迅速提高你可以有较低的生产率时意味着有点反常。
另一个因素可能是技术进步的总体速度有所放缓。我们有理由相信，上世纪90年代，随着互联网的引入，技术进步的时间相对比较快，我认为现在有点慢了，这也是有根据的。
第三点是，在过去十年中发生的技术进步，如以移动和消费者为中心的技术，是在数量上统计人员难以捕捉到的。原因是，在过去十年左右的时间里许多新技术的质量改进是很难定量的。统计学家们并没有在许多处于前沿的领域进行显著的质量改进。
所以我会指出三点。有周期性的影响，还可能是一些技术进步放缓，此外极有可能在生产力统计时候的测量误差增加。
Terry：回首20世纪90年代的生产力繁荣，技术发挥了什么作用？
Hatzius：推动这一切的主要是通用技术，如半导体和计算机，它们比20世纪70年代或20世纪80年代所占的经济份额大得多，因为那时候技术进步非常迅速，统计学家们很好地测量了这些技术。在上世纪90年代，统计学家们做了很多努力来较快地捕捉质量提高；处理器的速度，更大的内存，电脑硬件更好的属性，这导致在技术部门测量的贡献大幅增加。技术部门从上世纪90年代早期开始加速生产增长，持续到新世纪头十年中期。
Terry：我们已经在过去的10到15年里看到了很多技术的发展。为什么没有产生像iPhone、脸谱网和云计算这样的技术对生产力类似的影响？
Hatzius：我们没有一个完整的答案，但我认为答案的一个重要部分是衡量质量改善的统计能力的提升，新产品对经济统计的影响是有限的。衡量名义GDP比较容易，基本上就是增加收入的问题。几乎所有的东西都有测量误差，但是我没有真正一级关注，因为在衡量名义GDP方面，测量变得越来越差。通过采用调整后的物价指数来紧缩把名义GDP转换成实际GDP是很难的。你看，例如，在软件行业，如果你相信官方的数字，用1000美元的经费能买到的现在的软件和上世纪90年代能买到的一样。软件行业的货币没有升值。这很难令人相信。甚至都通不过气味测试。由于捕获这些质量改进存在困难，事实上，技术部门由通用硬件越来越多地转向专用硬件，软件和数码产品也会导致低估和估算误差。
Terry：人工智能和机器学习等技术的发展对生产力有什么影响？
Hatzius：原则上，它似乎在某种程度上比统计数据更好地捕捉到上一波创新，人工智能降低了成本，减少了劳动力投入到高附加值生产的需要。在商业部门的成本节约创新是统计学家设立起来为了更好地捕获信息，例如增加的应用程序的多样性和可用性的iPhone。在人工智能对商业部门的成本结构有广泛影响的程度上，我有理由相信，它将被统计学家所接受，并且会出现在整体生产力数据中。我只想警告一点，那就是美国的经济非常大。即使在一个经济部门中很重要，甚至是压倒性的力量，在你划分18万亿美元（这是美国名义GDP水平）时通常看起来不那么重要，所以百分比贡献可能不从底层的角度来思考。但原则上，这是可以产生显著影响的事情。
Terry：你谈到了对成本的影响，那怎么影响定价？ 这是否会成为我们在某些经济部门看到的更广泛的通货紧缩力量的贡献者？
Hatzius：我当然认为，在生产力提高方面，第一阶段的影响往往是降低成本和降低价格。保持一切不变的意思是降低整体经济的通货膨胀。通常这不是你想保持一切不变的正确假设。有经济决策者和有联邦储备委员会，如果影响很大，那么美联储将采取更容易的货币政策，使得不再在受人工智能影响的地区工作的人在别处能找到工作。美联储这样做可能有非通货膨胀的运行空间。从长远来看，我们一般不认为成本节约的创新会导致失业率上升或通胀大幅下降。在短期内可能是后果，但在长期来看，当政策作出反应时，经济最终会出现类似的失业和通货膨胀水平。
Terry：这些主题出现：人工智能工作或机器人接管劳动，你认为在一段时间内是不合法吗？
Hatzius：这些恐惧已经存在多年了，我认为我们可以说的一点是，到目前为止，他们还没有真正得到证实。如果我们回到19世纪初，人们担心机械化的纺纱机，这种想法会使大量的人失去工作。 在短期内，这种中断可以产生重大影响。历史上的技术进步导致了更高的失业率。但情况并非如此。我最好的猜测不是最终会有更高的失业率，因为最终人们会找到需要人类和人类劳动的东西。我的预期是，这可能是动荡的影响，但我不认为这会让我们失业率更高。
Terry：在过去十年中，我们看到企业利润越来越多地归于回购和股利，超过了资本投资。 从宏观经济的角度来看，是否存在一个阈值，生产率需要推动投资和资本吗？
Hatzius：投资和生产力是联系在一起的，因果关系是双向的。 近年来，我们的投资水平相对较低，主要是周期性原因，因为经济仍然有大量的剩余产能，在大衰退后资本存量不足。 没有强大的经济激励来投资新产业。 我认为在慢慢修复，我们已经看到投资率在上升。在未来几年中，商业投资对生产率增长的贡献比2010年和2011年有所增加。另一个方面，生产率增长是投资的主要驱动因素， 这取决于在前沿领域中的新发现。如果保持下去，那么还将有一个激励性的投资。
Terry：当我们看到生产率在历史上有所增长时，通常如何影响企业利润？ 当公司寻求竞争优势或者我们实际上看到盈利能力的持续增长时，成本是否只转移到收益表的另一部分？
Hatzius：我对历史证据的看法是，最初生产率提高回落到公司的最低水平，但因为更多的参与者最终这些高回报遭到淘汰。 它可以持续一段时间，但在长期，如果市场机制运作，它将被竞争淘汰。
Terry：在我们看到技术驱动的改进和效率的程度上，你倾向于认为资产估值有什么影响？ 在90年代，我们看到了一个与你正在谈论的生产力相关的市场反应，这样的东西有可能重复，让我们看到这种生产力改善人工智能和机器学习？
Hatzius：就整体经济而言，我认为如果你有证据表明生产力持续再加速，而且如果你发现近年来出现的许多恐惧，是由于于这种生产率的低速增长速度，我想你可能会看到股票价值的重估。
特别是，保持一切相同，我们发现生产率增长更快的时期也意味着资产估值更高的时期。 如果我们看看20世纪90年代，情况确实如此。发展到这个时期的尽头确实会有大泡沫，后果相当痛苦。这些事情可能是暂时的，但我认为我们通常会看到重估。
生态系统：云服务，开源是未来人工智能投资周期的主要受益者
我们相信，利用人工智能技术的能力将成为决定未来几年在所有主要行业的竞争优势的主要因素之一。虽然该战略会因公司规模和行业而不同，管理团队不专注于在人工智能领先，受益于产品创新和劳动效率，资本杠杆风险不作考虑。因此，我们认为，企业需要投资这些新技术以保持竞争力，将拉动对人工智能的人才、服务和硬件需求的增长。
作为对比，上世纪90年代的科技驱动的生产力繁荣推动了相应的繁荣。在技术上增加资本支出使得业务增加来衡量这笔资本支出。软件、硬件和网络公司不可避免地进行行业整合。下图突出显示软件行业的这个模式。通货膨胀调整后的市值在2亿美元到50亿美元间的公公软件公司的数量在1995-1999年期间增长了近两倍，在新世纪头个十年中期巩固之前。
：在快速增长的同时实现生态系统生产力的繁荣
：风险资本投资在这十年有曲折变化
我们看到潜在的与即将到来的人工智能驱动生产力的周期相关的热潮，随着企业投资人工智能，价值创造在跨软件，硬件，数据和服务供应商实现。正如强调的一样，VC资金进入人工智能相关的初创企业在这十年有较大的变化。企业人工智能投资未来繁荣的潜力也开始推动整合。特别是云平台已经在智能人才投入巨资，与谷歌、亚马逊、微软和Salesforce自2014年来联合进行17个 人工智能相关收购（）。
我们在与历史技术时期比较中也看到了一些人工智能和机器学习技术的发展的好处。在过去的50年主要技术周期中，计算（穆尔定律）是抑制剂和进步的推动者。例如，在系统架构中，我们目击了从大型机系统开始的演变之后，就将其转交给了客户端服务器模型，并且最近已经开始被云/移动模式取代的时代。这种演变的驱动因素是计算以及存储容量的提高，它的每个转变都伴随着应用程序的变化，包括各种新的编程语言的出现和演变（见图表15）和可能的应用类型。在上下文中，AI概念已经存在了几十年，比如20世纪60年代出现的概念神经网络，虽然它的计算能力不足以允许直到最近几年的任何实际使用情况。我们相信我们在早期的AI平台，类似于初始商业化的大型机在20世纪50年代和智能手机和21世纪的云的商业化。还有平台曲线弯曲成（我们认为发生的）一个爆炸应用程序，工具和服务启动器的情况，我们将在下面更详细地讨论。
：AI进展可以与系统中的历史技术演变相比较，虽然我们相信还在早期发展和采纳阶段，但是架构和编程语言的采用已经初见端倪。
推动者正在沿着三个平面发展：DIY，服务和AI-aaS
如下面章节所述，我们开始看到领导者和投资出现在这三个平面：
1.自我实现 - 具有才能和差异化数据的企业可能在机器学习能力上大量投资。 为了支持这些努力，我们正在目睹一个新的“AI堆栈”的出现。 AI堆栈具有类似的组件：历史计算堆栈：硅，存储，基础设施软件，数据处理引擎，编程语言和工具。 因为通过下面，我们将发现AI堆栈的输入主要是开源（来自提供者）的组合，如Databricks，Cloudera，Hortonworks和Skymind）和服务提供云平台如微软，谷歌，亚马逊和百度。
2.咨询服务 - 许多组织将有独特的数据库为内部使用，以及为客户和合作伙伴构建AI服务。 因为AI人才是目前稀缺的资源，专业服务提供商正在出现以帮助弥合差距。 IBM，结合垂直和域特定服务专业知识以及其沃森集团内的技术专长。早期的领导者在这个市场。 较新的模型也正在出现。 Kaggle，作为示例，连接组织与成千上万的数据科学家，以帮助解决人工智能的相关问题。
3. AI-a-a-service（AI-aaS） - 在我们称为AI-aaS的类别里，我们看到很大的潜力和最新的市场创造。 AI-aaS很可能在多个方面有所发展，但核心思想是：深度学习系统，许多企业将改为接受经过培训的深度学习系统而不是培训自己。 AI-aaS的一个例子是用图像和谷歌API启动Clarifai。由于谷歌的大集合的图像和AI人才，公司不太可能能够训练图像识别模型比Google更准确。相反，开发人员使用图像应用程序中的识别将每次调用Vision API图像在应用程序中需要识别。类似的AI-aaS产品可能是由具有独特水平的SaaS供应商（如Salesforce.com）开发数据集（如销售数据），面向数据和人才的创业公司是稀缺的（医学成像是一个例子），和有公司可能对供应商，客户或合作伙伴有价值的差异化数据。
DIY：云平台和开源可能是人工智能的精选
机器学习（特别是深度学习）仍然处于创新者或者说是早期，市场的采用者细分市场与人工智能的快速进展相比。 基于与公司和VC在空间讨论，我们认为人工智能/机器学习被大量使用，由互联网公司，以行业为中心的服务提供商（如Broad研究所）和更大的财富500强组织的尾巴（新兴用例突出显示在我们的工业小插曲）。
今天采用方面的最大障碍是数据和人才。但是，随着企业的到来，更好地通过物联网的数据收集和内部生成机器，以及客户数据和外部数据服务提供商的数量增长，数据采用障碍可能变得不那么令人生畏。 另外，作为人工智能/机器学习，学习技能差距扩大，大学毕业生结合相关技能，通过人工智能/机器学习，人工智能/机器学习咨询公司的培训，以及使过程自动化的更好的工具，可能出现填补空白。这是网络，是我们相信大多数大型企业（或较小的，以数据为中心的企业）可能最终至少进行实验人工智能和深度学习。
由于在空间创新的步伐和技术发展的前景还不甚明朗，机器学习的渠道仍然非常分散。然而，新兴的“AI堆栈”与大型机，客户端服务器和当前时代分析中的分析具有相似之处和开发堆栈。正如下面“堆栈演化”图中所强调的那样栈的组件从工具到语言，到存储仍然存在于当下。
AI堆栈和现有技术变化之间的主要区别在于：大部分机器学习的渠道严重依赖由云平台供应商提供的开源技术和服务。 这种转变的驱动力是多重的，但包括按需计算和存储处理大量数据。微软，亚马逊和谷歌等云服务提供商的投资机器学习服务，以大开源为标准的开源，企业买家为了避免供应商锁定并降低成本。
编码的演变以及它如何翻译成AI
Blue =专有供应商，Orange =开源，Green =云服务（注意：一些供应商，如IBM和Microsoft包括专有和云服务
GPU重用的深度学习是我们当前“AI春天”的主要驱动因素之一。在人工智能/机器学习生态系统中，有两个主要应用程序确定神经网络的性能，每个神经网络需要不同的资源设置。 第一个是构建和使用训练算法。 训练算法利用大的（通常是更大，更好的）数据集来找到相关性并建立一个模型，该模型可以在给定新输入的情况下确定输出的概率。培训是非常资源密集型的，大多数现代培训是在GPU供电的系统上完成的。
一旦他们已经被训练，使用模型和算法被称为推断。推断需要少得多的计算能力，并且通常梳理通过更小的增量数据输入集。给定推断的单一目的性质，专门为该应用开发专用硅，称为FPGA（现场可编程门阵列）和ASIC（专用集成电路）。这种类型的集成电路最初是为原型CPU开发的，但是越来越多地被用于人工智能的推理。Google的Tensor处理单元是专为人工智能和机器学习专门构建的ASIC的一个示例。 微软也一直在使用FPGA芯片进行推理。 I英特尔于2015年收购了FPGA制造商Altera，因为到2020年，三分之一的数据中心可以利用FPGA实现特殊用途。
公司看点：NVIDIA，Xilinx，Google，Intel（通过Nervana）
鉴于在内部和内部建立真正的AI或ML能力的成本 ，以及来自公共云提供商的改进选项，我们认为相对较少的企业将选择构建内部部署解决方案。这为Databricks（在云中提供Spark以及支持机器学习过程的一些工具）以及主要云平台提供商等提供商创建了一个开放环境。
来自主要平台提供商的产品具有可比性，但存在一些关键差异，一个解决方案或另一个更适用于特定的使用情况。尽管有许多供应商提供基于GPU的云产品，但我们的分析集中在那些具有最大扩展能力的产品，以及那些在与用户的对话中被频繁引用的产品。除了下面讨论的内容，Nvidia还列出了其GPU云计算合作伙伴：Aliyun，Outscale，Peer 1 Hosting，Penguin Computing，RapidSwitch，Rescale和IBM SoftLayer。
亚马逊AWS。亚马逊的P2似乎（至少是在纸上）最主要的公共云提供商提供的最强大的基于GPU的实例。 最大的包括64个CPU核心，16个Tesla K80 GPU，732 GiB内存，预留实例价格为6.80美元/小时。P2.16xlarge包括我们可以找到的最近的竞争对手提供的4倍的GPU。除了原始实例，AWS还提供Amazon Machine Learning，一种用于生成ML模型并在云中执行训练和推理功能的托管服务。亚马逊ML包括AWS集成，数据可视化，模型评估和解释工具，建模API，常用用例的预构建算法，数据转换和用于批处理和实时预测的API。
微软Azure。微软推出了新的N系列作为其最强大的基于GPU的实例。虽然目前只提供预览，广告内容包括24核，4 Nvidia Tesla K80 GPU，224 GB的内存和1.4TB SSD磁盘。定价范围大致取决于所选择的操作系统，从2.25美金每小时的Linux到11.66美金每小时的SQL Server。 Azure机器学习也被作为Cortana智力的保护下的管理服务营销套件，具有类似于AWS的功能和工具。
Google云端平台（GCP）。Google目前正在针对Cloud ML产品推出测试版。 尽管技术规格不像Azure或AWS中的实例那样容易公布，但我们的客户对话表明Google的平台（如果不是特别是Cloud ML实例）是高度先进的，为机器学习和人工智能使用提供了一个引人注目的平台。 Google利用其与DeepMind合作的技术及其在TensorFlow中的专业技术，提供全面的横向解决方案，如图像识别和翻译解决方案。
阿里巴巴。2016年1月，阿里巴巴的AliCloud宣布与Nvidia合作，推出中国第一个GPU加速的基于云的平台。更多详细信息缺乏，虽然公司和Nvidia都承认这种伙伴关系，并将使用Nvidia的Tesla K80 GPU。
：多个云供应商已经针对使用GPU加速的机器学习应用程序引入了实例
来自Amazon AWS和Microsoft Azure的人工智能/机器学习优化实例的技术规格和定价
特别是对于深度学习，大量的数据提高了机器学习模型的性能。许多行业的数据增长已经达到了拐点。 例如，在计算生物学中，今天的可用数据量据Broad研究所估计为200帕比特以上，并且比消费者网络数据增长得更快。 Petabyte规模数据通常在以下两种环境之一中进行评分：Hadoop集群（在HDFS中）或云对象存储服务（如Amazon S3）。诸如戴尔EMC部门（例如Isilon）等供应商的横向扩展存储解决方案也可能在某些环境中使用。但是，我们认为开源或基于云的存储服务可能会捕获创建的大量增量数据。 这主要是由于这些选项相对于本地专有备选方案的低成本以及在云中灵活地扩展和缩小使用的能力。
公司看点：Cloudera，Hortonworks，MapR，亚马逊（S3），谷歌（谷歌云存储），微软，IBM（云对象存储），戴尔/ EMC（Isilon，云对象存储）
消息，流处理和数据转换是机器学习管道的关键组件。训练模型时，在准备并馈送到神经网络或其他机器学习框架之前，将数据流传输到存储系统中。一旦创建了模型，来自传感器，网络或其他来源的“实时”数据被流式传输并准备好由模型进行分析，然后实时分析数据（）。历史上，ETL供应商（例如Informatica和IBM）和消息传递供应商（例如TIBCO）是流和流处理技术的提供者。 在过去五年里，情况发生了变化。在我们研究期间观察到的大多数机器学习环境中，开源解决方案（如Kafka，Storm和Spark）得到了大量使用。此外，还使用了诸如Amazon Kinesis和Google Pub/Sub之类的消息传递服务。
即使对于神经网络，数据需要准备。 例如，图像和文本被标准化为相同的大小和颜色（图像）或格式（文本）。 对于这些任务，可以编写自定义代码，或者可以使用Skyminds的DataVec等工具。
公司看点：Confluent（卡夫卡）、Databricks（Spark），Cloudera（火花流），Hortonworks（风暴，Spark Streaming）、亚马逊（运动），谷歌（云DataFlow）、Skymind（datavec），IBM（流）、微软（Azure数据流）。
：机器学习在生产中各种开源技术和云技术的应用管道
数据库/数据处理市场历来是最大和最有利可图的软件之一。例如，2015年，Gartner估计数据库市场规模为359亿美元。标准普尔（OCL）中规模最大的公司之一（市值大于1600亿美元）从其数据库产品中获得了大部分利润。在人工智能中，正在使用一组新的技术。首先，神经网络已经成为关键的数据处理技术。正如我们在“什么是人工智能”部分中解释的，神经网络通过节点处理输入数据以创建输出。例如，输入可能是电子邮件或图像，输出可能是“垃圾邮件”或“cat”。 到目前为止，神经网络的创建主要是通过使用各种框架（如Google TensorFlow或Caffe）的定制开发。云服务，如谷歌云机器学习也涌现，使开发人员和数据科学家能够在云中构建神经网络。
Spark作为处理技术的使用是我们与风险投资公司和公司讨论中的一个常见主题。Spark仍然是增长最快的开源项目之一（目前拥有超过10万个Github的明星），并且已经收到了来自IBM，Cloudera，Hortonworks和Databricks（其中有大部分是项目提交者）的大量投资。
公司看点：Cloudera（Spark）、Hortonworks（Spark），Databricks（Databricks），谷歌（谷歌云机学习），微软（Azure机器学习），Amazon（亚马逊机器学习），IBM（沃森）
人工智能和机器学习仍处于早期阶段。 这意味着定制开发仍然是创建生产应用程序和工作流的主要途径。机器学习和数据科学的语言是Python和R. Python还没有被货币化。在R生态系统中，微软（收购了Revolution Analytics）和RStudio（开源提供商）是主要的供应商。
:机器学习管道的主要开源项目
支持公司和适用性风险投资适用的项目
在分析的历史中，出现了工具，使企业能够从数据中提取价值，而不依赖于定制开发。 高级统计工具（如SAS研究所和SPSS），BI解决方案（如Microstrategy和Business Objects），报告解决方案（例如Crystal Reports）以及最近的数据可视化提供商（如Tableau）已经通过提高业务分析师的生产力， 供支持商业用途的数据科学家使用。
机器学习工具开始出现，加速了数据科学家的生产力。一个例子是微软的Azure机器学习解决方案，它为数据科学家创建一个拖放界面来创建机器学习工作流程。来自SAS的数据科学家关注的工具还提供工具，以支持开发和部署各种机器学习库。
公司看点：SAS（SAS Enterprise Miner）、画面、微软（Azure机器学习），亚马逊（亚马逊机器学习），谷歌（云机学习），Databricks。
咨询服务：货币化的技能差距
正如我们在本报告中提到的，人才仍然是机器学习采用的主要障碍之一。这创造了系统集成商的重大机会，如IBM、埃森哲和德勤。应用机器学习也提供了传统的技术供应商和大型咨询企业的机会（如IBM或者Teradata），去更有效地利用开源技术（通过咨询解决方案）。
在下面的中，我们描绘了机器学习人才的竞争。IBM，华为，埃森哲和德勤是最积极地雇用机器学习人才的公司。值得注意的是，由于机器学习人才仍然稀缺，较小的初创咨询公司很可能实现规模化。 在云计算中出现了类似的模式，出现了较小的咨询公司，如Appirio，Bluewolf和Fruition Partners（最终被大型IT咨询提供商收购）。
：IT服务提供商的机器学习招聘
LinkedIn招聘与“机器学习”
其他业务模式也正在出现，以缩小技能差距。 作为一个例子，Kaggle通过托管比赛来实现机器学习。数据科学家可以赢得奖金，练习“真实世界”数据集，构建机器学习组合。企业能够获得人才来解决问题，而不必大量投资于机器学习团队。
AI-aas：可能是创造新市场的最大驱动力
虽然我们预计许多公司将投资于DIY的人工智能，创造增长，我们看到在AI-aaS最有活力和新业务创造的潜力。 因为大型，独特的数据集是相对有限的，稀缺的人工智能人才可能合并到这样的数据集，在我们看来，这似乎不太可能，大量的企业在五年内建立自己的神经网络。 我们认为更可能的情况是，大量的AI服务提供商出现：1）可以访问唯一的数据集; 2）由于访问独特的数据集，吸引了创造人工智能服务增值服务所必需的人才。
AI-aaS产品通常通过API提供。 最基本的例子是一个开发者想要添加图像识别功能到其应用程序。开发者不是通过水平AI-aaS提供者（例如Clarifai，Google或Microsoft）访问Image API，而是获取大量数据集的图像并训练模型。当在应用中使用语音识别时，对云中的API进行调用，并且通过训练的机器学习模型来对图像进行分类。
：ai-as-a-service（AI-AAS）景观
机器学习API正在开发以解决水平和垂直用例
我们看到AI-aaS的市场至少沿着三个方面发展，如下面强调的和上面的图表20所示。
广泛的水平AI-aaS（图像，语音，文本等）
谷歌和微软都提供用于语音，翻译和图片识别的API，每月每千次API调用只需0.25美元（）。开发人员可以利用这些API将AI功能嵌入到他们的应用程序中。对于核心水平AI（如NLP和图像识别），我们认为大型云平台提供商处于最佳位置，因为他们拥有大数据集，能够实现更准确的AI服务，并能够根据实际消费者数十亿用户来优化其结果。
公司看点：谷歌，微软手表，脸谱网，IBM，Amazon，Clarifai，it.ai，Valossa
：水平AI-AAS产品的供给定价
云平台的AI AAS产品样本
狭义的AI-AAS（客户流失，员工保留等）
对于更重要的水平，如CRM（领先评分），人力资源（人才保留）和制造（预测性维护），我们认为SaaS供应商定位良好，因为SaaS供应商可以获得大量的差异化数据。Workday，Salesforce.com，Zendesk，Oracle，SAP和IBM是最终可以竞争狭义AI-aaS用例的供应商。我们谈到的大多数SaaS供应商都投资于数据基准测试和分析产品，认为他们的数据是长期进入的壁垒。
Salesforce已经成为机器学习人才最积极的收购者，在过去18个月发生4项人工智能相关收购（）。
公司看点：IBM、SAP、Oracle、Salesforce、Workday，Zendesk，HubSpot，Shopify，Ultimate Software，ServiceNow
垂直特异AI-AAS（医疗成像，欺诈预测，天气预报等）
垂直特定的AI即服务可能推动更多的多样性。大型行业巨头可以汇总数据，构建机器学习模型，并向合作伙伴，客户和供应商销售模型。初创公司可以在特定用例的垂直领域（如医疗成像）构建独特的数据集，并使医院网络能够访问API。零售或广告领域的行业联盟可以汇集数据，以更好地与更大的竞争对手竞争（例如，零售商可以汇集数据，更好地与亚马逊的推荐引擎竞争）。
IBM一直是医疗保健领域开发垂直特定AI-aaS能力的早期领导者。在过去两年里，IBM已经花费超过40亿美元收购了一些医疗保健技术和数据公司。 这些收购的结果是大量的医疗保健数据（IBM在其健康云中有超过3亿患者记录）。 通过这些医疗保健数据（以及通过合作伙伴收集的其他数据）及其收集的沃森技术，IBM开始提供针对肿瘤学，临床试验和基因组学使用案例的服务。 在医疗保健垂直行业，其他创业公司也采用类似的方法（如下面的所示）来解决医学成像，药物发现和诊断中的难点。
：医疗保健中的垂直AI-aaS
中国人工智能的现状
据艾瑞咨询，该国的人工智能市场估计将从2015年的12亿人民币增长到2020年的91亿人民币。 2015年，中国的人工智能（AI）大约流入了14亿元人民币（同比增长76％）。
在政府政策方面，中国国家发展和改革委员会（国家发展和改革委员会）与其他相关政府机构一起，于2016年5月18日发布了“互联网+人工智能”三年实施方案。实施计划阐述了六个支持人工智能发展的具体领域，包括资本融资，系统标准化，知识产权保护，人力资本开发，国际合作和实施安排。该计划的目标是到2018年在中国建立基础设施和创新平台，行业系统，创新服务体系和人工智能的基本行业标准化。发改委预计，中国人工智能行业将与国际发展同步，引领全球市场人工智能技术的应用。
中国已经采取了重大举措，提及“深度学习”或“深层神经网络”的期刊文章数量，中国在2014年超过了美国（）。中国的人工智能研究能力也令人印象深刻（），因为具有世界领先的语音和视觉识别技术。2015年11月由百度开发的Deep Speech 2能够达到97％的准确性，被MIT Tech Review评为2016年前十大突破性技术之一。此外，早在2014年，香港中文大学开发的DeepID在LFW（野生标签面孔）中的面部识别准确度达到了99.15％。
：提到“深度学习”或“深层神经网络”的期刊论文
图表24：引用“深度学习”或“深层神经网络”至少一次的期刊论文
中国互联网巨头百度、阿里巴巴和腾讯（BAT）是中国人工智能市场中的领先者，而数百家初创企业也在渗透该行业，并在各种AI领域和应用领域建立服务模式。目前，在中国人工智能领域涵盖：
1）基本服务，如数据资源和计算平台；
2）硬件产品，如工业机器人和服务机器人；
3）智能服务，如智能客户服务和商业智能；
4）技术能力，如视觉识别和机器学习。
根据艾瑞咨询，语音和视觉识别目前分别贡献了中国人工智能市场总量的60％和12.5％。 在中国的人工智能相关公司中，71％专注于开发应用程序。 其余的55％正在研究计算机视觉，13％在自然语言处理，9％在基础机器学习。
在我们看来，在人工智能前沿的关键参与者可能继续在美国和中国。
机器人：用户界面的未来
机器人是潜在的范式转移。在以机器人为中心的世界中，用户体验从基于点击的转换到对话（文本或语音），以及从网络或面向消息或面向语音平台的交互转换。换句话说，用户不需要打开三个不同的应用程序来预订旅行，购买衣服和参与客户服务，而是可以同时通过信使参与与提供帮助的机器人的交谈。因此，我们看到电子商务，客户支持，员工工作流程和生产力方受到广泛影响。
过去12-18个月的一个关键驱动因素是大型云和互联网公司创建和开源机器学习框架。2015年下半年，谷歌公司推出了TensorFlow，一个机器学习算法库，亚马逊和微软也一直活跃，发布云服务来支持自己的机器学习项目。我们预计这种趋向民主化的机器学习将继续促进智能机器人的发展，因为主要参与者（亚马逊，谷歌，苹果，微软）期望在他们各自的生态系统整合对话界面（Alexa，谷歌助理，Siri，Cortana）。 继今年三星收购Viv之后，我们预计将在三星的设备和智能手机生态系统中进一步整合基于Viv AI的数字助理。
自然语言处理（NLP）。机器人的承诺是植根于他们的智能和过程自然语言的潜力。因此，机器人兴趣的兴起与机器学习的兴趣和创新的兴起与自然语言处理（NLP）的人工智能领域的技术，或计算机理解，操纵和从语言的意义的推导相关。与类似于基于硬编码规则集构建的CTRL + F函数操作的字处理器相反，NLP利用机器学习算法来基于大量训练数据来学习规则，然后可以将其应用于新的文本集。机器学习的核心原则适用于NLP系统所获取的数据越多，其应用程序就越准确和更广泛。
虽然NLP的早期应用已经用于文本挖掘（例如，法律文件，保险政策和社交媒体的分析）和自动问答应用中，但是神经网络和深度学习模型的进步正在允许NLP系统变得越来越聪明并且管理困扰人类语言的歧义。谷歌在TensorFlow，SyntaxNet中实现的NLP的开源基础利用神经网络来消除左到右处理中的模糊性，只有在发现了其他更高等级的假设时才丢弃潜在的假设。因此，根据谷歌的说法，SyntaxNet模型是一些在TensorFlow框架内曾经训练过的最复杂的模型。
消息平台。 机器人的兴起与诸如Facebook Messenger，WhatsApp以及企业中的Slack和HipChat等消息应用的快速增长同步。消息应用程序提供了一种媒介，通过它，机器人可以与iOS，Android和网络上的用户进行交互。此外，更大的消息应用正在发展成支持多种交互类型的平台。在Slack上，企业用户可能与团队合作，监控应用程序，创建待办事项列表或从同一接口监控费用。在Facebook Messenger上，用户可以与朋友聊天，提出品牌的支持问题，或从同一界面叫Uber。
最近的聊天机器人收购或亚马逊（Angel.ai CEO）和Google（API.ai）的部分收购，每一个都专注于会话界面技术，突出了公司和投资者在聊天和自然语言过程能力的联合中看到的机会 。根据Pitchbook的数据，自2013年以来，私人消息公司在人工智能/ 机器学习，电子商务，SaaS和网络安全方面投入约120亿美元的累计风险投资资金，而在8年前则约为20亿美元。
：跨信息风控基金（百万美元）
在一些受益者正在出现的情况下机器人激增。 第一组受益者是消息平台——脸谱网，Slack，微信等。机器人增加了参与度，并创造了在这些平台上推动商业的机会。第二类是硬件和基础设施提供商，其范围从GPU提供商（NVIDIA）到开源供应商，数据平台供应商和云服务提供商，如亚马逊，谷歌和微软，亚马逊处于一个独特的位置，因为它的能力可以满足电子商务需求。 其他正在利用BOT功能的软件提供商包括Zendesk和Salesforce.com等软件提供商，他们将机器人视为自动化企业客户服务的潜在手段。
：Slack，FB Messenger用户的增长
企业和消费者信息平台的兴起
个人数字助理：许多公司已经使用复杂的算法，机器学习和大数据软件来创建基于过去一段时间的行为和客户数据的推荐引擎。这些引擎影响购买行为，但是大部分相同的技术被用于个人数字助理的工程中，或者具有基于语音命令来完成或自动化简单任务的能力的机器人。
使用语音识别软件将推荐引擎的复杂预测和推断功能合并，产生了苹果的Siri，亚马逊的Alexa，谷歌助手和微软的Cortana。利用机器学习和云基础设施，这些应用程序在收集关于用户的更多信息时改进：语音模式，兴趣，人口统计，消费习惯，日程，职业，喜欢和不喜欢。大多数（如果不是全部）这些信息通常可以通过软件监控一个人使用智能手机或连接设备（Amazon Echo，Google Home）来收集。随着这些数字个人助理访问更多的数据，分析应该允许他们区分来自不同用户的类似请求，变得越来越个性化。例如，指令“给我看最好的相机”对不同的消费者可能意味着不同的东西。与用户数据相结合的强大的分析引擎可以帮助确定用户是否喜欢最便宜的摄像机，最高评价的摄像机，或者等于对于该个人“最佳”的特征的某种其他组合。
我们看到数据聚合和分析的持续创新推动了人工智能数字助理的改进。我们还期望像亚马逊和谷歌这样的系列创新者继续消除购买过程中的摩擦点（Echo，Echo Dot），并进一步完善日常任务（谷歌首页）。
用例
农业
到2025年市场值将达到200亿美元
我们认为，机器学习有可能增加作物产量，减少化肥和灌溉成本，同时有助于早期发现作物/牲畜疾病，降低与收获后分拣相关的劳动力成本，提高市场产品和蛋白质的质量。当我们看到用于收集土壤，天气，航空/卫星图像，甚至听觉数据的传感器的扩散，我们认为，从深度学习算法对这些PB级数据集产生的洞察将提前告知（有时）种植时间，灌溉，施肥和家畜护理，并导致在农业范围内增加土地，设备和人类生产力。如果数字农业中使用的所有已识别的技术将被优化或完全由机器学习/人工智能提供，我们假设该价值创造的25％累积到机器学习/人工智能链中的供应商，这意味着TAM为600亿美元，到2050年将会有一个1.2万亿美元的农作物市场。假设在该时间段内TEM线性变化，意味着到2025年大约200亿美元的TAM。
什么是机会？
有的生产和产量损失可以通过在农业中的机器学习应用减少劳动力费用。在美国玉米生产中，我们的研究团队已经确定了从精确肥料到压实减少的技术，他们相信这些技术可以在2050年将玉米产量提高70％。重要的是，他们的研究中确定的每一个创新都是通过机器学习和人工智能实现的（）。
我们已经确定了农业中的几个具体领域，在这些领域我们特别受益于机器学习和人工智能技术的应用。例如，农民商业网络是一个组织，其汇总关于种子性能，农艺实践，投入品价格，产量基准和其他农民提交的数据的数据，以利用深度分析来提高产量。
利用传感器，天气，土壤，甚至无人机/卫星图像数据，机器学习可以根据当前和预期的天气模式，作物轮作对土壤质量的影响，帮助农民优化施肥，灌溉和其他决定，帮助确定最佳做法。对空间图像的分析可以比人类观察更快更有效地帮助确定作物疾病，例如大豆锈病，早期处理可以防止收成损失。
相同的模式识别技术可以用于在家畜动物中识别疾病和跛足（影响运动性和整体健康的腿/脚/蹄的感染或损伤）。最后，我们看到了使用视觉图像和自动分拣设施来替代人类检查员沿着产品和肉类产品的分级和分类线的应用。
：确定用于提高作物产量的所有涉及机器学习和人工智能应用的创新
美国玉米产量驱动因素
什么是难点？
农作物产量受次优施肥，灌溉和农药的抑制。在高盛研究报告《精确农场：用数字农业欺骗马尔萨斯》（2016年7月13日）中，发现了几个问题，可以通过收集适当的数据和执行适当的分析来解决。这是至关重要的，因为在2050年，为预计世界人口提供饲料需要增加70％的作物产量。
增加人工成本。农业历史上转向技术创新以抵消劳动力成本，我们认为机器学习是这一演变的下一步，特别是在收获后/屠宰分拣过程中，其中大多数对产品和肉类产品的目视检查仍然由人类工作者完成。根据劳工统计局的数据，在美国，53k个人被雇用为“分级和分拣机，农产品”，每年的劳动力成本约为13亿美元。根据BLS数据，“农药处理者，喷雾器和施药器”在农业中代表另外13亿美元的劳动力成本。
由于动物疾病造成的损失。我们估计，由于乳牛中可预防的跛足，全球乳品业的年损失超过110亿美元。学术研究表明，在乳汁流失，生育力下降和治疗成本之间，跛足使乳牛场成本每年达到175美元，每年每100头奶牛发生23.5例，这意味着当全球有2.5亿美元的奶牛时，成本将超过110亿美元。
目前的经营方式是什么？
绝大多数农场都很小，但大多数农田是由大型农场控制的。 根据联合国粮农组织的数据，全球72％的农场面积小于1公顷，而只有1％的农场大于50公顷，这些大型农场控制着65％的全球农业用地。超过10公顷的农场绝大多数存在于像美洲和欧洲这样更发达的地区（两者之间的73％），而亚洲占小于10公顷的农场的达85％。 因此，世界上大多数农田都能获得基础设施和经济发展，使得能够使用精确农业技术，只要这些技术在财务上可行的。
：小农场是发展中国家的常态
：发达国家的农业经营的规模
即使在经济发达国家，精确农业仍处于早期阶段。比如，灌溉仍然通过溢流或其他形式的表面灌溉进行，这是最低效率和最低技术先进的方法之一。在作物种植的主要领域，目前的技术包括：
l 肥料：天气和现场监测和毯子应用。
l 种植：多种子的播种，变率播种和作物轮作种植。
l 农药/除草剂：卫星和无人机图像已在目标区域的一些大规模作业中使用。 使用毛毯应用的小型操作。
l 灌溉：淹没式和其他表面灌溉，中央枢轴喷头，灌滴系统和混合洒水/滴灌系统。
l 收获/分类：玉米和小麦等作物的大部分收获已经实现了大型农场机械化。一些分类已实现自动化（按大小和特色）。
随着美国建立农民商业网络（FBN），我们还看到农业数据民主化的到来。FBN是一个独立的业务，农民可以匿名订阅并提交农场数据。在分析过程中，FBN使用聚合农场数据为单个成员农民利用产量，时间，天气和其他数据生成预测报告。
在畜牧业和乳制品业中，目前的技术包括普遍应用抗生素或其他预防性药物，接种疫苗，扑灭病动物，以及化学平衡的饲料添加剂。此外，黄牛作业也采用足浴预防和治疗蹄疾病及感染。
：在美国，近一半的灌溉农田是通过洪水或其他表面灌溉灌溉的——这是最低效的和最低技术的方法之一
人工智能和机器学习如何助力？
机器学习使用大型数据集来优化单个或一组最终目标的能力有利于解决农业中的问题，如作物产量，疾病预防和成本效率。
在收获后分拣和农药应用中，我们认为M机器学习/人工智能可以降低成本，提高效率，在美国境内创造30亿美元的年度劳动力储蓄。根据我们的估计，全球数字可能会超过这一数字的两倍。最后，我们认为，机器学习/人工智能应用可以改善育种和健康状况，单单从影响动物两种常见疾病出发，奶牛养殖价值创造可以达到约110亿美元（在收回失去的潜在收入和绝对成本降低之间），以及20亿美元的家禽生产。
提高作物产量。人们已经在利用几乎所有行星可用的农业用地，联合国预计到2050年全球人口将达到97亿。因此，有必要提高作物产量，以满足未来全球对粮食的需求。机器学习可用于分析来自无人机和卫星图像，天气模式，土壤样品和湿度传感器的数据，以帮助确定种子种植，受精，灌溉，喷洒和收获的最佳方法。
：机器学习几乎在每一个精准农业报告（2016年7月13日出版）提到的创新中都起着重要的作用
玉米产量通过技术的潜在改善
收获后分拣劳动。 我们看到一个简单的案例研究，日本黄瓜农夫应用谷歌的TensorFlow ML技术自动化排序他的黄瓜的过程。这个过程以往需要大量手动/视觉检查的人工成本。 使用简单，廉价的硬件，包括树莓派处理器和普通网络摄像头，农民能够利用TensorFlow训练一个算法，可以将黄瓜分成9类，具有相对较高的准确性，几乎消除了与分拣相关的人工成本。 我们认为类似的应用可以扩大规模，用于具有高分拣需求和成本的农产品，如番茄和土豆。
家禽群疾病检测：在一项学术研究中，研究人员收集和分析了鸡的声音文件，假设他们的声音会因生病或痛苦而改变。在收集数据和训练神经网络模式识别算法后，研究人员能够正确识别感染了两种最常见的致死性疾病之一的鸡，在疾病2天后精确度为66％，8天后精确度为100％ 的疾病（）。在损失发生之前尽早正确诊断动物并治疗可以减少行业专家估计的由疾病导致的20亿美元的损失。
：实验表明，机器学习可以通过听觉数据分析正确识别其他不可检测的疾病，减少由于某些可治愈疾病造成的损失
量化机会
基于产量，作物投入成本节省，乳品/畜牧成本节约，分拣和劳动力节约的潜在增长，我们认为机器学习可产生超过1万亿美元的价值。
在农业中，我们认为机器学习/人工智能可以帮助提高作物产量的70％的增长。在Jerry Revich的精确农业（《精确农业：数字农业欺诈马尔萨斯》，2016年7月13日发布）中，数字农业的TAM被确定为2,400亿美元，假设各种技术供应商的价值增长为30％。考虑到数字农业中使用的所有已识别的技术将被优化或完全由机器学习/人工智能提供，我们假设该价值创造的25％累积到机器学习/人工智能链中的供应商，这意味着在作物种植应用中TAM达600亿美元。在蛋白质农业中，我们认为机器学习（精确育种机制，疾病预防/治疗）的应用可以产生另外一个200亿美元。
：来自先进技术的全球作物产量的潜在增长可以在作物农业中产生超过8000亿美元的增值
美国东部时间，通过技术提高全球农作物价值（单位，百万美元）美东时间
：人工智能和机器学习可以减少潜在的超过110亿美元的亏损
美国东部时间，奶牛跛足的损失（单位：百万美元）
谁会占下风？
我们认为机器学习有可能根据灌溉，化肥，劳动力和疾病预防/治疗的成本节约，以较低的单位成本扩大作物，乳制品和牲畜的全球供应。我们预期化肥和农药/除草剂/杀菌剂以及兽医药品的全球市场会受恶性影响，因为机器学习应用限制了农业中的浪费和改进预防方法（限制了治疗方法的需要）。我们相信，这种影响大部分是长期的（5年以上），因为这些技术大部分仍然处于早期发展阶段，早期采用者的成本相对于其他潜在的改进机制有时候让人望而却步。
农民经营网络
我们与联合创始人兼首席执行官Amol Deshpande以及FBN工程团队的成员进行了交谈。 FBN是一个由2,800多名成员农民组成的网络，覆盖1000万英亩的农田，汇总从农民和农场设备上传的数据，使农场数据民主化，并使成员农民能够利用它进行定价，种子选择和产量优化 。
问题
农业中的不对称信息导致农民做出关于种子选择，肥料选择/应用和其他业务的重要方面的决定，而没有广泛了解哪些选择在近年来在其所在地区产生了最高产量，或者甚至价格是否与其他农民看到的一致。农民也受到供应商的偏见。
FBN解决办法
数据的汇总和分析：农民每年支付500美元（多年折扣），以获得FBN会员资格。 农民可以从他们的设备和系统上传数据，包括种子类型数据，土壤数据，收获/产量数据，以及地理位置和海拔数据等。FBN还聚合来自其他公共来源的数据，包括政府和天气数据。FBN使用机器学习来分析，清理和分析数据，以便为个体农民提供参考，为个体农场量身定制，帮助他们选择最佳投入和农场管理策略，以实现产量和生产力的最大化。
融资：FBN也开始了对自助金融服务的试验，利用来自实际农场的历史和预测数据来确定信用度。没有运行信用检查，FBN是否能够达到97%以上的回报率。
采购：从化学品开始，FBN开始为网络农民提供采购服务。鉴于FBN获得大量投入定价数据集，可以代表数千名农民以更大规模进行采购，该公司相信它可以更好地定价和降低投入成本，同时在每次交易中获得9%的佣金。早几个月的平均票面规模为45000美元。
：FBN的初始目标是利用数据和机器学习提前告知农民做出决定
数据聚合与使用周期
：最终目标是取代采购，销售和金融从业者
金融服务
到2025年每年节省成本34亿至430亿美元，并创造新的收入机会
机器学习和人工智能在金融服务领域具有广泛的应用，因为存在强大的，丰富的数据集，通知投资决策和信用风险特性，说明了有利于使用算法提高数据效率的环境。机器学习技术在人类驱动等效时间的一小部分时间内利用模式识别的能力为独特数据的采购和分析提供了机会，从而更准确地为投资决策提供信息。此外，商业银行提供广泛，全面的专有财务数据为人工智能/机器学习在减少一般银行部门成本方面提供了机会。保守地说，我们相信机器学习和人工智能可以在2025年之前每年获得大约34-430亿美元的成本节省和新的收入机会，并且这个数字会进一步上升，因为这些技术可以使得更快，更复杂的数据得以利用和执行。
什么是机会？
投资潜力最大化。我们认为，具有相对技术杠杆的资金管理公司（即量化对冲基金）最适合利用机器学习技术利用竞争性利润机会。将深度学习算法与应用程序加速器相连接的最新进展提高了识别数据乃至图像集趋势的速度和效率，为希望在信息和执行杠杆中获得竞争优势的公司提供了明确的前进方向。
在数据方面，我们认为人工智能/机器学习可以为分析投资决策提供重要的优势，为降低成本和打入新的利润池创造机会。在执行方面，2015年交易的1.7万亿美元以上的股票股票突显了大量机会，交易公司利用微小的延迟窗口，其中最新的安全价格存在于原始交易所，但不是整合的市场系统，我们认为人工智能/机器学习可以产生有意义的差异。我们相信，通过利用具有成本效益的硬件加速器和模式识别功能，人工智能/机器学习可以对数据质量分析，采购和执行速度产生重大影响，2015年前每年从更好的知情投资决策以及第十场的快速反应中获得190亿至280亿的收益。
降低信用风险。对于传统的贷款机构，我们相信机器学习和人工智能潜在地降低信用风险，识别处于风险中的账户，并执行可以减少这些机构的资产负债表和贷款损失准备金的信用额度减少或抵消。 即使在退税率相对较低的环境下，根据联邦储备委员会，每年增加的消费信贷额度也导致了约600亿美元的消费信贷相关费用，到2025年，可以使用人工智能/机器学习将其减少19%。
降低合规性和监管成本。对于金融服务公司，如社区银行和大型投资银行，我们估计合规相关员工成本每年高达180亿美元。虽然许多公司在过去几年中的合规成本增加了50％或更多，但我们认为人工智能/机器学习有可能降低行业的成本负担。包括降低信用风险，我们认为人工智能/机器学习可以在2025年前为金融服务部门每年提供约150亿美元的成本削减机会。
什么是难点？
今天，企业面临着资源分配困境，即在不断发展的技术中平衡员工薪酬和资本投资，目的是扩大“好数据”的使用，以产生资本回报和压缩成本。以下是我们认为阻碍公司有效利用数据的三个难点：
执行速度。资产管理者，特别是在技术市场运动交易的高频交易者（HFT）的主要难点是，在高流动性和快节奏的市场保持竞争力，毫秒级决定了回报潜力的巨大差异。 例如，在2014年，等待时间套利窗口的中位数长度几乎是一个整数秒，并显著减少了面临套利或HFT策略的资金管理者的急剧增长。
数据访问。在基本面方面，由于测量限制，地缘政治限制和分析成本约束，我们认为各种有用的数据是不可靠的或不可实现的。高技术壁垒阻碍了资产管理者获得新颖，及时和更准确的数据的竞争优势。
成本的二元性。我们认为，过去十年中数据清理，分析和执行的劳动成本为资产管理运营利润率保持在40％以下起到了重要作用。此外，程序化加速硬件的启动非重复工程（NRE）成本历史上为利用技术来提高竞争力提供了成本障碍。诸如现场可编程门阵列（FPGA）等更低成本选择的可用性和灵活性的提高为人工智能/机器学习过程提供了更多可利用的途径。
目前的经营方式是什么？
人力资本驱动成本，风险管理结构。对于今天的许多大型资产管理公司来说，创造收入的员工成本占创造收入的1/3到1/2之间，因为员工负责筛选强大的数据集，管理评论和研究观点，做出有利于客户的知情投资决策。为了同样的效果，传统贷款机构的贷款官员通常负责批准和监督信贷周转箱和可能出现的违约的定期贷款，其总体责任是尽量减少固定的贷款损失。在投资和社区银行，不断变化的监管环境增加了需要人力资本的合规工作的资本支出。
市场依赖于预定的主要来源数据发布来衡量综合ROIC。由于大数据访问的低障碍和通过在线渠道的相关一次性市场事件的低延迟传播，投资者分配大量的劳动力和资本以有效地清理数据集，获得专有边缘，并对快速变化的情况做出快速反应。然而，无论这些专有优势如何，资金管理者最终都依赖于主要源数据发布（例如每周EIA石油库存数据，公司收益报告）来衡量预测随后的市场变动以及所产生的ROIC。
人工智能/机器学习如何助力？
机器学习的应用可以快速监控和处理健壮的数据集，以寻求分析或执行特定的最终目标，特别适合高频交易公司，传统资产管理和传统贷款机构。
执行速度。具有HFT焦点的资产管理者面临来自竞争对手日益增长的压力，因为不断发展的技术采用减少了对技术和一次性基本市场催化剂的反应时间。延迟套利是资金用于在市场之前仅仅几分之一秒获得交易信息的一种做法，通过增加诸如ASIC和FPGA之类的硬件加速器来减轻。
企业能够以两种不同的方式减少延迟。首先，他们能够在交易所共同定位交易服务器，减少物理距离，并更快地获取相关贸易数据。第二，这些公司能够从原始交易进货中获取数据，并比传统数据合并过程更快地检索全国最佳出价/报价（NBBO）价格（）。公司可以在具有明显优势的市场之前接收数据，并且我们相信机器学习算法具有在延迟时间段更快速和准确地识别和执行价格扩展的潜力。
：延迟套利提供早期NBBO访问
人工智能和机器学习促进数据捕获和执行
数据访问。随着技术演进促进传统资产管理者获取大数据，企业越来越试图在行业中找到竞争优势。数据分析公司进入市场以捕捉未开发的机会。例如，一些公司正在利用来自卫星的数据，捕获关于股票，商品价格，甚至全面经济的信息的区域的图像。对于像Cargometrics和Orbital Insight这样的公司，这些图像包括运输模式，以通知商品价格以存储停车场，并分别通知零售商的客户增长率。有几家公司正在建造自己的火箭并预订未来的小型卫星以进行有效载荷发射，而SpaceFlight等公司则通过与世界各地的发射载波提供商合作来保证发射。
利用机器学习/人工智能的数据分析公司利用诸如卷积神经网络（CNN）的算法的图像识别能力来擦洗用于世界特定区域中的特定特征的图像数据。 以这种方式，他们能够更快速和准确地定制敏感，偏远和密集区域的数据，并打包它以通知具体的市场趋势。 风险投资公司Deep Knowledge Ventures是对大数据的行业承诺的最好例证，最值得注意的是，在2014年它向其董事会指定一个名为VITAL的数据分析算法。
：卫星数据周期
人工智能和机器学习创建优势，优于传统的数据收集
Orbital Insight（轨道透视）：在卫星图像分析中开创性地使用AI
我们与Orbital Insight（一家位于加利福尼亚州帕洛阿尔托市的数据分析公司）进行了交流，该公司汇总了来自8个卫星提供商的卫星图像数据，并使用人工智能技术加快资产管理者的市场适用性。
问题：资产管理公司面临着日益激烈的竞争环境，因为技术进步普及了数据的获取，并加速了市场对一次性事件的反应。当企业寻求利用市场低效率的方法时，许多相关的数据源仍然没有被利用（即卫星图像，航运运动），或者无法有效地商业化而用于市场。
Orbital Insight解决方法：轨道使用卫星数据来分离图像，指示特定的市场趋势。 无论是聚合油桶盖上的阴影形状以通知商品价格还是量化主要零售商的零售流量模式，该公司的分析解决方案利用了大量数据集，通常在传统收集指标无法覆盖的领域，并且训练机器学习算法，来快速打包与所需解决方案相关的数据。虽然该公司指出，图像数据本身是公开可供购买的，但它利用专有机器学习的能力超越了仅仅是学术用例，这对于创建有关数据对投资者的影响的差异化洞察是至关重要的。
该公司表示当今利用卫星图像的困难，因为卫星到任何特定的位置的访问从15-30天不等。 这需要将图像的相对捕获时间的变异性以及控制变量中的其他相关偏移归一化。然而，最近与Planet Labs的合作关系使得公司能够获取数据集，为下一年世界各地提供每日图像，因为纳米卫星队将进入轨道。
Orbital通过50-60专有神经网络分类器来强调它的价值主张，其基本上是在“训练集合”上训练的算法，来寻找和识别兴趣点和关于兴趣点的特定特性。该公司估计，他们的深度学习算法现在达到了90-95％的精度，通过使用可靠的数据集（即EIA油储存数据）进行比较来验证人工智能预测。
云与人工智能的交汇减少了瓶颈：随着Orbital扩展规模获得越来越多的图像数据，它正在利用亚马逊网络服务（AWS）云平台临时存储数据，同时也被分析。考虑到图像的潜在存储障碍，特别是与Planet Labs合作，该公司表示，它将依靠AI系统快速高效地更新数据，并在项目完成后平衡图像库存的一致流入/流出。
：微型分析通知零售趋势
:石油存储水平
信用风险降低。冲销阻碍了商业银行资产负债表和现金流，我们估计每年约有600亿美元与消费信贷有关。基于Khandani等人的报告（《通过机器学习算法的消费者信用风险模型》，MIT，2010年6月10日），我们认为人工智能/机器学习有可能迅速识别循环信用额度（RLOC）中的风险，并让数据显示的可能拖欠的账户执行限额减少或抵销。
研究表明，他们的机器学习模型能够预测RLOC中的信用违约率，线性回归
为85%，突出了机器学习应用于洗钱和信用数据。我们进一步认为，除了使用典型指标外，机器学习可以帮助贷款人员确定信用度，从而对非循环消费贷款做出类似贡献。在欺诈检测方面，诸如AIG和Stripe这样的私人支付公司正在使用机器学习进展来更好地通知和确定欺诈活动索赔和交易中的模式。
减少合规成本。在合规方面，小型社区银行和大型投资银行都在加大支出，对行业面临的新法规保持警惕。根据摩根大通最近的年度报告，公司在2011年至2015年期间将合规支出增加了50％，达到90亿美元。同样，花旗集团在2014年表示，合规员工人数增长到3万，占员工总数的12％以上。
我们认为人工智能/机器学习可以在减少执行某些任务所需的员工开销方面产生有意义的影响。对于Digital Reasoning，一家位于纳什维尔的私人分析公司，开发机器学习技术，以提供主动合规分析，完成任务，如筛选员工的电子邮件可能不合规的内容，并检测违规，如市场操纵等未经授权的交易交叉违规。
数据访问和ROI。为了说明利用人工智能/机器学习获得全面的专有数据对ROI潜力的潜在影响，我们对石油期货投资和2011 - 2016年隔离的前端石油期货合约价格进行了分析。使用合同价格数据，我们发现在EIA石油储存数据发布（星期三，每周）当天，石油期货市场的波动率增加了14％。
鉴于从采油ML容器，钻机，船运和生产设施的高清图像数据获得的价值和观察，没有地理或地缘政治约束，我们认为金融服务行业有机会利用数据驱动的市场事件使用机器学习。 石油期货市场数据释放的波动是一个例子，说明如何使用更好的数据来为投资决策提供信息，并提供更好的回报潜力。
量化机会
我们估计人工智能/机器学习有可能在2025年之前为金融服务行业每年节约大约340-430亿美元的成本和创造新的收入机会，随着相关技术在复杂性和复杂性方面不断发展，这个数字会进一步增大。我们量化人工智能/机器学习每年在未开发的延迟套利机会中贡献了65亿美元到150亿美元，130亿美元来自更高效的数据访问导致的资产管理器运营成本降低，每年约20亿美元来自合规性成本降低，以及每年约130亿美元来自传统贷款机构的年度减免。
潜伏套利。为了量化美国股票市场的潜在套利潜力，我们利用了Elaine Wah的学术研究（《如何普及和盈利是美国证券交易所的延迟套利机会》，密歇根大学，2016年2月8日）。根据研究人员，2014年495 S＆P 500股票的总延迟套利利润为30.3亿美元，每个股票每天有大约69个套利机会。根据这个分析，我们发现这样的利润相当于每股交易的3/10，而推算到2016年总估计美国股票交易量时，盈利水平为65亿美元。假设股票数量增长与2014-2016年水平保持不变（10％的年复合增长率），这意味着到2025年年收入150亿美元。
：潜伏套利利润
到2025年为65亿-150亿美元，取决于股权总量的复合年增长率
资产管理成本降低。波士顿咨询集团指出，资产管理公司营业利润占净收入的百分比在近年来保持在39％，2007年达到41％，2014年利润达到1020亿美元。我们认为，引入人工智能/机器学习数据访问和分析（如我们的小卫星案例研究所强调的）将缓慢地使得对冲基金和其他资产管理者以比数据采购成本的增长更快的速度减少劳动力需求。所有其他条件相同时，我们预计未来十年资产管理行业的运营成本将下降5％，或每年增加13亿美元。这意味着该行业在2025年之前每年可以节省130亿美元的成本，并且在假设对冲基金利润在未来几年保持基本持平。考虑到资产管理者利用人力资本的水平，我们认为人工智能/机器学习可以使运营利润高于我们在2007年看到的水平。
：资产经理营业利润率占净收入的百分比停滞不前
我们期望边际效应能通过人工智能/机器学习增加
传统贷款人风险降低。在Khandani等人关于机器学习和消费者信用风险的文献之前，研究人员表示，他们的循环式消费信贷违约的机器学习模型意味着收费成本节约了6%到23%。考虑到机器学习在我们看来只能用于贷款的前端，我们仍然更接近这个范围的保守末端（隐含成本约为8％），我们在机器学习应用中增加了非循环贷款，而并非在整个付款时间表加入循环信贷情况。然而，到2025年，随着技术在外部年代越来越复杂，我们的隐含成本节约增加到19％。假设每个类别中的违约概率相等，四分之一的退款来自循环信用，另外四分之三来自非循环（NR）信用协议。基于这些假设，我们预计到2025年，人工智能/机器学习每年为传统贷款机构节省成本约130亿美元。
：消费信贷持续增长
商业银行冲销已稳定在600亿美元
：机器学习可以减少贷款损失
我们估计到2025年每年成本减少130亿美元
减少合规成本。我们估计社区银行和大型投资银行每年总共支付约180亿美元的合规相关员工成本。根据美国联邦储备委员会对21世纪社区银行业的研究，社区银行（资产不到100亿美元的银行）在2015年支付了超过30亿美元，而我们估计最大的10家投资银行的支付额不到140亿美元。 我们假设每个合规员工的平均工资为每年69,000美元，并认为人工智能/机器学习可以减少合规员工成本的10％，因为银行合规工作的一部分由机器学习驱动。基于这些假设，我们认为到2025年，人工智能/机器学习可以为银行公司的合规成本削减贡献约20亿美元。
谁会占下风？
有资本限制和传统资产管理实践的公司可能会受到干扰，因为适应性公司更多地投资于竞争性人工智能/机器学习交易硬件和新的专有数据库。由于这些公司在缩小市场无效率差距方面减少了延迟，因此对于仅依靠人力资本进行研究的公司和技术市场运动/一次性基本市场催化剂交易的公司可能没有太多空间发展。
在批准贷款（即信用评分）时，具有繁重信用审批流程或依赖于少量信用度量标准的公司可能会受到开始使用人工智能/机器学习的竞争对手的影响。由于机器学习算法减少/消除了前沿公司的风险信用额度，这些客户可能越来越多地尝试从没有机器学习应用的传统机构接受贷款，这些公司的违约率将更高。
医疗保健
到2025年每年节约成本540亿美元
机器学习在医疗保健领域具有广泛的应用，如丰富的，定义明确的数据集应用，随时间的监测的需要以及结果的广泛的可变性，为药物发现，测试分析， 治疗优化和患者监测服务。 随着机器学习和人工智能的整合，有机会显著推动药物发现和开发过程，每年减少260亿美元的成本，同时使得全球医疗信息价值超过280亿美元。
什么是机会？
药物发现和开发。通过在整个开发过程中结合机器学习过程而产生的潜在效率增益不仅可以加快时间范围，还可以通过增加到达后期试验的药物的成功概率（POS）来提高研发支出的回报。Medicxi Ventures的合伙人David Grainger认为，避免假阳性发现率，根据他的一个主要的统计驱动现象，可以将后期试验的风险降低一半。此外，在早期药物发现中称为高通量筛选的当前虚拟筛选方法非常容易受到这种类型的统计误差的影响。减少昂贵的第三阶段试验的风险可以产生数十亿的储蓄，并影响超过900亿美元的研发支出在最大的制药公司的回报，释放资源以寻找更好的潜在机会。
虽然与晚期试验相关的大量成本经常集中在临床试验设计元素中，但我们相信在整个人工智能/机器学习实施的后期阶段也可以实现显著的效率增益，以优化关于选择标准，大小和研究长度的决策。
医生/医院效率。部分由于监管和分割的驱动，美国的医疗保健系统历史上一直在采用新技术较为缓慢。除了系统的挑战，新发现与医生和诊所提供新药物或治疗方法之间的时间往往较长，且不一致。
根据透明度市场研究公司的数据，到2023年，全球市场预计将达到约300亿美元，其中美国政府作为“美国复苏和再投资法案”的一部分，最近的授权推动了电子健康记录。独立医院的长期衰落创造了一个数据聚合的机会，利用在历史上不可能达到的规模的数据改进。 这反过来使得机器学习算法和人工智能能力提高在医疗保健的各个领域的速度，成本和准确性。
：供应商整合
社区医院卫生系统
：电子健康记录市场全球扩张
谷歌的DeepMind部门总部设在伦敦，正在与英国国家卫生服务（NHS）合作，建立一个旨在监测肾脏疾病患者的应用程序，以及一个以前被称为“患者救援”的平台，旨在支持诊断决策。任何人工智能/机器学习系统的关键输入是大量的数据，因此DeepMind和NHS达成了一个数据共享协议，为DeepMind提供了连续的新数据流和历史记录，用于训练算法。这种对临床数据的实时分析只有在大量数据的情况下才可能实现，尽管DeepMind提供的有效无限访问患者数据远远超出了肾脏疾病范围。
什么是难点？
药物发现和开发。医疗保健中的一个重要的难点是药物发现和开发的时间和成本。根据塔夫茨药物开发研究中心的数据，新疗法平均需要大约97个月才能从发现到达到FDA的批准。虽然专注可以减少时间，但是成本也继续稳步增长。德勤发现，在12家大型制药公司中，开发批准资产的成本自2010年以来增长了33％，每年约为16亿美元。
研发回报。生物制药的研发生产力仍然是一个争论不休的话题。虽然开发成功药物的成本增加了，由于报销的不利因素，较少的患者和竞争，收入依旧无法被回报改善。虽然我们预计2010-2020年与2000-2010年的回报率会有所改善，但变化是微不足道的。此外，最重要的回报阻碍之一仍然是失败的资产，特别是到达后期阶段，我们估计年度成本超过400亿美元。
：20年和10年总回报率
总回报比率(累积收入除以GAAP研发支出)
医生/医院效率。当新的药物和治疗之间的批准，医生开始实现患者的需求时，独特的医疗挑战仍明显滞后。因此，许多在医疗保健领域工作的机器学习和人工智能专家继续鼓励主要提供商将现代机器学习工具集成到他们的工作流程中，这些工具可以充分利用了今天收集和发布的大量医疗数据。
存在机器学习和AI的机会，减少发现和应用之间的时间，还能优化治疗。例如，2009年北美放射学会对肝胆（肝，胆囊）放射学的研究发现，23％的第二意见是诊断要有变化，机器学习公司侧重于医学成像的问题有机会得到解决。此外，像Deep Genomics这样的公司，使用机器学习来识别基因组水平的疾病，提供更有针对性和有效的治疗。
：大型生物制药10年研发支出 VS FDA批准
目前的经营方式是什么？
目前的药物发现和开发业务是一个广泛的研究，测试和批准的过程，可持续10年以上。来自塔夫茨药物研究中心的上市时间分析报告，药物从第一阶段推进到FDA批准，平均需要96.8个月。新治疗的发现是一个独特的挑战，不仅是因为所需的时间长度，而且还因为各个发展阶段的POS低值。
药物发现最初开始于识别了目标。 一旦识别了目标，高通量筛选（HTS）通常用于“发现”。 高通量筛选（HTS）是由机器人进行的自动化的，昂贵的过程，机器人试图通过进行数百万次测试来确定这些“点击”，以查看哪些化合物显示出目标的潜力。然后，过渡到先导生成，其中它们被优化以找到先导化合物，然后在进行临床前药物开发之前对其进行更广泛的优化。 该整个过程可以在药物达到阶段1之前持续1-3年，在该段时间里仅具有20％的成功概率。
l 第一阶段：强调安全;健康志愿者(POS 20%)。
l 第二阶段：关注有效性;有某些疾病或条件的志愿者(POS 40%)
l 第三阶段：收集关于不同人群，剂量和组合的安全性和有效性的进一步信息。范围从几百到数千志愿者(POS 60%)。
：药物发现和研发时间线
人工智能和机器学习如何助力？
机器学习和人工智能在医疗保健行业中的优势和用例范围很广。不仅是由数据而非人类的理解或直觉驱动的决策，决策和预测能够考虑超出人类能力的因素。深度学习特别展示了独特的潜力，因为它可以利用在不同任务中学到的知识提高其他任务的绩效。
减少药物发现失败并增加POS。 大量资本投入造成巨大的机会成本，去探索被认为具有大约20％成功概率（POS）达到一期试验的治疗。因此，迄今人工智能/机器学习几乎完全在学术界应用，努力开发有效和准确的虚拟筛选方法，以取代昂贵和耗时的高通量筛选过程。
谷歌和斯坦福研究人员最近利用深度学习努力开发虚拟筛选技术，以取代或增加传统的高通量筛选（HTS）过程，并提高筛选的速度和成功率。通过应用深度学习，研究人员能够跨越多个目标多个实验，促进信息共享。
“我们的实验表明，深层神经网络优于所有其他方法…特别是，深层网络大大超越了现有的商业解决方案。在许目标上，它实现了接近完美的预测，这让它适合用于虚拟筛选装置。总之，深度学习提供了建立虚拟筛选作为药物设计管道中的标准步骤的机会。”（Massively Multitask Networks for Drug Discovery， 2015年2月6日）
默克在2012年主办了一项Kaggle挑战，旨在确定虚拟筛选的统计技术，并开始测试深度学习和人工智能的应用，特别是通过与公司Atomwise合作启动人工智能药物发现。Atomwise最近利用人工智能技术进行了培训，像化学家一样分析药物，以了解如何安全地将现有的药物重新用于治疗埃博拉病毒。该分析评估了7,000种现有药物，在不到一天的时间内进行。 根据公司的统计，以往这项分析需要花费数月或数年才能完成。
提高医生/医院效率。应用机器学习的早期成功已经让我们看到了诊断的改善（Enlitic，DeepMind健康），分析放射学结果（斑马医学视觉，Bay实验室），基因组医学（深基因组学），甚至使用人工智能治疗抑郁症，焦虑， 和PTSD（Ginger.io）。由于健康数据的数字化和数据聚合，健康数据变得更易于访问，人工智能/机器学习不仅可以减少与过程任务相关的成本，而且还可以通过历史上不同数据集通信改善算法。最终，人工智能/机器学习超出人类能力的考虑问题的能力使得供应商以更高的效率诊断和治疗。
麻省理工学院-哈佛大学Broad研究所：在基因组学和抗癌中使用AI/ML
麻省理工学院-哈佛大学Broad研究所，一个非营利的生物医学和基因组研究中心坐落在马萨诸塞州的剑桥，处于学术界和工业的交叉点。通过与哈佛和麻省理工学院的合作，该中心促进了跨不同领域的合作研究，旨在发布其研究结果或将其授权给生物技术或制药公司。 根据Broad Institute首席数据官，心脏病学家和Google Ventures合作伙伴Anthony Philippakis的说法，最终，该中心的目标是产生人们可以用来推进其科学议程的结果。
我们接下来强调以下几个关键要点：
机会，挑战。Broad研究所现在在其基因组研究的某些领域运行人机测试。到目前为止，匹配算法没有错误，并且还减少了一组人的工作量。然而，数据或结果可能涉及伦理或政治问题时人类依然需要参与。
虽然不缺少人工智能/机器学习用于挽救生命或发现生命的案例，但是根据Philippakis先生找到合适的商业模式来支持最终目标是主要的挑战。 目前，医生要求每天根据记住的事实和首字母缩略词来确定治疗路径，做出改变生命的决定，这是在临床护理中人工智能/机器学习的重要应用的一个领域。然而，因为偿还决策支持工具和激励开放这种人工智能/机器学习一体化所需的卫生数据还没有赶上，依然存在很大的障碍。
技术堆栈。Broad是Google Cloud的大用户，拥有大量的平台开放源代码，因为该研究所的团队旨在在Spark框架中构建内容。尽管这些技术仍然处于转型阶段，但是云供应商的发展很快，因为他们是唯一能够匹配增长水平的公司。此外，根据Philippakis先生的说法，许多云供应商正在为基因组学建立专门的团队，尽管进化仍然处于“ML-as-a-Service”产品的学习曲线的开始阶段。
数据，数据，数据。Broad研究所每月生成大约一个PB的数据，每8个月的倍增一次。因此，该研究所正在与像Cycle Computing这样的公司合作，以摆脱传统的数据处理方法。结构化数据带来了重要的后续机会，该研究所还推动其他数据和分析标准发展，如基因组分析工具包（GATK），提供了各种各样的工具，专注于变异发现和基因分型。
理想情况下，Broad的科学家将分析基因组数据与EHR（电子健康记录），以了解特定细胞系和癌症之间的关系，但是目前EHR世界中存在有限的激励机制无法开放和共享，因为大多数激励机制存在数据披露风险。也就是说，Philippakis先生看到Broad在未来的一个大多数开放的基因组数据的世界，而不像其他的旨在囤积数据。
：Broad研究所的基因组分析工具
专注于发现和基因分型
量化机会
药物发现失败的成本。我们通过实施机器学习和人工智能，在以下假设下分析将药物开发发现相关风险减半的影响：
l 核准资产的平均年度开发成本为16亿美元，包括与失败资产相关的成本（德勤）。
l 来自失败资产的300亿美元年度成本可以平均分配给分析队列报告的批准资产数量，或43（德勤）。
FDA在2015年报告了60个批准，这意味着，根据每个批准的资产失败成本（2015年约6.98亿美元），将近420亿美元分配给失败的资产。我们认为机器学习和人工智能可以将发展过程的风险减半，到2025年全球制药行业每年可节约260亿美元。
：人工智能和机器学习可以减少260亿美元的开发成本
加速从转向电子健康记录的收益增长。仅在美国，卫生信息技术人员今天的年度薪酬就约为70亿美元。由于人口老龄化和政府向数字化转型需要部分驱动，根据BLS，健康信息技术人员的工作前景预计将在2014-2024年间达到高于平均水平的增长，在所有其他职业中增长15%vs.增长7%。然而，考虑到自动化和替代通过软件在职业内的许多任务，我们认为机器学习和人工智能可能取代几乎所有这些工作。
健康信息技术人员根据BLS确保报销和研究的患者健康数据的质量的准确性，可访问性和安全性，同时利用技术来分析患者数据，以提高护理和控制成本。医疗行业中人工智能/机器学习的扩散可能会对这类职业产生严重影响，我们根据人均卫生支出和全球支出份额估计，人工智能/机器学习可以通过以下方式在2025年前减少全球年度成本超过280亿美元。
：人工智能和机器学习可能取代几乎所有卫生信息科技（HIT）的位置
谁会占下风？
我们相信机器学习和人工智能有潜力大幅度改变大药房景观和医疗系统更广泛，基于成本节约和POS改善，使得整个药物发现和开发以及提供者和设施的效率改进。我们期望，长期内，机器学习和人工智能技术的激增，增加药物开发中的竞争，因为时间缩短和失败资产的损失下降。
此外，效率提高和自动化可能会让医疗专业和公司占了下风，这些医疗专业和公司对解释结果和诊断与实际交付护理或执行手术（例如放射科医生，提供第二意见的专家，以及行政或支持人员）指数过多。我们认为，大多数的影响是长期的，因为许多技仍然处于早期开发阶段，并且早期采用者的成本相对于其他改进机制让人望而却步。
存在的挑战
虽然人工智能/机器学习在医疗保健领域的机会跨越了许多子行业，但仍然存在障碍。
l 成本。作为人工智能/机器学习的必要成本可能是令人望而却步的，特别是在医疗保健中，护理成本仍然是焦点。确保机器学习算法，利用好的数据的投资，需要大量资本和专门技术，单凭计算能力非常昂贵。
l 可解释性。组合多个数据集的算法可以产生一些黑盒。以前一直受到严格监管的医疗保健行业可能会推迟人工智能/机器学习应用的进步。
l 人才。障碍也可能来源于能够应用人工智能/机器学习和解释结果的人才集中。2013年，谷歌支付超过4亿美元收购DeepMind科技；根据新闻报道，一个团队大概有十几个成员。这种人才的合并以及由此产生的成本可能会令人望而却步。
l 数据。虽然政府规定美国电子记录数字化，但将纸密集型系统转变为完全电子化的过程仍然存在挑战。此外，虽然许多已经达到“有意义的使用”的标准，但是重要的患者数据的碎片化和可获得性的缺乏可获得性可能阻碍进展。
l
零售
到2025年每年节省成本540亿美元，年收入410亿美元
虽然离线到在线转换已经证明了许多传统零售类别的挑战，但电子商务的出现也为零售商带来了大量的客户数据。然而，最重要的问题仍然存在。企业如何利用他们手头的数据来更好地为客户提供服务并赚更多钱？成功的早期迹象为广告技术的激增，使零售商能够更有效地定位网络上的客户。今天，零售商利用历史上不同的数据集，不仅优化广告，还优化库存管理，需求预测，客户管理和趋势外推。我们看到人工智能/机器学习通过预测需求，提高每年价值为540亿美元的劳动效率，同时优化定价，并在2025年之前在全球范围内实现410亿美元的服装和鞋类的年度销售提升。
什么是机会？
零售作为一个部门正在导航重大的长期趋势，因为千禧一代成为主要购买者，消费者习惯与在线购买。虽然零售商迄今为止在不同程度上取得了不同程度的成功，但是人工智能/机器学习为全渠道和纯粹电子商务零售商提供了一个机会，从购买转移在线和技术改进时积累的大量客户和产品数据中获得预测。在我们的研究中，我们确定了跨越零售价值链的人工智能/机器学习的关键领域的机会。
虽然推荐引擎不是电子商务中的新现象，但传统技术面临着一定的局限性，我们认为人工智能/机器学习可以超越，为销售和内容数据提供更深入，更准确的见解。此外，自然语言处理（NLP）人工智能系统实现更直观和相关的商业搜索以及对话。此外，将人工智能/机器学习整合到批发和零售采购的早期阶段以及后期销售阶段，可以通过更精确的需求预测和以优化定价改进销售，从而提高劳动力和库存效率。
：全球电子商务
：电子商务渗透
2015年整体普及率8%
什么是难点？
预测需求和趋势。零售业中最大的挑战之一是适当地引导趋势和衡量需求水平。特别是在服装行业，设计师和买家通常在商品上货架两年前确定未来时尚趋势。当前的预测模型是有限的，在自动化，解释需求驱动程序和历史数据的限制等领域不足。
存货管理。库存管理仍然是一个问题，因为各个系统的复杂程度和协调水平在价值链中的成员之间往往是不同的。效果是昂贵的，因为库存过剩和缺货可能对零售销售产生显著影响。 截至2015年春季的一年里，超过630亿美元的零售销售损失归因于缺货，超过470亿美元是由于库存过剩（销售发生在零售商亏损的价格点），根据IHL集团的一项研究。
门店数量和规模。无论是总量或人均的零售面积，仍然是零售商的摩擦点。2015年，美国的零售面积达到76亿平方英尺，人均23.5平方英尺，2005年分别为67亿平方英尺和22.8平方米（）。随着电子商务继续渗透传统类别，如电子和服装，新的类别如CPG为更大的股份转移提供了机会，进一步加剧了剩余零售空间的影响。
：美国人均零售空间
目前的经营方式是什么？
当前的经营方式的特点是一个广泛的价值链，可以分为4个部分：生产，仓储，分销和零售。虽然这四个步骤提供了一般意义上的一个过程，但是在这每一个桶内，通常可以找到附加的步骤或中间体。其结果是，从制造到销售的系统合并，可能导致库存过剩，缺货和资源分配效率低下，特别是在旺季。也就是说，物流和库存管理过程在近几十年来有了显着改善，因为已经采用了更多的技术和系统，比如即时制造系统。像UPS这样的第三方物流供应商也采用了高级分析来优化路线和包裹管理——这是我们在未来看到AI潜力的另一个领域。然而，目前的经营方式仍然存在挑战，特别是在时尚，服装和鞋类等类别中，预测消费者将需要什么，什么价格仍然有难度。
人工智能/机器学习将如何助力？
推荐引擎。人工智能/机器学习有潜力通过利用销售，客户和内容方面的巨大数据集来深化推荐引擎功能。早期电子商务的第一个机会是推荐引擎，尽管大多数功能主要基于产品属性，但对客户的偏好知之甚少。诸如协作过滤的技术通过利用客户偏好和品味中的已知相似性来提供对未知偏好的预测。
然而，诸如数据稀疏性或新的用户/项目“冷启动”问题的限制和可扩展性仍然是当用户快速增长并且计算资源的消耗水平变得不切实际时的问题。像Zalando和StitchFix这样的公司已经开始通过机器学习将销售和内容数据与消费者偏好相结合，因为Zalando认为客户关系将最终推动销售。
客户支持。自然语言处理（NLP）和图像识别也给零售业提供了机会，以改善客户支持度并扩展传统搜索的参数。最近的收购，如Etsy收购黑鸟技术公司，使用人工智能的图像识别和NLP提供更大的搜索性能的公司，表明电子商务公司正在寻求方法提高结果的相关性，并更好地利用他们的平台。
NLP还为企业提供了提供对话用户体验和商业的机会。最近的Alphabet收购API.ai，公司如Angel.ai正在创建人工智能系统，围绕自然语言处理，通过语音和消息传递来获取客户支持。简而言之，NLP和图像识别技术通过模拟人类的理解和利用历史上无法获得的产品属性（例如，视觉）来提供更相关的结果和服务。
需求预测和价格优化。机器学习和人工智能技术有潜力整合客户接触点的数据和内容，从而更准确地预测新项目和需求。在可以快速进入和退出的服装等类别的行业中预测需求已经成为零售行业长期存在的挑战，特别是考虑到某些类别的设计和生产。通过利用人工智能/机器学习，零售商可以识别模式，更好地了解促销和价格弹性在本地的影响，并将学习纳入营销和生产过程。
像亚马逊这样的公司已经朝这个方向迈出了一步，在2013年末收到了“预期包裹运输”专利。虽然原始文件没有提到机器学习，但显然这种类型的系统最终可以通过深度学习实现考虑季节性需求，天气，人口统计的独特的用户购物模式。
：人工智能/机器学习用传统方法预测头对头
关键优势：单算法，利用多项目历史，跨过程优化
dunnhumby: 跨越定价、促销和忠诚度整合人工智能/机器学习
dunnhumby是全资英国子公司，乐购跨国的杂货店，通过和品牌和零售商打交道优化零售经验。该公司拥有超过2000人，专注于全球范围内的数据分析，以提供库存管理，价格优化，促销和个性化的意见。
从历史上看，预测销售是一个相当静态的分析，根据历史数据和反动的调整进行。今天，dunnhumby将人工智能/机器学习与整个价值链整合，精度不仅在销售预测，也在库存管理和价格优化。最终，更好地预测零售业价值链的多米诺效应与分层人工智能/机器学习增量驱动效率在库存和定价可能降低成本，帮助零售商如Tesco提高销量。
l 销售预测。销售预测历来是非常规则驱动，dunnhumby创造的机器学习方法引入到预测过程会有更加准确的通知模型。
l 360度客户视图。优质客户数据是最重要的发展客户的360度视图。现在图像占所有新数据的80%左右，因此从图像中提取有用数据的能力是商品化的关键。通过建立一个360度视图，零售商正在寻找更有效的渠道来确定目标客户。
l 花费和保存优化。对于许多零售商来说，一个关键的促销工具是“花钱和节省”的报价。零售商通过调整折扣和消费门槛已经看到显著的性能改进。应用机器学习技术，优化这些开销和节省阈值，再加上准确的客户定位可以提高整个促销方案的质量。
收购团队和技术一直是零售业发展人工智能/机器学习技术的关键。具体而言，在2013KSS和2010标准分析的零售并购中，随着合资和2014 年沙盘中50%的股权，已经交付数据科学、人工智能的人才和解决方案，集成在dunnhumby的产出之中。
解释性仍然是一个机器学习解决方案模型的摩擦点，因为随着数据层合并模型会变得越来越不透明。结果，经常有关键的决策者和可解释性的模型成功率之间的权衡。如果一个相对合理的成功率可以通过一个简单的模型得到改进，分析师倾向于提供简单的解决方案给客户，如果给定了一个潜在的更复杂的人工智能/ 机器学习解决方案。
：客户数据科学核心到方法
：PriceStrat帮助模型和执行定价
量化机会
降低劳动力成本来提高需求预测。在美国的企业目前每年花费近60亿美元的劳动力成本分析过去的购买趋势，销售记录，价格以及商品质量的测定与产量。根据劳动统计局的规定，基于合同协议选择、订购和授权支付。另一方面，批发和零售买家的任务是利用历史数据，专业经验，专业知识，以确定哪些购物者在未来两年有兴趣。而电子商务的不断渗透，增加了此任务的可用的数据量，将这些数据转化为应用的挑战仍然存在，提高的不仅仅是广告定位也是预测趋势和倾向。我们相信，这种类型的考虑非常适合人工智能/机器学习的能力，去结合定量的可视化数据预测需求和优化购买决策。估计人工智能/机器学习在2025年前全球范围内可以较少每年零售业劳动力成本54亿。
：与批发和零售买家相关的劳动力成本
优化定价。HBS和Rue La La的联合研究优化每日定价，估计平均收入增长大约为9.7％，由机器学习过程的集成相关的90％置信区间为[2.3％，17.8％]。鉴于闪存销售模式和销售量的一些细微差别，我们将潜在的改进从平均值减少了200个基点到7.7％，并假设通过结合人工智能/机器学习基于预测需求优化定价的可变问题，可以有2.3％-7.7％的改进。在零售业，特别是服装和鞋类中，动态定价的挑战之一是缺乏新风格，颜色等历史数据来预测需求。应用机器学习，能够同时分析数百个产品和属性，最终运用比传统预测更广泛的数据集合更好地评估和优先观察。因此，我们看到人工智能/机器学习驱动的价格优化机会，到2025年全球服装和鞋类电子商务平均的年销售额增长将达到410亿美元。
：人工智能/机器学习 价格优化可以产生显著提升服装电子商务
谁会占下风？
随着在零售价值链中的人工智能/机器学习的整合带来一系列成就，对公司和员工而言，整个库存管理，生产和目标的效率显著提高。我们认为过度制造的零售商可能会占下风，因为人工智能/机器学习驱动的价值链的效率提高可以帮助资产缺乏的零售商进一步完善他们的需求预测和库存管理，领先于其强大的竞争对手。
我们也看到更严格的库存管理让不以价格为目标的零售商占了下风，他们从过度购买或过度生产的大型零售商和品牌那里得到好处。有了更准确的生产和需求预测，为降价的零售商提供了从生产超支和取消订单中受益的机会，并预测失误的几率可以显著降低。回顾，2015年春季销售中超过4700亿美元因存货积压而损失（IHL）。
：平方英尺增长与销售/平均平方英尺增长
：最近的商店关闭/公告选择零售商
能源
在2025年前累计节约1400亿美元
石油和天然气工业是非常资本密集型的，并且操作通常在极端条件下进行。设备可靠性极为重要，因为设备和过程的故障会极大地影响项目的经济性。为了避免故障，工业通常对设备进行过度工程设计，并采用多层冗余，从而提高了每个工作或项目所需的资本。在人工智能/机器学习设计更可靠设备的范围内，可以降低工业的资本支出和运营支出要求。效益可以相当大，我们估计石油和天然气行业的资本支出，运营支出和库存管理能减少1％，可以在10年内节省大约1400亿美元。在能源行业，我们认为一家公司特别适合采用A人工智能/机器学习，不仅降低自身的运营成本，而且还帮助客户降低成本——它就是斯伦贝谢（SLB）。
什么是机会？
我们相信人工智能/机器学习可以帮助石油和天然气产业的整个价值链。
项目规划。 世界各地的大型能源项目可能花费数百亿美元，可能有3到5年的交付周期。 管理层基于一系列宏观假设批准这些项目，涉及石油价格以及他们的主要产品、服务的需求和供应。 人工智能/机器学习的应用可以更好地告知管理层项目的可行性，公司可以做出更好的决策，减少所进行的不经济的项目的数量。此外，人工智能/机器学习应用可以帮助（1）更准确地确定项目成本，通过整合行业/公司在这些项目中的过去经验，以及（2）使项目成本与计划保持一致，更好地执行公司的项目。
提高设备可靠性。计划外设备停机和非生产性损失时间是项目成本增加爱的一些最大驱动因素。石油服务行业高度关注提高设备可靠性，人工智能/机器学习可以在这方面提供帮助。 该行业尤其针对海底防喷器（Blow Out Preventers），这些通常是钻机上最易发生故障的物品，每个故障都可能使深水行业的成本至少增加1000万到1500万美元（见下面的案例研究）。类似地，压力泵泵发生故障，为了最大限度地减少损失时间，服务公司带来的泵浦数量是技术上需要的泵数量的两倍。提高设备可靠性不仅会降低设备维护成本，还会降低服务公司为每个工作部署的资本。
改进了油气资源的识别，定位和开发。发现石油和天然气储量及其开采产生大量数据。 当行业进行地质地震分析以确定油气储量的位置时生成数据。类似地，钻井和测试井时产生数据。最后，当场被开发和生产时，生成大量的生产数据。将地质数据、生产相关数据和硬件安装相关数据相结合可以产生用于最佳利用储量的信息，一个项目的经验可以应用于更经济的未来项目设计。
增加下游行业的正常运行时间。计划和计划外停机会显著地影响下游行业的盈利能力。在天然气管道中，压缩机的正常运行时间对于维持良好的流动是非常重要的，同时管道的最佳“检查”可以减少意外停机的时间和泄漏。类似地，炼油和石油化工行业的计划内和计划外停机有很高的机会成本。即使使用率提高1％，也可以节省一大部分成本。
什么是难点？
能源工业在各个层面高度分散。在美国，页岩资源的开采涉及近400个行业，许多其他上游公司都在世界不同地区开展工作。在石油服务行业中，三大公司（斯伦贝谢，哈里伯顿和贝克休斯）主导着大多数技术驱动型企业，但是在钻井平台和压力泵送等更为商品化的服务领域有很多参与者。中游的炼油和石油化工业务也是分散的。
碎片化带来了挑战，因为关键数据掌握在许多玩家的手中。因此，一家公司可能无法访问地质游戏、某种类型的设备或过程的所有数据。此外，一些有权访问关键数据的公司可能不愿意共享它，即使他们自己可能没有财力或技术知识来利用它。
获取访问数据。此外，该行业的数据跨越了地理的界限，因为石油和天然气储备分布在世界各地，而且往往数据掌握在国家石油公司（NOC）的手中，这意味着数据的获取可能受到监管的限制。此外，数据跨越各种时间段，因为最早的井是在1880年钻探的。
最后，当在整个价值链中数据分析可能是最有用的。但一般来说，能源公司主要涉及业务的一个方面，可能无法访问价值链中的所有项目，这将优化分析。
数据的可用性。另一个痛点是关键数据的可用性，因为在过去，工业可能没有将传感器放置在烃链的关键部分，这将有助于人工智能/机器学习的应用。举个例子，虽然工业可能具有BOP崩溃的频率以及在其操作寿命期间遇到压力的关键数据，但是其可能没有关于BOP内的各种线圈和电子部件上的温度，电流和电压读数的数据。该行业现在开始将这样的传感器放在新产品上，而公司将需要一段时间才能获得更多的数据。
目前的经营方式是什么？
该行业仍在使用传统方法开采石油和天然气，并且使用改进的但不是真正革命性的方法和技术。影响行业的关键问题是，该行业正在各种各样的孤岛中前行，并且业务的各个部分之间的整合和凝聚力有限。例如，石油和天然气储备（E＆Ps）的所有者设计整个项目，然后在不同的服务提供商之间划分工作。E＆Ps有最多的信息，但他们不太了解什么服务公司可以提供服务，并且往往他们与服务公司保持距离，觉得过度依赖他们可能会导致未来的成本增加以及IP的泄漏。为了让能源行业真正从人工智能/机器学习中获益，数据将需要在E＆Ps和服务部门之间实现更广泛的共享，需要一个更协作的模式。在海上空间，由于国际石油公司已经在努力降低成本，一些IOC（国际石油公司）在与一体化综合服务公司如斯伦贝谢（SLB）和FMC技术（FTI，NR）的合作方面发挥了领导作用。
人工智能/机器学习如何助力？
人工智能/机器学习从以下方式：
l 从历史信息中获取知识提高产品的可靠性。人工智能/机器学习也可以减少产品开发，田间试验和商业化的时间。
l 更好地定位石油和天然气储量，通过削减时间和成本开凿，使得油田开发成本降低。
l 降低生产成本，通过改善设备正常运行时间和降低维修费用。
l 提高海洋和陆地钻机正常运行时间，提高了钻进效率，减少了钻井天数。
l 基于数据分析的人工智能/机器学习可以降低维修相关的下游行业的停机时间。
量化机会
在2016，我们预计高盛覆盖石油和天然气公司的固定资产投入近4000亿美元。此外，石油和天然气行业应该花了775美元亿美元的运营成本（不含炼化销售成本和DD&A），持有存货约2000亿美元。
我们估计人工智能/机器学习应用可以降低1%的资本支出和运营成本，行业通过更好的库存管理降低1%的库存，10年整个行业可以生下来的钱将达到1400亿美元。我们提出以下几个案例研究，指出成本可以减少的地方。
：高盛涵盖能源公司每年的资本支出+运营成本+存货达1.4万亿美元
：我们看到10年里通过削减1%的资本支出、运营成本和库存节省了1400亿美元
降低压力泵队成本。该行业的压力抽运车队经历了极大的设备磨损，设备维护通常约是成本的10％-15％。在过去5年中，压力泵平均已经有300亿美元的年度收入的业务，该行业每年花费近36亿美元来维持压力泵设备，这个数字不包括设备升级等主要资本成本。
斯伦贝谢是美国第二大压力泵，最近开始了一项计划，集中管理其水力压裂船队的部署和运输。该公司现场在它的压力泵浦泵上安装了先进的传感器，这些数据收集于其总部设在休斯顿的远程监控中心。采用高级数据分析，斯伦贝谢能够预测主要组件故障的发生。这使得它在泵失效之前将其从操作中移除。这大大降低了维护成本，也提供了现场需要的备用设备。 斯伦贝谢估计，这一项应用在六个月内节省了其中一台PP（压力泵）车队约400万美元。
：每PP舰队平均资本部署可减少25%
：工业可以减少35亿美元的PP舰队的总资本部署
通过“未来钻机”改善钻井时间。 当深水井正在钻探时，石油和天然气工业每天花费70万至100万美元，而水平页岩井的每日钻井成本可能约为6万美元。因此，该行业可以从其钻井计划中每天节省一笔可观数目的成本。
钻井时间可以通过三种方式减少：
l 提高设备的正常运行时间，特别是在问题项目如国际收支（尤其是海底）和顶驱。
l 根据井的实际情况选择合适的井底钻具组合。
l 优化钻井性能，通过建立一个在地面设备和底部钻具组合之间的“闭环信息系统”。自动化系统和减少“船员素质”产生可重复的良好性能。
行业正在积极减少国际收支（吹阀）和顶部驱动的停机时间，通过筛选数据，寻找领先的信号，预测即将到来的问题。
同样，先前钻井的数据分析可以帮助石油公司为特定井设计最佳钻井液和钻头。此外，通过在钻头附近的传感器与钻机面板上的控制之间建立闭环系统，可以设计“智能钻机”，其自动调节“钻压”和施加在钻机上的扭矩，根据井下条件最有效地钻井。人工智能/机器学习可以帮助持续改进可重复的性能。
钻井的关键问题之一是“人为干预”的影响，业内人士发现，即使在类似的井，钻井性能的显著变化取决于船员的质量。自动化可以减少“人为干预”对钻井性能的影响。
National Oilwell Varco（NOV），斯伦贝谢和Nabors工业正在研究新一代钻井概念。下面的展示显示，National Oilwell Varco的自动化系统可以将井底的钻井时间平均减少30％。更重要的是，NOV的自动化系统将钻井时间缩短到2.5至3.0天，而传统钻井方法则为2.5至5.5天。
斯伦贝谢是构建“平台的未来”，并希望它的第一个原型在今年年底之前出来。
：通过机器学习“闭环钻井自动化”提高可重复钻井性能
NOV报道了自动化钻井系统高水平的可重复的改进
提高炼油厂的正常运行时间。美国炼油工业的安装基数约为1800万桶/日，平均利用率约为90％，占该行业计划和计划外维护的时间的10%。平均而言，炼油利润率约为10美元，意味着该行业每桶生产线下的价格为10美元。我们估计，如果通过更好的数据分析，行业可以将维护相关停机时间从10％减少到9％，精炼商将实现每年6.57亿美元的额外利润，在十年内约为66亿美元。
：炼油厂维修相关的停机时间从10%减少到9%，可以在10年内节省美国炼油厂66亿美元
美国炼油厂的平均利润率因为平均10%的停机时间放弃每年66亿美元
谁会占下风？
小型或不太复杂的能源公司或者有资本约束和有限的技术诀窍的公司将受到最不利的影响，因为更好的公司采用人工智能/机器学习来降低成本。这对石油及石油服务业同样如此。关键的赢家是那些在过去投资于从他们的资产中获取数据的人，并且有远见去储存它。这些公司，不仅有财务能力，采用人工智能/机器学习技术来处理数据，也有文化层面的技术使用和创新来分析技术。
石油和天然气行业可能会因为那些关键数据库与技术实力而进一步巩固。
2016年11月1日，通用电气石油天然气和贝克休斯宣布了一项“创造新的全流数字产业服务的公司”协议。通用电气的首席执行官Jeff Immelt说：“本次交易加快了我们拓展数字框架的石油和天然气行业的能力。油田服务平台把以数字为基础的产品提供给我们的客户是必不可少的。我们期望Predix成为一个行业标准以及提高客户结果。”
在我们看来，运用人工智能/机器学习的一个大赢家是SLB，我们相信它有最大宽度的数据，继今年早些时候收购CAM。而数据访问是一个关键区别，斯伦贝谢因为具有利用信息技术与文化被进一步区分开。本公司已成立两个小组来做大数据和机器学习分析，一个在帕洛阿尔托，一个在剑桥。本公司一直从事一项数字化油田开发，今后将会非常有用。
斯伦贝谢的成功和可能的市场份额可能会导致小型服务业的缩水。美国石油服务业有许多小企业，并有可能在与斯伦贝谢的直接竞争中打乱小企业的顺序。我们看到许多小型压力泵有长期的压力，虽然可能会有一些短期的周期性隆升。此外，美国的土地钻探情况在未来会发生变化，正如斯伦贝谢所说的“钻机的未来”那样。
推动者
人工智能创新：谷歌、亚马逊
谷歌的Alphabet在做什么？
在过去的二十年里，谷歌搜索算法一直在迅速发展。从1998年的PageRank到2015年的rankbrain，公司已经从基于使用人工智能驱动的查询匹配系统，不断适应谷歌所特有的15%的搜索。在云计算中，2015年公司的开源机器学习软件库TensorFlow已补充了公司5月发布的可能涉及的平台定制的硬件加速器的进展公告；定制的ASIC称为张量处理单元（TPU）。该公司在过去三年中也一直积极致力于人工智能相关的收购。最引人注目的是DeepMind，它不仅提高了Alphabet的神经网络功能，也参与了各种人工智能驱动的项目。
为什么重要？
谷歌是在搜索中使用算法的先驱。本公司在应用自然语言处理方面继续领先，以配合人们的对所需的在线目的地的搜索意图，在这部分业务不断增加竞争优势。该公司的开源应用与TensorFlow一起为云基础的平台创造先例，并允许研究社区更好地利用公司的资源深化人工智能来促进智能一体化事业。
与此同时，谷歌正在通过运用其专有的优势如张量处理单元的开源世界，提供竞争优势，即使其机器学习库是开源的。公司用DeepMind增强了端到端的加固效果；强调通过alphago的计算机程序在2015年底击败了职业棋手。谷歌是一个主要的例子，让人工智能进入更广泛的研究领域，同时也通过软件和硬件的专有优势创新。
亚马逊在人工智能方面在做什么？
亚马逊在内部和云中使用人工智能。在2015年4月，公司宣布亚马逊ML，机器学习服务，提供了对云数据的使用，而无需以前的客户体验。紧跟谷歌的开源活动，亚马逊在今年五月通过开源DSSTNE，开发基于深度学习模型的数据库。在内部，公司使用机器学习来提高搜索从而提高端到端的客户体验，定制产品建议，语音识别，并提高产品质量。
为什么重要？
亚马逊是全球最大的AWS云服务提供商，也可以说是云上最复杂的人工智能平台。通过亚马逊的机器学习，亚马逊是人工智能服务生态系统的先驱，让以前没有机器学习经验的公司拥有复杂的推理能力。无需定制复杂的应用需求，AWS的客户可以在模型训练、潜力评价和优化上利用机器学习的数据。
亚马逊在推荐引擎上的机器学习内部使用创造了竞争优势，在匹配客户的意图和愿望，为公司创造商业机会占了上风。它更有效地利用收集到的数据，简化客户购买，让电子商务体验有了更多的互动。随着开源DSSTNE，亚马逊已经加入了其他科技巨头的行列，来加强人工智能的技术进展。
人工智能创新：AAPL, MSFT
苹果的AAPL在人工智能方面做什么呢？
苹果在过去一年左右的时间里是最活跃的一个人工智能收购方，涉及的公司有Vocal 的IQ，Perceptio，Emotient，Turi，和tuplejump。几乎同时发生的IQ和Perceptio的收购，公司聘请了Johnathan Cohen，他当时负责NVIDIA的CUDA 的软件库和GPU加速的软件开发。最近，据报道公司聘请Ruslan Salakhutdinov作为人工智能领域的负责人，可能标志着苹果的人工智能策略的转变。在此之前，苹果基于人工智能的首要成果是Siri，它是第一个运用嵌入式移动技术的虚拟助理，语音识别技术在2014年引进了神经网络系统。
为什么重要？
在过去一年左右的时间里，苹果一直相对专注于机器学习的进步；彭博商业周刊十月报道，2015年苹果研究人员没有发表任何人工智能相关的论文。然而，这种策略随着一些新的人工智能相关的招聘和收购开始转变。根据美国科技记者Steven Levy的反馈，强调公司这段时间一直活跃于人工智能。
特别是，苹果收购Turi凸显了公司推动对非结构化数据和推理的规模建设以及开放更广泛的人工智能研究社区。此次收购辅以较小的基于收购的应用反映了苹果的承诺，用新技术创新其产品。
微软的MSFT在人工智能方面做什么呢？
据首席执行官萨提亚•纳德拉，微软是“民主化的人工智能。”公司的人工智能研究集团，拥有员工5000多名，主要集中在改变人类与技术互动上。微软在嵌入新的人工智能综合能力为核心的服务方面非常活跃，在会话计算进展（如Cortana）和自然语言处理（编）中取得进展。公司还建立了云（Azure）的GPU和FPGA，提供机器学习的力量和速度等更高级别的人工智能服务，如语音连接、图像识别、自然语言处理。
为什么重要？
两个词：“民主化的人工智能。”微软创造了这个词，解释了许多领导人工智能的创新者，整个行业的公司都开放研究计划甚至数据库来打造更大的人工智能社区。微软在过去的一年中一直活跃在人工智能领域，正式宣布产品发布和研究计划，在2016年9月下旬宣布成立一个新的人工智能和研究小组。
微软FPGA的业绩凸显了人工智能可以给一般企业或个人带来的影响；它可以在不到十分之一秒内把整个维基百科（30亿字和500万篇文章）翻译出来。和个人助理如Cortana，Siri，Alexa或其它之间的竞争，将人工智能进一步发展为广泛应用的产品开发，来吸引客户。
人工智能创新：FB, CRM
脸谱网的FB在人工智能方面做什么呢？
在脸谱网人工智能研究（FAIR，2013）中，脸谱网的战略专注于开发技术的背景下更广泛的研究社区。集团尤其推动监督代表性学习的进展，即以对抗网络通过观察世界而不是人类干预学习算法。应用机器学习（AML）侧重于研究FB的产品，时间表是季度或月而不是几年，根据集团掌门人Joaquin Candela所说。该公司是利用机器学习能力来垂直发展各种产品，包括面部识别、机器翻译、高语境语言/文本学习。
为什么重要？
脸谱网发布了多个出版物出版的的无监督学习研究，一个重要的领域是机器学习超越了学习“正确的答案”，专注于独立模式的识别。
非监督学习已经有潜力去除更多大数据相关的人体部件，脸谱网在Yann LeCun的领导下在这方面成为领先。
5月引入的FBLearner Flow，简化了端到端的UI研究工作、实验、观察和比较输出。这样，公司的人工智能举措和应用不限于AML员工而被广泛使用在脸谱网的各门学科。这使得脸谱网能够在其研究领域以外运用人工智能的进展。
Salesforce的CRM在人工智能方面做什么呢？
在2014和2015年，Salesforce开始解释他们的Apex开发平台如何用于Salesforce1云机器学习的任务执行。自那时以来，该公司已集中更多的资源收购多个人工智能相关的公司，包括MinHash，predictionio和超念者。九月，Salesforce引入爱因斯坦，一个基于云的人工智能的平台。这一举措使得人工智能与销售云，营销云，服务云，社区云，物联网云，和应用程序云相结合。
为什么重要？
Salesforce的爱因斯坦提高企业使用数据的潜力。在销售云，该公司希望通过预测领先得分，机会洞察和自动捕捉，使组织能够优化销售。
营销和服务云将提供预测分析客户，提供预测的观众，以帮助确定有针对性的营销技术，并通过以趋势和用户历史为基础的自动化案例分类更快地提供客户服务。Salesforce把机器学习与云细致入微地结合使用，显示出该技术应用在核心竞争力的潜力。
人工智能创新：NVDA, INTC
英伟达的NVDA在人工智能方面做什么呢？
NVIDIA公司已经从一个基本的视频游戏的GPU生产者向机器学习应用强大的硬件生产者转化。该公司2015年底表示，GPU加速的神经网络训练比传统的CPU快10-20倍。而英特尔已经偏向FPGA投资作为GPU的替代，GPU机器学习应用允许更多计算密集型的训练。这与FPGAs提供更快，更少的计算密集型的推理和任务执行不同。截至2016年6月，NVIDIA过去五年里的GPU市场份额已从全球的一半多到近四分之三。
为什么重要？
GPU加速的深度学习的很多项目在人工智能创新公司和学术机构是出于前沿的。NVIDIA的大量存在意味着它可以随着人工智能成为近年来大企业更重要的话题获利。
NVIDIA产品使用的一个例子是俄罗斯的ntechlab，使用GPU加速的深层学习框架来识别个体的火车面部识别模型，并利用这些GPU在AWS进行推理。另外，多个高校使用NVIDIA Tesla加速器模拟抗体可能的突变，演化埃博拉病毒，进一步规划预防流感。
英特尔的INTC在人工智能方面做什么呢？
英特尔的战略独特性在于在其用例的多样性。在2016年中期，公司推出了第二代Xeon Phi产品家族，最著名的是高性能计算（HPC），它允许人工智能在较大的网络服务器和云上的拓展。除了FPGA的大量投资的硬件进步，在很大程度上是由于其推理的速度和灵活的可编程性。英特尔收购人工智能的著名例子包括Nervana系统（深度学习）和Altera公司，这给公司带来了FPGA创新。
为什么重要？
英特尔的重点是FPGA以及NVIDIA的GPU重心。FPGA提供更快的推理速度来处理大型数据集，这是公司如微软测试大数据分析的边界使用时需要的。
在物联网（IoT）的背景下，该公司还宣布了一个主动学习技术与可穿戴芯片的集成，特别是通过至强夸克。物联网和人工智能的结合有助于将机器学习解决方案带入数据收集机制供企业和个人日常使用。
人工智能创新：Uber, IBM
优步在人工智能方面做什么呢？
Uber使用机器学习来优化UberX ETA和街接头位置的精度。这通过使用来自先前骑乘的数百万个数据点来检测正常交通模式并允许相应地进行ETA /接头点调整来完成。2016年9月，Uber在卡内基梅隆大学（Uber聘用）的研究，与大型汽车制造商合作推出了在宾夕法尼亚州匹兹堡的自驾驾驶试点项目。 这样的一个协议是与沃尔沃3亿美元的合作，其中研究和开发协调为试点计划提供了机会。然而，公司还没有止步在汽车上。尤伯杯收购奥托，自主卡车的启动，使得科罗拉多在十月完成50000瓶啤酒的交付。
为什么重要？
Uber机器学习巨头Danny Lange在接受GeekWire采访时说，他的团队正在使这项技术无缝地提供给公司中的其他团队，那些没有机器学习背景的公司来使用API。 这使得公司的不同部分以简化的方式利用机器学习基础设施，Uber在UberX，UberPool，UberEats和自主车辆中的人工智能使用就是例证。
IBM在人工智能方面做什么呢？
IBM研究机构在全球有大约3000名研究人员，过去十年拥有超过1400项认知计算的专利，1200项下代云专利，7200项硅纳米科学专利。IBM Watson利用自然语言处理，机器学习技术来识别模式，提供对非结构化数据的理解，代表了80%的数据。其他Watson产品包括虚拟代理，自动化客户服务体验与响应分析，以及资源管理器——一个分析和连接大量的不同的数据集的工具。
为什么重要？
IBM一直是该领域的先驱，包括20世纪90年代的DeepBlue或2011年的Watson。在Watson的应用包括医疗保健中的患者治疗分析，基于推特的股票推荐，零售的消费者行为分析和打击网络安全威胁。 根据Fortune（发表于2016年10月26日），通用将Watson加入机动车，将Watson功能与OnStar系统相结合。
人工智能创新：BIDU
百度的BIDU在人工智能方面做什么呢？
在百度的人工智能研究是由2016年9月引进的百度大脑所促进的。它由三个元素组成：1）人工神经网络算法，基于超过数百亿的样本的大量的参数训练。2）成百上千服务器上的计算能力的服务器和的集群GPU（图形处理单元）操作的高性能计算（HPC）；HPC实现了更大规模的可扩展的深度学习算法。百度是宣布这一架构的第一个组织，与加州大学洛杉矶分校一同合作。3）标记的数据，其中百度收集了数以万亿计的网页，包括百亿的视频/音频/图像内容块，几十亿的搜索查询还有数百亿的定位查询。为一个特定的模型训练要求非常高，包括计算功率和4T的数据。
为什么重要？
人工智能横跨百度的产品线提高用户体验和用户粘性，并为每个用户推动高品质的内容定制。
构建运行深度学习实验标记数据的内部平台，不同的网络搜索和广告，通过CTR预测实现更高的点击率，这对广告有直接影响，因此影响百度现在的收入。此外，基于人工智能的技术导致了更高的点击率和每点击成本（CPC）的改进，从而在货币化上得到改进。