机器学习常见问题
1) 几种模型（ SVM，LR，GBDT，EM ）的原理以及公式推导；
2) RF,GBDT 的区别； GBDT,XgBoost的区别（烂大街的问题最好从底层原理去分析回答）；
3) 决策树处理连续值的方法；
4) 特征选择的方法；
5) 过拟合的解决方法；
6) K-means 的原理，优缺点以及改进；
7) 常见分类模型（ SVM ，决策树，贝叶斯等）的优缺点，适用场景以及如何选型；
8) SVM 为啥要引入拉格朗日的优化方法；
9) 假设面试官什么都不懂，详细解释 CNN 的原理；
10) 梯度下降的优缺点
11) EM与K-means的关系；
12) L1与L2的作用，区别以及如何解决L1求导困难；
13) 如何用尽可能少的样本训练模型同时又保证模型的性能；
14) ID3和C4.5的优缺点，树的融合(RF和GBDT)
15) 特征提取方法，如何判断特征是否重要
16) BP神经网络以及推导
17) HMM模型状态推导
18) 过拟合原因以及解决办法(深度学习同)
19) 常见损失函数
20）机器学习性能评价，准确率，召回率,ROC
22）降采样，PCA，LDA
深度学习常见问题
1）四种激活函数区别和作用
2）过拟合解决方法
3）(CNN)卷及神经网络各层作用
4）(RNN)循环神经网络
5）LSTM
6）梯度弥散
7）优化算法 adam，SGD等
8）分析Alexnet,VGG的网络结构以及各层作用
9）XgBoost(好像很多公司也面到了)
10)梯度下降的优化
12）卷积核参数计算
算法工程师面试必备
1. 成为算法工程师，应该学习哪些东西
首先说算法工程师有几个方向：NLP，推荐，CV，深度学习，然后结合公司业务做得内容各不相同
传统机器学习算法：感知机，SVM，LR，softmax，Kmeans，DBSCAN，决策树（CART，ID3，C45），GBDT，RF，Adaboost，xgboost，EM，BP神经网络，朴素贝叶斯，LDA，PCA，核函数，最大熵等
深度学习：CNN，RNN，LSTM，常用激活函数，Adam等优化算法，梯度消失（爆炸）等
推荐系统：itemBasedCF，userBasedCF，冷启动，SVD（各种变形），FM，LFM等
NLP：TF-IDF，textrank，word2vec(能推导，看过源码)，LCA，simhash
常见概念：最大似然估计，最小二乘法，模型融合方法，L1L2正则（Lasso，elestic net），判别式模型与生成式模型，熵-交叉熵-KL散度，数据归一化，最优化方法（梯度下降，牛顿法，共轭梯度法），无偏估计，F1（ROC，recall，precision等），交叉验证，bias-variance-tradeoff，皮尔逊系数，
概率论，高数，线性代数（像我一样懒的人，就可以遇到哪里复习哪里，:D）
常见问题（具体答案去搜知乎或者百度，最好能在实际项目中总结出来）：
常见损失函数
SGD与BGD
如何处理样本非均衡问题
过拟合原因，以及解决办法
如何处理数据缺失问题
如何选择特征
L1为什么能让参数稀疏，L2为什么会让参数趋于较小值，L1优化方法
各模型的优缺点，以及适用场景
学明白上述所有内容你需要多长时间？反正我这么笨的人用了不到一年时间（我本科完全没接触过算法相关，完全是研一学的）
2. 推荐书籍
C++：《C++primer5》《STL源码分析》《深度探索C++对象模型》《Effective C++》《Effective STL》 （虽然有些书有点老，不过开卷有益吧）（其他语言就不管了哈）
python：《python学习手册》《python源码分析》《改善python程序的91个建议》（Python必须要会）
刷题：《编程之美》《剑指offer》《程序员代码面试指南》《leetcode》
算法相关：《统计学习方法》（这本多看）《数据挖掘导论》《数学之美》《田林轩视频》《吴恩达视频》《西瓜书》
参考文献：机器学习面试总结（具体的问题我很早之前在简书上写过）