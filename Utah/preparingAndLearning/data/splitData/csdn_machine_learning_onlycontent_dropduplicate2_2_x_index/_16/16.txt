1.1机器学习（Machine Learning, ML)
机器学习时间轴
自从科学、技术与人工智能拥有了最初的观点，科学家们跟随着Blaise Pascal和Von Leibniz的脚步，思考是否有一种机器，拥有与人类相同的智能。著名作者如Jules Verne，Frank Baum(绿野仙踪)，Marry Shelly(弗兰肯斯坦)，George Lucas(星球大战)幻想着人造人有着与人类相似甚至更强的能力，在不同情况下拥有着人性化的能力。
1.1.1机器学习的定义
概念：机器学习是英文名称Machine Learning(简称ML)的直译。机器学习涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。
学科定位：人工智能(Artificial Intelligence, AI）的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。
定义：探究和开发一系列算法来如何使计算机不需要通过外部明显的指示，而可以自己通过数据来学习，建模，并且利用建好的模型和新的输入来进行预测的学科。
Arthur Samuel (1959): 一门不需要通过外部程序指示而让计算机有能力自我学习的学科。
Langley（1996)：机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。
Tom Michell(1997):机器学习是对能通过经验自动改进的计算机算法的研究。
经验学习：针对经验E (experience) 和一系列的任务 T (tasks) 和一定表现的衡量 P，如果随之经验E的积累，针对定义好的任务T可以提高表现P，就说计算机具有学习能力
1.1.2机器学习的发展历史
机器学习是人工智能研究较为年轻的分支，它的发展过程大体上可分为4个时期。
第一阶段是在20世纪50年代中叶到60年代中叶，属于热烈时期。
第二阶段是在20世纪60年代中叶至70年代中叶，被称为机器学习的冷静时期。
第三阶段是从20世纪70年代中叶至80年代中叶，称为复兴时期。
机器学习的最新阶段始于1986年。机器学习进入新阶段的重要表现在下列诸方面：
(1) 机器学习已成为新的边缘学科并在高校形成一门课程。它综合应用心理学、生物学和神经生理学以及数学、自动化和计算机科学形成机器学习理论基础。
(2) 结合各种学习方法，取长补短的多种形式的集成学习系统研究正在兴起。特别是连接学习符号学习的耦合可以更好地解决连续性信号处理中知识与技能的获取与求精问题而受到重视。
(3) 机器学习与人工智能各种基础问题的统一性观点正在形成。例如学习与问题求解结合进行、知识表达便于学习的观点产生了通用智能系统SOAR的组块学习。类比学习与问题求解结合的基于案例方法已成为经验学习的重要方向。
(4) 各种学习方法的应用范围不断扩大，一部分已形成商品。归纳学习的知识获取工具已在诊断分类型专家系统中广泛使用。连接学习在声图文识别中占优势。分析学习已用于设计综合型专家系统。遗传算法与强化学习在工程控制中有较好的应用前景。与符号系统耦合的神经网络连接学习将在企业的智能管理与智能机器人运动规划中发挥作用。
(5) 与机器学习有关的学术活动空前活跃。国际上除每年一次的机器学习研讨会外，还有计算机学习理论会议以及遗传算法会议。
1.1.3机器学习的分类
机器学习分为一下几类：监督学习、无监督学习、半监督学习、强化学习、迁移学习。
 监督学习
监督学习是利用已知类别的样本（即有标记的样本 labeled sample，已知其相应的类别），调整分类器的参数，训练得到一个最优模型，使其达到所要求性能，再利用这个训练后的模型，将所有的输入映射为相应的输出，对输出进行简单的判断，从而实现分类的目的，这样，即可以对未知数据进行分类。
通俗的来讲，我们给计算机一堆选择题（训练样本），并同时提供了它们的标准答案，计算机努力调整自己的模型参数，希望自己推测的答案与标准答案越一致越好，使计算机学会怎么做这类题。然后再让计算机去帮我们做没有提供答案的选择题（测试样本）。
 无监督学习
无监督学习的实现没有有标记的、已经分类好的样本，需要我们直接对输入数据集进行建模，例如聚类，最直接的例子就是我们常说的『人以群分，物以类聚』。我们只需要把相似度高的东西放在一起，对于新来的样本，计算相似度后，按照相似程度进行归类就好。
通俗的来讲，我们给计算机一堆选择题（训练样本），但是不提供标准答案，计算机尝试分析这些题目之间的关系，对题目进行分类，计算机也不知道这几堆题的答案分别是什么，但计算机认为每一个类别内的题的答案应该是相同的。
 半监督学习
半监督学习是介于监督学习与无监督学习之间一种机器学习方式，主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。
通俗的来讲，我们给计算机一堆选择题（训练样本），但是不全部提供标准答案，计算机尝试分析这些题目之间的关系，通过少量标注的样本对题目进行分类，从而得到标准答案。
应用的场景包括回归和分类，算法包括一些常用监督式学习算法的延伸，这些算法首先试图对未标注的数据进行建模，在此基础上再对标识的数据进行预测，如图论推理算法（Graph Inferece）或者拉普拉斯支持向量机（Laplacian SVM）等。
半监督学习字诞生以来，主要应用于处理人工合成数据，无噪声干扰的样本数据是当前大部分半监督学习方法使用的数据，而在实际生活中用到的数据大部分不是无干扰的，通常都比较难以得到纯样本数据。
 强化学习
所谓强化学习就是智能系统从环境到行为映射的学习，以使奖励信号(强化信号)函数值最大，强化学习不同于连接主义学习中的监督学习，主要表现在教师信号上，强化学习中由环境提供的强化信号是对产生动作的好坏作一种评价(通常为标量信号)，而不是告诉强化学习系统RLS(reinforcement learning system)如何去产生正确的动作。
通俗的来讲，我们给计算机一堆选择题（训练样本），但是不提供标准答案，计算机尝试去做这些题，我们作为老师批改计算机做的对不对，对的越多，奖励越多，则计算机努力调整自己的模型参数，希望自己推测的答案能够得到更多的奖励。不严谨的讲，可以理解为先无监督后有监督学习。
 迁移学习
考虑到大部分数据或任务是存在相关性的，所以通过transfer learning我们可以将已经学到的parameter 分享给新模型从而加快并优化模型的学习不用像之前那样learn from zero。把已学训练好的模型参数迁移到新的模型来帮助新模型训练数据集。

1.1.4机器学习的常见算法
1. 决策树
根据一些 feature 进行分类，每个节点提一个问题，通过判断，将数据分为两类，再继续提问。这些问题是根据已有数据学习出来的，再投入新数据的时候，就可以根据这棵树上的问题，将数据划分到合适的叶子上。

优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。
缺点：过拟合，可限制树深度及叶子节点个数。
关键词：ID3(信息增益) C4.5(信息增益比) CART(基尼系数)。
数据要求：标称型数据，因此数值型数据必须离散化。
2.随机森林
视频：https://www.youtube.com/watch?v=loNcrMjYh64
在源数据中随机选取数据，组成几个子集

S 矩阵是源数据，有 1-N 条数据，A B C 是feature，最后一列C是类别。
由 S 随机生成 M 个子矩阵。
这 M 个子集得到 M 个决策树，将新数据投入到这 M 个树中，得到 M 个分类结果，计数看预测成哪一类的数目最多，就将此类别作为最后的预测结果。

优点：对很多数据集表现很好，精确度比较高；不容易过拟合；可以得到变量的重要性排序；既能处理离散型数据，也能处理连续型数据，且不需要进行归一化处理；能够很好的处理缺失数据；容易并行化。
3.逻辑回归
视频：https://www.youtube.com/watch?v=gNhogKJ_q7U
https://www.youtube.com/watch?v=owI7zxCqNY0
当预测目标是概率这样的，值域需要满足大于等于0，小于等于1的，这个时候单纯的线性模型是做不到的，因为在定义域不在某个范围之内时，值域也超出了规定区间。

所以此时需要这样的形状的模型会比较好。

那么怎么得到这样的模型呢？这个模型需要满足两个条件大于等于0，小于等于1；大于等于0 的模型可以选择 绝对值，平方值，这里用指数函数，一定大于0；小于等于1 用除法，分子是自己，分母是自身加上1，那一定是小于1的了。
再做一下变形，就得到了 logistic regression 模型
通过源数据计算可以得到相应的系数了。
最后得到 logistic 的图形。

优点：计算代价不高，易于理解和实现。
缺点：容易欠拟合，分类精度可能不高。
关键词：Sigmoid函数、Softmax解决多分类
适用数据类型：数值型和标称型数据。
其它：逻辑回归函数虽然是一个非线性的函数，但其实其去除Sigmoid映射函数之后，其他步骤都和线性回归一致。
4.SVM
视频：https://www.youtube.com/watch?v=1NxnPkZM9bc
要将两类分开，想要得到一个超平面，最优的超平面是到两类的 margin 达到最大，margin就是超平面与离它最近一点的距离，如下图，Z2>Z1，所以绿色的超平面比较好。

将这个超平面表示成一个线性方程，在线上方的一类，都大于等于1，另一类小于等于－1。

点到面的距离根据图中的公式计算。

所以得到 total margin 的表达式如下，目标是最大化这个 margin，就需要最小化分母，于是变成了一个优化问题。
举个例子，三个点，找到最优的超平面，定义了 weight vector＝（2，3）－（1，1）。

得到 weight vector 为（a，2a），将两个点代入方程，代入（2，3）另其值＝1，代入（1，1）另其值＝-1，求解出 a 和 截矩 w0 的值，进而得到超平面的表达式。

a 求出来后，代入（a，2a）得到的就是 support vector，a 和 w0 代入超平面的方程就是 support vector machine。
优点：适合小数量样本数据，可以解决高维问题，理论基础比较完善，对于学数学的来说它的理论很美;可以提高泛化能力；
缺点：数据量大时，内存资源消耗大（存储训练样本和核矩阵），时间复杂度高，这时候LR等算法就比SVM要好；对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数。
对于核函数的运用对SVM来说确实是一个亮点，但是核函数不是SVM专属的，其他算法一旦涉及到内积运算，就可以使用核函数。它的优化方向的话就是各种不同的场景了，比如扩展到多分类，类别标签不平衡等都可以对SVM做些改变来适应场景。
关键词：最优超平面 最大间隔 拉格朗日乘子法 对偶问题 SMO求解 核函数 hinge损失 松弛变量 惩罚因子 多分类
适用数据类型：数值型和标称型数据。
参数：选择核函数，如径向基函数（低维到高维）、线性核函数，以及核函数的参数; 惩罚因子。
其它：SVM也并不是在任何场景都比其他算法好，SVM在邮件分类上不如逻辑回归、KNN、bayes的效果好，是基于距离的模型，需要归一化。
5.朴素贝叶斯
视频：https://www.youtube.com/watch?v=DNvwfNEiKvw
举个在 NLP 的应用，给一段文字，返回情感分类，这段文字的态度是positive，还是negative。

为了解决这个问题，可以只看其中的一些单词。

这段文字，将仅由一些单词和它们的计数代表。

原始问题是：给你一句话，它属于哪一类，通过 bayes rules 变成一个比较简单容易求得的问题。
问题变成，这一类中这句话出现的概率是多少，当然，别忘了公式里的另外两个概率
例子：单词 love 在 positive 的情况下出现的概率是 0.1，在 negative 的情况下出现的概率是 0.001。
6.K最近邻k nearest neighbours
视频：https://www.youtube.com/watch?v=zHbxbb2ye3E
给一个新的数据时，离它最近的 k 个点中，哪个类别多，这个数据就属于哪一类。
例子：要区分 猫 和 狗，通过 claws 和 sound 两个feature来判断的话，圆形和三角形是已知分类的了，那么这个 star 代表的是哪一类呢

k＝3时，这三条线链接的点就是最近的三个点，那么圆形多一些，所以这个star就是属于猫。

优点：精度高、对异常值不敏感、无数据输入假定。
缺点：计算复杂度高，空间复杂度，数据不平衡问题。KD-Tree。
数据类型：数值型和标称型。
其它：K值如何选择；数据不平衡时分类倾向更多样本的类，解决方法是距离加权重。
k值的选择：当k值较小时，预测结果对近邻的实例点非常敏感，容易发生过拟合；如果k值过大模型会倾向大类，容易欠拟合；通常k是不大于20的整数（参考《机器学习实战》）
7.K均值
视频：https://www.youtube.com/watch?v=zHbxbb2ye3E
想要将一组数据，分为三类，粉色数值大，黄色数值小，最开心先初始化，这里面选了最简单的 3，2，1 作为各类的初始值，剩下的数据里，每个都与三个初始值计算距离，然后归类到离它最近的初始值所在类别。

好类后，计算每一类的平均值，作为新一轮的中心点

几轮之后，分组不再变化了，就可以停止了。


优点：容易实现。
缺点：K值不容易确定，对初始值敏感，可能收敛到局部最小值。KD-Tree。
数据类型：数值型数据。
K值的确定：簇类指标（半径、直径）出现拐点；
克服K-均值算法收敛于局部最小值，需确定初始聚类中心：
K-Means++算法：初始的聚类中心之间的相互距离要尽可能的远。
二分K-均值算法：首先将所有点作为一个簇，然后将簇一分为二。之后选择其中一个簇继续划分，选择哪个一簇进行划分取决于对其划分是否可以最大程度降低SSE(Sum of Squared Error，两个簇的总误差平方和)的值。
8.Adaboost
视频：https://www.youtube.com/watch?v=rz9dnmHmZsY
Adaboost 是 bosting 的方法之一，bosting就是把若干个分类效果并不好的分类器综合起来考虑，会得到一个效果比较好的分类器。Adaboost是一种加和模型，每个模型都是基于上一次模型的错误率来建立的，过分关注分错的样本，而对正确分类的样本减少关注度，逐次迭代之后，可以得到一个相对较好的模型。下图，左右两个决策树，单个看是效果不怎么好的，但是把同样的数据投入进去，把两个结果加起来考虑，就会增加可信度。

adaboost 的例子，手写识别中，在画板上可以抓取到很多 features，例如 始点的方向，始点和终点的距离等等。

training 的时候，会得到每个 feature 的 weight，例如 2 和 3 的开头部分很像，这个 feature 对分类起到的作用很小，它的权重也就会较小。

而这个 alpha 角 就具有很强的识别性，这个 feature 的权重就会较大，最后的预测结果是综合考虑这些 feature 的结果。

优点：Adaboost是一种有很高精度的分类器。可以使用各种方法构建子分类器，Adaboost算法提供的是框架。当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单。简单，不用做特征筛选。不容易发生overfitting。
缺点：对outlier比较敏感。
9.神经网络
视频：https://www.youtube.com/watch?v=P2HPcj8lRJE
Neural Networks 适合一个input可能落入至少两个类别里，NN 由若干层神经元，和它们之间的联系组成，第一层是 input 层，最后一层是 output 层，在 hidden 层 和 output 层都有自己的 classifier。

input 输入到网络中，被激活，计算的分数被传递到下一层，激活后面的神经层，最后output 层的节点上的分数代表属于各类的分数，下图例子得到分类结果为 class 1。同样的 input 被传输到不同的节点上，之所以会得到不同的结果是因为各自节点有不同的weights 和 bias。这也就是 forward propagation。

优点：分类的准确度高；并行分布处理能力强,分布存储及学习能力强，对噪声神经有较强的鲁棒性和容错能力，能充分逼近复杂的非线性关系；具备联想记忆的功能。
缺点：神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；学习时间过长,甚至可能达不到学习的目的。
10.马尔可夫
视频：https://www.youtube.com/watch?v=56mGTszb_iM
Markov Chains 由 state 和 transitions 组成。例子，根据这一句话 ‘the quick brown fox jumps over the lazy dog’，要得到 markov chain。步骤，先给每一个单词设定成一个状态，然后计算状态间转换的概率。

这是一句话计算出来的概率，当你用大量文本去做统计的时候，会得到更大的状态转移矩阵，例如 the 后面可以连接的单词，及相应的概率。

生活中，键盘输入法的备选结果也是一样的原理，模型会更高级。

 机器学习的应用
语音识别，自动驾驶，语言翻译，计算机视觉，推荐系统，无人机，识别垃圾邮件。
 机器学习的应用实例
及时翻译：Speech Recognition Breakthrough for the Spoken, Translated Word
链接：https:www.youtube.com/watch?v=Nu-nlQqFCKg
无人驾驶汽车：Self-Driving Car Test: Steve Mahan
链接：https://www.youtube.com/watch?v=cdgQpa1pUUE
无人机：拉菲罗·安德烈: 四轴飞行器灵活的运动性能
链接：https:www.youtube.com/watch?v=w2itwFJCgFQ
参考：
机器学习就业需求：http://blog.linkedin.com/2014/12/17/the-25-hottest-skills-that-got-people-hired-in-2014/
1.2深度学习(Deep Learning)
1.2.1什么是深度学习
深度学习是基于机器学习延伸出来的一个新的领域，由以人大脑结构为启发的神经网络算法为起源加之模型结构深度的增加发展，并伴随大数据和计算能力的提高而产生的一系列新的算法。

1.2.2深度学习的发展过程
概念由著名科学家Geoffrey Hinton等人在2006年和2007年在《Sciences》等上发表的文章被提出和兴起。

1.2.3 学习能用来干什么
深度学习，作为机器学习中延伸出来的一个领域，被应用在图像处理与计算机视觉，自然语言处理以及语音识别等领域。自2006年至今，学术界和工业界合作在深度学习方面的研究与应用在以上领域取得了突破性的进展。以ImageNet为数据库的经典图像中的物体识别竞赛为例，击败了所有传统算法，取得了前所未有的精确度。

1.2.4 深度学习代表性的学术机构和公司
学校以多伦多大学，纽约大学，斯坦福大学为代表，工业界以Google, Facebook, 和百度为代表走在深度学习研究与应用的前沿。Google挖走了Hinton，Facebook挖走了LeCun，百度硅谷的实验室挖走了Andrew Ng，Google去年4月份以超过5亿美金收购了专门研究深度学习的初创公司DeepMind, 深度学习方因技术的发展与人才的稀有造成的人才抢夺战达到了前所未有激烈的程度。诸多的大大小小(如阿里巴巴，雅虎）等公司也都在跟进，开始涉足深度学习领域，深度学习人才需求量会持续快速增长。

1.2.5深度学习如今和未来将对我们生活影响
目前我们使用的Android手机中google的语音识别，百度识图，google的图片搜索，都已经使用到了深度学习技术。Facebook在去年名为DeepFace的项目中对人脸识别的准备率第一次接近人类肉眼（97.25% vs 97.5%)。大数据时代，结合深度学习的发展在未来对我们生活的影响无法估量。保守而言，很多目前人类从事的活动都将因为深度学习和相关技术的发展被机器取代，如自动汽车驾驶，无人飞机，以及更加职能的机器人等。深度学习的发展让我们第一次看到并接近人工智能的终极目标。

参考文献
[1] Hebb D. O., The organization of behaviour.New York: Wiley & Sons.
[2]Rosenblatt, Frank. “The perceptron: a probabilistic model for information storage and organization in the brain.” Psychological review 65.6 (1958): 386.
[3]Minsky, Marvin, and Papert Seymour. “Perceptrons.” (1969).
[4]Widrow, Hoff “Adaptive switching circuits.” (1960): 96-104.
[5]S. Linnainmaa. The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors. Master’s thesis, Univ. Helsinki, 1970.
[6] P. J. Werbos. Applications of advances in nonlinear sensitivity analysis. In Proceedings of the 10th IFIP Conference, 31.8 - 4.9, NYC, pages 762–770, 1981.
[7] Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. Learning internal representations by error propagation. No. ICS-8506. CALIFORNIA UNIV SAN DIEGO LA JOLLA INST FOR COGNITIVE SCIENCE, 1985.
[8] Hecht-Nielsen, Robert. “Theory of the backpropagation neural network.” Neural Networks, 1989. IJCNN., International Joint Conference on. IEEE, 1989.
[9] Quinlan, J. Ross. “Induction of decision trees.” Machine learning 1.1 (1986): 81-106.
[10] Cortes, Corinna, and Vladimir Vapnik. “Support-vector networks.” Machine learning 20.3 (1995): 273-297.
[11] Freund, Yoav, Robert Schapire, and N. Abe. "A short introduction to boosting."Journal-Japanese Society For Artificial Intelligence 14.771-780 (1999): 1612.
[12] Breiman, Leo. “Random forests.” Machine learning 45.1 (2001): 5-32.
[13] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. “A fast learning algorithm for deep belief nets.” Neural computation 18.7 (2006): 1527-1554.
[14] Bengio, Lamblin, Popovici, Larochelle, “Greedy Layer-Wise Training of Deep Networks”, NIPS’2006
[15] Ranzato, Poultney, Chopra, LeCun " Efficient Learning of Sparse Representations with an Energy-Based Model ", NIPS’2006
[16] Olshausen B a, Field DJ. Sparse coding with an overcomplete basis set: a strategy employed by V1? Vision Res. 1997;37(23):3311–25. Available at: http://www.ncbi.nlm.nih.gov/pubmed/9425546.
[17] Vincent, H. Larochelle Y. Bengio and P.A. Manzagol, Extracting and Composing Robust Features with Denoising Autoencoders, Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML‘08), pages 1096 - 1103, ACM, 2008.
[18] Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36, 193–202.
[19] LeCun, Yann, et al. "Gradient-based learning applied to document recognition."Proceedings of the IEEE 86.11 (1998): 2278-2324.
[20] LeCun, Yann, and Yoshua Bengio. “Convolutional networks for images, speech, and time series.” The handbook of brain theory and neural networks3361 (1995).
[21] Zeiler, Matthew D., et al. “Deconvolutional networks.” Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010.
[22] S. Vishwanathan, N. Schraudolph, M. Schmidt, and K. Mur- phy. Accelerated training of conditional random fields with stochastic meta-descent. In International Conference on Ma- chine Learning (ICML ’06), 2006.
[23] Nocedal, J. (1980). ”Updating Quasi-Newton Matrices with Limited Storage.” Mathematics of Computation 35 (151): 773782. doi:10.1090/S0025-5718-1980-0572855-
[24] S. Yun and K.-C. Toh, “A coordinate gradient descent method for l1- regularized convex minimization,” Computational Optimizations and Applications, vol. 48, no. 2, pp. 273–307, 2011.
[25] Goodfellow I, Warde-Farley D. Maxout networks. arXiv Prepr arXiv …. 2013. Available at: http://arxiv.org/abs/1302.4389. Accessed March 20, 2014.
[26] Wan L, Zeiler M. Regularization of neural networks using dropconnect. Proc …. 2013;(1). Available at: http://machinelearning.wustl.edu/mlpapers/papers/icml2013_wan13. Accessed March 13, 2014.
[27] Alekh Agarwal, Olivier Chapelle, Miroslav Dudik, John Langford, A Reliable Effective Terascale Linear Learning System, 2011
[28] M. Hoffman, D. Blei, F. Bach, Online Learning for Latent Dirichlet Allocation, in Neural Information Processing Systems (NIPS) 2010.
[29] Alina Beygelzimer, Daniel Hsu, John Langford, and Tong Zhang Agnostic Active Learning Without Constraints NIPS 2010.
[30] John Duchi, Elad Hazan, and Yoram Singer, Adaptive Subgradient Methods for Online Learning and Stochastic Optimization, JMLR 2011 & COLT 2010.
[31] H. Brendan McMahan, Matthew Streeter, Adaptive Bound Optimization for Online Convex Optimization, COLT 2010.
[32] Nikos Karampatziakis and John Langford, Importance Weight Aware Gradient Updates UAI 2010.
[33] Kilian Weinberger, Anirban Dasgupta, John Langford, Alex Smola, Josh Attenberg, Feature Hashing for Large Scale Multitask Learning, ICML 2009.
[34] Qinfeng Shi, James Petterson, Gideon Dror, John Langford, Alex Smola, and SVN Vishwanathan, Hash Kernels for Structured Data, AISTAT 2009.
[35] John Langford, Lihong Li, and Tong Zhang, Sparse Online Learning via Truncated Gradient, NIPS 2008.
[36] Leon Bottou, Stochastic Gradient Descent, 2007.
[37] Avrim Blum, Adam Kalai, and John Langford Beating the Holdout: Bounds for KFold and Progressive Cross-Validation. COLT99 pages 203-208.
[38] Nocedal, J. (1980). “Updating Quasi-Newton Matrices with Limited Storage”. Mathematics of Computation 35: 773–782.
[39] D. H. Ballard. Modular learning in neural networks. In AAAI, pages 279–284, 1987.
[40] S. Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f ̈ur Informatik, Lehrstuhl Prof. Brauer, Technische Universit ̈at M ̈unchen, 1991. Advisor: J. Schmidhuber.