时间过得很快，转眼间就要到了准备毕业论文的时候了。研究生的毕业论文不能像本科一样简单的发现规律，将规律表达出来便可。研究生的论文更像是一种通过发现现实问题，进行深入研究后，再将现象提炼出来进行规律总结最后对问题提出更为科学的解决方案。重点在这个提炼与应用的过程，也是很痛苦的一个过程。需要查看大量的文献，了解国际最新研究动态。运用很多较为先进的方法进行操作。特别是瞻仰过几篇师兄的毕业论文之后，发现我现在掌握的知识还远远不够。经过导师的点播，我决定往机器学习方面靠。这也是能够很好挖掘论文深度的一个方面。对我来说也是打开了一个新的领域。以下便是我学习了机器学习一段时间后的一个认识。
所谓机器学习其实也可以叫做统计学习，主要以计算机和网络为平台，对大量数据进行研究，目的是发现规律并进行预测分析的过程。这其中会用到很多的方法，也是机器学习的核心所在。何为学习，Herbert A.Simon说过：如果一个系统能够通过执行某个过程改进它的性能，这就是学习。
学习机器学习的总体目的便是考虑运用什么样的模型对数据进行学习，使得得到的模型能够更好的对数据进行预测，提高学习效率。方法有很多，模型也很多。通过一段时间的学习，所谓机器学习的主要过程可提炼为以下几点：
①得到一个有限的训练数据集合
②确定包含所有可能的模型的假设空间，即学习模型的集合
③确定模型选择的准则，即学习的策略
④实现求解最优模型的算法，即学习的算法
⑤通过学习方法选择最优模型
⑥利用学习的最优模型对新数据进行预测分析
机器学习方法的三要素为：模型（模型的假设空间）、策略（模型选择的准则）、算法（模型学习的算法）
对于学习模型的好坏也有这一套评判方法，比如0-1损失函数、平方损失函数、对数损失函数、绝对损失函数等。通过这些判断预测的好坏，便有了经验风险最小化的方法即：
这个判断方法需要实验样本比较大的情况，不过一味的最求经验风险的最小化会存在过拟合现象的发生，简单的说模型所含的参数过多，对已知的数据预测的很好，但是对未知的数据预测很差。达不到我们想要的结果。于是便有了结构风险最小化的方法在后面加了个正则化项
目的便是选择经验风险和模型复杂度同时较小的模型。
其实对于模型的选择问题除了正则化的处理还有交叉验证、S折交叉验证、留一交叉验证以及学习泛化能力等。
对于交叉验证是通过随机将数据切分成三部分：训练集（训练模型）、验证集（选择模型）、测试集（最终对学习方法评估）；该方法使用于数据充足的情况。
比如简单交叉验证：通过随机将数据分为两部分（训练集与测试集）然后在训练集中进行训练得出模型再在测试集中进行模型评判选择
应用最多的便是S折交叉验证了。通过随机将已知数据分为大小相同的S个子集，而后利用S-1个子集为训练模型，省下一个为测试模型。将这一过程对可能的S中选择进行重复，最后选出这S个测评中平均误差最小的模型。
作为S折交叉验证的特殊情况留一交叉验证用的极少，意思就是S=N的情况，N是给定数据集的容量。
学习的泛化能力:通常将学习方法对未知数据的预测能力称为泛化能力。说到这就不得不说一下泛化误差这东西了，泛化误差：选定模型对未知数据预测的误差，其实就是所学习的模型的期望风险。
监督学习可分为生成方法和判别方法两种。
生成方法：有数据联合概率分布P(X,Y),然后求出条件概率分布P(Y|X)作为预测的模型。公式表示为：个人感觉怎么这么的像以前学的概率论呢？可能就是吧。♪(･ω･)ﾉ它的特点是学习收敛快、能够对存在隐变量进行学习。
判断方法：由数据直接学习决策函数f(X)或者条件概率分布P(X|Y)作为预测的模型。特点是学习准确率高、可对数据进行抽象，定义特征并使用特征，可以简化学习问题。
监督学习主要应用在三大问题上：分类问题、标注问题和回归问题。
分类问题：重在分类二字将结果进行分类，对数据进行划分；主要包括学习（根据已知的训练数据集利用有效的学习方法学习一个分类器）和分类（利用学习的分类器对新的输入实例进行分类）两个步骤；常用的评价指标为精确率P=TP/(TP+FP)与召回率R=TP/(TP+FN)。2/F1=1/P+1/R.
TP--将正类预测为正类数
FN--将正类预测为负类数
FP--将负类预测为正类数
TN--将负类预测为负类数
标注问题：分类问题的一个推广，输入为观测序列，输出为标记序列或状态序列。
回归问题：用于预测输入变量和输出变量之间的关系。表达从输入变量到输出变量之间的映射函数类似于函数拟合。
可以说：输入变量与输出变量均为连续变量的预测问题为回归问题；输出变量为有限个离散变量的预测问题为分类问题；输入变量与输出变量均为变量序列的预测问题称为标注问题。
总体感受：很是枯燥乏味。可能是太难了吧，为了毕业，加油干吧！O(∩_∩)O哈哈~确实开阔了自己的视野。
。