继续是机器学习课程的笔记，本节课内容是异常检测，它是一个非监督学习算法，用于发现可能不应该属于一个已定义的组中的数据。
密度估计
首先是给出一个例子，如下图所示，是一个测试飞机引擎的例子，给定数据集{
x(1),x(2),…,x(m)
x^{(1)},x^{(2)},\ldots,x^{(m)}},假设数据集是正确的，我们希望知道新的数据
xtest
x_{test}是不是异常的，即这个测试数据不属于该组数据的几率如何。我们所构建的模型应该能根据该测试数据的位置告诉我们其属于一组数据的可能性
p(x)
p_{(x)}。
在上图中，在蓝色圈内的数据属于该组数据的可能性较高，而越是偏远的数据，其属于该组数据的可能性就越低。
这种方法称为密度估计，表达如下：
ifp(x){≤ϵanomaly>ϵnormal
if\quad p(x) \begin{cases} \le \epsilon \quad anomaly \\ \gt \epsilon \quad normal \end{cases}
异常检测主要用来识别欺骗。
例如，在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登陆一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。
再一个例子是检测一个数据中心，特征可能包含：内存使用情况，被访问的磁盘数量，CPU的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是否有可能出错了。
高斯分布
接下来回顾下高斯分布的基本知识。
通常如果我们认为变量x符合高斯分布，即
x∼N(μ,σ2)
x \sim N(\mu,\sigma^2),则其概率密度函数为：
p(x,μ,σ2)=1(√2π)σexp−((x−μ)22σ2)
p(x,\mu,\sigma^2)=\frac{1}{\sqrt(2\pi)\sigma}exp^{-(\frac{(x-\mu)^2}{2\sigma^2})}
下图是
μ
\mu和
σ2
\sigma^2取不同值时，高斯分布的曲线图例子：
我们可以利用已有的数据来预测总体中的
μ
\mu和
σ2
\sigma^2，计算方法如下：
μ=1m∑i=1mx(i)σ2=1m∑i=1m(x(i)−μ)2
\mu = \frac{1}{m} \sum_{i=1}^m x^{(i)} \\ \sigma^2 = \frac{1}{m} \sum_{i=1}^m (x^{(i)}-\mu)^2
注意，机器学习中对于方程，我们通常只除以m而非统计学中的（m-1）。
异常检测算法
这里将使用高斯分布来开发异常检测算法。
对于给定数据集{
x(1),x(2),…,x(m)
x^{(1)},x^{(2)},\ldots,x^{(m)}}，我们要选择一个认为可以找出异常例子的特征
xi
x_i,然后计算其
μ
\mu和
σ2
\sigma^2的估计值。
μj=1m∑i=1mx(i)σ2j=1m∑i=1m(x(i)j−μj)2
\mu_j = \frac{1}{m} \sum_{i=1}^m x^{(i)} \\ \sigma^2_j = \frac{1}{m} \sum_{i=1}^m (x^{(i)}_j-\mu_j)^2
一旦获得了
μ
\mu和
σ2
\sigma^2的估计值，给定新的一个训练实例，根据模型计算
p(x)
p(x):
p(x)=∏j=1np(xj;μj,σ2j)=∏j=1n1(√2π)σjexp−((xj−μj)22σ2j)
p(x) = \prod_{j=1}^n p(x_j;\mu_j,\sigma^2_j)=\prod_{j=1}^n \frac{1}{\sqrt(2\pi)\sigma_j}exp^{-(\frac{(x_j-\mu_j)^2}{2\sigma_j^2})}
然后设置一个阈值
ϵ
\epsilon,当
p(x)<ϵ
p(x) \lt \epsilon时，可以认为该测试数据是一个异常数据。
下图是一个有两个特征的训练集，以及特征的分布情况：
下面的三维图表示的是密度估计函数，z轴为根据两个特征的值所估计的
p(x)
p(x)值：
我们选择一个
ϵ
\epsilon,将
p(x)=ϵ
p(x) = \epsilon作为我们的判定边界，当
p(x)>ϵ
p(x) \gt \epsilon时预测数据为正常数据，否则就是异常数据。
评价一个异常检测系统
接下来是介绍如何评价一个异常检测系统。
异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量y的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。
当我们开发一个异常检测系统时，我们从带标记（异常或者正常）的数据着手，从其中选择一部分正常数据用于构建训练集，然后用剩下的正常数据和异常数据混合的数据构成交叉验证集和测试集。
例如，我们有10000台正常引擎的数据，20台异常引擎的数据。我们可以这样分配数据：
6000台正常引擎的数据作为训练集
2000台正常引擎和10台异常引擎的数据作为交叉验证集
2000台正常引擎和10台异常引擎的数据作为测试集
具体的评价方法如下：
根据测试集数据，我们估计特征的平均值和方差并构建
p(x)
p(x)函数
对交叉验证集，尝试使用不同的
ϵ
\epsilon值作为阈值，并预测数据是否异常，根据F1值或者查准率与查全率的比例来选择
ϵ
\epsilon
选出
ϵ
\epsilon后，针对测试集进行预测，计算异常检验系统的F1值或者查准率与查全率之比。
异常检测与监督学习之比
上一小节在评估异常检测算法的时候，是使用带有标记的数据，这与监督学习有些相似，两者的对比如下所示。
异常检测
监督学习
非常少量的正向类（异常数据 y=1），大量的负向类（y=0）
同时有大量的正向类和负向类
许多不同种类的异常，非常难根据非常少量的正向类数据来训练算法
有足够多的正向类，足够用于训练算法
未来遇到的异常可能与已掌握的异常非常的不同
未来遇到的正向类实例可能与训练集中国的非常相似
使用的例子，有如欺诈行为检测，生产（如飞机引擎），检测数据中心的计算机运行状况。
使用的例子，如邮件过滤器，天气预报，肿瘤分类
选择特征
对于异常检测算法，使用的特征是至关重要的，下面将介绍如何选择特征。
异常检测假设特征符合高斯分布，如果数据的分布不是高斯分布，异常检测算法也能够工作，但最好还是将数据转换成高斯分布。例如使用对数函数
x=log(x+c)
x=log(x+c),其中c为非负尝试；或者
x=xc
x=x^c，c是0-1之间的一个小数，等方法。如下图是一个使用对数函数进行转换成高斯分布的例子。
对于如何选择特征，可以借助误差分析。我们希望的是对于正常数据可以得到大的
p(x)
p(x)，而异常数据是得到小的
p(x)
p(x)值。
但一个常见的问题是一些异常的数据也会有较高的
p(x)
p(x)值，因而被认为是正常的。
这种情况下误差分析能够帮助我们，我们可以分析那些被算法错误预测为正常的数据，观察能否找出一些问题。我们可能能从问题中发现我们需要增加一些新的特征，增加这些特征后获得的新算法能够帮助我们更好地进行异常检测。
我们通常可以通过将一些相关的特征进行组合，来获得一些新的更好的特征（异常数据的该特征值异常地大或小）。
例如在检测数据中心的计算机状况的例子中，我们可以用CPU负载与网络通信量的比例作为一个新的特征，如果该值异常地大便有可能意味着该服务器是陷入了一些问题中。
多元高斯分布
假设有两个相关的特征，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。
下图是两个相关特征，红色的线（根据
ϵ
\epsilon的不同，范围也可大可小）是一般的高斯分布模型获得的判断边界，很明显绿色的X所代表的数据点可能是异常值，但是其
p(x)
p(x)值却仍然在正常范围内。多元高斯分布将创建像图中蓝色曲线所示的判断边界。
在一般的高斯分布模型中，计算
p(x)
p(x)的方法如下：
p(x)=∏j=1np(xj;μj,σ2j)=∏j=1n1(√2π)σjexp−((xj−μj)22σ2j)
p(x) = \prod_{j=1}^n p(x_j;\mu_j,\sigma^2_j)=\prod_{j=1}^n \frac{1}{\sqrt(2\pi)\sigma_j}exp^{-(\frac{(x_j-\mu_j)^2}{2\sigma_j^2})}
通过分别计算每个特征对应的几率，然后将其累乘起来，在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起计算
p(x)
p(x)。
首先计算所有特征的平均值：
μ=1m∑mi=1x(i)
\mu =\frac{1}{m} \sum_{i=1}^m x^{(i)};
其次，计算协方差矩阵：
∑=1m∑mi=1(x(i)−μ)(x(i)−μ)T=1m(X−μ)T(X−μ)
\sum = \frac{1}{m} \sum_{i=1}^m (x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)
注意，其中
μ
\mu是一个向量，其每一个单元都是原特征矩阵中一行数据的的均值。
最后计算多元高斯分布的
p(x)=1(2π)n2|∑|12exp(−12(x−μ)T∑−1(x−μ))
p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\sum|^{\frac{1}{2}}}exp^{(-\frac{1}{2}(x-\mu)^T\sum^{-1}(x-\mu))}
其中：
|∑|
|\sum|是定矩阵，在Octave中用det(sigma)计算
∑−1
\sum^{-1}是逆矩阵
下面看看协方差矩阵是如何影响模型的：
上图是5个不同的模型，从左往右依次分析：
是一个一般的高斯分布模型
通过协方差矩阵，令特征1有较小的偏差，同时保持特征2的偏差
通过协方差矩阵，令特征2有较大的偏差，同时保持特征1的偏差
通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的正相关性
通过协方差矩阵，在不改变两个特征的原有偏差的基础上，增加两者之间的负相关性
多元高斯分布模型与原高斯分布模型的关系：
可以证明的是，原本的高斯分布模型是多元高斯分布模型的一个子集，即像上图中的第1，2,3个例子，3个例子所示，如果协方差矩阵只在对角线的单位上有非零的值时，即为原本的高斯分布模型了。
原高斯分布模型与多元高斯模型比较如下：
原高斯分布模型
多元高斯分布模型
不能捕捉特征之间的相关性但可以通过将特征进行组合的方法来解决
自动捕捉特征之间的相关性
计算代价低，能适应大规模的特征
计算代价较高
训练集较小时也同样适用
必须要有
m>n
m \gt n,不然的话协方差矩阵是不可逆的，通常需要
m>10n
m \gt 10n，另外特征冗余也会导致协方差矩阵不可逆
原高斯分布模型被广泛使用着，如果特征之间在某种程度上存在相互关联的情况，我们可以通过构造新特征的方法来捕捉这些相关性。
如果训练集不是太大，并且没有太多的特征，我们可以使用多元高斯分布模型。
小结
本节内容，主要是介绍异常检测算法，其实现的具体细节以及应用的一些场景。