http://antkillerfarm.github.io/
因子分析的EM估计（续）
去掉和各参数无关的部分后，可得：
∑i=1mE[logp(x(i)|z(i);μ,Λ,Ψ)]=∑i=1mE[1(2π)n/2∣Ψ∣1/2exp(−12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i)))]=∑i=1mE[−12log∣Ψ∣−n2log(2π)−12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))]
\begin{align} &\sum_{i=1}^mE\left[\log p(x^{(i)}\vert z^{(i)};\mu,\Lambda,\Psi)\right] \\&=\sum_{i=1}^mE\left[\frac{1}{(2\pi)^{n/2}\lvert\Psi\rvert^{1/2}}\exp\left(-\frac{1}{2}(x^{(i)}-\mu-\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu-\Lambda z^{(i)})\right)\right] \\&=\sum_{i=1}^mE\left[-\frac{1}{2}\log\lvert\Psi\rvert-\frac{n}{2}\log(2\pi)-\frac{1}{2}(x^{(i)}-\mu-\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu-\Lambda z^{(i)})\right] \end{align}
去掉和
Λ
\Lambda无关的部分，并求导可得：
∇Λ∑i=1m−E[12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))](1)
\nabla_\Lambda\sum_{i=1}^m-E\left[\frac{1}{2}(x^{(i)}-\mu-\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu-\Lambda z^{(i)})\right]\tag{1}
因为公式1中
E[⋅]
E[\cdot]部分的结果实际上是个实数，因此该公式可变形为：
∇Λ∑i=1m−E[tr(12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i)))]
\nabla_\Lambda\sum_{i=1}^m-E\left[\operatorname{tr}\left(\frac{1}{2}(x^{(i)}-\mu-\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu-\Lambda z^{(i)})\right)\right]
而：
12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))=12[((x(i)−μ)T−(Λz(i))T)Ψ−1((x(i)−μ)−Λz(i))]=12[(x(i)−μ)TΨ−1(x(i)−μ)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)+(Λz(i))TΨ−1Λz(i)]
\begin{align} &\frac{1}{2}(x^{(i)}-\mu-\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu-\Lambda z^{(i)}) \\&=\frac{1}{2}\left[((x^{(i)}-\mu)^T-(\Lambda z^{(i)})^T)\Psi^{-1}((x^{(i)}-\mu)-\Lambda z^{(i)})\right] \\&=\frac{1}{2}\left[(x^{(i)}-\mu)^T\Psi^{-1}(x^{(i)}-\mu)-(x^{(i)}-\mu)^T\Psi^{-1}\Lambda z^{(i)} \\-(\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu)+(\Lambda z^{(i)})^T\Psi^{-1}\Lambda z^{(i)}\right] \end{align}
去掉和
Λ
\Lambda无关的部分，可得：
12[(Λz(i))TΨ−1Λz(i)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)]
\frac{1}{2}\left[(\Lambda z^{(i)})^T\Psi^{-1}\Lambda z^{(i)}-(x^{(i)}-\mu)^T\Psi^{-1}\Lambda z^{(i)}-(\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu)\right]
所以：
∇Λ∑i=1m−E[tr(12[(Λz(i))TΨ−1Λz(i)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)])]=∇Λ∑i=1m−E[12tr((Λz(i))TΨ−1Λz(i))−12tr((x(i)−μ)TΨ−1Λz(i))−12tr((Λz(i))TΨ−1(x(i)−μ))]=∑i=1m∇ΛE[−12tr(ΛTΨ−1Λz(i)(z(i))T)+tr(ΛTΨ−1(x(i)−μ)(z(i))T)](2)
\begin{align} &\nabla_\Lambda\sum_{i=1}^m-E\left[\operatorname{tr}\left(\frac{1}{2}\left[(\Lambda z^{(i)})^T\Psi^{-1}\Lambda z^{(i)}-(x^{(i)}-\mu)^T\Psi^{-1}\Lambda z^{(i)}-(\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu)\right]\right)\right] \\&\begin{split}=\nabla_\Lambda\sum_{i=1}^m-E\left[\frac{1}{2}\operatorname{tr}\left((\Lambda z^{(i)})^T\Psi^{-1}\Lambda z^{(i)}\right)-\frac{1}{2}\operatorname{tr}\left((x^{(i)}-\mu)^T\Psi^{-1}\Lambda z^{(i)}\right) \\-\frac{1}{2}\operatorname{tr}\left((\Lambda z^{(i)})^T\Psi^{-1}(x^{(i)}-\mu)\right)\right]\end{split} \\&=\sum_{i=1}^m\nabla_\Lambda E\left[-\frac{1}{2}\operatorname{tr}\left(\Lambda^T \Psi^{-1}\Lambda z^{(i)}(z^{(i)})^T\right)+\operatorname{tr}\left(\Lambda^T \Psi^{-1}(x^{(i)}-\mu)(z^{(i)})^T\right)\right]\tag{2} \end{align}
因为：
∇AtrABATC=CAB+CTABT
\nabla_A\operatorname{tr}ABA^TC=CAB+C^TAB^T
所以：
∇Atr(ΛTΨ−1Λz(i)(z(i))T)=z(i)(z(i))TΛTΨ−1+(z(i)(z(i))T)TΛT(Ψ−1)T=z(i)(z(i))TΛTΨ−1+((z(i))T)T(z(i))TΛTΨ−1=2z(i)(z(i))TΛTΨ−1
\begin{align} &\nabla_A\operatorname{tr}\left(\Lambda^T \Psi^{-1}\Lambda z^{(i)}(z^{(i)})^T\right)=z^{(i)}(z^{(i)})^T\Lambda^T \Psi^{-1}+(z^{(i)}(z^{(i)})^T)^T\Lambda^T(\Psi^{-1})^T \\&=z^{(i)}(z^{(i)})^T\Lambda^T \Psi^{-1}+((z^{(i)})^T)^T(z^{(i)})^T\Lambda^T\Psi^{-1}=2z^{(i)}(z^{(i)})^T\Lambda^T \Psi^{-1} \end{align}
代入公式2，可得：
∑i=1mE[−Ψ−1Λz(i)(z(i))T+Ψ−1(x(i)−μ)(z(i))T]
\sum_{i=1}^mE\left[-\Psi^{-1}\Lambda z^{(i)}(z^{(i)})^T+\Psi^{-1}(x^{(i)}-\mu)(z^{(i)})^T\right]
由上式等于0，可得：
∑i=1mΛEz(i)∼Qi[z(i)(z(i))T]=∑i=1m(x(i)−μ)Ez(i)∼Qi[(z(i))T]
\sum_{i=1}^m\Lambda E_{z^{(i)}\sim Q_i}\left[z^{(i)}(z^{(i)})^T\right]=\sum_{i=1}^m(x^{(i)}-\mu)E_{z^{(i)}\sim Q_i}\left[(z^{(i)})^T\right]
因此：
Λ=(∑i=1m(x(i)−μ)Ez(i)∼Qi[(z(i))T])(∑i=1mEz(i)∼Qi[z(i)(z(i))T])−1(3)
\Lambda=\left(\sum_{i=1}^m(x^{(i)}-\mu)E_{z^{(i)}\sim Q_i}\left[(z^{(i)})^T\right]\right)\left(\sum_{i=1}^m E_{z^{(i)}\sim Q_i}\left[z^{(i)}(z^{(i)})^T\right]\right)^{-1}\tag{3}
因为：
Cov(Y)=E[YYT]−E[Y]E[Y]T
\operatorname{Cov}(Y)=E[YY^T]-E[Y]E[Y]^T
所以：
E[YYT]=E[Y]E[Y]T+Cov(Y)
E[YY^T]=E[Y]E[Y]^T+\operatorname{Cov}(Y)
因此根据之前的讨论可得：
Ez(i)∼Qi[(z(i))T]=μTz(i)|x(i)
E_{z^{(i)}\sim Q_i}\left[(z^{(i)})^T\right]=\mu_{z^{(i)}\vert x^{(i)}}^T
Ez(i)∼Qi[z(i)(z(i))T]=μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i)
E_{z^{(i)}\sim Q_i}\left[z^{(i)}(z^{(i)})^T\right]=\mu_{z^{(i)}\vert x^{(i)}}\mu_{z^{(i)}\vert x^{(i)}}^T+\Sigma_{z^{(i)}\vert x^{(i)}}
将上式代入公式3，可得：
Λ=(∑i=1m(x(i)−μ)μTz(i)|x(i))(∑i=1m(μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i)))−1
\Lambda=\left(\sum_{i=1}^m(x^{(i)}-\mu)\mu_{z^{(i)}\vert x^{(i)}}^T\right)\left(\sum_{i=1}^m \left(\mu_{z^{(i)}\vert x^{(i)}}\mu_{z^{(i)}\vert x^{(i)}}^T+\Sigma_{z^{(i)}\vert x^{(i)}}\right)\right)^{-1}
这里需要注意的是，和之前的混合高斯模型相比，我们不仅要计算
Σz(i)|x(i)
\Sigma_{z^{(i)}\vert x^{(i)}}，还要计算
E[z]
E[z]和
E[zzT]
E[zz^T]。
此外，我们还可得出：（推导过程略）
μ=1m∑i=1mx(i)
\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}
Φ=1m∑i=1m(x(i)(x(i))T−x(i)μTz(i)|x(i)ΛT−Λμz(i)|x(i)(x(i))T+Λ(μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i))ΛT)
\begin{split}\Phi=\frac{1}{m}\sum_{i=1}^m\left(x^{(i)}(x^{(i)})^T-x^{(i)}\mu_{z^{(i)}\vert x^{(i)}}^T\Lambda^T-\Lambda\mu_{z^{(i)}\vert x^{(i)}}(x^{(i)})^T \\+\Lambda\left(\mu_{z^{(i)}\vert x^{(i)}}\mu_{z^{(i)}\vert x^{(i)}}^T+\Sigma_{z^{(i)}\vert x^{(i)}}\right)\Lambda^T\right)\end{split}
机器学习中的矩阵方法
在继续Andrew Ng的讲义之前，我们需要加强一些矩阵的相关知识。虽然Andrew Ng的讲义中已经包含了一个线性代数方面的简介文章，然而真的就只是简介而已，好多内容都没有。
这里推荐一本书《Matrix Methods in Data Mining and Pattern Recognition》。
作者：Lars Eld´en，执教于Linköping University数学系。
http://www.cnblogs.com/daniel-D/p/3204508.html
这是daniel-D写的中文笔记。
这一部分的内容属于数值计算领域，涉及的概念虽然不复杂，但提出一个高效算法，仍然不是件容易的事情。
还有另外一本书《Liner Algebra Done Right》，也值得推荐。这本书从定义矩阵算子，而不是通过行列式，来解释各种线性代数原理，提供了一种独特的视角。因为算子是有明确的几何或物理意义的，而行列式则不然。
作者：Sheldon Jay Axler，1949年生，美国数学家。普林斯顿大学本科，UCB博士，MIT博士后，San Francisco State University教授。美国的数学系基本就是本科和博士，很少有硕士。因为数学，尤其是理论数学，需要高度的抽象思维能力，半调子的硕士，既不好找工作，也不好搞科研。
三角矩阵的求逆问题
⎡⎣⎢l11l21l310l22l3200l33⎤⎦⎥⎡⎣⎢u1100u12u220u13u23u33⎤⎦⎥
\begin{bmatrix} l_{11} & 0 & 0 \\ l_{21} & l_{22} & 0 \\ l_{31} & l_{32} & l_{33} \\ \end{bmatrix} \begin{bmatrix} u_{11} & u_{12} & u_{13} \\ 0 & u_{22} & u_{23} \\ 0 & 0 & u_{33} \\ \end{bmatrix}
以3阶方阵为例，上面左边的矩阵被称为下三角矩阵（lower triangular matrix），而右边的矩阵被称为上三角矩阵（upper triangular matrix）。
对于矩阵求逆问题来说，下三角矩阵是一类比较简单的矩阵，求逆难度仅高于对角阵。
下三角矩阵的逆矩阵也是下三角矩阵，因此：
AA−1=⎡⎣⎢⎢⎢a11a21…an10a22…an2…………00…ann⎤⎦⎥⎥⎥⎡⎣⎢⎢⎢b11b21…bn10b22…bn2…………00…bnn⎤⎦⎥⎥⎥=⎡⎣⎢⎢⎢10…001…0…………00…1⎤⎦⎥⎥⎥
AA^{-1}=\begin{bmatrix} a_{11} & 0 & \dots & 0 \\ a_{21} & a_{22} & \dots & 0 \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \\ \end{bmatrix} \begin{bmatrix} b_{11} & 0 & \dots & 0 \\ b_{21} & b_{22} & \dots & 0 \\ \dots & \dots & \dots & \dots \\ b_{n1} & b_{n2} & \dots & b_{nn} \\ \end{bmatrix} =\begin{bmatrix} 1 & 0 & \dots & 0 \\ 0 & 1 & \dots & 0 \\ \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & 1 \\ \end{bmatrix}
由矩阵乘法定义，可得：
cij=∑k=jiaikbkj
c_{ij}=\sum_{k=j}^ia_{ik}b_{kj}
由
cij=1,i=j
c_{ij}=1,i=j，可得：
bii=1aii
b_{ii}=\frac{1}{a_{ii}}
由
cij=0,i≠j
c_{ij}=0,i\neq j，可得：
cij=∑k=ji−1aikbkj+aiibij=0
c_{ij}=\sum_{k=j}^{i-1}a_{ik}b_{kj}+a_{ii}b_{ij}=0
因此：
bij=−1aii∑k=ji−1aikbkj=−bii∑k=ji−1aikbkj
b_{ij}=-\frac{1}{a_{ii}}\sum_{k=j}^{i-1}a_{ik}b_{kj}=-b_{ii}\sum_{k=j}^{i-1}a_{ik}b_{kj}
上三角矩阵求逆，可通过转置转换成下三角矩阵求逆。这里会用到以下性质:
(AT)−1=(A−1)T
(A^T)^{-1}=(A^{-1})^T
LU分解
LU分解可将矩阵A分解为
A=LU
A=LU，其中L是下三角矩阵，U是上三角矩阵。
LU分解的用途很多，其中之一是求逆：
A−1=(LU)−1=U−1L−1
A^{-1}=(LU)^{-1}=U^{-1}L^{-1}
LU分解有若干种算法，常见的包括Doolittle、Cholesky、Crout算法。
注：Myrick Hascall Doolittlee，1830~1913。
Andr´e-Louis Cholesky，1875~1918，法国数学家、工程师、军官。死于一战战场。
Prescott Durand Crout，1907~1984，美国数学家，22岁获MIT博士。
这里只介绍一下Doolittle算法。
A=⎡⎣⎢⎢⎢a11a21…an1a12a22…an2…………a1na2n…ann⎤⎦⎥⎥⎥=LU=⎡⎣⎢⎢⎢1l21…ln101…ln2…………00…1⎤⎦⎥⎥⎥⎡⎣⎢⎢⎢u110…0u12u22…0…………u1nu2n…unn⎤⎦⎥⎥⎥
A=\begin{bmatrix} a_{11} & a_{12} & \dots & a_{1n} \\ a_{21} & a_{22} & \dots & a_{2n} \\ \dots & \dots & \dots & \dots \\ a_{n1} & a_{n2} & \dots & a_{nn} \\ \end{bmatrix}=LU= \begin{bmatrix} 1 & 0 & \dots & 0 \\ l_{21} & 1 & \dots & 0 \\ \dots & \dots & \dots & \dots \\ l_{n1} & l_{n2} & \dots & 1 \\ \end{bmatrix} \begin{bmatrix} u_{11} & u_{12} & \dots & u_{1n} \\ 0 & u_{22} & \dots & u_{2n} \\ \dots & \dots & \dots & \dots \\ 0 & 0 & \dots & u_{nn} \\ \end{bmatrix}
由矩阵乘法定义，可知：
a1j=u1j,j=1,2,…,n
a_{1j}=u_{1j},j=1,2,\dots,n
aij={∑jt=1litutj,∑i−1t=1litutj+uij,j<ij≥i
a_{ij}=\begin{cases} \sum_{t=1}^jl_{it}u_{tj}, & j<i \\ \sum_{t=1}^{i-1}l_{it}u_{tj}+u_{ij}, & j\ge i \\ \end{cases}
因此：
u1j=a1j,j=1,2,…,n
u_{1j}=a_{1j},j=1,2,\dots,n（U的第1行）
lj1=aj1/u11,j=1,2,…,n
l_{j1}=a_{j1}/u_{11},j=1,2,\dots,n（L的第1列）
For
i=2,3,…,n
i=2,3,\dots,n do
uii=aii−∑i−1t=1litutj
u_{ii}=a_{ii}-\sum_{t=1}^{i-1}l_{it}u_{tj}
uij=aij−∑i−1t=1litutj
u_{ij}=a_{ij}-\sum_{t=1}^{i-1}l_{it}u_{tj} for
j=i+1,…,n
j=i+1,\dots,n（U的第i行）
lji=aji−∑i−1t=1ljtutiuii
l_{ji}=\frac{a_{ji}-\sum_{t=1}^{i-1}l_{jt}u_{ti}}{u_{ii}} for
j=i+1,…,n
j=i+1,\dots,n（L的第i列）
End
unn=ann−∑n−1t=1lntutn
u_{nn}=a_{nn}-\sum_{t=1}^{n-1}l_{nt}u_{tn}
参见：
http://www3.nd.edu/~zxu2/acms40390F11/Alg-LU-Crout.pdf
QR分解
任意实数方阵A，都能被分解为
A=QR
A=QR。这里的Q为正交单位阵，即
QTQ=I
Q^TQ=I。R是一个上三角矩阵。这种分解被称为QR分解。
QR分解也有若干种算法，常见的包括Gram–Schmidt、Householder和Givens算法。
注：Jørgen Pedersen Gram，1850～1916，丹麦数学家，在矩阵、数论、泛函等领域皆有贡献。他居然是被自行车撞死的…
Erhard Schmidt，1876～1959，德国数学家，哥廷根大学博士，柏林大学教授。David Hilbert的学生。20世纪数学界的几位超级大神之一。1933年前的哥廷根大学数学系，秒杀其他所有学校。所谓“一流的学生去哥廷根，智商欠费才去藤校”。
Alston Scott Householder，1904～1993，美国数学家，芝加哥大学博士，田纳西大学教授。ACM主席。
James Wallace Givens, Jr.，1910～1993，美国数学家，普林斯顿大学博士，西北大学教授。参与UNIVAC I机器项目（1951年），这是最早的商用计算机。
这里只介绍Gram–Schmidt算法，这个算法虽然名为Gram–Schmidt，然而拉普拉斯和柯西早就已经用过了。
首先介绍一下向量的投影运算的符号表示。
如上图所示，根据余弦定理和向量点乘的定义可得：
a⋅b=|a||b|cosθ
a\cdot b=|a||b|\cos \theta
因此，向量a在向量b上的投影向量
a1
a_1，可表示为：
a1=|a|cosθb^=|a|a⋅b|a||b|b|b|=a⋅b|b|2b=a⋅bb⋅bb=⟨a,b⟩⟨b,b⟩b
a_1=|a|\cos \theta\hat b=|a|\frac{a\cdot b}{|a||b|}\frac{b}{|b|}=\frac{a\cdot b}{|b|^2}b=\frac{a\cdot b}{b\cdot b}b=\frac{\langle a,b\rangle}{\langle b,b\rangle}b
特别的，当b为单位向量时：
a1=⟨a,b⟩(4)
a_1=\langle a,b\rangle\tag{4}
我们定义投影符号如下：
projea=⟨e,a⟩⟨e,e⟩e
\mathrm{proj}_{\mathbf{e}}\mathbf{a} = \frac{\left\langle\mathbf{e},\mathbf{a}\right\rangle}{\left\langle\mathbf{e},\mathbf{e}\right\rangle}\mathbf{e}