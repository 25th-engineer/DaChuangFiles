自然语言处理研究的内容包括但不限于如下分支领域：文本分类、信息抽取、自动摘要、智能问答、话题推荐、机器翻译、主题词识别、知识库构建、深度文本表示、命名实体识别、文本生成、文本分析（词法、句法、语法）、语音识别与合成等。下面给出一些分支领域的详细介绍：
文本分类
文本分类用计算机设备对文本集(或其他实体或物件)按照一定的分类体系或标准进行自动分类标记。
定义
基于分类体系的自动分类
基于资讯过滤和用户兴趣(Profiles)的自动分类
所谓分类体系就是针对词的统计来分类
关键字分类，现在的全文检索
词的正确切分不易分辨（白痴造句法）
学习人类对文本分类的知识和策略
从人对文本和类别之间相关性判断来学习文件用字和标记类别之间的关联
过程
文本分类一般包括了文本的表达、 分类器的选择与训练、 分类结果的评价与反馈等过程，其中文本的表达又可细分为文本预处理、索引和统计、特征抽取等步骤。文本分类系统的总体功能模块为：
（1）预处理：将原始语料格式化为同一格式，便于后续的统一处理；
（2）索引：将文档分解为基本处理单元，同时降低后续处理的开销；
（3）统计：词频统计，项（单词、概念）与分类的相关概率；
（4）特征抽取：从文档中抽取出反映文档主题的特征；
（5）分类器：分类器的训练；
（6）评价：分类器的测试结果分析。
方法
※ 词匹配法
※ 知识工程
※ 统计学习
※ 分类算法
现如今，统计学习方法已经成为了文本分类领域绝对的主流。主要的原因在于其中的很多技术拥有坚实的理论基础（相比之下，知识工程方法中专家的主观因素居多），存在明确的评价标准，以及实际表现良好。统计分类算法将样本数据成功转化为向量表示之后，计算机才算开始真正意义上的“学习”过程。常用的分类算法为：
决策树，Rocchio，朴素贝叶斯，神经网络，支持向量机，线性最小平方拟合，kNN，遗传算法，最大熵，Generalized Instance Set等。
基于资讯过滤和用户兴趣(Profiles)的自动分类
所谓分类体系就是针对词的统计来分类
关键字分类，现在的全文检索
词的正确切分不易分辨（白痴造句法）
学习人类对文本分类的知识和策略
从人对文本和类别之间相关性判断来学习文件用字和标记类别之间的关联
信息抽取
信息抽取（Information Extraction: IE）是把文本里包含的信息进行结构化处理，变成表格一样的组织形式。输入信息抽取系统的是原始文本，输出的是固定格式的信息点。信息点从各种各样的文档中被抽取出来，然后以统一的形式集成在一起。这就是信息抽取的主要任务。信息以统一的形式集成在一起的好处是方便检查和比较。信息抽取技术并不试图全面理解整篇文档，只是对文档中包含相关信息的部分进行分析。至于哪些信息是相关的，那将由系统设计时定下的领域范围而定。
简介
信息抽取技术对于从大量的文档中抽取需要的特定事实来说是非常有用的。互联网上就存在着这么一个文档库。在网上，同一主题的信息通常分散存放在不同网站上，表现的形式也各不相同。若能将这些信息收集在一起，用结构化形式储存，那将是有益的。
由于网上的信息载体主要是文本，所以，信息抽取技术对于那些把因特网当成是知识来源的人来说是至关重要的。信息抽取系统可以看作是把信息从不同文档中转换成数据库记录的系统。因此，成功的信息抽取系统将把互联网变成巨大的数据库！
挑战
信息抽取技术是近十年来发展起来的新领域，遇到许多新的挑战。
信息抽取原来的目标是从自然语言文档中找到特定的信息，是自然语言处理领域特别有用的一个子领域。所开发的信息抽取系统既能处理含有表格信息的结构化文本，又能处理自由式文本（如新闻报道）。IE系统中的关键组成部分是一系列的抽取规则或模式，其作用是确定需要抽取的信息。网上文本信息的大量增加导致这方面的研究得到高度重视。
纯文本抽出通用程序库
DMCTextFilter V4.2是HYFsoft推出的纯文本抽出通用程序库，DMCTextFilter可以从各种各样的文档格式的数据中或从插入的OLE对象中，完全除掉特殊控制信息，快速抽出纯文本数据信息。便于用户实现对多种文档数据资源信息进行统一管理，编辑，检索和浏览。
DMCTextFilter采用了先进的多语言、多平台、多线程的设计理念，支持多国语言（英语，中文简体，中文繁体，日本语，韩国语），多种操作系统（Windows，Solaris，Linux，IBM AIX，Macintosh，HP-UNIX），多种文字集合代码（GBK，GB18030，Big5，ISO-8859-1，KS X 1001，Shift_JIS，WINDOWS31J，EUC-JP，ISO-10646-UCS-2，ISO-10646-UCS-4，UTF-16，UTF-8等）。提供了多种形式的API功能接口（文件格式识别函数，文本抽出函数，文件属性抽出函数，页抽出函数，设定User Password的PDF文件的文本抽出函数等），便于用户方便使用。用户可以十分便利的将本产品组装到自己的应用程序中，进行二次开发。通过调用本产品的提供的API功能接口，实现从多种文档格式的数据中快速抽出纯文本数据。
文件格式自动识别功能
本产品通过解析文件内部的信息，自动识别生成文件的应用程序名和其版本号，不依赖于文件的扩展名，能够正确识别文件格式和相应的版本信息。可以识别的文件格式如下：支持Microsoft Office、RTF、PDF、Visio、OutlookEML和MSG、Lotus1-2-3、HTML、AutoCAD DXF和DWG、IGES、PageMaker、ClarisWorks、AppleWorks、XML、WordPerfect、Mac Write、Works、CorelPresentations、QuarkXpress、DocuWorks、WPS、压缩文件的LZH/ZIP/RAR以及一太郎、OASYS等文件格式
文本抽出功能
即使系统中没有安装作成文件的应用程序，可以从指定的文件或插入到文件中的OLE中抽出文本数据。
文件属性抽出功能
从指定的文件中，抽出文件属性信息。
页抽出功能
从文件中，抽出指定页中文本数据。
对加密的PDF文件文本抽出功能
从设有打开文档口令密码的PDF文件中抽出文本数据。
流(Stream)抽出功能
从指定的文件、或是嵌入到文件中的OLE对象中向流里抽取文本数据。
支持的语言种类
本产品支持以下语言：英语，中文简体，中文繁体，日本语，韩国语
支持的字符集合的种类
抽出文本时，可以指定以下的字符集合作为文本文件的字符集(也可指定任意特殊字符集，但需要另行定制开发)：GBK，GB18030，Big5，ISO-8859-1，KS X 1001，Shift_JIS，WINDOWS31J，EUC-JP，ISO-10646-UCS-2，ISO-10646-UCS-4，UTF-16，UTF-8等。
自动文本摘要
自动文本摘要是利用计算机自动地从原始文献中提取文摘，文摘是全面准确地反映某一文献中心内容地简单连贯的短文。常用方法是自动摘要将文本作为句子的线性序列，将句子视为词的线性序列。
类型
技术应用类型：
·自动提取给定文章的摘要信息
·自动计算文章中词的权重
·自动计算文章中句子的权重
提取
·单篇文章的摘要自动提取
·大规模文档的摘要自动提取
·基于分类的摘要自动提取
智能问答系统
智能问答系统以一问一答形式，精确的定位网站用户所需要的提问知识，通过与网站用户进行交互，为网站用户提供个性化的信息服务。
介绍
智能问答系统是将积累的无序语料信息，进行有序和科学的整理，并建立基于知识的分类模型；这些分类模型可以指导新增加的语料咨询和服务信息，节约人力资源，提高信息处理的自动性，降低网站运行成本。基于对网站多年积累的关于政府和企业的基本情况常见问题及其解答，整理为规范的问答库形式，以支撑各种形式问题的智能问答。方便了用户，提高了办事效率，提升了企业形象。
应用场景
相关问答推送
当网站用户提出问题时，系统不仅将问题答案推送出来，而且会将与这个问题相关的知识也都推送出来供用户查询，这样就做到了一次提问全面掌握所有信息。
提问智能提示
用户在提问的过程中, 系统将已经输入的内容自动分析给予优化的补全或相关提示。
焦点问题自动排行
对在一定的时间内，用户对知识提问的热度，系统自动聚焦，并按照访问频度将热点知识集中在系统页面上显示；具体类别的知识也按照访问频度排序，在页面知识类别栏目中显示。
热点词聚焦
系统对用户提交的业务关键词进行统计，并按照访问的频度进行聚焦，将与关键词相关的业务列表自动链接，形成业务热点关键词。
在线客服问答
模拟在线客服人员，以网站智能客服形式完成客服作用。
引导式交互客服服务
将常见问题整理成若干流程诊断型的知识，通过引导交互式地服务，尽量从Web端解决客户常见问题。
客服座席协助
完成专家坐席功能，在普通坐席人员无法回答问题时提供标准化的知识协助，帮助普通客服人员快速，准确回答。
转人工客服
用户可以直接在智能咨询服务系统中连接人工客服人员，向客服人员进行在线咨询。
话题推荐
话题推荐只是推荐系统的一个小小的应用分支，下面主要通过介绍推荐系统来了解话题推荐的大致内容。
背景
现在社会的信息过载，为了更好的对过载的信息进行有效的过滤。
推荐系统
推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程。个性化推荐是根据用户的兴趣特点和购买行为，向用户推荐用户感兴趣的信息和商品。现在的应用领域更为广泛，比如今日头条的新闻推荐，购物平台的商品推荐，直播平台的主播推荐，知乎上的话题推荐等等。
定义
推荐系统有3个重要的模块：用户建模模块、推荐对象建模模块、推荐算法模块。推荐系统把用户模型中兴趣需求信息和推荐对象模型中的特征信息匹配，同时使用相应的推荐算法进行计算筛选，找到用户可能感兴趣的推荐对象，然后推荐给用户。
常用推荐方法
基于内容推荐
基于内容的推荐（Content-based Recommendation）是信息过滤技术的延续与发展，它是建立在项目的内容信息上作出推荐的，而不需要依据用户对项目的评价意见，更多地需要用机器学习的方法从关于内容的特征描述的事例中得到用户的兴趣资料。在基于内容的推荐系统中，项目或对象是通过相关的特征的属性来定义，系统基于用户评价对象的特征，学习用户的兴趣，考察用户资料与待预测项目的相匹配程度。用户的资料模型取决于所用学习方法，常用的有决策树、神经网络和基于向量的表示方法等。基于内容的用户资料是需要有用户的历史数据，用户资料模型可能随着用户的偏好改变而发生变化。
基于内容推荐方法的优点是：
1）不需要其它用户的数据，没有冷开始问题和稀疏问题。
2）能为具有特殊兴趣爱好的用户进行推荐。
3）能推荐新的或不是很流行的项目，没有新项目问题。
4）通过列出推荐项目的内容特征，可以解释为什么推荐那些项目。
5）已有比较好的技术，如关于分类学习方面的技术已相当成熟。
缺点是要求内容能容易抽取成有意义的特征，要求特征内容有良好的结构性，并且用户的口味必须能够用内容特征形式来表达，不能显式地得到其它用户的判断情况。
基于用户的系统过滤推荐过程
协同过滤推荐（Collaborative Filtering Recommendation）技术是推荐系统中应用最早和最为成功的技术之一。它一般采用最近邻技术，利用用户的历史喜好信息计算用户之间的距离，然后 利用目标用户的最近邻居用户对商品评价的加权评价值来预测目标用户对特定商品的喜好程度，系统从而根据这一喜好程度来对目标用户进行推荐。协同过滤最大优 点是对推荐对象没有特殊的要求，能处理非结构化的复杂对象，如音乐、电影。
协同过滤是基于这样的假设：为一用户找到他真正感兴趣的内容的好方法是首先找到与此用户有相似兴趣的其他用户，然后将他们感兴趣的内容推荐给此用户。其基本思想非常易于理解，在日常生活中，我们往往会利用好朋友的推荐来进行一些选择。协同过滤正是把这一思想运用到电子商务推荐系统中来，基于其他用户对某一内容的评价来向目标用户进行推荐。
基于协同过滤的推荐系统可以说是从用户的角度来进行相应推荐的，而且是自动的即用户获得的推荐是系统从购买模式或浏览行为等隐式获得的，不需要用户努力地找到适合自己兴趣的推荐信息，如填写一些调查表格等。
和基于内容的过滤方法相比，协同过滤具有如下的优点：
1）能够过滤难以进行机器自动内容分析的信息，如艺术品，音乐等。
2）共享其他人的经验，避免了内容分析的不完全和不精确，并且能够基于一些复杂的，难以表述的概念（如信息质量、个人品味）进行过滤。
3）有推荐新信息的能力。可以发现内容上完全不相似的信息，用户对推荐信息的内容事先是预料不到的。这也是协同过滤和基于内容的过滤一个较大的差别，基于内容的过滤推荐很多都是用户本来就熟悉的内容，而协同过滤可以发现用户潜在的但自己尚未发现的兴趣偏好。
4）能够有效的使用其他相似用户的反馈信息，较少用户的反馈量，加快个性化学习的速度。
虽然协同过滤作为一种典型的推荐技术有其相当的应用，但协同过滤仍有许多的问题需要解决。最典型的问题有稀疏问题（Sparsity）和可扩展问题（Scalability）。
基于关联规则推荐
基于关联规则的推荐（Association Rule-based Recommendation）是以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。关联规则挖掘可以发现不同商品在销售过程中的相关性，在零售业中已经得到了成功的应用。管理规则就是在一个交易数据库中统计购买了商品集X的交易中有多大比例的交易同时购买了商品集Y，其直观的意义就是用户在购买某些商品的时候有多大倾向去购买另外一些商品。比如购买牛奶的同时很多人会同时购买面包。
算法的第一步关联规则的发现最为关键且最耗时，是算法的瓶颈，但可以离线进行。其次，商品名称的同义性问题也是关联规则的一个难点。
基于效用推荐
基于效用的推荐（Utility-based Recommendation）是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性（Vendor Reliability）和产品的可得性（Product Availability）等考虑到效用计算中。
基于知识推荐
基于知识的推荐（Knowledge-based Recommendation）在某种程度是可以看成是一种推理（Inference）技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。效用知识（Functional Knowledge）是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。
组合推荐
由于各种推荐方法都有优缺点，所以在实际中，组合推（HybridRecommendation）经常被采用。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。
在组合方式上，有研究人员提出了七种组合思路：
1）加权（Weight）：加权多种推荐技术结果。
2）变换（Switch）：根据问题背景和实际情况或要求决定变换采用不同的推荐技术。
3）混合（Mixed）：同时采用多种推荐技术给出多种推荐结果为用户提供参考。
4）特征组合（Feature combination）：组合来自不同推荐数据源的特征被另一种推荐算法所采用。
5）层叠（Cascade）：先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。
6）特征扩充（Feature augmentation）：一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。
7）元级别（Meta-level）：用一种推荐方法产生的模型作为另一种推荐方法的输入。
体系结构
服务器端推荐系统
推荐系统的体系结构研究的重要问题就是用户信息收集和用户描述文件放在什么地方，服务器还是客户机上，或者是处于二者之间的代理服务器上。
最初的推荐系统都是基于服务器端的推荐系统。在这类推荐系统中，推荐系统与Web服务器一般共享一台硬件设备。在逻辑上，推荐系统要的用户信息收集和建模都依赖于Web服务器。
由此可知，基于服务器端的推荐系统存在的问题主要包括：
（1）个性化信息的收集完全由Web服务器来完成，受到了Web服务器功能的限制。
（2）增加了Web服务器的系统开销。
（3）对用户的隐私有极大威胁。无论是推荐系统的管理者还是入侵推荐系统的人员都能方便地获取存放在服务器上的用户数据。由于用户的个人数据是有很高价值的，接触到用户数据的部分人会出卖用户数据或把用户数据用于非法用途。
客户端推荐系统
基于客户端推荐系统：典型的客户端个性化服务系统有斯坦福大学的LIRA、麻省理工学院的Letizia、加州大学的Syskill&Webert、卡内基·梅隆大学的PersonalWeb-Watcher等。
基于客户端的推荐系统有如下优点：
（1）由于用户的信息就在本地收集和处理，因而不但能够获取丰富准确的用户信息以构建高质量的用户模型。
（2）少量甚至没有用户数据存放在服务器上，Web服务器不能访问和控制用户的数据，能比较好地保护用户的隐私。
（3）用户更愿意向推荐系统提供个人信息，从而提高推荐系统的推荐性能。因为基于客户端的推荐系统中的用户数据存储在用户本地客户机上，用户对数据能够进行自行控制。
基于客户端的推荐系统有一定缺点：
（1）用户描述文件的形成、推荐策略的应用都依赖于所有用户数据分析的基础上进行的，而基于客户端的推荐系统较难获取其他用户的数据，用户描述文件较难得到，协同推荐策略实施也较难，所以推荐系统要重新设计，尤其是推荐策略必须进行修改。
（2）个性化推荐处理过程中用户的数据资料还需要部分的传给服务器，存在隐私泄漏的危险，需要开发安全传输平台进行数据传输。
知名团队
明尼苏达大学GroupLens（John Riedl, Joseph A.Konstan）
密西根大学（Paul Resnick）
卡内基梅隆大学（JaimeCallan）
微软研究院（Ryen W.White）
纽约大学（Alexander Tuzhilin）
百分点科技团队（Baifendian）
机器翻译
机器翻译又称为自动翻译，是利用计算机将一种自然语言(源语言)转换为另一种自然语言(目标语言)的过程。它是计算机语言学的一个分支，是人工智能的终极目标之一，具有重要的科学研究价值。
基础
机器翻译技术的发展一直与计算机技术、信息论、语言学等学科的发展紧密相随。从早期的词典匹配，到词典结合语言学专家知识的规则翻译，再到基于语料库的统计机器翻译，随着计算机计算能力的提升和多语言信息的爆发式增长，机器翻译技术逐渐走出象牙塔，开始为普通用户提供实时便捷的翻译服务。
类别
·基于规则的机译系统
·基于统计
·基于人工神经网络
·在线机译
主题词识别
主题词识别应该是主题词提取的研究内容，通过对各类文本经过主题模型算法得到文本的主题词，对文本主题词进行分析和识别来实现对基于内容的文本匹配等功能。主要还是基于文本处理的基本方法：TF-IDF的文本表示，向量的文本表示方法，文本分词技术，主题模型等来提取主题词。
如有理解上的错误请指正，如以后有新的理解会有所改进。
知识库构建
知识库是用于指示管理的一种特殊的数据库，以便于有关领域只是的采集、整理以及提取。知识库中的知识源于领域专家它是求解问题所需领域知识的集合，包括基本事实、规则和其它有关信息。
现有知识库的构建常以本体论作为基础知识。本体论基础知识详见本体论研究综述论文的总结。
特点
1）知识库中的知识根据它们的应用领域特征、背景特征（获取时的背景信息）、使用特征、属性特征等而被构成便于利用的、有结构的组织形式。知识片一般是模块化的。
2）知识库的知识是有层次的。最低层是“事实知识”，中间层是用来控制“事实”的知识（通常用规则、过程等表示）；最高层次是“策略”，它以中间层知识为控制对象。策略也常常被认为是规则的规则。因此知识库的基本结构是层次结构，是由其知识本身的特性所确定的。在知识库中，知识片间通常都存在相互依赖关系。规则是最典型、最常用的一种知识片。
3）知识库中可有一种不只属于某一层次（或者说在任一层次都存在）的特殊形式的知识——可信度（或称信任度，置信测度等）。对某一问题，有关事实、规则和策略都可标以可信度。这样，就形成了增广知识库。在数据库中不存在不确定性度量。因为在数据库的处理中一切都属于“确定型”的。
4）知识库中还可存在一个通常被称作典型方法库的特殊部分。如果对于某些问题的解决途径是肯定和必然的，就可以把其作为一部分相当肯定的问题解决途径直接存储在典型方法库中。这种宏观的存储将构成知识库的另一部分。在使用这部分时，机器推理将只限于选用典型方法库中的某一层体部分。
功能
1.知识库使信息和知识有序化，是知识库对组织的首要贡献。
2.知识库加快知识和信息的流动，有利于知识共享与交流。
3.知识库还有利于实现组织的协作与沟通。
4.知识库可以帮助企业实现对客户知识的有效管理。
缺陷
不完整性
⒈悬挂条件
如果该规则的任意前提条件都不出现在数据库中，也不出现在所有规则的结论部分，则该规则永远不会被激活。
2.无用结论
如果一个规则结论部分的谓词没有在知识库中任何规则的前提条件中出现，该谓词称为无用条件。
3.孤立规则
如果一个规则前提部分的谓词都是悬挂条件，并且其结论部分的谓词都是无用结论，则称该规则为孤立的。
不一致性
⒈冗余规则
⒉包含规则
⒊循环规则
⒋冲突规则
文本表示
要使得计算机能高效的处理真实文本，就必须找到一种理想的形式化表示方法，这种表示一方面能真实的反映文档内容(主题、领域或结构等)，另一方面也要有对不同文档的区分能力。
随着对文本处理的要求越来越高，在对文本表示的的形式上的研究也在不断的进步和发展，下面给出一些常用的基于文本内容的表示方法：（以后补充基于行为的表示）
传统的方法
（1）one hot encoding
入门级文本表示方法，应用词袋模型（BOW）+ TF-IDF技术，优点是简单粗暴配合LR效果也不赖，缺点也明显，维度太高且有词义鸿沟问题，不适合大语料。
（2）主题模型系列
1）LSA/LSI：将文档为行，词为列，表示成“文档-词”大矩阵，利用SVD（奇异值分解）矩阵分解的实现技术，训练得到词和文档的特征向量，有点儿像推荐里的隐语义模型，模型忽略了语序，更注重主题相关，适合长文本，实际使用效果还不错。
2）LDA：比较适合长文本表示，不太适合短文本表示。LDA属于一种文档主题生成模型，引用其他博客的话：“LDA认为一篇文档的每个词都是通过“以一定概率选择了某个主题，并从这个主题中以一定概率选择某个词语”这样一个过程得到的，文档到主题服从多项式分布，主题到词语服从多项式分布”。
深度表示（NN：神经网络）
（1）word2vec + TF-IDF加权平均
虽然word2vec非DNN系列，但其训练词向量效率和效果均表现不俗。首先通过word2vec训练词向量，再通过简单的词加权/关键tag加权/tf-idf加权平均得到文档向量表示。在加权之前做停用词剔除、词聚类等预处理是个不错的选择。（PS：该方法对短文本效果还可以，长文本就不咋地了。kaggle101中的一个word2vec题目的tutorial里作者如是说：他试了一下简单加权和各种加权，不管如何处理，效果还不如01，归其原因作者认为加权的方式丢失了最重要的句子结构信息和词相关信息（也可以说是词序信息），而doc2vec的方法则保存了这种信息。）
（2）doc2vec
提到word2vec就不得的不提doc2vec，二者亲兄弟，doc2vec在word2vec基础上增加了个段落向量，能直接训练处（段落）文档向量，在实际使用中，貌似效果一般，特别是长文本NLP相关任务。（PS：gensim有现成的API）。参考：2014 ICML《Distributed Representations of Sentences and Documents》
（3）WMD
ICML2015的论文《From Word Embeddings To Document Distances, Kusner, Washington University》新提出一种计算doc相似度的方式，大致思路是将词之间的
余弦距离作为ground distance，词频作为权重，在权重的约束条件下，求WMD的线性规划最优解。
（4）glove
最近学术界兴起了glove的方法，核心思想就是挖掘词语共现信息的内在含义，融合基于全局统计的方法（如LSI/LSA等）和基于局部预测方法（如word2vec等）于一体，貌似效果不错，在词聚类任务上的效果超越了word2vec。PS：《GloVe: Global Vectors forWord Representation》
命名实体识别
命名实体识别（Named Entity Recognition，简称NER），又称作“专名识别”，是指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等。
作用
命名实体识别是信息提取、问答系统、句法分析、机器翻译、面向Semantic Web的元数据标注等应用领域的重要基础工具，在自然语言处理技术走向实用化的过程中占有重要地位。一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。
过程
通常包括两部分：（1）实体边界识别；（2） 确定实体类别（人名、地名、机构名或其他）。英语中的命名实体具有比较明显的形式标志（即实体中的每个词的第一个字母要大写），所以实体边界识别相对容易，任务的重点是确定实体的类别。和英语相比，汉语命名实体识别任务更加复杂，而且相对于实体类别标注子任务，实体边界的识别更加困难。
难点
（1）汉语文本没有类似英文文本中空格之类的显式标示词的边界标示符，命名实体识别的第一步就是确定词的边界，即分词；
（2）汉语分词和命名实体识别互相影响；
（3）除了英语中定义的实体，外国人名译名和地名译名是存在于汉语中的两类特殊实体类型；
（4）现代汉语文本，尤其是网络汉语文本，常出现中英文交替使用，这时汉语命名实体识别的任务还包括识别其中的英文命名实体；
（5）不同的命名实体具有不同的内部特征，不可能用一个统一的模型来刻画所有的实体内部特征。
文本分析
介绍
文本分析是指对文本的表示及其特征项的选取；文本分析是文本挖掘、信息检索的一个基本问题，它把从文本中抽取出的特征词进行量化来表示文本信息。文本（text），与讯息（message）的意义大致相同，指的是有一定的符号或符码组成的信息结构体，这种结构体可采用不同的表现形态，如语言的、文字的、影像的等等。文本是由特定的人制作的，文本的语义不可避免地会反映人的特定立场、观点、价值和利益。因此，由文本内容分析，可以推断文本提供者的意图和目的。
特征
将它们从一个无结构的原始文本转化为结构化的计算机可以识别处理的信息，即对文本进行科学的抽象，建立它的数学模型，用以描述和代替文本。使计算机能够通过对这种模型的计算和操作来实现对文本的识别。由于文本是非结构化的数据,要想从大量的文本中挖掘有用的信息就必须首先将文本转化为可处理的结构化形式。目前人们通常采用向量空间模型来描述文本向量,但是如果直接用分词算法和词频统计方法得到的特征项来表示文本向量中的各个维,那么这个向量的维度将是非常的大。这种未经处理的文本矢量不仅给后续工作带来巨大的计算开销,使整个处理过程的效率非常低下,而且会损害分类、聚类算法的精确性,从而使所得到的结果很难令人满意。因此,必须对文本向量做进一步净化处理,在保证原文含义的基础上,找出对文本特征类别最具代表性的文本特征。为了解决这个问题,最有效的办法就是通过特征选择来降维。
目前有关文本表示的研究主要集中于文本表示模型的选择和特征词选择算法的选取上。用于表示文本的基本单位通常称为文本的特征或特征项。特征项必须具备一定的特性:
1)特征项要能够确实标识文本内容;
2)特征项具有将目标文本与其他文本相区分的能力;
3)特征项的个数不能太多;
4)特征项分离要比较容易实现。
在中文文本中可以采用字、词或短语作为表示文本的特征项。相比较而言，词比字具有更强的表达能力，而词和短语相比，词的切分难度比短语的切分难度小得多。因此，目前大多数中文文本分类系统都采用词作为特征项，称作特征词。这些特征词作为文档的中间表示形式，用来实现文档与文档、文档与用户目标之间的相似度计算 。如果把所有的词都作为特征项，那么特征向量的维数将过于巨大，从而导致计算量太大，在这样的情况下，要完成文本分类几乎是不可能的。特征抽取的主要功能是在不损伤文本核心信息的情况下尽量减少要处理的单词数，以此来降低向量空间维数，从而简化计算，提高文本处理的速度和效率。文本特征选择对文本内容的过滤和分类、聚类处理、自动摘要以及用户兴趣模式发现、知识发现等有关方面的研究都有非常重要的影响。通常根据某个特征评估函数计算各个特征的评分值，然后按评分值对这些特征进行排序，选取若干个评分值最高的作为特征词，这就是特征选择(Feature Selection)。
特征选取的方式常见的有4种：
(1)用映射或变换的方法把原始特征变换为较少的新特征。
(2)从原始特征中挑选出一些最具代表性的特征。
(3)根据专家的知识挑选最有影响的特征。
(4)用数学的方法进行选取，找出最具分类信息的特征，这种方法是一种比较精确的方法，人为因素的干扰较少，尤其适合于文本自动分类挖掘系统的应用。
以后会补充一篇结合《自然语言处理综述》这本书，从词法、句法、语法、语用方面来介绍文本分析。
句法分析
句法分析：(Parsing)就是指对句子中的词语语法功能进行分析，比如“我来晚了”，这里“我”是主语，“来”是谓语，“晚了”是补语。
应用
句法分析现在主要的应用在于中文信息处理中，如机器翻译等。它是语块分析（chunking）思想的一个直接实现，语块分析通过识别出高层次的结构单元来简化句子的描述。从不同的句子中找到语块规律的一条途径是学习一种语法，这种语法能够解释我们所找到的分块结构。这属于语法归纳的范畴。
迄今为止，在句法分析领域中存在很多争议，也许你会发现恰巧有人提出了与你正在努力研究的语法归纳程序偶然产生的相似的句法结构，而且这些也可能已经被当成了句法结构模型的证据。但是，这些找到的结构依赖于学习程序中隐含的归纳偏置。这也指明了另外一个方向，我们需要事先知道模型能够找到什么样的结构，同时应该首先确定我们对句子进行句法分析的目的。这里有各种可能的目的：使用句法结构作为语义解释的第一步；识别短语语块，为信息检索系统的索引服务；构建一个概率句法分析器作为一个优于n元语法的语言模型。这些问题的共同目标是构建这样的一个系统：对于任意的句子都能够主产生证明有用的结构，也就是要构建一个句法分析器。
句法分析的三种不同的途径可以利用概率：
1、利用概率来确定句子：一种可能的做法是将句法分析器看成是一个词语网络上的语言模型，用来确定什么样的词序列经过网络的时候会获得最大概率。
2、利用概率来加速语法分析： 第二个目标是利用概率对句法分析器的搜索空间进行排序或剪枝。这使得句法分析器能够在不影响结果质量的情况下尽快找到最优的分析途径。
3、利用概率选择句法分析结果： 句法分析器可以从输入句子的众多分析结果中选择可能性最大的。
语音识别技术
语音识别技术，也被称为自动语音识别Automatic Speech Recognition，(ASR)，其目标是将人类的语音中的词汇内容转换为计算机可读的输入，例如按键、二进制编码或者字符序列。
简介
语音识别技术的应用包括语音拨号、语音导航、室内设备控制、语音文档检索、简单的听写数据录入等。语音识别技术与其他自然语言处理技术如机器翻译及语音合成技术相结合，可以构建出更加复杂的应用，例如语音到语音的翻译。
语音识别技术所涉及的领域包括：信号处理、模式识别、概率论和信息论、发声机理和听觉机理、人工智能等等。
语音识别技术和语音合成技术是比较大的两个研究分支，涉及的内容比较多、比较广，在此不做过多的介绍。如有可能，以后补充。