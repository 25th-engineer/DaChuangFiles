----------欢迎加入学习交流QQ群：657341423
SnowNLP是一个python写的类库,可以方便的处理中文文本内容。如
中文分词
词性标注
情感分析
文本分类
提取文本关键词
文本相似度计算
安装：pip install snownlp
完成snownlp安装后，查看模块的目录结构，如图所示
normal：文字转换成拼音
seg：中文分词
sentiment：情感分析
sim：文本相似度
summary：提取文本摘要
tag：词性标注
__init__.py：整个模块的函数方法
想了解snownlp，可以打开 __init__.py 查看snownlp提供的方法函数
# -*- coding: utf-8 -*- from __future__ import unicode_literals from . import normal from . import seg from . import tag from . import sentiment from .sim import bm25 from .summary import textrank from .summary import words_merge class SnowNLP(object): def __init__(self, doc): self.doc = doc self.bm25 = bm25.BM25(doc) @property def words(self): return seg.seg(self.doc) @property def sentences(self): return normal.get_sentences(self.doc) @property def han(self): return normal.zh2hans(self.doc) @property def pinyin(self): return normal.get_pinyin(self.doc) @property def sentiments(self): return sentiment.classify(self.doc) @property def tags(self): words = self.words tags = tag.tag(words) return zip(words, tags) @property def tf(self): return self.bm25.f @property def idf(self): return self.bm25.idf def sim(self, doc): return self.bm25.simall(doc) def summary(self, limit=5): doc = [] sents = self.sentences for sent in sents: words = seg.seg(sent) words = normal.filter_stop(words) doc.append(words) rank = textrank.TextRank(doc) rank.solve() ret = [] for index in rank.top_index(limit): ret.append(sents[index]) return ret def keywords(self, limit=5, merge=False): doc = [] sents = self.sentences for sent in sents: words = seg.seg(sent) words = normal.filter_stop(words) doc.append(words) rank = textrank.KeywordTextRank(doc) rank.solve() ret = [] for w in rank.top_index(limit): ret.append(w) if merge: wm = words_merge.SimpleMerge(self.doc, ret) return wm.merge() return ret
整个snownlp模块就提供这些方法函数给我们使用，具体的使用方式以官方文档为例
from snownlp import SnowNLP s = SnowNLP(u'这个东西真心很赞') # 分词 s.words # [u'这个', u'东西', u'真心', # u'很', u'赞'] # 词语标注 s.tags # [(u'这个', u'r'), (u'东西', u'n'), # (u'真心', u'd'), (u'很', u'd'), # (u'赞', u'Vg')] # 情感分析 s.sentiments # 0.9769663402895832 positive的概率 # 转换拼音 s.pinyin # [u'zhe', u'ge', u'dong', u'xi', # u'zhen', u'xin', u'hen', u'zan'] s = SnowNLP(u'「繁體字」「繁體中文」的叫法在臺灣亦很常見。') # 转换简体 s.han # u'「繁体字」「繁体中文」的叫法 # 在台湾亦很常见。' text = u''' 自然语言处理是计算机科学领域与人工智能领域中的一个重要方向。 它研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。 自然语言处理是一门融语言学、计算机科学、数学于一体的科学。 因此，这一领域的研究将涉及自然语言，即人们日常使用的语言， 所以它与语言学的研究有着密切的联系，但又有重要的区别。 自然语言处理并不是一般地研究自然语言， 而在于研制能有效地实现自然语言通信的计算机系统， 特别是其中的软件系统。因而它是计算机科学的一部分。 ''' s = SnowNLP(text) # 提取关键字 s.keywords(3) # [u'语言', u'自然', u'计算机'] # 提取摘要 s.summary(3) # [u'因而它是计算机科学的一部分', # u'自然语言处理是一门融语言学、计算机科学、 # 数学于一体的科学', # u'自然语言处理是计算机科学领域与人工智能 # 领域中的一个重要方向'] # 文本分句处理 temp_list = s.sentences s = SnowNLP([['这篇', '文章'], ['那篇', '论文'], ['这个']]) # TF-IDF算法 s.tf s.idf # 文本相似度。从s对象中找出与sim(['文章'])相似的文本 s.sim(['文章'])# [0.3756070762985226, 0, 0]
关于训练
训练是更好地完善现有的语料库，现在提供训练的包括分词，词性标注，情感分析。以分词为例 分词在snownlp/seg目录下
# 分词训练 from snownlp import seg seg.train('data.txt') seg.save('seg.marshal') # 词性标注训练 # from snownlp import tag # tag.train('199801.txt') # tag.save('tag.marshal') # 情感分析训练 # from snownlp import sentiment # sentiment.train('neg.txt', 'pos.txt') # sentiment.save('sentiment.marshal')
这样训练好的文件就存储为seg.marshal了，之后修改snownlp/seg/init.py里的data_path指向刚训练好的文件即可