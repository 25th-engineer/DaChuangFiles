1.假设句子按单词顺序为w1,w2,...,wn ，那么这个句子的概率公式为？
句子S在语料库中出现的概率P(S)=P(w1,w2,w3...wn)。根据条件概率公式P(w1,w2,w3...wn)=P(w1)*P(w2|w1)*p(w3|w1,w2)...P(wn|w1,w2...w(n-1))。
2.是否句子越长概率就越低？为什么？
3.一个语言模型的困惑度是怎么计算的？是什么意义？
理论方法：迷惑度/困惑度/混乱度（preplexity），其基本思想是给测试集的句子赋予较高概率值的语言模型较好,当语言模型训练完之后，测试集中的句子都是正常的句子，那么训练好的模型就是在测试集上的概率越高越好，公式如下：
由公式可知，迷惑度越小，句子概率越大，语言模型越好
4.神经网络的语言模型相对N-Gram模型有哪些改进的地方？实际的应用情况如何？
5.Word2Vec中skip-gram,cbow两者比较的优缺点是哪些？
6.HMM, CRF两者比较的优缺点是哪些？
7.Blue评价指标是干嘛用的？他考虑了哪些因素？缺点是什么？
8.做一个翻译模型，如果输出的词典很大，例如有100万个词，要怎么解决这个计算量问题？
9.什么是交叉熵？和KL距离有什么关系？
10.sgd, momentum, adagrad, adam这些优化算法之间的关系和区别是怎样的？分别适用于什么场景
11.理论上两层的神经网络可以拟合任意函数，为什么现在大多数是用多层的神经网络？
12.生成模型和判别模型两者差别是啥？分别适用于什么场景？
13.AUC的评估指标是怎么定义的？如果计算的AUC结果<0.5，主要是什么原因导致的？
14.逻辑回归和线性回归的区别是啥？适用场景分别是？
15.编码实现softmax