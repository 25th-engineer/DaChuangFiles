我的人工智能学习之路--NLP方向（开篇）
什么是机器学习，什么是深度学习
机器学习
机器学习环境及所需工具
机器学习十大算法
深度学习
深度学习中的函数类型
深度学习中的常见概念
NLP（自然语言处理）
数学基础
分词和统计分布规律
基于数学统计的语言模型
对于人工智能的学习，我主要侧重于自然语言处理方向，基于这个大方向，将我的学习脉络梳理成一套体系。按照总分原则，开篇先从总体上介绍机器学习、深度学习以及NLP的相关知识。在以后的博客中，我会边学边完善，同时我还会写入我参加各算法大赛的比赛经验，做到理论与实践相结合。期望我在这条道路上越走越深，排除万难，砥砺前行。
接下来，开启我的人工智能之旅吧！
什么是机器学习，什么是深度学习
以下关于人工智能、机器学习的定义来自《百面机器学习》
进入2018年以来，人工智能 机器学习 深度学习 神经网络等关键词已经成为人们茶余饭后的谈资，而且更会成为软件工程师的必备技能。
人工智能泛指机器具有人的智力的技术。这项技术的目的是使机器像人一样感知、思考、做事、解决问题。人工智能是一个宽泛的技术领域，包括自然语言理解、计算机视觉、机器人、逻辑和规划等。
机器学习
机器学习指计算机通过观察环境，与环境交互，在吸取信息中学习、自我更新的进步。简而言之，机器学习可以揭示数据背后的真是含义。大多数机器学习算法可以分成训练和测试两个步骤，这两个步骤可以重叠进行。
训练包括监督学习和无监督学习两类。其中，监督学习关注对事物未知表现的预测，一般包括分类问题和回归问题；无监督学习则倾向于对事物本身特性的分析，常用的技术包括数据降维和聚类问题等。
分类：顾名思义，便是对其所在的类别进行预测。类别既是离散的，同时也是预先知道数量的。
回归：同样是预测问题，只是预测的目标往往是连续变量。
数据降维：是对事物的特性进行压缩和筛选，这项任务相对比较抽象。
聚类：是依赖于数据的相似性，把相似的数据样本划分为一个簇。不同于分类问题，我们在大多数情况下不会预先知道簇的数量和每个簇的具体含义。
机器学习环境及所需工具
我习惯使用Python进行机器学习任务，同时利用里面强大的库资源来参加算法竞赛。
为什么使用Python及优势
Python是一种兼顾可读性和易用性的编程语言。同时，Python具有免费使用和跨平台执行的特性。作为一门解释型语言，也非常便于调试代码。
Python机器学习的优势：
1）方便调试的解释型语言
2）跨平台执行作业
3）广泛的应用编程接口
4）丰富完备的开源工具包
NumPy & SciPy
NumPy除了提供一些高级的数学运算机制以外，还具备非常高效的向量和矩阵运算功能。
SciPy是在NumPy的基础上构建更为强大，应用领域也更为广泛的科学计算包。它需要依赖NumPy的支持进行安装和运行。
Matplotlib
免费使用的绘图工具包。
Scikit-learn
封装了大量经典以及最新的机器学习模型。
Pandas
一款针对于数据处理和分析的Python工具包。
Anaconda
一个可以一次性获得300多种用于科学和工程计算相关任务的编程库的平台。
机器学习十大算法
C4.5决策树
K-均值（K-mean）
支持向量机（SVM）
Apriori
最大期望算法（EM）
PageRank算法
AdaBoost算法
k-近邻算法（kNN）
朴素贝叶斯算法（NB）
分裂回归树算法（CART）
深度学习
深度学习本身是传统神经网络算法的延伸。一般来说，深度学习适合解决数据量大、数据比较规范，但是决策函数高度非线性的问题。常见的深度学习应用非常成功的领域有图像识别、语音识别、文字生成、自然语言理解等。神经网络模型的发展大致经历了四个不同的阶段：
基本的感知器
传统的神经网络模型历史可以追溯到20世纪50年代，现在公认的鼻祖是Rosenblatt在1957年提出的感知器算法。
多层感知器
20世纪70年代到80年代，多层感知器被发现，其逼近高度非线性函数的能力使得科学界对它的兴趣大增，甚至有神经网络能解决一切问题的论调。
传统神经网络比较沉寂的时期
20世纪90年代到21世纪早些时候，传统神经网络模型比较沉寂，但却是核方法大行其道的时候。主要原因是计算能力跟不上。
神经网络模型
大约在2006年以后到现在，几个重要的技术进步促进了以深度学习为代表的神经网络的大规模应用。
首先是廉价的并行计算；其次是深度网络结构的持续研究，使得模型训练效率大大增加；最后是互联网的出现，为大规模数据的生成和获取提供了极大的便利。
深度学习中的函数类型
大多数神经网络中都包含四类函数：组合函数、激活函数、误差函数和目标函数。
组合函数
激活函数
误差函数
目标函数
深度学习中的常见概念
批量
在线学习和离线学习
偏移/阈值
标准化数据
深度递减算法
反向传播算法
NLP（自然语言处理）
从广义上讲，“自然语言处理”（Natural Language Processing 简称NLP）包含所有用计算机对自然语言进行的操作，从最简单的通过计数词出现的频率来比较不同的写作风格，到最复杂的完全“理解”人所说的话，至少要能达到对人的话语作出有效反应的程度。
自然语言处理是用计算机通过可计算的方法对自然语言的各级语言单位（字、词、语句、篇章等等）进行转换、传输、存贮、分析等加工处理的科学。是一门与语言学、计算机科学、数学、心理学、信息论、声学相联系的交叉性学科。
在词处理技术方面，词是自然语言中最小的有意义的构成单位，是自然语言处理中最基本的研究内容，也是其他研究的先行和基础。
词处理的主要内容包括分词、词性标注、词义消歧三个主要的内容。分词常用的方法包括正向最大匹配和反向最大匹配以及基于词网格的统计方法。困扰分词的主要问题就是歧义消解和新词识别，由于语言本身的复杂性，目前这两个问题并没有得到根本性的解决。
词性标注常用的方法就是基于隐马尔科夫模型的词性标注方法。常用的词性标注的方法包括基于词典知识库的方法，还有一些常用基于统计的分类方法，包括贝叶斯方法和最大熵模型。分词和词性标注是所有自然语言应用的基础，广泛的应用于机器翻译，信息检索等各个领域。
数学基础
概率论
信息论：信息熵、联合熵、条件熵
粗糙集
分词和统计分布规律
常用的分词方法：
1）正向最大匹配分词
2）反向最大匹配分词
3）基于统计的词网格分词
基于数学统计的语言模型
现有的主要统计语言模型
1）上下文无关模型
2）N元文法模型
3）N-pos模型
4）基于决策树的语言模型
5）动态、自适应、基于缓存的语言模型
6）隐马尔科夫模型
7）最大熵模型