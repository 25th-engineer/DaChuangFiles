自然语言处理
分类
自然语言理解是个综合的系统工程，涉及了很多细分的学科。
代表声音的 音系学：语言中发音的系统化组织。
代表构词法的 词态学：研究单词构成以及相互之间的关系。
代表语句结构的 句法学：给定文本的那部分是语法正确的。
代表理解的语义 句法学 和 语用学 ：给定文本的含义和目的是什么。
语言理解涉及语言、语境和各种语言形式的学科。但总的来说，自然语言理解又可以分为三个方面：
词义分析
句法分析
语义分析
自然语言的生成则是从结构化的数据（可以通俗理解为自然语言理解分析后的数据）以读取的方式自动生成文本。主要有三个阶段：
文本规划：完成结构化数据中的基础内容规划。
语句规划：从结构化数据中组合语句来表达信息流。
实现：产生语法通顺的语句来表达文本。
中文文本分类
做一个中文文本分类任务，首先要做的是文本的预处理，对文本进行分词和去停用词操作，来把字符串分割成词与词组合而成的字符串集合并去掉其中的一些非关键词汇（像是：的、地、得等）。再就是对预处理过后的文本进行特征提取。最后将提取到的特征送进分类器进行训练。
研究与应用
NLP 在现在大火的 AI 领域有着十分丰富的应用。总体来说，自然语言处理的研究问题（主要）有下面几种：
信息检索：对大规模文档进行索引。
语音识别：识别包含口语在内的自然语言的声学信号转换成符合预期的信号。
机器翻译：将一种语言翻译成另外一种语言。
智能问答：自动回答问题。
对话系统：通过多回合对话，跟用户进行聊天、回答、完成某项任务。
文本分类：将文本自动归类。
情感分析：判断某段文本的情感倾向
文本生成：根据需求自动生成文本
自动文摘：归纳，总结文本的摘要。
术语
分词
词性标注
命名实体消歧
词义消歧
句法分析
指代消解
HMM应用与分词
规定每个字在一个词语当中有着4个不同的位置，词首 B，词中 M，词尾 E，单字成词 S。我们通过给一句话中的每个字标记上述的属性，最后通过标注来确定分词结果。
考虑到独立输出假设，有限历史性假设，用来求解HMM的算法可以用
维特比算法
一种动态规划算法。嗯。
文本分类
词袋模型
把整个文档集的所有出现的词都丢进袋子里面，然后无序的排出来（去掉重复的）。对每一个文档，按照词语出现的次数来表示文档。
TF-IDF模型
这种模型主要是用词汇的统计特征来作为特征集。TF-IDF由两部分组成，TF（Term frequency），IDF（Inverse document frequency）
TF：
\[tf_{ij} = \frac{n_{ij}}{\sum_{k}n_{kj}}\]
其中分子 \(n_{ij}\) 表示词 \(i\) 在文档 \(j\) 中出现的频次。分母则是所有词频次的总和，也就是所有词的个数。
IDF：
\[idf_{i} = log\left ( \frac{\left | D \right |}{1+\left | D_{i} \right |} \right )\]
其中 \(\left | D \right |\) 代表文档的总数，分母部分 \(\left | D_{i} \right |\) 则是代表文档集中含有 \(i\) 词的文档数。原始公式是分母没有 \(+1\) 的，这里 \(+1\) 是采用了拉普拉斯平滑，避免了有部分新的词没有在语料库中出现而导致分母为零的情况出现。
\[tf*idf(i,j)=tf_{ij}*idf_{i}= \frac{n_{ij}}{\sum_{k}n_{kj}} *log\left ( \frac{\left | D \right |}{1+\left | D_{i} \right |} \right )\]
使用方法
加载词袋类：
调整类的参数：
建立文本库：
训练数据获得词袋特征，转换为array
加载TF-IDF类
调整类参数，并训练
中文邮件分类
数据准备
转化为对应列表，拼接
划分测试集和训练集
预处理（去停用词）
训练fit_transform(), 测试transform()
将特征和标签喂入SVM，测试集验证结果
转载于:https://www.cnblogs.com/xFANx/p/10203479.html