文章目录
一、Jieba
二、NLPIR
三、nltk
四、SnowNLP
五、StandFordNLP
六、thulac
七、StandfordNLP
八、结论
微信公众号
本次依然使用上篇博客（自然语言处理（一）——中英文分词）中我们使用过的工具，来对中英文文本进行词性标注与命名实体识别。
一、Jieba
词性标注与命名实体识别
二、NLPIR
NLPIR词性标注与命名实体识别
三、nltk
nltk词性标注与命名实体识别
四、SnowNLP
SnowNLP词性标注与命名实体识别
五、StandFordNLP
StandfordNLP词性标注与命名实体识别
六、thulac
thulac词性标注与命名实体识别
七、StandfordNLP
中文词性标注与命名实体识别
八、结论
词性标注与命名实体识别，和上一个实验的分词相比，难度又有所增加，在给出的实验文件中已经无法找到现成的代码，有些需要去百度找，有些需要自己写，不过好在都完成了。
在词性标注中，斯坦福大学nlp库的效果最好，但是占用内存较大，而且需要下载较大的预装包，在对中文进行处理时需要中文版；此外，结巴的中文分词是轻量级中效果最好的。
代码和文本太多，上传太麻烦，如果需要请点击这里下载
微信公众号
同时也欢迎各位关注我的微信公众号 南木的下午茶