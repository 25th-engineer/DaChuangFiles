视频列表：
43 句法分析技术（一）
44 句法分析技术（二）
45 句法分析技术（三）
46 句法分析技术（四）
47 句法分析技术（五）
43 句法分析技术（一）
第七章 句法分析技术
什么是句法分析
判断输入的词序列能否构成一个合乎语法的句子，确定合乎语法句子的句法结构
运用句法规则和其他知识将输入句子中词之间的线性次序，变成一个非线性的数据结构（例如短语结构树或有向无环图）
为什么要进行句法分析
例一：音字转换例
一只小花猫
例二：机器翻译示例
Jan hit the girl with long hair
Jan hit the girl with a hammer
例三：信息检索例
哪个球队获得了亚洲杯冠军？
日本队击败中国队获得亚洲杯冠军
例四：语法歧义：一个句子对应着几种句法分析结果
“咬死了猎人的狗”
“那只狼咬死了猎人的狗”
“那只咬死了猎人的狗失踪了”
汉语句法分析的独特性
根据朱德熙《语法答问》《语法讲义》
汉语没有形态
语序灵活
词类和句法成分不存在一一对应的关系
汉语句子的构造原则与词组的构造原则基本上是一致的
汉语语法形式化工作滞后
句法分析系统
一个句法分析系统通常由两部分组成：
形式语法体系
匹配模式
基于模板的方法
短语结构语法
句法规则
特征制约
语义解释
扩充转移网络
树邻接语法(TAG)
44 句法分析技术（二）
基于合一运算的语法（广义短语结构语法、词汇功能语法、功能合一语法、基于中心词驱动的短语结构语法(HPSG)）
基于词的语法（链语法、依存语法、配价语法）
分析控制机制
模式匹配技术
基于短语结构语法分析算法（厄尔利（ Earley ）分析算法、富田胜（ Tomida ）分析算法、线图（Chart）分析算法、确定性分析算法等等）
基于扩充转移网络的分析算法
链分析算法
Ｇ
=
(
N
,
∑
,
P
,
S
)
Ｇ = (N,\sum ,P, S)
Ｇ=(N,∑,P,S)是一个文法，α→β ∈ P
0型文法
对α→β不作任何限制
1型文法
|α|≤|β|
2型文法：上下文无关文法
α∈N
3型文法：正则文法
A→aB或A→a: G是右线性文法，L(G)是3型语言
A→Ba或A→ａ: G是左线性文法，L(G)是3型语言
在自然语言处理中研究和应用较多的是2型文法和3型文法
推导
一个字串的推导是一系列文法规则的应用
S→NP VP →John V NP →John V NP PP →John ate fish P NP →John ate fish with bone
这一推导的过程可以用分析树来表示
根据某上文下无关文法从起始非终结符可能推导出的所有字串的集合称为由该CFG定义的语言
CFG的形式化定义
一个CFG是一个四元组
Ｇ
=
&lt;
N
,
∑
,
P
,
S
&gt;
Ｇ = &lt;N,\sum ,P, S&gt;
Ｇ=<N,∑,P,S>
N是非终结符的集合
∑
\sum
∑是终结符的集合
P是产生式的集合，其中每个产生式形如:
A
→
α
A\rightarrow \alpha
A→α
A是非终结符
α
\alpha
α是由终结符与非终结符构成的字串
S是一个起始非终结符
上下文无关文法示例（context free grammar）
语言的合法性
概率上下文无关文法（Probabilistic (Stochastic) Context Free Grammar）
随机上下文无关语法可以直接统计语言学中词与词、词与词组以及词组与词组的规约信息，并且可以由语法规则生成给定句子的概率。
定义
定义：一个随机上下文无关语法（PCFG）由以下5部分组成：
（1）一个非终结符号集N
（2）一个终结符号集∑
（3）一个开始非终结符S∈N
（4）一个产生式集R
（5）对于任意产生式r∈R，其概率为P®
产生式具有形式X→Y，其中，X∈ N, Y ∈(N∪ ∑)*
∑
λ
P
(
X
→
λ
)
=
1
{\sum_{}^{\lambda }}P(X\rightarrow \lambda )=1
∑λ P(X→λ)=1
PCFG的三个基本假设
CFG的简单概率拓广
∑
λ
P
(
X
→
λ
)
=
1
{\sum_{}^{\lambda }}P(X\rightarrow \lambda )=1
∑λ P(X→λ)=1
基本假设
位置无关(Place invariance)
上下文无关(Context-free)
祖先无关(Ancestor-free)
分析树的概率等于所有施用规则概率之积
P(tree1)=1/22/32/3=2/9
P(tree2)=1/21/31/3=1/18
P(tree3)=1/21/2=1/4
P(tree4)=1/21/2=1/4
PCFG的三个基本问题
1、一个语句
W
=
w
1
w
2
…
.
w
n
W=w_{1}w_{2}….w_{n}
W=w1 w2 ….wn 的P(W|G),也就是产生语句W的概率？
P
(
W
∣
G
)
P(W|G)
P(W∣G)
2、在语句W的句法结构有歧义的情况下,如何快速选择最佳的语法分析(parse) ?
a
r
g
m
a
x
t
r
e
e
P
(
t
r
e
e
∣
W
,
G
)
\underset{tree}{argmax}P(tree|W,G)
treeargmax P(tree∣W,G)
3、如何从语料库中训练G的概率参数,使得P(W|G)最大
a
r
g
m
a
x
G
P
(
t
r
e
e
∣
W
,
G
)
\underset{G}{argmax}P(tree|W,G)
Gargmax P(tree∣W,G)
-问题1&2解决思路
向内（Inside）算法
非终结符A的内部概率（Inside probability）
定义为根据文法G从A推出词串
w
i
.
.
.
w
j
w_{i}...w_{j}
wi ...wj 的概率，
记为
α
i
,
j
(
A
)
\alpha _{i,j}(A)
αi,j (A),
i
≤
j
i\leq j
i≤j
α
i
,
j
(
A
)
\alpha _{i,j}(A)
αi,j (A)称为向内变量
45 句法分析技术（三）
向内概率公式
向内算法计算示例:
S→NP VP 1.0 NP→NP PP 0.4
PP→P NP 1.0 NP→John 0.1
VP→V NP 0.7 NP→bone 0.18
VP→VP PP 0.3 NP→star 0.04
P→with 1.0 NP→fish 0.18
V→ate 1.0 NP→telescope 0.1
问题2
Viterbi 算法
输入： G=(S,N,∑,R,P),字符串
W
=
w
1
w
2
…
.
w
n
W=w_{1}w_{2}….w_{n}
W=w1 w2 ….wn
输出：t* ( W在G下最可能的分析树)
Viterbi算法示例(自底向上)
问题3 参数训练问题-有指导学习方法
从树库直接统计——Treebank Grammar
最大似然估计
依赖于艰巨的工程：树库建设
PCFG的优缺点
优点
可以对句法分析的歧义结果进行概率排序
提高文法的容错能力（robustness）
缺点
没有考虑词对结构分析的影响
没有考虑上下文对结构分析的影响
许多当前的获得较高精度的句法分析系统以PCFG为基础
46 句法分析技术（四）
浅层句法分析技术
从完全句法分析（complete parsing）到浅层句法分析（shallow parsing）
真实语料的复杂性
语言知识的不足
提高分析的效率
应用目标驱动
浅层分析的其他名称：部分分析（partial parsing），组块分析（ chunking ）
基于HMM的浅层分析技术
识别目标：非递归的NP
组块分析：在线性序列中插入括号，来标示组块边界
[The/DT prosecutor/NN] said/VB in/IN [closing/NN] that/CS …
级联式有限状态句法分析
（1）从左向右扫描输入字符串，按照Li层级上的正则表达式模式进行归约，得到新的模式序列，对于输入串中无法归约的符号，直接输出；
（2）i=i+1，在新的Li层级上，用正则表达式模式进行归约
（3）不断进行上述步骤，直到无法归约为止；
（4）如果归约过程中有多种选择，以覆盖范围最大的归约子串为输入结果
47 句法分析技术（五）
小结
以PCFG为重点介绍了近年来句法分析技术的基本原理与方法
句法分析是当前语言处理技术的瓶颈问题之一
句法分析是语义分析（更深层次的语言理解）的必由之路
句法是形式、语义是内容
句法的强制性和语义的决定性
句法系统和语义系统是两个不同的系统，它们各自独立而又相互依存，彼此的对应关系十分复杂
致谢
关毅老师，现为哈工大计算机学院语言技术中心教授，博士生导师。通过认真学习了《自然语言处理（哈工大 关毅 64集视频）》1（来自互联网）的课程，受益良多，在此感谢关毅老师的辛勤工作！为进一步深入理解课程内容，对部分内容进行了延伸学习2 3 456，在此分享，期待对大家有所帮助，欢迎加我微信（验证：NLP），一起学习讨论，不足之处，欢迎指正。
参考文献
《自然语言处理（哈工大 关毅 64集视频）》（来自互联网） ↩︎
王晓龙、关毅 《计算机自然语言处理》 清华大学出版社 2005年 ↩︎
哈工大语言技术平台云官网：http://ltp.ai/ ↩︎
Steven Bird,Natural Language Processing with Python,2015 ↩︎
Claude E. Shannon. “Prediction and Entropy of Printed English”, Bell System Technical Journal 30:50-64. 195 ↩︎
An Empirical Study of Smoothing Techniques for Language Modeling, Stanley F. Chen ↩︎