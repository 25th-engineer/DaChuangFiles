自然语言处理(NLP)历史悠久，从上个世纪初，便有人开始提出自然语言相关的规律和假设，但本人阅读了若干自然语言相关的书籍后，发现自然语言处理的方法论在长达近1个世纪的时间内并无半点实质上的进展。
自然语言处理的方法体系目前大致可分为两个方向：
1.形式化语言处理方向
这个方向吸引了众多学者，体系非常庞杂，其中诞生了很多处理主义，但都并未有革命性的变化，基本上属于盲人摸象，其中就包括了如下理论：范畴语法、语言串分析、语言集合论、有限状态语法、短语结构语法、线图分析、汉字结构、左结合、合一运算、依存配价、格语法、词汇模型……
不一一列举了，防止被绕晕，其实都是文字概念上的变化，很多概念都有重复的嫌疑，总结一下，就是基于语言规则的形式化模型，各有各的细微变化，但都没有从根本上解决问题，用人力可以实现有限状态机的“有限度的”智能。
2.数字化语言处理方向
这个方向似乎才是沿着科学的道路在前进，但发展似乎也很慢，主要包括如下理论：概率语法、Bayes动态规划、HMM、CRF、LSTM、CNN，这些方法将语言看作数字信号，使用概率论的方法对其处理，但也没有真正实现语义理解。
针对以上两个方向，我个人认为，数字化语言处理才是正确的，但对形式化语言处理的认识越深，才能更好的设计自然语言处理模型，现阶段想要做出自动学习语言并生成语言认知模型还比较困难，但形式化方向上很多先驱提出的算法、语言规律和语言现象，有助于网络结构和参数的设计。