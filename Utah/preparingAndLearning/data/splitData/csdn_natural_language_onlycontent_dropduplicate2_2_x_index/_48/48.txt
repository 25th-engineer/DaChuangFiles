NLP 工具包 大调查 自然语言处理工具包合集
原创作品， 转载请注明出处：[ Mr.Scofield  http://blog.csdn.net/scotfield_msn/article/details/72904863  ]
From RxNLP.

可以想一想，如何你把NLP领域的所有的工具都能掌握的数如家珍，是不是很NB？必然的。
只用过这里面的一部分。。。
这份调查是基于使用语言差别来归纳的，别问我什么这么分类哈。。。
一、多语言多环境编译
1、THULAC{
分词
词性标注
}c++/python/java
2.NLPIR2016：{
汉语分词系统NLPIR(前身ICTCLAS)
分词标注、实体抽取、词频统计、关键词提取、Word2vec、文本分类、情感分析、依存文法、繁简编码转换、自动注音、摘要提取
{
original:https://github.com/NLPIR-team/NLPIR
java JNI:http://blog.csdn.net/u010161379/article/details/50813012
python:http://blog.csdn.net/junkichan/article/details/51883160
}
}c++/python/java
3.crfsuite{
A fast implementation of Conditional Random Fields (CRFs):
Fast training and tagging
}c++/python
4.哈工大LTP{一整套中文语言处理系统,以网络服务(Web Service)的形式进行使用。
1、分词
2、词性标注
3、依存句法分析
……
}c++/java
5.Libsvm{ Libsvm和Liblinear都是国立台湾大学的Chih-Jen Lin博士开发的
Libsvm主要是用来进行非线性svm 分类器的生成
}c++/python/java/matlab
6.Liblinear{
Liblinear则是去年才创建的，主要是应对large-scale的data classification，因为linear分类器的训练比非线性分类器的训练计算复杂度要低很多，时间也少很多，而且在large scale data上的性能和非线性的分类器性能相当，所以Liblinear是针对大数据而生的
}c++/python/java/matlab
二、Java
1、IKAnalyzer {
中文分词工具包
}
2、FNLP{综合性工具
信息检索： 文本分类 新闻聚类
中文处理： 中文分词 词性标注 实体名识别 关键词抽取 依存句法分析 时间短语识别
结构化学习： 在线学习 层次分类 聚类
}
3.hanLP{综合性工具
分词
词典
命名实体识别
篇章理解
简繁拼音转换
依存句法解析
智能推荐
}
4.openNLP{综合性工具
Apache OpenNLP
句法检测器：Sentence Detector
分词器：Tokenizer
名字查找器：Name Finder
文档分类器：Document Categorizer
词性标注器：Part-of-Speech Tagger
组块分析器：Chunker
解析器：Parser
指代消解：Coreference Resolution
}
5.stanfod NLP{综合性工具
Stanford CoreNLP：分词、词性标注、命名实体识别、语法分析
Stanford Word Segmenter：采用CRF（条件随机场）算法进行分词
Stanford POS Tagger：采用Java编写的面向英文、中文、法语、阿拉伯语、德语的命名实体识别工具
Stanford Named Entity Recognizer：采用条件随机场模型的命名实体工具
Stanford Parser：进行语法分析的工具
Stanford Classifier：
}
6、ansj{
基于中科院的 ictclas 中文分词算法
中文分词.
实体识别
用户自定义词典
}
7.lingpipe{
主题分类（Top Classification）
命名实体识别（Named Entity Recognition）
词性标注（Part-of Speech Tagging）
句题检测（Sentence Detection）
查询拼写检查（Query Spell Checking）
兴趣短语检测（Interseting Phrase Detection）
聚类（Clustering）
字符语言建模（Character Language Modeling）
医学文献下载/解析/索引（MEDLINE Download, Parsing and Indexing）
数据库文本挖掘（Database Text Mining）
中文分词（Chinese Word Segmentation）
情感分析（Sentiment Analysis）
语言辨别（Language Identification）
}
8.GATE：The General Architecture for Text Engineering {
针对不同的用例提供了一系列子项目
}
9.MALLET: Machine Learning for Language Toolkit{
文档分类、聚类、主题建模和信息提取
}
三、C/C++
1、CRF++{
crf实现工具，适用于序列标注问题
}
2. HTK ：Hidden Markov Model Toolkit{英国剑桥大学工程学院开发的隐马尔可夫模型
做语音识别的
}
3.svm light{
SVMlight is an implementation of Support Vector Machines (SVMs) in C
}
四、※Python
调查除下列包之外：{
scipy
numpy
sklearn
pandas
matplt
iPython
PyBrain
PyML - machine learning in Python
Milk：Machine learning toolkit in Python.
PyMVPA: MultiVariate Pattern Analysis (MVPA) in Python
Pyrallel - Parallel Data Analytics in Python
Monte - gradient based learning in Python
xgboost
}
1.gensim{
Corpora and Vector Spaces
Topics and Transformations：LSA，LDA，TF-IDF，
Experiments on the English Wikipedia
Distributed Computing：word2vec
}
2.jieba{
功能 1)：分词
功能 2) ：添加自定义词典
功能 3) ：关键词提取
功能 4) : 词性标注
功能 5) : 并行分词
功能 6) : Tokenize：返回词语在原文的起始位置
}
3.NLTK{
Tokenize and tag some text:
Identify named entities:
Display a parse tree:
它提供了 WordNet 这种方便处理词汇资源的借口，还有分类、分词、除茎、标注、语法分析、语义推理等类库
}
4.TextBlob{
词性标注，
名词性成分提取，
情感分析，
文本翻译
}
5.PyNLPI{
处理N元搜索，计算频率表和分布，建立语言模型。他还可以处理向优先队列这种更加复杂的数据结构，或者像 Beam 搜索这种更加复杂的算法。
Segmenting Text
Getting Key Words
}
6.spaCy{结合Python和Cython：是具有工业级强度的Python NLP工具包
英文断句
词干化（Lemmatize):
词性标注(POS Tagging):
命名实体识别（NER）：
名词短语提取：
}
7.polyglot{
Tokenization
Language detection
Morphological analysis
Named Entity Recognition
Sentiment Analysis
Word Embeddings
}