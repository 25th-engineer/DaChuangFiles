自然语言处理与DuReader概述
“自然语言处理是人工智能桂冠上的明珠”，这句话反应了NLP发展之艰巨。事实上，语言理解被我们认为是“AI的终极任务”，要解决这一难题，前提是要能解决全部人类水平人工智能的问题（https://www.yangfenzi.com/sousuo/61444.html）
百度在自然语言处理上研究和推进，正式实际的应用出发的内部的迫切需求。请见下面链接文章https://www.leiphone.com/news/201805/0UtBTaxsxpOqEU3h.html. （插播一句，建议某些公司研究技术要应用的实际促进产品中去，搜索结果不能让人怀疑技术都是临时抱佛脚吧。）
目前机器阅读理解国外做的比较多。例如在2018年伊始，阿里巴巴和微软亚洲研究院相继刷新了斯坦福大学发起的SQuAD（Stanford Question Answering Dataset）文本理解挑战赛成绩，机器阅读理解评分超过人类！这意味着机器阅读理解的能力已经开始在“指标”上超越人类，又是否能够引领自然语言处理（NLP）领域的下一场革命？（https://www.huxiu.com/article/233577.html?f=member_article）
SQuAD是斯坦福大学于2016年推出的阅读理解数据集，也是行业内公认的机器阅读理解标准水平测试，该数据集包含来自维基百科的536篇文章及共计十万多个问题。在阅读数据集内的文章后，机器需要回答若干与文章内容相关的问题，通过与标准答案对比来获取得分。目前整体排名第一的是科大讯飞与哈工大联合实验室，得分为82.482或者89.281（标准不同。微软MARCO也应用在机器阅读理解领域，是由10万个问答和20万篇不重复的文档组成的数据集。相比SQuAD，其最大不同在于数据集中的问题来自微软自家必应搜索引擎。MARCO的挑战难度更大，它需要测试者提交的模型具备理解复杂文档、回答复杂问题的能力。目前最高得分为百度NLP团队获得，为（46.72 50.45 70.96，不同标准）；DuReader数据集，目前最好的模型与人的准确率接近，但是还是很低， 约是60%的准确率，相比英文阅读，还是有很大差距。
机器阅读理解取得的成绩确实是一个突破性的进展，其可能是继机器翻译之后又一个取得重要进展的NLP领域；但机器阅读理解仍然是一种限定边界的任务(从某种意义上来讲，目前机器的阅读理解，是把问题词作为查找向量从文章中搜寻答案的词语位置，几乎没有变换及推断题)，机器阅读理解是一种边界限定的场景式机器理解，问题的前提条件和场景边界都比较清楚，所以机器阅读理解超过人类是以“设定文章集合、有限问题”为前提条件的，远远达不到真正的归纳和推理，因此对于人类的胜利更应该说是“指标”上的胜利。“以机器阅读理解任务来说，机器应该很快会从指标上超过人类的现有水平，但真正的阅读理解过程需要深层的推理和归纳，这恰恰是目前机器所欠缺的，还需要通过底层算法的突破才有可能实现机器在NLP领域的真正突破。”王士进谈到。 有人认为下一步推动NLP发展可能在知识图谱层面，通过知识图谱构建机器对任务的认知能力，再加以语义、交互等处理工具，通过应用才能更好推动一个行业的发展。其实知识图谱是源，不是机器阅读理解的钥匙，现在的核心是算法以及数据的自然性需要改进。
目前机器阅读理解的技术现状，1956 年乔姆斯基借鉴香农的工作，把有限状态机用作刻画语法的工具，建立了自然语言的有限状态模型，具体来说就是用“代数”和“集合”将语言转化为符号序列，建立了一大堆有关语法的数学模型(https://www.sohu.com/a/204243606_500659)。90 年代以来，基于统计的自然语言处理就开始大放异彩了。大家的重心开始转向大规模真实文本了，传统的仅仅基于规则的自然语言处理显然力不从心了。如句法剖析、词类标注、参照消解、话语处理的算法几乎把“概率”与“数据”作为标准方法，成为了自然语言处理的主流。其实语言词汇，用法，上下下文环境，都会导致自然语言处理的难度。“当前中文自然语言处理发展还不甚成熟的时期，私以为基于统计的方法在很多方面并不完美，“理性主义”的作用空间还很大”（总成庆）
深度学习掀开了机器学习的新篇章，目前深度学习应用于图像和语音已经产生了突破性的研究进展。(https://www.cnblogs.com/maybe2030/p/5427148.html)引用三年前一位网友的话来讲：　　“Steve Renals算了一下icassp录取文章题目中包含deep learning的数量，发现有44篇，而naacl则有0篇。有一种说法是，语言（词、句子、篇章等）属于人类认知过程中产生的高层认知抽象实体，而语音和图像属于较为底层的原始输入信号，所以后两者更适合做deep learning来学习特征。”
研究难点：（https://baike.baidu.com/item/NLP/25220）
单词的边界界定:在英语等语言中，使用空格等自然分词，这在有别于汉语等，需要使用者自己根据语义来自我划分词语边界。在汉语口语中，词与词之间通常是连贯的，而界定字词边界通常使用的办法是取用能让给定的上下文最为通顺且在文法上无误的一种最佳组合，这其中往往也有断句导致的沟通问题。在书写上，汉语也没有词与词之间的边界。在古汉语研究中，断句也是需要仔细的分析。
词义的消歧：许多字词不单只有一个意思，因而我们必须选出使句意最为通顺的解释。
句法的模糊性：自然语言的文法通常是模棱两可的，针对一个句子通常可能会剖析（Parse）出多棵剖析树（Parse Tree），而我们必须要仰赖语意及前后文的资讯才能在其中选择一棵最为适合的剖析树。
语言行为与机动响应：句子常常并不只是字面上的意思；例如，“你能把盐递过来吗”，一个好的回答应当是把盐递过去；在大多数上下文环境中，“能”将是糟糕的回答，虽说回答“不”或者“太远了我拿不到”也是可以接受的。再者，如果一门课程去年没开设，对于提问“这门课程去年有多少学生没通过？”回答“去年没开这门课”要比回答“没人没通过”好。
阅读库的完备性：自然语言，内容多样，语法语义，使用场景，都不能很好的界定数据库的特点。现在Squid，微软Marco，百度的dureader缺乏统一有效的标准，都是一种收集或者固定来源整理。
https://blog.csdn.net/weixin_38440272/article/details/80239298
机器阅读理解其实和人阅读理解面临的问题是类似的，不过为了降低任务难度，很多目前研究的机器阅读理解都将世界知识排除在外，采用人工构造的比较简单的数据集，以及回答一些相对简单的问题。
https://zhuanlan.zhihu.com/p/22671467
机器对语言的理解过程，可以分为几个步骤，其中很多的不确定性是逐渐明晰的（语音识别的不确定性更多，因为还要解决从声音到词的转换）。第一步是要把词分开，放到依存树上，看哪一个词是动词，对名词有哪些影响等等。随后，要理解每一个名字的含义。再次，再加入许多先验知识，即对这个世界的理解，因为很多句子只有使用了这些信息才能真正理解。如果足够幸运的话，到这就能得到清晰的理解了。https://www.yangfenzi.com/sousuo/61444.html:
自然语言处理领域进化出了深度神经网络的一种新模式，该模式分为：embed、encode、attend、predict四部分https://blog.csdn.net/jdbc/article/details/53292414  然而，大多数NLP问题面对的不是单个词语，而是需要分析更长的文本内容。现在有一个简单而灵活的解决方案，它在许多任务上都表现出了卓越的性能，即RNN模型。
高级词向量三部曲：https://blog.csdn.net/sinat_26917383/article/details/54850933
1、NLP︱高级词向量表达（一）：“GloVe（理论、相关测评结果、R&python实现、相关应用）
2、NLP︱高级词向量表达（二）：FastText（简述、学习笔记）
3、NLP︱高级词向量表达（三）：WordRank（简述）
4、其他NLP词表示方法paper:从符号到分布式表示NLP中词各种表示方法综述
如果用分类问题，用CNN。对于顺序建模，需要联系上下文，用RNN。深度学习是一个年轻的领域，理论建立并不完备，观点也会快速变化
目前机器阅读理解研究领域出现了非常多的具体模型，如果对这些模型进行技术思路梳理的话，会发现本质上大多数模型都是论文“Teaching Machines to Read and Comprehend”提出的两个基础模型”Attentive Reader”和“Impatient Reader”的变体，当然很多后续模型在结构上看上去有了很大的变化，但是如果仔细推敲的话会发现根源和基础思路并未发生颠覆性的改变。（https://zhuanlan.zhihu.com/p/22671467深度学习解决机器阅读理解任务的研究进展。）
DuReader，一个新的大型开放中文机器阅读理解数据集，其在中文应用中还是很有开创意义。实际上是”百度知道”和以及“百度搜索”，数据的全面性和权威性令人存疑。Dureader的基本内容介绍可以参见：
https://blog.csdn.net/LiJiancheng0614/article/details/80866088
由于规模大且问题类型复杂，基于DuReader数据集的分析工作相比以往数据集都要难得多。百度通过计算人工答案和文档的最小编辑距离来判断回答问题的困难度。编辑距离越大，对文档的编辑修改就更多，回答问题的复杂度也就越高。对于答案直接来源于原文的数据集（如SQuAD），它们的编辑距离应该是0。 下图展示了MS-MARCO和DuReader两个数据集答案与文档编辑距离分布情况。（https://zhuanlan.zhihu.com/p/36415104）
图 MS-MARCO和DuReader两个数据集答案与文档编辑距离分布情况
从图可以看出，在同为人工标注的数据集MS-MARCO中，77.1%的样本的编辑距离低于3，而在DuReader中51.3%的样本的编辑距离高于10，这说明DuReader更为复杂。
百度基于DuReader构建了两个基线模型：Match-LSTM和BiDAF。
Match-LSTM是广泛应用的MRC模型，Match-LSTM为了在文章中找到答案，依次遍历文章，动态地将注意力权重与文章的每个标记进行匹配。最后，使用一个应答指针层来查找文章中的答案跨度。
BiDAF既使用了语境对问题的注意，又使用了问题对上下文的注意，从而突出了问题和上下文中的重要部分。然后，利用注意流层融合所有有用的信息，从而得到每个位置的向量表示。
下面对Match-LSTM进行分享：（https://www.imooc.com/article/25027)
模型都分为三部分：
Embed 层使用词向量表示原文和问题；
Encode 层使用单向 LSTM 编码原文和问题 embedding；
Interaction层对原文中每个词，计算其关于问题的注意力分布，并使用该注意力分布汇总问题表示，将原文该词表示和对应问题表示输入另一个 LSTM编码，得到该词的 query-aware 表示；
在反方向重复步骤 2，获得双向 query-aware 表示；
Answer 层基于双向 query-aware 表示使用 Sequence Model 或 Boundary Model预测答案范围。
BiDAF[5]
相比于之前工作，BiDAF（Bi-Directional Attention Flow）最大的改进在于 Interaction 层中引入了双向注意力机制，即首先计算一个原文和问题的 Alignment matrix，然后基于该矩阵计算 Query2Context 和 Context2Query 两种注意力，并基于注意力计算 query-aware 的原文表示，接着使用双向 LSTM 进行语义信息的聚合。
另外，其 Embed 层中混合了词级 embedding 和字符级 embedding，词级 embedding 使用预训练的词向量进行初始化，而字符级 embedding 使用 CNN 进一步编码，两种 embedding 共同经过 2 层 Highway Network 作为 Encode 层输入。最后，BiDAF 同样使用 Boundary Model 来预测答案开始和结束位置。
目前有很多的框架实现版本，例如Tensorflow, Pytorch, Paddlepadlle, QAnet等。尽管目前结果提升比较明显，但是离英文机器阅读理解取得的成绩尚有很大距离。
目前笔者认为现在实现彻底的机器阅读理解，不妨从人类阅读理解的本质以及能从算法上实现渐进的路标和更加丰富完备的阅读理解数据集。