定义
书中定义的统计自然语言处理由所有的自动语言处理的定量方法组成，包括概率模型，信息论，线性代数。代表自然语言处理中非符号化和非逻辑的工作。
语言的非绝对性，需要利用统计观察来考察问题。
个人思考
因为生活中充满了不确定和不完整的信息，为了能和世界有效的相互作
用，我们需要处理这类信息，所以概率论和随机过程给我么一个可以处理不确定和不完整信息架构的量化框架
这里只是因为想到认知是随机的，所以推广到语言，但是我认为问题是需要针对特定问题的，在这里我认为语言处理的第一步就是需要让机器知道我们的某些想法，并且完成某些事情。如果阶段性的去划分这样一个过程，我觉得应该是这样。
下命令->执行命令
1.给出具体某一条命令，电脑执行某一条命令：开机/关机
2.给出命令，电脑反馈所有能执行的命令：明天天气真好->各个游玩地点信息，日程安排等。。。
3.给出任意命令，准确知道我要干什么。
那么以上的问题首先就是机器要能做某些事情。
语言就是信息，信息就是一定要传达某种内容，目标就是解析内容嘛！
关于歧义自己的想法
其实我还没有觉得有什么歧义的问题，首先你必须知道这个句子中的每个词语和字，如果这个都不知道肯定分析不出来嘛，我还是那个观点，每个人心中对词都有一个词网，“南京市长江大桥”如果我知道这个地方，OK，那么这个词就是一个固定词，如果不知道，那么我就要用已知的方式去猜测，长江大桥我有概念，南京市我也知道。如果能精确的让我去划分这个短语，我肯定不知道江大桥是个什么玩意，所以我能很好的判断出来，也就是说我需要建立这样一套系统，我要给出我对每个词语了解程度的多少。关键就成了如何去联系词语和现实世界。
语法规则问题：
关于语法这一块的话，我现在是这么考虑的，所有的内容都是词语，不需要。必要，一定是必要的。以我语文语法水平为基准，我知道的基本我认为是必要的。名词，动词，形容词。词语中人物，时间，地点等基本少许的概念一定是要有的吧。既然是我知道的，那么规则也肯定不多，肯定是够用的。
一些法则
由于语料库使用中绝大部分词语出现极少，而常用词出现频率极高，这样很难预测行为，最初认为使用更大的语料库就可以解决这个问题，但是愿望是无法证实的，下面提出语料库语言学中最著名的早期结论：Zipf法则，这个法则针对的问题就是这些稀有词汇。
Zipf我们能够统计一种语言中所有的词在一个大型语料库中出现的次数，并且按照其出现次数排列，发现f x r =k