参考：《中文信息处理发展报告2016》
什么是语音识别？
语音识别(Automatic Speech Recognition,ASR)：利用计算机实现从语音到文字自动转换的任务。
语音识别的技术有哪些？
语音识别技术 = 早期基于信号处理和模式识别 + 机器学习 + 深度学习 + 数值分析+ 高性能计算 + 自然语言处理
语音识别技术的发展可以说是有一定的历史背景，上世纪80年代，语音识别研究的重点已经开始逐渐转向大词汇量、非特定人连续语音识别。到了90年代以后，语音识别并没有什么重大突破，直到大数据与深度神经网络时代的到来，语音识别技术才取得了突飞猛进的进展。
语音识别的相关领域有哪些？
语音识别关联领域 = 自然语言理解 + 自然语言生成 + 语音合成
语音识别的社会价值在哪里？
语音信号是典型的局部稳态时间序列，而日常所见的大量信号都属于这种局部稳态时间序列信号，如视频，雷达信号，金融资产价格，经济数据等。这些信号的共同特点是在抽象的时间序列中包含大量不同层次的信息，可以用相似的模型进行分析。
历史上，语音信号的研究成果在若干领域起到启发作用，如语音信号处理中的隐马尔科夫模型在金融分析，机械控制等领域都得到广泛的应用。近年来，深度神经网络在语音识别领域的巨大成功直接促进了各种深度学习模型在自然语言处理，图形图像处理，知识推理等众多领域的发展应用，取得了一个有一个令人惊叹的成果。
怎么构建语音识别系统？
语音识别系统构建总体包括两个部分：训练和识别。
训练通常来讲都是离线完成的，将海量的未知语音通过话筒变成信号之后加在识别系统的输入端，经过处理后再根据语音特点建立模型，对输入的信号进行分析，并提取信号中的特征，在此基础上建立语音识别所需的模板。
识别则通常是在线完成的，对用户实时语音进行自动识别。这个过程又基本可以分为“前端”和“后端”两个模块。前端主要的作用就是进行端点检测、降噪、特征提取等。后端的主要作用是利用训练好的“声音模型”和“语音模型”对用户的语音特征向量进行统计模式识别，得到其中包含的文字信息。
语音识别技术中的关键问题是什么？
语音特征抽取
语音识别的一个主要困难在于语音信号的复杂性和多变性。一段看似简单的语音信号， 其中包含了说话人、发音内容、信道特征、口音方言等大量信息。不仅如此，这些底层信息互相组合在一起，又表达了如情绪变化、语法语义、暗示内涵等丰富的高层信息。如此众多 的信息中，仅有少量是和语音识别相关的，这些信息被淹没在大量其它信息中，因此充满了变动性。语音特征抽取即是在原始语音信号中提取出与语音识别最相关的信息，滤除其它无关信息。
语音特征抽取的原则是：尽量保留对发音内容的区分性，同时提高对其它信息变量的鲁棒性。历史上研究者通过各种物理学、生理学、心理学等模型构造出各种精巧的语音特征抽 取方法，近年来的研究倾向于通过数据驱动学习适合某一应用场景的语音特征。
模型构建
语音识别中的建模包括声学建模和语言建模。声学建模是对声音信号（语音特征）的特性进行抽象化。自上世纪 70 年代中期以来，声学模型基本上以统计模型为主，特别是隐马尔科夫模型/高斯混合模型(HMM/GMM)结构。最近几年，深度神经网络(DNN)和各种异构神经 网络成为声学模型的主流结构。
声学模型需要解决如下几个基本问题： 如何描述语音信号的短时平稳性；
 如何描述语音信号在某一平稳瞬态的静态特性，即特征分布规律；
 如何应用语法语义等高层信息；
 如何对模型进行优化，即模型训练。
同时，在实际应用中，还需要解决众多应用问题，例如：
 如何从一个领域快速自适应到另一个领域；
 如何对噪音、信道等非语音内容进行补偿；
 如何利用少量数据建模；
 如何提高对语音内容的区分性；
 如何利用半标注或无标注数据，等等。 语言建模是对语言中的词语搭配关系进行归纳，抽象成概率模型。这一模型在解码过程中对解码空间形成约束，不仅减小计算量，而且可以提高解码精度。传统语言模型多基于 N元文法 (n-gram)，近年来基于递归神经网络（RNN）的语言模型发展很快，在某些识别任务 中取得了比 n-gram 模型更好的结果。
语言模型要解决的主要问题是如何对低频词进行平滑。不论是 n-gram 模型还是 RNN 模型，低频词很难积累足够的统计量，因而无法得到较好的概率估计。平滑方法借用高频词或相似词的统计量，提高对低频词概率估计的准确性。除此之外，语言建模研究还包括：
 如何对字母、字、词、短语、主题等多层次语言单元进行多层次建模
 如何对应用领域进行快速自适应；
 如何提高训练效率，特别是对神经网络模型来说，提高效率尤为重要；
 如何有效利用大量噪声数据，等等。
解码
解码是利用语音模型和语言模型中积累的知识，对语音信号序列进行推理，从而得到相应语音内容的过程。早期的解码器一般为动态解码，即在开始解码前，将各种知识源以独立模块形式加载到内存中，动态构造解码图。现代语音识别系统多采用静态解码，即将各种知 识源统一表达成有限状态转移机（FST），并将各层次的 FST 嵌套组合在一起，形成解码图。 解码时，一般采用 Viterbi 算法在解码图中进行路径搜索。为加快搜索速度，一般对搜索路 径进行剪枝，保留最有希望的路径，即束搜索（beam search）。
对解码器的研究包括但不限于如下内容：
 如何加快解码速度，特别是在应用神经网络语言模型进行一遍解码时；
 如何实现静态解码图的动态更新，如加入新词；
 如何利用高层语义信息；
 如何估计解码结果的信任度；
 如何实现多语言和混合语言解码；
 如何对多个解码器的解码结果进行融合。