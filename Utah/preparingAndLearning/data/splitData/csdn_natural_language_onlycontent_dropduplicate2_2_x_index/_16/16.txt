1. 引言
最早接触知识图谱是在一篇分析人工智能的文章，文章提出一个很有意思的观点：“在感知层面，人工智能进步很大，在更高级的认知层面，我们现在了解的仍然很少。”　我对这句话的粗浅理解是，人工智能在学习数据的内在表示（无监督学习），或者对数据的输出结果判别方面表现出了强大的能力，甚至在计算机视觉、语音识别、机器翻译等方面接近或超过人类的表现水平，但这些都还停留在对数据内容的归纳和感知层面，对于需要复杂背景知识和前后上下文的认知和推理层面了解仍然不够，例如我有一堆数据，我想让机器自己学习和推理出正确的知识，以及知识和知识的联系。当然知识图谱也知识在认知计算领域走出了一步，远未达到人们对认知的期望。
具体到知识图谱，简单理解就是一个知识库，我们能利用这个知识库，给定你要查询的内容，然后到知识库中去进行关联分析和推理，试图让机器了解你的意图，反馈和你查询相关内容的更多关联信息。举一个简单例子，我们用所有的菜谱构建知识图谱，然后问“夏天西红柿怎么做汤”，知识图谱会查询“夏天”、“‘西红柿”和“汤”在所有菜谱中的直接和间接关系，进而推荐给你几个最匹配的菜谱。就我的总结，知识图谱有两大类主要应用：a) 搜索和问答类型的场景；b)自然语言理解类的场景。典型的应用场景如下：
那知识图谱是怎么表示的呢？大多数知识图谱用RDF(Resource Description Framework)表示，RDF表征了实体和实体的关系，这种关系有两种：一种是属性关系，即一个实体是另一个实体的属性；另一种是外部关系，表明两个实体之间存在外部关联。。RDF形式上表示为SPO（Subject Predicate Object）三元组，所以实体通过关系链接成无向的网络。例如：
2. 知识图谱的架构体系
可以用知名的知识图谱平台PlantData为例，介绍知识图谱的架构体系：
从图中我们可以看出知识图谱的体系分成４个过程：数据采集、知识抽取、知识链接和融合、知识的应用。
首先说数据采集，构建知识图谱是以大量的数据为基础的，需要进行大规模的数据采集，采集的数据来源一般是：网络上的公开数据、学术领域的已整理的开放数据、商业领域的共享和合作数据，这些数据可能是结构化的、半结构化的或者非结构化的，数据采集器要适应不同类型的数据。
知识抽取是对数据进行粗加工，将数据提取成实体－关系三元组，根据数据所在的问题领域，抽取方法分成开放支持抽取和专有领域知识抽取。
知识链接和融合，由于表征知识的实体－关系三元组抽取自不同来源的数据，可能不同的实体可以进一步融合成新的实体，实现在抽象层面的融合；根据融合之后的新实体，三元组集合可以进一步学习和推理，将表达相同或相似含义的不同关系合并成相同关系，检测相同实体对之间的关系冲突等。
知识图谱构建完成之后，形成了一个无向图网络，可以运用一些图论方法进行网络关联分析，将其用于文档、检索以及智能决策等领域。例如，阿里的知识图谱以商品、标准产品、 标准品牌、 标准条码、标准分类为核心， 利用实体识别、实体链指和语义分析技术，整合关联了例如舆情、百科、国家行业标准等9大类一级本体，包含了百亿级别的三元组，形成了巨大的知识网，然后将商品知识图谱广泛地应用于搜索、前端导购、平台治理、智能问答、品牌商运营等核心、创新业务。
3. 知识图谱的构建
知识图谱的构建有两大类方法：如果知识领域比较贴近开放领域，可以先从网络上找一个开放知识图谱，然后以此为基础进行扩充；如果知识领域只某个专有行业的，例如信息安全领域，则开发知识图谱图谱中可直接使用的知识表示相对较少，需要花更多的精力构建专业的知识图谱，一个典型的工具是Deepdive允许通过机器学习和人工参与的方式不断迭代提升知识图谱。
不管构建哪一类的知识图谱，都要经历：数据收集、信息抽取、链接和融合数据、数据可视化以及分析等过程。目前中国的知识图谱从业者们建立了一个非常好的开放知识图谱共享网站：OpenKG.CN，网址是：http://www.openkg.cn/，网站的主要内容如下：
其中，“数据”栏目里给出了开源知识图谱或者用于构建知识图谱的专业数据集。“工具”栏目里给出了几十种用于自然语言处理、知识抽取、知识存储、知识表示、知识链接、知识推理、知识查询、对话系统等用于构建知识图谱和应用知识图谱的工具。“成员”里列出了参与的科研机构和知识图谱从业企业单位。
我们可以利用OpenKG.CN里提供的数据集和工具帮助我们构建知识图谱。数据集可以帮助我们建立一个知识图谱的初始版本，即从里面获得初始的知识表示：SPO三元组，然后根据我们收集的真实业务数据再进行知识抽取和知识推理。构建知识图谱的前提是收集数据，收集的数据越全面，则可供提取的知识表示越丰富，知识图谱的用处越大。
3.1 数据收集
收集数据的方法包括：
a) 收集通用的百科知识，包括百度百科、维基百科等；
b)收集自然语言处理或者类似OpenKG.CN这类网站提供的公开数据集，例如自然语言处理的语料库、同义词近义词库，OpenKG.CN提供的疾病、菜谱、人物、商品、音乐、企业年报、突发事件、脑科学、中文地理、中医药等领域的数据集；
c) 业务领域的数据，从业者所在的企业或者机构所能获取的问题领域的数据。
以上数据的规模较大，需要一个大数据平台来支撑数据的收集、存储和查询，例如利用Hadoop系统或者单独的非关系数据库（Redis、Mongodb、Hbase和postgresql等数据库）进行存储。
3.2 知识抽取（生成SPO三元组）
收集数据之后需要对数据进行处理，这里面最有价值的首先是文本数据，因此要用到自然语言处理，基本的过程是：语言分词、词性标注、命名实体识别、句法分析，更高级写的应用还包括语义依存分析。对于构建知识库而言，自然语言处理的目的是获取命名实体，再根据命名实体和句法分析抽取知识三元组SPO。自然语言处理有两个强大的工具NLTK和Standford NLP，由于Standford NLP提供了开放信息抽取OpenIE功能用于提取三元组SPO，所以使用Standford NLP更贴合知识图谱构建任务，比较麻烦的一点是Standford NLP需要的计算资源和内存较大（推荐内存4GB），启动时间较长，分析效率低于NLTK，不过支持文件列表的输入方式，实现一次多文件输入得到多个文件的输出结果，总体效率还好。当然研究者也开发和共享了更多的知识抽取工具，例如OpenKG.CN里除了Standford NLP还提供了Reverb: 开放三元组抽取、SOFIE: 抽取链接本体及本体间关系、OLLIE：开放三元组知识抽取等工具。
3.2.1 DeepDive
以上知识抽取工具有一个共同的缺点是：利用别人训练好的模型、按照给定的模式进行抽取，对于开放领域的知识抽取，可能是足够的。但对于专业领域，例如某个特定行业的知识抽取，可能提供的工具并没有覆盖到该行业领域，此时该工具进行知识抽取的准确率是比较低的，需要一个能够根据你自己收集的业务数据，自适应的更新知识抽取的模型，通过不断迭代的方式逐渐提升知识抽取的准确性，这个迭代过程要允许人工参与。Deepdive是一款被广泛使用的知识抽取开源工具，DeepDive (http://deepdive.stanford.edu/) 是斯坦福大学开发的信息抽取系统，能处理文本、表格、图表、图片等多种格式的无结构数据，从中抽取结构化的信息。系统集成了文件分析、信息提取、信息整合、概率预测等功能。Deepdive在OpenKG.CN上有一个中文的教程：http://openkg1.oss-cn-beijing.aliyuncs.com/478e0087-8dd6-417c-9a49-4ce12f5ec22c/tutorial.pdf
DeepDive系统的基本输入包括：
1) 无结构数据，如自然语言文本
2) 现有知识库或知识图谱中的相关知识
3) 若干启发式规则
DeepDive系统的基本输出包括：
1) 规定形式的结构化知识，可以为关系（实体1，实体2）或者属性（实体，属性值）等形式
2) 对每一条提取信息的概率预测
DeepDive系统运行过程中还包括一个重要的迭代环节，即每轮输出生成后，用户需要对运行结果进行错误分析，通过特征调整、更新知识库信息、修改规则等手段干预系统的学习，这样的交互与迭代计算能使得系统的输出不断得到改进。
DeepDive系统架构和工作流程：
DeepDive主要针对关系抽取，在指定的关系抽取中效果比较理想，在实体确定后可以很好地进行关系抽取。同时也支持中文关系抽取，仅需要引入中文相关的基础处理工具即可(详情参考：http://www.openkg.cn/tool/cn-deepdive)。不足之处在于未提供专门的针对概念、实体和事件抽取的支持，同时需要大量的标注语料支持，并通过人工设置标注规则。
总结一下，知识三元组的抽取，对于开放领域的信息抽取直接使用现有OpenIE工具，对于特定行业领域内的信息抽取，需要使用类似Deepdive这样的工具，在内部集成自然语言处理工具、实体识别工具、实体对之间的关系抽取、人工标注修正错误等步骤。实体识别工具可以直接用资源语言处理领域的命名实体识别NER工具，也可以根据从外部或者人工提取的知识库进行实体匹配，最难做的是实体对之间的关系抽取。Deepdive对实体对之间的关系通过弱监督训练和预测的方法，具体步骤是：
a) 先通过启发式规则的方式标注一部分实体对之间的关系作为监督学习的标记;
b) 对每个实体对所在的文本进行特征提取生成监督学习的特征向量；
c) 根据启发式规则的标注对所有已标实体对所在文本的特征向量进行监督学习的训练过程生成预测模型，再根据预测模型预测未标注实体对的关系标签，得到所有候选实体对的关系标签；
d) 导出所有候选实体对及其关系标签，然后对SPO三元组做人工确认，将人工修改后实体对的关系标记重新导入启发式规则作为监督学习的已标注样本。
重复以上监督学习的训练、预测过程和人工确认过程，迭代式的实现实体对关系的更新。
Deepdive中的监督学习是一种远程监督学习技术。为了打破有监督学习中人工数据标注的局限性，Mintz等人提出了远程监督（Distant Supervision）算法，该算法的核心思想是将文本与大规模知识图谱进行实体对齐，利用知识图谱已有的实体间关系对文本进行标注。远程监督基于的基本假设是：如果从知识图谱中可获取三元组R（E1，E2）（注：R代表关系，E1、E2代表两个实体），且E1和E2共现与句子S中，则S表达了E1和E2间的关系R，标注为训练正例。
远程监督算法是目前主流的关系抽取系统广泛采用的方法，也是该领域的研究热点之一。该算法很好地解决了数据标注的规模问题，但它基于的基本假设过强，会引入大量噪音数据，出现 the wrong label problem 的问题，原因是远程监督假设一个实体对只对应一种关系，但实际上实体对间可以同时具有多种关系，如上例中还存在CEO（乔布斯，苹果公司）的关系，实体对间也可能不存在通常定义的某种关系，而仅因为共同涉及了某个话题才在句中共现。
为了减小 the wrong label problem 的影响，学术界陆续提出了多种改进算法，主要包括：
a) 基于规则的方法：通过对wrong label cases的统计分析，添加规则，将原本获得正例标注的wrong label cases直接标为负例，或通过分值控制，抵消原有的正标注。
b) 基于图模型的方法：构建因子图（factor graph）等能表征变量间关联的图模型，通过对特征的学习和对特征权重的推算减小wrong label cases对全局的影响。
c) 基于多示例学习（multi-instance learning）的方法：将所有包含（E1，E2）的句子组成一个bag，从每个bag对句子进行筛选来生成训练样本。
除了Deepdive的关系抽取技术，基于深度学习的关系技术也很流行。两种方法相辅相成，各有优势：DeepDive系统较多依赖于自然语言处理工具和基于上下文的特征进行抽取，在语料规模的选择上更为灵活，能进行有针对性的关系抽取，且能方便地在抽取过程中进行人工检验和干预；而深度学习的方法主要应用了词向量和卷积神经网络，在大规模语料处理和多关系抽取的人物中有明显的优势。
４. 知识图谱的应用
4.1 进行图分析
列举一些我们常用的图算法：
图遍历：广度优先遍历、深度优先遍历
最短路径查询： Dijkstra（迪杰斯特拉算法）、Floyd（弗洛伊德算法）
路径探寻：给定两个或多个节点，发现它们之间的关联关系
权威节点分析：PageRank算法
族群发现：最大流算法
相似节点发现：基于节点属性、关系的相似度算法
其中，权威节点分析做过社交网络分析的人应该都知道，可以用来做社交网络里的权威人物分析，我们在创投知识图谱中用来做权威投资机构的发现。族群发现算法一般用来在社交网络中主题社区的发现，在这里我们同样可以用来识别企业知识图谱中的派系（阿里系、腾讯系）。相似节点发现应用就更加广泛了，在企业知识图谱中可以做相似企业的发现，这里有个很重要的实际应用场景，可以利用相似企业进行精准的获客营销。
4.2 基于本体的推理
基于本体的知识推理应用也非常的多，比如我们在实际场景中的冲突检测。因为不管是手动构建，还是自动构建知识图谱，都会碰到这样一个问题：或者数据来源不同，或者构建的人员不同、方法不同，这就会不可避免的导致一些冲突，这些冲突自身很难直观的去发现，但是可以利用知识图谱里面的冲突检测去发现存在的有矛盾的、有冲突的知识。
本体推理基本方法包括：
基于表运算及改进的方法：FaCT++、Racer、 Pellet Hermit等
基于一阶查询重写的方法（Ontology based data access，基于本体的数据访问）
基于产生式规则的算法（如rete）：Jena 、Sesame、OWLIM等
基于Datalog转换的方法如KAON、RDFox等
回答集程序 Answer set programming
OpenKG.CN上有一些知识推理的工具，例如：http://www.openkg.cn/tool?tags=%E7%9F%A5%E8%AF%86%E6%8E%A8%E7%90%86
4.3 基于规则的推理
基于规则的推理是在知识图谱基础知识的基础上，专家依据行业应用的业务特征进行规则的定义，这在业务应用中是非常常见的。基于规则的推理是在知识图谱基础知识的基础上，专家依据行业应用的业务特征进行规则的定义，这在业务应用中是非常常见的。介绍一下我们常用的Drools（因被JBOSS收购，现已更名为JBoss Rules），它是为Java量身定制的基于Charles Forgy的RETE算法的规则引擎的实现，使用了OO接口的RETE,使得商业规则有了更自然的表达，其推理的效率也比较高。结合规则引擎工具，基于基础知识与所定义的规则，执行推理过程给出推理结果。
4.4 可视化辅助决策
首先介绍两个比较常见的可视化工具D3.js和ECharts。D3.js全称Data-Driven Documents，是一个用动态图形显示数据的JavaScript库，一个数据可视化工具，它提供了各种简单易用的函数，大大方便了数据可视化的工作。
ECharts是一款由百度前端技术部开发的，同样基于Javascript的数据可视化图标库。它提供大量常用的数据可视化图表。对于出入门的知识图谱使用者，推荐两个入门级别的开源的知识图谱展示工具：
a) 知识图谱Demo，Demo的详细介绍：
https://zhuanlan.zhihu.com/p/29332977?group_id=891668221558661120
开源代码网址：
https://github.com/Shuang0420/knowledge_graph_demo
生成的图谱展示结果如下：
b) 农业知识图谱(KG)：农业领域的信息检索，命名实体识别，关系抽取，分类树构建，数据挖掘。
开源代码网址：
https://github.com/qq547276542/Agriculture_KnowledgeGraph
知识图谱的Demo展示网址：
http://ecnukg.vicp.io/
展示效果如下：
更深入的应用或则展示可以参考商业知识图谱平台PlantData，网址是：https://wx.jdcloud.com/shop/shopDetail/HiKnowledge
4.5 问答系统
这里介绍一个OpenKG.CN的问答demo：基于 REfO 的 KBQA 实现及示例
网址是：http://www.openkg.cn/tool/refo-kbqa，这是一个基于 Python 模块 REfO 实现的知识库问答初级系统. 该问答系统可以解析输入的自然语言问句生成 SPARQL 查询，进一步请求后台基于 TDB 知识库的 Apache Jena Fuseki 服务, 得到结果。这是一个入门级的例子. 内含介绍此项目的 README.pdf. 方便用户快速把握这个项目的想法. 希望用户体会默认的 3 类 5 个问题. 不同的表述能够用统一的"对象正则表达式"匹配得到结果, 进而生成对应 SPARQL 查询语句。
知识库由大量的三元组组成，并且这些三元组的实体和实体关系都是形式化的语言。给定一个自然语言的问题“Where was Obama born？”　我们面临的第一个挑战，就是如何建立问题到知识库的映射？语义解析KB-QA的思路是通过对自然语言进行语义上的分析，转化成为一种能够让知识库“看懂”的语义表示即逻辑形式（Logic Form），进而通过知识库中的知识，进行推理（Inference）查询（Query），得出最终的答案。KB-QA的详细介绍，可以参考知乎专栏：“揭开知识库问答KB-QA的面纱”。
由于个人对知识图谱的理解也比较浅显，本文只是记录自己的一些平时整理的知识和经验，方便自己以后查询和深入学习。