主要概要有：
语言的兴起
人工智能
自然语言处理
中文分词
隐马尔可夫
信息熵
贾里尼克
布尔与搜索
图论与爬虫
PageRank——相关性与可信度
TF-IDF
余弦定理与分类
矩阵运算与文本处理
信息指纹
密码学
搜索引擎
最大熵模型
拼音输入法
马库斯
布隆过滤
贝叶斯网络
条件随机场
维特比
K均值与分类
逻辑回归与广告
MapReduce
关键内容有：
1.信息度量
信息就是不确定性的多少，信息就是要减少不确定性；
熵: 信息的混杂程度，越大，信息越杂，越不纯；
条件熵: 一个信息确定的条件下，另外一个信息不确定度的减少量；
互信息: 在一个信息的条件下，为了是另外一个信息不确定度减少所需要提供的信息量；
相对熵: 衡量两个函数值为正数的函数的相关性。
2.指纹信息
指纹: 每段信息包括文字，图片，音频，等都可以对应一组不太长的随机数
伪随机数:压缩
基于加密的伪随机数:密码
集合的判定，文章，网页的判定，视频的判定
指纹可能重复，但可能性很小
相似哈希:词，权重，指纹，二进制的结合(提供了一种思路)
3.最大熵模型
最大熵原理: 保留全部的不确定性，让风险降到最小；
最大熵模型: 在所有满足约束条件的模型中选出熵最大的模型；
模型学习: 任何一组不自相矛盾的信息，最大熵模型存在并且唯一，都具有相同的形式，指数形式；
特点: 能同时满足成千上万的中不同条件的模型(有效的组合很多特征)
参数训练: 对数似然函数求极大
4.期望最大
如果模型的变量都是观测变量，用极大似然估计或贝叶斯估计
如果存在隐含变量，用EM迭代，最大后验概率
典型:kmeans聚类，隐马的参数训练，最大熵模型的训练
特点: 局部最优，计算速度慢
5.散列表与布隆过滤器
散列表的核心:哈希函数hashcode(),equals()函数；
散列表的特点:时间复杂度o(1),浪费空间，冲突；
布隆过滤器核心: 一组二进制数和随机映射函数；
布隆过滤器的特点: 时间复杂度o(1)，节约空间，到存在错误率
6.文本分类
相似性: 余弦定理，距离
方法: k近邻思想，自底向上的两两合并，EM迭代，奇异值分解；
技巧: 计算时存储重复计算的变量，只考虑非零元素，删除虚词
余弦定理和奇异分解:余弦定理多次迭代，计算量大，消耗资源多；svd无需多次迭代，时间短，但存储空间需求大，适合超大规模分类；建议svd粗分类，余弦定理细分类
TF-IDF解决两个重要问题:词的预测能力越强，权重越大；停止词的权重为零
7.隐马尔可夫
马尔可夫假设: t时刻的状态只取决于t-1时刻
马尔可夫链: 状态链
隐马模型: 初始概率分布，状态转移概率分布，观测概率分布(马尔可夫假设，观测独立)
3个问题:
参数估计-baum-uelch算法
计算概率-直接，前向，后向算法
预测状态-维特比算法(动态规划)
8.贝叶斯网络
是马尔可夫链的推广(链状-拓扑)
又称信念网络: 弧+可信度
训练: 结构和参数训练，交叉进行
方法: 贪心算法，蒙卡，互信息
9.条件随机场
特点:观测值可能和前后的状态都有关
条件随机场是无向图，贝叶斯网络是有向图
核心:找到符合所有边缘分布的最大熵模型
10.有限状态机和动态规划
有限状态机: 开始，终止状态，有向弧，条件
常见:  建立状态机，已知状态机匹配字符串
区别: 基于概率的有限状态机和离散马尔可夫链等效
动态规划: 把全程路径最短锁定到局部路径最短
作者：哈得死
链接：https://www.jianshu.com/p/0b997bd1c125
来源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。