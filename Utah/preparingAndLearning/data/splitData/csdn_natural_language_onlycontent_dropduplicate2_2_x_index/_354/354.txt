自然语言处理NLP知识结构
文|秦陇纪，数据简化DataSimp
自然语言处理(计算机语言学、自然语言理解)涉及：字处理，词处理，语句处理，篇章处理词处理分词、词性标注、实体识别、词义消歧语句处理句法分析(SyntacticAnalysis)、语义分析(SenmanticAnalysis)等。其中，重点有：
1.句法语义分析：分词，词性标记，命名实体识别。
2.信息抽取
3.文本挖掘：文本聚类，情感分析。基于统计。
4.机器翻译：基于规则，基于统计，基于神经网络。
5.信息检索
6.问答系统
7.对话系统建议…本文总结的自然语言处理历史、模型、知识体系结构内容，涉及NLP的语言理论、算法和工程实践各方面，内容繁杂。参考黄志洪老师自然语言处理课程、宗成庆老师《统计自然语言处理》，郑捷2017年电子工业出版社出版的图书《NLP汉语自然语言处理原理与实践》，以及国外著名NLP书籍的英文资料、汉译版资料。
一、NLP知识结构概述
1)自然语言处理：利用计算机为工具，对书面实行或者口头形式进行各种各样的处理和加工的技术，是研究人与人交际中以及人与计算机交际中的演员问题的一门学科，是人工智能的主要内容。
2)自然语言处理是研究语言能力和语言应用的模型，建立计算机(算法)框架来实现这样的语言模型，并完善、评测、最终用于设计各种实用系统。
3)研究问题(主要)：
信息检索
机器翻译
文档分类
问答系统
信息过滤
自动文摘
信息抽取
文本挖掘
舆情分析
机器写作
语音识别
研究模式：自然语言场景问题，数学算法，算法如何应用到解决这些问题，预料训练，相关实际应用
自然语言的困难：
场景的困难：语言的多样性、多变性、歧义性
学习的困难：艰难的数学模型(hmm,crf,EM,深度学习等)
语料的困难：什么的语料？语料的作用？如何获取语料？
二、NLP知识十大结构
1形式语言与自动机
语言：按照一定规律构成的句子或者字符串的有限或者无限的集合。
描述语言的三种途径：
穷举法
文法(产生式系统)描述
自动机
自然语言不是人为设计而是自然进化的，形式语言比如：运算符号、化学分子式、编程语言
形式语言理论朱啊哟研究的是内部结构模式这类语言的纯粹的语法领域，从语言学而来，作为一种理解自然语言的句法规律，在计算机科学中，形式语言通常作为定义编程和语法结构的基础
形式语言与自动机基础知识：
集合论
图论
自动机的应用：
1，单词自动查错纠正
2，词性消歧(什么是词性？什么的词性标注？为什么需要标注？如何标注？)
形式语言的缺陷：
1、对于像汉语，英语这样的大型自然语言系统，难以构造精确的文法
2、不符合人类学习语言的习惯
3、有些句子语法正确，但在语义上却不可能，形式语言无法排出这些句子
4、解决方向：基于大量语料，采用统计学手段建立模型
2 语言模型
1)语言模型(重要)：通过语料计算某个句子出现的概率(概率表示)，常用的有2-元模型，3-元模型
2)语言模型应用：
语音识别歧义消除例如，给定拼音串：ta shi yan yan jiu saun fa de
可能的汉字串：踏实烟酒算法的他是研究酸法的他是研究算法的，显然，最后一句才符合。
3)语言模型的启示：
1、开启自然语言处理的统计方法
2、统计方法的一般步骤：
收集大量语料
对语料进行统计分析，得出知识
针对场景建立算法模型
解释和应用结果
4)语言模型性能评价，包括评价目标，评价的难点，常用指标(交叉熵，困惑度)
5)数据平滑：
数据平滑的概念，为什么需要平滑
平滑的方法，加一法，加法平滑法，古德-图灵法，J-M法，Katz平滑法等
6)语言模型的缺陷：
语料来自不同的领域，而语言模型对文本类型、主题等十分敏感
n与相邻的n-1个词相关，假设不是很成立。
3概率图模型
生成模型与判别模型，贝叶斯网络，马尔科夫链与隐马尔科夫模型(HMM)
1)概率图模型概述(什么的概率图模型，参考清华大学教材《概率图模型》)
2)马尔科夫过程(定义，理解)
3)隐马尔科夫过程(定义，理解)
HMM的三个基本问题(定义，解法，应用)
注：第一个问题，涉及最大似然估计法，第二个问题涉及EM算法，第三个问题涉及维特比算法，内容很多，要重点理解，(参考书李航《统计学习方法》，网上博客，笔者github)
4 马尔科夫网，最大熵模型，条件随机场(CRF)
1)HMM的三个基本问题的参数估计与计算
2)什么是熵
3)EM算法(应用十分广泛，好好理解)
4)HMM的应用
5)层次化马尔科夫模型与马尔科夫网络
提出原因，HMM存在两个问题
6)最大熵马尔科夫模型
优点：与HMM相比，允许使用特征刻画观察序列，训练高效
缺点：存在标记偏置问题
7)条件随机场及其应用(概念，模型过程，与HMM关系)
参数估计方法(GIS算法，改进IIS算法)
CRF基本问题：特征选取(特征模板)、概率计算、参数训练、解码(维特比)
应用场景：
词性标注类问题(现在一般用RNN+CRF)
中文分词(发展过程，经典算法，了解开源工具jieba分词)
中文人名，地名识别
8)CRF++
5 命名实体识别，词性标注，内容挖掘、语义分析与篇章分析(大量用到前面的算法)
1)命名实体识别问题
相关概率，定义
相关任务类型
方法(基于规程->基于大规模语料库)
2)未登录词的解决方法(搜索引擎，基于语料)
3)CRF解决命名实体识别(NER)流程总结：
训练阶段：确定特征模板，不同场景(人名，地名等)所使用的特征模板不同，对现有语料进行分词，在分词结果基础上进行词性标注(可能手工)，NER对应的标注问题是基于词的，然后训练CRF模型，得到对应权值参数值
识别过程：将待识别文档分词，然后送入CRF模型进行识别计算(维特比算法)，得到标注序列，然后根据标注划分出命名实体
4)词性标注(理解含义，意义)及其一致性检查方法(位置属性向量，词性标注序列向量，聚类或者分类算法)
6句法分析
1)句法分析理解以及意义
1、句法结构分析
完全句法分析
浅层分析
2、依存关系分析
2)句法分析方法
1、基于规则的句法结构分析
2、基于统计的语法结构分析
7 文本分类，情感分析
1)文本分类，文本排重
文本分类：在预定义的分类体系下，根据文本的特征，将给定的文本与一个或者多个类别相关联
典型应用：垃圾邮件判定，网页自动分类
2)文本表示，特征选取与权重计算，词向量
文本特征选择常用方法：
1、基于本文频率的特征提取法
2、信息增量法
3、X2(卡方)统计量
4、互信息法
3)分类器设计
SVM，贝叶斯，决策树等
4)分类器性能评测
1、召回率
2、正确率
3、F1值
5)主题模型(LDA)与PLSA
LDA模型十分强大，基于贝叶斯改进了PLSA，可以提取出本章的主题词和关键词，建模过程复杂，难以理解。
6)情感分析
借助计算机帮助用户快速获取，整理和分析相关评论信息，对带有感情色彩的主观文本进行分析，处理和归纳例如，评论自动分析，水军识别。
某种意义上看，情感分析也是一种特殊的分类问题
7)应用案例
8信息检索，搜索引擎及其原理
1)信息检索起源于图书馆资料查询检索，引入计算机技术后，从单纯的文本查询扩展到包含图片，音视频等多媒体信息检索，检索对象由数据库扩展到互联网。
1、点对点检索
2、精确匹配模型与相关匹配模型
3、检索系统关键技术：标引，相关度计算
2)常见模型：布尔模型，向量空间模型，概率模型
3)常用技术：倒排索引，隐语义分析(LDA等)
4)评测指标
9 自动文摘与信息抽取，机器翻译，问答系统
1)统计机器翻译的的思路，过程，难点，以及解决
2)问答系统
基本组成：问题分析，信息检索，答案抽取
类型：基于问题-答案，基于自由文本
典型的解决思路
3)自动文摘的意义，常用方法
4)信息抽取模型(LDA等)
10深度学习在自然语言中的应用
1)单词表示，比如词向量的训练(wordvoc)
2)自动写文本
写新闻等
3)机器翻译
4)基于CNN、RNN的文本分类
5)深度学习与CRF结合用于词性标注
三，中文NLP知识目录
选自郑捷2017年电子工业出版社出版的图书《NLP汉语自然语言处理原理与实践》。
第1章 中文语言的机器处理 1
1.1 历史回顾 2
1.1.1 从科幻到现实 2
1.1.2 早期的探索 3
1.1.3 规则派还是统计派 3
1.1.4 从机器学习到认知计算 5
1.2 现代自然语言系统简介 6
1.2.1 NLP流程与开源框架 6
1.2.2 哈工大NLP平台及其演示环境 9
1.2.3 StanfordNLP团队及其演示环境 11
1.2.4 NLTK开发环境 13
1.3 整合中文分词模块 16
1.3.1 安装Ltp Python组件 17
1.3.2 使用Ltp 3.3进行中文分词 18
1.3.3 使用结巴分词模块 20
1.4 整合词性标注模块 22
1.4.1 Ltp 3.3词性标注 23
1.4.2 安装StanfordNLP并编写Python接口类 24
1.4.3 执行Stanford词性标注 28
1.5 整合命名实体识别模块 29
1.5.1 Ltp 3.3命名实体识别 29
1.5.2 Stanford命名实体识别 30
1.6 整合句法解析模块 32
1.6.1 Ltp 3.3句法依存树 33
1.6.2 StanfordParser类 35
1.6.3 Stanford短语结构树 36
1.6.4 Stanford依存句法树 37
1.7 整合语义角色标注模块 38
1.8 结语 40
第2章 汉语语言学研究回顾 42
2.1 文字符号的起源 42
2.1.1 从记事谈起 43
2.1.2 古文字的形成 47
2.2 六书及其他 48
2.2.1 象形 48
2.2.2 指事 50
2.2.3 会意 51
2.2.4 形声 53
2.2.5 转注 54
2.2.6 假借 55
2.3 字形的流变 56
2.3.1 笔与墨的形成与变革 56
2.3.2 隶变的方式 58
2.3.3 汉字的符号化与结构 61
2.4 汉语的发展 67
2.4.1 完整语义的基本形式——句子 68
2.4.2 语言的初始形态与文言文 71
2.4.3 白话文与复音词 73
2.4.4 白话文与句法研究 78
2.5 三个平面中的语义研究 80
2.5.1 词汇与本体论 81
2.5.2 格语法及其框架 84
2.6 结语 86
第3章 词汇与分词技术 88
3.1 中文分词 89
3.1.1 什么是词与分词规范 90
3.1.2 两种分词标准 93
3.1.3 歧义、机械分词、语言模型 94
3.1.4 词汇的构成与未登录词 97
3.2 系统总体流程与词典结构 98
3.2.1 概述 98
3.2.2 中文分词流程 99
3.2.3 分词词典结构 103
3.2.4 命名实体的词典结构 105
3.2.5 词典的存储结构 108
3.3 算法部分源码解析 111
3.3.1 系统配置 112
3.3.2 Main方法与例句 113
3.3.3 句子切分 113
3.3.4 分词流程 117
3.3.5 一元词网 118
3.3.6 二元词图 125
3.3.7 NShort算法原理 130
3.3.8 后处理规则集 136
3.3.9 命名实体识别 137
3.3.10 细分阶段与最短路径 140
3.4 结语 142
第4章 NLP中的概率图模型 143
4.1 概率论回顾 143
4.1.1 多元概率论的几个基本概念 144
4.1.2 贝叶斯与朴素贝叶斯算法 146
4.1.3 文本分类 148
4.1.4 文本分类的实现 151
4.2 信息熵 154
4.2.1 信息量与信息熵 154
4.2.2 互信息、联合熵、条件熵 156
4.2.3 交叉熵和KL散度 158
4.2.4 信息熵的NLP的意义 159
4.3 NLP与概率图模型 160
4.3.1 概率图模型的几个基本问题 161
4.3.2 产生式模型和判别式模型 162
4.3.3 统计语言模型与NLP算法设计 164
4.3.4 极大似然估计 167
4.4 隐马尔科夫模型简介 169
4.4.1 马尔科夫链 169
4.4.2 隐马尔科夫模型 170
4.4.3 HMMs的一个实例 171
4.4.4 Viterbi算法的实现 176
4.5 最大熵模型 179
4.5.1 从词性标注谈起 179
4.5.2 特征和约束 181
4.5.3 最大熵原理 183
4.5.4 公式推导 185
4.5.5 对偶问题的极大似然估计 186
4.5.6 GIS实现 188
4.6 条件随机场模型 193
4.6.1 随机场 193
4.6.2 无向图的团(Clique)与因子分解 194
4.6.3 线性链条件随机场 195
4.6.4 CRF的概率计算 198
4.6.5 CRF的参数学习 199
4.6.6 CRF预测标签 200
4.7 结语 201
第5章 词性、语块与命名实体识别 202
5.1 汉语词性标注 203
5.1.1 汉语的词性 203
5.1.2 宾州树库的词性标注规范 205
5.1.3stanfordNLP标注词性 210
5.1.4 训练模型文件 213
5.2 语义组块标注 219
5.2.1 语义组块的种类 220
5.2.2 细说NP 221
5.2.3 细说VP 223
5.2.4 其他语义块 227
5.2.5 语义块的抽取 229
5.2.6 CRF的使用 232
5.3 命名实体识别 240
5.3.1 命名实体 241
5.3.2 分词架构与专名词典 243
5.3.3 算法的策略——词典与统计相结合 245
5.3.4 算法的策略——层叠式架构 252
5.4 结语 259
第6章 句法理论与自动分析 260
6.1 转换生成语法 261
6.1.1 乔姆斯基的语言观 261
6.1.2 短语结构文法 263
6.1.3 汉语句类 269
6.1.4 谓词论元与空范畴 274
6.1.5 轻动词分析理论 279
6.1.6 NLTK操作句法树 280
6.2 依存句法理论 283
6.2.1 配价理论 283
6.2.2 配价词典 285
6.2.3 依存理论概述 287
6.2.4 Ltp依存分析介绍 290
6.2.5 Stanford依存转换、解析 293
6.3 PCFG短语结构句法分析 298
6.3.1 PCFG短语结构 298
6.3.2 内向算法和外向算法 301
6.3.3 Viterbi算法 303
6.3.4 参数估计 304
6.3.5 Stanford的PCFG算法训练 305
6.4 结语 310
第7章 建设语言资源库 311
7.1 语料库概述 311
7.1.1 语料库的简史 312
7.1.2 语言资源库的分类 314
7.1.3 语料库的设计实例：国家语委语料库 315
7.1.4 语料库的层次加工 321
7.2 语法语料库 323
7.2.1 中文分词语料库 323
7.2.2 中文分词的测评 326
7.2.3 宾州大学CTB简介 327
7.3 语义知识库 333
7.3.1 知识库与HowNet简介 333
7.3.2 发掘义原 334
7.3.3 语义角色 336
7.3.4 分类原则与事件分类 344
7.3.5 实体分类 347
7.3.6 属性与分类 352
7.3.7 相似度计算与实例 353
7.4 语义网与百科知识库 360
7.4.1 语义网理论介绍 360
7.4.2 维基百科知识库 364
7.4.3 DBpedia抽取原理 365
7.5 结语 368
第8章 语义与认知 370
8.1 回顾现代语义学 371
8.1.1 语义三角论 371
8.1.2 语义场论 373
8.1.3 基于逻辑的语义学 376
8.2 认知语言学概述 377
8.2.1 象似性原理 379
8.2.2 顺序象似性 380
8.2.3 距离象似性 380
8.2.4 重叠象似性 381
8.3 意象图式的构成 383
8.3.1 主观性与焦点 383
8.3.2 范畴化：概念的认知 385
8.3.3 主体与背景 390
8.3.4 意象图式 392
8.3.5 社交中的图式 396
8.3.6 完形：压缩与省略 398
8.4 隐喻与转喻 401
8.4.1 隐喻的结构 402
8.4.2 隐喻的认知本质 403
8.4.3 隐喻计算的系统架构 405
8.4.4 隐喻计算的实现 408
8.5 构式语法 412
8.5.1 构式的概念 413
8.5.2 句法与构式 415
8.5.3 构式知识库 417
8.6 结语 420
第9章 NLP中的深度学习 422
9.1 神经网络回顾 422
9.1.1 神经网络框架 423
9.1.2 梯度下降法推导 425
9.1.3 梯度下降法的实现 427
9.1.4 BP神经网络介绍和推导 430
9.2 Word2Vec简介 433
9.2.1 词向量及其表达 434
9.2.2 Word2Vec的算法原理 436
9.2.3 训练词向量 439
9.2.4 大规模上下位关系的自动识别 443
9.3 NLP与RNN 448
9.3.1Simple-RNN 449
9.3.2 LSTM原理 454
9.3.3 LSTM的Python实现 460
9.4 深度学习框架与应用 467
9.4.1 Keras框架介绍 467
9.4.2 Keras序列标注 471
9.4.3 依存句法的算法原理 478
9.4.4 Stanford依存解析的训练过程 483
9.5 结语 488
第10章 语义计算的架构 490
10.1 句子的语义和语法预处理 490
10.1.1 长句切分和融合 491
10.1.2 共指消解 496
10.2 语义角色 502
10.2.1 谓词论元与语义角色 502
10.2.2PropBank简介 505
10.2.3 CPB中的特殊句式 506
10.2.4 名词性谓词的语义角色 509
10.2.5PropBank展开 512
10.3 句子的语义解析 517
10.3.1 语义依存 517
10.3.2 完整架构 524
10.3.3 实体关系抽取 527
10.4 结语 531 [29]
https://blog.csdn.net/yH0VLDe8VG8ep9VGe/article/details/83747195