包括 理解 卷积 神经 网络 使用 数据 增强 缓解 过拟合 
使用 预 训练 卷积 网络 做 特征提取 微调 预 训练 
网络 模型 可视化 卷积 网络 学习 结果 以及 分类 决策 
过程 介绍 卷积 神经网络 convnets 深度 学习 在 计算机 视觉 
方面 广泛 应用 的 一个 网络 模型 卷积 网络 介绍 
在 介绍 卷积 神经网络 理论 以及 神经 网络 在 计算机 
视觉 方面 应用 广泛 的 原因 之前 先 介绍 一个 
卷积 网络 的 实例 整体 了解 卷积 网络 模型 用 
卷积 网络 识别 MNIST 数据集 from keras import layers from 
keras import models model = models . Sequential model . 
add layers . Conv2D 32 3 3 activation = relu 
input _ shape = 28 28 1 model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu 卷积 网络 接收 
image _ height image _ width image _ channels 形状 
的 张量 作为 输入 不包括 batch size MNIST 中 将 
图片 转换成 28 28 1 形状 然后 在 第一 层 
传递 input _ shape 参数 显示 网络 架构 model . 
summary _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = conv2d _ 1 Conv2D None 
26 26 32 320 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
1 MaxPooling2D None 13 13 32 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ conv2d _ 2 Conv2D None 11 11 64 18496 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ maxpooling2d _ 2 MaxPooling2D None 5 
5 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ conv2d _ 3 
Conv2D None 3 3 64 36928 = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
Total params 55 744 Trainable params 55 744 Non trainable 
params 0 可以 看到 每个 Conv2D 和 MaxPooling2D 网络层 输出 
都是 3D 张量 形状 为 height width channels . 随着 
网络层 的 加深 长度 和 宽度 逐渐 减小 通 道数 
通过 Conv2D 层 的 参数 控制 下 一步 连接 Dense 
层 但 当前 输出 为 3D 张量 需要 将 3D 
张量 平 铺成 1D 然后 添加 Dense 层 model . 
add layers . Flatten model . add layers . Dense 
64 activation = relu model . add layers . Dense 
10 activation = softmax 因为 是 10 分类 最后 一层 
为 10个 神经元 激活 函数 为 softmax 最后 的 网络 
架构 model . summary Layer type Output Shape Param # 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = conv2d _ 1 Conv2D None 26 
26 32 320 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ maxpooling2d _ 1 
MaxPooling2D None 13 13 32 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
conv2d _ 2 Conv2D None 11 11 64 18496 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ maxpooling2d _ 2 MaxPooling2D None 5 5 
64 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ conv2d _ 3 Conv2D 
None 3 3 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ flatten 
_ 1 Flatten None 576 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
dense _ 1 Dense None 64 36928 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ dense _ 2 Dense None 10 650 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 93 322 Trainable params 93 322 
Non trainable params 0 3 3 64 输出 平摊 成 
576 向量 网络 训练 from keras . datasets import mnist 
from keras . utils import to _ categorical train _ 
images train _ labels test _ images test _ labels 
= mnist . load _ data train _ images = 
train _ images . reshape 60000 28 28 1 train 
_ images = train _ images . astype float32 / 
255 test _ images = test _ images . reshape 
10000 28 28 1 test _ images = test _ 
images . astype float32 / 255 train _ labels = 
to _ categorical train _ labels test _ labels = 
to _ categorical test _ labels model . compile optimizer 
= rmsprop loss = categorical _ crossentropy metrics = accuracy 
model . fit train _ images train _ labels epochs 
= 5 batch _ size = 64 测试 集上 模型 
评估 test _ loss test _ acc = model . 
evaluate test _ images test _ labels test _ acc 
0 . 9 9 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 1 在 
Dense 网络 上 准确率 为 97.8% 基本 卷积 网络 上 
准确率 到 99% . 为什么 简单 的 卷积 网络 工作 
效果 这么 好 回答 之前 先 了解 Conv2D 和 MaxPooling2D 
层 卷积/n 操作/v 全/a 连接/v 网络/n 和/c 卷积/n 网络/n 的/uj 
区别/n 在于/v Dense/w 全/a 连接/v 层/q 学习/v 输入/v 特征/n 空间/n 
的/uj 全局/n 模式/n 特征/n 而 卷积 神经 网络 学习 输入 
特征 空间 的 局部 模式 特征 卷积 网络 的 两个 
关键 特性 学习 具有 平移 不变性 的 模式 特征 一旦 
学习 到 图片 左上角 的 模式 特征 可以 在 任何 
地方 识别 如 右下角 这种 特性 使得 图片 处理 更加 
有效 需要 的 样本 相对 减少 实际 生活 中 具有 
平移 不变性 学习 模式 的 空间 层次结构 第一 个 卷积 
层 将 学习 小 的 局部 模式 如 边缘 第二个 
卷积 层 将 学习 由 第一 层 特征 构成 的 
更大 图案 等等 这 使得 卷积 网络 能够 有效 地 
学习 越来越 复杂 和 抽象 的 视觉 概念 现实 生活 
中 许多 都是 分级 的 卷 积在 3D 张量 上 
运算 称 为特征 映射 具 有 两个 空间 轴 高度 
和 宽度 以及 深度 轴 也 称为 通道 轴 . 
对 RGB 三原色 图片 来说 通 道数 为 3 红 
绿 蓝 MNIST 数据 集中 图片 通 道数 为 1 
灰度 图 卷积 操作 在 输入 特征 图上 小分 片上 
然后 将 多个 操作 结果 生成 最后 的 特征 图 
输出 的 特征 图 仍然 是 3D 张量 width height 
深度 可以 是 任意 值 因为 深度 是 网络层 的 
一个 参数 而且 深度 值 不再 代表 红绿蓝 颜色通道 表示 
过滤器 的 个数 过滤器 对 输入 数据 的 特定 方面 
进行 编码 比如 在 高级别 单个 过滤器 可以 编码 输入 
中 存在 面部 的 概念 卷积 定义 的 两个 参数 
卷积 核 大小 通常 为 3x3 5x5 . 卷积 核 
个数 卷积 核 个数 等于 本 层 网络 输出 层 
的 深度 Keras 中 Conv2D 网络层 定义 Conv2D output _ 
depth window _ height window _ width . 卷积 卷积 
核 在上 一层 的 特征 图 的 全 通道 进行 
滑动 然后 抽取 形状 为 window _ height window _ 
width input _ depth 形状 的 3D 片 特征 每个 
3D 片 特征 最后 转换成 1D 向量 卷积 运算 张量 
点积 形状 output _ depth 所有 的 结果 向量 整合 
形成 最后 的 3D 特征 height width output _ depth 
./i 输出/v 结果/n 的/uj 宽度/n 和/c 高度/n 可能/v 和/c 输入/v 
宽度/n 高度/n 不同/a 由于 Padding 项 Strides 步长 最大 池化/nr 
MaxPooling 最大 池化层/nr 的 作用 在于 对 特征 图 进行 
下 采样 最大 池化在/nr 特征 图中 选择 window 然后 每个 
通道 的 在 窗口 内 求 最大值 概念上 与 卷积 
操作 类似 卷积 操 作在 小 patch 中 做 线性转换 
最大 池化是/nr 求 最大值 通过 tensor 的 max 张量 操作 
最大 池化/nr 通常 采用 2x2 窗口 步 长为 2 特征 
图 减半 卷积 通常 卷积 核 大小 为 3x3 步 
长为 1 下 采样 的 目的 在于 减少 要 处理 
特征 图 的 参数 量 通过 使 连续 的 卷积 
层 看到 越来越 大 的 窗口 就 它们 所 涵盖 
的 原始 输入 的 比例 而言 来 促使 空间 滤波器 
层次结构 最大 池化并/nr 不是 唯一 的 下 采 样方法 可以 
使 用带 步长 卷积 或 平均 池化/nr 但是 最大 池化的/nr 
工作 效果 更好 小 数据集 上 训练 卷积 网络计算机 视觉 
中 进场 会 遇到 使用 很少 的 数据 集 去 
训练 一个 图像 分类 模型 小 样本 意味着 样本量 在 
几百 到 几 万张 . 比如 猫狗 分类 共 4000张 
图片 猫 2000张 狗 2000张 用 2000张 图片 来 训练 
1000张 验证 集 1000张 测试 集 首先 不 做 任何 
正则化 处理 直接 训练 得到 一个 baseline 模型 准确率 为 
71% 主要 问题 在于 模型 过拟合 之后 介绍 data augmentation 
数据 增强 减缓 过拟合 训练 后为 82% 更 有效 的 
方法 是 用 已 训 练好 的 模型 最 特征提取 
准确率 90% 96% 或者 微调 已 训 练好 的 网络 
做 特征提取 97% 这三种 方法 有助于 在 小 数据 集上 
的 模型 训练 深度 学习 与 小 数据 问题 的 
相关性 可能 经常 听说 深度 学习 只能 工作 在 大 
数据 集上 这种 说法 部分 正确 深度 学习 的 一个 
重要 特性 在于 深度 学习 能 自己 在 训练 数据 
中 寻找 特征 而 不 需要 人工干预 而 这个 特性 
只有在 大 数据 样本量 上 才 有效 特别 是 输入 
数据 维度 特别高 时 eg 图片 但是 对于 初学者 来说 
构成 大量 样本 的 内容 与 尝试 训练 的 网络 
的 大小 和 深度 是 相对 的 用 几十 张 
图片 训练 卷积 网络 来 解决 一个 十分 复杂 的 
问题 是 不 可能 的 但 如果 模型 比较简单 经过 
正则化 处理 同时 任务 比较 简单 几百/m 张/q 图片/n 也/d 
能/v 解决问题/n 因为 卷积 网络 学习 局部 的 具有 平移 
不变性 的 特征 它们 在 感知 问题 上 具有 很高 
的 数据 效率 尽管 相对 缺乏 数据 但 无需 额外 
的 特征 工程 即使 在 非常 小 的 图像 数据 
集上 从头 开始 训练 卷积 网络 仍然 会 产生 合理 
的 结果 更 重要 的 是 深度 学习 模型 本质上 
是 高度 可再 利用 的 例如 可以 采用 在 大规模 
数据 集上 训练 的 图像 分类 或 语音 到 文本 
模型 只需 进行 微小 的 更改 就 可以 重新 用于 
显著 不同 的 问题 上 具体 而言 以 计算机 视觉 
为例 许多 预先 训 练好 的 模型 通常在 ImageNet 数据集 
上 训练 提供 公开 下载 当 样本量 少时 可以 用 
在 模型 中 做 特征提取 使用 提升 工作 效果 数据 
下载 Keras 中 没有 包括 Dogs vs . Cats 数据集 
可以 在 Kaggle 上 下载 图片格式 为 JPEGs . 数据集 
包含 25000张 猫狗 图片 一半一半 下载 解压缩 后 创建 一个 
新 数据集 包括 3个 文件夹 每类 1000张 的 训练 集 
每类 500张 的 验证 集 和 每类 500张 的 测试 
集 import os shutil # 原始数据 original _ dataset _ 
dir = / Users / fchollet / Downloads / kaggle 
_ original _ data # 新 数据集 目录 base _ 
dir = / Users / fchollet / Downloads / cats 
_ and _ dogs _ small os . mkdir base 
_ dir # 创建 训练 集 验证 集 测试 集 
目录 train _ dir = os . path . join 
base _ dir train os . mkdir train _ dir 
validation _ dir = os . path . join base 
_ dir validation os . mkdir validation _ dir test 
_ dir = os . path . join base _ 
dir test os . mkdir test _ dir # 创建 
对应 数据集 下 不同 类别 的 目录 train _ cats 
_ dir = os . path . join train _ 
dir cats os . mkdir train _ cats _ dir 
train _ dogs _ dir = os . path . 
join train _ dir dogs os . mkdir train _ 
dogs _ dir validation _ cats _ dir = os 
. path . join validation _ dir cats os . 
mkdir validation _ cats _ dir validation _ dogs _ 
dir = os . path . join validation _ dir 
dogs os . mkdir validation _ dogs _ dir test 
_ cats _ dir = os . path . join 
test _ dir cats os . mkdir test _ cats 
_ dir test _ dogs _ dir = os . 
path . join test _ dir dogs os . mkdir 
test _ dogs _ dir fnames = cat . { 
} . jpg . format i for i in range 
1000 # 取 前 1000张 猫 图片 for fname in 
fnames # 将 前 一千张 猫 图片 复制到 新 数据集 
目 录下 src = os . path . join original 
_ dataset _ dir fname dst = os . path 
. join train _ cats _ dir fname shutil . 
copyfile src dst fnames = cat . { } . 
jpg . format i for i in range 1000 1500 
# 取 500张 猫 图片 for fname in fnames # 
500张 猫 图片 复制到 验证 集 src = os . 
path . join original _ dataset _ dir fname dst 
= os . path . join validation _ cats _ 
dir fname shutil . copyfile src dst fnames = cat 
. { } . jpg . format i for i 
in range 1500 2000 # 取 500张 猫 图片 for 
fname in fnames # 500张 猫 图片 做 测试 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
test _ cats _ dir fname shutil . copyfile src 
dst # 狗 图片 fnames = dog . { } 
. jpg . format i for i in range 1000 
# 1000张 狗 图片 做 训练 集 for fname in 
fnames src = os . path . join original _ 
dataset _ dir fname dst = os . path . 
join train _ dogs _ dir fname shutil . copyfile 
src dst fnames = dog . { } . jpg 
. format i for i in range 1000 1500 for 
fname in fnames # 500张 狗 图片 做 验证 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
validation _ dogs _ dir fname shutil . copyfile src 
dst Copies the next 500 fnames = dog . { 
} . jpg . format i for i in range 
1500 2000 for fname in fnames # 500张 狗 图片 
做 测试 集 src = os . path . join 
original _ dataset _ dir fname dst = os . 
path . join test _ dogs _ dir fname shutil 
. copyfile src dst 构建 模型 from keras import layers 
from keras import models model = models . Sequential model 
. add layers . Conv2D 32 3 3 activation = 
relu input _ shape = 150 150 3 model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 64 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Flatten model . add layers . Dense 512 activation 
= relu model . add layers . Dense 1 activation 
= sigmoid 模型 架构 model . summary Layer type Output 
Shape Param # = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = conv2d _ 1 
Conv2D None 148 148 32 896 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
maxpooling2d _ 1 MaxPooling2D None 74 74 32 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ conv2d _ 2 Conv2D None 72 72 
64 18496 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ maxpooling2d _ 2 MaxPooling2D 
None 36 36 64 0 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ conv2d 
_ 3 Conv2D None 34 34 128 73856 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ maxpooling2d _ 3 MaxPooling2D None 17 17 128 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ conv2d _ 4 Conv2D None 
15 15 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
4 MaxPooling2D None 7 7 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ flatten _ 1 Flatten None 6272 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ dense _ 1 Dense None 512 3211776 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ dense _ 2 Dense None 1 513 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = Total params 3 453 121 Trainable 
params 3 453 121 Non trainable params 0 编译 阶段 
使用 RMSProp 优化 算法 binary crossentropy 为 损失 函数 from 
keras import optimizers model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 4 
metrics = acc 数据 预处理 数据 在 送到 网络 模型 
之前 应该 转换成 浮点 类型 的 张量 目前 数据 集中 
数据格式 为 JPEG 所以 处理 步骤 大致 为 读取 图片 
文件 将 JPEG 格式 转换 为 RGB 像素 值 转换成 
浮点 类型 张量 将 像素 值 0 ~ 255 缩 
放到 0 1 之间 针对 上述 步骤 Keras 中有 自动化 
处理 方法 Keras 中 有一个 图像处理 模块 keras . preprocessing 
. image . 其中 包括 一个 I m a g 
e D a t a G e n e r 
a t o r 类 可以 将 磁 盘上 的 
图片 文件 自动 转换 成 预处理 的 张量 batch 批量 
使用 方法 from keras . preprocessing . image import I 
m a g e D a t a G e 
n e r a t o r train _ datagen 
= I m a g e D a t a 
G e n e r a t o r rescale 
= 1 . / 255 test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 # 将 图片 转换成 150x150 类别 为 
2 class _ mode 确定 返回 标签 的 类型 binary 
二 分类 1D 类型 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
\ target _ size = 150 150 batch _ size 
= 20 class _ mode = binary validation _ generator 
= test _ datagen . flow _ from _ directory 
validation _ dir target _ size = 150 150 batch 
_ size = 20 class _ mode = binary 生成器 
generator 的 数据 结果 为 150x150 RGB 批量 图片 尺寸 
为 20 150 150 3 二进制 标签 形状 20 每个 
批量 大小 为 20个 样本 batch _ size 为 20 
. 注意 生成器 无限期 地 生成 这些 批次 它 在 
目标 文件夹 的 图像 上 无休止 地 循环 使用 generator 
数据 生成器 对模型 进行 训练 使用 fit _ generator 方法 
对于 数据 生成器 来说 相当于 fit 方法 fit _ generator 
第一个 参数 是 Python 生成器 类型 能/v 不断/d 地/uv 生成/v 
输入/v 和/c 标签/n 批量/n 因为 数据 不断 生成 Keras 模型 
需要 知道 在 声明 一个 epoch 之前 从 发生器 中 
抽取 多少 批量 steps _ per _ epoch 参数 从 
生成器 中 生成 steps _ per _ epoch 个 批量 
数据 在 经过 steps _ per _ epoch 次梯度 下降 
后 在 下 一个 epoch 上 进行 训练 在 这里 
批量 大小 为 20 一个 epoch 有 100个 批量 生成 
2000张 图片 样本 使用 fit _ generator 方法 可以 传递 
validataion _ data 参数 和 fit 方法 相似 值得 注意 
的 是 这个 参数 可以 赋值 为 数据 生成器 也 
可以 是 numpy 数组 的 元组 如果 validation _ data 
参数 是 数据 生成器 生成器 能 不断 地 生成 数据 
所以 需要 设置 validation _ steps 参数 确定 从 生成器 
中 生成 多少 验证 集 批量 history = model . 
fit _ generator train _ generator steps _ per _ 
epoch = 100 epoch = 30 validation _ data = 
validation _ generator validation _ steps = 50 模型 保存 
model . save cats _ and _ dogs _ small 
_ 1 . h5 训练 集 验证 集 准确率 损失 
值 变化 可以 发现 模型 发生 过拟合 现象 训练 准确率 
随着 时间 线性 增加 直到 100% 而 验证 集 准确率 
在 70 72% 波动 验证 集 损失 在 5个 epoch 
之后 达到 最小值 之后 开始 波动 训练 集 损失 线性 
减少 直到 为 0 因为 训练 集 只有 2000张 图片 
遇到 的 第一 个 问题 就是 模型 过拟合 Dropout 权重 
衰减 可以 减缓 过拟合 还有 一个 计算机 视觉 任务 中 
经常 使用 的 处理 方法 数据 增强 data augmentation 数据 
增强 过度 拟合 是 由于 样本 太少 而 无法 学习 
导致 无法 训练 可以 推广 到 新 数据 的 模型 
给定 无限 的 数据 模型 可以 学习 到 手头 数据分布 
的 每个 可能 方面 永远 不会 过拟合 数据 增强 采用 
从 现有 训练样本 生成 更多 训练 数据 的 方法 通过 
大量 随机 变换 来 增加 样本 从而 产生 新的 可靠 
的 图像 样本 目标 是 在 训练 时 模型 将 
永远 不会 看到 两张 完全 相同 的 图片 这 有助于 
模型 观察 数据 的 更多 方面 并 更好 地 概括 
数据 Keras 中 可以 通过 实例 化 I m a 
g e D a t a G e n e 
r a t o r 实例 确定 图片 转换方法 从而 
实现 数据 增强 datagen = I m a g e 
D a t a G e n e r a 
t o r rotation _ range = 40 # 最大 
旋转 角度 width _ shift _ range = 0.2 # 
水平 随机 平移 图片 的 范围 比例 height _ shift 
_ range = 0.2 # 垂直 随机 平移 图片 的 
范围 shear _ range = 0.2 # 随机 应用 剪切 
变换 zoom _ range = 0.2 # 随机 缩放 图片 
horizontal _ flip = True # 随机 翻转 图片 fill 
_ mode = nearest # 用于 填充 新 创建 的 
像素 的 策略 在 旋转 或 宽度 / 高度 偏移 
后 出现 如果 使用 这样 的 数据 增强 配置 训练 
新 网络 网络 将 永远 不会 看到 两张 相同 的 
输入 图片 但 它 看到 的 输入 仍然 是 严重 
相互 关联 的 因为 它们 来自 少量 原始 图像 无法 
生成 新 信息 只能 重新 混合 现有 信息 因此 这 
不 可能 完全 摆脱 过拟合 为了 进一步 减缓 过拟合 需要 
增加 Dropout 层 在 全 连接 层 之前 新 网络 
模型 model = models . Sequential model . add layers 
. Conv2D 32 3 3 activation = relu input _ 
shape = 150 150 3 model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 64 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Flatten model 
. add layers . Dropout 0.5 model . add layers 
. Dense 512 activation = relu model . add layers 
. Dense 1 activation = sigmoid model . compile loss 
= binary _ crossentropy optimizer = optimizers . RMSprop lr 
= 1e 4 metrics = acc 使用 数据 增强 和 
Dropout 训练 网络 train _ datagen = I m a 
g e D a t a G e n e 
r a t o r rescale = 1 . / 
255 rotation _ range = 40 width _ shift _ 
range = 0.2 height _ shift _ range = 0.2 
shear _ range = 0.2 zoom _ range = 0.2 
horizontal _ flip = True test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 train _ generator = train _ datagen 
. flow _ from _ directory train _ dir target 
_ size = 150 150 batch _ size = 32 
class _ mode = binary validation _ generator = test 
_ datagen . flow _ from _ directory validation _ 
dir target _ size = 150 150 batch _ size 
= 32 class _ mode = binary history = model 
. fit _ generator train _ generator steps _ per 
_ epoch = 100 epochs = 100 validation _ data 
= validation _ generator validation _ steps = 50 model 
. save cats _ and _ dogs _ small _ 
2 . h5 # 模型 保存 使用 数据 增强 和 
Dropout 后 训练 集 验证 集 准确率 和 损失 函数 
变化 模型 不再 过拟合 训练 集 曲线 和 验证 集 
曲线 几乎 相互 吻合 准确率 82% 提高 了 15% 左右 
使用 正则化 技术 微调 网络 超 参数 模型 准确率 会 
进一步 提高 到 86% ~ 87% . 但是 很难 继续 
提高 因为 训练 数据 有限 样本 量 太少 另一种 方法 
可以 采用 预先 训 练好 的 网络 模型 做 特征提取 
提高 准确率 使用 预 训练 卷积 网络 在 小 图像 
数据 集上 使用 深度 学习 的 一种 常见 且 高效 
的 方法 是 使用 预 训练 网络 预 训练 网络 
是 先前 在 大型 数据集 上 训练 的 已 保存 
网络 通常 是 处理 大规模 图像 分类 任务 如果 这个 
原始 数据集 足够 大 且 代表 性强 则 预 训练 
网络 学习 的 特征 的 空间 层次结构 可以 有效 地 
充当 视觉 世界 的 通用 模型 因此 其 特征 可以 
证明 对 许多 不同 的 计算机 视觉 问题 都 有用 
甚至 这些 新 问题 可能 涉及 与 原始 任务 完全 
不同 例如 可以 在 ImageNet 上 训练 网络 其中 类 
主要 是 动物 和 日常 物品 然后 将 这个 训练 
好 的 网络 重新 用于 识别 图像 中 的 家具 
物品 任务 中 与 许多 较 旧 的 浅 学习 
方法 传统 机器学习 方法 相比 学习 特征 在 不同 问题 
中 的 这种 可移植性 是 深度 学习 的 关键 优势 
并且 它 使得 深度 学习 对于 小 数据 问题 非常 
有效 比如 在 ImageNet 数据集 上 训练 的 网络 模型 
140 万个 标记 图像 和1/nr 000个 不 同类 ImageNet 包含 
许多 动物 类别 包括 不同 种类 的 猫 和狗/nr 因此 
可以 期望 在 狗 与 猫 的 分类 问题 上 
表现 良好 使用 VGG16 网络 架构 它 是 ImageNet 的 
简单 且 广泛 使用 的 convnet 架构 使用 预 训练 
网络 有 两种 方法 特征提取 和 微调 特征提取 特征提取 包括 
使用 先前 网络 学习 的 表示 从新 样本 中 提取 
有趣 特征 然后 这些 功能 将 通过 一个 新的 分类器 
运行 该 分类器 从头 开始 训练 如前所述 用于 图像 分类 
的 网络 包含 两 部分 它们/r 以/p 一/m 系列/q 池化和/nr 
卷积/n 层/q 开始/v 并以 密集 连接 的 分类器 结束 第一 
部分 称为 模型 的 卷积 基础 在 卷积 网络 中 
特征提取 包括 获取 先前 训练 的 网络 的 卷积 基础 
通过 它 运行 新 数据 以及 在 输出 之上 训练 
新的 分类器 为什么 只 重用 卷积 网络 是否 可以 重复 
使用 全 连接 分类器 一般来说 应该 避免 这样 做 原因 
是 卷积 网络 学习 的 表示 可能 更 通用 因此 
更 可 重复 使用 特征 网络 的 特征 图 是 
图片 上 一般 概念 的 存在 图 无论 处理 的 
计算机 视觉 问题 是 什么 都 可能 是 有用 的 
但是 分类器 学习 的 表示 必然 特 定于 训练 模型 
的 类 集 它们 将 仅 包含 关于 整个 图像 
中 该类 或 该类 的 存在 概率 的 信息 此外 
在 全 连接 网络层 的 输出 表示 不再 包含 有关 
对象 在 输入 图像 中 的 位置 信息 这些 表示 
消除 了 空间 的 概念 而 卷积 特征 图 还 
可以 描述 对象 的 位置 信息 对于 对象 位置 很 
重要 的 问题 全 连接 的 特征 表示 在 很大 
程度 上 是 无用 的 注意 由 特定 卷积 层 
提取 的 表示 的 一般性 以及 因此 可 重 用性 
的 级别 取决于 模型 中 网络层 的 深度 模型 中 
较早 出现 的 图层 会 提取 局部 的 高度 通用 
的 特征 贴图 例如 可视 边缘 颜色 和 纹理 而 
较 高层 的 图层 会 提取 更 抽象 的 概念 
例如 猫耳朵 或 狗眼 因此 如果 训练 数据集 与 训练 
原始 模型 的 数据 集 有 很大 差异 那么 最好 
只 使用 模型 的 前 几层 来 进行 特征提取 而 
不是 使用 整个 卷积 网络 的 输出 在 这种 情况 
下 因为 ImageNet 类 集 包含 多个 dog 和 cat 
类 所以 重用 原始 模型 的 全 连接 层 中 
包含 的 信息 可能 是 有益 的 但是 我们 会 
选择 不 这样 做 以便 涵盖 新 问题 的 类 
集 不与 原始 模型 的 类 集 重叠 的 更 
一般情况 通过 使用 在 ImageNet 上 训练 的 VGG16 网络 
的 卷积 网络 来 实现 这 一点 从猫和/nr 狗/n 图像/n 
中/f 提取/v 有趣/a 的/uj 特征/n 然后 在 这些 特征 之上 
训练 狗 与 猫 的 分类器 Keras 中 可以 直接 
获取 VGG16 模型 包含 在 keras . applications 模块 中 
其中 还 包括 其他 模型 X c e p t 
i o n I n c e p t i 
o n V 3 R e s N e t 
5 0 V G G 1 6 V G G 
1 9 M o b i l e N e 
t 实例 化 VGG16 模型 from keras . application import 
vgg16 conv _ base = VGG16 weights = imagenet include 
_ top = False input _ shape = 150 150 
3 构造器 的 3个 参数 weights 读取 权重 保存 点 
文件 初始化 模型 include _ top 是否 包含 网络 的 
全 连接 层 模型 全 连接 层 分类 类别 在 
ImageNet 上 的 1000类 因为 要 使用 自己 创建 的 
全 连接 分类器 可以 不 使用 原来 的 全 连接 
层 input _ shape 送到 模型 中 图片 张量 的 
形状 参数 是 可选 的 如果 不 传递 参数 网络 
可以 处理 任意 形状 的 输入 VGG16 网络 模型 架构 
conv _ base . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = input _ 1 InputLayer None 
150 150 3 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block1 _ 
conv1 Convolution2D None 150 150 64 1792 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block1 _ conv2 Convolution2D None 150 150 64 36928 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block1 _ pool MaxPooling2D None 75 
75 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block2 _ conv1 
Convolution2D None 75 75 128 73856 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block2 _ conv2 Convolution2D None 75 75 128 147584 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block2 _ pool MaxPooling2D None 37 37 
128 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block3 _ conv1 Convolution2D 
None 37 37 256 295168 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block3 
_ conv2 Convolution2D None 37 37 256 590080 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block3 _ conv3 Convolution2D None 37 37 256 
590080 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block3 _ pool MaxPooling2D None 
18 18 256 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block4 _ 
conv1 Convolution2D None 18 18 512 1180160 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block4 _ conv2 Convolution2D None 18 18 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block4 _ conv3 Convolution2D None 18 
18 512 2359808 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block4 _ pool 
MaxPooling2D None 9 9 512 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block5 _ conv1 Convolution2D None 9 9 512 2359808 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block5 _ conv2 Convolution2D None 9 9 
512 2359808 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block5 _ conv3 Convolution2D 
None 9 9 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block5 
_ pool MaxPooling2D None 4 4 512 0 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 14 714 688 Trainable params 14 
714 688 Non trainable params 0 最后 一层 的 特征 
图 形状 为 4 4 512 . 之后 连接 到 
全 连接 分类器 上 有 两种 处理 方法 训练 卷积 
网络 模型 部分 将 输出 结果 保存 在 磁 盘上 
之后 读取 磁 盘上 的 数据 送到 全 连接 分类器 
中 优点 在于 运行 高效 快速 因为 卷积 网络 部分 
针对 每张 输入 图片 只 运行 一次 而 卷积 部分 
是 最 耗时 耗费 运算 能力 资源 的 但 同时 
不能 使用 数据 增强 将/d 全/a 连接/v 分类器/n 和/c 卷积/n 
部分/n 整合/v 到/v 一起/m 在 输入 数据 上端 到 端的 
运行 可以 使用 数据 增强 因为 每次 输入 模型 的 
图像 都会 通过 模型 经过 卷积 部分 不/d 使用/v 数据/n 
增强/v 的/uj 特征/n 提取/v 使用/v I/w m/w a/w g/w e/w 
D/w a/w t/w a/w G/w e/w n/w e/w r/w a/w 
t/w o/w r/w 将/d 磁盘/n 文件/n 和/c 标签/n 读取/v 成/n 
张量/nr 形式/n 运行 卷积 部分 的 predict 提取 图片 特征 
import os import numpy as np from keras . preprocessing 
. image import I m a g e D a 
t a G e n e r a t o 
r base _ dir = / Users / fchollet / 
Downloads / cats _ and _ dogs _ small train 
_ dir = os . path . join base _ 
dir train # 训练 数据 validation _ dir = os 
. path . join base _ dir validation # 验证 
数据 test _ dir = os . path . join 
base _ dir test # 测试数据 datagen = I m 
a g e D a t a G e n 
e r a t o r rescale = 1 . 
/ 255 # batch _ size = 20 def extract 
_ features directory sample _ count # 读取 文件 转换成 
张量 形式 features = np . zeros shape = sample 
_ count 4 4 512 labels = np . zeros 
shape = sample _ count generator = datagen . flow 
_ from _ directory directory target _ size = 150 
150 batch _ size = batch _ size class _ 
mode = binary i = 0 for inputs _ batch 
labels _ batch in generator # 生成 对应 批量 数据 
features _ batch = conv _ base . predict inputs 
_ batch # 卷积 特征提取 结果 features i * batch 
_ size i + 1 * batch _ size = 
features _ batch labels i * batch _ size i 
+ 1 * batch _ size = labels _ batch 
i + = 1 if i * batch _ size 
= sample _ count break return features labels train _ 
features train _ labels = extract _ features train _ 
dir 2000 validation _ features validation _ labels = extract 
_ features validation _ dir 1000 test _ features test 
_ labels = extract _ features test _ dir 1000 
当前 提取 特征 形状 为 samples 4 4 512 在 
送到 全 连接 层 之前 需要 先 平 铺成 samples 
8192 train _ features = np . reshape train _ 
features 2000 4 * 4 * 512 validation _ features 
= np . reshape validation _ features 1000 4 * 
4 * 512 test _ features = np . reshape 
test _ features 1000 4 * 4 * 512 定义 
全 连接 分类器 将 特征 数据 送到 分类器 中 训练 
from keras import models from keras import layers from keras 
import optimizers model = models . Sequential model . add 
layers . Dense 256 activation = relu input _ dim 
= 4 * 4 * 512 model . add layers 
. Dropout 0.5 model . add layers . Dense 1 
activation = sigmoid model . compile optimizer = optimizers . 
RMSprop lr = 2e 5 loss = binary _ crossentropy 
metrics = acc history = model . fit train _ 
features train _ labels epochs = 30 batch _ size 
= 20 validation _ data = validation _ features validation 
_ labels 验证 集 训练 集上 损失 值 和 准确率 
变化 情况 验证 集 准确率 达到 90% . 但 图示 
显示 模型 从 开始 就 过拟合 了 使用 数据 正 
增强 可以 缓解 一下 使用 数据 增强 的 特征 提取 
和 第一 种 方法 相比 运算速度 更慢 耗费 运算 资源 
更多 通常 需要 GPU 如果 GPU 上 速度 还慢 最好 
使用 第 一种 方法 from keras import models from keras 
import layers model = models . Sequential model . add 
conv _ base model . add layers . Flatten model 
. add layers . Dense 256 activation = relu model 
. add layers . Dense 1 activation = sigmoid 模型 
架构 为 model . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = vgg16 Model None 4 4 
512 14714688 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ flatten _ 1 Flatten 
None 8192 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ dense _ 1 
Dense None 256 2097408 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ dense _ 
2 Dense None 1 257 = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = Total 
params 16 812 353 Trainable params 16 812 353 Non 
trainable params 0 在 模型 训练 之前 需要 对 卷积 
部分 进行 freeze 冻住 Freezing 网络层 意味着 避免 在 训练 
过程 网络层 的 参数 被 更新 如果 不 做 freeze 
处理 训练 过程 中 卷积 部分 提取 的 特征 会 
逐渐 改变 在 Keras 中 可以 通过 设置 trainable 参数 
为 False 进行 Freeze 处理 conv _ base . trainable 
= False 注意 为了 使 这些 更改 生效 必须 首先 
编译 模型 如果在 编译 后 修改 了 权重 可 训练 
性 则应 重新 编译 模型 否则 将 忽略 这些 更改 
from keras . preprocessing . image import I m a 
g e D a t a G e n e 
r a t o r from keras import optimizers train 
_ datagen = I m a g e D a 
t a G e n e r a t o 
r rescale = 1 . / 255 rotation _ range 
= 40 width _ shift _ range = 0.2 height 
_ shift _ range = 0.2 shear _ range = 
0.2 zoom _ range = 0.2 horizontal _ flip = 
True fill _ mode = nearest test _ datagen = 
I m a g e D a t a G 
e n e r a t o r rescale = 
1 . / 255 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
target _ size = 150 150 batch _ size = 
20 class _ mode = binary validation _ generator = 
test _ datagen . flow _ from _ directory validation 
_ dir target _ size = 150 150 batch _ 
size = 20 class _ mode = binary model . 
compile loss = binary _ crossentropy optimizer = optimizers . 
RMSprop lr = 2e 5 metrics = acc history = 
model . fit _ generator train _ generator steps _ 
per _ epoch = 100 epochs = 30 validation _ 
data = validation _ generator validation _ steps = 50 
损失 值 和 准确率 变化 验证 集上 准确率 达到 96% 
. 模型 微调 Fine tuning 另一种 广泛 使用 的 模型 
重用 技术 对 特征提取 的 补充 就是 模型 参数 微调 
微调 包括 解冻 用于 特征提取 的 冻结 模型 基础 的 
一些 顶层 并 联合 训练 模型 的 新 添加 部分 
在 这种 情况 下 全 连接 的 分类器 和 这些 
顶层 这 称为 微调 因为 它 稍微 调整了 重复 使用 
的 模型 的 抽象 表示 以使 它们 与 手头 的 
问题 更 相关 微调 网络 模型 步骤 在 已经 训 
练好 的 网络 模型 上 添加 自定义 网络 模型 Freeze 
冻住 训 练好 的 模型 训练 添加 部分 网络 Unfreeze 
解冻 部分 base 网络 重新 训练 解冻 部分 和 添加 
部分 base 部分 网络 模型 conv _ base . summary 
Layer type Output Shape Param # = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
input _ 1 InputLayer None 150 150 3 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block1 _ conv1 Convolution2D None 150 150 
64 1792 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block1 _ conv2 Convolution2D 
None 150 150 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block1 
_ pool MaxPooling2D None 75 75 64 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block2 _ conv1 Convolution2D None 75 75 128 
73856 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block2 _ conv2 Convolution2D None 
75 75 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block2 _ 
pool MaxPooling2D None 37 37 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block3 _ conv1 Convolution2D None 37 37 256 295168 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block3 _ conv2 Convolution2D None 37 
37 256 590080 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block3 _ conv3 
Convolution2D None 37 37 256 590080 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block3 _ pool MaxPooling2D None 18 18 256 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block4 _ conv1 Convolution2D None 18 18 
512 1180160 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block4 _ conv2 Convolution2D 
None 18 18 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block4 
_ conv3 Convolution2D None 18 18 512 2359808 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block4 _ pool MaxPooling2D None 9 9 512 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block5 _ conv1 Convolution2D None 
9 9 512 2359808 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block5 _ 
conv2 Convolution2D None 9 9 512 2359808 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block5 _ conv3 Convolution2D None 9 9 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block5 _ pool MaxPooling2D None 4 
4 512 0 = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = Total params 14714688 
微调 模型 的 最后 3个 卷积 层 意味着 到 block4 
_ pool 之前 都被 冻住 网络层 block5 _ conv1 block5 
_ conv2 和 block5 _ conv3 都是 可 训练 的 
为什么 不 微调 更 多层 为什么 不 微调 整个 卷积 
网络 可以 这么 做 但是 你 需要 考虑 以下 几点 
卷积 网络 中的 前 几层 编码 更 通用 可 重用 
的 特征 而 更 高层 的 编码 更 专业 的 
特征 微调 更 专业 的 功能 更 有用 因为 这些 
功能 需要 重新 用于 新 问题 微调 下层 会有 快速 
下降 的 回报 训练 的 参数 越多 越有/nr 可能/v 过度/n 
拟合/v 卷积 网络 模型 有 1500 万个 参数 因此 尝试 
在 小 数据集 上 训练 它 会有 风险 一个 很好 
的 策略 是 只 微调 卷积 基础 中的 前 两个 
或 三个 层 conv _ base . trainable = True 
set _ trainable = False for layer in conv _ 
base . layers if layer . name = = block5 
_ conv1 # block5 _ conv1 可 训练 set _ 
trainable = True # flag 可 训练 if set _ 
trainable layer . trainable = True # block5 _ conv1 
网络层 设置 为 可 训练 else layer . trainable = 
False # 其它 层 不可 训练 现在 可以 开始 微调 
网络 了 使用 RMSProp 优 化器 以 非常 低 的 
学习 速率 执行 此 操作 使用 低 学习率 的 原因 
是 希望 限制 对 正在 微调 的 三个 网络层 的 
表示 所做 的 修改 的 幅度 太大 的 更新 可能会 
损害 这些 表示 model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 5 
metrics = acc history = model . fit _ generator 
train _ generator steps _ per _ epoch = 100 
epochs = 100 validation _ data = validation _ generator 
validation _ steps = 50 验证 集 测试 集上 损失 
函数 和 准确率 变化 请注意 损失 曲线 没有 显示 任何 
真正 的 改善 事实上 它 正在 恶化 如果 损失 没有减少 
准确度 如何 保持 稳定 或 改善 答案 很 简单 展示 
的 是 指数 损失 值 的 平均值 但是 对于 准确性 
而言 重要 的 是 损失 值 的 分布 而 不是 
它们 的 平均值 因为 精度 是 模型 预测 的 类 
概率 的 二元 阈值 的 结果 即使 没有 反映 在 
平均 损失 中 该 模型 仍 可能会 有所 改善 在 
测试 集上 评估 test _ generator = test _ datagen 
. flow _ from _ directory test _ dir target 
_ size = 150 150 batch _ size = 20 
class _ mode = binary test _ loss test _ 
acc = model . evaluate _ generator test _ generator 
steps = 50 print test acc test _ acc # 
97% 小结 Convnets 是 用于 计算机 视觉 任务 的 最佳 
机器学习 模型 即使 在 非常 小 的 数据 集上 也 
可以 从头 开始 训练 并 获得 不错 的 结果 在 
小型 数据 集上 过度 拟合 将 是 主要 问题 在 
处理 图像 数据 时 数据 增强 是 对抗 过度 拟合 
的 有效 方法 通过 重用 现有 的 卷积 网络 模型 
可以 在 新 数据 集上 做 特征提取 这是 处理 小 
图像 数据集 的 有用 技术 作为 特征提取 的 补充 可以 
使用 模型 微调 让 模型 适应 新 问题 以前 现有 
模型 可以 学习 新 问题 的 特征 表示 能 进一步 
推动 性能 卷积 学习 结果 可视化 人们 常说 深度 学习 
模型 是 黑匣子 学习 表示 难以 提取 以及 很难 以 
人类 可读 的 形式 呈现 虽然 对于 某些 类型 的 
深度 学习 模型 来说 这 是 部分 正确 的 但 
对于 convnets 来说 绝对 不是 这样 由 convnet 学习 的 
表示 非常 适合 可视化 这在 很大 程度 上 是因为 它们 
是 视觉 概念 的 表示 三种 常见 的 可视化 方法 
可视化 中间 信号 输出 中间 激活 有助于 了解 连续 的 
convnet 层 如何 转换 输入 数据 以及 了解 各个 convnet 
过滤器 的 含义 可视化 convnets 过滤器 有助于 准确 理解 convnet 
中 每个 过滤器 可 接受 的 视觉 模式 或 概念 
可视化 图像 中 类 激活 的 热 图 有助于 了解 
图像 的 哪些 部分 被 识别 为 属于 给定 的 
类 从而 可以 在 图像 中 本地化 对象 可视化/n 中间/f 
激活/a 值/n 可视化/n 中间/f 激活/a 包括/v 在/p 给定/v 特定/d 输入/v 
的/uj 情况/n 下/f 显示/v 由/p 网络/n 中/f 的/uj 各种/r 卷积/n 
和池化/nr 层/q 输出/v 的/uj 特征/n 映射/v 层 的 输出 通常 
称 为其 激活 激活 函数 的 输出 这 给出 了 
如何 将 输入 分解 为 网络 学习 的 不同 过滤器 
的 视图 希望 从 三个 维度 宽度 高度 和 深度 
通道 可视化 特征 图 每个 通道 编码 相对 独立 的 
特征 因此 可视化 这些 特征 图 的 正确 方法 是 
通过 将 每个 通道 的 内容 独立 地 绘制 为 
2D 图像 加载 保存 的 模型 from keras . models 
import load _ model model = load _ model cats 
_ and _ dogs _ small _ 2 . h5 
img _ path = . / cats _ and _ 
dogs _ small / test / cats / cat . 
1700 . jpg # 给定 一张 图片 from keras . 
preprocessing import image import numpy as np img = image 
. load _ img img _ path target _ size 
= 150 150 img _ tensor = image . img 
_ to _ array img img _ tensor = np 
. expand _ dims img _ tensor axis = 0 
img _ tensor / = 255 . 查看 所有 网络层 
的 输出 结果 from keras import models layer _ outputs 
= layer . output for layer in model . layers 
8 activation _ model = models . Model inputs = 
model . input outputs = layer _ outputs 输入 图像 
输 入时 此 模型 返回 原始 模型 中 网络层 激活 
的 值 一个 多 输出 模型 到 目前 为止 看到 
的 模型 只有 一个 输入 和 一个 输出 在 一般 
情况 下 模型 可以 具有 任意 数量 的 输入 和 
输出 这个/r 有/v 一个/m 输入/v 和/c 八个/m 输出/v 每层 激活 
一个 输出 模型 运行 activations = activation _ model . 
predict img _ tensor # 输出 每层 激活 值 一个 
数 组 第一 个 卷积 层 结果 first _ layer 
_ activation = activations 0 print first _ layer _ 
activation . shape # 1 148 148 32 import matplotlib 
. pyplot as plt plt . matshow first _ layer 
_ activation 0 4 cmap = viridis # 第 4 
通道 可视化 网络 中 所有 激活 函数值 可视化 将 8个 
网络层 激活 函数值 的 所有 通道 结果 显示 出来 layer 
_ names = for layer in model . layers 8 
layer _ names . append layer . name images _ 
per _ row = 16 for layer _ name layer 
_ activation in zip layer _ names activations n _ 
features = layer _ activation . shape 1 size = 
layer _ activation . shape 1 n _ cols = 
n _ features / / images _ per _ row 
display _ grid = np . zeros size * n 
_ cols images _ per _ row * size for 
col in range n _ cols for row in range 
images _ per _ row channel _ image = layer 
_ activation 0 col * images _ per _ row 
+ row channel _ image = channel _ image . 
mean channel _ image / = channel _ image . 
std channel _ image * = 64 channel _ image 
+ = 128 channel _ image = np . clip 
channel _ image 0 255 . astype uint8 display _ 
grid col * size col + 1 * size row 
* size row + 1 * size = channel _ 
image scale = 1 . / size plt . figure 
figsize = scale * display _ grid . shape 1 
scale * display _ grid . shape 0 plt . 
title layer _ name plt . grid False plt . 
imshow display _ grid aspect = auto cmap = viridis 
值得 注意 的 是 第一层 充当 各种 边缘 检测器 的 
集合 在 那个 阶段 激活 值 几乎 保留 了 初始 
图 片中 的 所有 信息 随着 网络层 的 增加 激活 
变得 越来越 抽象 在 视觉 上 也不 那么 容易 理解 
开始 编码 更高 级别 的 概念 如 猫耳 和 猫眼 
更高 级别 的 表示 关于 图像 的 视觉 内容 越来越 
少 关于 图像 类型 的 信息 越来越 多 激活 的 
稀疏 性 随着 层 的 深度 而 增加 在 第一 
层 中 所有 滤波器 都由 输入 图像 激活 但在 以下 
图层 中 越来越 多 的 过滤器 为 空白 这 意味着 
在 输入 图像 中 找 不到 滤镜 编码 的 图案 
刚刚 证明 了 深度 神经 网络 所 学习 的 表征 
的 一个 重要 的 普遍 特征 由 层 提取 的 
特征 随着 层 的 深度 而 变得 越来越 抽象 更 
高层 的 激活 越来越少 地 显示 关于 所 看到 的 
特定 输入 的 信息 越来越 多 关于 目标 的 信息 
. 深度 神经网络 有效 地 充当 信息 蒸馏 管道 原始数据 
进入 在 这种 情况下 为 RGB 图像 并被 重复 变换 
以便 过滤掉 无关 信息 例如 图像 的 特定 视觉 外观 
以及 有用 的 信息 被 放大 和 细化 例如 图像 
的 类 可视化 卷积 核 另一种 检查 由 convnet 学习 
的 过滤器 的 简单 方法 是 显示 每个 过滤器 要 
响应 的 视觉 模式 这 可以 通过 输入 空间 中的 
渐变 上升 来 完成 将 渐变 下降 应用于 convnet 的 
输入 图像 的 值 空间 上 从 空白 输入 图像 
开始 最大化 特定 过滤器 的 响应 得到 的 输入 图像 
将 是 所选 滤波器 最大 响应 的 图像 过程 很 
简单 您 将 构建 一个 损失 函数 使 给定 卷积 
层 中 给定 滤波器 的 值 最大化 然后 您 将 
使用 随机 梯度 下降 来 调整 输入 图像 的 值 
以便 最大化 此 激活 值 例如 这是 在 VGG16 的 
block3 _ conv1 中 激活 过滤器 0 的 损失 . 
from keras . applications import VGG16 from keras import backend 
as K model = VGG16 weights = imagenet include _ 
top = False layer _ name = block3 _ conv1 
filter _ index = 0 layer _ output = model 
. get _ layer layer _ name . output # 
得到 block3 _ conv1 的 激活 值 loss = K 
. mean layer _ output filter _ index 要 实现 
梯度 下降 需要 相对于 模型 输入 求 损失 的 梯度 
grads = K . gradients loss model . input 0 
使用 梯度 正则化 平滑 梯度 值 grads / = K 
. sqrt K . mean K . square grads + 
1e 5 计算 损失 张量 和 梯度 张量 使用 keras 
的 iterate 函数 接收 numpy 张量 返回 关于 损失 和 
梯度 的 张量 列表 iterate = K . function model 
. input loss grads import numpy as np loss _ 
value grads _ value = iterate np . zeros 1 
150 150 3 将 张量 转换 为 图片格式 def deprocess 
_ image x x = x . mean x / 
= x . std + 1e 5 x * = 
0.1 x + = 0.5 x = np . clip 
x 0 1 x * = 255 x = np 
. clip x 0 255 . astype uint8 return x 
整合 卷积 核 可视化 函数 def generate _ pattern layer 
_ name filter _ index size = 150 layer _ 
output = model . get _ layer layer _ name 
. output loss = K . mean layer _ output 
filter _ index grads = K . gradients loss model 
. input 0 grads / = K . sqrt K 
. mean K . square grads + 1e 5 iterate 
= K . function model . input loss grads input 
_ img _ data = np . random . random 
1 size size 3 * 20 + 128 . step 
= 1 . for i in range 40 loss _ 
value grads _ value = iterate input _ img _ 
data input _ img _ data + = grads _ 
value * step img = input _ img _ data 
0 return deprocess _ image img 这些 过滤器 可视化 展示 
了 很多 关于 如何 使用 数字 网络层 来 查看 世界 
网络 中 的 每个 层 都 学习 了 一组 过滤器 
以便 它们 的 输入 可以 表示 为 过滤器 的 组合 
类别 激活 值 heatmap 可视化 一种 可视化 技术 有助于 理解 
给定 图像 的 哪些 部分 引导 其 进行 最终 分类 
决策 的 可视化 技术 这种 通用 类别 的 技术 称为 
类 激活 图 CAM 可视化 它 包括 在 输入 图像 
上 生成 类 激活 的 热 图 类 激活 热 
图 是 与 特定 输出 类 相 关联 的 分数 
的 2D 网格 针对 任何 输入 图像 中 的 每个 
位置 计算 指示 每个 位置 相对 于所/nr 考虑 的 类 
的 重要 程度 小结 Convnets 是 处理 视觉 分类 问题 
的 最佳 工具 Convnets 通过学习 模块化 模式 和 概念 的 
层次 结构 来 表示 视觉 世界 现在 能够 从头 开始 
训练 自己 的 网络 以 解决 图像 分类 问题 如何 
使用 数据 增强 重用 预 训练 网络 微调 与 训练 
过 网络 来 缓解 过拟合 现象 生成 由 convnet 学习 
的 过滤器 的 可视化 等 包括 理解 卷积 神经 网络 使用 数据 增强 缓解 过拟合 
使用 预 训练 卷积 网络 做 特征提取 微调 预 训练 
网络 模型 可视化 卷积 网络 学习 结果 以及 分类 决策 
过程 介绍 卷积 神经网络 convnets 深度 学习 在 计算机 视觉 
方面 广泛 应用 的 一个 网络 模型 卷积 网络 介绍 
在 介绍 卷积 神经网络 理论 以及 神经 网络 在 计算机 
视觉 方面 应用 广泛 的 原因 之前 先 介绍 一个 
卷积 网络 的 实例 整体 了解 卷积 网络 模型 用 
卷积 网络 识别 MNIST 数据集 from keras import layers from 
keras import models model = models . Sequential model . 
add layers . Conv2D 32 3 3 activation = relu 
input _ shape = 28 28 1 model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu 卷积 网络 接收 
image _ height image _ width image _ channels 形状 
的 张量 作为 输入 不包括 batch size MNIST 中 将 
图片 转换成 28 28 1 形状 然后 在 第一 层 
传递 input _ shape 参数 显示 网络 架构 model . 
summary _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = conv2d _ 1 Conv2D None 
26 26 32 320 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
1 MaxPooling2D None 13 13 32 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ conv2d _ 2 Conv2D None 11 11 64 18496 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ maxpooling2d _ 2 MaxPooling2D None 5 
5 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ conv2d _ 3 
Conv2D None 3 3 64 36928 = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
Total params 55 744 Trainable params 55 744 Non trainable 
params 0 可以 看到 每个 Conv2D 和 MaxPooling2D 网络层 输出 
都是 3D 张量 形状 为 height width channels . 随着 
网络层 的 加深 长度 和 宽度 逐渐 减小 通 道数 
通过 Conv2D 层 的 参数 控制 下 一步 连接 Dense 
层 但 当前 输出 为 3D 张量 需要 将 3D 
张量 平 铺成 1D 然后 添加 Dense 层 model . 
add layers . Flatten model . add layers . Dense 
64 activation = relu model . add layers . Dense 
10 activation = softmax 因为 是 10 分类 最后 一层 
为 10个 神经元 激活 函数 为 softmax 最后 的 网络 
架构 model . summary Layer type Output Shape Param # 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = conv2d _ 1 Conv2D None 26 
26 32 320 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ maxpooling2d _ 1 
MaxPooling2D None 13 13 32 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
conv2d _ 2 Conv2D None 11 11 64 18496 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ maxpooling2d _ 2 MaxPooling2D None 5 5 
64 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ conv2d _ 3 Conv2D 
None 3 3 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ flatten 
_ 1 Flatten None 576 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
dense _ 1 Dense None 64 36928 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ dense _ 2 Dense None 10 650 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 93 322 Trainable params 93 322 
Non trainable params 0 3 3 64 输出 平摊 成 
576 向量 网络 训练 from keras . datasets import mnist 
from keras . utils import to _ categorical train _ 
images train _ labels test _ images test _ labels 
= mnist . load _ data train _ images = 
train _ images . reshape 60000 28 28 1 train 
_ images = train _ images . astype float32 / 
255 test _ images = test _ images . reshape 
10000 28 28 1 test _ images = test _ 
images . astype float32 / 255 train _ labels = 
to _ categorical train _ labels test _ labels = 
to _ categorical test _ labels model . compile optimizer 
= rmsprop loss = categorical _ crossentropy metrics = accuracy 
model . fit train _ images train _ labels epochs 
= 5 batch _ size = 64 测试 集上 模型 
评估 test _ loss test _ acc = model . 
evaluate test _ images test _ labels test _ acc 
0 . 9 9 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 1 在 
Dense 网络 上 准确率 为 97.8% 基本 卷积 网络 上 
准确率 到 99% . 为什么 简单 的 卷积 网络 工作 
效果 这么 好 回答 之前 先 了解 Conv2D 和 MaxPooling2D 
层 卷积/n 操作/v 全/a 连接/v 网络/n 和/c 卷积/n 网络/n 的/uj 
区别/n 在于/v Dense/w 全/a 连接/v 层/q 学习/v 输入/v 特征/n 空间/n 
的/uj 全局/n 模式/n 特征/n 而 卷积 神经 网络 学习 输入 
特征 空间 的 局部 模式 特征 卷积 网络 的 两个 
关键 特性 学习 具有 平移 不变性 的 模式 特征 一旦 
学习 到 图片 左上角 的 模式 特征 可以 在 任何 
地方 识别 如 右下角 这种 特性 使得 图片 处理 更加 
有效 需要 的 样本 相对 减少 实际 生活 中 具有 
平移 不变性 学习 模式 的 空间 层次结构 第一 个 卷积 
层 将 学习 小 的 局部 模式 如 边缘 第二个 
卷积 层 将 学习 由 第一 层 特征 构成 的 
更大 图案 等等 这 使得 卷积 网络 能够 有效 地 
学习 越来越 复杂 和 抽象 的 视觉 概念 现实 生活 
中 许多 都是 分级 的 卷 积在 3D 张量 上 
运算 称 为特征 映射 具 有 两个 空间 轴 高度 
和 宽度 以及 深度 轴 也 称为 通道 轴 . 
对 RGB 三原色 图片 来说 通 道数 为 3 红 
绿 蓝 MNIST 数据 集中 图片 通 道数 为 1 
灰度 图 卷积 操作 在 输入 特征 图上 小分 片上 
然后 将 多个 操作 结果 生成 最后 的 特征 图 
输出 的 特征 图 仍然 是 3D 张量 width height 
深度 可以 是 任意 值 因为 深度 是 网络层 的 
一个 参数 而且 深度 值 不再 代表 红绿蓝 颜色通道 表示 
过滤器 的 个数 过滤器 对 输入 数据 的 特定 方面 
进行 编码 比如 在 高级别 单个 过滤器 可以 编码 输入 
中 存在 面部 的 概念 卷积 定义 的 两个 参数 
卷积 核 大小 通常 为 3x3 5x5 . 卷积 核 
个数 卷积 核 个数 等于 本 层 网络 输出 层 
的 深度 Keras 中 Conv2D 网络层 定义 Conv2D output _ 
depth window _ height window _ width . 卷积 卷积 
核 在上 一层 的 特征 图 的 全 通道 进行 
滑动 然后 抽取 形状 为 window _ height window _ 
width input _ depth 形状 的 3D 片 特征 每个 
3D 片 特征 最后 转换成 1D 向量 卷积 运算 张量 
点积 形状 output _ depth 所有 的 结果 向量 整合 
形成 最后 的 3D 特征 height width output _ depth 
./i 输出/v 结果/n 的/uj 宽度/n 和/c 高度/n 可能/v 和/c 输入/v 
宽度/n 高度/n 不同/a 由于 Padding 项 Strides 步长 最大 池化/nr 
MaxPooling 最大 池化层/nr 的 作用 在于 对 特征 图 进行 
下 采样 最大 池化在/nr 特征 图中 选择 window 然后 每个 
通道 的 在 窗口 内 求 最大值 概念上 与 卷积 
操作 类似 卷积 操 作在 小 patch 中 做 线性转换 
最大 池化是/nr 求 最大值 通过 tensor 的 max 张量 操作 
最大 池化/nr 通常 采用 2x2 窗口 步 长为 2 特征 
图 减半 卷积 通常 卷积 核 大小 为 3x3 步 
长为 1 下 采样 的 目的 在于 减少 要 处理 
特征 图 的 参数 量 通过 使 连续 的 卷积 
层 看到 越来越 大 的 窗口 就 它们 所 涵盖 
的 原始 输入 的 比例 而言 来 促使 空间 滤波器 
层次结构 最大 池化并/nr 不是 唯一 的 下 采 样方法 可以 
使 用带 步长 卷积 或 平均 池化/nr 但是 最大 池化的/nr 
工作 效果 更好 小 数据集 上 训练 卷积 网络计算机 视觉 
中 进场 会 遇到 使用 很少 的 数据 集 去 
训练 一个 图像 分类 模型 小 样本 意味着 样本量 在 
几百 到 几 万张 . 比如 猫狗 分类 共 4000张 
图片 猫 2000张 狗 2000张 用 2000张 图片 来 训练 
1000张 验证 集 1000张 测试 集 首先 不 做 任何 
正则化 处理 直接 训练 得到 一个 baseline 模型 准确率 为 
71% 主要 问题 在于 模型 过拟合 之后 介绍 data augmentation 
数据 增强 减缓 过拟合 训练 后为 82% 更 有效 的 
方法 是 用 已 训 练好 的 模型 最 特征提取 
准确率 90% 96% 或者 微调 已 训 练好 的 网络 
做 特征提取 97% 这三种 方法 有助于 在 小 数据 集上 
的 模型 训练 深度 学习 与 小 数据 问题 的 
相关性 可能 经常 听说 深度 学习 只能 工作 在 大 
数据 集上 这种 说法 部分 正确 深度 学习 的 一个 
重要 特性 在于 深度 学习 能 自己 在 训练 数据 
中 寻找 特征 而 不 需要 人工干预 而 这个 特性 
只有在 大 数据 样本量 上 才 有效 特别 是 输入 
数据 维度 特别高 时 eg 图片 但是 对于 初学者 来说 
构成 大量 样本 的 内容 与 尝试 训练 的 网络 
的 大小 和 深度 是 相对 的 用 几十 张 
图片 训练 卷积 网络 来 解决 一个 十分 复杂 的 
问题 是 不 可能 的 但 如果 模型 比较简单 经过 
正则化 处理 同时 任务 比较 简单 几百/m 张/q 图片/n 也/d 
能/v 解决问题/n 因为 卷积 网络 学习 局部 的 具有 平移 
不变性 的 特征 它们 在 感知 问题 上 具有 很高 
的 数据 效率 尽管 相对 缺乏 数据 但 无需 额外 
的 特征 工程 即使 在 非常 小 的 图像 数据 
集上 从头 开始 训练 卷积 网络 仍然 会 产生 合理 
的 结果 更 重要 的 是 深度 学习 模型 本质上 
是 高度 可再 利用 的 例如 可以 采用 在 大规模 
数据 集上 训练 的 图像 分类 或 语音 到 文本 
模型 只需 进行 微小 的 更改 就 可以 重新 用于 
显著 不同 的 问题 上 具体 而言 以 计算机 视觉 
为例 许多 预先 训 练好 的 模型 通常在 ImageNet 数据集 
上 训练 提供 公开 下载 当 样本量 少时 可以 用 
在 模型 中 做 特征提取 使用 提升 工作 效果 数据 
下载 Keras 中 没有 包括 Dogs vs . Cats 数据集 
可以 在 Kaggle 上 下载 图片格式 为 JPEGs . 数据集 
包含 25000张 猫狗 图片 一半一半 下载 解压缩 后 创建 一个 
新 数据集 包括 3个 文件夹 每类 1000张 的 训练 集 
每类 500张 的 验证 集 和 每类 500张 的 测试 
集 import os shutil # 原始数据 original _ dataset _ 
dir = / Users / fchollet / Downloads / kaggle 
_ original _ data # 新 数据集 目录 base _ 
dir = / Users / fchollet / Downloads / cats 
_ and _ dogs _ small os . mkdir base 
_ dir # 创建 训练 集 验证 集 测试 集 
目录 train _ dir = os . path . join 
base _ dir train os . mkdir train _ dir 
validation _ dir = os . path . join base 
_ dir validation os . mkdir validation _ dir test 
_ dir = os . path . join base _ 
dir test os . mkdir test _ dir # 创建 
对应 数据集 下 不同 类别 的 目录 train _ cats 
_ dir = os . path . join train _ 
dir cats os . mkdir train _ cats _ dir 
train _ dogs _ dir = os . path . 
join train _ dir dogs os . mkdir train _ 
dogs _ dir validation _ cats _ dir = os 
. path . join validation _ dir cats os . 
mkdir validation _ cats _ dir validation _ dogs _ 
dir = os . path . join validation _ dir 
dogs os . mkdir validation _ dogs _ dir test 
_ cats _ dir = os . path . join 
test _ dir cats os . mkdir test _ cats 
_ dir test _ dogs _ dir = os . 
path . join test _ dir dogs os . mkdir 
test _ dogs _ dir fnames = cat . { 
} . jpg . format i for i in range 
1000 # 取 前 1000张 猫 图片 for fname in 
fnames # 将 前 一千张 猫 图片 复制到 新 数据集 
目 录下 src = os . path . join original 
_ dataset _ dir fname dst = os . path 
. join train _ cats _ dir fname shutil . 
copyfile src dst fnames = cat . { } . 
jpg . format i for i in range 1000 1500 
# 取 500张 猫 图片 for fname in fnames # 
500张 猫 图片 复制到 验证 集 src = os . 
path . join original _ dataset _ dir fname dst 
= os . path . join validation _ cats _ 
dir fname shutil . copyfile src dst fnames = cat 
. { } . jpg . format i for i 
in range 1500 2000 # 取 500张 猫 图片 for 
fname in fnames # 500张 猫 图片 做 测试 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
test _ cats _ dir fname shutil . copyfile src 
dst # 狗 图片 fnames = dog . { } 
. jpg . format i for i in range 1000 
# 1000张 狗 图片 做 训练 集 for fname in 
fnames src = os . path . join original _ 
dataset _ dir fname dst = os . path . 
join train _ dogs _ dir fname shutil . copyfile 
src dst fnames = dog . { } . jpg 
. format i for i in range 1000 1500 for 
fname in fnames # 500张 狗 图片 做 验证 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
validation _ dogs _ dir fname shutil . copyfile src 
dst Copies the next 500 fnames = dog . { 
} . jpg . format i for i in range 
1500 2000 for fname in fnames # 500张 狗 图片 
做 测试 集 src = os . path . join 
original _ dataset _ dir fname dst = os . 
path . join test _ dogs _ dir fname shutil 
. copyfile src dst 构建 模型 from keras import layers 
from keras import models model = models . Sequential model 
. add layers . Conv2D 32 3 3 activation = 
relu input _ shape = 150 150 3 model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 64 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Flatten model . add layers . Dense 512 activation 
= relu model . add layers . Dense 1 activation 
= sigmoid 模型 架构 model . summary Layer type Output 
Shape Param # = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = conv2d _ 1 
Conv2D None 148 148 32 896 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
maxpooling2d _ 1 MaxPooling2D None 74 74 32 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ conv2d _ 2 Conv2D None 72 72 
64 18496 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ maxpooling2d _ 2 MaxPooling2D 
None 36 36 64 0 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ conv2d 
_ 3 Conv2D None 34 34 128 73856 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ maxpooling2d _ 3 MaxPooling2D None 17 17 128 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ conv2d _ 4 Conv2D None 
15 15 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
4 MaxPooling2D None 7 7 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ flatten _ 1 Flatten None 6272 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ dense _ 1 Dense None 512 3211776 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ dense _ 2 Dense None 1 513 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = Total params 3 453 121 Trainable 
params 3 453 121 Non trainable params 0 编译 阶段 
使用 RMSProp 优化 算法 binary crossentropy 为 损失 函数 from 
keras import optimizers model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 4 
metrics = acc 数据 预处理 数据 在 送到 网络 模型 
之前 应该 转换成 浮点 类型 的 张量 目前 数据 集中 
数据格式 为 JPEG 所以 处理 步骤 大致 为 读取 图片 
文件 将 JPEG 格式 转换 为 RGB 像素 值 转换成 
浮点 类型 张量 将 像素 值 0 ~ 255 缩 
放到 0 1 之间 针对 上述 步骤 Keras 中有 自动化 
处理 方法 Keras 中 有一个 图像处理 模块 keras . preprocessing 
. image . 其中 包括 一个 I m a g 
e D a t a G e n e r 
a t o r 类 可以 将 磁 盘上 的 
图片 文件 自动 转换 成 预处理 的 张量 batch 批量 
使用 方法 from keras . preprocessing . image import I 
m a g e D a t a G e 
n e r a t o r train _ datagen 
= I m a g e D a t a 
G e n e r a t o r rescale 
= 1 . / 255 test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 # 将 图片 转换成 150x150 类别 为 
2 class _ mode 确定 返回 标签 的 类型 binary 
二 分类 1D 类型 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
\ target _ size = 150 150 batch _ size 
= 20 class _ mode = binary validation _ generator 
= test _ datagen . flow _ from _ directory 
validation _ dir target _ size = 150 150 batch 
_ size = 20 class _ mode = binary 生成器 
generator 的 数据 结果 为 150x150 RGB 批量 图片 尺寸 
为 20 150 150 3 二进制 标签 形状 20 每个 
批量 大小 为 20个 样本 batch _ size 为 20 
. 注意 生成器 无限期 地 生成 这些 批次 它 在 
目标 文件夹 的 图像 上 无休止 地 循环 使用 generator 
数据 生成器 对模型 进行 训练 使用 fit _ generator 方法 
对于 数据 生成器 来说 相当于 fit 方法 fit _ generator 
第一个 参数 是 Python 生成器 类型 能/v 不断/d 地/uv 生成/v 
输入/v 和/c 标签/n 批量/n 因为 数据 不断 生成 Keras 模型 
需要 知道 在 声明 一个 epoch 之前 从 发生器 中 
抽取 多少 批量 steps _ per _ epoch 参数 从 
生成器 中 生成 steps _ per _ epoch 个 批量 
数据 在 经过 steps _ per _ epoch 次梯度 下降 
后 在 下 一个 epoch 上 进行 训练 在 这里 
批量 大小 为 20 一个 epoch 有 100个 批量 生成 
2000张 图片 样本 使用 fit _ generator 方法 可以 传递 
validataion _ data 参数 和 fit 方法 相似 值得 注意 
的 是 这个 参数 可以 赋值 为 数据 生成器 也 
可以 是 numpy 数组 的 元组 如果 validation _ data 
参数 是 数据 生成器 生成器 能 不断 地 生成 数据 
所以 需要 设置 validation _ steps 参数 确定 从 生成器 
中 生成 多少 验证 集 批量 history = model . 
fit _ generator train _ generator steps _ per _ 
epoch = 100 epoch = 30 validation _ data = 
validation _ generator validation _ steps = 50 模型 保存 
model . save cats _ and _ dogs _ small 
_ 1 . h5 训练 集 验证 集 准确率 损失 
值 变化 可以 发现 模型 发生 过拟合 现象 训练 准确率 
随着 时间 线性 增加 直到 100% 而 验证 集 准确率 
在 70 72% 波动 验证 集 损失 在 5个 epoch 
之后 达到 最小值 之后 开始 波动 训练 集 损失 线性 
减少 直到 为 0 因为 训练 集 只有 2000张 图片 
遇到 的 第一 个 问题 就是 模型 过拟合 Dropout 权重 
衰减 可以 减缓 过拟合 还有 一个 计算机 视觉 任务 中 
经常 使用 的 处理 方法 数据 增强 data augmentation 数据 
增强 过度 拟合 是 由于 样本 太少 而 无法 学习 
导致 无法 训练 可以 推广 到 新 数据 的 模型 
给定 无限 的 数据 模型 可以 学习 到 手头 数据分布 
的 每个 可能 方面 永远 不会 过拟合 数据 增强 采用 
从 现有 训练样本 生成 更多 训练 数据 的 方法 通过 
大量 随机 变换 来 增加 样本 从而 产生 新的 可靠 
的 图像 样本 目标 是 在 训练 时 模型 将 
永远 不会 看到 两张 完全 相同 的 图片 这 有助于 
模型 观察 数据 的 更多 方面 并 更好 地 概括 
数据 Keras 中 可以 通过 实例 化 I m a 
g e D a t a G e n e 
r a t o r 实例 确定 图片 转换方法 从而 
实现 数据 增强 datagen = I m a g e 
D a t a G e n e r a 
t o r rotation _ range = 40 # 最大 
旋转 角度 width _ shift _ range = 0.2 # 
水平 随机 平移 图片 的 范围 比例 height _ shift 
_ range = 0.2 # 垂直 随机 平移 图片 的 
范围 shear _ range = 0.2 # 随机 应用 剪切 
变换 zoom _ range = 0.2 # 随机 缩放 图片 
horizontal _ flip = True # 随机 翻转 图片 fill 
_ mode = nearest # 用于 填充 新 创建 的 
像素 的 策略 在 旋转 或 宽度 / 高度 偏移 
后 出现 如果 使用 这样 的 数据 增强 配置 训练 
新 网络 网络 将 永远 不会 看到 两张 相同 的 
输入 图片 但 它 看到 的 输入 仍然 是 严重 
相互 关联 的 因为 它们 来自 少量 原始 图像 无法 
生成 新 信息 只能 重新 混合 现有 信息 因此 这 
不 可能 完全 摆脱 过拟合 为了 进一步 减缓 过拟合 需要 
增加 Dropout 层 在 全 连接 层 之前 新 网络 
模型 model = models . Sequential model . add layers 
. Conv2D 32 3 3 activation = relu input _ 
shape = 150 150 3 model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 64 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Flatten model 
. add layers . Dropout 0.5 model . add layers 
. Dense 512 activation = relu model . add layers 
. Dense 1 activation = sigmoid model . compile loss 
= binary _ crossentropy optimizer = optimizers . RMSprop lr 
= 1e 4 metrics = acc 使用 数据 增强 和 
Dropout 训练 网络 train _ datagen = I m a 
g e D a t a G e n e 
r a t o r rescale = 1 . / 
255 rotation _ range = 40 width _ shift _ 
range = 0.2 height _ shift _ range = 0.2 
shear _ range = 0.2 zoom _ range = 0.2 
horizontal _ flip = True test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 train _ generator = train _ datagen 
. flow _ from _ directory train _ dir target 
_ size = 150 150 batch _ size = 32 
class _ mode = binary validation _ generator = test 
_ datagen . flow _ from _ directory validation _ 
dir target _ size = 150 150 batch _ size 
= 32 class _ mode = binary history = model 
. fit _ generator train _ generator steps _ per 
_ epoch = 100 epochs = 100 validation _ data 
= validation _ generator validation _ steps = 50 model 
. save cats _ and _ dogs _ small _ 
2 . h5 # 模型 保存 使用 数据 增强 和 
Dropout 后 训练 集 验证 集 准确率 和 损失 函数 
变化 模型 不再 过拟合 训练 集 曲线 和 验证 集 
曲线 几乎 相互 吻合 准确率 82% 提高 了 15% 左右 
使用 正则化 技术 微调 网络 超 参数 模型 准确率 会 
进一步 提高 到 86% ~ 87% . 但是 很难 继续 
提高 因为 训练 数据 有限 样本 量 太少 另一种 方法 
可以 采用 预先 训 练好 的 网络 模型 做 特征提取 
提高 准确率 使用 预 训练 卷积 网络 在 小 图像 
数据 集上 使用 深度 学习 的 一种 常见 且 高效 
的 方法 是 使用 预 训练 网络 预 训练 网络 
是 先前 在 大型 数据集 上 训练 的 已 保存 
网络 通常 是 处理 大规模 图像 分类 任务 如果 这个 
原始 数据集 足够 大 且 代表 性强 则 预 训练 
网络 学习 的 特征 的 空间 层次结构 可以 有效 地 
充当 视觉 世界 的 通用 模型 因此 其 特征 可以 
证明 对 许多 不同 的 计算机 视觉 问题 都 有用 
甚至 这些 新 问题 可能 涉及 与 原始 任务 完全 
不同 例如 可以 在 ImageNet 上 训练 网络 其中 类 
主要 是 动物 和 日常 物品 然后 将 这个 训练 
好 的 网络 重新 用于 识别 图像 中 的 家具 
物品 任务 中 与 许多 较 旧 的 浅 学习 
方法 传统 机器学习 方法 相比 学习 特征 在 不同 问题 
中 的 这种 可移植性 是 深度 学习 的 关键 优势 
并且 它 使得 深度 学习 对于 小 数据 问题 非常 
有效 比如 在 ImageNet 数据集 上 训练 的 网络 模型 
140 万个 标记 图像 和1/nr 000个 不 同类 ImageNet 包含 
许多 动物 类别 包括 不同 种类 的 猫 和狗/nr 因此 
可以 期望 在 狗 与 猫 的 分类 问题 上 
表现 良好 使用 VGG16 网络 架构 它 是 ImageNet 的 
简单 且 广泛 使用 的 convnet 架构 使用 预 训练 
网络 有 两种 方法 特征提取 和 微调 特征提取 特征提取 包括 
使用 先前 网络 学习 的 表示 从新 样本 中 提取 
有趣 特征 然后 这些 功能 将 通过 一个 新的 分类器 
运行 该 分类器 从头 开始 训练 如前所述 用于 图像 分类 
的 网络 包含 两 部分 它们/r 以/p 一/m 系列/q 池化和/nr 
卷积/n 层/q 开始/v 并以 密集 连接 的 分类器 结束 第一 
部分 称为 模型 的 卷积 基础 在 卷积 网络 中 
特征提取 包括 获取 先前 训练 的 网络 的 卷积 基础 
通过 它 运行 新 数据 以及 在 输出 之上 训练 
新的 分类器 为什么 只 重用 卷积 网络 是否 可以 重复 
使用 全 连接 分类器 一般来说 应该 避免 这样 做 原因 
是 卷积 网络 学习 的 表示 可能 更 通用 因此 
更 可 重复 使用 特征 网络 的 特征 图 是 
图片 上 一般 概念 的 存在 图 无论 处理 的 
计算机 视觉 问题 是 什么 都 可能 是 有用 的 
但是 分类器 学习 的 表示 必然 特 定于 训练 模型 
的 类 集 它们 将 仅 包含 关于 整个 图像 
中 该类 或 该类 的 存在 概率 的 信息 此外 
在 全 连接 网络层 的 输出 表示 不再 包含 有关 
对象 在 输入 图像 中 的 位置 信息 这些 表示 
消除 了 空间 的 概念 而 卷积 特征 图 还 
可以 描述 对象 的 位置 信息 对于 对象 位置 很 
重要 的 问题 全 连接 的 特征 表示 在 很大 
程度 上 是 无用 的 注意 由 特定 卷积 层 
提取 的 表示 的 一般性 以及 因此 可 重 用性 
的 级别 取决于 模型 中 网络层 的 深度 模型 中 
较早 出现 的 图层 会 提取 局部 的 高度 通用 
的 特征 贴图 例如 可视 边缘 颜色 和 纹理 而 
较 高层 的 图层 会 提取 更 抽象 的 概念 
例如 猫耳朵 或 狗眼 因此 如果 训练 数据集 与 训练 
原始 模型 的 数据 集 有 很大 差异 那么 最好 
只 使用 模型 的 前 几层 来 进行 特征提取 而 
不是 使用 整个 卷积 网络 的 输出 在 这种 情况 
下 因为 ImageNet 类 集 包含 多个 dog 和 cat 
类 所以 重用 原始 模型 的 全 连接 层 中 
包含 的 信息 可能 是 有益 的 但是 我们 会 
选择 不 这样 做 以便 涵盖 新 问题 的 类 
集 不与 原始 模型 的 类 集 重叠 的 更 
一般情况 通过 使用 在 ImageNet 上 训练 的 VGG16 网络 
的 卷积 网络 来 实现 这 一点 从猫和/nr 狗/n 图像/n 
中/f 提取/v 有趣/a 的/uj 特征/n 然后 在 这些 特征 之上 
训练 狗 与 猫 的 分类器 Keras 中 可以 直接 
获取 VGG16 模型 包含 在 keras . applications 模块 中 
其中 还 包括 其他 模型 X c e p t 
i o n I n c e p t i 
o n V 3 R e s N e t 
5 0 V G G 1 6 V G G 
1 9 M o b i l e N e 
t 实例 化 VGG16 模型 from keras . application import 
vgg16 conv _ base = VGG16 weights = imagenet include 
_ top = False input _ shape = 150 150 
3 构造器 的 3个 参数 weights 读取 权重 保存 点 
文件 初始化 模型 include _ top 是否 包含 网络 的 
全 连接 层 模型 全 连接 层 分类 类别 在 
ImageNet 上 的 1000类 因为 要 使用 自己 创建 的 
全 连接 分类器 可以 不 使用 原来 的 全 连接 
层 input _ shape 送到 模型 中 图片 张量 的 
形状 参数 是 可选 的 如果 不 传递 参数 网络 
可以 处理 任意 形状 的 输入 VGG16 网络 模型 架构 
conv _ base . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = input _ 1 InputLayer None 
150 150 3 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block1 _ 
conv1 Convolution2D None 150 150 64 1792 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block1 _ conv2 Convolution2D None 150 150 64 36928 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block1 _ pool MaxPooling2D None 75 
75 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block2 _ conv1 
Convolution2D None 75 75 128 73856 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block2 _ conv2 Convolution2D None 75 75 128 147584 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block2 _ pool MaxPooling2D None 37 37 
128 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block3 _ conv1 Convolution2D 
None 37 37 256 295168 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block3 
_ conv2 Convolution2D None 37 37 256 590080 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block3 _ conv3 Convolution2D None 37 37 256 
590080 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block3 _ pool MaxPooling2D None 
18 18 256 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block4 _ 
conv1 Convolution2D None 18 18 512 1180160 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block4 _ conv2 Convolution2D None 18 18 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block4 _ conv3 Convolution2D None 18 
18 512 2359808 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block4 _ pool 
MaxPooling2D None 9 9 512 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block5 _ conv1 Convolution2D None 9 9 512 2359808 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block5 _ conv2 Convolution2D None 9 9 
512 2359808 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block5 _ conv3 Convolution2D 
None 9 9 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block5 
_ pool MaxPooling2D None 4 4 512 0 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 14 714 688 Trainable params 14 
714 688 Non trainable params 0 最后 一层 的 特征 
图 形状 为 4 4 512 . 之后 连接 到 
全 连接 分类器 上 有 两种 处理 方法 训练 卷积 
网络 模型 部分 将 输出 结果 保存 在 磁 盘上 
之后 读取 磁 盘上 的 数据 送到 全 连接 分类器 
中 优点 在于 运行 高效 快速 因为 卷积 网络 部分 
针对 每张 输入 图片 只 运行 一次 而 卷积 部分 
是 最 耗时 耗费 运算 能力 资源 的 但 同时 
不能 使用 数据 增强 将/d 全/a 连接/v 分类器/n 和/c 卷积/n 
部分/n 整合/v 到/v 一起/m 在 输入 数据 上端 到 端的 
运行 可以 使用 数据 增强 因为 每次 输入 模型 的 
图像 都会 通过 模型 经过 卷积 部分 不/d 使用/v 数据/n 
增强/v 的/uj 特征/n 提取/v 使用/v I/w m/w a/w g/w e/w 
D/w a/w t/w a/w G/w e/w n/w e/w r/w a/w 
t/w o/w r/w 将/d 磁盘/n 文件/n 和/c 标签/n 读取/v 成/n 
张量/nr 形式/n 运行 卷积 部分 的 predict 提取 图片 特征 
import os import numpy as np from keras . preprocessing 
. image import I m a g e D a 
t a G e n e r a t o 
r base _ dir = / Users / fchollet / 
Downloads / cats _ and _ dogs _ small train 
_ dir = os . path . join base _ 
dir train # 训练 数据 validation _ dir = os 
. path . join base _ dir validation # 验证 
数据 test _ dir = os . path . join 
base _ dir test # 测试数据 datagen = I m 
a g e D a t a G e n 
e r a t o r rescale = 1 . 
/ 255 # batch _ size = 20 def extract 
_ features directory sample _ count # 读取 文件 转换成 
张量 形式 features = np . zeros shape = sample 
_ count 4 4 512 labels = np . zeros 
shape = sample _ count generator = datagen . flow 
_ from _ directory directory target _ size = 150 
150 batch _ size = batch _ size class _ 
mode = binary i = 0 for inputs _ batch 
labels _ batch in generator # 生成 对应 批量 数据 
features _ batch = conv _ base . predict inputs 
_ batch # 卷积 特征提取 结果 features i * batch 
_ size i + 1 * batch _ size = 
features _ batch labels i * batch _ size i 
+ 1 * batch _ size = labels _ batch 
i + = 1 if i * batch _ size 
= sample _ count break return features labels train _ 
features train _ labels = extract _ features train _ 
dir 2000 validation _ features validation _ labels = extract 
_ features validation _ dir 1000 test _ features test 
_ labels = extract _ features test _ dir 1000 
当前 提取 特征 形状 为 samples 4 4 512 在 
送到 全 连接 层 之前 需要 先 平 铺成 samples 
8192 train _ features = np . reshape train _ 
features 2000 4 * 4 * 512 validation _ features 
= np . reshape validation _ features 1000 4 * 
4 * 512 test _ features = np . reshape 
test _ features 1000 4 * 4 * 512 定义 
全 连接 分类器 将 特征 数据 送到 分类器 中 训练 
from keras import models from keras import layers from keras 
import optimizers model = models . Sequential model . add 
layers . Dense 256 activation = relu input _ dim 
= 4 * 4 * 512 model . add layers 
. Dropout 0.5 model . add layers . Dense 1 
activation = sigmoid model . compile optimizer = optimizers . 
RMSprop lr = 2e 5 loss = binary _ crossentropy 
metrics = acc history = model . fit train _ 
features train _ labels epochs = 30 batch _ size 
= 20 validation _ data = validation _ features validation 
_ labels 验证 集 训练 集上 损失 值 和 准确率 
变化 情况 验证 集 准确率 达到 90% . 但 图示 
显示 模型 从 开始 就 过拟合 了 使用 数据 正 
增强 可以 缓解 一下 使用 数据 增强 的 特征 提取 
和 第一 种 方法 相比 运算速度 更慢 耗费 运算 资源 
更多 通常 需要 GPU 如果 GPU 上 速度 还慢 最好 
使用 第 一种 方法 from keras import models from keras 
import layers model = models . Sequential model . add 
conv _ base model . add layers . Flatten model 
. add layers . Dense 256 activation = relu model 
. add layers . Dense 1 activation = sigmoid 模型 
架构 为 model . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = vgg16 Model None 4 4 
512 14714688 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ flatten _ 1 Flatten 
None 8192 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ dense _ 1 
Dense None 256 2097408 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ dense _ 
2 Dense None 1 257 = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = Total 
params 16 812 353 Trainable params 16 812 353 Non 
trainable params 0 在 模型 训练 之前 需要 对 卷积 
部分 进行 freeze 冻住 Freezing 网络层 意味着 避免 在 训练 
过程 网络层 的 参数 被 更新 如果 不 做 freeze 
处理 训练 过程 中 卷积 部分 提取 的 特征 会 
逐渐 改变 在 Keras 中 可以 通过 设置 trainable 参数 
为 False 进行 Freeze 处理 conv _ base . trainable 
= False 注意 为了 使 这些 更改 生效 必须 首先 
编译 模型 如果在 编译 后 修改 了 权重 可 训练 
性 则应 重新 编译 模型 否则 将 忽略 这些 更改 
from keras . preprocessing . image import I m a 
g e D a t a G e n e 
r a t o r from keras import optimizers train 
_ datagen = I m a g e D a 
t a G e n e r a t o 
r rescale = 1 . / 255 rotation _ range 
= 40 width _ shift _ range = 0.2 height 
_ shift _ range = 0.2 shear _ range = 
0.2 zoom _ range = 0.2 horizontal _ flip = 
True fill _ mode = nearest test _ datagen = 
I m a g e D a t a G 
e n e r a t o r rescale = 
1 . / 255 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
target _ size = 150 150 batch _ size = 
20 class _ mode = binary validation _ generator = 
test _ datagen . flow _ from _ directory validation 
_ dir target _ size = 150 150 batch _ 
size = 20 class _ mode = binary model . 
compile loss = binary _ crossentropy optimizer = optimizers . 
RMSprop lr = 2e 5 metrics = acc history = 
model . fit _ generator train _ generator steps _ 
per _ epoch = 100 epochs = 30 validation _ 
data = validation _ generator validation _ steps = 50 
损失 值 和 准确率 变化 验证 集上 准确率 达到 96% 
. 模型 微调 Fine tuning 另一种 广泛 使用 的 模型 
重用 技术 对 特征提取 的 补充 就是 模型 参数 微调 
微调 包括 解冻 用于 特征提取 的 冻结 模型 基础 的 
一些 顶层 并 联合 训练 模型 的 新 添加 部分 
在 这种 情况 下 全 连接 的 分类器 和 这些 
顶层 这 称为 微调 因为 它 稍微 调整了 重复 使用 
的 模型 的 抽象 表示 以使 它们 与 手头 的 
问题 更 相关 微调 网络 模型 步骤 在 已经 训 
练好 的 网络 模型 上 添加 自定义 网络 模型 Freeze 
冻住 训 练好 的 模型 训练 添加 部分 网络 Unfreeze 
解冻 部分 base 网络 重新 训练 解冻 部分 和 添加 
部分 base 部分 网络 模型 conv _ base . summary 
Layer type Output Shape Param # = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
input _ 1 InputLayer None 150 150 3 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block1 _ conv1 Convolution2D None 150 150 
64 1792 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block1 _ conv2 Convolution2D 
None 150 150 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block1 
_ pool MaxPooling2D None 75 75 64 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block2 _ conv1 Convolution2D None 75 75 128 
73856 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block2 _ conv2 Convolution2D None 
75 75 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block2 _ 
pool MaxPooling2D None 37 37 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block3 _ conv1 Convolution2D None 37 37 256 295168 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block3 _ conv2 Convolution2D None 37 
37 256 590080 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block3 _ conv3 
Convolution2D None 37 37 256 590080 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block3 _ pool MaxPooling2D None 18 18 256 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block4 _ conv1 Convolution2D None 18 18 
512 1180160 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block4 _ conv2 Convolution2D 
None 18 18 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block4 
_ conv3 Convolution2D None 18 18 512 2359808 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block4 _ pool MaxPooling2D None 9 9 512 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block5 _ conv1 Convolution2D None 
9 9 512 2359808 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block5 _ 
conv2 Convolution2D None 9 9 512 2359808 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block5 _ conv3 Convolution2D None 9 9 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block5 _ pool MaxPooling2D None 4 
4 512 0 = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = Total params 14714688 
微调 模型 的 最后 3个 卷积 层 意味着 到 block4 
_ pool 之前 都被 冻住 网络层 block5 _ conv1 block5 
_ conv2 和 block5 _ conv3 都是 可 训练 的 
为什么 不 微调 更 多层 为什么 不 微调 整个 卷积 
网络 可以 这么 做 但是 你 需要 考虑 以下 几点 
卷积 网络 中的 前 几层 编码 更 通用 可 重用 
的 特征 而 更 高层 的 编码 更 专业 的 
特征 微调 更 专业 的 功能 更 有用 因为 这些 
功能 需要 重新 用于 新 问题 微调 下层 会有 快速 
下降 的 回报 训练 的 参数 越多 越有/nr 可能/v 过度/n 
拟合/v 卷积 网络 模型 有 1500 万个 参数 因此 尝试 
在 小 数据集 上 训练 它 会有 风险 一个 很好 
的 策略 是 只 微调 卷积 基础 中的 前 两个 
或 三个 层 conv _ base . trainable = True 
set _ trainable = False for layer in conv _ 
base . layers if layer . name = = block5 
_ conv1 # block5 _ conv1 可 训练 set _ 
trainable = True # flag 可 训练 if set _ 
trainable layer . trainable = True # block5 _ conv1 
网络层 设置 为 可 训练 else layer . trainable = 
False # 其它 层 不可 训练 现在 可以 开始 微调 
网络 了 使用 RMSProp 优 化器 以 非常 低 的 
学习 速率 执行 此 操作 使用 低 学习率 的 原因 
是 希望 限制 对 正在 微调 的 三个 网络层 的 
表示 所做 的 修改 的 幅度 太大 的 更新 可能会 
损害 这些 表示 model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 5 
metrics = acc history = model . fit _ generator 
train _ generator steps _ per _ epoch = 100 
epochs = 100 validation _ data = validation _ generator 
validation _ steps = 50 验证 集 测试 集上 损失 
函数 和 准确率 变化 请注意 损失 曲线 没有 显示 任何 
真正 的 改善 事实上 它 正在 恶化 如果 损失 没有减少 
准确度 如何 保持 稳定 或 改善 答案 很 简单 展示 
的 是 指数 损失 值 的 平均值 但是 对于 准确性 
而言 重要 的 是 损失 值 的 分布 而 不是 
它们 的 平均值 因为 精度 是 模型 预测 的 类 
概率 的 二元 阈值 的 结果 即使 没有 反映 在 
平均 损失 中 该 模型 仍 可能会 有所 改善 在 
测试 集上 评估 test _ generator = test _ datagen 
. flow _ from _ directory test _ dir target 
_ size = 150 150 batch _ size = 20 
class _ mode = binary test _ loss test _ 
acc = model . evaluate _ generator test _ generator 
steps = 50 print test acc test _ acc # 
97% 小结 Convnets 是 用于 计算机 视觉 任务 的 最佳 
机器学习 模型 即使 在 非常 小 的 数据 集上 也 
可以 从头 开始 训练 并 获得 不错 的 结果 在 
小型 数据 集上 过度 拟合 将 是 主要 问题 在 
处理 图像 数据 时 数据 增强 是 对抗 过度 拟合 
的 有效 方法 通过 重用 现有 的 卷积 网络 模型 
可以 在 新 数据 集上 做 特征提取 这是 处理 小 
图像 数据集 的 有用 技术 作为 特征提取 的 补充 可以 
使用 模型 微调 让 模型 适应 新 问题 以前 现有 
模型 可以 学习 新 问题 的 特征 表示 能 进一步 
推动 性能 卷积 学习 结果 可视化 人们 常说 深度 学习 
模型 是 黑匣子 学习 表示 难以 提取 以及 很难 以 
人类 可读 的 形式 呈现 虽然 对于 某些 类型 的 
深度 学习 模型 来说 这 是 部分 正确 的 但 
对于 convnets 来说 绝对 不是 这样 由 convnet 学习 的 
表示 非常 适合 可视化 这在 很大 程度 上 是因为 它们 
是 视觉 概念 的 表示 三种 常见 的 可视化 方法 
可视化 中间 信号 输出 中间 激活 有助于 了解 连续 的 
convnet 层 如何 转换 输入 数据 以及 了解 各个 convnet 
过滤器 的 含义 可视化 convnets 过滤器 有助于 准确 理解 convnet 
中 每个 过滤器 可 接受 的 视觉 模式 或 概念 
可视化 图像 中 类 激活 的 热 图 有助于 了解 
图像 的 哪些 部分 被 识别 为 属于 给定 的 
类 从而 可以 在 图像 中 本地化 对象 可视化/n 中间/f 
激活/a 值/n 可视化/n 中间/f 激活/a 包括/v 在/p 给定/v 特定/d 输入/v 
的/uj 情况/n 下/f 显示/v 由/p 网络/n 中/f 的/uj 各种/r 卷积/n 
和池化/nr 层/q 输出/v 的/uj 特征/n 映射/v 层 的 输出 通常 
称 为其 激活 激活 函数 的 输出 这 给出 了 
如何 将 输入 分解 为 网络 学习 的 不同 过滤器 
的 视图 希望 从 三个 维度 宽度 高度 和 深度 
通道 可视化 特征 图 每个 通道 编码 相对 独立 的 
特征 因此 可视化 这些 特征 图 的 正确 方法 是 
通过 将 每个 通道 的 内容 独立 地 绘制 为 
2D 图像 加载 保存 的 模型 from keras . models 
import load _ model model = load _ model cats 
_ and _ dogs _ small _ 2 . h5 
img _ path = . / cats _ and _ 
dogs _ small / test / cats / cat . 
1700 . jpg # 给定 一张 图片 from keras . 
preprocessing import image import numpy as np img = image 
. load _ img img _ path target _ size 
= 150 150 img _ tensor = image . img 
_ to _ array img img _ tensor = np 
. expand _ dims img _ tensor axis = 0 
img _ tensor / = 255 . 查看 所有 网络层 
的 输出 结果 from keras import models layer _ outputs 
= layer . output for layer in model . layers 
8 activation _ model = models . Model inputs = 
model . input outputs = layer _ outputs 输入 图像 
输 入时 此 模型 返回 原始 模型 中 网络层 激活 
的 值 一个 多 输出 模型 到 目前 为止 看到 
的 模型 只有 一个 输入 和 一个 输出 在 一般 
情况 下 模型 可以 具有 任意 数量 的 输入 和 
输出 这个/r 有/v 一个/m 输入/v 和/c 八个/m 输出/v 每层 激活 
一个 输出 模型 运行 activations = activation _ model . 
predict img _ tensor # 输出 每层 激活 值 一个 
数 组 第一 个 卷积 层 结果 first _ layer 
_ activation = activations 0 print first _ layer _ 
activation . shape # 1 148 148 32 import matplotlib 
. pyplot as plt plt . matshow first _ layer 
_ activation 0 4 cmap = viridis # 第 4 
通道 可视化 网络 中 所有 激活 函数值 可视化 将 8个 
网络层 激活 函数值 的 所有 通道 结果 显示 出来 layer 
_ names = for layer in model . layers 8 
layer _ names . append layer . name images _ 
per _ row = 16 for layer _ name layer 
_ activation in zip layer _ names activations n _ 
features = layer _ activation . shape 1 size = 
layer _ activation . shape 1 n _ cols = 
n _ features / / images _ per _ row 
display _ grid = np . zeros size * n 
_ cols images _ per _ row * size for 
col in range n _ cols for row in range 
images _ per _ row channel _ image = layer 
_ activation 0 col * images _ per _ row 
+ row channel _ image = channel _ image . 
mean channel _ image / = channel _ image . 
std channel _ image * = 64 channel _ image 
+ = 128 channel _ image = np . clip 
channel _ image 0 255 . astype uint8 display _ 
grid col * size col + 1 * size row 
* size row + 1 * size = channel _ 
image scale = 1 . / size plt . figure 
figsize = scale * display _ grid . shape 1 
scale * display _ grid . shape 0 plt . 
title layer _ name plt . grid False plt . 
imshow display _ grid aspect = auto cmap = viridis 
值得 注意 的 是 第一层 充当 各种 边缘 检测器 的 
集合 在 那个 阶段 激活 值 几乎 保留 了 初始 
图 片中 的 所有 信息 随着 网络层 的 增加 激活 
变得 越来越 抽象 在 视觉 上 也不 那么 容易 理解 
开始 编码 更高 级别 的 概念 如 猫耳 和 猫眼 
更高 级别 的 表示 关于 图像 的 视觉 内容 越来越 
少 关于 图像 类型 的 信息 越来越 多 激活 的 
稀疏 性 随着 层 的 深度 而 增加 在 第一 
层 中 所有 滤波器 都由 输入 图像 激活 但在 以下 
图层 中 越来越 多 的 过滤器 为 空白 这 意味着 
在 输入 图像 中 找 不到 滤镜 编码 的 图案 
刚刚 证明 了 深度 神经 网络 所 学习 的 表征 
的 一个 重要 的 普遍 特征 由 层 提取 的 
特征 随着 层 的 深度 而 变得 越来越 抽象 更 
高层 的 激活 越来越少 地 显示 关于 所 看到 的 
特定 输入 的 信息 越来越 多 关于 目标 的 信息 
. 深度 神经网络 有效 地 充当 信息 蒸馏 管道 原始数据 
进入 在 这种 情况下 为 RGB 图像 并被 重复 变换 
以便 过滤掉 无关 信息 例如 图像 的 特定 视觉 外观 
以及 有用 的 信息 被 放大 和 细化 例如 图像 
的 类 可视化 卷积 核 另一种 检查 由 convnet 学习 
的 过滤器 的 简单 方法 是 显示 每个 过滤器 要 
响应 的 视觉 模式 这 可以 通过 输入 空间 中的 
渐变 上升 来 完成 将 渐变 下降 应用于 convnet 的 
输入 图像 的 值 空间 上 从 空白 输入 图像 
开始 最大化 特定 过滤器 的 响应 得到 的 输入 图像 
将 是 所选 滤波器 最大 响应 的 图像 过程 很 
简单 您 将 构建 一个 损失 函数 使 给定 卷积 
层 中 给定 滤波器 的 值 最大化 然后 您 将 
使用 随机 梯度 下降 来 调整 输入 图像 的 值 
以便 最大化 此 激活 值 例如 这是 在 VGG16 的 
block3 _ conv1 中 激活 过滤器 0 的 损失 . 
from keras . applications import VGG16 from keras import backend 
as K model = VGG16 weights = imagenet include _ 
top = False layer _ name = block3 _ conv1 
filter _ index = 0 layer _ output = model 
. get _ layer layer _ name . output # 
得到 block3 _ conv1 的 激活 值 loss = K 
. mean layer _ output filter _ index 要 实现 
梯度 下降 需要 相对于 模型 输入 求 损失 的 梯度 
grads = K . gradients loss model . input 0 
使用 梯度 正则化 平滑 梯度 值 grads / = K 
. sqrt K . mean K . square grads + 
1e 5 计算 损失 张量 和 梯度 张量 使用 keras 
的 iterate 函数 接收 numpy 张量 返回 关于 损失 和 
梯度 的 张量 列表 iterate = K . function model 
. input loss grads import numpy as np loss _ 
value grads _ value = iterate np . zeros 1 
150 150 3 将 张量 转换 为 图片格式 def deprocess 
_ image x x = x . mean x / 
= x . std + 1e 5 x * = 
0.1 x + = 0.5 x = np . clip 
x 0 1 x * = 255 x = np 
. clip x 0 255 . astype uint8 return x 
整合 卷积 核 可视化 函数 def generate _ pattern layer 
_ name filter _ index size = 150 layer _ 
output = model . get _ layer layer _ name 
. output loss = K . mean layer _ output 
filter _ index grads = K . gradients loss model 
. input 0 grads / = K . sqrt K 
. mean K . square grads + 1e 5 iterate 
= K . function model . input loss grads input 
_ img _ data = np . random . random 
1 size size 3 * 20 + 128 . step 
= 1 . for i in range 40 loss _ 
value grads _ value = iterate input _ img _ 
data input _ img _ data + = grads _ 
value * step img = input _ img _ data 
0 return deprocess _ image img 这些 过滤器 可视化 展示 
了 很多 关于 如何 使用 数字 网络层 来 查看 世界 
网络 中 的 每个 层 都 学习 了 一组 过滤器 
以便 它们 的 输入 可以 表示 为 过滤器 的 组合 
类别 激活 值 heatmap 可视化 一种 可视化 技术 有助于 理解 
给定 图像 的 哪些 部分 引导 其 进行 最终 分类 
决策 的 可视化 技术 这种 通用 类别 的 技术 称为 
类 激活 图 CAM 可视化 它 包括 在 输入 图像 
上 生成 类 激活 的 热 图 类 激活 热 
图 是 与 特定 输出 类 相 关联 的 分数 
的 2D 网格 针对 任何 输入 图像 中 的 每个 
位置 计算 指示 每个 位置 相对 于所/nr 考虑 的 类 
的 重要 程度 小结 Convnets 是 处理 视觉 分类 问题 
的 最佳 工具 Convnets 通过学习 模块化 模式 和 概念 的 
层次 结构 来 表示 视觉 世界 现在 能够 从头 开始 
训练 自己 的 网络 以 解决 图像 分类 问题 如何 
使用 数据 增强 重用 预 训练 网络 微调 与 训练 
过 网络 来 缓解 过拟合 现象 生成 由 convnet 学习 
的 过滤器 的 可视化 等 包括 理解 卷积 神经 网络 使用 数据 增强 缓解 过拟合 
使用 预 训练 卷积 网络 做 特征提取 微调 预 训练 
网络 模型 可视化 卷积 网络 学习 结果 以及 分类 决策 
过程 介绍 卷积 神经网络 convnets 深度 学习 在 计算机 视觉 
方面 广泛 应用 的 一个 网络 模型 卷积 网络 介绍 
在 介绍 卷积 神经网络 理论 以及 神经 网络 在 计算机 
视觉 方面 应用 广泛 的 原因 之前 先 介绍 一个 
卷积 网络 的 实例 整体 了解 卷积 网络 模型 用 
卷积 网络 识别 MNIST 数据集 from keras import layers from 
keras import models model = models . Sequential model . 
add layers . Conv2D 32 3 3 activation = relu 
input _ shape = 28 28 1 model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu model . add 
layers . MaxPooling2D 2 2 model . add layers . 
Conv2D 64 3 3 activation = relu 卷积 网络 接收 
image _ height image _ width image _ channels 形状 
的 张量 作为 输入 不包括 batch size MNIST 中 将 
图片 转换成 28 28 1 形状 然后 在 第一 层 
传递 input _ shape 参数 显示 网络 架构 model . 
summary _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = conv2d _ 1 Conv2D None 
26 26 32 320 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
1 MaxPooling2D None 13 13 32 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ conv2d _ 2 Conv2D None 11 11 64 18496 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ maxpooling2d _ 2 MaxPooling2D None 5 
5 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ conv2d _ 3 
Conv2D None 3 3 64 36928 = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
Total params 55 744 Trainable params 55 744 Non trainable 
params 0 可以 看到 每个 Conv2D 和 MaxPooling2D 网络层 输出 
都是 3D 张量 形状 为 height width channels . 随着 
网络层 的 加深 长度 和 宽度 逐渐 减小 通 道数 
通过 Conv2D 层 的 参数 控制 下 一步 连接 Dense 
层 但 当前 输出 为 3D 张量 需要 将 3D 
张量 平 铺成 1D 然后 添加 Dense 层 model . 
add layers . Flatten model . add layers . Dense 
64 activation = relu model . add layers . Dense 
10 activation = softmax 因为 是 10 分类 最后 一层 
为 10个 神经元 激活 函数 为 softmax 最后 的 网络 
架构 model . summary Layer type Output Shape Param # 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = conv2d _ 1 Conv2D None 26 
26 32 320 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ maxpooling2d _ 1 
MaxPooling2D None 13 13 32 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
conv2d _ 2 Conv2D None 11 11 64 18496 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ maxpooling2d _ 2 MaxPooling2D None 5 5 
64 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ conv2d _ 3 Conv2D 
None 3 3 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ flatten 
_ 1 Flatten None 576 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
dense _ 1 Dense None 64 36928 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ dense _ 2 Dense None 10 650 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 93 322 Trainable params 93 322 
Non trainable params 0 3 3 64 输出 平摊 成 
576 向量 网络 训练 from keras . datasets import mnist 
from keras . utils import to _ categorical train _ 
images train _ labels test _ images test _ labels 
= mnist . load _ data train _ images = 
train _ images . reshape 60000 28 28 1 train 
_ images = train _ images . astype float32 / 
255 test _ images = test _ images . reshape 
10000 28 28 1 test _ images = test _ 
images . astype float32 / 255 train _ labels = 
to _ categorical train _ labels test _ labels = 
to _ categorical test _ labels model . compile optimizer 
= rmsprop loss = categorical _ crossentropy metrics = accuracy 
model . fit train _ images train _ labels epochs 
= 5 batch _ size = 64 测试 集上 模型 
评估 test _ loss test _ acc = model . 
evaluate test _ images test _ labels test _ acc 
0 . 9 9 0 8 0 0 0 0 
0 0 0 0 0 0 0 0 1 在 
Dense 网络 上 准确率 为 97.8% 基本 卷积 网络 上 
准确率 到 99% . 为什么 简单 的 卷积 网络 工作 
效果 这么 好 回答 之前 先 了解 Conv2D 和 MaxPooling2D 
层 卷积/n 操作/v 全/a 连接/v 网络/n 和/c 卷积/n 网络/n 的/uj 
区别/n 在于/v Dense/w 全/a 连接/v 层/q 学习/v 输入/v 特征/n 空间/n 
的/uj 全局/n 模式/n 特征/n 而 卷积 神经 网络 学习 输入 
特征 空间 的 局部 模式 特征 卷积 网络 的 两个 
关键 特性 学习 具有 平移 不变性 的 模式 特征 一旦 
学习 到 图片 左上角 的 模式 特征 可以 在 任何 
地方 识别 如 右下角 这种 特性 使得 图片 处理 更加 
有效 需要 的 样本 相对 减少 实际 生活 中 具有 
平移 不变性 学习 模式 的 空间 层次结构 第一 个 卷积 
层 将 学习 小 的 局部 模式 如 边缘 第二个 
卷积 层 将 学习 由 第一 层 特征 构成 的 
更大 图案 等等 这 使得 卷积 网络 能够 有效 地 
学习 越来越 复杂 和 抽象 的 视觉 概念 现实 生活 
中 许多 都是 分级 的 卷 积在 3D 张量 上 
运算 称 为特征 映射 具 有 两个 空间 轴 高度 
和 宽度 以及 深度 轴 也 称为 通道 轴 . 
对 RGB 三原色 图片 来说 通 道数 为 3 红 
绿 蓝 MNIST 数据 集中 图片 通 道数 为 1 
灰度 图 卷积 操作 在 输入 特征 图上 小分 片上 
然后 将 多个 操作 结果 生成 最后 的 特征 图 
输出 的 特征 图 仍然 是 3D 张量 width height 
深度 可以 是 任意 值 因为 深度 是 网络层 的 
一个 参数 而且 深度 值 不再 代表 红绿蓝 颜色通道 表示 
过滤器 的 个数 过滤器 对 输入 数据 的 特定 方面 
进行 编码 比如 在 高级别 单个 过滤器 可以 编码 输入 
中 存在 面部 的 概念 卷积 定义 的 两个 参数 
卷积 核 大小 通常 为 3x3 5x5 . 卷积 核 
个数 卷积 核 个数 等于 本 层 网络 输出 层 
的 深度 Keras 中 Conv2D 网络层 定义 Conv2D output _ 
depth window _ height window _ width . 卷积 卷积 
核 在上 一层 的 特征 图 的 全 通道 进行 
滑动 然后 抽取 形状 为 window _ height window _ 
width input _ depth 形状 的 3D 片 特征 每个 
3D 片 特征 最后 转换成 1D 向量 卷积 运算 张量 
点积 形状 output _ depth 所有 的 结果 向量 整合 
形成 最后 的 3D 特征 height width output _ depth 
./i 输出/v 结果/n 的/uj 宽度/n 和/c 高度/n 可能/v 和/c 输入/v 
宽度/n 高度/n 不同/a 由于 Padding 项 Strides 步长 最大 池化/nr 
MaxPooling 最大 池化层/nr 的 作用 在于 对 特征 图 进行 
下 采样 最大 池化在/nr 特征 图中 选择 window 然后 每个 
通道 的 在 窗口 内 求 最大值 概念上 与 卷积 
操作 类似 卷积 操 作在 小 patch 中 做 线性转换 
最大 池化是/nr 求 最大值 通过 tensor 的 max 张量 操作 
最大 池化/nr 通常 采用 2x2 窗口 步 长为 2 特征 
图 减半 卷积 通常 卷积 核 大小 为 3x3 步 
长为 1 下 采样 的 目的 在于 减少 要 处理 
特征 图 的 参数 量 通过 使 连续 的 卷积 
层 看到 越来越 大 的 窗口 就 它们 所 涵盖 
的 原始 输入 的 比例 而言 来 促使 空间 滤波器 
层次结构 最大 池化并/nr 不是 唯一 的 下 采 样方法 可以 
使 用带 步长 卷积 或 平均 池化/nr 但是 最大 池化的/nr 
工作 效果 更好 小 数据集 上 训练 卷积 网络计算机 视觉 
中 进场 会 遇到 使用 很少 的 数据 集 去 
训练 一个 图像 分类 模型 小 样本 意味着 样本量 在 
几百 到 几 万张 . 比如 猫狗 分类 共 4000张 
图片 猫 2000张 狗 2000张 用 2000张 图片 来 训练 
1000张 验证 集 1000张 测试 集 首先 不 做 任何 
正则化 处理 直接 训练 得到 一个 baseline 模型 准确率 为 
71% 主要 问题 在于 模型 过拟合 之后 介绍 data augmentation 
数据 增强 减缓 过拟合 训练 后为 82% 更 有效 的 
方法 是 用 已 训 练好 的 模型 最 特征提取 
准确率 90% 96% 或者 微调 已 训 练好 的 网络 
做 特征提取 97% 这三种 方法 有助于 在 小 数据 集上 
的 模型 训练 深度 学习 与 小 数据 问题 的 
相关性 可能 经常 听说 深度 学习 只能 工作 在 大 
数据 集上 这种 说法 部分 正确 深度 学习 的 一个 
重要 特性 在于 深度 学习 能 自己 在 训练 数据 
中 寻找 特征 而 不 需要 人工干预 而 这个 特性 
只有在 大 数据 样本量 上 才 有效 特别 是 输入 
数据 维度 特别高 时 eg 图片 但是 对于 初学者 来说 
构成 大量 样本 的 内容 与 尝试 训练 的 网络 
的 大小 和 深度 是 相对 的 用 几十 张 
图片 训练 卷积 网络 来 解决 一个 十分 复杂 的 
问题 是 不 可能 的 但 如果 模型 比较简单 经过 
正则化 处理 同时 任务 比较 简单 几百/m 张/q 图片/n 也/d 
能/v 解决问题/n 因为 卷积 网络 学习 局部 的 具有 平移 
不变性 的 特征 它们 在 感知 问题 上 具有 很高 
的 数据 效率 尽管 相对 缺乏 数据 但 无需 额外 
的 特征 工程 即使 在 非常 小 的 图像 数据 
集上 从头 开始 训练 卷积 网络 仍然 会 产生 合理 
的 结果 更 重要 的 是 深度 学习 模型 本质上 
是 高度 可再 利用 的 例如 可以 采用 在 大规模 
数据 集上 训练 的 图像 分类 或 语音 到 文本 
模型 只需 进行 微小 的 更改 就 可以 重新 用于 
显著 不同 的 问题 上 具体 而言 以 计算机 视觉 
为例 许多 预先 训 练好 的 模型 通常在 ImageNet 数据集 
上 训练 提供 公开 下载 当 样本量 少时 可以 用 
在 模型 中 做 特征提取 使用 提升 工作 效果 数据 
下载 Keras 中 没有 包括 Dogs vs . Cats 数据集 
可以 在 Kaggle 上 下载 图片格式 为 JPEGs . 数据集 
包含 25000张 猫狗 图片 一半一半 下载 解压缩 后 创建 一个 
新 数据集 包括 3个 文件夹 每类 1000张 的 训练 集 
每类 500张 的 验证 集 和 每类 500张 的 测试 
集 import os shutil # 原始数据 original _ dataset _ 
dir = / Users / fchollet / Downloads / kaggle 
_ original _ data # 新 数据集 目录 base _ 
dir = / Users / fchollet / Downloads / cats 
_ and _ dogs _ small os . mkdir base 
_ dir # 创建 训练 集 验证 集 测试 集 
目录 train _ dir = os . path . join 
base _ dir train os . mkdir train _ dir 
validation _ dir = os . path . join base 
_ dir validation os . mkdir validation _ dir test 
_ dir = os . path . join base _ 
dir test os . mkdir test _ dir # 创建 
对应 数据集 下 不同 类别 的 目录 train _ cats 
_ dir = os . path . join train _ 
dir cats os . mkdir train _ cats _ dir 
train _ dogs _ dir = os . path . 
join train _ dir dogs os . mkdir train _ 
dogs _ dir validation _ cats _ dir = os 
. path . join validation _ dir cats os . 
mkdir validation _ cats _ dir validation _ dogs _ 
dir = os . path . join validation _ dir 
dogs os . mkdir validation _ dogs _ dir test 
_ cats _ dir = os . path . join 
test _ dir cats os . mkdir test _ cats 
_ dir test _ dogs _ dir = os . 
path . join test _ dir dogs os . mkdir 
test _ dogs _ dir fnames = cat . { 
} . jpg . format i for i in range 
1000 # 取 前 1000张 猫 图片 for fname in 
fnames # 将 前 一千张 猫 图片 复制到 新 数据集 
目 录下 src = os . path . join original 
_ dataset _ dir fname dst = os . path 
. join train _ cats _ dir fname shutil . 
copyfile src dst fnames = cat . { } . 
jpg . format i for i in range 1000 1500 
# 取 500张 猫 图片 for fname in fnames # 
500张 猫 图片 复制到 验证 集 src = os . 
path . join original _ dataset _ dir fname dst 
= os . path . join validation _ cats _ 
dir fname shutil . copyfile src dst fnames = cat 
. { } . jpg . format i for i 
in range 1500 2000 # 取 500张 猫 图片 for 
fname in fnames # 500张 猫 图片 做 测试 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
test _ cats _ dir fname shutil . copyfile src 
dst # 狗 图片 fnames = dog . { } 
. jpg . format i for i in range 1000 
# 1000张 狗 图片 做 训练 集 for fname in 
fnames src = os . path . join original _ 
dataset _ dir fname dst = os . path . 
join train _ dogs _ dir fname shutil . copyfile 
src dst fnames = dog . { } . jpg 
. format i for i in range 1000 1500 for 
fname in fnames # 500张 狗 图片 做 验证 集 
src = os . path . join original _ dataset 
_ dir fname dst = os . path . join 
validation _ dogs _ dir fname shutil . copyfile src 
dst Copies the next 500 fnames = dog . { 
} . jpg . format i for i in range 
1500 2000 for fname in fnames # 500张 狗 图片 
做 测试 集 src = os . path . join 
original _ dataset _ dir fname dst = os . 
path . join test _ dogs _ dir fname shutil 
. copyfile src dst 构建 模型 from keras import layers 
from keras import models model = models . Sequential model 
. add layers . Conv2D 32 3 3 activation = 
relu input _ shape = 150 150 3 model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 64 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Conv2D 128 3 3 activation = relu model . 
add layers . MaxPooling2D 2 2 model . add layers 
. Flatten model . add layers . Dense 512 activation 
= relu model . add layers . Dense 1 activation 
= sigmoid 模型 架构 model . summary Layer type Output 
Shape Param # = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = conv2d _ 1 
Conv2D None 148 148 32 896 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
maxpooling2d _ 1 MaxPooling2D None 74 74 32 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ conv2d _ 2 Conv2D None 72 72 
64 18496 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ maxpooling2d _ 2 MaxPooling2D 
None 36 36 64 0 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ conv2d 
_ 3 Conv2D None 34 34 128 73856 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ maxpooling2d _ 3 MaxPooling2D None 17 17 128 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ conv2d _ 4 Conv2D None 
15 15 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ maxpooling2d _ 
4 MaxPooling2D None 7 7 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ flatten _ 1 Flatten None 6272 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ dense _ 1 Dense None 512 3211776 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ dense _ 2 Dense None 1 513 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = Total params 3 453 121 Trainable 
params 3 453 121 Non trainable params 0 编译 阶段 
使用 RMSProp 优化 算法 binary crossentropy 为 损失 函数 from 
keras import optimizers model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 4 
metrics = acc 数据 预处理 数据 在 送到 网络 模型 
之前 应该 转换成 浮点 类型 的 张量 目前 数据 集中 
数据格式 为 JPEG 所以 处理 步骤 大致 为 读取 图片 
文件 将 JPEG 格式 转换 为 RGB 像素 值 转换成 
浮点 类型 张量 将 像素 值 0 ~ 255 缩 
放到 0 1 之间 针对 上述 步骤 Keras 中有 自动化 
处理 方法 Keras 中 有一个 图像处理 模块 keras . preprocessing 
. image . 其中 包括 一个 I m a g 
e D a t a G e n e r 
a t o r 类 可以 将 磁 盘上 的 
图片 文件 自动 转换 成 预处理 的 张量 batch 批量 
使用 方法 from keras . preprocessing . image import I 
m a g e D a t a G e 
n e r a t o r train _ datagen 
= I m a g e D a t a 
G e n e r a t o r rescale 
= 1 . / 255 test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 # 将 图片 转换成 150x150 类别 为 
2 class _ mode 确定 返回 标签 的 类型 binary 
二 分类 1D 类型 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
\ target _ size = 150 150 batch _ size 
= 20 class _ mode = binary validation _ generator 
= test _ datagen . flow _ from _ directory 
validation _ dir target _ size = 150 150 batch 
_ size = 20 class _ mode = binary 生成器 
generator 的 数据 结果 为 150x150 RGB 批量 图片 尺寸 
为 20 150 150 3 二进制 标签 形状 20 每个 
批量 大小 为 20个 样本 batch _ size 为 20 
. 注意 生成器 无限期 地 生成 这些 批次 它 在 
目标 文件夹 的 图像 上 无休止 地 循环 使用 generator 
数据 生成器 对模型 进行 训练 使用 fit _ generator 方法 
对于 数据 生成器 来说 相当于 fit 方法 fit _ generator 
第一个 参数 是 Python 生成器 类型 能/v 不断/d 地/uv 生成/v 
输入/v 和/c 标签/n 批量/n 因为 数据 不断 生成 Keras 模型 
需要 知道 在 声明 一个 epoch 之前 从 发生器 中 
抽取 多少 批量 steps _ per _ epoch 参数 从 
生成器 中 生成 steps _ per _ epoch 个 批量 
数据 在 经过 steps _ per _ epoch 次梯度 下降 
后 在 下 一个 epoch 上 进行 训练 在 这里 
批量 大小 为 20 一个 epoch 有 100个 批量 生成 
2000张 图片 样本 使用 fit _ generator 方法 可以 传递 
validataion _ data 参数 和 fit 方法 相似 值得 注意 
的 是 这个 参数 可以 赋值 为 数据 生成器 也 
可以 是 numpy 数组 的 元组 如果 validation _ data 
参数 是 数据 生成器 生成器 能 不断 地 生成 数据 
所以 需要 设置 validation _ steps 参数 确定 从 生成器 
中 生成 多少 验证 集 批量 history = model . 
fit _ generator train _ generator steps _ per _ 
epoch = 100 epoch = 30 validation _ data = 
validation _ generator validation _ steps = 50 模型 保存 
model . save cats _ and _ dogs _ small 
_ 1 . h5 训练 集 验证 集 准确率 损失 
值 变化 可以 发现 模型 发生 过拟合 现象 训练 准确率 
随着 时间 线性 增加 直到 100% 而 验证 集 准确率 
在 70 72% 波动 验证 集 损失 在 5个 epoch 
之后 达到 最小值 之后 开始 波动 训练 集 损失 线性 
减少 直到 为 0 因为 训练 集 只有 2000张 图片 
遇到 的 第一 个 问题 就是 模型 过拟合 Dropout 权重 
衰减 可以 减缓 过拟合 还有 一个 计算机 视觉 任务 中 
经常 使用 的 处理 方法 数据 增强 data augmentation 数据 
增强 过度 拟合 是 由于 样本 太少 而 无法 学习 
导致 无法 训练 可以 推广 到 新 数据 的 模型 
给定 无限 的 数据 模型 可以 学习 到 手头 数据分布 
的 每个 可能 方面 永远 不会 过拟合 数据 增强 采用 
从 现有 训练样本 生成 更多 训练 数据 的 方法 通过 
大量 随机 变换 来 增加 样本 从而 产生 新的 可靠 
的 图像 样本 目标 是 在 训练 时 模型 将 
永远 不会 看到 两张 完全 相同 的 图片 这 有助于 
模型 观察 数据 的 更多 方面 并 更好 地 概括 
数据 Keras 中 可以 通过 实例 化 I m a 
g e D a t a G e n e 
r a t o r 实例 确定 图片 转换方法 从而 
实现 数据 增强 datagen = I m a g e 
D a t a G e n e r a 
t o r rotation _ range = 40 # 最大 
旋转 角度 width _ shift _ range = 0.2 # 
水平 随机 平移 图片 的 范围 比例 height _ shift 
_ range = 0.2 # 垂直 随机 平移 图片 的 
范围 shear _ range = 0.2 # 随机 应用 剪切 
变换 zoom _ range = 0.2 # 随机 缩放 图片 
horizontal _ flip = True # 随机 翻转 图片 fill 
_ mode = nearest # 用于 填充 新 创建 的 
像素 的 策略 在 旋转 或 宽度 / 高度 偏移 
后 出现 如果 使用 这样 的 数据 增强 配置 训练 
新 网络 网络 将 永远 不会 看到 两张 相同 的 
输入 图片 但 它 看到 的 输入 仍然 是 严重 
相互 关联 的 因为 它们 来自 少量 原始 图像 无法 
生成 新 信息 只能 重新 混合 现有 信息 因此 这 
不 可能 完全 摆脱 过拟合 为了 进一步 减缓 过拟合 需要 
增加 Dropout 层 在 全 连接 层 之前 新 网络 
模型 model = models . Sequential model . add layers 
. Conv2D 32 3 3 activation = relu input _ 
shape = 150 150 3 model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 64 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Conv2D 128 
3 3 activation = relu model . add layers . 
MaxPooling2D 2 2 model . add layers . Flatten model 
. add layers . Dropout 0.5 model . add layers 
. Dense 512 activation = relu model . add layers 
. Dense 1 activation = sigmoid model . compile loss 
= binary _ crossentropy optimizer = optimizers . RMSprop lr 
= 1e 4 metrics = acc 使用 数据 增强 和 
Dropout 训练 网络 train _ datagen = I m a 
g e D a t a G e n e 
r a t o r rescale = 1 . / 
255 rotation _ range = 40 width _ shift _ 
range = 0.2 height _ shift _ range = 0.2 
shear _ range = 0.2 zoom _ range = 0.2 
horizontal _ flip = True test _ datagen = I 
m a g e D a t a G e 
n e r a t o r rescale = 1 
. / 255 train _ generator = train _ datagen 
. flow _ from _ directory train _ dir target 
_ size = 150 150 batch _ size = 32 
class _ mode = binary validation _ generator = test 
_ datagen . flow _ from _ directory validation _ 
dir target _ size = 150 150 batch _ size 
= 32 class _ mode = binary history = model 
. fit _ generator train _ generator steps _ per 
_ epoch = 100 epochs = 100 validation _ data 
= validation _ generator validation _ steps = 50 model 
. save cats _ and _ dogs _ small _ 
2 . h5 # 模型 保存 使用 数据 增强 和 
Dropout 后 训练 集 验证 集 准确率 和 损失 函数 
变化 模型 不再 过拟合 训练 集 曲线 和 验证 集 
曲线 几乎 相互 吻合 准确率 82% 提高 了 15% 左右 
使用 正则化 技术 微调 网络 超 参数 模型 准确率 会 
进一步 提高 到 86% ~ 87% . 但是 很难 继续 
提高 因为 训练 数据 有限 样本 量 太少 另一种 方法 
可以 采用 预先 训 练好 的 网络 模型 做 特征提取 
提高 准确率 使用 预 训练 卷积 网络 在 小 图像 
数据 集上 使用 深度 学习 的 一种 常见 且 高效 
的 方法 是 使用 预 训练 网络 预 训练 网络 
是 先前 在 大型 数据集 上 训练 的 已 保存 
网络 通常 是 处理 大规模 图像 分类 任务 如果 这个 
原始 数据集 足够 大 且 代表 性强 则 预 训练 
网络 学习 的 特征 的 空间 层次结构 可以 有效 地 
充当 视觉 世界 的 通用 模型 因此 其 特征 可以 
证明 对 许多 不同 的 计算机 视觉 问题 都 有用 
甚至 这些 新 问题 可能 涉及 与 原始 任务 完全 
不同 例如 可以 在 ImageNet 上 训练 网络 其中 类 
主要 是 动物 和 日常 物品 然后 将 这个 训练 
好 的 网络 重新 用于 识别 图像 中 的 家具 
物品 任务 中 与 许多 较 旧 的 浅 学习 
方法 传统 机器学习 方法 相比 学习 特征 在 不同 问题 
中 的 这种 可移植性 是 深度 学习 的 关键 优势 
并且 它 使得 深度 学习 对于 小 数据 问题 非常 
有效 比如 在 ImageNet 数据集 上 训练 的 网络 模型 
140 万个 标记 图像 和1/nr 000个 不 同类 ImageNet 包含 
许多 动物 类别 包括 不同 种类 的 猫 和狗/nr 因此 
可以 期望 在 狗 与 猫 的 分类 问题 上 
表现 良好 使用 VGG16 网络 架构 它 是 ImageNet 的 
简单 且 广泛 使用 的 convnet 架构 使用 预 训练 
网络 有 两种 方法 特征提取 和 微调 特征提取 特征提取 包括 
使用 先前 网络 学习 的 表示 从新 样本 中 提取 
有趣 特征 然后 这些 功能 将 通过 一个 新的 分类器 
运行 该 分类器 从头 开始 训练 如前所述 用于 图像 分类 
的 网络 包含 两 部分 它们/r 以/p 一/m 系列/q 池化和/nr 
卷积/n 层/q 开始/v 并以 密集 连接 的 分类器 结束 第一 
部分 称为 模型 的 卷积 基础 在 卷积 网络 中 
特征提取 包括 获取 先前 训练 的 网络 的 卷积 基础 
通过 它 运行 新 数据 以及 在 输出 之上 训练 
新的 分类器 为什么 只 重用 卷积 网络 是否 可以 重复 
使用 全 连接 分类器 一般来说 应该 避免 这样 做 原因 
是 卷积 网络 学习 的 表示 可能 更 通用 因此 
更 可 重复 使用 特征 网络 的 特征 图 是 
图片 上 一般 概念 的 存在 图 无论 处理 的 
计算机 视觉 问题 是 什么 都 可能 是 有用 的 
但是 分类器 学习 的 表示 必然 特 定于 训练 模型 
的 类 集 它们 将 仅 包含 关于 整个 图像 
中 该类 或 该类 的 存在 概率 的 信息 此外 
在 全 连接 网络层 的 输出 表示 不再 包含 有关 
对象 在 输入 图像 中 的 位置 信息 这些 表示 
消除 了 空间 的 概念 而 卷积 特征 图 还 
可以 描述 对象 的 位置 信息 对于 对象 位置 很 
重要 的 问题 全 连接 的 特征 表示 在 很大 
程度 上 是 无用 的 注意 由 特定 卷积 层 
提取 的 表示 的 一般性 以及 因此 可 重 用性 
的 级别 取决于 模型 中 网络层 的 深度 模型 中 
较早 出现 的 图层 会 提取 局部 的 高度 通用 
的 特征 贴图 例如 可视 边缘 颜色 和 纹理 而 
较 高层 的 图层 会 提取 更 抽象 的 概念 
例如 猫耳朵 或 狗眼 因此 如果 训练 数据集 与 训练 
原始 模型 的 数据 集 有 很大 差异 那么 最好 
只 使用 模型 的 前 几层 来 进行 特征提取 而 
不是 使用 整个 卷积 网络 的 输出 在 这种 情况 
下 因为 ImageNet 类 集 包含 多个 dog 和 cat 
类 所以 重用 原始 模型 的 全 连接 层 中 
包含 的 信息 可能 是 有益 的 但是 我们 会 
选择 不 这样 做 以便 涵盖 新 问题 的 类 
集 不与 原始 模型 的 类 集 重叠 的 更 
一般情况 通过 使用 在 ImageNet 上 训练 的 VGG16 网络 
的 卷积 网络 来 实现 这 一点 从猫和/nr 狗/n 图像/n 
中/f 提取/v 有趣/a 的/uj 特征/n 然后 在 这些 特征 之上 
训练 狗 与 猫 的 分类器 Keras 中 可以 直接 
获取 VGG16 模型 包含 在 keras . applications 模块 中 
其中 还 包括 其他 模型 X c e p t 
i o n I n c e p t i 
o n V 3 R e s N e t 
5 0 V G G 1 6 V G G 
1 9 M o b i l e N e 
t 实例 化 VGG16 模型 from keras . application import 
vgg16 conv _ base = VGG16 weights = imagenet include 
_ top = False input _ shape = 150 150 
3 构造器 的 3个 参数 weights 读取 权重 保存 点 
文件 初始化 模型 include _ top 是否 包含 网络 的 
全 连接 层 模型 全 连接 层 分类 类别 在 
ImageNet 上 的 1000类 因为 要 使用 自己 创建 的 
全 连接 分类器 可以 不 使用 原来 的 全 连接 
层 input _ shape 送到 模型 中 图片 张量 的 
形状 参数 是 可选 的 如果 不 传递 参数 网络 
可以 处理 任意 形状 的 输入 VGG16 网络 模型 架构 
conv _ base . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = input _ 1 InputLayer None 
150 150 3 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block1 _ 
conv1 Convolution2D None 150 150 64 1792 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block1 _ conv2 Convolution2D None 150 150 64 36928 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block1 _ pool MaxPooling2D None 75 
75 64 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block2 _ conv1 
Convolution2D None 75 75 128 73856 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block2 _ conv2 Convolution2D None 75 75 128 147584 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block2 _ pool MaxPooling2D None 37 37 
128 0 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block3 _ conv1 Convolution2D 
None 37 37 256 295168 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block3 
_ conv2 Convolution2D None 37 37 256 590080 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block3 _ conv3 Convolution2D None 37 37 256 
590080 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block3 _ pool MaxPooling2D None 
18 18 256 0 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block4 _ 
conv1 Convolution2D None 18 18 512 1180160 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block4 _ conv2 Convolution2D None 18 18 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block4 _ conv3 Convolution2D None 18 
18 512 2359808 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block4 _ pool 
MaxPooling2D None 9 9 512 0 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block5 _ conv1 Convolution2D None 9 9 512 2359808 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block5 _ conv2 Convolution2D None 9 9 
512 2359808 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block5 _ conv3 Convolution2D 
None 9 9 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block5 
_ pool MaxPooling2D None 4 4 512 0 = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = Total params 14 714 688 Trainable params 14 
714 688 Non trainable params 0 最后 一层 的 特征 
图 形状 为 4 4 512 . 之后 连接 到 
全 连接 分类器 上 有 两种 处理 方法 训练 卷积 
网络 模型 部分 将 输出 结果 保存 在 磁 盘上 
之后 读取 磁 盘上 的 数据 送到 全 连接 分类器 
中 优点 在于 运行 高效 快速 因为 卷积 网络 部分 
针对 每张 输入 图片 只 运行 一次 而 卷积 部分 
是 最 耗时 耗费 运算 能力 资源 的 但 同时 
不能 使用 数据 增强 将/d 全/a 连接/v 分类器/n 和/c 卷积/n 
部分/n 整合/v 到/v 一起/m 在 输入 数据 上端 到 端的 
运行 可以 使用 数据 增强 因为 每次 输入 模型 的 
图像 都会 通过 模型 经过 卷积 部分 不/d 使用/v 数据/n 
增强/v 的/uj 特征/n 提取/v 使用/v I/w m/w a/w g/w e/w 
D/w a/w t/w a/w G/w e/w n/w e/w r/w a/w 
t/w o/w r/w 将/d 磁盘/n 文件/n 和/c 标签/n 读取/v 成/n 
张量/nr 形式/n 运行 卷积 部分 的 predict 提取 图片 特征 
import os import numpy as np from keras . preprocessing 
. image import I m a g e D a 
t a G e n e r a t o 
r base _ dir = / Users / fchollet / 
Downloads / cats _ and _ dogs _ small train 
_ dir = os . path . join base _ 
dir train # 训练 数据 validation _ dir = os 
. path . join base _ dir validation # 验证 
数据 test _ dir = os . path . join 
base _ dir test # 测试数据 datagen = I m 
a g e D a t a G e n 
e r a t o r rescale = 1 . 
/ 255 # batch _ size = 20 def extract 
_ features directory sample _ count # 读取 文件 转换成 
张量 形式 features = np . zeros shape = sample 
_ count 4 4 512 labels = np . zeros 
shape = sample _ count generator = datagen . flow 
_ from _ directory directory target _ size = 150 
150 batch _ size = batch _ size class _ 
mode = binary i = 0 for inputs _ batch 
labels _ batch in generator # 生成 对应 批量 数据 
features _ batch = conv _ base . predict inputs 
_ batch # 卷积 特征提取 结果 features i * batch 
_ size i + 1 * batch _ size = 
features _ batch labels i * batch _ size i 
+ 1 * batch _ size = labels _ batch 
i + = 1 if i * batch _ size 
= sample _ count break return features labels train _ 
features train _ labels = extract _ features train _ 
dir 2000 validation _ features validation _ labels = extract 
_ features validation _ dir 1000 test _ features test 
_ labels = extract _ features test _ dir 1000 
当前 提取 特征 形状 为 samples 4 4 512 在 
送到 全 连接 层 之前 需要 先 平 铺成 samples 
8192 train _ features = np . reshape train _ 
features 2000 4 * 4 * 512 validation _ features 
= np . reshape validation _ features 1000 4 * 
4 * 512 test _ features = np . reshape 
test _ features 1000 4 * 4 * 512 定义 
全 连接 分类器 将 特征 数据 送到 分类器 中 训练 
from keras import models from keras import layers from keras 
import optimizers model = models . Sequential model . add 
layers . Dense 256 activation = relu input _ dim 
= 4 * 4 * 512 model . add layers 
. Dropout 0.5 model . add layers . Dense 1 
activation = sigmoid model . compile optimizer = optimizers . 
RMSprop lr = 2e 5 loss = binary _ crossentropy 
metrics = acc history = model . fit train _ 
features train _ labels epochs = 30 batch _ size 
= 20 validation _ data = validation _ features validation 
_ labels 验证 集 训练 集上 损失 值 和 准确率 
变化 情况 验证 集 准确率 达到 90% . 但 图示 
显示 模型 从 开始 就 过拟合 了 使用 数据 正 
增强 可以 缓解 一下 使用 数据 增强 的 特征 提取 
和 第一 种 方法 相比 运算速度 更慢 耗费 运算 资源 
更多 通常 需要 GPU 如果 GPU 上 速度 还慢 最好 
使用 第 一种 方法 from keras import models from keras 
import layers model = models . Sequential model . add 
conv _ base model . add layers . Flatten model 
. add layers . Dense 256 activation = relu model 
. add layers . Dense 1 activation = sigmoid 模型 
架构 为 model . summary Layer type Output Shape Param 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = vgg16 Model None 4 4 
512 14714688 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ flatten _ 1 Flatten 
None 8192 0 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ dense _ 1 
Dense None 256 2097408 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ dense _ 
2 Dense None 1 257 = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = Total 
params 16 812 353 Trainable params 16 812 353 Non 
trainable params 0 在 模型 训练 之前 需要 对 卷积 
部分 进行 freeze 冻住 Freezing 网络层 意味着 避免 在 训练 
过程 网络层 的 参数 被 更新 如果 不 做 freeze 
处理 训练 过程 中 卷积 部分 提取 的 特征 会 
逐渐 改变 在 Keras 中 可以 通过 设置 trainable 参数 
为 False 进行 Freeze 处理 conv _ base . trainable 
= False 注意 为了 使 这些 更改 生效 必须 首先 
编译 模型 如果在 编译 后 修改 了 权重 可 训练 
性 则应 重新 编译 模型 否则 将 忽略 这些 更改 
from keras . preprocessing . image import I m a 
g e D a t a G e n e 
r a t o r from keras import optimizers train 
_ datagen = I m a g e D a 
t a G e n e r a t o 
r rescale = 1 . / 255 rotation _ range 
= 40 width _ shift _ range = 0.2 height 
_ shift _ range = 0.2 shear _ range = 
0.2 zoom _ range = 0.2 horizontal _ flip = 
True fill _ mode = nearest test _ datagen = 
I m a g e D a t a G 
e n e r a t o r rescale = 
1 . / 255 train _ generator = train _ 
datagen . flow _ from _ directory train _ dir 
target _ size = 150 150 batch _ size = 
20 class _ mode = binary validation _ generator = 
test _ datagen . flow _ from _ directory validation 
_ dir target _ size = 150 150 batch _ 
size = 20 class _ mode = binary model . 
compile loss = binary _ crossentropy optimizer = optimizers . 
RMSprop lr = 2e 5 metrics = acc history = 
model . fit _ generator train _ generator steps _ 
per _ epoch = 100 epochs = 30 validation _ 
data = validation _ generator validation _ steps = 50 
损失 值 和 准确率 变化 验证 集上 准确率 达到 96% 
. 模型 微调 Fine tuning 另一种 广泛 使用 的 模型 
重用 技术 对 特征提取 的 补充 就是 模型 参数 微调 
微调 包括 解冻 用于 特征提取 的 冻结 模型 基础 的 
一些 顶层 并 联合 训练 模型 的 新 添加 部分 
在 这种 情况 下 全 连接 的 分类器 和 这些 
顶层 这 称为 微调 因为 它 稍微 调整了 重复 使用 
的 模型 的 抽象 表示 以使 它们 与 手头 的 
问题 更 相关 微调 网络 模型 步骤 在 已经 训 
练好 的 网络 模型 上 添加 自定义 网络 模型 Freeze 
冻住 训 练好 的 模型 训练 添加 部分 网络 Unfreeze 
解冻 部分 base 网络 重新 训练 解冻 部分 和 添加 
部分 base 部分 网络 模型 conv _ base . summary 
Layer type Output Shape Param # = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
input _ 1 InputLayer None 150 150 3 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block1 _ conv1 Convolution2D None 150 150 
64 1792 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block1 _ conv2 Convolution2D 
None 150 150 64 36928 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block1 
_ pool MaxPooling2D None 75 75 64 0 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block2 _ conv1 Convolution2D None 75 75 128 
73856 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block2 _ conv2 Convolution2D None 
75 75 128 147584 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block2 _ 
pool MaxPooling2D None 37 37 128 0 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block3 _ conv1 Convolution2D None 37 37 256 295168 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block3 _ conv2 Convolution2D None 37 
37 256 590080 _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ block3 _ conv3 
Convolution2D None 37 37 256 590080 _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
block3 _ pool MaxPooling2D None 18 18 256 0 _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ block4 _ conv1 Convolution2D None 18 18 
512 1180160 _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ block4 _ conv2 Convolution2D 
None 18 18 512 2359808 _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ block4 
_ conv3 Convolution2D None 18 18 512 2359808 _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ block4 _ pool MaxPooling2D None 9 9 512 
0 _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ block5 _ conv1 Convolution2D None 
9 9 512 2359808 _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ block5 _ 
conv2 Convolution2D None 9 9 512 2359808 _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ block5 _ conv3 Convolution2D None 9 9 512 2359808 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ _ _ _ _ _ _ 
_ _ _ _ block5 _ pool MaxPooling2D None 4 
4 512 0 = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = Total params 14714688 
微调 模型 的 最后 3个 卷积 层 意味着 到 block4 
_ pool 之前 都被 冻住 网络层 block5 _ conv1 block5 
_ conv2 和 block5 _ conv3 都是 可 训练 的 
为什么 不 微调 更 多层 为什么 不 微调 整个 卷积 
网络 可以 这么 做 但是 你 需要 考虑 以下 几点 
卷积 网络 中的 前 几层 编码 更 通用 可 重用 
的 特征 而 更 高层 的 编码 更 专业 的 
特征 微调 更 专业 的 功能 更 有用 因为 这些 
功能 需要 重新 用于 新 问题 微调 下层 会有 快速 
下降 的 回报 训练 的 参数 越多 越有/nr 可能/v 过度/n 
拟合/v 卷积 网络 模型 有 1500 万个 参数 因此 尝试 
在 小 数据集 上 训练 它 会有 风险 一个 很好 
的 策略 是 只 微调 卷积 基础 中的 前 两个 
或 三个 层 conv _ base . trainable = True 
set _ trainable = False for layer in conv _ 
base . layers if layer . name = = block5 
_ conv1 # block5 _ conv1 可 训练 set _ 
trainable = True # flag 可 训练 if set _ 
trainable layer . trainable = True # block5 _ conv1 
网络层 设置 为 可 训练 else layer . trainable = 
False # 其它 层 不可 训练 现在 可以 开始 微调 
网络 了 使用 RMSProp 优 化器 以 非常 低 的 
学习 速率 执行 此 操作 使用 低 学习率 的 原因 
是 希望 限制 对 正在 微调 的 三个 网络层 的 
表示 所做 的 修改 的 幅度 太大 的 更新 可能会 
损害 这些 表示 model . compile loss = binary _ 
crossentropy optimizer = optimizers . RMSprop lr = 1e 5 
metrics = acc history = model . fit _ generator 
train _ generator steps _ per _ epoch = 100 
epochs = 100 validation _ data = validation _ generator 
validation _ steps = 50 验证 集 测试 集上 损失 
函数 和 准确率 变化 请注意 损失 曲线 没有 显示 任何 
真正 的 改善 事实上 它 正在 恶化 如果 损失 没有减少 
准确度 如何 保持 稳定 或 改善 答案 很 简单 展示 
的 是 指数 损失 值 的 平均值 但是 对于 准确性 
而言 重要 的 是 损失 值 的 分布 而 不是 
它们 的 平均值 因为 精度 是 模型 预测 的 类 
概率 的 二元 阈值 的 结果 即使 没有 反映 在 
平均 损失 中 该 模型 仍 可能会 有所 改善 在 
测试 集上 评估 test _ generator = test _ datagen 
. flow _ from _ directory test _ dir target 
_ size = 150 150 batch _ size = 20 
class _ mode = binary test _ loss test _ 
acc = model . evaluate _ generator test _ generator 
steps = 50 print test acc test _ acc # 
97% 小结 Convnets 是 用于 计算机 视觉 任务 的 最佳 
机器学习 模型 即使 在 非常 小 的 数据 集上 也 
可以 从头 开始 训练 并 获得 不错 的 结果 在 
小型 数据 集上 过度 拟合 将 是 主要 问题 在 
处理 图像 数据 时 数据 增强 是 对抗 过度 拟合 
的 有效 方法 通过 重用 现有 的 卷积 网络 模型 
可以 在 新 数据 集上 做 特征提取 这是 处理 小 
图像 数据集 的 有用 技术 作为 特征提取 的 补充 可以 
使用 模型 微调 让 模型 适应 新 问题 以前 现有 
模型 可以 学习 新 问题 的 特征 表示 能 进一步 
推动 性能 卷积 学习 结果 可视化 人们 常说 深度 学习 
模型 是 黑匣子 学习 表示 难以 提取 以及 很难 以 
人类 可读 的 形式 呈现 虽然 对于 某些 类型 的 
深度 学习 模型 来说 这 是 部分 正确 的 但 
对于 convnets 来说 绝对 不是 这样 由 convnet 学习 的 
表示 非常 适合 可视化 这在 很大 程度 上 是因为 它们 
是 视觉 概念 的 表示 三种 常见 的 可视化 方法 
可视化 中间 信号 输出 中间 激活 有助于 了解 连续 的 
convnet 层 如何 转换 输入 数据 以及 了解 各个 convnet 
过滤器 的 含义 可视化 convnets 过滤器 有助于 准确 理解 convnet 
中 每个 过滤器 可 接受 的 视觉 模式 或 概念 
可视化 图像 中 类 激活 的 热 图 有助于 了解 
图像 的 哪些 部分 被 识别 为 属于 给定 的 
类 从而 可以 在 图像 中 本地化 对象 可视化/n 中间/f 
激活/a 值/n 可视化/n 中间/f 激活/a 包括/v 在/p 给定/v 特定/d 输入/v 
的/uj 情况/n 下/f 显示/v 由/p 网络/n 中/f 的/uj 各种/r 卷积/n 
和池化/nr 层/q 输出/v 的/uj 特征/n 映射/v 层 的 输出 通常 
称 为其 激活 激活 函数 的 输出 这 给出 了 
如何 将 输入 分解 为 网络 学习 的 不同 过滤器 
的 视图 希望 从 三个 维度 宽度 高度 和 深度 
通道 可视化 特征 图 每个 通道 编码 相对 独立 的 
特征 因此 可视化 这些 特征 图 的 正确 方法 是 
通过 将 每个 通道 的 内容 独立 地 绘制 为 
2D 图像 加载 保存 的 模型 from keras . models 
import load _ model model = load _ model cats 
_ and _ dogs _ small _ 2 . h5 
img _ path = . / cats _ and _ 
dogs _ small / test / cats / cat . 
1700 . jpg # 给定 一张 图片 from keras . 
preprocessing import image import numpy as np img = image 
. load _ img img _ path target _ size 
= 150 150 img _ tensor = image . img 
_ to _ array img img _ tensor = np 
. expand _ dims img _ tensor axis = 0 
img _ tensor / = 255 . 查看 所有 网络层 
的 输出 结果 from keras import models layer _ outputs 
= layer . output for layer in model . layers 
8 activation _ model = models . Model inputs = 
model . input outputs = layer _ outputs 输入 图像 
输 入时 此 模型 返回 原始 模型 中 网络层 激活 
的 值 一个 多 输出 模型 到 目前 为止 看到 
的 模型 只有 一个 输入 和 一个 输出 在 一般 
情况 下 模型 可以 具有 任意 数量 的 输入 和 
输出 这个/r 有/v 一个/m 输入/v 和/c 八个/m 输出/v 每层 激活 
一个 输出 模型 运行 activations = activation _ model . 
predict img _ tensor # 输出 每层 激活 值 一个 
数 组 第一 个 卷积 层 结果 first _ layer 
_ activation = activations 0 print first _ layer _ 
activation . shape # 1 148 148 32 import matplotlib 
. pyplot as plt plt . matshow first _ layer 
_ activation 0 4 cmap = viridis # 第 4 
通道 可视化 网络 中 所有 激活 函数值 可视化 将 8个 
网络层 激活 函数值 的 所有 通道 结果 显示 出来 layer 
_ names = for layer in model . layers 8 
layer _ names . append layer . name images _ 
per _ row = 16 for layer _ name layer 
_ activation in zip layer _ names activations n _ 
features = layer _ activation . shape 1 size = 
layer _ activation . shape 1 n _ cols = 
n _ features / / images _ per _ row 
display _ grid = np . zeros size * n 
_ cols images _ per _ row * size for 
col in range n _ cols for row in range 
images _ per _ row channel _ image = layer 
_ activation 0 col * images _ per _ row 
+ row channel _ image = channel _ image . 
mean channel _ image / = channel _ image . 
std channel _ image * = 64 channel _ image 
+ = 128 channel _ image = np . clip 
channel _ image 0 255 . astype uint8 display _ 
grid col * size col + 1 * size row 
* size row + 1 * size = channel _ 
image scale = 1 . / size plt . figure 
figsize = scale * display _ grid . shape 1 
scale * display _ grid . shape 0 plt . 
title layer _ name plt . grid False plt . 
imshow display _ grid aspect = auto cmap = viridis 
值得 注意 的 是 第一层 充当 各种 边缘 检测器 的 
集合 在 那个 阶段 激活 值 几乎 保留 了 初始 
图 片中 的 所有 信息 随着 网络层 的 增加 激活 
变得 越来越 抽象 在 视觉 上 也不 那么 容易 理解 
开始 编码 更高 级别 的 概念 如 猫耳 和 猫眼 
更高 级别 的 表示 关于 图像 的 视觉 内容 越来越 
少 关于 图像 类型 的 信息 越来越 多 激活 的 
稀疏 性 随着 层 的 深度 而 增加 在 第一 
层 中 所有 滤波器 都由 输入 图像 激活 但在 以下 
图层 中 越来越 多 的 过滤器 为 空白 这 意味着 
在 输入 图像 中 找 不到 滤镜 编码 的 图案 
刚刚 证明 了 深度 神经 网络 所 学习 的 表征 
的 一个 重要 的 普遍 特征 由 层 提取 的 
特征 随着 层 的 深度 而 变得 越来越 抽象 更 
高层 的 激活 越来越少 地 显示 关于 所 看到 的 
特定 输入 的 信息 越来越 多 关于 目标 的 信息 
. 深度 神经网络 有效 地 充当 信息 蒸馏 管道 原始数据 
进入 在 这种 情况下 为 RGB 图像 并被 重复 变换 
以便 过滤掉 无关 信息 例如 图像 的 特定 视觉 外观 
以及 有用 的 信息 被 放大 和 细化 例如 图像 
的 类 可视化 卷积 核 另一种 检查 由 convnet 学习 
的 过滤器 的 简单 方法 是 显示 每个 过滤器 要 
响应 的 视觉 模式 这 可以 通过 输入 空间 中的 
渐变 上升 来 完成 将 渐变 下降 应用于 convnet 的 
输入 图像 的 值 空间 上 从 空白 输入 图像 
开始 最大化 特定 过滤器 的 响应 得到 的 输入 图像 
将 是 所选 滤波器 最大 响应 的 图像 过程 很 
简单 您 将 构建 一个 损失 函数 使 给定 卷积 
层 中 给定 滤波器 的 值 最大化 然后 您 将 
使用 随机 梯度 下降 来 调整 输入 图像 的 值 
以便 最大化 此 激活 值 例如 这是 在 VGG16 的 
block3 _ conv1 中 激活 过滤器 0 的 损失 . 
from keras . applications import VGG16 from keras import backend 
as K model = VGG16 weights = imagenet include _ 
top = False layer _ name = block3 _ conv1 
filter _ index = 0 layer _ output = model 
. get _ layer layer _ name . output # 
得到 block3 _ conv1 的 激活 值 loss = K 
. mean layer _ output filter _ index 要 实现 
梯度 下降 需要 相对于 模型 输入 求 损失 的 梯度 
grads = K . gradients loss model . input 0 
使用 梯度 正则化 平滑 梯度 值 grads / = K 
. sqrt K . mean K . square grads + 
1e 5 计算 损失 张量 和 梯度 张量 使用 keras 
的 iterate 函数 接收 numpy 张量 返回 关于 损失 和 
梯度 的 张量 列表 iterate = K . function model 
. input loss grads import numpy as np loss _ 
value grads _ value = iterate np . zeros 1 
150 150 3 将 张量 转换 为 图片格式 def deprocess 
_ image x x = x . mean x / 
= x . std + 1e 5 x * = 
0.1 x + = 0.5 x = np . clip 
x 0 1 x * = 255 x = np 
. clip x 0 255 . astype uint8 return x 
整合 卷积 核 可视化 函数 def generate _ pattern layer 
_ name filter _ index size = 150 layer _ 
output = model . get _ layer layer _ name 
. output loss = K . mean layer _ output 
filter _ index grads = K . gradients loss model 
. input 0 grads / = K . sqrt K 
. mean K . square grads + 1e 5 iterate 
= K . function model . input loss grads input 
_ img _ data = np . random . random 
1 size size 3 * 20 + 128 . step 
= 1 . for i in range 40 loss _ 
value grads _ value = iterate input _ img _ 
data input _ img _ data + = grads _ 
value * step img = input _ img _ data 
0 return deprocess _ image img 这些 过滤器 可视化 展示 
了 很多 关于 如何 使用 数字 网络层 来 查看 世界 
网络 中 的 每个 层 都 学习 了 一组 过滤器 
以便 它们 的 输入 可以 表示 为 过滤器 的 组合 
类别 激活 值 heatmap 可视化 一种 可视化 技术 有助于 理解 
给定 图像 的 哪些 部分 引导 其 进行 最终 分类 
决策 的 可视化 技术 这种 通用 类别 的 技术 称为 
类 激活 图 CAM 可视化 它 包括 在 输入 图像 
上 生成 类 激活 的 热 图 类 激活 热 
图 是 与 特定 输出 类 相 关联 的 分数 
的 2D 网格 针对 任何 输入 图像 中 的 每个 
位置 计算 指示 每个 位置 相对 于所/nr 考虑 的 类 
的 重要 程度 小结 Convnets 是 处理 视觉 分类 问题 
的 最佳 工具 Convnets 通过学习 模块化 模式 和 概念 的 
层次 结构 来 表示 视觉 世界 现在 能够 从头 开始 
训练 自己 的 网络 以 解决 图像 分类 问题 如何 
使用 数据 增强 重用 预 训练 网络 微调 与 训练 
过 网络 来 缓解 过拟合 现象 生成 由 convnet 学习 
的 过滤器 的 可视化 等 