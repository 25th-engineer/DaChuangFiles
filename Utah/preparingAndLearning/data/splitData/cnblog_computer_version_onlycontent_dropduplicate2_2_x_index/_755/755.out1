选自 Analytics Vidhya 机器 之心 编译 参与 路雪 李亚洲 黄 
小天 近日 Faizan Shaikh 在 Analytics Vidhya 发表 了 一篇 
题为 10 Advanced Deep Learning Architectures Data Scientists Should Know 
的 文章 总结 了 计算机 视觉 领域 已经 成效 卓著 
的 10 个 深度 学习 架构 并 附上 了 每篇 
论文 的 地址 链 接和 代码 实现 机器 之心 对 
该文 进行 了 编译 原文 链接 请见 文末 时刻 跟上 
深度 学习 领域 的 最新 进展 变 的 越来越 难 
几乎/d 每一天/i 都有/nr 创新/v 或/c 新/a 应用/v 但是 大多数 进展 
隐藏 在 大量 发表 的 ArXiv / Springer 研究 论文 
中 为了 时刻 了解 最新 动态 我们 创建 了 一个 
阅读 小组 在 Analytics Vidhya 内部 分享 学习 成果 我 
想 和 大家 分享 的 是 一项 关于 研究 社区 
开 发出 的 高级 架构 的 调查 本文 包括 深度 
学习 领域 的 最新 进展 keras 库 中的 代码 实现 
以及 论文 链接 为 保证 文章 简明 我 只 总结 
了 计算机 视觉 领域 的 成功 架构 什么 是 高级 
架构 相比 于 单一 的 传统 机器学习 算法 深度 学习 
算法 由 多样化 的 模型 组成 这 是 由于 神经 
网络 在 构建 一个 完整 的 端 到 端的 模型 
时所/nr 提供 的 灵活性 神经网络 有时 可 比作 乐高 块 
借助 想象力 你 几乎 可以 用 它 建构 从 简单 
到 复杂 的 任何 结构 我们 可以 把 高级 架构 
定义 为 一个 具有 良好 记录 的 成功 模型 这 
主要 见于 挑战赛 中 比如 ImageNet 其中 你 的 任务 
是 借助 给定 的 数据 解决 图像 识别 等 问题 
正如 下文 所 描述 的 每一个 架构 其中 每 一个 
都与 常见 的 模型 有 细微 不同 在 解决 问题 
时这/nr 成了 一种 优势 这些 架构 同样 属于 「 深度 
」 模型 的 范畴 因此 有 可能 比 浅层 模型 
表现 更好 计算机 视觉 任务 的 类型 本文 主要 聚焦 
于 计算机 视觉 因此 很 自然 地 描述 了 计算机 
视觉 任务 的 分类 顾名思义 计算机 视觉 即 通过 创建 
人工 模型 来 模拟 本 由 人类 执行 的 视觉 
任务 其 本质 是 人类 的 感知 与 观察 是 
一个 过程 它 可在 人工 系统 中 被 理解 和 
实现 计算机 视觉 任务 的 主要 类型 如下 物体 识别 
／ 分类 在 物体 识别 中 给出 一张 原始 图像 
你 的 任务 是 识别 出 该 图像 属于 哪个 
类别 分类 + 定位 如果 图像 中 只有 一个 物体 
你 的 任务 是 找到 该 物体 在 图像 中 
的 位置 一个 更 专业 的 称谓 是 定位 物体 
检测 在 物体 检测 中 你 的 任务 是 找到 
图像 中 多个 物体 的 各自 位置 这些 物体 可能 
属于 同一 类别 或者 各自 不同 图像 分割 图像 分割 
是 一个 稍微 复杂 的 任务 其 目标 是 将 
每一个 像素 映射 到 正确 的 分类 深度 学习 架构 
清单 现在 我们 明白 了 什么 是 高级 架构 并 
探讨 了 计算机 视觉 的 任务 分类 现在 让 我们 
列举 并 描述 一下 最 重要 的 深度 学习 架构 
吧 1 . AlexNetAlexNet 是 首个 深度 架构 它 由 
深度 学习 先驱 Geoffrey Hinton 及其 同僚 共同 引入 AlexNet 
是 一个 简单 却 功能 强大 的 网络 架构 为 
深度 学习 的 开创性 研究 铺平 了 道路 下图 是 
论文 作者 提出 架构 的 示图 如图所示 分解 后的/nr AlexNet 
像 是 一个 简单 的 架构 卷积/n 层/q 和池化/nr 层层/n 
叠加/v 最上层 是 全 连接 层 这 是 一个 非常 
简单 的 架构 其 早在 80 年代 就 已被 概念化 
但是 该 模型 的 突出 特征 是 其 执行 任务 
的 规模 与 使用 GPU 进行 训练 20 世纪 80 
年代 训练 神经 网络 使用 的 是 CPU 而 AlexNet 
借助 GPU 将 训练 提速 了 10x 论文 ImageNet Classification 
with Deep Convolutional Neural Networks 链接 https / / papers 
. nips . cc / paper / 4824 imagenet classification 
with deep convolutional neural networks . pdf 代码 实现 https 
/ / gist . github . com / JBed / 
c 2 f b 3 c e 8 e d 
2 9 9 f 1 9 7 e f f 
2 . VGG NetVGG 网络 由 牛津 可视化 图形 组 
Visual Graphics Group 开发 因此 其 名称 为 VGG 该 
网络 的 特点 是 金字塔 形 与 图像 最近 的 
底层 比 较宽 而 顶层 很深 如上 图 所示 VGG 
包含 池化层/nr 之后 的 卷积 层 池化层/nr 负责 使 层 
变窄 他们 在 论文 中 提出 多个 此 类网络 不同之处 
在于 架构 深度 的 变化 VGG 的 优势 适合 在 
特定 任务 上 进行 基准测试 VGG 的 预 训练 网络 
可 在 互联网 上 免费 获取 因此 被 广泛 用于 
各种 应用 另一方面 它 的 主要 缺陷 在于 如果 从头 
训练 则 过程 缓慢 即使 在 性能 很好 的 GPU 
上 也 需要 一周 多 的 时间 才能 完成 训练 
论文 Very Deep Convolutional Networks for Large Scale Image Recognition 
链接 https / / arxiv . org / abs / 
1409.1556 代码 实现 https / / github . com / 
fchollet / keras / blob / master / keras / 
applications / vgg16 . py3 . G o o g 
l e N e t G o o g l 
e N e t 或 Inception 网络 是 谷歌 研究者 
设计 的 一种 架构 GoogleNet 是 ImageNet 2014 的 冠军 
是 当时 最 强大 的 模型 该 架构 中 随着 
深度 增加 它 包含 22 层 而 VGG 只有 19 
层 研究者 还 开发 了 一种 叫作 「 Inception 模块 
」 的 新型 方法 如上 图 所示 它 与 我们 
之前 看到 的 序列 架构 发生 了 很大 改变 单个 
层 中 出现 了 多种 「 特征 抽取 器 feature 
extractor 」 这 间接 地 改善 了 该 网络 的 
性能 因为 该 网络 在 训练 过程 中 有 多个 
选项 可以 选择 来 解决 该 任务 它 可以 选择 
与 输入 进行 卷积 也 可以 直接 将其 池化/nr 最终 
架构 包括 堆叠 在 一起 的 多个 inception 模块 GoogleNet 
的 训练 过程 也 有 稍许 不同 即 最上层 有 
自己 的 输出 层 这一 细微差别 帮助 模型 更快 地 
进行 卷积 因为 模型 内存 在 联合 训练 和层/nr 本身 
的 并行 训练 GoogleNet 的 优势 在于 GoogleNet 训练 速度 
比 VGG 快 预 训练 GoogleNet 的 规模 比 VGG 
小 VGG 模型 大于 500 MB 而 GoogleNet 的 大小 
只有 96MB GoogleNet 本身 没有 短期 劣势 但是 该 架构 
的 进一步 改变 使 模型 性能 更佳 其中 一个 变化 
是 Xception 网络 它 增加 了 inception 模块 的 发散 
极限 我们 可以 从 上图 中 看到 GoogleNet 中有 4 
个 inception 模块 现在 从 理论上 讲 该 架构 是 
无限 的 因此 又叫 极限 inception 论文 Rethinking the Inception 
Architecture for Computer Vision 链接 https / / arxiv . 
org / abs / 1512.00567 代码 实现 https / / 
github . com / fchollet / keras / blob / 
master / keras / applications / inception _ v3 . 
py4 . ResNetResNet 是 一个 妖怪 般的 架构 让 我们 
看到 了 深度 学习 架构 能够 有多深 残差 网络 ResNet 
包含 多个 后续 残差 模块 是 建立 ResNet 架构 的 
基础 下图 是 残差 模块 的 表示 图 简言之 一个 
残差 模块 有 两个 选择 完成 输入端 的 一系列 函数 
或者 跳过 此 步骤 类似于 GoogleNet 这些 残差 模块 一个 
接 一个 地 堆叠 组成 了 完整 的 端 到 
端网络 ResNet 引入 的 新 技术 有 使用 标准 的 
SGD 而非 适应性 学习 技术 它 联通 一个 合理 的 
初始化 函数 保持 训练 的 完整性 做到 的 这 一点 
输入 预处理 的 变化 输入 首先 被 区 分到 图像 
块 中 然后 输送 到 网络 中 ResNet 主要 的 
优势 是 数百 甚至 数千 的 残差 层 都能 被 
用于 创造 一个 新 网络 然后 训练 这 不同 于 
平常 的 序列 网络 增加 层 数量 时 表现 会 
下降 论文 Deep Residual Learning for Image Recognition 链接 https 
/ / arxiv . org / abs / 1512.03385 代码 
实现 https / / github . com / fchollet / 
keras / blob / master / keras / applications / 
resnet50 . py5 . ResNeXtResNeXt 据说 是 解决 目标 识别 
问题 的 最 先进 技术 它 建立 在 inception 和 
resnet 的 概念 上 并 带来 改进 的 新 架构 
下图 是 对 ResNeXt 模块 中的 残差 模块 的 总结 
图 1 . 左 ResNet 块 右 基数 = 32 
的 ResNeXt 块 复杂度 大致相同 层 显示 为 # in 
channels filter size # out channels 论文 Aggregated Residual Transformations 
for Deep Neural Networks 链接 https / / arxiv . 
org / pdf / 1611.05431 . pdf 代码 实现 https 
/ / github . com / titu1994 / Keras ResNeXt6 
. RCNN 基于 区域 的 CNN 基于 区域 的 CNN 
架构 据说 是 所有 深度 学习 架构 中 对 目标 
检测 问题 最 有 影响力 的 架构 为了 解决 检测 
问题 RCNN 尝试 在 图像 中 所有 物体 上 画出 
边界 框 然后 识别 图像 中 的 物体 工作 原理 
如下 RCNN 结构 如下 论文 Faster R CNN Towards Real 
Time Object Detection with Region Proposal Networks 链接 https / 
/ arxiv . org / abs / 1506.01497 代码 实现 
https / / github . com / yhenon / keras 
frcnn7 . YOLO You Only Look once YOLO 是 当前 
深度 学习 领域 解决 图像 检测 问题 最 先进 的 
实时系统 如下 图 所示 YOLO 首先 将 图像 划分为 规定 
的 边界 框 然后 对 所有 边界 框 并行 运行 
识别 算法 来 确定 物体 所属 的 类别 确定 类别 
之后 yolo 继续 智能 地 合并 这些 边界 框 在 
物体 周围 形成 最优 边界 框 这些 步骤 全部 并行 
进行 因此 YOLO 能够 实现 实时 运行 并且 每秒 处理 
多达 40 张 图像 尽管 相比 于 RCNN 它 的 
表现 有所 降低 但在 日常 实时 的 问题 中 它 
还是 有 优势 的 下图 是 YOLO 架构 的 示图 
论文 You Only Look Once Unified Real Time Object Detection 
链接 https / / pjreddie . com / media / 
files / papers / yolo . pdf 代码 实现 https 
/ / github . com / allanzelener / YAD2K8 . 
q u e e z e N e t q 
u e e N e t 架构 是 在 移动 
平台 这样 的 低 宽带 场景 中 极其 强大 的 
一种 架构 这种 架构 只 占用 4.9 MB 的 空间 
而 Inception 架构 大小 为 100MB 这种 巨大 的 差距 
由 一种 名为 Fire Module 的 特殊 结构 引起 下图 
是 Fire Module 的 表示 图 SqueezeNet 的 完整 架构 
如下 论文 SQUEEZENET ALEXNET LEVEL ACCURACY WITH 50X FEWER PARAMETERS 
AND 链接 https / / arxiv . org / abs 
/ 1602.07360 代码 实现 https / / github . com 
/ rcmalli / keras squeezenet9 . SegNetSegNet 是 一个 用于 
解决 图像 分割 问题 的 深度 学习 架构 它 包含 
处理 层 编码器 序列 之后 是 对应 的 解码器 序列 
用于 分类 像素 下图 是 SegNet 解析 图 SegNet 的/uj 
一个/m 主要/b 特征/n 是/v 在/p 编码器/n 网络/n 的/uj 池化/nr 指标/n 
与/p 解码器/n 网络/n 的/uj 池化/nr 指标/n 连/nr 接时/c 分割 图像 
保留 高频 细节 简言之 直接 进行 信息 迁移 而非 卷积 
它们 在 处理 图像 分割 问题 时 SgeNet 是 最好 
的 模型 之一 论文 SegNet A Deep Convolutional Encoder Decoder 
Architecture for Image Segmentation 链接 https / / arxiv . 
org / abs / 1511.00561 代码 实现 https / / 
github . com / imlab uiip / keras segnet10 . 
GANGAN 是 神经 网络 架构 中 完全 不同 的 类别 
GAN 中 一种 神经网络 用于 生成 全新 的 训练 集中 
未曾 有过 的 图像 但却 足够 真实 例如 以下 是 
GAN 工作 原理 的 解析 图 论文 Generative Adversarial Networks 
链接 https / / arxiv . org / abs / 
1406.2661 代码 实现 https / / github . com / 
bstriner / keras adversarial 原文 地址 https / / www 
. analyticsvidhya . com / blog / 2017 / 08/10 
advanced deep learning architectures data scientists / 选自 Analytics Vidhya 机器 之心 编译 参与 路雪 李亚洲 黄 
小天 近日 Faizan Shaikh 在 Analytics Vidhya 发表 了 一篇 
题为 10 Advanced Deep Learning Architectures Data Scientists Should Know 
的 文章 总结 了 计算机 视觉 领域 已经 成效 卓著 
的 10 个 深度 学习 架构 并 附上 了 每篇 
论文 的 地址 链 接和 代码 实现 机器 之心 对 
该文 进行 了 编译 原文 链接 请见 文末 时刻 跟上 
深度 学习 领域 的 最新 进展 变 的 越来越 难 
几乎/d 每一天/i 都有/nr 创新/v 或/c 新/a 应用/v 但是 大多数 进展 
隐藏 在 大量 发表 的 ArXiv / Springer 研究 论文 
中 为了 时刻 了解 最新 动态 我们 创建 了 一个 
阅读 小组 在 Analytics Vidhya 内部 分享 学习 成果 我 
想 和 大家 分享 的 是 一项 关于 研究 社区 
开 发出 的 高级 架构 的 调查 本文 包括 深度 
学习 领域 的 最新 进展 keras 库 中的 代码 实现 
以及 论文 链接 为 保证 文章 简明 我 只 总结 
了 计算机 视觉 领域 的 成功 架构 什么 是 高级 
架构 相比 于 单一 的 传统 机器学习 算法 深度 学习 
算法 由 多样化 的 模型 组成 这 是 由于 神经 
网络 在 构建 一个 完整 的 端 到 端的 模型 
时所/nr 提供 的 灵活性 神经网络 有时 可 比作 乐高 块 
借助 想象力 你 几乎 可以 用 它 建构 从 简单 
到 复杂 的 任何 结构 我们 可以 把 高级 架构 
定义 为 一个 具有 良好 记录 的 成功 模型 这 
主要 见于 挑战赛 中 比如 ImageNet 其中 你 的 任务 
是 借助 给定 的 数据 解决 图像 识别 等 问题 
正如 下文 所 描述 的 每一个 架构 其中 每 一个 
都与 常见 的 模型 有 细微 不同 在 解决 问题 
时这/nr 成了 一种 优势 这些 架构 同样 属于 「 深度 
」 模型 的 范畴 因此 有 可能 比 浅层 模型 
表现 更好 计算机 视觉 任务 的 类型 本文 主要 聚焦 
于 计算机 视觉 因此 很 自然 地 描述 了 计算机 
视觉 任务 的 分类 顾名思义 计算机 视觉 即 通过 创建 
人工 模型 来 模拟 本 由 人类 执行 的 视觉 
任务 其 本质 是 人类 的 感知 与 观察 是 
一个 过程 它 可在 人工 系统 中 被 理解 和 
实现 计算机 视觉 任务 的 主要 类型 如下 物体 识别 
／ 分类 在 物体 识别 中 给出 一张 原始 图像 
你 的 任务 是 识别 出 该 图像 属于 哪个 
类别 分类 + 定位 如果 图像 中 只有 一个 物体 
你 的 任务 是 找到 该 物体 在 图像 中 
的 位置 一个 更 专业 的 称谓 是 定位 物体 
检测 在 物体 检测 中 你 的 任务 是 找到 
图像 中 多个 物体 的 各自 位置 这些 物体 可能 
属于 同一 类别 或者 各自 不同 图像 分割 图像 分割 
是 一个 稍微 复杂 的 任务 其 目标 是 将 
每一个 像素 映射 到 正确 的 分类 深度 学习 架构 
清单 现在 我们 明白 了 什么 是 高级 架构 并 
探讨 了 计算机 视觉 的 任务 分类 现在 让 我们 
列举 并 描述 一下 最 重要 的 深度 学习 架构 
吧 1 . AlexNetAlexNet 是 首个 深度 架构 它 由 
深度 学习 先驱 Geoffrey Hinton 及其 同僚 共同 引入 AlexNet 
是 一个 简单 却 功能 强大 的 网络 架构 为 
深度 学习 的 开创性 研究 铺平 了 道路 下图 是 
论文 作者 提出 架构 的 示图 如图所示 分解 后的/nr AlexNet 
像 是 一个 简单 的 架构 卷积/n 层/q 和池化/nr 层层/n 
叠加/v 最上层 是 全 连接 层 这 是 一个 非常 
简单 的 架构 其 早在 80 年代 就 已被 概念化 
但是 该 模型 的 突出 特征 是 其 执行 任务 
的 规模 与 使用 GPU 进行 训练 20 世纪 80 
年代 训练 神经 网络 使用 的 是 CPU 而 AlexNet 
借助 GPU 将 训练 提速 了 10x 论文 ImageNet Classification 
with Deep Convolutional Neural Networks 链接 https / / papers 
. nips . cc / paper / 4824 imagenet classification 
with deep convolutional neural networks . pdf 代码 实现 https 
/ / gist . github . com / JBed / 
c 2 f b 3 c e 8 e d 
2 9 9 f 1 9 7 e f f 
2 . VGG NetVGG 网络 由 牛津 可视化 图形 组 
Visual Graphics Group 开发 因此 其 名称 为 VGG 该 
网络 的 特点 是 金字塔 形 与 图像 最近 的 
底层 比 较宽 而 顶层 很深 如上 图 所示 VGG 
包含 池化层/nr 之后 的 卷积 层 池化层/nr 负责 使 层 
变窄 他们 在 论文 中 提出 多个 此 类网络 不同之处 
在于 架构 深度 的 变化 VGG 的 优势 适合 在 
特定 任务 上 进行 基准测试 VGG 的 预 训练 网络 
可 在 互联网 上 免费 获取 因此 被 广泛 用于 
各种 应用 另一方面 它 的 主要 缺陷 在于 如果 从头 
训练 则 过程 缓慢 即使 在 性能 很好 的 GPU 
上 也 需要 一周 多 的 时间 才能 完成 训练 
论文 Very Deep Convolutional Networks for Large Scale Image Recognition 
链接 https / / arxiv . org / abs / 
1409.1556 代码 实现 https / / github . com / 
fchollet / keras / blob / master / keras / 
applications / vgg16 . py3 . G o o g 
l e N e t G o o g l 
e N e t 或 Inception 网络 是 谷歌 研究者 
设计 的 一种 架构 GoogleNet 是 ImageNet 2014 的 冠军 
是 当时 最 强大 的 模型 该 架构 中 随着 
深度 增加 它 包含 22 层 而 VGG 只有 19 
层 研究者 还 开发 了 一种 叫作 「 Inception 模块 
」 的 新型 方法 如上 图 所示 它 与 我们 
之前 看到 的 序列 架构 发生 了 很大 改变 单个 
层 中 出现 了 多种 「 特征 抽取 器 feature 
extractor 」 这 间接 地 改善 了 该 网络 的 
性能 因为 该 网络 在 训练 过程 中 有 多个 
选项 可以 选择 来 解决 该 任务 它 可以 选择 
与 输入 进行 卷积 也 可以 直接 将其 池化/nr 最终 
架构 包括 堆叠 在 一起 的 多个 inception 模块 GoogleNet 
的 训练 过程 也 有 稍许 不同 即 最上层 有 
自己 的 输出 层 这一 细微差别 帮助 模型 更快 地 
进行 卷积 因为 模型 内存 在 联合 训练 和层/nr 本身 
的 并行 训练 GoogleNet 的 优势 在于 GoogleNet 训练 速度 
比 VGG 快 预 训练 GoogleNet 的 规模 比 VGG 
小 VGG 模型 大于 500 MB 而 GoogleNet 的 大小 
只有 96MB GoogleNet 本身 没有 短期 劣势 但是 该 架构 
的 进一步 改变 使 模型 性能 更佳 其中 一个 变化 
是 Xception 网络 它 增加 了 inception 模块 的 发散 
极限 我们 可以 从 上图 中 看到 GoogleNet 中有 4 
个 inception 模块 现在 从 理论上 讲 该 架构 是 
无限 的 因此 又叫 极限 inception 论文 Rethinking the Inception 
Architecture for Computer Vision 链接 https / / arxiv . 
org / abs / 1512.00567 代码 实现 https / / 
github . com / fchollet / keras / blob / 
master / keras / applications / inception _ v3 . 
py4 . ResNetResNet 是 一个 妖怪 般的 架构 让 我们 
看到 了 深度 学习 架构 能够 有多深 残差 网络 ResNet 
包含 多个 后续 残差 模块 是 建立 ResNet 架构 的 
基础 下图 是 残差 模块 的 表示 图 简言之 一个 
残差 模块 有 两个 选择 完成 输入端 的 一系列 函数 
或者 跳过 此 步骤 类似于 GoogleNet 这些 残差 模块 一个 
接 一个 地 堆叠 组成 了 完整 的 端 到 
端网络 ResNet 引入 的 新 技术 有 使用 标准 的 
SGD 而非 适应性 学习 技术 它 联通 一个 合理 的 
初始化 函数 保持 训练 的 完整性 做到 的 这 一点 
输入 预处理 的 变化 输入 首先 被 区 分到 图像 
块 中 然后 输送 到 网络 中 ResNet 主要 的 
优势 是 数百 甚至 数千 的 残差 层 都能 被 
用于 创造 一个 新 网络 然后 训练 这 不同 于 
平常 的 序列 网络 增加 层 数量 时 表现 会 
下降 论文 Deep Residual Learning for Image Recognition 链接 https 
/ / arxiv . org / abs / 1512.03385 代码 
实现 https / / github . com / fchollet / 
keras / blob / master / keras / applications / 
resnet50 . py5 . ResNeXtResNeXt 据说 是 解决 目标 识别 
问题 的 最 先进 技术 它 建立 在 inception 和 
resnet 的 概念 上 并 带来 改进 的 新 架构 
下图 是 对 ResNeXt 模块 中的 残差 模块 的 总结 
图 1 . 左 ResNet 块 右 基数 = 32 
的 ResNeXt 块 复杂度 大致相同 层 显示 为 # in 
channels filter size # out channels 论文 Aggregated Residual Transformations 
for Deep Neural Networks 链接 https / / arxiv . 
org / pdf / 1611.05431 . pdf 代码 实现 https 
/ / github . com / titu1994 / Keras ResNeXt6 
. RCNN 基于 区域 的 CNN 基于 区域 的 CNN 
架构 据说 是 所有 深度 学习 架构 中 对 目标 
检测 问题 最 有 影响力 的 架构 为了 解决 检测 
问题 RCNN 尝试 在 图像 中 所有 物体 上 画出 
边界 框 然后 识别 图像 中 的 物体 工作 原理 
如下 RCNN 结构 如下 论文 Faster R CNN Towards Real 
Time Object Detection with Region Proposal Networks 链接 https / 
/ arxiv . org / abs / 1506.01497 代码 实现 
https / / github . com / yhenon / keras 
frcnn7 . YOLO You Only Look once YOLO 是 当前 
深度 学习 领域 解决 图像 检测 问题 最 先进 的 
实时系统 如下 图 所示 YOLO 首先 将 图像 划分为 规定 
的 边界 框 然后 对 所有 边界 框 并行 运行 
识别 算法 来 确定 物体 所属 的 类别 确定 类别 
之后 yolo 继续 智能 地 合并 这些 边界 框 在 
物体 周围 形成 最优 边界 框 这些 步骤 全部 并行 
进行 因此 YOLO 能够 实现 实时 运行 并且 每秒 处理 
多达 40 张 图像 尽管 相比 于 RCNN 它 的 
表现 有所 降低 但在 日常 实时 的 问题 中 它 
还是 有 优势 的 下图 是 YOLO 架构 的 示图 
论文 You Only Look Once Unified Real Time Object Detection 
链接 https / / pjreddie . com / media / 
files / papers / yolo . pdf 代码 实现 https 
/ / github . com / allanzelener / YAD2K8 . 
q u e e z e N e t q 
u e e N e t 架构 是 在 移动 
平台 这样 的 低 宽带 场景 中 极其 强大 的 
一种 架构 这种 架构 只 占用 4.9 MB 的 空间 
而 Inception 架构 大小 为 100MB 这种 巨大 的 差距 
由 一种 名为 Fire Module 的 特殊 结构 引起 下图 
是 Fire Module 的 表示 图 SqueezeNet 的 完整 架构 
如下 论文 SQUEEZENET ALEXNET LEVEL ACCURACY WITH 50X FEWER PARAMETERS 
AND 链接 https / / arxiv . org / abs 
/ 1602.07360 代码 实现 https / / github . com 
/ rcmalli / keras squeezenet9 . SegNetSegNet 是 一个 用于 
解决 图像 分割 问题 的 深度 学习 架构 它 包含 
处理 层 编码器 序列 之后 是 对应 的 解码器 序列 
用于 分类 像素 下图 是 SegNet 解析 图 SegNet 的/uj 
一个/m 主要/b 特征/n 是/v 在/p 编码器/n 网络/n 的/uj 池化/nr 指标/n 
与/p 解码器/n 网络/n 的/uj 池化/nr 指标/n 连/nr 接时/c 分割 图像 
保留 高频 细节 简言之 直接 进行 信息 迁移 而非 卷积 
它们 在 处理 图像 分割 问题 时 SgeNet 是 最好 
的 模型 之一 论文 SegNet A Deep Convolutional Encoder Decoder 
Architecture for Image Segmentation 链接 https / / arxiv . 
org / abs / 1511.00561 代码 实现 https / / 
github . com / imlab uiip / keras segnet10 . 
GANGAN 是 神经 网络 架构 中 完全 不同 的 类别 
GAN 中 一种 神经网络 用于 生成 全新 的 训练 集中 
未曾 有过 的 图像 但却 足够 真实 例如 以下 是 
GAN 工作 原理 的 解析 图 论文 Generative Adversarial Networks 
链接 https / / arxiv . org / abs / 
1406.2661 代码 实现 https / / github . com / 
bstriner / keras adversarial 原文 地址 https / / www 
. analyticsvidhya . com / blog / 2017 / 08/10 
advanced deep learning architectures data scientists / 选自 Analytics Vidhya 机器 之心 编译 参与 路雪 李亚洲 黄 
小天 近日 Faizan Shaikh 在 Analytics Vidhya 发表 了 一篇 
题为 10 Advanced Deep Learning Architectures Data Scientists Should Know 
的 文章 总结 了 计算机 视觉 领域 已经 成效 卓著 
的 10 个 深度 学习 架构 并 附上 了 每篇 
论文 的 地址 链 接和 代码 实现 机器 之心 对 
该文 进行 了 编译 原文 链接 请见 文末 时刻 跟上 
深度 学习 领域 的 最新 进展 变 的 越来越 难 
几乎/d 每一天/i 都有/nr 创新/v 或/c 新/a 应用/v 但是 大多数 进展 
隐藏 在 大量 发表 的 ArXiv / Springer 研究 论文 
中 为了 时刻 了解 最新 动态 我们 创建 了 一个 
阅读 小组 在 Analytics Vidhya 内部 分享 学习 成果 我 
想 和 大家 分享 的 是 一项 关于 研究 社区 
开 发出 的 高级 架构 的 调查 本文 包括 深度 
学习 领域 的 最新 进展 keras 库 中的 代码 实现 
以及 论文 链接 为 保证 文章 简明 我 只 总结 
了 计算机 视觉 领域 的 成功 架构 什么 是 高级 
架构 相比 于 单一 的 传统 机器学习 算法 深度 学习 
算法 由 多样化 的 模型 组成 这 是 由于 神经 
网络 在 构建 一个 完整 的 端 到 端的 模型 
时所/nr 提供 的 灵活性 神经网络 有时 可 比作 乐高 块 
借助 想象力 你 几乎 可以 用 它 建构 从 简单 
到 复杂 的 任何 结构 我们 可以 把 高级 架构 
定义 为 一个 具有 良好 记录 的 成功 模型 这 
主要 见于 挑战赛 中 比如 ImageNet 其中 你 的 任务 
是 借助 给定 的 数据 解决 图像 识别 等 问题 
正如 下文 所 描述 的 每一个 架构 其中 每 一个 
都与 常见 的 模型 有 细微 不同 在 解决 问题 
时这/nr 成了 一种 优势 这些 架构 同样 属于 「 深度 
」 模型 的 范畴 因此 有 可能 比 浅层 模型 
表现 更好 计算机 视觉 任务 的 类型 本文 主要 聚焦 
于 计算机 视觉 因此 很 自然 地 描述 了 计算机 
视觉 任务 的 分类 顾名思义 计算机 视觉 即 通过 创建 
人工 模型 来 模拟 本 由 人类 执行 的 视觉 
任务 其 本质 是 人类 的 感知 与 观察 是 
一个 过程 它 可在 人工 系统 中 被 理解 和 
实现 计算机 视觉 任务 的 主要 类型 如下 物体 识别 
／ 分类 在 物体 识别 中 给出 一张 原始 图像 
你 的 任务 是 识别 出 该 图像 属于 哪个 
类别 分类 + 定位 如果 图像 中 只有 一个 物体 
你 的 任务 是 找到 该 物体 在 图像 中 
的 位置 一个 更 专业 的 称谓 是 定位 物体 
检测 在 物体 检测 中 你 的 任务 是 找到 
图像 中 多个 物体 的 各自 位置 这些 物体 可能 
属于 同一 类别 或者 各自 不同 图像 分割 图像 分割 
是 一个 稍微 复杂 的 任务 其 目标 是 将 
每一个 像素 映射 到 正确 的 分类 深度 学习 架构 
清单 现在 我们 明白 了 什么 是 高级 架构 并 
探讨 了 计算机 视觉 的 任务 分类 现在 让 我们 
列举 并 描述 一下 最 重要 的 深度 学习 架构 
吧 1 . AlexNetAlexNet 是 首个 深度 架构 它 由 
深度 学习 先驱 Geoffrey Hinton 及其 同僚 共同 引入 AlexNet 
是 一个 简单 却 功能 强大 的 网络 架构 为 
深度 学习 的 开创性 研究 铺平 了 道路 下图 是 
论文 作者 提出 架构 的 示图 如图所示 分解 后的/nr AlexNet 
像 是 一个 简单 的 架构 卷积/n 层/q 和池化/nr 层层/n 
叠加/v 最上层 是 全 连接 层 这 是 一个 非常 
简单 的 架构 其 早在 80 年代 就 已被 概念化 
但是 该 模型 的 突出 特征 是 其 执行 任务 
的 规模 与 使用 GPU 进行 训练 20 世纪 80 
年代 训练 神经 网络 使用 的 是 CPU 而 AlexNet 
借助 GPU 将 训练 提速 了 10x 论文 ImageNet Classification 
with Deep Convolutional Neural Networks 链接 https / / papers 
. nips . cc / paper / 4824 imagenet classification 
with deep convolutional neural networks . pdf 代码 实现 https 
/ / gist . github . com / JBed / 
c 2 f b 3 c e 8 e d 
2 9 9 f 1 9 7 e f f 
2 . VGG NetVGG 网络 由 牛津 可视化 图形 组 
Visual Graphics Group 开发 因此 其 名称 为 VGG 该 
网络 的 特点 是 金字塔 形 与 图像 最近 的 
底层 比 较宽 而 顶层 很深 如上 图 所示 VGG 
包含 池化层/nr 之后 的 卷积 层 池化层/nr 负责 使 层 
变窄 他们 在 论文 中 提出 多个 此 类网络 不同之处 
在于 架构 深度 的 变化 VGG 的 优势 适合 在 
特定 任务 上 进行 基准测试 VGG 的 预 训练 网络 
可 在 互联网 上 免费 获取 因此 被 广泛 用于 
各种 应用 另一方面 它 的 主要 缺陷 在于 如果 从头 
训练 则 过程 缓慢 即使 在 性能 很好 的 GPU 
上 也 需要 一周 多 的 时间 才能 完成 训练 
论文 Very Deep Convolutional Networks for Large Scale Image Recognition 
链接 https / / arxiv . org / abs / 
1409.1556 代码 实现 https / / github . com / 
fchollet / keras / blob / master / keras / 
applications / vgg16 . py3 . G o o g 
l e N e t G o o g l 
e N e t 或 Inception 网络 是 谷歌 研究者 
设计 的 一种 架构 GoogleNet 是 ImageNet 2014 的 冠军 
是 当时 最 强大 的 模型 该 架构 中 随着 
深度 增加 它 包含 22 层 而 VGG 只有 19 
层 研究者 还 开发 了 一种 叫作 「 Inception 模块 
」 的 新型 方法 如上 图 所示 它 与 我们 
之前 看到 的 序列 架构 发生 了 很大 改变 单个 
层 中 出现 了 多种 「 特征 抽取 器 feature 
extractor 」 这 间接 地 改善 了 该 网络 的 
性能 因为 该 网络 在 训练 过程 中 有 多个 
选项 可以 选择 来 解决 该 任务 它 可以 选择 
与 输入 进行 卷积 也 可以 直接 将其 池化/nr 最终 
架构 包括 堆叠 在 一起 的 多个 inception 模块 GoogleNet 
的 训练 过程 也 有 稍许 不同 即 最上层 有 
自己 的 输出 层 这一 细微差别 帮助 模型 更快 地 
进行 卷积 因为 模型 内存 在 联合 训练 和层/nr 本身 
的 并行 训练 GoogleNet 的 优势 在于 GoogleNet 训练 速度 
比 VGG 快 预 训练 GoogleNet 的 规模 比 VGG 
小 VGG 模型 大于 500 MB 而 GoogleNet 的 大小 
只有 96MB GoogleNet 本身 没有 短期 劣势 但是 该 架构 
的 进一步 改变 使 模型 性能 更佳 其中 一个 变化 
是 Xception 网络 它 增加 了 inception 模块 的 发散 
极限 我们 可以 从 上图 中 看到 GoogleNet 中有 4 
个 inception 模块 现在 从 理论上 讲 该 架构 是 
无限 的 因此 又叫 极限 inception 论文 Rethinking the Inception 
Architecture for Computer Vision 链接 https / / arxiv . 
org / abs / 1512.00567 代码 实现 https / / 
github . com / fchollet / keras / blob / 
master / keras / applications / inception _ v3 . 
py4 . ResNetResNet 是 一个 妖怪 般的 架构 让 我们 
看到 了 深度 学习 架构 能够 有多深 残差 网络 ResNet 
包含 多个 后续 残差 模块 是 建立 ResNet 架构 的 
基础 下图 是 残差 模块 的 表示 图 简言之 一个 
残差 模块 有 两个 选择 完成 输入端 的 一系列 函数 
或者 跳过 此 步骤 类似于 GoogleNet 这些 残差 模块 一个 
接 一个 地 堆叠 组成 了 完整 的 端 到 
端网络 ResNet 引入 的 新 技术 有 使用 标准 的 
SGD 而非 适应性 学习 技术 它 联通 一个 合理 的 
初始化 函数 保持 训练 的 完整性 做到 的 这 一点 
输入 预处理 的 变化 输入 首先 被 区 分到 图像 
块 中 然后 输送 到 网络 中 ResNet 主要 的 
优势 是 数百 甚至 数千 的 残差 层 都能 被 
用于 创造 一个 新 网络 然后 训练 这 不同 于 
平常 的 序列 网络 增加 层 数量 时 表现 会 
下降 论文 Deep Residual Learning for Image Recognition 链接 https 
/ / arxiv . org / abs / 1512.03385 代码 
实现 https / / github . com / fchollet / 
keras / blob / master / keras / applications / 
resnet50 . py5 . ResNeXtResNeXt 据说 是 解决 目标 识别 
问题 的 最 先进 技术 它 建立 在 inception 和 
resnet 的 概念 上 并 带来 改进 的 新 架构 
下图 是 对 ResNeXt 模块 中的 残差 模块 的 总结 
图 1 . 左 ResNet 块 右 基数 = 32 
的 ResNeXt 块 复杂度 大致相同 层 显示 为 # in 
channels filter size # out channels 论文 Aggregated Residual Transformations 
for Deep Neural Networks 链接 https / / arxiv . 
org / pdf / 1611.05431 . pdf 代码 实现 https 
/ / github . com / titu1994 / Keras ResNeXt6 
. RCNN 基于 区域 的 CNN 基于 区域 的 CNN 
架构 据说 是 所有 深度 学习 架构 中 对 目标 
检测 问题 最 有 影响力 的 架构 为了 解决 检测 
问题 RCNN 尝试 在 图像 中 所有 物体 上 画出 
边界 框 然后 识别 图像 中 的 物体 工作 原理 
如下 RCNN 结构 如下 论文 Faster R CNN Towards Real 
Time Object Detection with Region Proposal Networks 链接 https / 
/ arxiv . org / abs / 1506.01497 代码 实现 
https / / github . com / yhenon / keras 
frcnn7 . YOLO You Only Look once YOLO 是 当前 
深度 学习 领域 解决 图像 检测 问题 最 先进 的 
实时系统 如下 图 所示 YOLO 首先 将 图像 划分为 规定 
的 边界 框 然后 对 所有 边界 框 并行 运行 
识别 算法 来 确定 物体 所属 的 类别 确定 类别 
之后 yolo 继续 智能 地 合并 这些 边界 框 在 
物体 周围 形成 最优 边界 框 这些 步骤 全部 并行 
进行 因此 YOLO 能够 实现 实时 运行 并且 每秒 处理 
多达 40 张 图像 尽管 相比 于 RCNN 它 的 
表现 有所 降低 但在 日常 实时 的 问题 中 它 
还是 有 优势 的 下图 是 YOLO 架构 的 示图 
论文 You Only Look Once Unified Real Time Object Detection 
链接 https / / pjreddie . com / media / 
files / papers / yolo . pdf 代码 实现 https 
/ / github . com / allanzelener / YAD2K8 . 
q u e e z e N e t q 
u e e N e t 架构 是 在 移动 
平台 这样 的 低 宽带 场景 中 极其 强大 的 
一种 架构 这种 架构 只 占用 4.9 MB 的 空间 
而 Inception 架构 大小 为 100MB 这种 巨大 的 差距 
由 一种 名为 Fire Module 的 特殊 结构 引起 下图 
是 Fire Module 的 表示 图 SqueezeNet 的 完整 架构 
如下 论文 SQUEEZENET ALEXNET LEVEL ACCURACY WITH 50X FEWER PARAMETERS 
AND 链接 https / / arxiv . org / abs 
/ 1602.07360 代码 实现 https / / github . com 
/ rcmalli / keras squeezenet9 . SegNetSegNet 是 一个 用于 
解决 图像 分割 问题 的 深度 学习 架构 它 包含 
处理 层 编码器 序列 之后 是 对应 的 解码器 序列 
用于 分类 像素 下图 是 SegNet 解析 图 SegNet 的/uj 
一个/m 主要/b 特征/n 是/v 在/p 编码器/n 网络/n 的/uj 池化/nr 指标/n 
与/p 解码器/n 网络/n 的/uj 池化/nr 指标/n 连/nr 接时/c 分割 图像 
保留 高频 细节 简言之 直接 进行 信息 迁移 而非 卷积 
它们 在 处理 图像 分割 问题 时 SgeNet 是 最好 
的 模型 之一 论文 SegNet A Deep Convolutional Encoder Decoder 
Architecture for Image Segmentation 链接 https / / arxiv . 
org / abs / 1511.00561 代码 实现 https / / 
github . com / imlab uiip / keras segnet10 . 
GANGAN 是 神经 网络 架构 中 完全 不同 的 类别 
GAN 中 一种 神经网络 用于 生成 全新 的 训练 集中 
未曾 有过 的 图像 但却 足够 真实 例如 以下 是 
GAN 工作 原理 的 解析 图 论文 Generative Adversarial Networks 
链接 https / / arxiv . org / abs / 
1406.2661 代码 实现 https / / github . com / 
bstriner / keras adversarial 原文 地址 https / / www 
. analyticsvidhya . com / blog / 2017 / 08/10 
advanced deep learning architectures data scientists / 