本文转载自雷锋网2018 全球人工智能与机器人峰会（CCF-GAIR）在深圳召开，峰会由中国计算机学会（CCF）主办，雷锋网、香港中文大学（深圳）承办，得到了宝安区政府的大力指导，是国内人工智能和机器人学术界、工业界及投资界三大领域的顶级交流盛会，旨在打造国内人工智能领域最具实力的跨界交流合作平台。CCF-GAIR 2018 延续前两届的“顶尖”阵容，提供1个主会场和11个专场（仿生机器人，机器人行业应用，计算机视觉，智能安全，金融科技，智能驾驶，NLP，AI+，AI芯片，IoT，投资人）的丰富平台，意欲给三界参会者从产学研多个维度，呈现出更富前瞻性与落地性相结合的会议内容与现场体验。大会第二天的计算机视觉专场，香港科技大学教授，Altizure 创始人，ICCV 2011主席，IEEE Fellow权龙教授作为开场嘉宾，发表题为“计算机视觉, 识别与三维重建”的精彩演讲，点燃了现场气氛。权龙教授主要从三个方面进行阐述，分别是计算机视觉的基础、计算机视觉的变迁与发展，以及计算机视觉最新的进展。他谈到，当下因为深度学习技术的发展，人工智能变得非常火热，计算机视觉作为人工智能的一个领域，也变得异常火热。不过目前计算机视觉的研究和应用主要集中在“识别”，“识别”只是计算机视觉的一部分。如果要去做一些交互和感知，必须先恢复三维，所以在识别的基础上，下一个层次必须走向“三维重建”。针对这个领域，权龙教授和他的研究团队已经做了诸多的工作并取得了一定的成绩，在 4 月份，他们拿下了两个计算机视觉榜单的全球第一。当然，目前在深度学习推动下的计算机视觉技术还有很多不足和挑战，需要更多业内研究者不断去探索，特别是在卷积神经网络在高维度空间的理论理解与解释。以下是权龙教授的演讲全文，雷锋网做了不改变原意的整理与编辑：感谢大会主办方的邀请，今天我想跟大家分享计算机视觉中的识别和三维重建问题。我今天的演讲分为三部分：首先讲一下计算机视觉的基础，然后介绍它的变迁与发展，最后再谈谈它的最新进展。计算机视觉的源起什么是人工智能和计算机视觉？人工智能的目的是让计算机去看、去听和去读。图像、语音和文字的理解，这三大部分基本构成了我们现在的人工智能。而在人工智能的这些领域中，视觉又是核心。大家知道，视觉占人类所有感官输入的80%，也是最困难的一部分感知。如果说人工智能是一场革命，那么它将发轫于计算机视觉，而非别的领域。2012年是非常重要的一年，我在标题中称之为“a year of no significance”。这一年看似平凡，却发生了很多事情。2012年，在一个叫CVPR的计算机视觉顶级会议上发生了一件看似重要，但也不那么重要的事情。那就是一个叫ImageNet的比赛，它把图像识别准确率从75%提高到了85%，引发了一系列（人工智能）热浪。再把时间回溯到1998年，当年有了卷积神经网络，它是今天所有卷积神经网络的鼻祖模型。它有几个特点，首先它输入的图像比较小，只有32*32pixel；其次它没有GPU，这正是它计算力比较弱的原因。2012年，卷积神经网络复活，我们称之为AlexNet。和上一阶段相比，它的内部结构基本一模一样，变化非常小，但输入的尺寸不一样。1998年的模型，输入尺寸为32*32pixel，且只有一个通道。新的模型输入尺寸已经扩大到了224*224pixel，而且有三个通道。最关键的是里面有了GPU，它当时训练时用了两块GPU。从1998年到2012年，中间经历了10多年，卷积神经网络的架构还是一样的，那么它内部发生了哪些变化？有两点非常重要：一、英伟达研发了GPU，GPU最早是为游戏而不是人工智能诞生的；二、华人学者、斯坦福大学教授李飞飞创建了ImageNet，她把几百万张照片发到网络上并发动群众做了标注。6年后的今天又发生了哪些变化呢？2012年训练AlexNet模型需要使用两块GPU，花费6天时间；今天做同样的事情只需要一块DGX-2，十几分钟就能搞定。再看看学术会议。CVPR以前是一个一般的学术会议，只有几百人参与。今年，我们刚从盐湖城回来，参会群众规模已经达到了6500人，基本实现了10倍增长。我们有幸将于2022年在新奥尔良组织这个会议。相信到时候将有上万人参加，我们需要担忧的是哪里能找到可容纳这么多人的场地。什么是计算机视觉？计算机视觉的本质是对图像进行理解。“理解”这个词没有准确的定义，事实上计算机无法做到“理解”，只能做到认知。计算机视觉的终极目的就是达到认知。我们研究计算机视觉的目的是得到视觉特征，有了视觉特征才能开展一系列的工作。为什么视觉特征如此重要？在语音识别领域，语音的特征已经定义得非常清晰 - 音素。但如果我们拿来一个图像，问它最重要的视觉特征是什么，答案并不明确。大家知道图像包含像素，但像素并不是真正的特征。像素只是一个数字化的载体，将图像进行了数字化的表述。计算机视觉的终极目标就是寻找行之有效的视觉特征。计算机视觉包含两个基本应用 - 识别和重建。它们的英文单词都以“re”做前缀，说明这是一个反向的问题。计算机视觉发展简史我们简单回顾一下计算机视觉的发展历史。上世纪70/80年代，计算机视觉有了最初的发展。那个年代，基本所有的计算机视觉研究都以Marr的primal sketches为理论依据。它的可计算数学模型都是以edges为主的边缘提取。有了edge之后，再把它高层化后的线段元做简单的统计分类或者三维重建。Edge在数学上是很好定义的，我们定义了很多优化准则后，这个研究方向就到头了。90年代到2000年，行业内有一些变化，大家从edge回过头来研究几何问题。几何就是三维重建，一维的edges不适合做计算。几何最本质的元素是点，它是二维的，更内在。这推动了很多研究工作以点为基础展开，对点做描述，也就是feature descriptors。这对推动计算机视觉发展产生了重要作用。从识别方面来看，有了feature descriptors就可以把很多东西变成矢量的无序集合，然后再去做统计。当时最成功的是三维重建，所谓成功也只是把一些点从二维变成三维，没有真正语义上的描述。这是1990-2000年间的发展。2012年开始，我称之为CNN时代。这时候视觉领域开始发生变化，从特征到识别算法基本都被CNN一统。CNN现在已经很强大了，基本所有计算机视觉论文都会提到它。CNN的好处在于，它是端到端的，比较容易实现。给大家讲一个趣闻，90年代计算机视觉如日中天的时候，卷积神经网络还沉浸在痛苦中无人理睬。机器学习、计算机视觉和语音识别领域的人都忽视它。2012年，AlexNet在重要会议上只能参加一些边缘比赛，不能进入主会场。那个年代，如果你的论文中提到CNN，估计会直接被拒；但今天你的论文如果不提CNN，就非常难入围。今天计算机视觉中的识别技术基本是端到端的，从1998年的LeNet到2012年的AlexNet，再到2016年ResNet。目前ResNet已经非常成熟，谷歌给出了开源标准ResNet50，只需要把数据丢进去训练即可。今天，如果你能清晰地定义问题，做好数据标定，这个问题基本就解决了。哪怕找一个高中生把它输入Net也能得到非常好的结果。让计算机学习图片之后，再给它展示一张它之前没见过的图片，一般它也能识别出来，水平基本与人类一致，甚至高于人类。因为人类有时会不小心犯错，但机器记忆或学会了之后便不会犯错。这些成果都是基于深度神经网络取得的。但也不能忘记，这种东西有很大的局限，它并不是真的很聪明，只是记住了很多样本。你也可以说它很蠢，因为它根本不知道自己在做什么。一切取决于你的标准，如果你把一个东西标注成cat，它就认为这是一只猫，明天你再把它标注成dog，它就认为这是一条狗。所以它并没有真正理解，只是在做简单的统计分类。人类可以把狼和狗归为同类，也可以把萨摩耶和白狼区分，这些都是主观的，取决于我们如何定义问题。我们如何定义，机器就给出什么样的答案，它本质上没有自己的认知。卷积神经网络能够识别图像只是表象，我们应该回归本质——计算机视觉。计算机视觉是对视觉特征的寻求和探索。CNN本质上是重新学习和定义了我们以前寻找的视觉特征。以前的视觉特征是手工定义的，维数不会太高，有几十、几百就已经比较高了，毕竟人类能力有限。卷积神经网络学习的视觉特征维数更多，动辄上百万，而且是有结构的。下一步将走向三维重建现在每个人都在研究识别，但识别只是计算机视觉的一部分。真正意义上的计算机视觉要超越识别，感知三维环境。我们活在三维空间里，要做到交互和感知，就必须将世界恢复到三维。所以，在识别的基础上，计算机视觉下一步必须走向三维重建。三维重建中包含深度、视差和重建三个概念，它们基本等价。使用哪个词汇取决你处在哪个群体。人类有两只眼睛，通过两只眼睛才能得到有深度的三维信息。当然，通过一只移动的眼睛，也可以获得有深度的信息。获取深度信息的挑战很大，它本质上是一个三角测量问题。第一步需要将两幅图像或两只眼睛感知到的东西进行匹配，也就是识别。这里的“识别”和前面有所不同，前面提到的是有标注情况下的识别，这里的“识别”是两幅图像之间的识别，没有数据库。它不仅要识别物体，还要识别每一个像素，所以对计算量要求非常高。双目视觉非常重要，哺乳动物都有双目视觉，而且智商越高，双目视线重叠的区域越大。马的眼睛是往两边看的，这并不代表它没有双目视觉，只是双目视线重叠的范围比较小。鱼也是如此。由此可见，现代三维视觉是由三维重建所定义的。CNN诞生之前，它的主要动力源于几何，因为它的定义相对清晰。计算机视觉中的三维重建包含三大问题：一、位置。假如我给出一张照片，计算机视觉要知道这张照片是在什么位置拍的。二、多目。通过多目的视差获取三维信息，识别每一个像素并进行匹配，进行三维重建。三、语义识别。完成几何三维重建后，要对这个三维信息进行语义识别，这是重建的最终目的。2012年之前，计算机视觉中的三维视觉已经得到了显著发展，那么新的深度学习对它有哪些启发呢？三维视觉本质上也是一个“识别”的问题，深度学习让它在识别方面得到了强化。视觉中的特征非常重要，以前的几何做法一般是用手工特征。CNN的重要之处不在于它能识别一只猫或一条狗，而在于它学会了很多视觉特征，我们可以拿这些特征做图像之间的识别和匹配。识别方面，现在我们面临比过去更大的挑战，因为现在的数据量比以前更多。以前是几十幅、上百幅，现在动辄几十万、上百万幅。这就涉及到计算机规模化的问题，规模化意味着分布式，这也是一个重要课题。前面提到双目和多目视觉，这个领域也有很多发展。以前是传统的方法，现在所有stereo方法都可以重新回到卷积神经网络的框架下。它的卷积不是简单的在图像里，而是在更高维的视差空间进行的。这个领域发展得非常快。Altizure 三维重建开放云平台下面宣传下我们做的工作。我在科大的团队创立了一家公司altizure，我认为我们的三维重建做的最出色。Altizure是一个公共云平台，大家可以用手机或无人机拍照然后上传，就可以自动得到一个三维模型。我们的终极目标是把世界上的所有东西全部三维复现。我们生活在三维的环境里，所以要把所有东西全部恢复到三维。今天的世界是数据为王，我们通过这个开放平台收集了很多数据，并进行标注。有了这样一个平台，今后的算法会越来越强大。我们研究的领域现在每天都在发生变化。我们团队今年4月份在两个重要榜单上名列第一，一个是三维点云，另一个是场景识别。计算机视觉的机遇与挑战深度学习浪潮下，计算机视觉面临哪些机遇和挑战？UCLA一位做统计的教授认为，现在的深度学习跟以前差不多，只是模拟了一个曲线或曲面，只是维度更高一些。另外一个学者Piekniewski也提出了质疑。2012年时AlexNet有6000个参数，今天我们已经可以学习比它多1000倍的参数，这是否意味着我们的能力提升了1000倍？其实不是，我们的改进仍然是非常边缘的。我的观点是，毫无疑问，CNN是一个非常强大的工具，但关于它我们还有很多不清楚的地方。CNN处理的是非常高维的数据，以前几十、几百个维度就已经高不可攀了，但今天是几百万、几千万个维度。高处不胜寒，即便研究数学的人也不太清楚中间发生了什么。这些还需要一段时间去理解。再来说说“理解”这个词，其实我们也不很清楚什么样才叫做理解。如果要做到真正理解，就要对世界和环境进行有结构、有逻辑的描述，但我们现在没有任何结构，完全是由数据带动，只有输入和输出。最后简单总结一下。早在80年代人工智能就很火，我研究生第一志愿报的就是人工智能。当时并不理解人工智能是什么，后来才慢慢明白，世上本无人工智能，只有图像识别、计算机视觉、语音识别、自然语言理解等一个个具体的问题。我们必须肯定这些年来取得的成绩，尤其硬件领域的发展非常可观。GPU已经在手机、电脑中普及，使得我们拥有非常强大的计算能力。以前相机是摄影师才有的，现在人手一台手机，随时随地可以拍照。甚至还有了无人机，可以从天上拍照。我们非常荣幸能在计算机视觉领域工作，这个领域发展很快，在中国大地上也很有前景。举两个例子：一、旷视在人脸和物的识别方面世界领先，类似的公司在中国还有很多；二、Altizure三维重建视觉平台在全世界也是独一无二的。从广义的人工智能来说，我不认为它有多大的发展，但我们也不能否认存在真正的进步。< END >如果喜欢这篇文章，欢迎转发－深圳珠科创新技术有限公司－Everest Innovation Technology Limitedsupport@altizure.com（技术支持）sales@altizure.com（商务联络）hr@altizure.com（简历投递）深圳 | 香港 | 北京随时了解 Altizure 的最新动态！欢迎关注我们的微信公众号：altizure_info