对 用 卷积 神经 网络 进行 目标 检测 方法 的 
一种 改进 通过 提取 多 尺度 的 特征 信息 进行 
融合 进而 提高 目标 检测 的 精度 特别是在 小物体 检测 
上 的 精度 FPN 是 ResNet 或 DenseNet 等 通用 
特征提取 网络 的 附加 组件 可以 和 经典 网络 组合 
提升 原 网络 效果 一 问题 背景 网络 的 深度 
对应 到 感受 野 与总 stride 通常 是 一对 矛盾 
的 东西 常用 的 网络 结构 对应 的 总 stride 
一般 会 比较 大 如 32 而 图像 中的 小物体 
甚至会 小于 stride 的 大小 造成 的 结果 就是 小 
物体 的 检测 性能 急剧下降 传统 解决 这个 问题 的 
思路 包括 1 多 尺度 训练 和 测试 又称 图像 
金字塔 如 下图 a 所示 目前/t 几乎/d 所有/b 在/p ImageNet/w 
和/c COCO/w 检测/vn 任务/n 上/f 取得/v 好成绩/i 的/uj 方法/n 都/d 
使用/v 了/ul 图像/n 金字塔/nr 方法/n 然而 这样 的 方法 由于 
很高 的 时间 及 计算 量 消耗 难以 在 实际 
中 应用 2 特征 分层 即 每层 分别 预测 对应 
的 scale 分辨率 的 检测 结果 如 下图 c 所示 
SSD 检测 框架 采用 了 类似 的 思想 这样 的 
方法 问题 在于 直接 强行 让 不同 层 学习 同样 
的 语义 信息 而 对于 卷积 神经网络 而言 不同 深度 
对应 着 不同 层次 的 语义 特征 浅层 网络 分辨率 
高 学 的 更多 是 细节 特征 深层 网络 分辨率 
低 学 的 更多 是 语义 特征 因而 目前 多 
尺度 的 物体 检测 主要 面临 的 挑战 为 1 
. 如何 学习 具有 强 语义 信息 的 多 尺度 
特征 表示 2 . 如何 设计 通用 的 特征 表示 
来 解决 物体 检测 中 的 多个 子 问题 如 
object proposal box localization instance segmentation . 3 . 如何 
高效 计算 多 尺度 的 特征 表示 二 特征 金字塔 
网络 Feature Pyramid Networks 作者 提出 了 FPN 算法 做法 
很 简单 如下 图 所示 把 低分辨率 高/a 语义/n 信息/n 
的/uj 高层/n 特征/n 和/c 高分辨率/n 低 语义 信息 的 低层 
特征 进行 自上而下 的 侧边 连接 使得/v 所有/b 尺度/n 下/f 
的/uj 特征/n 都有/nr 丰富/a 的/uj 语义/n 信息/n 图中 未 注明 
的 是 融合 之后 的 feat 还 需要 进行 一次 
3 * 3 卷积 作者 的 算法 结构 可以 分为 
三 个 部分 自下而上 的 卷积 神经网络 上 图左 自上而下 
过程 上 图右 和 特征 与 特征 之间 的 侧边 
连接 自下而上 的 部分 其实 就是 卷积 神经 网络 的 
前 向 过程 在前 向 过程 中 特征 图 的 
大小 在 经过 某些 层 后会 改变 而在 经过 其他 
一些 层 的 时候 不会 改变 作者 将 不 改变 
特征 图 大小 的 层 归为 一个 阶段 因此 每次 
抽取 的 特征 都是/nr 每个 阶段 的 最后 一个 层 
的 输出 这样 就 能 构成 特征 金字塔 具体来说 对于 
ResNets 作者 使用 了 每个 阶段 的 最后 一个 残差 
结构 的 特征 激活 输出 将 这些 残差 模块 输出 
表示 为 { C2 C3 C4 C5 } 对应 于 
conv2 conv3 conv4 和 conv5 的 输出 自上而下 的 过程 
采用 上 采样 进行 上 采样 几乎 都是/nr 采用 内 
插值 方法 即在 原有 图像 像素 的 基础 上 在 
像素点 之间 采用 合适 的 插值 算法 插入 新的 元素 
从而 扩大 原 图像 的 大小 通过 对 特征 图 
进行 上 采样 使/v 得上/i 采样/v 后的/nr 特征/n 图/n 具有/v 
和下/nr 一层/m 的/uj 特征/n 图/n 相同/d 的/uj 大小/b 根本 上 
来说 侧边 之间 的 横向 连接 是 将上 采样 的 
结果 和 自下而上 生成 的 特征 图 进行 融合 我们 
将 卷积 神经 网络 中 生成 的 对应 层 的 
特征 图 进行 1 × 1 的 卷积 操作 将之 
与 经过 上 采样 的 特征 图 融合 得到 一个 
新 的 特征 图 这个 特征 图 融合 了 不同 
层 的 特征 具有 更 丰富 的 信息 这里 1 
× 1 的 卷积 操作 目的 是 改变 channels 要求/v 
和后/nr 一层/m 的/uj channels/w 相同/d 在 融合 之后 还会 再 
采用 3 * 3 的 卷积 核对 每个 融合 结果 
进行 卷积 目的 是 消除 上 采样 的 混 叠 
效应 如此 就 得到 了 一个 新 的 特征 图 
这样 一层 一层 地 迭代 下去 就 可以 得到 多 
个 新的 特征 图 假设 生成 的 特征 图 结果 
是 P2 P3 P4 P5 它们 和 原来 自底向上 的 
卷积 结果 C2 C3 C4 C5 一一对应 金字塔 结构 中 
所有 层级 共享 分类 层 回归 层 三 fast rcnn 
中的 特征 金字塔 Fast rcnn 中的 ROI Pooling 层 使用 
region proposal 的 结果 和 特征 图 作为 输入 经过 
特征 金字塔 我们 得到 了 许多 特征 图 作者 认为 
不同 层次 的 特征 图上 包含 的 物体 大小 也 
不同 因此 不同 尺度 的 ROI 使用 不同 特征 层 
作为 ROI pooling 层 的 输入 大尺度 ROI 就用 后面 
一些 的 金字塔 层 比如 P5 小尺度 ROI 就用 前面 
一点 的 特征 层 比如 P4 但是 如何 确定 不同 
的 roi 对应 的 不同 特征 层 呢 作者 提出 
了 一种 方法 224 是 ImageNet 的 标准 输入 k0 
是 基准值 设置 为 5 代表 P 5层 的 输出 
原图 大小 就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 
长/a 和宽/nr 假设 ROI 是 112 * 112 的 大小 
那么 k = k0 1 = 5 1 = 4 
意味着 该 ROI 应该 使用 P4 的 特征 层 k 
值 做 取整 处理 这 意味着 如果 RoI 的 尺度 
变小 比如 224 的 1/2 那么 它 应该 被 映射 
到 一个 精细 的 分辨率 水平 与 RPN 一样 FPN 
每层 feature map 加入 3 * 3 的 卷积 及 
两个 相邻 的 1 * 1卷 积分 别做 分类 和 
回归 的 预测 在 RPN 中 实验 对比 了 FPN 
不 同层 feature map 卷积 参数 共享 与否 发现 共享 
仍然 能 达到 很好 性能 说明 特征 金字塔 使 得不 
同层 学到 了 相同 层次 的 语义 特征 用于 RPN 
的 FPN 用 FPN 替换 单一 尺度 的 FMap 它们/r 
对/p 每个/r 级/q 都有/nr 一个/m 单一/b 尺度/n 的/uj anchor/w 不 
需要 多级 作为 其 FPN 它们 还 表明 金字塔 的 
所有 层级 都有 相似 的 语义 层级 Faster RCNN 他们 
以 类似 于 图像 金字塔 输出 的 方式 观察 金字塔 
因此 使用 下面 这个 公式 将 RoI 分配 到 特定 
level 其中 w h 分别 表示 宽度 和 高度 k 
是 分配 RoI 的 level 是 w h = 224 
224时 映射 的 level 四 其他 问题 Q1 不同 深度 
的 feature map 为什么 可以 经过 upsample 后 直接 相加 
答 作者 解释 说 这个 原因 在于 我们 做了 end 
to end 的 training 因为 不 同层 的 参数 不是 
固定 的 不 同层 同时 给 监督 做 end to 
end training 所以 相加 训练 出来 的 东西 能够 更 
有效 地 融合 浅层 和 深层 的 信息 Q2 为什么 
FPN 相比 去掉 深层 特征 upsample bottom up pyramid 对于 
小物体 检测 提升 明显 RPN 步骤 AR 从 30.5 到 
44.9 Fast RCNN 步骤 AP 从 24.9 到 33.9 答 
作者 在 poster 里 给出 了 这个 问题 的 答案 
对于 小物体 一 方面 我们 需要 高 分辨率 的 feature 
map 更多 关注 小区域 信息 另一方面 如图 中的 挎包 一样 
需要 更 全局 的 信息 更 准确 判断 挎包 的 
存在 及 位置 Q3 如果 不 考虑 时间 情况下 image 
pyramid 是否 可能 会比 feature pyramid 的 性能 更高 答 
作者 觉得 经过 精细 调整 训练 是 可能 的 但是 
image pyramid 金字塔 主要 的 问题 在于 时间 和 空间 
占用 太大 而 feature pyramid 可以 在 几乎 不 增加 
额外 计算 量 情况 下 解决 多 尺度 检测 问题 
五 代码 层面 看 FPN 本部 分截 取自 知乎 文章 
从 代码 细节 理解 FPN 作者 使用 Mask RCNN 的 
源码 辅助 理解 FPN 结构 项目 地址 见 MRCNN 关于 
MRCNN 文章 计算机 视觉 RCNN 学习 _ 其三 Mask RCNN 
会 介绍 1 怎么做 的 上 采样 高层 特征 怎么 
上 采样 和下/nr 一层 的 特征 融合 的 代码 里面 
可以 看到 P5 = KL . Conv2D 256 1 1 
name = fpn _ c5p5 C5 C5 是 resnet 最 
顶层 的 输出 它 会 先 通过 一个 1 * 
1 的 卷积 层 同时 把 通 道数 转为 256 
得到 FPN 的 最 上面 的 一层 P5 KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 Keras 的 API 说明 告诉 我们 也 就是说 这里 
的 实现 使用 的 是 最简单 的 上 采样 没有 
使用 线性插值 没有 使 用反 卷积 而是 直接 复制 2 
怎么做 的 横向 连接 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
256 1 1 name = fpn _ c4p4 C4 这里 
可以 很 明显 的 看到 P4 就是 上 采样 之后 
的 P5 加上 1 * 1 卷积 之后 的 C4 
这里 的 横向 连接 实际上 就是 像素 加法 先把 P5 
和 C4 转换 到 一样 的 尺寸 再 直接 进行 
相加 注意 这里 对 从 resnet 抽取 的 特征 图 
做 的 是 1 * 1 的 卷积 1x1 的 
卷积 我 认为 有 三个 作用 使 bottom up 对应 
层 降 维 至 256 缓冲作用 防止 梯度 直接影响 bottom 
up 主干网络 更 稳定 组合 特征 3 FPN 自上而下 的 
网络结构 代码 怎么 实现 # 先从 resnet 抽取 四个 不同 
阶段 的 特征 图 C2 C5 _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers 构建 自上而下 的 
网络结构 # 从 C5 开始 处理 先 卷积 来 转换 
特征 图 尺寸 P5 = KL . Conv2D 256 1 
1 name = fpn _ c5p5 C5 # 上 采样 
之后 的 P5 和 卷积 之后 的 C4 像素 相加 
得到 P4 后续 的 过程 就 类似 了 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D 256 1 1 name = fpn 
_ c4p4 C4 P3 = KL . Add name = 
fpn _ p3add KL . UpSampling2D size = 2 2 
name = fpn _ p4upsampled P4 KL . Conv2D 256 
1 1 name = fpn _ c3p3 C3 P2 = 
KL . Add name = fpn _ p2add KL . 
UpSampling2D size = 2 2 name = fpn _ p3upsampled 
P3 KL . Conv2D 256 1 1 name = fpn 
_ c2p2 C2 # P2 P5 最后 又 做了 一次 
3 * 3 的 卷积 作用 是 消除 上 采样 
带来 的 混 叠 效应 # Attach 3x3 conv to 
all P layers to get the final feature maps . 
P2 = KL . Conv2D 256 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D 256 3 3 padding = SAME name = 
fpn _ p3 P3 P4 = KL . Conv2D 256 
3 3 padding = SAME name = fpn _ p4 
P4 P5 = KL . Conv2D 256 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # 注意 P6 是 用在 RPN 目标 区域 提取 
网络 里 面的 而 不是 用在 FPN 网络 # Note 
that P6 is used in RPN but not in the 
classifier heads . rpn _ feature _ maps = P2 
P3 P4 P5 P6 # 最后 得到 了 5个 融合 
了 不同 层级 特征 的 特征 图 列表 注意 P6 
是 用在 RPN 目标 区域 提取 网络 里 面的 而 
不是 用在 FPN 网络 另外 这里 P2 P5 最后 又 
做了 一次 3 * 3 的 卷积 作用 是 消除 
上 采样 带来 的 混 叠 效应 4 如何 确定 
某个 ROI 使用 哪 一层 特征 图 进行 ROIpooling 看 
代码 # Assign each ROI to a level in the 
pyramid based on the ROI area . # 这里 的 
boxes 是 ROI 的 框 用来 计算 得到 每个 ROI 
框 的 面积 y1 x1 y2 x2 = tf . 
split boxes 4 axis = 2 h = y2 y1 
w = x2 x1 # Use shape of first image 
. Images in a batch must have the same size 
. # 这里 得到 原图 的 尺寸 计算 原图 的 
面积 image _ shape = parse _ image _ meta 
_ graph image _ meta image _ shape 0 # 
Equation 1 in the Feature Pyramid Networks paper . Account 
for # the fact that our coordinates are normalized here 
. # e . g . a 224x224 ROI in 
pixels maps to P4 # 原图 面积 image _ area 
= tf . cast image _ shape 0 * image 
_ shape 1 tf . float32 # 分 两步 计算 
每个 ROI 框 需要 在 哪个 层 的 特征 图中 
进行 pooling roi _ level = log2 _ graph tf 
. sqrt h * w / 224.0 / tf . 
sqrt image _ area roi _ level = tf . 
minimum 5 tf . maximum 2 4 + tf . 
cast tf . round roi _ level tf . int32 
不同 尺度 的 ROI 使用 不同 特征 层 作为 ROI 
pooling 层 的 输入 大尺度 ROI 就用 后面 一些 的 
金字塔 层 比如 P5 小尺度 ROI 就用 前面 一点 的 
特征 层 比如 P4 那 怎么 判断 ROI 改用 那个 
层 的 输出 呢 论文 的 K 使用 如下 公式 
代码 做了 一点 更改 替换 为 roi _ level # 
代码 里面 的 计算 替换 为 以下 计算 方式 roi 
_ level = min 5 max 2 4 + log2 
sqrt w * h / 224 / sqrt image _ 
area 224 是 ImageNet 的 标准 输入 k0 是 基准值 
设置 为 5 代表 P 5层 的 输出 原图 大小 
就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 长/a 和宽/nr 
image _ area 是 输入 图片 的 长 乘以 宽 
即 输入 图片 的 面积 假设 ROI 是 112 * 
112 的 大小 那么 k = k0 1 = 5 
1 = 4 意味着 该 ROI 应该 使用 P4 的 
特征 层 k 值 会做 取整 处理 防止 结果 不是 
整数 5 上面 得到 的 5个 融合 了 不同 层级 
的 特征 图 怎么 使用 可以 看到 这里 只 使用 
2 5 四个 特征 图 for i level in enumerate 
range 2 6 # 先 找出 需要 在 第 level 
层 计算 ROI ix = tf . where tf . 
equal roi _ level level level _ boxes = tf 
. gather _ nd boxes ix # Box indicies for 
crop _ and _ resize . box _ indices = 
tf . cast ix 0 tf . int32 # Keep 
track of which box is mapped to which level box 
_ to _ level . append ix # Stop gradient 
propogation to ROI proposals level _ boxes = tf . 
stop _ gradient level _ boxes box _ indices = 
tf . stop _ gradient box _ indices # Crop 
and Resize # From Mask R CNN paper We sample 
four regular locations so # that we can evaluate either 
max or average pooling . In fact # interpolating only 
a single value at each bin center without # pooling 
is nearly as effective . # # Here we use 
the simplified approach of a single value per bin # 
which is how it s done in tf . crop 
_ and _ resize # Result batch * num _ 
boxes pool _ height pool _ width channels # 使用 
tf . image . crop _ and _ resize 进行 
ROI pooling pooled . append tf . image . crop 
_ and _ resize feature _ maps i level _ 
boxes box _ indices self . pool _ shape method 
= bilinear 对 每个 box 都 提取 其中 每 一层 
特征 图上 该 box 对应 的 特征 然后 组成 一个 
大 的 特征 列表 pooled 6 金字塔 结构 中 所有 
层级 共享 分类 层 是 怎么 回事 先看 代码 # 
ROI Pooling # Shape batch num _ boxes pool _ 
height pool _ width channels # 得到 经过 ROI pooling 
之后 的 特征 列表 x = PyramidROIAlign pool _ size 
pool _ size name = roi _ align _ classifier 
rois image _ meta + feature _ maps # 将 
上面 得到 的 特征 列表 送入 2 个 1024 通 
道数 的 卷积 层 以及 2 个 rulu 激活 层 
# Two 1024 FC layers implemented with Conv2D for consistency 
x = KL . TimeDistributed KL . Conv2D 1024 pool 
_ size pool _ size padding = valid name = 
mrcnn _ class _ conv1 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn1 x 
training = train _ bn x = KL . Activation 
relu x x = KL . TimeDistributed KL . Conv2D 
1024 1 1 name = mrcnn _ class _ conv2 
x x = KL . TimeDistributed BatchNorm name = mrcnn 
_ class _ bn2 x training = train _ bn 
x = KL . Activation relu x shared = KL 
. Lambda lambda x K . squeeze K . squeeze 
x 3 2 name = pool _ squeeze x # 
分类 层 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBOX 的 位置 偏移 回归 层 # BBox head # 
batch boxes num _ classes * dy dx log dh 
log dw x = KL . TimeDistributed KL . Dense 
num _ classes * 4 activation = linear name = 
mrcnn _ bbox _ fc shared # Reshape to batch 
boxes num _ classes dy dx log dh log dw 
s = K . int _ shape x mrcnn _ 
bbox = KL . Reshape s 1 num _ classes 
4 name = mrcnn _ bbox x 这里 的 PyramidROIAlign 
得到 的 x 就是 上面 一步 得到 的 从 每个 
层 的 特征 图上 提取 出来 的 特征 列表 这里 
对 这个 特征 列表 先接 两个 1024 通 道数 的 
卷积 层 再 分别 送入 分类 层 和 回归 层 
得到 最终 的 结果 也 就是说 每个 ROI 都在 P2 
P5 中的 某 一层 得到 了 一个 特征 然后 送入 
同一 个 分类 和 回归 网络 得到 最终 结果 FPN 
中 每 一层 的 heads 参数 都是 共享 的 作者 
认为 共享 参数 的 效果 也 不错 就 说明 FPN 
中所 有层 的 语义 都 相似 7 它 的 思想 
是 什么 把 高层 的 特征 传下来 补充 低层 的 
语义 这样 就 可以 获得 高 分辨率 强 语义 的 
特征 有利于 小 目标 的 检测 8 横向 连接 起 
什么 作用 如果 不 进行 特征 的 融合 也 就是说 
去掉 所有 的 1x1 侧 连接 虽然 理论上 分辨率 没变 
语义 也 增强 了 但是 AR 下降 了 10% 左右 
作者 认为 这些 特征 上下 采样 太 多次 了 导致 
它们 不 适于 定位 Bottom up 的 特征 包含 了 
更 精确 的 位置 信息 六 资源 资料 Feature Pyramid 
Networks for Object Detection CVPR 2017 论文 知乎 特征 金字塔 
网络 FPN 知乎 从 代码 细节 理解 FPNFPN 特征 金字塔 
网络 论文/nz 解读/v 详解/v 何恺明/nr 团队/n 4篇/mq 大作/n | 从 
特征 金字塔 网络 Mask R CNN 到 学习 分割 一切 
源码 资料 官方 Caffe2https / / github . com / 
facebookresearch / Detectron / tree / master / configs / 
12 _ 2017 _ b a s e l i 
n e s C a f f e h t 
t p s / / github . com / unsky 
/ FPNPyTorchhttps / / github . com / kuangliu / 
pytorch fpn   just the network MXNethttps / / github 
. com / unsky / FPN m x n e 
t T e n s o r f l o 
w h t t p s / / github . 
com / yangxue0827 / FPN _ Tensorflow 对 用 卷积 神经 网络 进行 目标 检测 方法 的 
一种 改进 通过 提取 多 尺度 的 特征 信息 进行 
融合 进而 提高 目标 检测 的 精度 特别是在 小物体 检测 
上 的 精度 FPN 是 ResNet 或 DenseNet 等 通用 
特征提取 网络 的 附加 组件 可以 和 经典 网络 组合 
提升 原 网络 效果 一 问题 背景 网络 的 深度 
对应 到 感受 野 与总 stride 通常 是 一对 矛盾 
的 东西 常用 的 网络 结构 对应 的 总 stride 
一般 会 比较 大 如 32 而 图像 中的 小物体 
甚至会 小于 stride 的 大小 造成 的 结果 就是 小 
物体 的 检测 性能 急剧下降 传统 解决 这个 问题 的 
思路 包括 1 多 尺度 训练 和 测试 又称 图像 
金字塔 如 下图 a 所示 目前/t 几乎/d 所有/b 在/p ImageNet/w 
和/c COCO/w 检测/vn 任务/n 上/f 取得/v 好成绩/i 的/uj 方法/n 都/d 
使用/v 了/ul 图像/n 金字塔/nr 方法/n 然而 这样 的 方法 由于 
很高 的 时间 及 计算 量 消耗 难以 在 实际 
中 应用 2 特征 分层 即 每层 分别 预测 对应 
的 scale 分辨率 的 检测 结果 如 下图 c 所示 
SSD 检测 框架 采用 了 类似 的 思想 这样 的 
方法 问题 在于 直接 强行 让 不同 层 学习 同样 
的 语义 信息 而 对于 卷积 神经网络 而言 不同 深度 
对应 着 不同 层次 的 语义 特征 浅层 网络 分辨率 
高 学 的 更多 是 细节 特征 深层 网络 分辨率 
低 学 的 更多 是 语义 特征 因而 目前 多 
尺度 的 物体 检测 主要 面临 的 挑战 为 1 
. 如何 学习 具有 强 语义 信息 的 多 尺度 
特征 表示 2 . 如何 设计 通用 的 特征 表示 
来 解决 物体 检测 中 的 多个 子 问题 如 
object proposal box localization instance segmentation . 3 . 如何 
高效 计算 多 尺度 的 特征 表示 二 特征 金字塔 
网络 Feature Pyramid Networks 作者 提出 了 FPN 算法 做法 
很 简单 如下 图 所示 把 低分辨率 高/a 语义/n 信息/n 
的/uj 高层/n 特征/n 和/c 高分辨率/n 低 语义 信息 的 低层 
特征 进行 自上而下 的 侧边 连接 使得/v 所有/b 尺度/n 下/f 
的/uj 特征/n 都有/nr 丰富/a 的/uj 语义/n 信息/n 图中 未 注明 
的 是 融合 之后 的 feat 还 需要 进行 一次 
3 * 3 卷积 作者 的 算法 结构 可以 分为 
三 个 部分 自下而上 的 卷积 神经网络 上 图左 自上而下 
过程 上 图右 和 特征 与 特征 之间 的 侧边 
连接 自下而上 的 部分 其实 就是 卷积 神经 网络 的 
前 向 过程 在前 向 过程 中 特征 图 的 
大小 在 经过 某些 层 后会 改变 而在 经过 其他 
一些 层 的 时候 不会 改变 作者 将 不 改变 
特征 图 大小 的 层 归为 一个 阶段 因此 每次 
抽取 的 特征 都是/nr 每个 阶段 的 最后 一个 层 
的 输出 这样 就 能 构成 特征 金字塔 具体来说 对于 
ResNets 作者 使用 了 每个 阶段 的 最后 一个 残差 
结构 的 特征 激活 输出 将 这些 残差 模块 输出 
表示 为 { C2 C3 C4 C5 } 对应 于 
conv2 conv3 conv4 和 conv5 的 输出 自上而下 的 过程 
采用 上 采样 进行 上 采样 几乎 都是/nr 采用 内 
插值 方法 即在 原有 图像 像素 的 基础 上 在 
像素点 之间 采用 合适 的 插值 算法 插入 新的 元素 
从而 扩大 原 图像 的 大小 通过 对 特征 图 
进行 上 采样 使/v 得上/i 采样/v 后的/nr 特征/n 图/n 具有/v 
和下/nr 一层/m 的/uj 特征/n 图/n 相同/d 的/uj 大小/b 根本 上 
来说 侧边 之间 的 横向 连接 是 将上 采样 的 
结果 和 自下而上 生成 的 特征 图 进行 融合 我们 
将 卷积 神经 网络 中 生成 的 对应 层 的 
特征 图 进行 1 × 1 的 卷积 操作 将之 
与 经过 上 采样 的 特征 图 融合 得到 一个 
新 的 特征 图 这个 特征 图 融合 了 不同 
层 的 特征 具有 更 丰富 的 信息 这里 1 
× 1 的 卷积 操作 目的 是 改变 channels 要求/v 
和后/nr 一层/m 的/uj channels/w 相同/d 在 融合 之后 还会 再 
采用 3 * 3 的 卷积 核对 每个 融合 结果 
进行 卷积 目的 是 消除 上 采样 的 混 叠 
效应 如此 就 得到 了 一个 新 的 特征 图 
这样 一层 一层 地 迭代 下去 就 可以 得到 多 
个 新的 特征 图 假设 生成 的 特征 图 结果 
是 P2 P3 P4 P5 它们 和 原来 自底向上 的 
卷积 结果 C2 C3 C4 C5 一一对应 金字塔 结构 中 
所有 层级 共享 分类 层 回归 层 三 fast rcnn 
中的 特征 金字塔 Fast rcnn 中的 ROI Pooling 层 使用 
region proposal 的 结果 和 特征 图 作为 输入 经过 
特征 金字塔 我们 得到 了 许多 特征 图 作者 认为 
不同 层次 的 特征 图上 包含 的 物体 大小 也 
不同 因此 不同 尺度 的 ROI 使用 不同 特征 层 
作为 ROI pooling 层 的 输入 大尺度 ROI 就用 后面 
一些 的 金字塔 层 比如 P5 小尺度 ROI 就用 前面 
一点 的 特征 层 比如 P4 但是 如何 确定 不同 
的 roi 对应 的 不同 特征 层 呢 作者 提出 
了 一种 方法 224 是 ImageNet 的 标准 输入 k0 
是 基准值 设置 为 5 代表 P 5层 的 输出 
原图 大小 就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 
长/a 和宽/nr 假设 ROI 是 112 * 112 的 大小 
那么 k = k0 1 = 5 1 = 4 
意味着 该 ROI 应该 使用 P4 的 特征 层 k 
值 做 取整 处理 这 意味着 如果 RoI 的 尺度 
变小 比如 224 的 1/2 那么 它 应该 被 映射 
到 一个 精细 的 分辨率 水平 与 RPN 一样 FPN 
每层 feature map 加入 3 * 3 的 卷积 及 
两个 相邻 的 1 * 1卷 积分 别做 分类 和 
回归 的 预测 在 RPN 中 实验 对比 了 FPN 
不 同层 feature map 卷积 参数 共享 与否 发现 共享 
仍然 能 达到 很好 性能 说明 特征 金字塔 使 得不 
同层 学到 了 相同 层次 的 语义 特征 用于 RPN 
的 FPN 用 FPN 替换 单一 尺度 的 FMap 它们/r 
对/p 每个/r 级/q 都有/nr 一个/m 单一/b 尺度/n 的/uj anchor/w 不 
需要 多级 作为 其 FPN 它们 还 表明 金字塔 的 
所有 层级 都有 相似 的 语义 层级 Faster RCNN 他们 
以 类似 于 图像 金字塔 输出 的 方式 观察 金字塔 
因此 使用 下面 这个 公式 将 RoI 分配 到 特定 
level 其中 w h 分别 表示 宽度 和 高度 k 
是 分配 RoI 的 level 是 w h = 224 
224时 映射 的 level 四 其他 问题 Q1 不同 深度 
的 feature map 为什么 可以 经过 upsample 后 直接 相加 
答 作者 解释 说 这个 原因 在于 我们 做了 end 
to end 的 training 因为 不 同层 的 参数 不是 
固定 的 不 同层 同时 给 监督 做 end to 
end training 所以 相加 训练 出来 的 东西 能够 更 
有效 地 融合 浅层 和 深层 的 信息 Q2 为什么 
FPN 相比 去掉 深层 特征 upsample bottom up pyramid 对于 
小物体 检测 提升 明显 RPN 步骤 AR 从 30.5 到 
44.9 Fast RCNN 步骤 AP 从 24.9 到 33.9 答 
作者 在 poster 里 给出 了 这个 问题 的 答案 
对于 小物体 一 方面 我们 需要 高 分辨率 的 feature 
map 更多 关注 小区域 信息 另一方面 如图 中的 挎包 一样 
需要 更 全局 的 信息 更 准确 判断 挎包 的 
存在 及 位置 Q3 如果 不 考虑 时间 情况下 image 
pyramid 是否 可能 会比 feature pyramid 的 性能 更高 答 
作者 觉得 经过 精细 调整 训练 是 可能 的 但是 
image pyramid 金字塔 主要 的 问题 在于 时间 和 空间 
占用 太大 而 feature pyramid 可以 在 几乎 不 增加 
额外 计算 量 情况 下 解决 多 尺度 检测 问题 
五 代码 层面 看 FPN 本部 分截 取自 知乎 文章 
从 代码 细节 理解 FPN 作者 使用 Mask RCNN 的 
源码 辅助 理解 FPN 结构 项目 地址 见 MRCNN 关于 
MRCNN 文章 计算机 视觉 RCNN 学习 _ 其三 Mask RCNN 
会 介绍 1 怎么做 的 上 采样 高层 特征 怎么 
上 采样 和下/nr 一层 的 特征 融合 的 代码 里面 
可以 看到 P5 = KL . Conv2D 256 1 1 
name = fpn _ c5p5 C5 C5 是 resnet 最 
顶层 的 输出 它 会 先 通过 一个 1 * 
1 的 卷积 层 同时 把 通 道数 转为 256 
得到 FPN 的 最 上面 的 一层 P5 KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 Keras 的 API 说明 告诉 我们 也 就是说 这里 
的 实现 使用 的 是 最简单 的 上 采样 没有 
使用 线性插值 没有 使 用反 卷积 而是 直接 复制 2 
怎么做 的 横向 连接 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
256 1 1 name = fpn _ c4p4 C4 这里 
可以 很 明显 的 看到 P4 就是 上 采样 之后 
的 P5 加上 1 * 1 卷积 之后 的 C4 
这里 的 横向 连接 实际上 就是 像素 加法 先把 P5 
和 C4 转换 到 一样 的 尺寸 再 直接 进行 
相加 注意 这里 对 从 resnet 抽取 的 特征 图 
做 的 是 1 * 1 的 卷积 1x1 的 
卷积 我 认为 有 三个 作用 使 bottom up 对应 
层 降 维 至 256 缓冲作用 防止 梯度 直接影响 bottom 
up 主干网络 更 稳定 组合 特征 3 FPN 自上而下 的 
网络结构 代码 怎么 实现 # 先从 resnet 抽取 四个 不同 
阶段 的 特征 图 C2 C5 _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers 构建 自上而下 的 
网络结构 # 从 C5 开始 处理 先 卷积 来 转换 
特征 图 尺寸 P5 = KL . Conv2D 256 1 
1 name = fpn _ c5p5 C5 # 上 采样 
之后 的 P5 和 卷积 之后 的 C4 像素 相加 
得到 P4 后续 的 过程 就 类似 了 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D 256 1 1 name = fpn 
_ c4p4 C4 P3 = KL . Add name = 
fpn _ p3add KL . UpSampling2D size = 2 2 
name = fpn _ p4upsampled P4 KL . Conv2D 256 
1 1 name = fpn _ c3p3 C3 P2 = 
KL . Add name = fpn _ p2add KL . 
UpSampling2D size = 2 2 name = fpn _ p3upsampled 
P3 KL . Conv2D 256 1 1 name = fpn 
_ c2p2 C2 # P2 P5 最后 又 做了 一次 
3 * 3 的 卷积 作用 是 消除 上 采样 
带来 的 混 叠 效应 # Attach 3x3 conv to 
all P layers to get the final feature maps . 
P2 = KL . Conv2D 256 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D 256 3 3 padding = SAME name = 
fpn _ p3 P3 P4 = KL . Conv2D 256 
3 3 padding = SAME name = fpn _ p4 
P4 P5 = KL . Conv2D 256 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # 注意 P6 是 用在 RPN 目标 区域 提取 
网络 里 面的 而 不是 用在 FPN 网络 # Note 
that P6 is used in RPN but not in the 
classifier heads . rpn _ feature _ maps = P2 
P3 P4 P5 P6 # 最后 得到 了 5个 融合 
了 不同 层级 特征 的 特征 图 列表 注意 P6 
是 用在 RPN 目标 区域 提取 网络 里 面的 而 
不是 用在 FPN 网络 另外 这里 P2 P5 最后 又 
做了 一次 3 * 3 的 卷积 作用 是 消除 
上 采样 带来 的 混 叠 效应 4 如何 确定 
某个 ROI 使用 哪 一层 特征 图 进行 ROIpooling 看 
代码 # Assign each ROI to a level in the 
pyramid based on the ROI area . # 这里 的 
boxes 是 ROI 的 框 用来 计算 得到 每个 ROI 
框 的 面积 y1 x1 y2 x2 = tf . 
split boxes 4 axis = 2 h = y2 y1 
w = x2 x1 # Use shape of first image 
. Images in a batch must have the same size 
. # 这里 得到 原图 的 尺寸 计算 原图 的 
面积 image _ shape = parse _ image _ meta 
_ graph image _ meta image _ shape 0 # 
Equation 1 in the Feature Pyramid Networks paper . Account 
for # the fact that our coordinates are normalized here 
. # e . g . a 224x224 ROI in 
pixels maps to P4 # 原图 面积 image _ area 
= tf . cast image _ shape 0 * image 
_ shape 1 tf . float32 # 分 两步 计算 
每个 ROI 框 需要 在 哪个 层 的 特征 图中 
进行 pooling roi _ level = log2 _ graph tf 
. sqrt h * w / 224.0 / tf . 
sqrt image _ area roi _ level = tf . 
minimum 5 tf . maximum 2 4 + tf . 
cast tf . round roi _ level tf . int32 
不同 尺度 的 ROI 使用 不同 特征 层 作为 ROI 
pooling 层 的 输入 大尺度 ROI 就用 后面 一些 的 
金字塔 层 比如 P5 小尺度 ROI 就用 前面 一点 的 
特征 层 比如 P4 那 怎么 判断 ROI 改用 那个 
层 的 输出 呢 论文 的 K 使用 如下 公式 
代码 做了 一点 更改 替换 为 roi _ level # 
代码 里面 的 计算 替换 为 以下 计算 方式 roi 
_ level = min 5 max 2 4 + log2 
sqrt w * h / 224 / sqrt image _ 
area 224 是 ImageNet 的 标准 输入 k0 是 基准值 
设置 为 5 代表 P 5层 的 输出 原图 大小 
就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 长/a 和宽/nr 
image _ area 是 输入 图片 的 长 乘以 宽 
即 输入 图片 的 面积 假设 ROI 是 112 * 
112 的 大小 那么 k = k0 1 = 5 
1 = 4 意味着 该 ROI 应该 使用 P4 的 
特征 层 k 值 会做 取整 处理 防止 结果 不是 
整数 5 上面 得到 的 5个 融合 了 不同 层级 
的 特征 图 怎么 使用 可以 看到 这里 只 使用 
2 5 四个 特征 图 for i level in enumerate 
range 2 6 # 先 找出 需要 在 第 level 
层 计算 ROI ix = tf . where tf . 
equal roi _ level level level _ boxes = tf 
. gather _ nd boxes ix # Box indicies for 
crop _ and _ resize . box _ indices = 
tf . cast ix 0 tf . int32 # Keep 
track of which box is mapped to which level box 
_ to _ level . append ix # Stop gradient 
propogation to ROI proposals level _ boxes = tf . 
stop _ gradient level _ boxes box _ indices = 
tf . stop _ gradient box _ indices # Crop 
and Resize # From Mask R CNN paper We sample 
four regular locations so # that we can evaluate either 
max or average pooling . In fact # interpolating only 
a single value at each bin center without # pooling 
is nearly as effective . # # Here we use 
the simplified approach of a single value per bin # 
which is how it s done in tf . crop 
_ and _ resize # Result batch * num _ 
boxes pool _ height pool _ width channels # 使用 
tf . image . crop _ and _ resize 进行 
ROI pooling pooled . append tf . image . crop 
_ and _ resize feature _ maps i level _ 
boxes box _ indices self . pool _ shape method 
= bilinear 对 每个 box 都 提取 其中 每 一层 
特征 图上 该 box 对应 的 特征 然后 组成 一个 
大 的 特征 列表 pooled 6 金字塔 结构 中 所有 
层级 共享 分类 层 是 怎么 回事 先看 代码 # 
ROI Pooling # Shape batch num _ boxes pool _ 
height pool _ width channels # 得到 经过 ROI pooling 
之后 的 特征 列表 x = PyramidROIAlign pool _ size 
pool _ size name = roi _ align _ classifier 
rois image _ meta + feature _ maps # 将 
上面 得到 的 特征 列表 送入 2 个 1024 通 
道数 的 卷积 层 以及 2 个 rulu 激活 层 
# Two 1024 FC layers implemented with Conv2D for consistency 
x = KL . TimeDistributed KL . Conv2D 1024 pool 
_ size pool _ size padding = valid name = 
mrcnn _ class _ conv1 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn1 x 
training = train _ bn x = KL . Activation 
relu x x = KL . TimeDistributed KL . Conv2D 
1024 1 1 name = mrcnn _ class _ conv2 
x x = KL . TimeDistributed BatchNorm name = mrcnn 
_ class _ bn2 x training = train _ bn 
x = KL . Activation relu x shared = KL 
. Lambda lambda x K . squeeze K . squeeze 
x 3 2 name = pool _ squeeze x # 
分类 层 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBOX 的 位置 偏移 回归 层 # BBox head # 
batch boxes num _ classes * dy dx log dh 
log dw x = KL . TimeDistributed KL . Dense 
num _ classes * 4 activation = linear name = 
mrcnn _ bbox _ fc shared # Reshape to batch 
boxes num _ classes dy dx log dh log dw 
s = K . int _ shape x mrcnn _ 
bbox = KL . Reshape s 1 num _ classes 
4 name = mrcnn _ bbox x 这里 的 PyramidROIAlign 
得到 的 x 就是 上面 一步 得到 的 从 每个 
层 的 特征 图上 提取 出来 的 特征 列表 这里 
对 这个 特征 列表 先接 两个 1024 通 道数 的 
卷积 层 再 分别 送入 分类 层 和 回归 层 
得到 最终 的 结果 也 就是说 每个 ROI 都在 P2 
P5 中的 某 一层 得到 了 一个 特征 然后 送入 
同一 个 分类 和 回归 网络 得到 最终 结果 FPN 
中 每 一层 的 heads 参数 都是 共享 的 作者 
认为 共享 参数 的 效果 也 不错 就 说明 FPN 
中所 有层 的 语义 都 相似 7 它 的 思想 
是 什么 把 高层 的 特征 传下来 补充 低层 的 
语义 这样 就 可以 获得 高 分辨率 强 语义 的 
特征 有利于 小 目标 的 检测 8 横向 连接 起 
什么 作用 如果 不 进行 特征 的 融合 也 就是说 
去掉 所有 的 1x1 侧 连接 虽然 理论上 分辨率 没变 
语义 也 增强 了 但是 AR 下降 了 10% 左右 
作者 认为 这些 特征 上下 采样 太 多次 了 导致 
它们 不 适于 定位 Bottom up 的 特征 包含 了 
更 精确 的 位置 信息 六 资源 资料 Feature Pyramid 
Networks for Object Detection CVPR 2017 论文 知乎 特征 金字塔 
网络 FPN 知乎 从 代码 细节 理解 FPNFPN 特征 金字塔 
网络 论文/nz 解读/v 详解/v 何恺明/nr 团队/n 4篇/mq 大作/n | 从 
特征 金字塔 网络 Mask R CNN 到 学习 分割 一切 
源码 资料 官方 Caffe2https / / github . com / 
facebookresearch / Detectron / tree / master / configs / 
12 _ 2017 _ b a s e l i 
n e s C a f f e h t 
t p s / / github . com / unsky 
/ FPNPyTorchhttps / / github . com / kuangliu / 
pytorch fpn   just the network MXNethttps / / github 
. com / unsky / FPN m x n e 
t T e n s o r f l o 
w h t t p s / / github . 
com / yangxue0827 / FPN _ Tensorflow 对 用 卷积 神经 网络 进行 目标 检测 方法 的 
一种 改进 通过 提取 多 尺度 的 特征 信息 进行 
融合 进而 提高 目标 检测 的 精度 特别是在 小物体 检测 
上 的 精度 FPN 是 ResNet 或 DenseNet 等 通用 
特征提取 网络 的 附加 组件 可以 和 经典 网络 组合 
提升 原 网络 效果 一 问题 背景 网络 的 深度 
对应 到 感受 野 与总 stride 通常 是 一对 矛盾 
的 东西 常用 的 网络 结构 对应 的 总 stride 
一般 会 比较 大 如 32 而 图像 中的 小物体 
甚至会 小于 stride 的 大小 造成 的 结果 就是 小 
物体 的 检测 性能 急剧下降 传统 解决 这个 问题 的 
思路 包括 1 多 尺度 训练 和 测试 又称 图像 
金字塔 如 下图 a 所示 目前/t 几乎/d 所有/b 在/p ImageNet/w 
和/c COCO/w 检测/vn 任务/n 上/f 取得/v 好成绩/i 的/uj 方法/n 都/d 
使用/v 了/ul 图像/n 金字塔/nr 方法/n 然而 这样 的 方法 由于 
很高 的 时间 及 计算 量 消耗 难以 在 实际 
中 应用 2 特征 分层 即 每层 分别 预测 对应 
的 scale 分辨率 的 检测 结果 如 下图 c 所示 
SSD 检测 框架 采用 了 类似 的 思想 这样 的 
方法 问题 在于 直接 强行 让 不同 层 学习 同样 
的 语义 信息 而 对于 卷积 神经网络 而言 不同 深度 
对应 着 不同 层次 的 语义 特征 浅层 网络 分辨率 
高 学 的 更多 是 细节 特征 深层 网络 分辨率 
低 学 的 更多 是 语义 特征 因而 目前 多 
尺度 的 物体 检测 主要 面临 的 挑战 为 1 
. 如何 学习 具有 强 语义 信息 的 多 尺度 
特征 表示 2 . 如何 设计 通用 的 特征 表示 
来 解决 物体 检测 中 的 多个 子 问题 如 
object proposal box localization instance segmentation . 3 . 如何 
高效 计算 多 尺度 的 特征 表示 二 特征 金字塔 
网络 Feature Pyramid Networks 作者 提出 了 FPN 算法 做法 
很 简单 如下 图 所示 把 低分辨率 高/a 语义/n 信息/n 
的/uj 高层/n 特征/n 和/c 高分辨率/n 低 语义 信息 的 低层 
特征 进行 自上而下 的 侧边 连接 使得/v 所有/b 尺度/n 下/f 
的/uj 特征/n 都有/nr 丰富/a 的/uj 语义/n 信息/n 图中 未 注明 
的 是 融合 之后 的 feat 还 需要 进行 一次 
3 * 3 卷积 作者 的 算法 结构 可以 分为 
三 个 部分 自下而上 的 卷积 神经网络 上 图左 自上而下 
过程 上 图右 和 特征 与 特征 之间 的 侧边 
连接 自下而上 的 部分 其实 就是 卷积 神经 网络 的 
前 向 过程 在前 向 过程 中 特征 图 的 
大小 在 经过 某些 层 后会 改变 而在 经过 其他 
一些 层 的 时候 不会 改变 作者 将 不 改变 
特征 图 大小 的 层 归为 一个 阶段 因此 每次 
抽取 的 特征 都是/nr 每个 阶段 的 最后 一个 层 
的 输出 这样 就 能 构成 特征 金字塔 具体来说 对于 
ResNets 作者 使用 了 每个 阶段 的 最后 一个 残差 
结构 的 特征 激活 输出 将 这些 残差 模块 输出 
表示 为 { C2 C3 C4 C5 } 对应 于 
conv2 conv3 conv4 和 conv5 的 输出 自上而下 的 过程 
采用 上 采样 进行 上 采样 几乎 都是/nr 采用 内 
插值 方法 即在 原有 图像 像素 的 基础 上 在 
像素点 之间 采用 合适 的 插值 算法 插入 新的 元素 
从而 扩大 原 图像 的 大小 通过 对 特征 图 
进行 上 采样 使/v 得上/i 采样/v 后的/nr 特征/n 图/n 具有/v 
和下/nr 一层/m 的/uj 特征/n 图/n 相同/d 的/uj 大小/b 根本 上 
来说 侧边 之间 的 横向 连接 是 将上 采样 的 
结果 和 自下而上 生成 的 特征 图 进行 融合 我们 
将 卷积 神经 网络 中 生成 的 对应 层 的 
特征 图 进行 1 × 1 的 卷积 操作 将之 
与 经过 上 采样 的 特征 图 融合 得到 一个 
新 的 特征 图 这个 特征 图 融合 了 不同 
层 的 特征 具有 更 丰富 的 信息 这里 1 
× 1 的 卷积 操作 目的 是 改变 channels 要求/v 
和后/nr 一层/m 的/uj channels/w 相同/d 在 融合 之后 还会 再 
采用 3 * 3 的 卷积 核对 每个 融合 结果 
进行 卷积 目的 是 消除 上 采样 的 混 叠 
效应 如此 就 得到 了 一个 新 的 特征 图 
这样 一层 一层 地 迭代 下去 就 可以 得到 多 
个 新的 特征 图 假设 生成 的 特征 图 结果 
是 P2 P3 P4 P5 它们 和 原来 自底向上 的 
卷积 结果 C2 C3 C4 C5 一一对应 金字塔 结构 中 
所有 层级 共享 分类 层 回归 层 三 fast rcnn 
中的 特征 金字塔 Fast rcnn 中的 ROI Pooling 层 使用 
region proposal 的 结果 和 特征 图 作为 输入 经过 
特征 金字塔 我们 得到 了 许多 特征 图 作者 认为 
不同 层次 的 特征 图上 包含 的 物体 大小 也 
不同 因此 不同 尺度 的 ROI 使用 不同 特征 层 
作为 ROI pooling 层 的 输入 大尺度 ROI 就用 后面 
一些 的 金字塔 层 比如 P5 小尺度 ROI 就用 前面 
一点 的 特征 层 比如 P4 但是 如何 确定 不同 
的 roi 对应 的 不同 特征 层 呢 作者 提出 
了 一种 方法 224 是 ImageNet 的 标准 输入 k0 
是 基准值 设置 为 5 代表 P 5层 的 输出 
原图 大小 就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 
长/a 和宽/nr 假设 ROI 是 112 * 112 的 大小 
那么 k = k0 1 = 5 1 = 4 
意味着 该 ROI 应该 使用 P4 的 特征 层 k 
值 做 取整 处理 这 意味着 如果 RoI 的 尺度 
变小 比如 224 的 1/2 那么 它 应该 被 映射 
到 一个 精细 的 分辨率 水平 与 RPN 一样 FPN 
每层 feature map 加入 3 * 3 的 卷积 及 
两个 相邻 的 1 * 1卷 积分 别做 分类 和 
回归 的 预测 在 RPN 中 实验 对比 了 FPN 
不 同层 feature map 卷积 参数 共享 与否 发现 共享 
仍然 能 达到 很好 性能 说明 特征 金字塔 使 得不 
同层 学到 了 相同 层次 的 语义 特征 用于 RPN 
的 FPN 用 FPN 替换 单一 尺度 的 FMap 它们/r 
对/p 每个/r 级/q 都有/nr 一个/m 单一/b 尺度/n 的/uj anchor/w 不 
需要 多级 作为 其 FPN 它们 还 表明 金字塔 的 
所有 层级 都有 相似 的 语义 层级 Faster RCNN 他们 
以 类似 于 图像 金字塔 输出 的 方式 观察 金字塔 
因此 使用 下面 这个 公式 将 RoI 分配 到 特定 
level 其中 w h 分别 表示 宽度 和 高度 k 
是 分配 RoI 的 level 是 w h = 224 
224时 映射 的 level 四 其他 问题 Q1 不同 深度 
的 feature map 为什么 可以 经过 upsample 后 直接 相加 
答 作者 解释 说 这个 原因 在于 我们 做了 end 
to end 的 training 因为 不 同层 的 参数 不是 
固定 的 不 同层 同时 给 监督 做 end to 
end training 所以 相加 训练 出来 的 东西 能够 更 
有效 地 融合 浅层 和 深层 的 信息 Q2 为什么 
FPN 相比 去掉 深层 特征 upsample bottom up pyramid 对于 
小物体 检测 提升 明显 RPN 步骤 AR 从 30.5 到 
44.9 Fast RCNN 步骤 AP 从 24.9 到 33.9 答 
作者 在 poster 里 给出 了 这个 问题 的 答案 
对于 小物体 一 方面 我们 需要 高 分辨率 的 feature 
map 更多 关注 小区域 信息 另一方面 如图 中的 挎包 一样 
需要 更 全局 的 信息 更 准确 判断 挎包 的 
存在 及 位置 Q3 如果 不 考虑 时间 情况下 image 
pyramid 是否 可能 会比 feature pyramid 的 性能 更高 答 
作者 觉得 经过 精细 调整 训练 是 可能 的 但是 
image pyramid 金字塔 主要 的 问题 在于 时间 和 空间 
占用 太大 而 feature pyramid 可以 在 几乎 不 增加 
额外 计算 量 情况 下 解决 多 尺度 检测 问题 
五 代码 层面 看 FPN 本部 分截 取自 知乎 文章 
从 代码 细节 理解 FPN 作者 使用 Mask RCNN 的 
源码 辅助 理解 FPN 结构 项目 地址 见 MRCNN 关于 
MRCNN 文章 计算机 视觉 RCNN 学习 _ 其三 Mask RCNN 
会 介绍 1 怎么做 的 上 采样 高层 特征 怎么 
上 采样 和下/nr 一层 的 特征 融合 的 代码 里面 
可以 看到 P5 = KL . Conv2D 256 1 1 
name = fpn _ c5p5 C5 C5 是 resnet 最 
顶层 的 输出 它 会 先 通过 一个 1 * 
1 的 卷积 层 同时 把 通 道数 转为 256 
得到 FPN 的 最 上面 的 一层 P5 KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 Keras 的 API 说明 告诉 我们 也 就是说 这里 
的 实现 使用 的 是 最简单 的 上 采样 没有 
使用 线性插值 没有 使 用反 卷积 而是 直接 复制 2 
怎么做 的 横向 连接 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
256 1 1 name = fpn _ c4p4 C4 这里 
可以 很 明显 的 看到 P4 就是 上 采样 之后 
的 P5 加上 1 * 1 卷积 之后 的 C4 
这里 的 横向 连接 实际上 就是 像素 加法 先把 P5 
和 C4 转换 到 一样 的 尺寸 再 直接 进行 
相加 注意 这里 对 从 resnet 抽取 的 特征 图 
做 的 是 1 * 1 的 卷积 1x1 的 
卷积 我 认为 有 三个 作用 使 bottom up 对应 
层 降 维 至 256 缓冲作用 防止 梯度 直接影响 bottom 
up 主干网络 更 稳定 组合 特征 3 FPN 自上而下 的 
网络结构 代码 怎么 实现 # 先从 resnet 抽取 四个 不同 
阶段 的 特征 图 C2 C5 _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers 构建 自上而下 的 
网络结构 # 从 C5 开始 处理 先 卷积 来 转换 
特征 图 尺寸 P5 = KL . Conv2D 256 1 
1 name = fpn _ c5p5 C5 # 上 采样 
之后 的 P5 和 卷积 之后 的 C4 像素 相加 
得到 P4 后续 的 过程 就 类似 了 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D 256 1 1 name = fpn 
_ c4p4 C4 P3 = KL . Add name = 
fpn _ p3add KL . UpSampling2D size = 2 2 
name = fpn _ p4upsampled P4 KL . Conv2D 256 
1 1 name = fpn _ c3p3 C3 P2 = 
KL . Add name = fpn _ p2add KL . 
UpSampling2D size = 2 2 name = fpn _ p3upsampled 
P3 KL . Conv2D 256 1 1 name = fpn 
_ c2p2 C2 # P2 P5 最后 又 做了 一次 
3 * 3 的 卷积 作用 是 消除 上 采样 
带来 的 混 叠 效应 # Attach 3x3 conv to 
all P layers to get the final feature maps . 
P2 = KL . Conv2D 256 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D 256 3 3 padding = SAME name = 
fpn _ p3 P3 P4 = KL . Conv2D 256 
3 3 padding = SAME name = fpn _ p4 
P4 P5 = KL . Conv2D 256 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # 注意 P6 是 用在 RPN 目标 区域 提取 
网络 里 面的 而 不是 用在 FPN 网络 # Note 
that P6 is used in RPN but not in the 
classifier heads . rpn _ feature _ maps = P2 
P3 P4 P5 P6 # 最后 得到 了 5个 融合 
了 不同 层级 特征 的 特征 图 列表 注意 P6 
是 用在 RPN 目标 区域 提取 网络 里 面的 而 
不是 用在 FPN 网络 另外 这里 P2 P5 最后 又 
做了 一次 3 * 3 的 卷积 作用 是 消除 
上 采样 带来 的 混 叠 效应 4 如何 确定 
某个 ROI 使用 哪 一层 特征 图 进行 ROIpooling 看 
代码 # Assign each ROI to a level in the 
pyramid based on the ROI area . # 这里 的 
boxes 是 ROI 的 框 用来 计算 得到 每个 ROI 
框 的 面积 y1 x1 y2 x2 = tf . 
split boxes 4 axis = 2 h = y2 y1 
w = x2 x1 # Use shape of first image 
. Images in a batch must have the same size 
. # 这里 得到 原图 的 尺寸 计算 原图 的 
面积 image _ shape = parse _ image _ meta 
_ graph image _ meta image _ shape 0 # 
Equation 1 in the Feature Pyramid Networks paper . Account 
for # the fact that our coordinates are normalized here 
. # e . g . a 224x224 ROI in 
pixels maps to P4 # 原图 面积 image _ area 
= tf . cast image _ shape 0 * image 
_ shape 1 tf . float32 # 分 两步 计算 
每个 ROI 框 需要 在 哪个 层 的 特征 图中 
进行 pooling roi _ level = log2 _ graph tf 
. sqrt h * w / 224.0 / tf . 
sqrt image _ area roi _ level = tf . 
minimum 5 tf . maximum 2 4 + tf . 
cast tf . round roi _ level tf . int32 
不同 尺度 的 ROI 使用 不同 特征 层 作为 ROI 
pooling 层 的 输入 大尺度 ROI 就用 后面 一些 的 
金字塔 层 比如 P5 小尺度 ROI 就用 前面 一点 的 
特征 层 比如 P4 那 怎么 判断 ROI 改用 那个 
层 的 输出 呢 论文 的 K 使用 如下 公式 
代码 做了 一点 更改 替换 为 roi _ level # 
代码 里面 的 计算 替换 为 以下 计算 方式 roi 
_ level = min 5 max 2 4 + log2 
sqrt w * h / 224 / sqrt image _ 
area 224 是 ImageNet 的 标准 输入 k0 是 基准值 
设置 为 5 代表 P 5层 的 输出 原图 大小 
就用 P 5层 w/w 和h是/nr ROI/w 区域/n 的/uj 长/a 和宽/nr 
image _ area 是 输入 图片 的 长 乘以 宽 
即 输入 图片 的 面积 假设 ROI 是 112 * 
112 的 大小 那么 k = k0 1 = 5 
1 = 4 意味着 该 ROI 应该 使用 P4 的 
特征 层 k 值 会做 取整 处理 防止 结果 不是 
整数 5 上面 得到 的 5个 融合 了 不同 层级 
的 特征 图 怎么 使用 可以 看到 这里 只 使用 
2 5 四个 特征 图 for i level in enumerate 
range 2 6 # 先 找出 需要 在 第 level 
层 计算 ROI ix = tf . where tf . 
equal roi _ level level level _ boxes = tf 
. gather _ nd boxes ix # Box indicies for 
crop _ and _ resize . box _ indices = 
tf . cast ix 0 tf . int32 # Keep 
track of which box is mapped to which level box 
_ to _ level . append ix # Stop gradient 
propogation to ROI proposals level _ boxes = tf . 
stop _ gradient level _ boxes box _ indices = 
tf . stop _ gradient box _ indices # Crop 
and Resize # From Mask R CNN paper We sample 
four regular locations so # that we can evaluate either 
max or average pooling . In fact # interpolating only 
a single value at each bin center without # pooling 
is nearly as effective . # # Here we use 
the simplified approach of a single value per bin # 
which is how it s done in tf . crop 
_ and _ resize # Result batch * num _ 
boxes pool _ height pool _ width channels # 使用 
tf . image . crop _ and _ resize 进行 
ROI pooling pooled . append tf . image . crop 
_ and _ resize feature _ maps i level _ 
boxes box _ indices self . pool _ shape method 
= bilinear 对 每个 box 都 提取 其中 每 一层 
特征 图上 该 box 对应 的 特征 然后 组成 一个 
大 的 特征 列表 pooled 6 金字塔 结构 中 所有 
层级 共享 分类 层 是 怎么 回事 先看 代码 # 
ROI Pooling # Shape batch num _ boxes pool _ 
height pool _ width channels # 得到 经过 ROI pooling 
之后 的 特征 列表 x = PyramidROIAlign pool _ size 
pool _ size name = roi _ align _ classifier 
rois image _ meta + feature _ maps # 将 
上面 得到 的 特征 列表 送入 2 个 1024 通 
道数 的 卷积 层 以及 2 个 rulu 激活 层 
# Two 1024 FC layers implemented with Conv2D for consistency 
x = KL . TimeDistributed KL . Conv2D 1024 pool 
_ size pool _ size padding = valid name = 
mrcnn _ class _ conv1 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn1 x 
training = train _ bn x = KL . Activation 
relu x x = KL . TimeDistributed KL . Conv2D 
1024 1 1 name = mrcnn _ class _ conv2 
x x = KL . TimeDistributed BatchNorm name = mrcnn 
_ class _ bn2 x training = train _ bn 
x = KL . Activation relu x shared = KL 
. Lambda lambda x K . squeeze K . squeeze 
x 3 2 name = pool _ squeeze x # 
分类 层 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBOX 的 位置 偏移 回归 层 # BBox head # 
batch boxes num _ classes * dy dx log dh 
log dw x = KL . TimeDistributed KL . Dense 
num _ classes * 4 activation = linear name = 
mrcnn _ bbox _ fc shared # Reshape to batch 
boxes num _ classes dy dx log dh log dw 
s = K . int _ shape x mrcnn _ 
bbox = KL . Reshape s 1 num _ classes 
4 name = mrcnn _ bbox x 这里 的 PyramidROIAlign 
得到 的 x 就是 上面 一步 得到 的 从 每个 
层 的 特征 图上 提取 出来 的 特征 列表 这里 
对 这个 特征 列表 先接 两个 1024 通 道数 的 
卷积 层 再 分别 送入 分类 层 和 回归 层 
得到 最终 的 结果 也 就是说 每个 ROI 都在 P2 
P5 中的 某 一层 得到 了 一个 特征 然后 送入 
同一 个 分类 和 回归 网络 得到 最终 结果 FPN 
中 每 一层 的 heads 参数 都是 共享 的 作者 
认为 共享 参数 的 效果 也 不错 就 说明 FPN 
中所 有层 的 语义 都 相似 7 它 的 思想 
是 什么 把 高层 的 特征 传下来 补充 低层 的 
语义 这样 就 可以 获得 高 分辨率 强 语义 的 
特征 有利于 小 目标 的 检测 8 横向 连接 起 
什么 作用 如果 不 进行 特征 的 融合 也 就是说 
去掉 所有 的 1x1 侧 连接 虽然 理论上 分辨率 没变 
语义 也 增强 了 但是 AR 下降 了 10% 左右 
作者 认为 这些 特征 上下 采样 太 多次 了 导致 
它们 不 适于 定位 Bottom up 的 特征 包含 了 
更 精确 的 位置 信息 六 资源 资料 Feature Pyramid 
Networks for Object Detection CVPR 2017 论文 知乎 特征 金字塔 
网络 FPN 知乎 从 代码 细节 理解 FPNFPN 特征 金字塔 
网络 论文/nz 解读/v 详解/v 何恺明/nr 团队/n 4篇/mq 大作/n | 从 
特征 金字塔 网络 Mask R CNN 到 学习 分割 一切 
源码 资料 官方 Caffe2https / / github . com / 
facebookresearch / Detectron / tree / master / configs / 
12 _ 2017 _ b a s e l i 
n e s C a f f e h t 
t p s / / github . com / unsky 
/ FPNPyTorchhttps / / github . com / kuangliu / 
pytorch fpn   just the network MXNethttps / / github 
. com / unsky / FPN m x n e 
t T e n s o r f l o 
w h t t p s / / github . 
com / yangxue0827 / FPN _ Tensorflow 