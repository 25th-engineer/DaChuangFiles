推荐 一个 语义 分割 专栏 作者 对 本 领域 的 
很多 论文 都 进行 了 整理 语义 分割 刷 怪 
进阶 而 截止 目前 CNN 已经 在 图像 分类 分 
方面 取得 了 巨大 的 成就 涌现出 如 VGG 和 
Resnet 等 网络结构 并在 ImageNet 中 取得 了 好成绩 CNN 
的 强大 之处 在于 它 的 多层 结构 能 自动 
学习 特征 并且 可以 学习 到 多个 层次 的 特征 
较浅 的 卷积 层 感知 域 较小 学习 到 一些 
局部 区域 的 特征 较深 的 卷积 层 具有 较大 
的 感知 域 能够 学习 到 更加 抽象 一些 的 
特征 这些 深层 抽象 特征 对 物体 的 大小 位置 
和 方向 等 敏感性 更低 从而 有助于 分类 性能 的 
提高 这些 抽象 的 特征 对 分类 很有帮助 可以 很好 
地 判断 出 一幅 图像 中 包含 什么 类别 的 
物体 也 就是说 图像 分类 是 图像 级别 任务 参考 
图像 语义 分割 入门 与 分类 不同 的 是 语义 
分割 需要 判断 图像 每个 像素点 的 类别 进行 精确 
分割 图像 语义 分割 是 像素 级别 的 任务 但是 
由于 CNN 在 进行 convolution 和 pooling 过程 中 丢失 
了 图像 细节 即 feature map size 逐渐 变小 所以 
不能 很好 地 指出 物体 的 具体 轮廓 指出 每个 
像素 具体 属于 哪个 物体 无法 做到 精确 的 分割 
针对 这个 问题 Jonathan Long 等人 提出 了 Fully Convolutional 
Networks FCN 用于 图像 语义 分割 自从 提出 后 FCN 
已经 成为 语义 分割 的 基本 框架 后续 算法 其实 
都是 在 这个 框架 中 改进 而来 注意 本文 仅对 
基于 深度 学习 的 经典 语义 分割 成果 进行 梳理 
之所以 说 是 经典 是 因为 本文 几乎 没有 涉及 
18年 及 之后 的 最新 进展 故 标题 也 说 
了 只是 入门 基于 深度 学习 的 语义 分割 一 
FCN 对于 一般 的 分类 CNN 网络 如 VGG 和 
Resnet 都会 在 网络 的 最后 加入 一些 全 连接 
层 经过 softmax 后就/nr 可以 获得 类别 概率 信息 但是 
这个 概率 信息 是 1 维 的 即 只能 标识 
整个 图片 的 类别 不能 标识 每个 像素点 的 类别 
所以/c 这种/r 全/a 连接/v 方法/n 不/d 适用/v 于/p 图像/n 分割/v 
而/c FCN/w 提出/v 可以/c 把/p 后面/f 几个/m 全/a 连接/v 都/d 
换成/v 卷积/n 这样 就 可以 获得 一张 2 维 的 
feature map 后接 softmax 获得 每个 像素点 的 分类信息 从而 
解决 了 分割 问题 1 网络 特点 全 卷积 Convolutional 
上 采样 Upsample 跳跃 结构 Skip Layer 2 网络结构 3 
原理/n 说明/v 全/a 卷积/n FCN/w 将/d 传统/n CNN/w 中的/i 全/a 
连接/v 层/q 转化/v 成/n 一个/m 个/q 的/uj 卷积/n 层/q 如下 
图 所示 在 传统 的 CNN 结构 中 前 5层 
是 卷积 层 第 6层 和第/nr 7层 分别 是 一个 
长度 为 4096 的 一维 向量 第 8层 是 长度 
为 1000 的 一维 向量 分别 对应 1000个 类别 的 
概率 FCN 将 这 3层 表示 为 卷积 层 卷积 
核 的 大小 通 道数 宽 高 分别为 4096 1 
1 4096 1 1 1000 1 1 所有 的 层 
都是 卷积 层 故 称为 全 卷积 网络 上 采样 
转置 卷积 TensotFlow 转置 卷积 可以 发现 经过 多次 卷积 
还有 pooling 以后 得到 的 图像 越来越 小 分辨率 越来越低 
粗略 的 图像 那么 FCN 是 如何 得到 图像 中 
每一个 像素 的 类别 的 呢 为了 从 这个 分辨率 
低 的 粗略 图像 恢复 到 原图 的 分辨率 FCN 
使用 了 上 采样 例如 经过 5次 卷积 和 pooling 
以后 图像 的 分辨率 依次 缩小 了 2 4 8 
16 32倍 对于 最后 一层 的 输出 图像 需要 进行 
32倍 的 上 采样 以 得到 原图 一样 的 大小 
这个 上 采样 是 通过 反 卷积 deconvolution 实现 的 
另外 补充 一句 上 采样 upsampling 一般 包括 2种 方式 
Resize 如 双 线性插值 直接 缩放 类似于 图像 缩放 这种 
方法 在 原文 中 提到 Deconvolution 也叫 Transposed Convolution 一张 
更为 形象 的 说明 如下 跳跃 结构 对 第 5层 
的 输出 32倍 放大 反卷 积到 原图 大小 得到 的 
结果 还是 不够 精确 一些 细节 无法 恢复 于是 Jonathan 
将 第 4层 的 输出 和第/nr 3层 的 输出 也 
依次 反 卷积 分别 需要 16倍 和 8倍 上 采样 
结果 就 精细 一些 了 其 卷积 过程 类似 image 
经过 多个 conv 和+/nr 一个 max pooling 变为 pool1 feature 
宽 高 变为 1 / 2pool1 feature 再 经过 多个 
conv + 一个 max pooling 变为 pool2 feature 宽 高 
变为 1 / 4pool2 feature 再 经过 多个 conv + 
一个 max pooling 变为 pool3 feature 宽 高 变为 1/8 
. . . . . . 直到 pool5 feature 宽 
高 变为 1/32 相 对应 的 对于 FCN 32s 直接 
对 pool5 feature 进行 32倍 上 采样 获得 32x upsampled 
feature 再 对 32x upsampled feature 每个 点 做 softmax 
prediction 获得 32x upsampled feature prediction 即 分割 图 对于 
FCN 16s 首先 对 pool5 feature 进行 2倍 上 采样 
获得 2x upsampled feature 再把 pool4 feature 和 2x upsampled 
feature 逐点 相加 然后 对 相加 的 feature 进行 16倍 
上 采样 并 softmax prediction 获得 16x upsampled feature prediction 
对于 FCN 8s 首先 进行 pool4 + 2x upsampled feature 
逐点 相加 然后 又 进行 pool3 + 2x upsampled 逐点 
相加 即 进行 更多 次 特征 融合 具体 过程 与 
16s 类似 不再 赘述 下图 是 这个 卷积 和反/nr 卷积 
上 采样 的 过程 下图 是 32倍 16倍 和 8倍 
上 采样 得到 的 结果 的 对比 可以 看到 它们 
得到 的 结果 越来越 精确 4 优点 贡献 和/c 不足/a 
优点/n 和/c 贡献/n 1/m ./i 为/p 深度/ns 学习/v 解决/v 语义/n 
分割/v 提供/v 了/ul 基本/n 思路/n 激发 了 很多 优秀 的 
工作 2 . 输入 图像 大小 没有 限制 结构 灵活 
3 . 更加 高效 节省 时间 和 空间 不足 1 
. 结果 不够 精细 边界 不 清晰 2 . 没有 
充分 考虑到 语义 间 的 上下文 关系 3 . padding 
操作 可能 会 引入 噪声 二 SegNet 基于 FCN 的 
一项 工作 修改 VGG 16 网络 得到 的 语义 分割 
网络 有 两种 SegNet 分别 为 正常 版 与 贝叶斯 
版 同时 SegNet 作者 根据 网络 的 深度 提供 了 
一个 basic 版 浅 网络 1 网络结构 作者 提供 了 
几种 网络结构 上图 就是 通用 结构 对称 的 encode decode 
结构 想 了解 更为 具体 的 实现 建议 查看 开源 
实现 2 创新/v 点/m SegNet/w 的/uj 最大/a 池化层/nr 和上/nr 采样/v 
层/q 不同于/c 通常/d 的/uj 处理/v SegNet 中 使用 最大 池化/nr 
并且 同时 输出 最 大点 的 index 同一 层次 的 
上 采样 根据 index 确定 池化前/nr max 值 的 点 
的 位置 并对 其他 丢失 的 点 做 插值 补充 
一点 tensorflow 对于 SegNet 的 上 采样 方式 并不 支持 
也许 只是 没有 封装 好 而已 可以 手动 实现 不确定 
所以 我 查到 的 实现 一般 就 直接 用 普通 
的 上 采样 了 这样 tf 版本 的 SegNet 结构 
相较 U Net 简单 了 不少 个人感觉 两者 还是 很 
相似 的 有趣/a 的/uj 是/v 带/v 索引/nr 最大/a 池化/nr tf/w 
是/v 有/v 封装/v 好/a 的/uj 接口/v 的/uj 在 nn 包中/nr 
作为 对比 下 左为/nr SegNet 下 右 为 FCN 中的 
上 采样 实现 FCN 的 上 采样 相较 现在 成熟 
的 上 采样 方案 也 略有不同 多加 了 一个 根据 
原始 编码 得来 并 保存 的 y 这 需要 消耗 
额外 的 内存 此外 还有 贝叶斯 SegNet 变种 不太 懂 
就不 画蛇添足 了 三 U NetU Net 是 原作者 参加 
ISBI Challenge 提出 的 一种 分割 网络 能够 适应 很小 
的 训练 集 大约 30张 图 U Net 与 FCN 
都是 很小 的 分割 网络 既 没有 使用 空洞 卷积 
也 没有 后接 CRF 结构 简单 卷积 网络 被 大 
规模 应用 在 分类 任务 中 输出 的 结果 是 
整个 图像 的 类 标签 然而 在 许多 视觉 任务 
尤其 是 生物 医学 图像处理 领域 目标 输出 应该 包括 
目标 类别 的 位置 并且/c 每个/r 像素/n 都/d 应该/v 有类/nr 
标签/n 另外 在 生物 医学 图像 往往 缺少 训练 图片 
所以 Ciresan 等人 训练 了 一个 卷积 神经网络 用 滑动 
窗口 提供 像素 的 周围 区域 patch 作为 输入 来 
预测 每个 像素 的 类 标签 这个 网络 有 两个 
优点 第一 输出 结果 可以 定位 出 目标 类别 的 
位置 第二 由于 输入 的 训练 数据 是 patches 这样 
就 相当于 进行 了 数据 增广 解决 了 生物 医学 
图像 数量 少 的 问题 但是 这个 方法 也 有 
两个 很明显 缺点 第一 它 很慢 因为 这个 网络 必须 
训练 每个 patch 并且 因为 patch 间 的 重叠 有 
很多 的 冗余 冗余 会 造成 什么 影响 呢 卷积 
核 里面 的 W 就是 提取 特征 的 权重 两个 
块 如果 重叠 的 部分 太多 这个 权重 会被 同 
一些 特征 训练 两次 造成 资源 的 浪费 减慢 训练 
时间 和 效率 虽然 说 会 有一些 冗余 训练 集 
大了 准确率 不就 高 了吗 可是 你 这个 是 相同 
的 图片 啊 重叠 的 东西 都是/nr 相同 的 举个 
例子 我 用 一张 相同 的 图片 训练 20次 按照 
这个 意思 也是 增大 了 训练 集 啊 可是 会 
出现 什么 结果 呢 很显然 会 导致 过拟合 也 就是 
对 你 这个 图片 识别 很准 别的/nr 图片 就 不一定 
了 第二 定位 准确性 和 获取 上下文 信息 不可 兼得 
大 的 patches 需要 更多 的 max pooling 层 这样 
减小 了 定位 准确性 为什么 因为 你 是 对 以 
这个 像素 为 中心 的 点 进行 分类 如果 patch 
太大 最后 经过 全 连接 层 的 前 一层 大小 
肯定 是 不变 的 如果 你 patch 大 就 需要 
更多 的 pooling 达到 这个 大小 而 pooling 层 越多 
丢失 信息 的 信息 也 越多 小 的 patches 只能 
看到 很小 的 局部 信息 包含 的 背景 信息 不够 
和 SegNet 格式 极为 相近 不过 其 添加 了 中间 
的 center crop 和 concat 操作 实现 了 不同 层次 
特征 的 upsample 目的 同样 是 使上 采样 的 层 
能够 更多 的 参考 前 面下 采样 中间层 的 信息 
更好 的 达到 还原 的 效果 U Net 的 格式 
也 不复杂 形状 如下 参看 github 开源 实现 不难 复现 
注意 用 好 相关 张量 操作 API 即可 如 concet 
slice 等 值得 注意 的 是 U Net 采用 了 
与 FCN 完全 不同 的 特征 融合 方式 拼接 与 
FCN 逐点 相加 不同 U Net 采用 将 特征 在 
channel 维度 拼接 在 一起 形成 更 厚 的 特征 
所以 语义 分割 网络 在 特征 融 合时 也有 2种 
办法 FCN 式 的 逐点 相加 对应 caffe 的 EltwiseLayer 
层 对应 tensorflow 的 tf . add U Net 式 
的 channel 维度 拼接 融合 对应 caffe 的 ConcatLayer 层 
对应 tensorflow 的 tf . concat 1 使用 全 卷积 
神经网络 全/a 卷积/n 神经/n 网络/n 就是/d 卷积/n 取代/v 了/ul 全/a 
连接/v 层/q 全 连接 层 必须 固定 图像 大 小而 
卷积 不用 所以 这个 策略 使得 你 可以 输入 任意 
尺寸 的 图片 而且 输出 也是 图片 所以 这 是 
一个 端 到 端的 网络 2 左边 的 网络 是 
收缩 路径 使用 卷积 和 maxpooling 3 右边 的 网络 
是 扩张路径 使用 上 采样 产生 的 特征 图 与 
左侧 收缩 路径 对应 层 产生 的 特征 图 进行 
concatenate 操作 pooling 层 会 丢失 图像 信息 和 降低 
图像 分辨率 且 是 不可逆的 操作 对 图像 分割 任务 
有 一些 影响 对 图像 分类 任务 的 影响 不大 
为什么 要 做上 采样 因为 上 采样 可以 补足 一些 
图片 的 信息 但是 信息 补充 的 肯定 不 完全 
所以 还 需要 与 左边 的 分辨率 比 较高 的 
图片 相 连接 起来 直接 复制 过来 再 裁 剪到 
与 上 采样 图片 一样 大小 这就 相当于 在 高分辨率 
和更/nr 抽象 特征 当中 做 一个 折衷 因为 随着 卷积 
次数 增多 提取 的 特征 也 更加 有效 更加 抽象 
上 采样 的 图片 是 经历 多次 卷积 后的/nr 图片 
肯定 是 比较 高效 和 抽象 的 图片 然后 把 
它 与 左边 不怎么 抽象 但 更高 分辨率 的 特征 
图片 进行 连接 4 最后 再 经过 两次 反 卷积 
操作 生成 特征 图 再用 两个 1X1 的 卷积 做 
分类 得到 最后 的 两张 heatmap 例如 第一 张 表示 
的 是 第一 类 的 得分 第二 张 表示 第二类 
的 得分 heatmap 然后 作为 softmax 函数 的 输入 算出 
概率 比 较大 的 softmax 类 选择 它 作为 输入 
给 交叉 熵 进行 反向 传播 训练 四 空洞 卷积 
计算机 视觉 空洞 卷积 池化/nr 操作 增大 了 感受 野 
有助于 实现 分 类网络 但是 池化/nr 操作 在 分割 过程 
中 也 降低 了 分辨率 空洞 卷积 层 则 可以 
在 不 降低 空间维度 的 前提 下 增大 了 相应 
的 感受 野 指数 五 DeepLabv1 面临 问题 在 DCNN 
进行 分割 任务 时 有 两个 瓶颈 一个 是 下 
采样 所 导致 的 信息 丢失 通过 带 孔 卷积 
的 方法 解决 另 一个 是 CNN 空间 不变性 所 
导致 的 边缘 不够 准确 通过 全 连接 的 CRF 
解决 CRF 是 可以 通过 底层 特征 进行 分割 的 
一个 方法 核心 工作 空洞 卷积 计算 的 特征 映射 
更加 密集 + 如何 降低 计算 量 + CRF 作为 
后处理 知乎 文章 FCN 3 DenseCRF Deeplab 使 用带 孔 
算法 空洞 卷积 进行 特征提取 将 VGG16 的 全连 层 
转换 为 卷积 层 将/d 最后/f 两个/m 最大/a 池化层/nr 的/uj 
后的下/nr 采样/v 去掉/v 中间 的 卷积 替换 为 带 孔 
卷积 对于 空洞 卷积 作者 提到 了 两个 实现 方法 
在 卷积 核 中间 加 0 / 先降 采样 然后 
过 正常 卷积 第二 种 方法 计算 速度快 最后 三个 
卷积 层 使用 2倍 的 步长 第一 个 全连 层 
使用 4倍 步长 这样 做 的 好处 是 不 需要 
引入 额外 的 近似算法 感受 野 控制 加速 卷积 网络 
的 密集 计算 将/d VGG16/i 转换/v 为/p 全/a 卷积/n 层/q 
后/f 计算/v 量/n 变得/v 非常/d 大/a 为了 降低 运算 将 
第一 个 全连 层 进行 降 采样 这个 做法 降低 
了 感受 野 的 大小 不是 很懂 CRF 的 具体 
做法 简单 的 原文 的 图 贴上来 感受一下 框架 的 
pipline v2 相较 于 v1 简单 来说 空洞/n 卷积/n +/i 
全/a 连接/v CRF/w +/i ASPP/w 模块/n 主干网络/i 从预/nr 训练/vn 的/uj 
VGG/w 变成/v 了/ul ResNet/w 首先在/i 三个/m 尺度/n 上/f 训练/vn 和/c 
测试/vn 在 给定 的 输入 上以 不同 采样率 的 空洞 
卷积 并行 采样 相当于 以多 个 比例 捕捉 图像 的 
上下文 称为 ASPP atrous spatial pyramid pooling 模块 得到 的 
概率 是 输入 图片 的 八分之一 大小 然后 是 将 
概率 图 进行 双 线性插值 到 原始 输入 图片大小 将 
三个 尺度 的 概率 图 进行 融合 融合 策略 是 
最简单 的 取 最大值 最后/f 将/d 融合/vn 之后/f 的/uj 和/c 
原始/v 输入/v 一样/r 大小/b 的/uj 概率/n 图/n 输入/v 到/v 全/a 
连接/v 条件/n 随/v 机场/n 中/f 细化/n 边缘/n 细节/n 得到/v 最终/d 
的/uj 分割/v 结果/n 训练 的 时候 将 GT 降 采样 
了 8倍 和 CNN 直接 输出 的 概率 图 同样 
的 大小 计算 loss 下面 这张 图 展示 了 不同 
方式 的 上下文 信息 获取 最后 一张 图 是 ASPP 
的 原型 1 . Image Pyramid 将 输入 图片 放缩 
成 不同 比例 分别 应用在 DCNN 上 将 预测 结果 
融合 得到 最终 输出 2 . Encoder Decoder 利用 Encoder 
阶段 的 多 尺度 特征 运用 到 Decoder 阶段 上 
恢复 空间 分辨率 代表 工作 有 FCN SegNet PSPNet 等 
工 3 . Deeper w . Atrous Convolution 使用 空洞 
卷积 4 . Spatial Pyramid Pooling 空间/n 金字塔/nr 池化/nr 具有/v 
不同/a 采样率/v 和/c 多种/m 视野/n 的/uj 卷积/n 核/n 能够 以多 
尺度 捕捉 对象 v3 第三版 相对于 第二 版 的 改动 
不是 很大 主要 是 借鉴 了 下面 的 两篇 论文 
的 思想 然后 分别 对 之前 的 空洞 卷积 和 
ASPP 模块 就行了 改进 然后 整体 加入 了 BN 需要 
注意 的 是从 本 版本 开始 已经 不要 CRF 进行 
后 处理 了 Understanding Convolution for Semantic e g m 
e n t a t i o n P y 
r a m i d Scene Parsing Network 另外 文章 
指出 了 在 训练 的 时候 将 GT 应该 保持 
不动 将 概率 图 插值 之后 再 进行 计算 loss 
这样 不会 导致 金 标准 在 降 采样 过程 中 
丢失 细节 毕竟 8倍 的 降 采样 还是 很 严重 
的 v3 + 鉴于 对 最后 的 概率 图 依然 
使用 大 倍数 的 双 线性插值 恢复 到 与 原图 
一样 的 大小 还是 过于 简单 了 因此 在 这个 
版本 中 增加 了 一个 恢复 细节 的 解码器 部分 
A 是 aspp 结构 其中 8x 的 上 采样 可以 
看做 是 一个 解码器 B 是 编解码 结构 它 集合 
了 高层 和 底层 的 特征 C 就是 本文 采取 
的 结构 下图 展示 了 具体 的 网络 表示 该 
框架 参考 了 spatial pyramid pooling SPP module 和 encoder 
decoder 两种 形式 的 分割 框架 前一种 就是 PSPNet 那 
一款 后 一种 更 像是 SegNet 的 做法 ASPP 方法 
的 优点 是 该种 结构 可以 提取 比较 dense 的 
特征 因为 参考 了 不同 尺度 的 feature 并且 atrous 
convolution 的 使用 加强 了 提取 dense 特征 的 能力 
但是 在 该种 方法 中 由于 pooling 和有 stride 的 
conv 的 存在 使得 分割 目标 的 边界 信息 丢失 
严重 Encoder Decoder 方法 的 decoder 中 就 可以 起到 
修复 尖锐 物体 边界 的 作用 关于 Encoder 中 卷积 
的 改进 DeepLab V3 + 效仿 了 Xception 中 使用 
的 depthwise separable convolution 在 DeepLab V3 的 结构 中 
使用 了 atrous depthwise separable convolution 降低 了 计算 量 
的 同时 保持 了 相同 或 更好 的 效果 Decoder 
的 设计 2.1 . Encoder 提 取出 的 特征 首先 
被 x4 上 采样 称之为 F1 2.2 . Encoder 中 
提取 出来 的 与 F1 同 尺度 的 特征 F2 
先 进行 1x1 卷积 降低 通 道数 得到 F2 再 
进行 F1 和 F2 的 concatenation 得到 F3 为什么 要 
进行 通道 降 维 因为/c 在/p encoder/w 中/f 这些/r 尺度/n 
的/uj 特征/n 通常/d 通/v 道数/n 有/v 256/m 或者/c 512个/mq 而 
encoder 最后 提取 出来 的 特征 通 道数 没有 这么 
多 如果 不 进行 降 维 就 进行 concate 的话 
无形之中 加大 了 F2 的 权重 加大 了 网络 的 
训练 难度 2.3 . 对 F3 进行 常规 的 3x3convolution 
微调 特征 最后 直接 x4upsample 得到 分割 结果 总结 一下 
CNN 图像 语义 分割 也就 基本上 是 这个 套路 下 
采样 + 上 采样 Convlution + Deconvlution ／ Resize 多 
尺度 特征 融合 特征 逐点 相加 ／ 特征 channel 维度 
拼接 获得 像素 级别 的 segement map 对 每 一个 
像素点 进行 判断 类别 推荐 一个 语义 分割 专栏 作者 对 本 领域 的 
很多 论文 都 进行 了 整理 语义 分割 刷 怪 
进阶 而 截止 目前 CNN 已经 在 图像 分类 分 
方面 取得 了 巨大 的 成就 涌现出 如 VGG 和 
Resnet 等 网络结构 并在 ImageNet 中 取得 了 好成绩 CNN 
的 强大 之处 在于 它 的 多层 结构 能 自动 
学习 特征 并且 可以 学习 到 多个 层次 的 特征 
较浅 的 卷积 层 感知 域 较小 学习 到 一些 
局部 区域 的 特征 较深 的 卷积 层 具有 较大 
的 感知 域 能够 学习 到 更加 抽象 一些 的 
特征 这些 深层 抽象 特征 对 物体 的 大小 位置 
和 方向 等 敏感性 更低 从而 有助于 分类 性能 的 
提高 这些 抽象 的 特征 对 分类 很有帮助 可以 很好 
地 判断 出 一幅 图像 中 包含 什么 类别 的 
物体 也 就是说 图像 分类 是 图像 级别 任务 参考 
图像 语义 分割 入门 与 分类 不同 的 是 语义 
分割 需要 判断 图像 每个 像素点 的 类别 进行 精确 
分割 图像 语义 分割 是 像素 级别 的 任务 但是 
由于 CNN 在 进行 convolution 和 pooling 过程 中 丢失 
了 图像 细节 即 feature map size 逐渐 变小 所以 
不能 很好 地 指出 物体 的 具体 轮廓 指出 每个 
像素 具体 属于 哪个 物体 无法 做到 精确 的 分割 
针对 这个 问题 Jonathan Long 等人 提出 了 Fully Convolutional 
Networks FCN 用于 图像 语义 分割 自从 提出 后 FCN 
已经 成为 语义 分割 的 基本 框架 后续 算法 其实 
都是 在 这个 框架 中 改进 而来 注意 本文 仅对 
基于 深度 学习 的 经典 语义 分割 成果 进行 梳理 
之所以 说 是 经典 是 因为 本文 几乎 没有 涉及 
18年 及 之后 的 最新 进展 故 标题 也 说 
了 只是 入门 基于 深度 学习 的 语义 分割 一 
FCN 对于 一般 的 分类 CNN 网络 如 VGG 和 
Resnet 都会 在 网络 的 最后 加入 一些 全 连接 
层 经过 softmax 后就/nr 可以 获得 类别 概率 信息 但是 
这个 概率 信息 是 1 维 的 即 只能 标识 
整个 图片 的 类别 不能 标识 每个 像素点 的 类别 
所以/c 这种/r 全/a 连接/v 方法/n 不/d 适用/v 于/p 图像/n 分割/v 
而/c FCN/w 提出/v 可以/c 把/p 后面/f 几个/m 全/a 连接/v 都/d 
换成/v 卷积/n 这样 就 可以 获得 一张 2 维 的 
feature map 后接 softmax 获得 每个 像素点 的 分类信息 从而 
解决 了 分割 问题 1 网络 特点 全 卷积 Convolutional 
上 采样 Upsample 跳跃 结构 Skip Layer 2 网络结构 3 
原理/n 说明/v 全/a 卷积/n FCN/w 将/d 传统/n CNN/w 中的/i 全/a 
连接/v 层/q 转化/v 成/n 一个/m 个/q 的/uj 卷积/n 层/q 如下 
图 所示 在 传统 的 CNN 结构 中 前 5层 
是 卷积 层 第 6层 和第/nr 7层 分别 是 一个 
长度 为 4096 的 一维 向量 第 8层 是 长度 
为 1000 的 一维 向量 分别 对应 1000个 类别 的 
概率 FCN 将 这 3层 表示 为 卷积 层 卷积 
核 的 大小 通 道数 宽 高 分别为 4096 1 
1 4096 1 1 1000 1 1 所有 的 层 
都是 卷积 层 故 称为 全 卷积 网络 上 采样 
转置 卷积 TensotFlow 转置 卷积 可以 发现 经过 多次 卷积 
还有 pooling 以后 得到 的 图像 越来越 小 分辨率 越来越低 
粗略 的 图像 那么 FCN 是 如何 得到 图像 中 
每一个 像素 的 类别 的 呢 为了 从 这个 分辨率 
低 的 粗略 图像 恢复 到 原图 的 分辨率 FCN 
使用 了 上 采样 例如 经过 5次 卷积 和 pooling 
以后 图像 的 分辨率 依次 缩小 了 2 4 8 
16 32倍 对于 最后 一层 的 输出 图像 需要 进行 
32倍 的 上 采样 以 得到 原图 一样 的 大小 
这个 上 采样 是 通过 反 卷积 deconvolution 实现 的 
另外 补充 一句 上 采样 upsampling 一般 包括 2种 方式 
Resize 如 双 线性插值 直接 缩放 类似于 图像 缩放 这种 
方法 在 原文 中 提到 Deconvolution 也叫 Transposed Convolution 一张 
更为 形象 的 说明 如下 跳跃 结构 对 第 5层 
的 输出 32倍 放大 反卷 积到 原图 大小 得到 的 
结果 还是 不够 精确 一些 细节 无法 恢复 于是 Jonathan 
将 第 4层 的 输出 和第/nr 3层 的 输出 也 
依次 反 卷积 分别 需要 16倍 和 8倍 上 采样 
结果 就 精细 一些 了 其 卷积 过程 类似 image 
经过 多个 conv 和+/nr 一个 max pooling 变为 pool1 feature 
宽 高 变为 1 / 2pool1 feature 再 经过 多个 
conv + 一个 max pooling 变为 pool2 feature 宽 高 
变为 1 / 4pool2 feature 再 经过 多个 conv + 
一个 max pooling 变为 pool3 feature 宽 高 变为 1/8 
. . . . . . 直到 pool5 feature 宽 
高 变为 1/32 相 对应 的 对于 FCN 32s 直接 
对 pool5 feature 进行 32倍 上 采样 获得 32x upsampled 
feature 再 对 32x upsampled feature 每个 点 做 softmax 
prediction 获得 32x upsampled feature prediction 即 分割 图 对于 
FCN 16s 首先 对 pool5 feature 进行 2倍 上 采样 
获得 2x upsampled feature 再把 pool4 feature 和 2x upsampled 
feature 逐点 相加 然后 对 相加 的 feature 进行 16倍 
上 采样 并 softmax prediction 获得 16x upsampled feature prediction 
对于 FCN 8s 首先 进行 pool4 + 2x upsampled feature 
逐点 相加 然后 又 进行 pool3 + 2x upsampled 逐点 
相加 即 进行 更多 次 特征 融合 具体 过程 与 
16s 类似 不再 赘述 下图 是 这个 卷积 和反/nr 卷积 
上 采样 的 过程 下图 是 32倍 16倍 和 8倍 
上 采样 得到 的 结果 的 对比 可以 看到 它们 
得到 的 结果 越来越 精确 4 优点 贡献 和/c 不足/a 
优点/n 和/c 贡献/n 1/m ./i 为/p 深度/ns 学习/v 解决/v 语义/n 
分割/v 提供/v 了/ul 基本/n 思路/n 激发 了 很多 优秀 的 
工作 2 . 输入 图像 大小 没有 限制 结构 灵活 
3 . 更加 高效 节省 时间 和 空间 不足 1 
. 结果 不够 精细 边界 不 清晰 2 . 没有 
充分 考虑到 语义 间 的 上下文 关系 3 . padding 
操作 可能 会 引入 噪声 二 SegNet 基于 FCN 的 
一项 工作 修改 VGG 16 网络 得到 的 语义 分割 
网络 有 两种 SegNet 分别 为 正常 版 与 贝叶斯 
版 同时 SegNet 作者 根据 网络 的 深度 提供 了 
一个 basic 版 浅 网络 1 网络结构 作者 提供 了 
几种 网络结构 上图 就是 通用 结构 对称 的 encode decode 
结构 想 了解 更为 具体 的 实现 建议 查看 开源 
实现 2 创新/v 点/m SegNet/w 的/uj 最大/a 池化层/nr 和上/nr 采样/v 
层/q 不同于/c 通常/d 的/uj 处理/v SegNet 中 使用 最大 池化/nr 
并且 同时 输出 最 大点 的 index 同一 层次 的 
上 采样 根据 index 确定 池化前/nr max 值 的 点 
的 位置 并对 其他 丢失 的 点 做 插值 补充 
一点 tensorflow 对于 SegNet 的 上 采样 方式 并不 支持 
也许 只是 没有 封装 好 而已 可以 手动 实现 不确定 
所以 我 查到 的 实现 一般 就 直接 用 普通 
的 上 采样 了 这样 tf 版本 的 SegNet 结构 
相较 U Net 简单 了 不少 个人感觉 两者 还是 很 
相似 的 有趣/a 的/uj 是/v 带/v 索引/nr 最大/a 池化/nr tf/w 
是/v 有/v 封装/v 好/a 的/uj 接口/v 的/uj 在 nn 包中/nr 
作为 对比 下 左为/nr SegNet 下 右 为 FCN 中的 
上 采样 实现 FCN 的 上 采样 相较 现在 成熟 
的 上 采样 方案 也 略有不同 多加 了 一个 根据 
原始 编码 得来 并 保存 的 y 这 需要 消耗 
额外 的 内存 此外 还有 贝叶斯 SegNet 变种 不太 懂 
就不 画蛇添足 了 三 U NetU Net 是 原作者 参加 
ISBI Challenge 提出 的 一种 分割 网络 能够 适应 很小 
的 训练 集 大约 30张 图 U Net 与 FCN 
都是 很小 的 分割 网络 既 没有 使用 空洞 卷积 
也 没有 后接 CRF 结构 简单 卷积 网络 被 大 
规模 应用 在 分类 任务 中 输出 的 结果 是 
整个 图像 的 类 标签 然而 在 许多 视觉 任务 
尤其 是 生物 医学 图像处理 领域 目标 输出 应该 包括 
目标 类别 的 位置 并且/c 每个/r 像素/n 都/d 应该/v 有类/nr 
标签/n 另外 在 生物 医学 图像 往往 缺少 训练 图片 
所以 Ciresan 等人 训练 了 一个 卷积 神经网络 用 滑动 
窗口 提供 像素 的 周围 区域 patch 作为 输入 来 
预测 每个 像素 的 类 标签 这个 网络 有 两个 
优点 第一 输出 结果 可以 定位 出 目标 类别 的 
位置 第二 由于 输入 的 训练 数据 是 patches 这样 
就 相当于 进行 了 数据 增广 解决 了 生物 医学 
图像 数量 少 的 问题 但是 这个 方法 也 有 
两个 很明显 缺点 第一 它 很慢 因为 这个 网络 必须 
训练 每个 patch 并且 因为 patch 间 的 重叠 有 
很多 的 冗余 冗余 会 造成 什么 影响 呢 卷积 
核 里面 的 W 就是 提取 特征 的 权重 两个 
块 如果 重叠 的 部分 太多 这个 权重 会被 同 
一些 特征 训练 两次 造成 资源 的 浪费 减慢 训练 
时间 和 效率 虽然 说 会 有一些 冗余 训练 集 
大了 准确率 不就 高 了吗 可是 你 这个 是 相同 
的 图片 啊 重叠 的 东西 都是/nr 相同 的 举个 
例子 我 用 一张 相同 的 图片 训练 20次 按照 
这个 意思 也是 增大 了 训练 集 啊 可是 会 
出现 什么 结果 呢 很显然 会 导致 过拟合 也 就是 
对 你 这个 图片 识别 很准 别的/nr 图片 就 不一定 
了 第二 定位 准确性 和 获取 上下文 信息 不可 兼得 
大 的 patches 需要 更多 的 max pooling 层 这样 
减小 了 定位 准确性 为什么 因为 你 是 对 以 
这个 像素 为 中心 的 点 进行 分类 如果 patch 
太大 最后 经过 全 连接 层 的 前 一层 大小 
肯定 是 不变 的 如果 你 patch 大 就 需要 
更多 的 pooling 达到 这个 大小 而 pooling 层 越多 
丢失 信息 的 信息 也 越多 小 的 patches 只能 
看到 很小 的 局部 信息 包含 的 背景 信息 不够 
和 SegNet 格式 极为 相近 不过 其 添加 了 中间 
的 center crop 和 concat 操作 实现 了 不同 层次 
特征 的 upsample 目的 同样 是 使上 采样 的 层 
能够 更多 的 参考 前 面下 采样 中间层 的 信息 
更好 的 达到 还原 的 效果 U Net 的 格式 
也 不复杂 形状 如下 参看 github 开源 实现 不难 复现 
注意 用 好 相关 张量 操作 API 即可 如 concet 
slice 等 值得 注意 的 是 U Net 采用 了 
与 FCN 完全 不同 的 特征 融合 方式 拼接 与 
FCN 逐点 相加 不同 U Net 采用 将 特征 在 
channel 维度 拼接 在 一起 形成 更 厚 的 特征 
所以 语义 分割 网络 在 特征 融 合时 也有 2种 
办法 FCN 式 的 逐点 相加 对应 caffe 的 EltwiseLayer 
层 对应 tensorflow 的 tf . add U Net 式 
的 channel 维度 拼接 融合 对应 caffe 的 ConcatLayer 层 
对应 tensorflow 的 tf . concat 1 使用 全 卷积 
神经网络 全/a 卷积/n 神经/n 网络/n 就是/d 卷积/n 取代/v 了/ul 全/a 
连接/v 层/q 全 连接 层 必须 固定 图像 大 小而 
卷积 不用 所以 这个 策略 使得 你 可以 输入 任意 
尺寸 的 图片 而且 输出 也是 图片 所以 这 是 
一个 端 到 端的 网络 2 左边 的 网络 是 
收缩 路径 使用 卷积 和 maxpooling 3 右边 的 网络 
是 扩张路径 使用 上 采样 产生 的 特征 图 与 
左侧 收缩 路径 对应 层 产生 的 特征 图 进行 
concatenate 操作 pooling 层 会 丢失 图像 信息 和 降低 
图像 分辨率 且 是 不可逆的 操作 对 图像 分割 任务 
有 一些 影响 对 图像 分类 任务 的 影响 不大 
为什么 要 做上 采样 因为 上 采样 可以 补足 一些 
图片 的 信息 但是 信息 补充 的 肯定 不 完全 
所以 还 需要 与 左边 的 分辨率 比 较高 的 
图片 相 连接 起来 直接 复制 过来 再 裁 剪到 
与 上 采样 图片 一样 大小 这就 相当于 在 高分辨率 
和更/nr 抽象 特征 当中 做 一个 折衷 因为 随着 卷积 
次数 增多 提取 的 特征 也 更加 有效 更加 抽象 
上 采样 的 图片 是 经历 多次 卷积 后的/nr 图片 
肯定 是 比较 高效 和 抽象 的 图片 然后 把 
它 与 左边 不怎么 抽象 但 更高 分辨率 的 特征 
图片 进行 连接 4 最后 再 经过 两次 反 卷积 
操作 生成 特征 图 再用 两个 1X1 的 卷积 做 
分类 得到 最后 的 两张 heatmap 例如 第一 张 表示 
的 是 第一 类 的 得分 第二 张 表示 第二类 
的 得分 heatmap 然后 作为 softmax 函数 的 输入 算出 
概率 比 较大 的 softmax 类 选择 它 作为 输入 
给 交叉 熵 进行 反向 传播 训练 四 空洞 卷积 
计算机 视觉 空洞 卷积 池化/nr 操作 增大 了 感受 野 
有助于 实现 分 类网络 但是 池化/nr 操作 在 分割 过程 
中 也 降低 了 分辨率 空洞 卷积 层 则 可以 
在 不 降低 空间维度 的 前提 下 增大 了 相应 
的 感受 野 指数 五 DeepLabv1 面临 问题 在 DCNN 
进行 分割 任务 时 有 两个 瓶颈 一个 是 下 
采样 所 导致 的 信息 丢失 通过 带 孔 卷积 
的 方法 解决 另 一个 是 CNN 空间 不变性 所 
导致 的 边缘 不够 准确 通过 全 连接 的 CRF 
解决 CRF 是 可以 通过 底层 特征 进行 分割 的 
一个 方法 核心 工作 空洞 卷积 计算 的 特征 映射 
更加 密集 + 如何 降低 计算 量 + CRF 作为 
后处理 知乎 文章 FCN 3 DenseCRF Deeplab 使 用带 孔 
算法 空洞 卷积 进行 特征提取 将 VGG16 的 全连 层 
转换 为 卷积 层 将/d 最后/f 两个/m 最大/a 池化层/nr 的/uj 
后的下/nr 采样/v 去掉/v 中间 的 卷积 替换 为 带 孔 
卷积 对于 空洞 卷积 作者 提到 了 两个 实现 方法 
在 卷积 核 中间 加 0 / 先降 采样 然后 
过 正常 卷积 第二 种 方法 计算 速度快 最后 三个 
卷积 层 使用 2倍 的 步长 第一 个 全连 层 
使用 4倍 步长 这样 做 的 好处 是 不 需要 
引入 额外 的 近似算法 感受 野 控制 加速 卷积 网络 
的 密集 计算 将/d VGG16/i 转换/v 为/p 全/a 卷积/n 层/q 
后/f 计算/v 量/n 变得/v 非常/d 大/a 为了 降低 运算 将 
第一 个 全连 层 进行 降 采样 这个 做法 降低 
了 感受 野 的 大小 不是 很懂 CRF 的 具体 
做法 简单 的 原文 的 图 贴上来 感受一下 框架 的 
pipline v2 相较 于 v1 简单 来说 空洞/n 卷积/n +/i 
全/a 连接/v CRF/w +/i ASPP/w 模块/n 主干网络/i 从预/nr 训练/vn 的/uj 
VGG/w 变成/v 了/ul ResNet/w 首先在/i 三个/m 尺度/n 上/f 训练/vn 和/c 
测试/vn 在 给定 的 输入 上以 不同 采样率 的 空洞 
卷积 并行 采样 相当于 以多 个 比例 捕捉 图像 的 
上下文 称为 ASPP atrous spatial pyramid pooling 模块 得到 的 
概率 是 输入 图片 的 八分之一 大小 然后 是 将 
概率 图 进行 双 线性插值 到 原始 输入 图片大小 将 
三个 尺度 的 概率 图 进行 融合 融合 策略 是 
最简单 的 取 最大值 最后/f 将/d 融合/vn 之后/f 的/uj 和/c 
原始/v 输入/v 一样/r 大小/b 的/uj 概率/n 图/n 输入/v 到/v 全/a 
连接/v 条件/n 随/v 机场/n 中/f 细化/n 边缘/n 细节/n 得到/v 最终/d 
的/uj 分割/v 结果/n 训练 的 时候 将 GT 降 采样 
了 8倍 和 CNN 直接 输出 的 概率 图 同样 
的 大小 计算 loss 下面 这张 图 展示 了 不同 
方式 的 上下文 信息 获取 最后 一张 图 是 ASPP 
的 原型 1 . Image Pyramid 将 输入 图片 放缩 
成 不同 比例 分别 应用在 DCNN 上 将 预测 结果 
融合 得到 最终 输出 2 . Encoder Decoder 利用 Encoder 
阶段 的 多 尺度 特征 运用 到 Decoder 阶段 上 
恢复 空间 分辨率 代表 工作 有 FCN SegNet PSPNet 等 
工 3 . Deeper w . Atrous Convolution 使用 空洞 
卷积 4 . Spatial Pyramid Pooling 空间/n 金字塔/nr 池化/nr 具有/v 
不同/a 采样率/v 和/c 多种/m 视野/n 的/uj 卷积/n 核/n 能够 以多 
尺度 捕捉 对象 v3 第三版 相对于 第二 版 的 改动 
不是 很大 主要 是 借鉴 了 下面 的 两篇 论文 
的 思想 然后 分别 对 之前 的 空洞 卷积 和 
ASPP 模块 就行了 改进 然后 整体 加入 了 BN 需要 
注意 的 是从 本 版本 开始 已经 不要 CRF 进行 
后 处理 了 Understanding Convolution for Semantic e g m 
e n t a t i o n P y 
r a m i d Scene Parsing Network 另外 文章 
指出 了 在 训练 的 时候 将 GT 应该 保持 
不动 将 概率 图 插值 之后 再 进行 计算 loss 
这样 不会 导致 金 标准 在 降 采样 过程 中 
丢失 细节 毕竟 8倍 的 降 采样 还是 很 严重 
的 v3 + 鉴于 对 最后 的 概率 图 依然 
使用 大 倍数 的 双 线性插值 恢复 到 与 原图 
一样 的 大小 还是 过于 简单 了 因此 在 这个 
版本 中 增加 了 一个 恢复 细节 的 解码器 部分 
A 是 aspp 结构 其中 8x 的 上 采样 可以 
看做 是 一个 解码器 B 是 编解码 结构 它 集合 
了 高层 和 底层 的 特征 C 就是 本文 采取 
的 结构 下图 展示 了 具体 的 网络 表示 该 
框架 参考 了 spatial pyramid pooling SPP module 和 encoder 
decoder 两种 形式 的 分割 框架 前一种 就是 PSPNet 那 
一款 后 一种 更 像是 SegNet 的 做法 ASPP 方法 
的 优点 是 该种 结构 可以 提取 比较 dense 的 
特征 因为 参考 了 不同 尺度 的 feature 并且 atrous 
convolution 的 使用 加强 了 提取 dense 特征 的 能力 
但是 在 该种 方法 中 由于 pooling 和有 stride 的 
conv 的 存在 使得 分割 目标 的 边界 信息 丢失 
严重 Encoder Decoder 方法 的 decoder 中 就 可以 起到 
修复 尖锐 物体 边界 的 作用 关于 Encoder 中 卷积 
的 改进 DeepLab V3 + 效仿 了 Xception 中 使用 
的 depthwise separable convolution 在 DeepLab V3 的 结构 中 
使用 了 atrous depthwise separable convolution 降低 了 计算 量 
的 同时 保持 了 相同 或 更好 的 效果 Decoder 
的 设计 2.1 . Encoder 提 取出 的 特征 首先 
被 x4 上 采样 称之为 F1 2.2 . Encoder 中 
提取 出来 的 与 F1 同 尺度 的 特征 F2 
先 进行 1x1 卷积 降低 通 道数 得到 F2 再 
进行 F1 和 F2 的 concatenation 得到 F3 为什么 要 
进行 通道 降 维 因为/c 在/p encoder/w 中/f 这些/r 尺度/n 
的/uj 特征/n 通常/d 通/v 道数/n 有/v 256/m 或者/c 512个/mq 而 
encoder 最后 提取 出来 的 特征 通 道数 没有 这么 
多 如果 不 进行 降 维 就 进行 concate 的话 
无形之中 加大 了 F2 的 权重 加大 了 网络 的 
训练 难度 2.3 . 对 F3 进行 常规 的 3x3convolution 
微调 特征 最后 直接 x4upsample 得到 分割 结果 总结 一下 
CNN 图像 语义 分割 也就 基本上 是 这个 套路 下 
采样 + 上 采样 Convlution + Deconvlution ／ Resize 多 
尺度 特征 融合 特征 逐点 相加 ／ 特征 channel 维度 
拼接 获得 像素 级别 的 segement map 对 每 一个 
像素点 进行 判断 类别 推荐 一个 语义 分割 专栏 作者 对 本 领域 的 
很多 论文 都 进行 了 整理 语义 分割 刷 怪 
进阶 而 截止 目前 CNN 已经 在 图像 分类 分 
方面 取得 了 巨大 的 成就 涌现出 如 VGG 和 
Resnet 等 网络结构 并在 ImageNet 中 取得 了 好成绩 CNN 
的 强大 之处 在于 它 的 多层 结构 能 自动 
学习 特征 并且 可以 学习 到 多个 层次 的 特征 
较浅 的 卷积 层 感知 域 较小 学习 到 一些 
局部 区域 的 特征 较深 的 卷积 层 具有 较大 
的 感知 域 能够 学习 到 更加 抽象 一些 的 
特征 这些 深层 抽象 特征 对 物体 的 大小 位置 
和 方向 等 敏感性 更低 从而 有助于 分类 性能 的 
提高 这些 抽象 的 特征 对 分类 很有帮助 可以 很好 
地 判断 出 一幅 图像 中 包含 什么 类别 的 
物体 也 就是说 图像 分类 是 图像 级别 任务 参考 
图像 语义 分割 入门 与 分类 不同 的 是 语义 
分割 需要 判断 图像 每个 像素点 的 类别 进行 精确 
分割 图像 语义 分割 是 像素 级别 的 任务 但是 
由于 CNN 在 进行 convolution 和 pooling 过程 中 丢失 
了 图像 细节 即 feature map size 逐渐 变小 所以 
不能 很好 地 指出 物体 的 具体 轮廓 指出 每个 
像素 具体 属于 哪个 物体 无法 做到 精确 的 分割 
针对 这个 问题 Jonathan Long 等人 提出 了 Fully Convolutional 
Networks FCN 用于 图像 语义 分割 自从 提出 后 FCN 
已经 成为 语义 分割 的 基本 框架 后续 算法 其实 
都是 在 这个 框架 中 改进 而来 注意 本文 仅对 
基于 深度 学习 的 经典 语义 分割 成果 进行 梳理 
之所以 说 是 经典 是 因为 本文 几乎 没有 涉及 
18年 及 之后 的 最新 进展 故 标题 也 说 
了 只是 入门 基于 深度 学习 的 语义 分割 一 
FCN 对于 一般 的 分类 CNN 网络 如 VGG 和 
Resnet 都会 在 网络 的 最后 加入 一些 全 连接 
层 经过 softmax 后就/nr 可以 获得 类别 概率 信息 但是 
这个 概率 信息 是 1 维 的 即 只能 标识 
整个 图片 的 类别 不能 标识 每个 像素点 的 类别 
所以/c 这种/r 全/a 连接/v 方法/n 不/d 适用/v 于/p 图像/n 分割/v 
而/c FCN/w 提出/v 可以/c 把/p 后面/f 几个/m 全/a 连接/v 都/d 
换成/v 卷积/n 这样 就 可以 获得 一张 2 维 的 
feature map 后接 softmax 获得 每个 像素点 的 分类信息 从而 
解决 了 分割 问题 1 网络 特点 全 卷积 Convolutional 
上 采样 Upsample 跳跃 结构 Skip Layer 2 网络结构 3 
原理/n 说明/v 全/a 卷积/n FCN/w 将/d 传统/n CNN/w 中的/i 全/a 
连接/v 层/q 转化/v 成/n 一个/m 个/q 的/uj 卷积/n 层/q 如下 
图 所示 在 传统 的 CNN 结构 中 前 5层 
是 卷积 层 第 6层 和第/nr 7层 分别 是 一个 
长度 为 4096 的 一维 向量 第 8层 是 长度 
为 1000 的 一维 向量 分别 对应 1000个 类别 的 
概率 FCN 将 这 3层 表示 为 卷积 层 卷积 
核 的 大小 通 道数 宽 高 分别为 4096 1 
1 4096 1 1 1000 1 1 所有 的 层 
都是 卷积 层 故 称为 全 卷积 网络 上 采样 
转置 卷积 TensotFlow 转置 卷积 可以 发现 经过 多次 卷积 
还有 pooling 以后 得到 的 图像 越来越 小 分辨率 越来越低 
粗略 的 图像 那么 FCN 是 如何 得到 图像 中 
每一个 像素 的 类别 的 呢 为了 从 这个 分辨率 
低 的 粗略 图像 恢复 到 原图 的 分辨率 FCN 
使用 了 上 采样 例如 经过 5次 卷积 和 pooling 
以后 图像 的 分辨率 依次 缩小 了 2 4 8 
16 32倍 对于 最后 一层 的 输出 图像 需要 进行 
32倍 的 上 采样 以 得到 原图 一样 的 大小 
这个 上 采样 是 通过 反 卷积 deconvolution 实现 的 
另外 补充 一句 上 采样 upsampling 一般 包括 2种 方式 
Resize 如 双 线性插值 直接 缩放 类似于 图像 缩放 这种 
方法 在 原文 中 提到 Deconvolution 也叫 Transposed Convolution 一张 
更为 形象 的 说明 如下 跳跃 结构 对 第 5层 
的 输出 32倍 放大 反卷 积到 原图 大小 得到 的 
结果 还是 不够 精确 一些 细节 无法 恢复 于是 Jonathan 
将 第 4层 的 输出 和第/nr 3层 的 输出 也 
依次 反 卷积 分别 需要 16倍 和 8倍 上 采样 
结果 就 精细 一些 了 其 卷积 过程 类似 image 
经过 多个 conv 和+/nr 一个 max pooling 变为 pool1 feature 
宽 高 变为 1 / 2pool1 feature 再 经过 多个 
conv + 一个 max pooling 变为 pool2 feature 宽 高 
变为 1 / 4pool2 feature 再 经过 多个 conv + 
一个 max pooling 变为 pool3 feature 宽 高 变为 1/8 
. . . . . . 直到 pool5 feature 宽 
高 变为 1/32 相 对应 的 对于 FCN 32s 直接 
对 pool5 feature 进行 32倍 上 采样 获得 32x upsampled 
feature 再 对 32x upsampled feature 每个 点 做 softmax 
prediction 获得 32x upsampled feature prediction 即 分割 图 对于 
FCN 16s 首先 对 pool5 feature 进行 2倍 上 采样 
获得 2x upsampled feature 再把 pool4 feature 和 2x upsampled 
feature 逐点 相加 然后 对 相加 的 feature 进行 16倍 
上 采样 并 softmax prediction 获得 16x upsampled feature prediction 
对于 FCN 8s 首先 进行 pool4 + 2x upsampled feature 
逐点 相加 然后 又 进行 pool3 + 2x upsampled 逐点 
相加 即 进行 更多 次 特征 融合 具体 过程 与 
16s 类似 不再 赘述 下图 是 这个 卷积 和反/nr 卷积 
上 采样 的 过程 下图 是 32倍 16倍 和 8倍 
上 采样 得到 的 结果 的 对比 可以 看到 它们 
得到 的 结果 越来越 精确 4 优点 贡献 和/c 不足/a 
优点/n 和/c 贡献/n 1/m ./i 为/p 深度/ns 学习/v 解决/v 语义/n 
分割/v 提供/v 了/ul 基本/n 思路/n 激发 了 很多 优秀 的 
工作 2 . 输入 图像 大小 没有 限制 结构 灵活 
3 . 更加 高效 节省 时间 和 空间 不足 1 
. 结果 不够 精细 边界 不 清晰 2 . 没有 
充分 考虑到 语义 间 的 上下文 关系 3 . padding 
操作 可能 会 引入 噪声 二 SegNet 基于 FCN 的 
一项 工作 修改 VGG 16 网络 得到 的 语义 分割 
网络 有 两种 SegNet 分别 为 正常 版 与 贝叶斯 
版 同时 SegNet 作者 根据 网络 的 深度 提供 了 
一个 basic 版 浅 网络 1 网络结构 作者 提供 了 
几种 网络结构 上图 就是 通用 结构 对称 的 encode decode 
结构 想 了解 更为 具体 的 实现 建议 查看 开源 
实现 2 创新/v 点/m SegNet/w 的/uj 最大/a 池化层/nr 和上/nr 采样/v 
层/q 不同于/c 通常/d 的/uj 处理/v SegNet 中 使用 最大 池化/nr 
并且 同时 输出 最 大点 的 index 同一 层次 的 
上 采样 根据 index 确定 池化前/nr max 值 的 点 
的 位置 并对 其他 丢失 的 点 做 插值 补充 
一点 tensorflow 对于 SegNet 的 上 采样 方式 并不 支持 
也许 只是 没有 封装 好 而已 可以 手动 实现 不确定 
所以 我 查到 的 实现 一般 就 直接 用 普通 
的 上 采样 了 这样 tf 版本 的 SegNet 结构 
相较 U Net 简单 了 不少 个人感觉 两者 还是 很 
相似 的 有趣/a 的/uj 是/v 带/v 索引/nr 最大/a 池化/nr tf/w 
是/v 有/v 封装/v 好/a 的/uj 接口/v 的/uj 在 nn 包中/nr 
作为 对比 下 左为/nr SegNet 下 右 为 FCN 中的 
上 采样 实现 FCN 的 上 采样 相较 现在 成熟 
的 上 采样 方案 也 略有不同 多加 了 一个 根据 
原始 编码 得来 并 保存 的 y 这 需要 消耗 
额外 的 内存 此外 还有 贝叶斯 SegNet 变种 不太 懂 
就不 画蛇添足 了 三 U NetU Net 是 原作者 参加 
ISBI Challenge 提出 的 一种 分割 网络 能够 适应 很小 
的 训练 集 大约 30张 图 U Net 与 FCN 
都是 很小 的 分割 网络 既 没有 使用 空洞 卷积 
也 没有 后接 CRF 结构 简单 卷积 网络 被 大 
规模 应用 在 分类 任务 中 输出 的 结果 是 
整个 图像 的 类 标签 然而 在 许多 视觉 任务 
尤其 是 生物 医学 图像处理 领域 目标 输出 应该 包括 
目标 类别 的 位置 并且/c 每个/r 像素/n 都/d 应该/v 有类/nr 
标签/n 另外 在 生物 医学 图像 往往 缺少 训练 图片 
所以 Ciresan 等人 训练 了 一个 卷积 神经网络 用 滑动 
窗口 提供 像素 的 周围 区域 patch 作为 输入 来 
预测 每个 像素 的 类 标签 这个 网络 有 两个 
优点 第一 输出 结果 可以 定位 出 目标 类别 的 
位置 第二 由于 输入 的 训练 数据 是 patches 这样 
就 相当于 进行 了 数据 增广 解决 了 生物 医学 
图像 数量 少 的 问题 但是 这个 方法 也 有 
两个 很明显 缺点 第一 它 很慢 因为 这个 网络 必须 
训练 每个 patch 并且 因为 patch 间 的 重叠 有 
很多 的 冗余 冗余 会 造成 什么 影响 呢 卷积 
核 里面 的 W 就是 提取 特征 的 权重 两个 
块 如果 重叠 的 部分 太多 这个 权重 会被 同 
一些 特征 训练 两次 造成 资源 的 浪费 减慢 训练 
时间 和 效率 虽然 说 会 有一些 冗余 训练 集 
大了 准确率 不就 高 了吗 可是 你 这个 是 相同 
的 图片 啊 重叠 的 东西 都是/nr 相同 的 举个 
例子 我 用 一张 相同 的 图片 训练 20次 按照 
这个 意思 也是 增大 了 训练 集 啊 可是 会 
出现 什么 结果 呢 很显然 会 导致 过拟合 也 就是 
对 你 这个 图片 识别 很准 别的/nr 图片 就 不一定 
了 第二 定位 准确性 和 获取 上下文 信息 不可 兼得 
大 的 patches 需要 更多 的 max pooling 层 这样 
减小 了 定位 准确性 为什么 因为 你 是 对 以 
这个 像素 为 中心 的 点 进行 分类 如果 patch 
太大 最后 经过 全 连接 层 的 前 一层 大小 
肯定 是 不变 的 如果 你 patch 大 就 需要 
更多 的 pooling 达到 这个 大小 而 pooling 层 越多 
丢失 信息 的 信息 也 越多 小 的 patches 只能 
看到 很小 的 局部 信息 包含 的 背景 信息 不够 
和 SegNet 格式 极为 相近 不过 其 添加 了 中间 
的 center crop 和 concat 操作 实现 了 不同 层次 
特征 的 upsample 目的 同样 是 使上 采样 的 层 
能够 更多 的 参考 前 面下 采样 中间层 的 信息 
更好 的 达到 还原 的 效果 U Net 的 格式 
也 不复杂 形状 如下 参看 github 开源 实现 不难 复现 
注意 用 好 相关 张量 操作 API 即可 如 concet 
slice 等 值得 注意 的 是 U Net 采用 了 
与 FCN 完全 不同 的 特征 融合 方式 拼接 与 
FCN 逐点 相加 不同 U Net 采用 将 特征 在 
channel 维度 拼接 在 一起 形成 更 厚 的 特征 
所以 语义 分割 网络 在 特征 融 合时 也有 2种 
办法 FCN 式 的 逐点 相加 对应 caffe 的 EltwiseLayer 
层 对应 tensorflow 的 tf . add U Net 式 
的 channel 维度 拼接 融合 对应 caffe 的 ConcatLayer 层 
对应 tensorflow 的 tf . concat 1 使用 全 卷积 
神经网络 全/a 卷积/n 神经/n 网络/n 就是/d 卷积/n 取代/v 了/ul 全/a 
连接/v 层/q 全 连接 层 必须 固定 图像 大 小而 
卷积 不用 所以 这个 策略 使得 你 可以 输入 任意 
尺寸 的 图片 而且 输出 也是 图片 所以 这 是 
一个 端 到 端的 网络 2 左边 的 网络 是 
收缩 路径 使用 卷积 和 maxpooling 3 右边 的 网络 
是 扩张路径 使用 上 采样 产生 的 特征 图 与 
左侧 收缩 路径 对应 层 产生 的 特征 图 进行 
concatenate 操作 pooling 层 会 丢失 图像 信息 和 降低 
图像 分辨率 且 是 不可逆的 操作 对 图像 分割 任务 
有 一些 影响 对 图像 分类 任务 的 影响 不大 
为什么 要 做上 采样 因为 上 采样 可以 补足 一些 
图片 的 信息 但是 信息 补充 的 肯定 不 完全 
所以 还 需要 与 左边 的 分辨率 比 较高 的 
图片 相 连接 起来 直接 复制 过来 再 裁 剪到 
与 上 采样 图片 一样 大小 这就 相当于 在 高分辨率 
和更/nr 抽象 特征 当中 做 一个 折衷 因为 随着 卷积 
次数 增多 提取 的 特征 也 更加 有效 更加 抽象 
上 采样 的 图片 是 经历 多次 卷积 后的/nr 图片 
肯定 是 比较 高效 和 抽象 的 图片 然后 把 
它 与 左边 不怎么 抽象 但 更高 分辨率 的 特征 
图片 进行 连接 4 最后 再 经过 两次 反 卷积 
操作 生成 特征 图 再用 两个 1X1 的 卷积 做 
分类 得到 最后 的 两张 heatmap 例如 第一 张 表示 
的 是 第一 类 的 得分 第二 张 表示 第二类 
的 得分 heatmap 然后 作为 softmax 函数 的 输入 算出 
概率 比 较大 的 softmax 类 选择 它 作为 输入 
给 交叉 熵 进行 反向 传播 训练 四 空洞 卷积 
计算机 视觉 空洞 卷积 池化/nr 操作 增大 了 感受 野 
有助于 实现 分 类网络 但是 池化/nr 操作 在 分割 过程 
中 也 降低 了 分辨率 空洞 卷积 层 则 可以 
在 不 降低 空间维度 的 前提 下 增大 了 相应 
的 感受 野 指数 五 DeepLabv1 面临 问题 在 DCNN 
进行 分割 任务 时 有 两个 瓶颈 一个 是 下 
采样 所 导致 的 信息 丢失 通过 带 孔 卷积 
的 方法 解决 另 一个 是 CNN 空间 不变性 所 
导致 的 边缘 不够 准确 通过 全 连接 的 CRF 
解决 CRF 是 可以 通过 底层 特征 进行 分割 的 
一个 方法 核心 工作 空洞 卷积 计算 的 特征 映射 
更加 密集 + 如何 降低 计算 量 + CRF 作为 
后处理 知乎 文章 FCN 3 DenseCRF Deeplab 使 用带 孔 
算法 空洞 卷积 进行 特征提取 将 VGG16 的 全连 层 
转换 为 卷积 层 将/d 最后/f 两个/m 最大/a 池化层/nr 的/uj 
后的下/nr 采样/v 去掉/v 中间 的 卷积 替换 为 带 孔 
卷积 对于 空洞 卷积 作者 提到 了 两个 实现 方法 
在 卷积 核 中间 加 0 / 先降 采样 然后 
过 正常 卷积 第二 种 方法 计算 速度快 最后 三个 
卷积 层 使用 2倍 的 步长 第一 个 全连 层 
使用 4倍 步长 这样 做 的 好处 是 不 需要 
引入 额外 的 近似算法 感受 野 控制 加速 卷积 网络 
的 密集 计算 将/d VGG16/i 转换/v 为/p 全/a 卷积/n 层/q 
后/f 计算/v 量/n 变得/v 非常/d 大/a 为了 降低 运算 将 
第一 个 全连 层 进行 降 采样 这个 做法 降低 
了 感受 野 的 大小 不是 很懂 CRF 的 具体 
做法 简单 的 原文 的 图 贴上来 感受一下 框架 的 
pipline v2 相较 于 v1 简单 来说 空洞/n 卷积/n +/i 
全/a 连接/v CRF/w +/i ASPP/w 模块/n 主干网络/i 从预/nr 训练/vn 的/uj 
VGG/w 变成/v 了/ul ResNet/w 首先在/i 三个/m 尺度/n 上/f 训练/vn 和/c 
测试/vn 在 给定 的 输入 上以 不同 采样率 的 空洞 
卷积 并行 采样 相当于 以多 个 比例 捕捉 图像 的 
上下文 称为 ASPP atrous spatial pyramid pooling 模块 得到 的 
概率 是 输入 图片 的 八分之一 大小 然后 是 将 
概率 图 进行 双 线性插值 到 原始 输入 图片大小 将 
三个 尺度 的 概率 图 进行 融合 融合 策略 是 
最简单 的 取 最大值 最后/f 将/d 融合/vn 之后/f 的/uj 和/c 
原始/v 输入/v 一样/r 大小/b 的/uj 概率/n 图/n 输入/v 到/v 全/a 
连接/v 条件/n 随/v 机场/n 中/f 细化/n 边缘/n 细节/n 得到/v 最终/d 
的/uj 分割/v 结果/n 训练 的 时候 将 GT 降 采样 
了 8倍 和 CNN 直接 输出 的 概率 图 同样 
的 大小 计算 loss 下面 这张 图 展示 了 不同 
方式 的 上下文 信息 获取 最后 一张 图 是 ASPP 
的 原型 1 . Image Pyramid 将 输入 图片 放缩 
成 不同 比例 分别 应用在 DCNN 上 将 预测 结果 
融合 得到 最终 输出 2 . Encoder Decoder 利用 Encoder 
阶段 的 多 尺度 特征 运用 到 Decoder 阶段 上 
恢复 空间 分辨率 代表 工作 有 FCN SegNet PSPNet 等 
工 3 . Deeper w . Atrous Convolution 使用 空洞 
卷积 4 . Spatial Pyramid Pooling 空间/n 金字塔/nr 池化/nr 具有/v 
不同/a 采样率/v 和/c 多种/m 视野/n 的/uj 卷积/n 核/n 能够 以多 
尺度 捕捉 对象 v3 第三版 相对于 第二 版 的 改动 
不是 很大 主要 是 借鉴 了 下面 的 两篇 论文 
的 思想 然后 分别 对 之前 的 空洞 卷积 和 
ASPP 模块 就行了 改进 然后 整体 加入 了 BN 需要 
注意 的 是从 本 版本 开始 已经 不要 CRF 进行 
后 处理 了 Understanding Convolution for Semantic e g m 
e n t a t i o n P y 
r a m i d Scene Parsing Network 另外 文章 
指出 了 在 训练 的 时候 将 GT 应该 保持 
不动 将 概率 图 插值 之后 再 进行 计算 loss 
这样 不会 导致 金 标准 在 降 采样 过程 中 
丢失 细节 毕竟 8倍 的 降 采样 还是 很 严重 
的 v3 + 鉴于 对 最后 的 概率 图 依然 
使用 大 倍数 的 双 线性插值 恢复 到 与 原图 
一样 的 大小 还是 过于 简单 了 因此 在 这个 
版本 中 增加 了 一个 恢复 细节 的 解码器 部分 
A 是 aspp 结构 其中 8x 的 上 采样 可以 
看做 是 一个 解码器 B 是 编解码 结构 它 集合 
了 高层 和 底层 的 特征 C 就是 本文 采取 
的 结构 下图 展示 了 具体 的 网络 表示 该 
框架 参考 了 spatial pyramid pooling SPP module 和 encoder 
decoder 两种 形式 的 分割 框架 前一种 就是 PSPNet 那 
一款 后 一种 更 像是 SegNet 的 做法 ASPP 方法 
的 优点 是 该种 结构 可以 提取 比较 dense 的 
特征 因为 参考 了 不同 尺度 的 feature 并且 atrous 
convolution 的 使用 加强 了 提取 dense 特征 的 能力 
但是 在 该种 方法 中 由于 pooling 和有 stride 的 
conv 的 存在 使得 分割 目标 的 边界 信息 丢失 
严重 Encoder Decoder 方法 的 decoder 中 就 可以 起到 
修复 尖锐 物体 边界 的 作用 关于 Encoder 中 卷积 
的 改进 DeepLab V3 + 效仿 了 Xception 中 使用 
的 depthwise separable convolution 在 DeepLab V3 的 结构 中 
使用 了 atrous depthwise separable convolution 降低 了 计算 量 
的 同时 保持 了 相同 或 更好 的 效果 Decoder 
的 设计 2.1 . Encoder 提 取出 的 特征 首先 
被 x4 上 采样 称之为 F1 2.2 . Encoder 中 
提取 出来 的 与 F1 同 尺度 的 特征 F2 
先 进行 1x1 卷积 降低 通 道数 得到 F2 再 
进行 F1 和 F2 的 concatenation 得到 F3 为什么 要 
进行 通道 降 维 因为/c 在/p encoder/w 中/f 这些/r 尺度/n 
的/uj 特征/n 通常/d 通/v 道数/n 有/v 256/m 或者/c 512个/mq 而 
encoder 最后 提取 出来 的 特征 通 道数 没有 这么 
多 如果 不 进行 降 维 就 进行 concate 的话 
无形之中 加大 了 F2 的 权重 加大 了 网络 的 
训练 难度 2.3 . 对 F3 进行 常规 的 3x3convolution 
微调 特征 最后 直接 x4upsample 得到 分割 结果 总结 一下 
CNN 图像 语义 分割 也就 基本上 是 这个 套路 下 
采样 + 上 采样 Convlution + Deconvlution ／ Resize 多 
尺度 特征 融合 特征 逐点 相加 ／ 特征 channel 维度 
拼接 获得 像素 级别 的 segement map 对 每 一个 
像素点 进行 判断 类别 