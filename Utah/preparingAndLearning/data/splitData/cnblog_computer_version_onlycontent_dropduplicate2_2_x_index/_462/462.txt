导读怎么样来理解近期异常火热的深度学习网络？深度学习有什么亮点呢？答案事实上非常简答。今年十月份有幸參加了深圳高交会的中科院院士论坛。IEEE fellow汤晓欧做了一场精彩的报告，这个问题被汤大神一语道破，他说深度学习网络说白了就是一个多层的神经网络。同20年前相比，计算机硬件性能提升非常多，有了实现处理大数据和并行运算的能力，deep learning才被又一次重视起来。这里，再反复一遍CNN的实质：CNN就是一个更深层次、具有很多其它节点的ANN网络。但与简单的ANN相比：CNN主要是卷积使得权值共享。减少连接的数量级。同一时候兼顾二维特征；从算法层面上。CNN的核心还是同BP网络一样权值正向传播误差反向传播，并利用误差来更新每一层的权值。DNN的背景DNN，deep neural network。近几年机器学习算法中崛起的旗舰方法，作为分类精度最高、处理高维大数据的算法，拯救了机器学习在半个世纪里发展缓慢的颓势，也为人工智能新领域的拓展起着重要作用，来看看近期一些IT巨头在深度学习领域中的开展的工作。2012年，《纽约时报》报道的google Brian项目，引起广泛关注，这个项目由机器学习领域大师级人物吴恩达和大规模计算机系统方面的世界顶级专家JeffDean主导，使用万为数量级的CPU数量搭建并行计算平台。模拟出10亿数量级的神经节点，让这个巨大的系统收看YouTube视频可以自学习和识别具有一个小孩的智力水平。微软在天津举办一次公开的活动展示了全自己主动的同声传译系统。演讲者用英语说话，后台计算机一气呵成地完毕语音识别、英中文翻译、语音合成，效果非常流畅。这个系统背后的关键技术就是DNN。或者说DL(Deep Learning)。2013年。李彦宏在百度年会上高调宣布成立“深度学习研究院”。Why DNN深度学习，体现出仿生生物学和人工智能等领域的光辉思想，借用获得诺贝尔生理学奖的“视觉分层”理论，深度学习採用多层的分层形式来模拟视觉系统的原理，从底层的像素获取形状方向。到大脑皮层不同区域抽象迭代获得局部特征。再到提取高层特征直到可以简单识别出模式。正由于深度学习神经网络中的深层次结构，可以无遗漏地提取样本特征，具有强大的分类能力。所以深度学习相比于其它机器学习的算法。可以减少误差率。成为近年来非常热门的算法。深度学习有着多层深层的层次结构，将底层的特征不断抽象和迭代出可标示的特征。可以发现大数据中的复杂结构，具有强大的分类能力，因而在视频图像识别、语音识别、海量文本分类等方面具有重要应用。深度学习的思想是通过深层网络的结构自己主动学习和提取海量数据的特征。假设将深度学习网络看成一个信号处理系统。输入是一堆数据（一批图片或一叠文本），通过多层网络 （i=1,2..）的处理后无损地得到输出，形象表示为： I=>S1=>S2=>…=>Sn => O，假设I和O相等，说明该系统可以无损处理输入信号。这样可以不断迭代训练网络得到一个多层网络 每层网络从低到高来表述特征。所以深度学习的目的就是训练这个多层网络，得到正确的分类參数。深度学习网络的眼下主流的模型主要有三种，深度信念网络。受限玻尔兹曼机和卷积神经网络。这里主要解说机器学习课程上的卷积神经网络模型。How CNN work这里从两个方面来阐述这个庞大的问题：- 理论方面比如。CNN怎样权值正向传播并进行误差反向？卷积过程？- 实例代码解说比如，怎样使用matlab工具箱构建CNN网络？怎样训练网络？Typical Example这里就机器学习方面的大师级人物LecunYann设计训练的CNN网络模型来说明问题，。CNN流程图具体解释