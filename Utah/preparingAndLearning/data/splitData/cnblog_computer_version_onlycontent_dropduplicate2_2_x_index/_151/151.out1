教程 Batch Normalization 层 介绍 知乎 详解 深度 学习 中的 
Normalization BN / LN / WN 一 两个 概念 独立 
同 分布 independent and identically distributed 独立 同 分布 的 
数据 可以 简化 常规 机器学习 模型 的 训练 提升 机器学习 
模型 的 预测 能力 白化 whitening 去除 特征 之间 的 
相关性 独立 使得 所有 特征 具有 相同 的 均值 和 
方差 同 分布 二 问题 1 抽象 程度 高的层/nr 难以 
训练 深度 神经网络 涉及 到 很多 层 的 叠加 而每 
一层 的 参数 更新 会 导致 上层 的 输入 数据分布 
发生变化 通过 层层 叠加 高层 抽象 程度 高 的 输入 
分布 变化 会 非常 剧烈 这就 使得 高层 需要 不断 
去 重新 适应 底层 的 数据 更新 Google 将 这一 
现象 总 结为 Internal Covariate Shif 统计 机器学习 中 的 
一个 经典 假设 是 源 空间 source domain 和 目标 
空间 target domain 的 数据 分布 distribution 是 一致 的 
如果 不 一致 那么 就 出现 了 新的 机器学习 问题 
如 transfer learning / domain adaptation 等 而 covariate shift 
就是 分布 不 一致 假设 之下 的 一个 分支 问题 
它 是 指 源 空间 和 目标 空间 的 条件 
概率 是 一致 的 但是 其 边缘 概率 不同 即 
对 所有 但是 大家 细想 便会 发现 的确 对于 神经 
网络 的 各层 输出 由于 它们 经 过了 层内 操作 
作用 各层 的 输入 信号 的 分布 显然 不同 而且 
差异 会 随着 网络 深度 增大 而 增大 可是 它们 
所能 指示 的 样本 标记 label 仍然 是 不变 的 
这 便 符合 了 covariate shift 的 定义 由 于是 
对 层间 信号 的 分析 也 即是 internal 的 来由 
问题 描述 简而言之 每个 神经元 的 输入 数据 不再 是 
独立 同 分布 其一 上层 参数 需要 不断 适应 新的 
输入 数据分布 降低 学习 速度 其二 下层 输入 的 变化 
可能 趋向于 变大 或者 变小 导致 上层 落入 饱和 区 
使得 学习 过早 停止 其三 每层 的 更新 都会 影响 
到 其它 层 因此 每层 的 参数 更 新策略 需要 
尽可能 的 谨慎 2 问题 挑战 我们 以 神经 网络 
中 的 一个 普通 神经元 为例 神经元 接收 一组 输入 
向量 通过 某种 运算 后 输 出 一个 标 量值 
由于 ICS 问题 的 存在 对于 某一 特定 层 不同 
批次 的 输入 的 分布 可能 相差 很大 要 解决 
独立 同 分布 的 问题 理论 正确 的 方法 就是 
对 每 一层 的 数据 都 进行 白化 操作 然而 
标准 的 白化 操作 代价 高昂 特别 是 我们 还 
希望 白化 操作 是 可微 的 保证 白化 操作 可以 
通过 反向 传播 来 更新 梯度 三 解决 思路 BN1 
通用 框 架在 将 送给 神经元 之前 先 对其 做 
平移 和 伸缩 变换 将 的 分布 规范 化成 在 
固定 区间 范围 的 标准 分布 通用 变换 框架 就 
如下 所示 1 是 平移 参数 shift parameter 是 缩放 
参数 scale parameter 通过 这 两个 参数 进行 shift 和 
scale 变换 得到 的 数据 符合 均值 为 0 方差 
为 1 的 标准 分布 2 是 再 平移 参数 
re shift parameter 是 再 缩放 参数 re scale parameter 
将 上 一步 得到 的 进一步 变换 为 最终 得到 
的 数据 符合 均值 为 方差 为 的 分布 2 
第二 次 变换 的 目的 1 目的 一 第一 次 
变换 得到 均值 为 0 方差 为 1 的 标准 
分布 表达 能力 有限 下层 神经元 可能 很 努力 地 
在 学习 但 不论 其 如何 变化 其 输出 的 
结果 在 交给 上层 神经元 进行 处理 之前 将被 粗暴 
地 重新 调整 到 这一 固定 范围 为了 更好 的 
应用 底层 神经 网络 的 学习 结果 我们/r 将/d 规范化/n 
后的/nr 数据/n 进行/v 再/d 平移/v 和再/nr 缩放/v 使得 每个 神经元 
对应 的 输入 范围 是 针对 该 神经元 量身 定制 
的 一个 确定 范围 均值 为 方差 为 rescale 和 
reshift 的 参数 都是 可 学习 的 这就 使得 Normalization 
层 可以 学习 如何 去 适应 底层 的 学习 结果 
2 目的 二 除了 充分利用 底层 学习 的 能力 另一 
方面 的 重要 意义 在于 保证 获得 非线性 的 表达 
能力 Sigmoid 等 激活 函数 在 神经 网络 中 有着 
重要 作用 通过 区分 饱和 区 和 非饱和 区 使得 
神经 网络 的 数据 变换 具有 了 非线性 计算能力 而 
第一步 的 规范化 会将 几乎 所有 数据 映 射到 激活 
函数 的 非饱和 区 线性 区 仅 利用 到了 线性 
变化 能力 从而 降低 了 神经 网络 的 表达 能力 
而 进行 再变换 则 可以 将 数据 从 线性 区 
变换 到 非线性 区 恢复 模型 的 表达 能力 3 
优势 不 添加 正则化 的 均值 取决于 下层 神经 网络 
的 复杂 关联 添加 本 层 后 取值 仅 由 
来 确定 去 除了 与 下层 计算 的 密切 耦合 
新 参数 很 容易 通过 梯度 下降 来 学习 简化 
了 神经 网络 的 训练 4 问题 a BN 的 
实际 作用 标准 白化 操作 的 目的 是 独立 同 
分布 独立 就 不说 了 暂 不考虑 变换 为 均值 
为 方差 为 的 分布 也 并 不是 严格 的 
同 分布 只是 映 射到 了 一个 确定 的 区间 
范围 而已 所以 这个 问题 仍然 有 研究 空间 另外 
有人 提出 BN 其 优势 并 非 解决 了 独立 
同 分布 的 问题 实际上 它 也没 解决 其 最大 
意义 在于 解决 了 梯度 弥散 问题 见 论文 How 
Does Batch Normalization Help Optimization 知乎 上 的 一篇 阅读 
笔记 为什么 Batch Normalization 那么 有用 文章 结论 如下 没有 
证据 表明 BN 的 work 是 因为 减少 了 ICS 
Interval Covariate Shift BN work 的 根本 原因 是 因为 
在 网络 的 训练 阶段 其 能够 让 优化 空间 
optimization landscape 变 的 平滑 其他 的 normalization 技术 也 
能够 像 BN 那样 对于 网络 的 训练 起到 作用 
其 作用 为 防止 梯度 爆炸 或 弥散 可以 提高 
训练 时 模型 对于 不同 超 参 学习率 初始化 的 
鲁棒性 可以 让 大部分 的 激活 函数 能够 远离 其 
饱和 区域 b BN 对 小批 次 训练 效果 不好 
当 单个 小 批次 minibatch 的 数据 不能 代表 整个 
数据 的 分布 时 BN 的 表现 就会 不 尽如人意 
这 意味着 忘记 将 输入 随机 打乱 顺序 的 情况 
下 使用 批 归一化 是 很 危险 的 实际上 batch 
过小 的 时候 就 不太 适合 开放 BN 的 可 
训练 性 具体 讨论 见 论文 Batch Normalization Accelerating Deep 
Network Training by Reducing BN 训练 时 为什么 不 使用 
全局 均值 / 方差 使用 BN 的 目的 就是 为了 
保证 每批 数据 的 分布 稳定 使用 全局 统计量 反而 
违背 了 这个 初衷 BN 的 作者 认为 在 训练 
时 采用 移动 平均 可能会 与 梯度 优化 存在 冲突 
四 主流 Normalization 方法 梳理 BatchNorm batch 方向 做 归一化 
算 N * H * W 的 均值 LayerNorm channel 
方向 做 归一化 算 C * H * W 的 
均值 InstanceNorm 一个 channel 内 做 归一化 算 H * 
W 的 均值 GroupNorm 将 channel 方向 分 group 然后 
每个 group 内 做 归一化 算 C / / G 
* H * W 的 均值 https / / zhuanlan 
. zhihu . com / p / 696598441 Batch Normalization 
TensorFlow 批处理 类 教程 Batch Normalization 层 介绍 于 2015年 
由 Google 提出 BN 独立 地 规范化 每一个 层 不同 
批次 的 但 规范化 的 参数 是 一个 mini batch 
的 一 阶 统计量 和 二阶 统计量 这就 要求 每一个 
mini batch 的 统计 量 是 整体 统计量 的 近似 
估计 或者说 每 一个 mini batch 彼此之间 以及 和 整体 
数据 都 应该 是 近似 同 分布 的 分布 差距 
较小 的 mini batch 可以 看做 是 为 规范化 操作 
和 模型 训练 引入 了 噪声 可以 增加 模型 的 
鲁棒性 但 如果 每个 mini batch 的 原始 分布 差别 
很大 那么 不同 mini batch 的 数据 将 会 进行 
不 一样 的 数据 变换 这就 增加 了 模型 训练 
的 难度 训练 时 网络 会 记录 每一个 batch 滑动 
平均 的 均值 和 方差 训练 结束 的 时候 这四个 
参数 就 固定 了 供 测试 时 直接 加载 使用 
BN 比较 适用 的 场景 是 每个 mini batch 比较 
大 数据分布 比较 接近 在 进行 训练 之前 要 做好 
充分 的 shuffle 否则 效果 会 差 很多 另外 由于 
BN 需要 在 运行 过程 中 统计 每个 mini batch 
的 一 阶 统计量 和 二阶 统计量 因此 不 适用 
于 动态 的 网络 结构 和 RNN 网络 不过 也有 
研究者 专门 提出 了 适用于 RNN 的 BN 使用 方法 
这里 先不 展开 了 2 Layer NormalizationLN 针对 单个 训练样本 
进行 不 依赖 于 其他 数据 因此 可以 避免 BN 
中 受 mini batch 数据分布 影响 的 问题 可以 用于 
小 mini batch 场景 动态网络 场景 和 RNN 特别 是 
自然 语言 处理 领域 此外 LN 不 需要 保存 mini 
batch 的 均值 和 方差 节省 了 额外 的 存储空间 
但是 BN 的 转换 是 针对 单个 神经元 可 训练 
的 不同 神经元 的 输入 经过 再 平移 和再缩/nr 放后 
分布 在 不同 的 区间 而 LN 对于 一 整层 
的 神经元 训练 得到 同 一个 转换 所有 的 输入 
都在 同一个 区间 范围内 如果 不 同 输入 特征 不属于 
相似 的 类别 比如 颜色 和 大小 那么 LN 的 
处理 可能 会 降低 模型 的 表达 能力 3 Instance 
Normalization 在 GAN 和 style transfer 的 任务 中 目前 
的 IN norm 要好 于 BN IN 主要 用于 对 
单张 图像 的 数据 做 处理 而 BN 主要 是 
对 Bacth 的 数据 做 处理 由于/c BN/w 在/p 训练/vn 
时/n 每个/r batch/w 的/uj 均值/n 和/c 方差/n 会/v 由于/c shuffle/w 
都会/i 改变/v 所以 可以 理解 为 一种 数据 增强 而 
IN 可以 理解 为 对 数据 做 一个 归一化 的 
操作 换句话说 BN 的 计算 是 要 受 其他 样本 
影响 的 由于 每个 batch 的 均值 和 标准差 不稳定 
对于 单个 数据 而言 相对于 是 引入 了 噪声 但在 
分类 这种 问题 上 结果/n 和/c 数据/n 的/uj 整体/n 分布/v 
有/v 关系/n 因此 需要 通过 BN 获得 数据 的 整体 
分布 而 instance norm/w 的/uj 信息/n 都是/nr 来自/v 于/p 自身/r 
的/uj 图片/n 相当于 对 全局 信息 做 了 一次 整合 
和 调整 在 图像 转换 这种 问题 上 BN 获得 
的 整体 信息 不会 带来 任何 收益 带来 的 噪声 
反而会 弱化 实例 之间 的 独立性 这类 生成式 方法 每张 
图片 自己 的 风格 比较 独立 不 应该 与 batch 
中 其他 的 样本 产生 太大 联系 4 Group N 
o r m a l i z a t i 
o n g r o u p normalization/w 是/v 2018年/tdq 
3/m 月份/n 何恺明/nr 大神/n 的/uj 又一/i 力作/n 优化 了 BN 
在 比较 小 的 mini batch 情况 下 表现 不太好 
的 劣势 批量 维度 进行 归一化 会 带来 一些 问题 
批量 统计 估算 不准确 导致 批 量变 小时 BN 的 
误差 会 迅速 增加 在 训练 大型 网络 和将/nr 特征 
转移 到 计算机 视觉 任务 中 包括 检测 分割 和 
视频 内存 消耗 限制 了 只能 使用 小 批量 的 
BN 事实上 GN 的 极端 情况 就是 LN 和 IN 
分别 对应 G 等于 C 和G/nr 等于 1 tf 实现 
并 不复杂 如下 def GroupNorm x G = 16 eps 
= 1e 5 N H W C = x . 
shape x = tf . reshape x tf . cast 
N tf . int32 tf . cast H tf . 
int32 tf . cast W tf . int32 tf . 
cast G tf . int32 tf . cast C / 
/ G tf . int32 mean var = tf . 
nn . moments x 1 2 4 keep _ dims 
= True x = x mean / tf . sqrt 
var + eps x = tf . reshape x tf 
. cast N tf . int32 tf . cast H 
tf . int32 tf . cast W tf . int32 
tf . cast C tf . int32 gamma = tf 
. Variable tf . ones shape = 1 1 1 
tf . cast C tf . int32 name = gamma 
beta = tf . Variable tf . zeros shape = 
1 1 1 tf . cast C tf . int32 
name = beta return x * gamma + beta 在 
深度 学习 没有 火 起来 之前 提取 特征 通常 是 
使用 SIFT HOG 和 GIST 特征 这些 特征 有 一个 
共性 都 具有 按 group 表示 的 特性 每一个 group 
由 相同 种类 直方图 的 构建 而成 这些 特征 通常 
是 对在 每个 直方图 histogram 或 每个 方向 orientation 上 
进行 组 归一化 group wise norm 而 得到 从 深度 
学习 上 来讲 完全 可以 认为 卷积 提取 的 特征 
是 一种 非 结构化 的 特征 或者 向量 拿 网络 
的 第一 层 卷积 为例 卷积 层 中的 的 卷积 
核 filter1 和此/nr 卷积 核 的 其他 经过 transform 过 
的 版本 filter2 transform 可以 是 horizontal flipping 等 在 
同一 张 图像 上 学习 到 的 特征 应该 是 
具有 相同 的 分布 那么 具有 相同 的 特征 可以 
被 分到 同一个 group 中 按照 个人 理解 每 一层 
有 很多 的 卷积 核 这些 核 学习 到 的 
特征 并不 完全 是 独立 的 某些 特征 具有 相同 
的 分布 因此 可以 被 group 教程 Batch Normalization 层 介绍 知乎 详解 深度 学习 中的 
Normalization BN / LN / WN 一 两个 概念 独立 
同 分布 independent and identically distributed 独立 同 分布 的 
数据 可以 简化 常规 机器学习 模型 的 训练 提升 机器学习 
模型 的 预测 能力 白化 whitening 去除 特征 之间 的 
相关性 独立 使得 所有 特征 具有 相同 的 均值 和 
方差 同 分布 二 问题 1 抽象 程度 高的层/nr 难以 
训练 深度 神经网络 涉及 到 很多 层 的 叠加 而每 
一层 的 参数 更新 会 导致 上层 的 输入 数据分布 
发生变化 通过 层层 叠加 高层 抽象 程度 高 的 输入 
分布 变化 会 非常 剧烈 这就 使得 高层 需要 不断 
去 重新 适应 底层 的 数据 更新 Google 将 这一 
现象 总 结为 Internal Covariate Shif 统计 机器学习 中 的 
一个 经典 假设 是 源 空间 source domain 和 目标 
空间 target domain 的 数据 分布 distribution 是 一致 的 
如果 不 一致 那么 就 出现 了 新的 机器学习 问题 
如 transfer learning / domain adaptation 等 而 covariate shift 
就是 分布 不 一致 假设 之下 的 一个 分支 问题 
它 是 指 源 空间 和 目标 空间 的 条件 
概率 是 一致 的 但是 其 边缘 概率 不同 即 
对 所有 但是 大家 细想 便会 发现 的确 对于 神经 
网络 的 各层 输出 由于 它们 经 过了 层内 操作 
作用 各层 的 输入 信号 的 分布 显然 不同 而且 
差异 会 随着 网络 深度 增大 而 增大 可是 它们 
所能 指示 的 样本 标记 label 仍然 是 不变 的 
这 便 符合 了 covariate shift 的 定义 由 于是 
对 层间 信号 的 分析 也 即是 internal 的 来由 
问题 描述 简而言之 每个 神经元 的 输入 数据 不再 是 
独立 同 分布 其一 上层 参数 需要 不断 适应 新的 
输入 数据分布 降低 学习 速度 其二 下层 输入 的 变化 
可能 趋向于 变大 或者 变小 导致 上层 落入 饱和 区 
使得 学习 过早 停止 其三 每层 的 更新 都会 影响 
到 其它 层 因此 每层 的 参数 更 新策略 需要 
尽可能 的 谨慎 2 问题 挑战 我们 以 神经 网络 
中 的 一个 普通 神经元 为例 神经元 接收 一组 输入 
向量 通过 某种 运算 后 输 出 一个 标 量值 
由于 ICS 问题 的 存在 对于 某一 特定 层 不同 
批次 的 输入 的 分布 可能 相差 很大 要 解决 
独立 同 分布 的 问题 理论 正确 的 方法 就是 
对 每 一层 的 数据 都 进行 白化 操作 然而 
标准 的 白化 操作 代价 高昂 特别 是 我们 还 
希望 白化 操作 是 可微 的 保证 白化 操作 可以 
通过 反向 传播 来 更新 梯度 三 解决 思路 BN1 
通用 框 架在 将 送给 神经元 之前 先 对其 做 
平移 和 伸缩 变换 将 的 分布 规范 化成 在 
固定 区间 范围 的 标准 分布 通用 变换 框架 就 
如下 所示 1 是 平移 参数 shift parameter 是 缩放 
参数 scale parameter 通过 这 两个 参数 进行 shift 和 
scale 变换 得到 的 数据 符合 均值 为 0 方差 
为 1 的 标准 分布 2 是 再 平移 参数 
re shift parameter 是 再 缩放 参数 re scale parameter 
将 上 一步 得到 的 进一步 变换 为 最终 得到 
的 数据 符合 均值 为 方差 为 的 分布 2 
第二 次 变换 的 目的 1 目的 一 第一 次 
变换 得到 均值 为 0 方差 为 1 的 标准 
分布 表达 能力 有限 下层 神经元 可能 很 努力 地 
在 学习 但 不论 其 如何 变化 其 输出 的 
结果 在 交给 上层 神经元 进行 处理 之前 将被 粗暴 
地 重新 调整 到 这一 固定 范围 为了 更好 的 
应用 底层 神经 网络 的 学习 结果 我们/r 将/d 规范化/n 
后的/nr 数据/n 进行/v 再/d 平移/v 和再/nr 缩放/v 使得 每个 神经元 
对应 的 输入 范围 是 针对 该 神经元 量身 定制 
的 一个 确定 范围 均值 为 方差 为 rescale 和 
reshift 的 参数 都是 可 学习 的 这就 使得 Normalization 
层 可以 学习 如何 去 适应 底层 的 学习 结果 
2 目的 二 除了 充分利用 底层 学习 的 能力 另一 
方面 的 重要 意义 在于 保证 获得 非线性 的 表达 
能力 Sigmoid 等 激活 函数 在 神经 网络 中 有着 
重要 作用 通过 区分 饱和 区 和 非饱和 区 使得 
神经 网络 的 数据 变换 具有 了 非线性 计算能力 而 
第一步 的 规范化 会将 几乎 所有 数据 映 射到 激活 
函数 的 非饱和 区 线性 区 仅 利用 到了 线性 
变化 能力 从而 降低 了 神经 网络 的 表达 能力 
而 进行 再变换 则 可以 将 数据 从 线性 区 
变换 到 非线性 区 恢复 模型 的 表达 能力 3 
优势 不 添加 正则化 的 均值 取决于 下层 神经 网络 
的 复杂 关联 添加 本 层 后 取值 仅 由 
来 确定 去 除了 与 下层 计算 的 密切 耦合 
新 参数 很 容易 通过 梯度 下降 来 学习 简化 
了 神经 网络 的 训练 4 问题 a BN 的 
实际 作用 标准 白化 操作 的 目的 是 独立 同 
分布 独立 就 不说 了 暂 不考虑 变换 为 均值 
为 方差 为 的 分布 也 并 不是 严格 的 
同 分布 只是 映 射到 了 一个 确定 的 区间 
范围 而已 所以 这个 问题 仍然 有 研究 空间 另外 
有人 提出 BN 其 优势 并 非 解决 了 独立 
同 分布 的 问题 实际上 它 也没 解决 其 最大 
意义 在于 解决 了 梯度 弥散 问题 见 论文 How 
Does Batch Normalization Help Optimization 知乎 上 的 一篇 阅读 
笔记 为什么 Batch Normalization 那么 有用 文章 结论 如下 没有 
证据 表明 BN 的 work 是 因为 减少 了 ICS 
Interval Covariate Shift BN work 的 根本 原因 是 因为 
在 网络 的 训练 阶段 其 能够 让 优化 空间 
optimization landscape 变 的 平滑 其他 的 normalization 技术 也 
能够 像 BN 那样 对于 网络 的 训练 起到 作用 
其 作用 为 防止 梯度 爆炸 或 弥散 可以 提高 
训练 时 模型 对于 不同 超 参 学习率 初始化 的 
鲁棒性 可以 让 大部分 的 激活 函数 能够 远离 其 
饱和 区域 b BN 对 小批 次 训练 效果 不好 
当 单个 小 批次 minibatch 的 数据 不能 代表 整个 
数据 的 分布 时 BN 的 表现 就会 不 尽如人意 
这 意味着 忘记 将 输入 随机 打乱 顺序 的 情况 
下 使用 批 归一化 是 很 危险 的 实际上 batch 
过小 的 时候 就 不太 适合 开放 BN 的 可 
训练 性 具体 讨论 见 论文 Batch Normalization Accelerating Deep 
Network Training by Reducing BN 训练 时 为什么 不 使用 
全局 均值 / 方差 使用 BN 的 目的 就是 为了 
保证 每批 数据 的 分布 稳定 使用 全局 统计量 反而 
违背 了 这个 初衷 BN 的 作者 认为 在 训练 
时 采用 移动 平均 可能会 与 梯度 优化 存在 冲突 
四 主流 Normalization 方法 梳理 BatchNorm batch 方向 做 归一化 
算 N * H * W 的 均值 LayerNorm channel 
方向 做 归一化 算 C * H * W 的 
均值 InstanceNorm 一个 channel 内 做 归一化 算 H * 
W 的 均值 GroupNorm 将 channel 方向 分 group 然后 
每个 group 内 做 归一化 算 C / / G 
* H * W 的 均值 https / / zhuanlan 
. zhihu . com / p / 696598441 Batch Normalization 
TensorFlow 批处理 类 教程 Batch Normalization 层 介绍 于 2015年 
由 Google 提出 BN 独立 地 规范化 每一个 层 不同 
批次 的 但 规范化 的 参数 是 一个 mini batch 
的 一 阶 统计量 和 二阶 统计量 这就 要求 每一个 
mini batch 的 统计 量 是 整体 统计量 的 近似 
估计 或者说 每 一个 mini batch 彼此之间 以及 和 整体 
数据 都 应该 是 近似 同 分布 的 分布 差距 
较小 的 mini batch 可以 看做 是 为 规范化 操作 
和 模型 训练 引入 了 噪声 可以 增加 模型 的 
鲁棒性 但 如果 每个 mini batch 的 原始 分布 差别 
很大 那么 不同 mini batch 的 数据 将 会 进行 
不 一样 的 数据 变换 这就 增加 了 模型 训练 
的 难度 训练 时 网络 会 记录 每一个 batch 滑动 
平均 的 均值 和 方差 训练 结束 的 时候 这四个 
参数 就 固定 了 供 测试 时 直接 加载 使用 
BN 比较 适用 的 场景 是 每个 mini batch 比较 
大 数据分布 比较 接近 在 进行 训练 之前 要 做好 
充分 的 shuffle 否则 效果 会 差 很多 另外 由于 
BN 需要 在 运行 过程 中 统计 每个 mini batch 
的 一 阶 统计量 和 二阶 统计量 因此 不 适用 
于 动态 的 网络 结构 和 RNN 网络 不过 也有 
研究者 专门 提出 了 适用于 RNN 的 BN 使用 方法 
这里 先不 展开 了 2 Layer NormalizationLN 针对 单个 训练样本 
进行 不 依赖 于 其他 数据 因此 可以 避免 BN 
中 受 mini batch 数据分布 影响 的 问题 可以 用于 
小 mini batch 场景 动态网络 场景 和 RNN 特别 是 
自然 语言 处理 领域 此外 LN 不 需要 保存 mini 
batch 的 均值 和 方差 节省 了 额外 的 存储空间 
但是 BN 的 转换 是 针对 单个 神经元 可 训练 
的 不同 神经元 的 输入 经过 再 平移 和再缩/nr 放后 
分布 在 不同 的 区间 而 LN 对于 一 整层 
的 神经元 训练 得到 同 一个 转换 所有 的 输入 
都在 同一个 区间 范围内 如果 不 同 输入 特征 不属于 
相似 的 类别 比如 颜色 和 大小 那么 LN 的 
处理 可能 会 降低 模型 的 表达 能力 3 Instance 
Normalization 在 GAN 和 style transfer 的 任务 中 目前 
的 IN norm 要好 于 BN IN 主要 用于 对 
单张 图像 的 数据 做 处理 而 BN 主要 是 
对 Bacth 的 数据 做 处理 由于/c BN/w 在/p 训练/vn 
时/n 每个/r batch/w 的/uj 均值/n 和/c 方差/n 会/v 由于/c shuffle/w 
都会/i 改变/v 所以 可以 理解 为 一种 数据 增强 而 
IN 可以 理解 为 对 数据 做 一个 归一化 的 
操作 换句话说 BN 的 计算 是 要 受 其他 样本 
影响 的 由于 每个 batch 的 均值 和 标准差 不稳定 
对于 单个 数据 而言 相对于 是 引入 了 噪声 但在 
分类 这种 问题 上 结果/n 和/c 数据/n 的/uj 整体/n 分布/v 
有/v 关系/n 因此 需要 通过 BN 获得 数据 的 整体 
分布 而 instance norm/w 的/uj 信息/n 都是/nr 来自/v 于/p 自身/r 
的/uj 图片/n 相当于 对 全局 信息 做 了 一次 整合 
和 调整 在 图像 转换 这种 问题 上 BN 获得 
的 整体 信息 不会 带来 任何 收益 带来 的 噪声 
反而会 弱化 实例 之间 的 独立性 这类 生成式 方法 每张 
图片 自己 的 风格 比较 独立 不 应该 与 batch 
中 其他 的 样本 产生 太大 联系 4 Group N 
o r m a l i z a t i 
o n g r o u p normalization/w 是/v 2018年/tdq 
3/m 月份/n 何恺明/nr 大神/n 的/uj 又一/i 力作/n 优化 了 BN 
在 比较 小 的 mini batch 情况 下 表现 不太好 
的 劣势 批量 维度 进行 归一化 会 带来 一些 问题 
批量 统计 估算 不准确 导致 批 量变 小时 BN 的 
误差 会 迅速 增加 在 训练 大型 网络 和将/nr 特征 
转移 到 计算机 视觉 任务 中 包括 检测 分割 和 
视频 内存 消耗 限制 了 只能 使用 小 批量 的 
BN 事实上 GN 的 极端 情况 就是 LN 和 IN 
分别 对应 G 等于 C 和G/nr 等于 1 tf 实现 
并 不复杂 如下 def GroupNorm x G = 16 eps 
= 1e 5 N H W C = x . 
shape x = tf . reshape x tf . cast 
N tf . int32 tf . cast H tf . 
int32 tf . cast W tf . int32 tf . 
cast G tf . int32 tf . cast C / 
/ G tf . int32 mean var = tf . 
nn . moments x 1 2 4 keep _ dims 
= True x = x mean / tf . sqrt 
var + eps x = tf . reshape x tf 
. cast N tf . int32 tf . cast H 
tf . int32 tf . cast W tf . int32 
tf . cast C tf . int32 gamma = tf 
. Variable tf . ones shape = 1 1 1 
tf . cast C tf . int32 name = gamma 
beta = tf . Variable tf . zeros shape = 
1 1 1 tf . cast C tf . int32 
name = beta return x * gamma + beta 在 
深度 学习 没有 火 起来 之前 提取 特征 通常 是 
使用 SIFT HOG 和 GIST 特征 这些 特征 有 一个 
共性 都 具有 按 group 表示 的 特性 每一个 group 
由 相同 种类 直方图 的 构建 而成 这些 特征 通常 
是 对在 每个 直方图 histogram 或 每个 方向 orientation 上 
进行 组 归一化 group wise norm 而 得到 从 深度 
学习 上 来讲 完全 可以 认为 卷积 提取 的 特征 
是 一种 非 结构化 的 特征 或者 向量 拿 网络 
的 第一 层 卷积 为例 卷积 层 中的 的 卷积 
核 filter1 和此/nr 卷积 核 的 其他 经过 transform 过 
的 版本 filter2 transform 可以 是 horizontal flipping 等 在 
同一 张 图像 上 学习 到 的 特征 应该 是 
具有 相同 的 分布 那么 具有 相同 的 特征 可以 
被 分到 同一个 group 中 按照 个人 理解 每 一层 
有 很多 的 卷积 核 这些 核 学习 到 的 
特征 并不 完全 是 独立 的 某些 特征 具有 相同 
的 分布 因此 可以 被 group 教程 Batch Normalization 层 介绍 知乎 详解 深度 学习 中的 
Normalization BN / LN / WN 一 两个 概念 独立 
同 分布 independent and identically distributed 独立 同 分布 的 
数据 可以 简化 常规 机器学习 模型 的 训练 提升 机器学习 
模型 的 预测 能力 白化 whitening 去除 特征 之间 的 
相关性 独立 使得 所有 特征 具有 相同 的 均值 和 
方差 同 分布 二 问题 1 抽象 程度 高的层/nr 难以 
训练 深度 神经网络 涉及 到 很多 层 的 叠加 而每 
一层 的 参数 更新 会 导致 上层 的 输入 数据分布 
发生变化 通过 层层 叠加 高层 抽象 程度 高 的 输入 
分布 变化 会 非常 剧烈 这就 使得 高层 需要 不断 
去 重新 适应 底层 的 数据 更新 Google 将 这一 
现象 总 结为 Internal Covariate Shif 统计 机器学习 中 的 
一个 经典 假设 是 源 空间 source domain 和 目标 
空间 target domain 的 数据 分布 distribution 是 一致 的 
如果 不 一致 那么 就 出现 了 新的 机器学习 问题 
如 transfer learning / domain adaptation 等 而 covariate shift 
就是 分布 不 一致 假设 之下 的 一个 分支 问题 
它 是 指 源 空间 和 目标 空间 的 条件 
概率 是 一致 的 但是 其 边缘 概率 不同 即 
对 所有 但是 大家 细想 便会 发现 的确 对于 神经 
网络 的 各层 输出 由于 它们 经 过了 层内 操作 
作用 各层 的 输入 信号 的 分布 显然 不同 而且 
差异 会 随着 网络 深度 增大 而 增大 可是 它们 
所能 指示 的 样本 标记 label 仍然 是 不变 的 
这 便 符合 了 covariate shift 的 定义 由 于是 
对 层间 信号 的 分析 也 即是 internal 的 来由 
问题 描述 简而言之 每个 神经元 的 输入 数据 不再 是 
独立 同 分布 其一 上层 参数 需要 不断 适应 新的 
输入 数据分布 降低 学习 速度 其二 下层 输入 的 变化 
可能 趋向于 变大 或者 变小 导致 上层 落入 饱和 区 
使得 学习 过早 停止 其三 每层 的 更新 都会 影响 
到 其它 层 因此 每层 的 参数 更 新策略 需要 
尽可能 的 谨慎 2 问题 挑战 我们 以 神经 网络 
中 的 一个 普通 神经元 为例 神经元 接收 一组 输入 
向量 通过 某种 运算 后 输 出 一个 标 量值 
由于 ICS 问题 的 存在 对于 某一 特定 层 不同 
批次 的 输入 的 分布 可能 相差 很大 要 解决 
独立 同 分布 的 问题 理论 正确 的 方法 就是 
对 每 一层 的 数据 都 进行 白化 操作 然而 
标准 的 白化 操作 代价 高昂 特别 是 我们 还 
希望 白化 操作 是 可微 的 保证 白化 操作 可以 
通过 反向 传播 来 更新 梯度 三 解决 思路 BN1 
通用 框 架在 将 送给 神经元 之前 先 对其 做 
平移 和 伸缩 变换 将 的 分布 规范 化成 在 
固定 区间 范围 的 标准 分布 通用 变换 框架 就 
如下 所示 1 是 平移 参数 shift parameter 是 缩放 
参数 scale parameter 通过 这 两个 参数 进行 shift 和 
scale 变换 得到 的 数据 符合 均值 为 0 方差 
为 1 的 标准 分布 2 是 再 平移 参数 
re shift parameter 是 再 缩放 参数 re scale parameter 
将 上 一步 得到 的 进一步 变换 为 最终 得到 
的 数据 符合 均值 为 方差 为 的 分布 2 
第二 次 变换 的 目的 1 目的 一 第一 次 
变换 得到 均值 为 0 方差 为 1 的 标准 
分布 表达 能力 有限 下层 神经元 可能 很 努力 地 
在 学习 但 不论 其 如何 变化 其 输出 的 
结果 在 交给 上层 神经元 进行 处理 之前 将被 粗暴 
地 重新 调整 到 这一 固定 范围 为了 更好 的 
应用 底层 神经 网络 的 学习 结果 我们/r 将/d 规范化/n 
后的/nr 数据/n 进行/v 再/d 平移/v 和再/nr 缩放/v 使得 每个 神经元 
对应 的 输入 范围 是 针对 该 神经元 量身 定制 
的 一个 确定 范围 均值 为 方差 为 rescale 和 
reshift 的 参数 都是 可 学习 的 这就 使得 Normalization 
层 可以 学习 如何 去 适应 底层 的 学习 结果 
2 目的 二 除了 充分利用 底层 学习 的 能力 另一 
方面 的 重要 意义 在于 保证 获得 非线性 的 表达 
能力 Sigmoid 等 激活 函数 在 神经 网络 中 有着 
重要 作用 通过 区分 饱和 区 和 非饱和 区 使得 
神经 网络 的 数据 变换 具有 了 非线性 计算能力 而 
第一步 的 规范化 会将 几乎 所有 数据 映 射到 激活 
函数 的 非饱和 区 线性 区 仅 利用 到了 线性 
变化 能力 从而 降低 了 神经 网络 的 表达 能力 
而 进行 再变换 则 可以 将 数据 从 线性 区 
变换 到 非线性 区 恢复 模型 的 表达 能力 3 
优势 不 添加 正则化 的 均值 取决于 下层 神经 网络 
的 复杂 关联 添加 本 层 后 取值 仅 由 
来 确定 去 除了 与 下层 计算 的 密切 耦合 
新 参数 很 容易 通过 梯度 下降 来 学习 简化 
了 神经 网络 的 训练 4 问题 a BN 的 
实际 作用 标准 白化 操作 的 目的 是 独立 同 
分布 独立 就 不说 了 暂 不考虑 变换 为 均值 
为 方差 为 的 分布 也 并 不是 严格 的 
同 分布 只是 映 射到 了 一个 确定 的 区间 
范围 而已 所以 这个 问题 仍然 有 研究 空间 另外 
有人 提出 BN 其 优势 并 非 解决 了 独立 
同 分布 的 问题 实际上 它 也没 解决 其 最大 
意义 在于 解决 了 梯度 弥散 问题 见 论文 How 
Does Batch Normalization Help Optimization 知乎 上 的 一篇 阅读 
笔记 为什么 Batch Normalization 那么 有用 文章 结论 如下 没有 
证据 表明 BN 的 work 是 因为 减少 了 ICS 
Interval Covariate Shift BN work 的 根本 原因 是 因为 
在 网络 的 训练 阶段 其 能够 让 优化 空间 
optimization landscape 变 的 平滑 其他 的 normalization 技术 也 
能够 像 BN 那样 对于 网络 的 训练 起到 作用 
其 作用 为 防止 梯度 爆炸 或 弥散 可以 提高 
训练 时 模型 对于 不同 超 参 学习率 初始化 的 
鲁棒性 可以 让 大部分 的 激活 函数 能够 远离 其 
饱和 区域 b BN 对 小批 次 训练 效果 不好 
当 单个 小 批次 minibatch 的 数据 不能 代表 整个 
数据 的 分布 时 BN 的 表现 就会 不 尽如人意 
这 意味着 忘记 将 输入 随机 打乱 顺序 的 情况 
下 使用 批 归一化 是 很 危险 的 实际上 batch 
过小 的 时候 就 不太 适合 开放 BN 的 可 
训练 性 具体 讨论 见 论文 Batch Normalization Accelerating Deep 
Network Training by Reducing BN 训练 时 为什么 不 使用 
全局 均值 / 方差 使用 BN 的 目的 就是 为了 
保证 每批 数据 的 分布 稳定 使用 全局 统计量 反而 
违背 了 这个 初衷 BN 的 作者 认为 在 训练 
时 采用 移动 平均 可能会 与 梯度 优化 存在 冲突 
四 主流 Normalization 方法 梳理 BatchNorm batch 方向 做 归一化 
算 N * H * W 的 均值 LayerNorm channel 
方向 做 归一化 算 C * H * W 的 
均值 InstanceNorm 一个 channel 内 做 归一化 算 H * 
W 的 均值 GroupNorm 将 channel 方向 分 group 然后 
每个 group 内 做 归一化 算 C / / G 
* H * W 的 均值 https / / zhuanlan 
. zhihu . com / p / 696598441 Batch Normalization 
TensorFlow 批处理 类 教程 Batch Normalization 层 介绍 于 2015年 
由 Google 提出 BN 独立 地 规范化 每一个 层 不同 
批次 的 但 规范化 的 参数 是 一个 mini batch 
的 一 阶 统计量 和 二阶 统计量 这就 要求 每一个 
mini batch 的 统计 量 是 整体 统计量 的 近似 
估计 或者说 每 一个 mini batch 彼此之间 以及 和 整体 
数据 都 应该 是 近似 同 分布 的 分布 差距 
较小 的 mini batch 可以 看做 是 为 规范化 操作 
和 模型 训练 引入 了 噪声 可以 增加 模型 的 
鲁棒性 但 如果 每个 mini batch 的 原始 分布 差别 
很大 那么 不同 mini batch 的 数据 将 会 进行 
不 一样 的 数据 变换 这就 增加 了 模型 训练 
的 难度 训练 时 网络 会 记录 每一个 batch 滑动 
平均 的 均值 和 方差 训练 结束 的 时候 这四个 
参数 就 固定 了 供 测试 时 直接 加载 使用 
BN 比较 适用 的 场景 是 每个 mini batch 比较 
大 数据分布 比较 接近 在 进行 训练 之前 要 做好 
充分 的 shuffle 否则 效果 会 差 很多 另外 由于 
BN 需要 在 运行 过程 中 统计 每个 mini batch 
的 一 阶 统计量 和 二阶 统计量 因此 不 适用 
于 动态 的 网络 结构 和 RNN 网络 不过 也有 
研究者 专门 提出 了 适用于 RNN 的 BN 使用 方法 
这里 先不 展开 了 2 Layer NormalizationLN 针对 单个 训练样本 
进行 不 依赖 于 其他 数据 因此 可以 避免 BN 
中 受 mini batch 数据分布 影响 的 问题 可以 用于 
小 mini batch 场景 动态网络 场景 和 RNN 特别 是 
自然 语言 处理 领域 此外 LN 不 需要 保存 mini 
batch 的 均值 和 方差 节省 了 额外 的 存储空间 
但是 BN 的 转换 是 针对 单个 神经元 可 训练 
的 不同 神经元 的 输入 经过 再 平移 和再缩/nr 放后 
分布 在 不同 的 区间 而 LN 对于 一 整层 
的 神经元 训练 得到 同 一个 转换 所有 的 输入 
都在 同一个 区间 范围内 如果 不 同 输入 特征 不属于 
相似 的 类别 比如 颜色 和 大小 那么 LN 的 
处理 可能 会 降低 模型 的 表达 能力 3 Instance 
Normalization 在 GAN 和 style transfer 的 任务 中 目前 
的 IN norm 要好 于 BN IN 主要 用于 对 
单张 图像 的 数据 做 处理 而 BN 主要 是 
对 Bacth 的 数据 做 处理 由于/c BN/w 在/p 训练/vn 
时/n 每个/r batch/w 的/uj 均值/n 和/c 方差/n 会/v 由于/c shuffle/w 
都会/i 改变/v 所以 可以 理解 为 一种 数据 增强 而 
IN 可以 理解 为 对 数据 做 一个 归一化 的 
操作 换句话说 BN 的 计算 是 要 受 其他 样本 
影响 的 由于 每个 batch 的 均值 和 标准差 不稳定 
对于 单个 数据 而言 相对于 是 引入 了 噪声 但在 
分类 这种 问题 上 结果/n 和/c 数据/n 的/uj 整体/n 分布/v 
有/v 关系/n 因此 需要 通过 BN 获得 数据 的 整体 
分布 而 instance norm/w 的/uj 信息/n 都是/nr 来自/v 于/p 自身/r 
的/uj 图片/n 相当于 对 全局 信息 做 了 一次 整合 
和 调整 在 图像 转换 这种 问题 上 BN 获得 
的 整体 信息 不会 带来 任何 收益 带来 的 噪声 
反而会 弱化 实例 之间 的 独立性 这类 生成式 方法 每张 
图片 自己 的 风格 比较 独立 不 应该 与 batch 
中 其他 的 样本 产生 太大 联系 4 Group N 
o r m a l i z a t i 
o n g r o u p normalization/w 是/v 2018年/tdq 
3/m 月份/n 何恺明/nr 大神/n 的/uj 又一/i 力作/n 优化 了 BN 
在 比较 小 的 mini batch 情况 下 表现 不太好 
的 劣势 批量 维度 进行 归一化 会 带来 一些 问题 
批量 统计 估算 不准确 导致 批 量变 小时 BN 的 
误差 会 迅速 增加 在 训练 大型 网络 和将/nr 特征 
转移 到 计算机 视觉 任务 中 包括 检测 分割 和 
视频 内存 消耗 限制 了 只能 使用 小 批量 的 
BN 事实上 GN 的 极端 情况 就是 LN 和 IN 
分别 对应 G 等于 C 和G/nr 等于 1 tf 实现 
并 不复杂 如下 def GroupNorm x G = 16 eps 
= 1e 5 N H W C = x . 
shape x = tf . reshape x tf . cast 
N tf . int32 tf . cast H tf . 
int32 tf . cast W tf . int32 tf . 
cast G tf . int32 tf . cast C / 
/ G tf . int32 mean var = tf . 
nn . moments x 1 2 4 keep _ dims 
= True x = x mean / tf . sqrt 
var + eps x = tf . reshape x tf 
. cast N tf . int32 tf . cast H 
tf . int32 tf . cast W tf . int32 
tf . cast C tf . int32 gamma = tf 
. Variable tf . ones shape = 1 1 1 
tf . cast C tf . int32 name = gamma 
beta = tf . Variable tf . zeros shape = 
1 1 1 tf . cast C tf . int32 
name = beta return x * gamma + beta 在 
深度 学习 没有 火 起来 之前 提取 特征 通常 是 
使用 SIFT HOG 和 GIST 特征 这些 特征 有 一个 
共性 都 具有 按 group 表示 的 特性 每一个 group 
由 相同 种类 直方图 的 构建 而成 这些 特征 通常 
是 对在 每个 直方图 histogram 或 每个 方向 orientation 上 
进行 组 归一化 group wise norm 而 得到 从 深度 
学习 上 来讲 完全 可以 认为 卷积 提取 的 特征 
是 一种 非 结构化 的 特征 或者 向量 拿 网络 
的 第一 层 卷积 为例 卷积 层 中的 的 卷积 
核 filter1 和此/nr 卷积 核 的 其他 经过 transform 过 
的 版本 filter2 transform 可以 是 horizontal flipping 等 在 
同一 张 图像 上 学习 到 的 特征 应该 是 
具有 相同 的 分布 那么 具有 相同 的 特征 可以 
被 分到 同一个 group 中 按照 个人 理解 每 一层 
有 很多 的 卷积 核 这些 核 学习 到 的 
特征 并不 完全 是 独立 的 某些 特征 具有 相同 
的 分布 因此 可以 被 group 