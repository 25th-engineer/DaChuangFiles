图像的卷积：一幅图像与一个矩阵做卷积，矩阵必须为m*n的（矩阵中必须有中心点），将图像中的点与这个矩阵的中心点对应，对于m*n个位置，相对应的两点分别相乘，再把这m*n个乘积相加除以m*n，所得结果即为结果图像中相应的点。如下图：核函数（SVM中）：解决线性不可分问题的基本思路——向高维空间转化，使其变得线性可分。计算方面我们只关心那个高维空间里内积的值，那个值算出来了，分类结果就算出来了。核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值。范数(norm)：对于向量v，它的lp Norms为：当v是向量之差时，其与l1距离，l2距离等是一个意思：KNN（K nearest neighbor）：nearest neighbor分类方法是计算新样本与训练集中的最小距离来决定它的分类。KNN扩展了这种思想：选择K个最近的邻居，邻居中各自分类可能不同，可以取大多数的共同分类。Decision Directed Acyclic Graph (DDAG)：用来将多个两类分类器组合成一个多类分类器。对于一个N类的分类器，需要N(N-1)/2个两类分类器（每一对类之间一个）。Kernel methods：如Support Vector Machines, Gaussian Processes等在监督和非监督的机器学习上表现很好。它们的关键在于Kernel methods可以被分为两个模块：1.将数据映射到高位的特征空间，这对于不同种类的数据是一种强大的框架。2.在特征空间使用线性算法，它高效且有理论支持。Kernel Matrix：设有高维映射则Kernel Matrix定义为：<>表示内积。超平面：是 n 维欧氏空间中余维度等于一的线性子空间。这是平面中的直线、空间中的平面之推广。