图像 的 卷积 一幅 图像 与 一个 矩阵 做 卷积 
矩阵 必须 为 m * n 的 矩阵 中 必须 
有 中心点 将 图像 中的 点 与 这个 矩阵 的 
中心点 对应 对于 m * n 个 位置 相 对应 
的 两点 分别 相乘 再 把这 m * n 个 
乘积 相加 除以 m * n 所得 结果 即为 结果 
图像 中 相应 的 点 如 下图 核 函数 SVM 
中 解决 线性 不可分 问题 的 基本 思路 向 高维空间 
转化 使其 变得 线性 可分 计算 方面 我们 只 关心 
那个 高维空间 里 内积 的 值 那个 值 算 出来 
了 分类 结果 就 算 出来 了 核 函数 的 
基本 作用 就是 接受 两个 低维 空间 里 的 向量 
能够 计算 出 经过 某个 变换 后在/nr 高维空间 里 的 
向量 内积 值 范数 norm 对于 向量 v 它 的 
lp Norms 为 当 v 是 向量 之差 时 其 
与 l1 距离 l2 距离 等 是 一个 意思 KNN 
K nearest neighbor nearest neighbor 分类 方法 是 计算 新 
样本 与 训练 集中 的 最小 距离 来 决定 它 
的 分类 KNN 扩展 了 这种 思想 选择 K 个 
最近 的 邻居 邻 居中 各自 分类 可能 不同 可以 
取 大多数 的 共同 分类 Decision Directed Acyclic Graph DDAG 
用来 将 多个 两类 分类器 组合 成 一个 多类 分类器 
对于 一个 N 类 的 分类器 需要 N N 1 
/ 2 个 两类 分类器 每 一对 类 之间 一个 
Kernel methods 如 Support Vector Machines Gaussian Processes 等在 监督 
和非/nr 监督 的 机器 学习 上 表现 很好 它们 的 
关键 在于 Kernel methods 可以 被 分为 两个 模块 1 
. 将 数据 映 射到 高位 的 特征 空间 这 
对于 不同 种类 的 数据 是 一种 强大 的 框架 
2 . 在 特征 空间 使用 线性 算法 它 高效 
且有 理论 支持 Kernel Matrix 设有 高维 映射 则 Kernel 
Matrix 定义 为 表示 内积 超平面 是 n 维 欧氏 
空间 中 余 维度 等于 一 的 线性 子空间 这是 
平面 中的 直线 空间 中 的 平面 之 推广 图像 的 卷积 一幅 图像 与 一个 矩阵 做 卷积 
矩阵 必须 为 m * n 的 矩阵 中 必须 
有 中心点 将 图像 中的 点 与 这个 矩阵 的 
中心点 对应 对于 m * n 个 位置 相 对应 
的 两点 分别 相乘 再 把这 m * n 个 
乘积 相加 除以 m * n 所得 结果 即为 结果 
图像 中 相应 的 点 如 下图 核 函数 SVM 
中 解决 线性 不可分 问题 的 基本 思路 向 高维空间 
转化 使其 变得 线性 可分 计算 方面 我们 只 关心 
那个 高维空间 里 内积 的 值 那个 值 算 出来 
了 分类 结果 就 算 出来 了 核 函数 的 
基本 作用 就是 接受 两个 低维 空间 里 的 向量 
能够 计算 出 经过 某个 变换 后在/nr 高维空间 里 的 
向量 内积 值 范数 norm 对于 向量 v 它 的 
lp Norms 为 当 v 是 向量 之差 时 其 
与 l1 距离 l2 距离 等 是 一个 意思 KNN 
K nearest neighbor nearest neighbor 分类 方法 是 计算 新 
样本 与 训练 集中 的 最小 距离 来 决定 它 
的 分类 KNN 扩展 了 这种 思想 选择 K 个 
最近 的 邻居 邻 居中 各自 分类 可能 不同 可以 
取 大多数 的 共同 分类 Decision Directed Acyclic Graph DDAG 
用来 将 多个 两类 分类器 组合 成 一个 多类 分类器 
对于 一个 N 类 的 分类器 需要 N N 1 
/ 2 个 两类 分类器 每 一对 类 之间 一个 
Kernel methods 如 Support Vector Machines Gaussian Processes 等在 监督 
和非/nr 监督 的 机器 学习 上 表现 很好 它们 的 
关键 在于 Kernel methods 可以 被 分为 两个 模块 1 
. 将 数据 映 射到 高位 的 特征 空间 这 
对于 不同 种类 的 数据 是 一种 强大 的 框架 
2 . 在 特征 空间 使用 线性 算法 它 高效 
且有 理论 支持 Kernel Matrix 设有 高维 映射 则 Kernel 
Matrix 定义 为 表示 内积 超平面 是 n 维 欧氏 
空间 中 余 维度 等于 一 的 线性 子空间 这是 
平面 中的 直线 空间 中 的 平面 之 推广 图像 的 卷积 一幅 图像 与 一个 矩阵 做 卷积 
矩阵 必须 为 m * n 的 矩阵 中 必须 
有 中心点 将 图像 中的 点 与 这个 矩阵 的 
中心点 对应 对于 m * n 个 位置 相 对应 
的 两点 分别 相乘 再 把这 m * n 个 
乘积 相加 除以 m * n 所得 结果 即为 结果 
图像 中 相应 的 点 如 下图 核 函数 SVM 
中 解决 线性 不可分 问题 的 基本 思路 向 高维空间 
转化 使其 变得 线性 可分 计算 方面 我们 只 关心 
那个 高维空间 里 内积 的 值 那个 值 算 出来 
了 分类 结果 就 算 出来 了 核 函数 的 
基本 作用 就是 接受 两个 低维 空间 里 的 向量 
能够 计算 出 经过 某个 变换 后在/nr 高维空间 里 的 
向量 内积 值 范数 norm 对于 向量 v 它 的 
lp Norms 为 当 v 是 向量 之差 时 其 
与 l1 距离 l2 距离 等 是 一个 意思 KNN 
K nearest neighbor nearest neighbor 分类 方法 是 计算 新 
样本 与 训练 集中 的 最小 距离 来 决定 它 
的 分类 KNN 扩展 了 这种 思想 选择 K 个 
最近 的 邻居 邻 居中 各自 分类 可能 不同 可以 
取 大多数 的 共同 分类 Decision Directed Acyclic Graph DDAG 
用来 将 多个 两类 分类器 组合 成 一个 多类 分类器 
对于 一个 N 类 的 分类器 需要 N N 1 
/ 2 个 两类 分类器 每 一对 类 之间 一个 
Kernel methods 如 Support Vector Machines Gaussian Processes 等在 监督 
和非/nr 监督 的 机器 学习 上 表现 很好 它们 的 
关键 在于 Kernel methods 可以 被 分为 两个 模块 1 
. 将 数据 映 射到 高位 的 特征 空间 这 
对于 不同 种类 的 数据 是 一种 强大 的 框架 
2 . 在 特征 空间 使用 线性 算法 它 高效 
且有 理论 支持 Kernel Matrix 设有 高维 映射 则 Kernel 
Matrix 定义 为 表示 内积 超平面 是 n 维 欧氏 
空间 中 余 维度 等于 一 的 线性 子空间 这是 
平面 中的 直线 空间 中 的 平面 之 推广 