Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 training 网络 简介 流程 和 inference 大部分 一致 在下 
图中 我们 将 之前 inference 就 介绍 过 的 分类 
回归 和 掩码 生成 流程 压缩 到 一个 块 中 
以便 其他 部分 更为 清晰 而 两者 主要 不同之处 为 
网络 输入 输入 tensor 增加 到了 7个 之多 图上 画出 
的 6个 以及 image _ meta 大 部分 是 计算 
Loss 的 标签 前置 损失 函数 添加 了 5个 损失 
函数 2个 用于 RPN 计算 2个 用于 最终 分类 回归 
instance 1个 用于 掩码 损失 计算 原始 标签 处理 推理 
网络 中 Proposeal 筛选 出来 的 rpn _ rois 直接 
用于 生成 分类 回归 以及 掩码 信息 而 training 中 
这些 候 选区 需要 和 图片 标签 信息 进行 运算 
生成 有 训练 价值 的 输出 进行 后面 的 生成 
以及 损失 函数 计算 首先 初始化 并 载入 预 训练 
参数 下 节会 介绍 本 部分 相关 操作 然后 经由 
下面 几行 代码 即可 进行 训练 网络 输入 build 函数 
在 train 方法 中被 调用 model . py 涉及 巨 
多 预 处理函数 设计 需要 的 时候 自行 进入 train 
方法 查看 更 确切 的 说是 在 data _ generator 
方法 由 train 调用 images batch H W C image 
_ meta batch meta data Image details . See compose 
_ image _ meta rpn _ match batch N Integer 
1 = positive anchor 1 = negative 0 = neutral 
rpn _ bbox batch N dy dx log dh log 
dw Anchor bbox deltas . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs gt 
_ boxes batch MAX _ GT _ INSTANCES y1 x1 
y2 x2 gt _ masks batch height width MAX _ 
GT _ INSTANCES . The height and widthare those of 
the image unless use _ mini _ mask is True 
in whichcase they are defined in MINI _ MASK _ 
SHAPE . 原始 标签 处理 然后 我们 在 开篇 流程图 
中 标注 了 一个 名为 检测 目标 处理 的 框 
对应 代码 如下 # Generate detection targets # Subsamples proposals 
and generates target outputs for training # Note that proposal 
class IDs gt _ boxes and gt _ masks are 
zero # padded . Equally returned rois and targets are 
zero padded . rois target _ class _ ids target 
_ bbox target _ mask = \ D e t 
e c t i o n T a r g 
e t L a y e r config name = 
proposal _ targets target _ rois input _ gt _ 
class _ ids gt _ boxes input _ gt _ 
masks 其 目的 是 将 原始 的 图像 信息 input 
和 proposal 们 进行 计算 融合 输出 可以 用于 Loss 
计算 的 标准 的 格式 文档 很 清晰 Subsamples proposals 
and generates target box refinement class _ ids and masks 
for each . Inputs proposals batch N y1 x1 y2 
x2 in normalized coordinates . Mightbe zero padded if there 
are not enough proposals . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs . 
gt _ boxes batch MAX _ GT _ INSTANCES y1 
x1 y2 x2 in n o r m a l 
i z e d c o o r d i 
n a t e s . gt _ masks batch 
height width MAX _ GT _ INSTANCES of boolean typeReturns 
Target ROIs and corresponding class IDs bounding box shifts and 
masks . rois batch TRAIN _ ROIS _ PER _ 
IMAGE y1 x1 y2 x2 in n o r m 
a l i z e d c o o r 
d i n a t e s t a r 
g e t _ class _ ids batch TRAIN _ 
ROIS _ PER _ IMAGE . Integer class IDs . 
target _ deltas batch TRAIN _ ROIS _ PER _ 
IMAGE dy dx log dh log dw target _ mask 
batch TRAIN _ ROIS _ PER _ IMAGE height width 
Masks cropped to bbox boundaries and resized to neuralnetwork output 
size . Note Returned arrays might be zero padded if 
not enough target ROIs . 这个 处理 之后 结构 同 
inference 中的 介绍 mrcnn _ class _ logits mrcnn _ 
class mrcnn _ bbox = \ fpn _ classifier _ 
graph rois mrcnn _ feature _ maps input _ image 
_ meta config . POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN fc _ layers _ size = config . FPN 
_ CLASSIF _ FC _ LAYERS _ SIZE mrcnn _ 
mask = build _ fpn _ mask _ graph rois 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN 损失 函数 然后 就是 损失 函 数了 浩浩荡荡 10 
来 行 注意 output _ rois 这 一行 我们 之前 
就 提过 keras 中 接收 tf 的 Tensor 只能 作为 
class 的 初始化 参数 而 不能 作为 网络 数据流 所以 
这里 加了 一层 封装 output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask 二 损失 函数 简介 RPN 分类 
损失 我们 先 看一下 RPN 真实 标签 生成 函数 中的 
一段 注释 # Match anchors to GT Boxes # If 
an anchor overlaps a GT box with IoU = 0.7 
then it s positive . # If an anchor overlaps 
a GT box with IoU 0.3 then it s negative 
. # Neutral anchors are those that don t match 
the conditions above # and they don t influence the 
loss function . # However don t keep any GT 
box unmatched rare but happens . Instead # match it 
to the closest anchor even if its max IoU is 
0.3 . 然后 看 本 损失 函数 def rpn _ 
class _ loss _ graph rpn _ match rpn _ 
class _ logits RPN anchor classifier loss . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ class _ logits batch anchors 2 . RPN 
classifier logits for FG / BG . # Squeeze last 
dim to simplify rpn _ match = tf . squeeze 
rpn _ match 1 # Get anchor classes . Convert 
the 1 / + 1 match to 0/1 values . 
anchor _ class = K . cast K . equal 
rpn _ match 1 tf . int32 # Positive and 
Negative anchors contribute to the loss # but neutral anchors 
match value = 0 don t . indices = tf 
. where K . not _ equal rpn _ match 
0 # Pick rows that contribute to the loss and 
filter out the rest . rpn _ class _ logits 
= tf . gather _ nd rpn _ class _ 
logits indices anchor _ class = tf . gather _ 
nd anchor _ class indices # Cross entropy loss loss 
= K . sparse _ categorical _ crossentropy target = 
anchor _ class output = rpn _ class _ logits 
from _ logits = True loss = K . switch 
tf . size loss 0 K . mean loss tf 
. constant 0.0 return loss 真实 标 签有 { 1 
0 1 } 三种 logits 结果 在 0 ~ 1 
分布 而在 RPN 分类 结果 中 真实 标签 为 0 
的 anchors 不 参与 损失 函数 的 构建 所以 我们 
将 标签 为 0 的 真实 标签 剔除 然后 将 
1 标签 转换 为 0 进行 交叉 熵 计算 RPN 
回归 损失 def rpn _ bbox _ loss _ graph 
config target _ bbox rpn _ match rpn _ bbox 
Return the RPN bounding box loss graph . config the 
model config object . target _ bbox batch max positive 
anchors dy dx log dh log dw . Uses 0 
padding to fill in unsed bbox deltas . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ bbox batch anchors dy dx log dh log 
dw # input _ rpn _ bbox input _ rpn 
_ match rpn _ bbox # Positive anchors contribute to 
the loss but negative and # neutral anchors match value 
of 0 or 1 don t . rpn _ match 
= K . squeeze rpn _ match 1 # batch 
anchors indices = tf . where K . equal rpn 
_ match 1 # Pick bbox deltas that contribute to 
the loss rpn _ bbox = tf . gather _ 
nd rpn _ bbox indices # n 4 # Trim 
target bounding box deltas to the same length as rpn 
_ bbox . batch _ counts = K . sum 
K . cast K . equal rpn _ match 1 
tf . int32 axis = 1 # 1 标签 数目 
# target _ bbox batch max positive anchors dy dx 
log dh log dw # rpn _ match batch target 
_ bbox = batch _ pack _ graph target _ 
bbox batch _ counts config . IMAGES _ PER _ 
GPU loss = smooth _ l1 _ loss target _ 
bbox rpn _ bbox loss = K . switch tf 
. size loss 0 K . mean loss tf . 
constant 0.0 return loss 仅仅 真实 标签 为 1 的 
类 参与 回归 运算 对于 target _ bbox 虽然 对 
每张 图片 其 框 数 一致 且 和 rpn _ 
match 的 第二 维度 相等 但是 对于 图片 i 只有 
前 面的 Ni 个 框 有意义 而 不是 和 anchors 
一一对应 的 后 面为 0 填充 Ni 值 等于 对应 
图片 的 rpn _ match 等于 1 的 数目 推测 
target _ bbox 中 bbox 坐标 的 排列 顺序 等于 
rpn _ match 中的 标识 顺序 所以/c 使用/v rpn/w _/i 
match/w 索/nr 引出/v rpn/w _/i bbox/w 对应/vn 1/m 的/uj 位置/v 
后/f 直接/ad 和/c target/w _/i bbox/w 的/uj 前/f Ni/w 运算/vn 
即可/d def/w batch _ pack _ graph x counts num 
_ rows Picks different number of values from each row 
in x depending on the values in counts . x 
batch max positive anchors dy dx log dh log dw 
counts batch outputs = for i in range num _ 
rows outputs . append x i counts i return tf 
. concat outputs axis = 0 损失 函数 使用 smooth 
_ l1 _ loss 坐标 回归 都用 这个 def smooth 
_ l1 _ loss y _ true y _ pred 
Implements Smooth L1 loss . y _ true and y 
_ pred are typically N 4 but could be any 
shape . diff = K . abs y _ true 
y _ pred less _ than _ one = K 
. cast K . less diff 1.0 float32 loss = 
less _ than _ one * 0.5 * diff * 
* 2 + 1 less _ than _ one * 
diff 0.5 return loss 附 我 在 数据 准备 函数 
build _ rpn _ targets 中 查询 到 如下 片段 
可以 佐证 上面 说法 下面 的 rpn _ box 对应 
上面 的 target _ bbox 即 target _ box 和 
anchor 并不 一一对应 仅 根据 正 样本 标签 数目 进行 
填充 代码 片段 1 两者 注册 长度 都 不一样 # 
RPN Match 1 = positive anchor 1 = negative anchor 
0 = neutral rpn _ match = np . zeros 
anchors . shape 0 dtype = np . int32 # 
RPN bounding boxes max anchors per image dy dx log 
dh log dw rpn _ bbox = np . zeros 
config . RPN _ TRAIN _ ANCHORS _ PER _ 
IMAGE 4 代码 片段 2 # For positive anchors compute 
shift and scale needed to transform them # to match 
the corresponding GT boxes . ids = np . where 
rpn _ match = = 1 0 ix = 0 
# index into rpn _ bbox # TODO use box 
_ refinement rather than duplicating the code here for i 
a in zip ids anchors ids # Closest gt box 
it might have IoU 0.7 gt = gt _ boxes 
anchor _ iou _ argmax i # Convert coordinates to 
center plus width / height . # GT Box gt 
_ h = gt 2 gt 0 gt _ w 
= gt 3 gt 1 gt _ center _ y 
= gt 0 + 0.5 * gt _ h gt 
_ center _ x = gt 1 + 0.5 * 
gt _ w # Anchor a _ h = a 
2 a 0 a _ w = a 3 a 
1 a _ center _ y = a 0 + 
0.5 * a _ h a _ center _ x 
= a 1 + 0.5 * a _ w # 
Compute the bbox refinement that the RPN should predict . 
rpn _ bbox ix = gt _ center _ y 
a _ center _ y / a _ h gt 
_ center _ x a _ center _ x / 
a _ w np . log gt _ h / 
a _ h np . log gt _ w / 
a _ w # Normalize rpn _ bbox ix / 
= config . RPN _ BBOX _ STD _ DEV 
ix + = 1 return rpn _ match rpn _ 
bboxMRCNN 分类 损失 函数 如果 分类 得分 最高 class 不 
对应 于本/nr 数据集 则不 贡献 Loss 值 def mrcnn _ 
class _ loss _ graph target _ class _ ids 
pred _ class _ logits active _ class _ ids 
Loss for the classifier head of Mask RCNN . target 
_ class _ ids batch num _ rois . Integer 
class IDs . Uses zero padding to fill in the 
array . pred _ class _ logits batch num _ 
rois num _ classes active _ class _ ids batch 
num _ classes . Has a value of 1 for 
classes that are in the dataset of the image and 
0 for classes that are not in the dataset . 
# During model building Keras calls this function with # 
target _ class _ ids of type float32 . Unclear 
why . Cast it # to int to get around 
it . target _ class _ ids = tf . 
cast target _ class _ ids int64 # Find predictions 
of classes that are not in the dataset . pred 
_ class _ ids = tf . argmax pred _ 
class _ logits axis = 2 # TODO Update this 
line to work with batch 1 . Right now it 
assumes all # images in a batch have the same 
active _ class _ ids pred _ active = tf 
. gather active _ class _ ids 0 pred _ 
class _ ids # Loss loss = tf . nn 
. sparse _ softmax _ cross _ entropy _ with 
_ logits labels = target _ class _ ids logits 
= pred _ class _ logits # batch num _ 
rois # Erase losses of predictions of classes that are 
not in the active # classes of the image . 
loss = loss * pred _ active # batch num 
_ rois ~ { 0 1 } * batch num 
_ rois # Computer loss mean . Use only predictions 
that contribute # to the loss to get a correct 
mean . loss = tf . reduce _ sum loss 
/ tf . reduce _ sum pred _ active return 
loss 涉及 到 active _ class _ ids 相关 如下 
即将 该 图片 隶属 数据 集中 所有 的 class 标记 
为 1 不 隶属 本 数据 集合 的 class 标记 
为 0 计算 Loss 贡献 时 交叉 熵 会对 每个 
框 进行 输出 一个 值 如果 这个 框 最大 的 
得分 class 并不 属于 其 数据集 则 不计 本 框 
Loss active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
# # Active classes # # Different datasets have different 
classes so track the # # classes supported in the 
dataset of this image . # active _ class _ 
ids = np . zeros dataset . num _ classes 
dtype = np . int32 # source _ class _ 
ids = dataset . source _ class _ ids dataset 
. image _ info image _ id source # active 
_ class _ ids source _ class _ ids = 
1MRCNN 回归 损失 函数 仅 计算 真实 标签 非 背景 
class 分类 数 大于 0 由于 预测 对于 每个 框体 
的 每个 类别 都有 回归 输出 batch num _ rois 
num _ classes dy dx log dh log dw 仅 
计算 真实 类别 的 回归 Loss 代码 如下 def mrcnn 
_ bbox _ loss _ graph target _ bbox target 
_ class _ ids pred _ bbox Loss for Mask 
R CNN bounding box refinement . target _ bbox batch 
num _ rois dy dx log dh log dw target 
_ class _ ids batch num _ rois . Integer 
class IDs . pred _ bbox batch num _ rois 
num _ classes dy dx log dh log dw # 
Reshape to merge batch and roi dimensions for simplicity . 
target _ class _ ids = K . reshape target 
_ class _ ids 1 # batch * num _ 
rois target _ bbox = K . reshape target _ 
bbox 1 4 pred _ bbox = K . reshape 
pred _ bbox 1 K . int _ shape pred 
_ bbox 2 4 # Only positive ROIs contribute to 
the loss . And only # the right class _ 
id of each ROI . Get their indices . # 
class _ ids N where class _ ids 0 M 
1 即 where 会升 维 positive _ roi _ ix 
= tf . where target _ class _ ids 0 
0 # M positive _ roi _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ roi _ ix tf . int64 
# 框 序号 真实 类别 id indices = tf . 
stack positive _ roi _ ix positive _ roi _ 
class _ ids axis = 1 # Gather the deltas 
predicted and true that contribute to loss target _ bbox 
= tf . gather target _ bbox positive _ roi 
_ ix pred _ bbox = tf . gather _ 
nd pred _ bbox indices # Smooth L1 Loss loss 
= K . switch tf . size target _ bbox 
0 smooth _ l1 _ loss y _ true = 
target _ bbox y _ pred = pred _ bbox 
tf . constant 0.0 loss = K . mean loss 
return lossMRCNN 掩码 损失 函数 keras 的 二进制 交叉 熵 
实际 调用 的 就是 sigmoid 交叉 熵 的 后端 详见 
TensorFlow 分类 问题 与 交叉 熵 def mrcnn _ mask 
_ loss _ graph target _ masks target _ class 
_ ids pred _ masks Mask binary cross entropy loss 
for the masks head . target _ masks batch num 
_ rois height width . A float32 tensor of values 
0 or 1 . Uses zero padding to fill array 
. target _ class _ ids batch num _ rois 
. Integer class IDs . Zero padded . pred _ 
masks batch proposals height width num _ classes float32 tensor 
with values from 0 to 1 . # Reshape for 
simplicity . Merge first two dimensions into one . target 
_ class _ ids = K . reshape target _ 
class _ ids 1 mask _ shape = tf . 
shape target _ masks target _ masks = K . 
reshape target _ masks 1 mask _ shape 2 mask 
_ shape 3 pred _ shape = tf . shape 
pred _ masks pred _ masks = K . reshape 
pred _ masks 1 pred _ shape 2 pred _ 
shape 3 pred _ shape 4 # Permute predicted masks 
to N num _ classes height width pred _ masks 
= tf . transpose pred _ masks 0 3 1 
2 # Only positive ROIs contribute to the loss . 
And only # the class specific mask of each ROI 
. positive _ ix = tf . where target _ 
class _ ids 0 0 positive _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ ix tf . int64 indices = 
tf . stack positive _ ix positive _ class _ 
ids axis = 1 # Gather the masks predicted and 
true that contribute to loss y _ true = tf 
. gather target _ masks positive _ ix y _ 
pred = tf . gather _ nd pred _ masks 
indices # Compute binary cross entropy . If no positive 
ROIs then return 0 . # shape batch roi num 
_ classes loss = K . switch tf . size 
y _ true 0 K . binary _ crossentropy target 
= y _ true output = y _ pred tf 
. constant 0.0 loss = K . mean loss return 
loss Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 training 网络 简介 流程 和 inference 大部分 一致 在下 
图中 我们 将 之前 inference 就 介绍 过 的 分类 
回归 和 掩码 生成 流程 压缩 到 一个 块 中 
以便 其他 部分 更为 清晰 而 两者 主要 不同之处 为 
网络 输入 输入 tensor 增加 到了 7个 之多 图上 画出 
的 6个 以及 image _ meta 大 部分 是 计算 
Loss 的 标签 前置 损失 函数 添加 了 5个 损失 
函数 2个 用于 RPN 计算 2个 用于 最终 分类 回归 
instance 1个 用于 掩码 损失 计算 原始 标签 处理 推理 
网络 中 Proposeal 筛选 出来 的 rpn _ rois 直接 
用于 生成 分类 回归 以及 掩码 信息 而 training 中 
这些 候 选区 需要 和 图片 标签 信息 进行 运算 
生成 有 训练 价值 的 输出 进行 后面 的 生成 
以及 损失 函数 计算 首先 初始化 并 载入 预 训练 
参数 下 节会 介绍 本 部分 相关 操作 然后 经由 
下面 几行 代码 即可 进行 训练 网络 输入 build 函数 
在 train 方法 中被 调用 model . py 涉及 巨 
多 预 处理函数 设计 需要 的 时候 自行 进入 train 
方法 查看 更 确切 的 说是 在 data _ generator 
方法 由 train 调用 images batch H W C image 
_ meta batch meta data Image details . See compose 
_ image _ meta rpn _ match batch N Integer 
1 = positive anchor 1 = negative 0 = neutral 
rpn _ bbox batch N dy dx log dh log 
dw Anchor bbox deltas . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs gt 
_ boxes batch MAX _ GT _ INSTANCES y1 x1 
y2 x2 gt _ masks batch height width MAX _ 
GT _ INSTANCES . The height and widthare those of 
the image unless use _ mini _ mask is True 
in whichcase they are defined in MINI _ MASK _ 
SHAPE . 原始 标签 处理 然后 我们 在 开篇 流程图 
中 标注 了 一个 名为 检测 目标 处理 的 框 
对应 代码 如下 # Generate detection targets # Subsamples proposals 
and generates target outputs for training # Note that proposal 
class IDs gt _ boxes and gt _ masks are 
zero # padded . Equally returned rois and targets are 
zero padded . rois target _ class _ ids target 
_ bbox target _ mask = \ D e t 
e c t i o n T a r g 
e t L a y e r config name = 
proposal _ targets target _ rois input _ gt _ 
class _ ids gt _ boxes input _ gt _ 
masks 其 目的 是 将 原始 的 图像 信息 input 
和 proposal 们 进行 计算 融合 输出 可以 用于 Loss 
计算 的 标准 的 格式 文档 很 清晰 Subsamples proposals 
and generates target box refinement class _ ids and masks 
for each . Inputs proposals batch N y1 x1 y2 
x2 in normalized coordinates . Mightbe zero padded if there 
are not enough proposals . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs . 
gt _ boxes batch MAX _ GT _ INSTANCES y1 
x1 y2 x2 in n o r m a l 
i z e d c o o r d i 
n a t e s . gt _ masks batch 
height width MAX _ GT _ INSTANCES of boolean typeReturns 
Target ROIs and corresponding class IDs bounding box shifts and 
masks . rois batch TRAIN _ ROIS _ PER _ 
IMAGE y1 x1 y2 x2 in n o r m 
a l i z e d c o o r 
d i n a t e s t a r 
g e t _ class _ ids batch TRAIN _ 
ROIS _ PER _ IMAGE . Integer class IDs . 
target _ deltas batch TRAIN _ ROIS _ PER _ 
IMAGE dy dx log dh log dw target _ mask 
batch TRAIN _ ROIS _ PER _ IMAGE height width 
Masks cropped to bbox boundaries and resized to neuralnetwork output 
size . Note Returned arrays might be zero padded if 
not enough target ROIs . 这个 处理 之后 结构 同 
inference 中的 介绍 mrcnn _ class _ logits mrcnn _ 
class mrcnn _ bbox = \ fpn _ classifier _ 
graph rois mrcnn _ feature _ maps input _ image 
_ meta config . POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN fc _ layers _ size = config . FPN 
_ CLASSIF _ FC _ LAYERS _ SIZE mrcnn _ 
mask = build _ fpn _ mask _ graph rois 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN 损失 函数 然后 就是 损失 函 数了 浩浩荡荡 10 
来 行 注意 output _ rois 这 一行 我们 之前 
就 提过 keras 中 接收 tf 的 Tensor 只能 作为 
class 的 初始化 参数 而 不能 作为 网络 数据流 所以 
这里 加了 一层 封装 output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask 二 损失 函数 简介 RPN 分类 
损失 我们 先 看一下 RPN 真实 标签 生成 函数 中的 
一段 注释 # Match anchors to GT Boxes # If 
an anchor overlaps a GT box with IoU = 0.7 
then it s positive . # If an anchor overlaps 
a GT box with IoU 0.3 then it s negative 
. # Neutral anchors are those that don t match 
the conditions above # and they don t influence the 
loss function . # However don t keep any GT 
box unmatched rare but happens . Instead # match it 
to the closest anchor even if its max IoU is 
0.3 . 然后 看 本 损失 函数 def rpn _ 
class _ loss _ graph rpn _ match rpn _ 
class _ logits RPN anchor classifier loss . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ class _ logits batch anchors 2 . RPN 
classifier logits for FG / BG . # Squeeze last 
dim to simplify rpn _ match = tf . squeeze 
rpn _ match 1 # Get anchor classes . Convert 
the 1 / + 1 match to 0/1 values . 
anchor _ class = K . cast K . equal 
rpn _ match 1 tf . int32 # Positive and 
Negative anchors contribute to the loss # but neutral anchors 
match value = 0 don t . indices = tf 
. where K . not _ equal rpn _ match 
0 # Pick rows that contribute to the loss and 
filter out the rest . rpn _ class _ logits 
= tf . gather _ nd rpn _ class _ 
logits indices anchor _ class = tf . gather _ 
nd anchor _ class indices # Cross entropy loss loss 
= K . sparse _ categorical _ crossentropy target = 
anchor _ class output = rpn _ class _ logits 
from _ logits = True loss = K . switch 
tf . size loss 0 K . mean loss tf 
. constant 0.0 return loss 真实 标 签有 { 1 
0 1 } 三种 logits 结果 在 0 ~ 1 
分布 而在 RPN 分类 结果 中 真实 标签 为 0 
的 anchors 不 参与 损失 函数 的 构建 所以 我们 
将 标签 为 0 的 真实 标签 剔除 然后 将 
1 标签 转换 为 0 进行 交叉 熵 计算 RPN 
回归 损失 def rpn _ bbox _ loss _ graph 
config target _ bbox rpn _ match rpn _ bbox 
Return the RPN bounding box loss graph . config the 
model config object . target _ bbox batch max positive 
anchors dy dx log dh log dw . Uses 0 
padding to fill in unsed bbox deltas . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ bbox batch anchors dy dx log dh log 
dw # input _ rpn _ bbox input _ rpn 
_ match rpn _ bbox # Positive anchors contribute to 
the loss but negative and # neutral anchors match value 
of 0 or 1 don t . rpn _ match 
= K . squeeze rpn _ match 1 # batch 
anchors indices = tf . where K . equal rpn 
_ match 1 # Pick bbox deltas that contribute to 
the loss rpn _ bbox = tf . gather _ 
nd rpn _ bbox indices # n 4 # Trim 
target bounding box deltas to the same length as rpn 
_ bbox . batch _ counts = K . sum 
K . cast K . equal rpn _ match 1 
tf . int32 axis = 1 # 1 标签 数目 
# target _ bbox batch max positive anchors dy dx 
log dh log dw # rpn _ match batch target 
_ bbox = batch _ pack _ graph target _ 
bbox batch _ counts config . IMAGES _ PER _ 
GPU loss = smooth _ l1 _ loss target _ 
bbox rpn _ bbox loss = K . switch tf 
. size loss 0 K . mean loss tf . 
constant 0.0 return loss 仅仅 真实 标签 为 1 的 
类 参与 回归 运算 对于 target _ bbox 虽然 对 
每张 图片 其 框 数 一致 且 和 rpn _ 
match 的 第二 维度 相等 但是 对于 图片 i 只有 
前 面的 Ni 个 框 有意义 而 不是 和 anchors 
一一对应 的 后 面为 0 填充 Ni 值 等于 对应 
图片 的 rpn _ match 等于 1 的 数目 推测 
target _ bbox 中 bbox 坐标 的 排列 顺序 等于 
rpn _ match 中的 标识 顺序 所以/c 使用/v rpn/w _/i 
match/w 索/nr 引出/v rpn/w _/i bbox/w 对应/vn 1/m 的/uj 位置/v 
后/f 直接/ad 和/c target/w _/i bbox/w 的/uj 前/f Ni/w 运算/vn 
即可/d def/w batch _ pack _ graph x counts num 
_ rows Picks different number of values from each row 
in x depending on the values in counts . x 
batch max positive anchors dy dx log dh log dw 
counts batch outputs = for i in range num _ 
rows outputs . append x i counts i return tf 
. concat outputs axis = 0 损失 函数 使用 smooth 
_ l1 _ loss 坐标 回归 都用 这个 def smooth 
_ l1 _ loss y _ true y _ pred 
Implements Smooth L1 loss . y _ true and y 
_ pred are typically N 4 but could be any 
shape . diff = K . abs y _ true 
y _ pred less _ than _ one = K 
. cast K . less diff 1.0 float32 loss = 
less _ than _ one * 0.5 * diff * 
* 2 + 1 less _ than _ one * 
diff 0.5 return loss 附 我 在 数据 准备 函数 
build _ rpn _ targets 中 查询 到 如下 片段 
可以 佐证 上面 说法 下面 的 rpn _ box 对应 
上面 的 target _ bbox 即 target _ box 和 
anchor 并不 一一对应 仅 根据 正 样本 标签 数目 进行 
填充 代码 片段 1 两者 注册 长度 都 不一样 # 
RPN Match 1 = positive anchor 1 = negative anchor 
0 = neutral rpn _ match = np . zeros 
anchors . shape 0 dtype = np . int32 # 
RPN bounding boxes max anchors per image dy dx log 
dh log dw rpn _ bbox = np . zeros 
config . RPN _ TRAIN _ ANCHORS _ PER _ 
IMAGE 4 代码 片段 2 # For positive anchors compute 
shift and scale needed to transform them # to match 
the corresponding GT boxes . ids = np . where 
rpn _ match = = 1 0 ix = 0 
# index into rpn _ bbox # TODO use box 
_ refinement rather than duplicating the code here for i 
a in zip ids anchors ids # Closest gt box 
it might have IoU 0.7 gt = gt _ boxes 
anchor _ iou _ argmax i # Convert coordinates to 
center plus width / height . # GT Box gt 
_ h = gt 2 gt 0 gt _ w 
= gt 3 gt 1 gt _ center _ y 
= gt 0 + 0.5 * gt _ h gt 
_ center _ x = gt 1 + 0.5 * 
gt _ w # Anchor a _ h = a 
2 a 0 a _ w = a 3 a 
1 a _ center _ y = a 0 + 
0.5 * a _ h a _ center _ x 
= a 1 + 0.5 * a _ w # 
Compute the bbox refinement that the RPN should predict . 
rpn _ bbox ix = gt _ center _ y 
a _ center _ y / a _ h gt 
_ center _ x a _ center _ x / 
a _ w np . log gt _ h / 
a _ h np . log gt _ w / 
a _ w # Normalize rpn _ bbox ix / 
= config . RPN _ BBOX _ STD _ DEV 
ix + = 1 return rpn _ match rpn _ 
bboxMRCNN 分类 损失 函数 如果 分类 得分 最高 class 不 
对应 于本/nr 数据集 则不 贡献 Loss 值 def mrcnn _ 
class _ loss _ graph target _ class _ ids 
pred _ class _ logits active _ class _ ids 
Loss for the classifier head of Mask RCNN . target 
_ class _ ids batch num _ rois . Integer 
class IDs . Uses zero padding to fill in the 
array . pred _ class _ logits batch num _ 
rois num _ classes active _ class _ ids batch 
num _ classes . Has a value of 1 for 
classes that are in the dataset of the image and 
0 for classes that are not in the dataset . 
# During model building Keras calls this function with # 
target _ class _ ids of type float32 . Unclear 
why . Cast it # to int to get around 
it . target _ class _ ids = tf . 
cast target _ class _ ids int64 # Find predictions 
of classes that are not in the dataset . pred 
_ class _ ids = tf . argmax pred _ 
class _ logits axis = 2 # TODO Update this 
line to work with batch 1 . Right now it 
assumes all # images in a batch have the same 
active _ class _ ids pred _ active = tf 
. gather active _ class _ ids 0 pred _ 
class _ ids # Loss loss = tf . nn 
. sparse _ softmax _ cross _ entropy _ with 
_ logits labels = target _ class _ ids logits 
= pred _ class _ logits # batch num _ 
rois # Erase losses of predictions of classes that are 
not in the active # classes of the image . 
loss = loss * pred _ active # batch num 
_ rois ~ { 0 1 } * batch num 
_ rois # Computer loss mean . Use only predictions 
that contribute # to the loss to get a correct 
mean . loss = tf . reduce _ sum loss 
/ tf . reduce _ sum pred _ active return 
loss 涉及 到 active _ class _ ids 相关 如下 
即将 该 图片 隶属 数据 集中 所有 的 class 标记 
为 1 不 隶属 本 数据 集合 的 class 标记 
为 0 计算 Loss 贡献 时 交叉 熵 会对 每个 
框 进行 输出 一个 值 如果 这个 框 最大 的 
得分 class 并不 属于 其 数据集 则 不计 本 框 
Loss active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
# # Active classes # # Different datasets have different 
classes so track the # # classes supported in the 
dataset of this image . # active _ class _ 
ids = np . zeros dataset . num _ classes 
dtype = np . int32 # source _ class _ 
ids = dataset . source _ class _ ids dataset 
. image _ info image _ id source # active 
_ class _ ids source _ class _ ids = 
1MRCNN 回归 损失 函数 仅 计算 真实 标签 非 背景 
class 分类 数 大于 0 由于 预测 对于 每个 框体 
的 每个 类别 都有 回归 输出 batch num _ rois 
num _ classes dy dx log dh log dw 仅 
计算 真实 类别 的 回归 Loss 代码 如下 def mrcnn 
_ bbox _ loss _ graph target _ bbox target 
_ class _ ids pred _ bbox Loss for Mask 
R CNN bounding box refinement . target _ bbox batch 
num _ rois dy dx log dh log dw target 
_ class _ ids batch num _ rois . Integer 
class IDs . pred _ bbox batch num _ rois 
num _ classes dy dx log dh log dw # 
Reshape to merge batch and roi dimensions for simplicity . 
target _ class _ ids = K . reshape target 
_ class _ ids 1 # batch * num _ 
rois target _ bbox = K . reshape target _ 
bbox 1 4 pred _ bbox = K . reshape 
pred _ bbox 1 K . int _ shape pred 
_ bbox 2 4 # Only positive ROIs contribute to 
the loss . And only # the right class _ 
id of each ROI . Get their indices . # 
class _ ids N where class _ ids 0 M 
1 即 where 会升 维 positive _ roi _ ix 
= tf . where target _ class _ ids 0 
0 # M positive _ roi _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ roi _ ix tf . int64 
# 框 序号 真实 类别 id indices = tf . 
stack positive _ roi _ ix positive _ roi _ 
class _ ids axis = 1 # Gather the deltas 
predicted and true that contribute to loss target _ bbox 
= tf . gather target _ bbox positive _ roi 
_ ix pred _ bbox = tf . gather _ 
nd pred _ bbox indices # Smooth L1 Loss loss 
= K . switch tf . size target _ bbox 
0 smooth _ l1 _ loss y _ true = 
target _ bbox y _ pred = pred _ bbox 
tf . constant 0.0 loss = K . mean loss 
return lossMRCNN 掩码 损失 函数 keras 的 二进制 交叉 熵 
实际 调用 的 就是 sigmoid 交叉 熵 的 后端 详见 
TensorFlow 分类 问题 与 交叉 熵 def mrcnn _ mask 
_ loss _ graph target _ masks target _ class 
_ ids pred _ masks Mask binary cross entropy loss 
for the masks head . target _ masks batch num 
_ rois height width . A float32 tensor of values 
0 or 1 . Uses zero padding to fill array 
. target _ class _ ids batch num _ rois 
. Integer class IDs . Zero padded . pred _ 
masks batch proposals height width num _ classes float32 tensor 
with values from 0 to 1 . # Reshape for 
simplicity . Merge first two dimensions into one . target 
_ class _ ids = K . reshape target _ 
class _ ids 1 mask _ shape = tf . 
shape target _ masks target _ masks = K . 
reshape target _ masks 1 mask _ shape 2 mask 
_ shape 3 pred _ shape = tf . shape 
pred _ masks pred _ masks = K . reshape 
pred _ masks 1 pred _ shape 2 pred _ 
shape 3 pred _ shape 4 # Permute predicted masks 
to N num _ classes height width pred _ masks 
= tf . transpose pred _ masks 0 3 1 
2 # Only positive ROIs contribute to the loss . 
And only # the class specific mask of each ROI 
. positive _ ix = tf . where target _ 
class _ ids 0 0 positive _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ ix tf . int64 indices = 
tf . stack positive _ ix positive _ class _ 
ids axis = 1 # Gather the masks predicted and 
true that contribute to loss y _ true = tf 
. gather target _ masks positive _ ix y _ 
pred = tf . gather _ nd pred _ masks 
indices # Compute binary cross entropy . If no positive 
ROIs then return 0 . # shape batch roi num 
_ classes loss = K . switch tf . size 
y _ true 0 K . binary _ crossentropy target 
= y _ true output = y _ pred tf 
. constant 0.0 loss = K . mean loss return 
loss Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 training 网络 简介 流程 和 inference 大部分 一致 在下 
图中 我们 将 之前 inference 就 介绍 过 的 分类 
回归 和 掩码 生成 流程 压缩 到 一个 块 中 
以便 其他 部分 更为 清晰 而 两者 主要 不同之处 为 
网络 输入 输入 tensor 增加 到了 7个 之多 图上 画出 
的 6个 以及 image _ meta 大 部分 是 计算 
Loss 的 标签 前置 损失 函数 添加 了 5个 损失 
函数 2个 用于 RPN 计算 2个 用于 最终 分类 回归 
instance 1个 用于 掩码 损失 计算 原始 标签 处理 推理 
网络 中 Proposeal 筛选 出来 的 rpn _ rois 直接 
用于 生成 分类 回归 以及 掩码 信息 而 training 中 
这些 候 选区 需要 和 图片 标签 信息 进行 运算 
生成 有 训练 价值 的 输出 进行 后面 的 生成 
以及 损失 函数 计算 首先 初始化 并 载入 预 训练 
参数 下 节会 介绍 本 部分 相关 操作 然后 经由 
下面 几行 代码 即可 进行 训练 网络 输入 build 函数 
在 train 方法 中被 调用 model . py 涉及 巨 
多 预 处理函数 设计 需要 的 时候 自行 进入 train 
方法 查看 更 确切 的 说是 在 data _ generator 
方法 由 train 调用 images batch H W C image 
_ meta batch meta data Image details . See compose 
_ image _ meta rpn _ match batch N Integer 
1 = positive anchor 1 = negative 0 = neutral 
rpn _ bbox batch N dy dx log dh log 
dw Anchor bbox deltas . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs gt 
_ boxes batch MAX _ GT _ INSTANCES y1 x1 
y2 x2 gt _ masks batch height width MAX _ 
GT _ INSTANCES . The height and widthare those of 
the image unless use _ mini _ mask is True 
in whichcase they are defined in MINI _ MASK _ 
SHAPE . 原始 标签 处理 然后 我们 在 开篇 流程图 
中 标注 了 一个 名为 检测 目标 处理 的 框 
对应 代码 如下 # Generate detection targets # Subsamples proposals 
and generates target outputs for training # Note that proposal 
class IDs gt _ boxes and gt _ masks are 
zero # padded . Equally returned rois and targets are 
zero padded . rois target _ class _ ids target 
_ bbox target _ mask = \ D e t 
e c t i o n T a r g 
e t L a y e r config name = 
proposal _ targets target _ rois input _ gt _ 
class _ ids gt _ boxes input _ gt _ 
masks 其 目的 是 将 原始 的 图像 信息 input 
和 proposal 们 进行 计算 融合 输出 可以 用于 Loss 
计算 的 标准 的 格式 文档 很 清晰 Subsamples proposals 
and generates target box refinement class _ ids and masks 
for each . Inputs proposals batch N y1 x1 y2 
x2 in normalized coordinates . Mightbe zero padded if there 
are not enough proposals . gt _ class _ ids 
batch MAX _ GT _ INSTANCES Integer class IDs . 
gt _ boxes batch MAX _ GT _ INSTANCES y1 
x1 y2 x2 in n o r m a l 
i z e d c o o r d i 
n a t e s . gt _ masks batch 
height width MAX _ GT _ INSTANCES of boolean typeReturns 
Target ROIs and corresponding class IDs bounding box shifts and 
masks . rois batch TRAIN _ ROIS _ PER _ 
IMAGE y1 x1 y2 x2 in n o r m 
a l i z e d c o o r 
d i n a t e s t a r 
g e t _ class _ ids batch TRAIN _ 
ROIS _ PER _ IMAGE . Integer class IDs . 
target _ deltas batch TRAIN _ ROIS _ PER _ 
IMAGE dy dx log dh log dw target _ mask 
batch TRAIN _ ROIS _ PER _ IMAGE height width 
Masks cropped to bbox boundaries and resized to neuralnetwork output 
size . Note Returned arrays might be zero padded if 
not enough target ROIs . 这个 处理 之后 结构 同 
inference 中的 介绍 mrcnn _ class _ logits mrcnn _ 
class mrcnn _ bbox = \ fpn _ classifier _ 
graph rois mrcnn _ feature _ maps input _ image 
_ meta config . POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN fc _ layers _ size = config . FPN 
_ CLASSIF _ FC _ LAYERS _ SIZE mrcnn _ 
mask = build _ fpn _ mask _ graph rois 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN 损失 函数 然后 就是 损失 函 数了 浩浩荡荡 10 
来 行 注意 output _ rois 这 一行 我们 之前 
就 提过 keras 中 接收 tf 的 Tensor 只能 作为 
class 的 初始化 参数 而 不能 作为 网络 数据流 所以 
这里 加了 一层 封装 output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask 二 损失 函数 简介 RPN 分类 
损失 我们 先 看一下 RPN 真实 标签 生成 函数 中的 
一段 注释 # Match anchors to GT Boxes # If 
an anchor overlaps a GT box with IoU = 0.7 
then it s positive . # If an anchor overlaps 
a GT box with IoU 0.3 then it s negative 
. # Neutral anchors are those that don t match 
the conditions above # and they don t influence the 
loss function . # However don t keep any GT 
box unmatched rare but happens . Instead # match it 
to the closest anchor even if its max IoU is 
0.3 . 然后 看 本 损失 函数 def rpn _ 
class _ loss _ graph rpn _ match rpn _ 
class _ logits RPN anchor classifier loss . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ class _ logits batch anchors 2 . RPN 
classifier logits for FG / BG . # Squeeze last 
dim to simplify rpn _ match = tf . squeeze 
rpn _ match 1 # Get anchor classes . Convert 
the 1 / + 1 match to 0/1 values . 
anchor _ class = K . cast K . equal 
rpn _ match 1 tf . int32 # Positive and 
Negative anchors contribute to the loss # but neutral anchors 
match value = 0 don t . indices = tf 
. where K . not _ equal rpn _ match 
0 # Pick rows that contribute to the loss and 
filter out the rest . rpn _ class _ logits 
= tf . gather _ nd rpn _ class _ 
logits indices anchor _ class = tf . gather _ 
nd anchor _ class indices # Cross entropy loss loss 
= K . sparse _ categorical _ crossentropy target = 
anchor _ class output = rpn _ class _ logits 
from _ logits = True loss = K . switch 
tf . size loss 0 K . mean loss tf 
. constant 0.0 return loss 真实 标 签有 { 1 
0 1 } 三种 logits 结果 在 0 ~ 1 
分布 而在 RPN 分类 结果 中 真实 标签 为 0 
的 anchors 不 参与 损失 函数 的 构建 所以 我们 
将 标签 为 0 的 真实 标签 剔除 然后 将 
1 标签 转换 为 0 进行 交叉 熵 计算 RPN 
回归 损失 def rpn _ bbox _ loss _ graph 
config target _ bbox rpn _ match rpn _ bbox 
Return the RPN bounding box loss graph . config the 
model config object . target _ bbox batch max positive 
anchors dy dx log dh log dw . Uses 0 
padding to fill in unsed bbox deltas . rpn _ 
match batch anchors 1 . Anchor match type . 1 
= positive 1 = negative 0 = neutral anchor . 
rpn _ bbox batch anchors dy dx log dh log 
dw # input _ rpn _ bbox input _ rpn 
_ match rpn _ bbox # Positive anchors contribute to 
the loss but negative and # neutral anchors match value 
of 0 or 1 don t . rpn _ match 
= K . squeeze rpn _ match 1 # batch 
anchors indices = tf . where K . equal rpn 
_ match 1 # Pick bbox deltas that contribute to 
the loss rpn _ bbox = tf . gather _ 
nd rpn _ bbox indices # n 4 # Trim 
target bounding box deltas to the same length as rpn 
_ bbox . batch _ counts = K . sum 
K . cast K . equal rpn _ match 1 
tf . int32 axis = 1 # 1 标签 数目 
# target _ bbox batch max positive anchors dy dx 
log dh log dw # rpn _ match batch target 
_ bbox = batch _ pack _ graph target _ 
bbox batch _ counts config . IMAGES _ PER _ 
GPU loss = smooth _ l1 _ loss target _ 
bbox rpn _ bbox loss = K . switch tf 
. size loss 0 K . mean loss tf . 
constant 0.0 return loss 仅仅 真实 标签 为 1 的 
类 参与 回归 运算 对于 target _ bbox 虽然 对 
每张 图片 其 框 数 一致 且 和 rpn _ 
match 的 第二 维度 相等 但是 对于 图片 i 只有 
前 面的 Ni 个 框 有意义 而 不是 和 anchors 
一一对应 的 后 面为 0 填充 Ni 值 等于 对应 
图片 的 rpn _ match 等于 1 的 数目 推测 
target _ bbox 中 bbox 坐标 的 排列 顺序 等于 
rpn _ match 中的 标识 顺序 所以/c 使用/v rpn/w _/i 
match/w 索/nr 引出/v rpn/w _/i bbox/w 对应/vn 1/m 的/uj 位置/v 
后/f 直接/ad 和/c target/w _/i bbox/w 的/uj 前/f Ni/w 运算/vn 
即可/d def/w batch _ pack _ graph x counts num 
_ rows Picks different number of values from each row 
in x depending on the values in counts . x 
batch max positive anchors dy dx log dh log dw 
counts batch outputs = for i in range num _ 
rows outputs . append x i counts i return tf 
. concat outputs axis = 0 损失 函数 使用 smooth 
_ l1 _ loss 坐标 回归 都用 这个 def smooth 
_ l1 _ loss y _ true y _ pred 
Implements Smooth L1 loss . y _ true and y 
_ pred are typically N 4 but could be any 
shape . diff = K . abs y _ true 
y _ pred less _ than _ one = K 
. cast K . less diff 1.0 float32 loss = 
less _ than _ one * 0.5 * diff * 
* 2 + 1 less _ than _ one * 
diff 0.5 return loss 附 我 在 数据 准备 函数 
build _ rpn _ targets 中 查询 到 如下 片段 
可以 佐证 上面 说法 下面 的 rpn _ box 对应 
上面 的 target _ bbox 即 target _ box 和 
anchor 并不 一一对应 仅 根据 正 样本 标签 数目 进行 
填充 代码 片段 1 两者 注册 长度 都 不一样 # 
RPN Match 1 = positive anchor 1 = negative anchor 
0 = neutral rpn _ match = np . zeros 
anchors . shape 0 dtype = np . int32 # 
RPN bounding boxes max anchors per image dy dx log 
dh log dw rpn _ bbox = np . zeros 
config . RPN _ TRAIN _ ANCHORS _ PER _ 
IMAGE 4 代码 片段 2 # For positive anchors compute 
shift and scale needed to transform them # to match 
the corresponding GT boxes . ids = np . where 
rpn _ match = = 1 0 ix = 0 
# index into rpn _ bbox # TODO use box 
_ refinement rather than duplicating the code here for i 
a in zip ids anchors ids # Closest gt box 
it might have IoU 0.7 gt = gt _ boxes 
anchor _ iou _ argmax i # Convert coordinates to 
center plus width / height . # GT Box gt 
_ h = gt 2 gt 0 gt _ w 
= gt 3 gt 1 gt _ center _ y 
= gt 0 + 0.5 * gt _ h gt 
_ center _ x = gt 1 + 0.5 * 
gt _ w # Anchor a _ h = a 
2 a 0 a _ w = a 3 a 
1 a _ center _ y = a 0 + 
0.5 * a _ h a _ center _ x 
= a 1 + 0.5 * a _ w # 
Compute the bbox refinement that the RPN should predict . 
rpn _ bbox ix = gt _ center _ y 
a _ center _ y / a _ h gt 
_ center _ x a _ center _ x / 
a _ w np . log gt _ h / 
a _ h np . log gt _ w / 
a _ w # Normalize rpn _ bbox ix / 
= config . RPN _ BBOX _ STD _ DEV 
ix + = 1 return rpn _ match rpn _ 
bboxMRCNN 分类 损失 函数 如果 分类 得分 最高 class 不 
对应 于本/nr 数据集 则不 贡献 Loss 值 def mrcnn _ 
class _ loss _ graph target _ class _ ids 
pred _ class _ logits active _ class _ ids 
Loss for the classifier head of Mask RCNN . target 
_ class _ ids batch num _ rois . Integer 
class IDs . Uses zero padding to fill in the 
array . pred _ class _ logits batch num _ 
rois num _ classes active _ class _ ids batch 
num _ classes . Has a value of 1 for 
classes that are in the dataset of the image and 
0 for classes that are not in the dataset . 
# During model building Keras calls this function with # 
target _ class _ ids of type float32 . Unclear 
why . Cast it # to int to get around 
it . target _ class _ ids = tf . 
cast target _ class _ ids int64 # Find predictions 
of classes that are not in the dataset . pred 
_ class _ ids = tf . argmax pred _ 
class _ logits axis = 2 # TODO Update this 
line to work with batch 1 . Right now it 
assumes all # images in a batch have the same 
active _ class _ ids pred _ active = tf 
. gather active _ class _ ids 0 pred _ 
class _ ids # Loss loss = tf . nn 
. sparse _ softmax _ cross _ entropy _ with 
_ logits labels = target _ class _ ids logits 
= pred _ class _ logits # batch num _ 
rois # Erase losses of predictions of classes that are 
not in the active # classes of the image . 
loss = loss * pred _ active # batch num 
_ rois ~ { 0 1 } * batch num 
_ rois # Computer loss mean . Use only predictions 
that contribute # to the loss to get a correct 
mean . loss = tf . reduce _ sum loss 
/ tf . reduce _ sum pred _ active return 
loss 涉及 到 active _ class _ ids 相关 如下 
即将 该 图片 隶属 数据 集中 所有 的 class 标记 
为 1 不 隶属 本 数据 集合 的 class 标记 
为 0 计算 Loss 贡献 时 交叉 熵 会对 每个 
框 进行 输出 一个 值 如果 这个 框 最大 的 
得分 class 并不 属于 其 数据集 则 不计 本 框 
Loss active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
# # Active classes # # Different datasets have different 
classes so track the # # classes supported in the 
dataset of this image . # active _ class _ 
ids = np . zeros dataset . num _ classes 
dtype = np . int32 # source _ class _ 
ids = dataset . source _ class _ ids dataset 
. image _ info image _ id source # active 
_ class _ ids source _ class _ ids = 
1MRCNN 回归 损失 函数 仅 计算 真实 标签 非 背景 
class 分类 数 大于 0 由于 预测 对于 每个 框体 
的 每个 类别 都有 回归 输出 batch num _ rois 
num _ classes dy dx log dh log dw 仅 
计算 真实 类别 的 回归 Loss 代码 如下 def mrcnn 
_ bbox _ loss _ graph target _ bbox target 
_ class _ ids pred _ bbox Loss for Mask 
R CNN bounding box refinement . target _ bbox batch 
num _ rois dy dx log dh log dw target 
_ class _ ids batch num _ rois . Integer 
class IDs . pred _ bbox batch num _ rois 
num _ classes dy dx log dh log dw # 
Reshape to merge batch and roi dimensions for simplicity . 
target _ class _ ids = K . reshape target 
_ class _ ids 1 # batch * num _ 
rois target _ bbox = K . reshape target _ 
bbox 1 4 pred _ bbox = K . reshape 
pred _ bbox 1 K . int _ shape pred 
_ bbox 2 4 # Only positive ROIs contribute to 
the loss . And only # the right class _ 
id of each ROI . Get their indices . # 
class _ ids N where class _ ids 0 M 
1 即 where 会升 维 positive _ roi _ ix 
= tf . where target _ class _ ids 0 
0 # M positive _ roi _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ roi _ ix tf . int64 
# 框 序号 真实 类别 id indices = tf . 
stack positive _ roi _ ix positive _ roi _ 
class _ ids axis = 1 # Gather the deltas 
predicted and true that contribute to loss target _ bbox 
= tf . gather target _ bbox positive _ roi 
_ ix pred _ bbox = tf . gather _ 
nd pred _ bbox indices # Smooth L1 Loss loss 
= K . switch tf . size target _ bbox 
0 smooth _ l1 _ loss y _ true = 
target _ bbox y _ pred = pred _ bbox 
tf . constant 0.0 loss = K . mean loss 
return lossMRCNN 掩码 损失 函数 keras 的 二进制 交叉 熵 
实际 调用 的 就是 sigmoid 交叉 熵 的 后端 详见 
TensorFlow 分类 问题 与 交叉 熵 def mrcnn _ mask 
_ loss _ graph target _ masks target _ class 
_ ids pred _ masks Mask binary cross entropy loss 
for the masks head . target _ masks batch num 
_ rois height width . A float32 tensor of values 
0 or 1 . Uses zero padding to fill array 
. target _ class _ ids batch num _ rois 
. Integer class IDs . Zero padded . pred _ 
masks batch proposals height width num _ classes float32 tensor 
with values from 0 to 1 . # Reshape for 
simplicity . Merge first two dimensions into one . target 
_ class _ ids = K . reshape target _ 
class _ ids 1 mask _ shape = tf . 
shape target _ masks target _ masks = K . 
reshape target _ masks 1 mask _ shape 2 mask 
_ shape 3 pred _ shape = tf . shape 
pred _ masks pred _ masks = K . reshape 
pred _ masks 1 pred _ shape 2 pred _ 
shape 3 pred _ shape 4 # Permute predicted masks 
to N num _ classes height width pred _ masks 
= tf . transpose pred _ masks 0 3 1 
2 # Only positive ROIs contribute to the loss . 
And only # the class specific mask of each ROI 
. positive _ ix = tf . where target _ 
class _ ids 0 0 positive _ class _ ids 
= tf . cast tf . gather target _ class 
_ ids positive _ ix tf . int64 indices = 
tf . stack positive _ ix positive _ class _ 
ids axis = 1 # Gather the masks predicted and 
true that contribute to loss y _ true = tf 
. gather target _ masks positive _ ix y _ 
pred = tf . gather _ nd pred _ masks 
indices # Compute binary cross entropy . If no positive 
ROIs then return 0 . # shape batch roi num 
_ classes loss = K . switch tf . size 
y _ true 0 K . binary _ crossentropy target 
= y _ true output = y _ pred tf 
. constant 0.0 loss = K . mean loss return 
loss 