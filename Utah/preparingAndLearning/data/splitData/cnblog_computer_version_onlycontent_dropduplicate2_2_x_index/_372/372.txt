前段时间的“人机大战”——谷歌的Alpha Go战胜人类棋手的新闻甚嚣尘上，不禁有人会想起1997年IBM自主研发的深蓝战胜卡斯帕罗夫的事件。“人工智能”这个词再次被推上风口浪尖，而“认知计算”却鲜有人听说，同样是人类模拟机器思索，让机器具有自主思考能力，都是具有跨时代意义和里程碑式的存在。认知计算更加强调机器或人造大脑如何能够主动学习、推理、感知这个世界，并与人类、环境进行交互的反应。它会根据环境的变化做出动态的反应，所以认知更加强调它的动态性、自适应性、鲁棒性、交互性。计算机在体系架构上的发展历史主要体现在两个方面：计算能力的增强计算规模的增大随着计算机计算能力的大幅增强，具备了处理海量数据的能力；另一方面，日常生活中所产生的数据规模日益扩大，所拥有的数据源驱动了深层次分析的需求；同时大数据、云计算技术的不断完善，都促进了对数据进行深度挖掘，提取数据的特征，利用特征让机器具有自主学习与思考的能力。按照计算方式的不同，可以分为三个计算时代：1990s~1940s  打卡阶段（The Tabulating Era）       机械式1950s~现在     编程阶段（The Programming Era）   自主输入2011~将来      认知计算阶段（The Cognitive Era）    自动思考“大脑”项目：Think & Learn2006     IBM        Watson      利用自然语言分析，让机器自动推理事件与回答问题；涵盖医疗、数据分析、“危险游戏”等。2011     Google    谷歌大脑     通过神经网络，能够让更多的用户拥有完美的、没有错误的使用体验；谷歌无人驾驶汽车、谷歌眼镜等。2012     Baidu      百度大脑     融合深度学习算法、数据建模、大规模GPU并行化平台等技术，构造起深度神经网络。一、认知计算的概念：人工智能与认知计算的区别：人工，以人为主导；认知，机器对事物与外界的理解，交互的能力编程能力；学习与推理的能力确定性结果；概率性结果人并未参与；人、机器、环境之间的交互图灵测试或仿造人测量；实际应用中的测试2.  认知计算所涉及的技术领域：神经科学：机器模拟人脑神经元的思考过程；超计算：超级快速计算和处理能力；纳米技术：芯片、系统等底层架构设计。3. 认知计算系统的组成：需要一个能够理解、学习、推理的“大脑”，一个物物相连的外部环境，大脑与环境之间互相感知与交互。4.  认知计算的应用：典型系统特征：大规模、复杂、人与外界交互、大量非结构化数据、输出结果不定的系统；生命科学领域：医疗、保险；社会机构领域：金融银行、政府、能源、教育、商业、交通等。5.  案例：Watson-历史上第一个认知系统自然语言处理问答技术高性能计算知识的表达和推理机器学习非结构化信息管理6.  认知系统的五个核心功能：创造更深的人工参与测量和提升专业知识认知融入产品和服务实现认知过程和操作加强探索和发现7.  认知计算系统的挑战与要求：8.  认知计算系统的架构：底层架构：芯片设计（GPU、FPGA、ASIC、POWER8）基础设施：云环境、超级计算节点组织构架：caffe、Theano、Torch等库文件：数据库、工具、包等应用层：信息采集的有效性、人机交互界面、搜索引擎等二、人工智能的概述：人的大脑科学&计算机科学——>可视化、心理学、神经元组成、深度学习1. 人工智能发展过程：重要的时间节点与人物：1950-1956：两个重要的人物，诺伯特·维纳（控制论）和克劳德·艾尔伍德·香农（信息论）将事物从更高的层次进行抽象，奠定了AI坚实的理论基础；1950：图灵，提出了图灵测试的基本测试方法；1956：达特茅斯会议第一次正式提出AI的概念；1956-1974：AI得到极大发展，提出了许多新的理论，包括自然语言处理、reasoning as search、micro-worlds等；1974-1980：由于发展迅速所带来的副作用日益凸显，关于机器代替人类的社会、伦理等问题、投资人看不到长期受益问题等导致其发展陷入低谷；1980-1987：在日本的第五代项目提出，结合AI来发展现代工业生产，又给AI界打了一针强心剂（专家系统）；1987-1993：计算机的高速发展，给传统硬件组成的研究系统带来巨大挑战，更多的人将注意力放在计算能力更强、价格更为便宜的普通计算机上；1995：Sparse coding，将计算机科学理论与生物神经科学理论相结合；2006：Deep Learning，含多隐层的多层感知器的深度学习结构；2007：GPU CUDA，CPU与GPU并用的“协同处理”发展的统一计算设备架构；2011：Google Brain，谷歌在人工智能领域开发出的一款模拟人脑的软件。2. 机器学习的概述：机器学习两种传统分类：监督学习：已知label来对事物进行分类；无监督学习：未知label来学习事物特征。应用领域：图像识别、计算机视觉、语音识别、生物监控、机器人控制、经验科学、智能医疗等。机器学习的流程图（有监督学习）：分类算法（Classification）：支持向量机（SVM）神经网络（Neural Network）朴素贝叶斯（Naiive Bayes）贝叶斯网络（Bayesian network）逻辑回归（Logistic regression）随机森林（Randomized Forests）决策树（Boosted Decision Trees）k近邻（K-nearest neighbor）RBMs聚类算法（Clustering）：K-means合并聚类（agglomerative clustering）均值漂移聚类（mean shift clustering）谱聚类（spectral clustering）泛化问题（Generalization）：过拟合、欠拟合3. 深度学习的概述：深度学习是机器学习的一个分支，通过利用多层处理的复杂结构，基于一系列的算法来建立高维抽象的模型。其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。深度学习的概念由Hinton等人于2006年提出。基于深度置信网络(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络（CNN）是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。典型的深度学习：卷积神经网络CNN实验已经证明，CNN在图像和语音处理中能够取得比传统方法更好的识别效果，也产生了许多著名的深度学习网络VGG-Net、AlexNet等。VGG-Net与AlexNet的对比分析：深度学习网络AlexNetVGG-Net产生背景2012年，deep learning的大牛教授 Geoffrey Hinton的学生Alex Krizhevsky设计了一个8层的CNN，并把它用于ImageNet的image classification，直接把当时最好算法的错误率差不多减半。Andrew Zisserman 教授的组 (Oxford)，VGG-Net 在2014年的 ILSVRC localization and classification 两个问题上分别取得了第一名和第二名。结构层次总共有8层，由5层 convolutional layer，2层 fully connected layer，和最后一层 label layer (1000个node, 每个node代表ImageNet中的一个类别) 组成。VGG-Net使用更多的层，通常有16－19层，所有 convolutional layer 使用同样大小的 convolutional filter。结构示意特征描述中间层描述了图片的局部特征，全连接层表示了图像的全局特征。业界牛人：开发架构：机器学习的常用库和数据集：