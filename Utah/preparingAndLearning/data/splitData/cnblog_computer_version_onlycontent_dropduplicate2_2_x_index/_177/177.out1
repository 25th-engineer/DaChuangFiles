一 模块 概述 上节 的 最后 我们 进行 了 如下 
操作 获取 了 有限 的 proposal # IMAGES _ PER 
_ GPU num _ rois y1 x1 y2 x2 # 
IMAGES _ PER _ GPU 取代 了 batch 之后 说 
的 batch 都是 IMAGES _ PER _ GPU rpn _ 
rois = ProposalLayer proposal _ count = proposal _ count 
nms _ threshold = config . RPN _ NMS _ 
THRESHOLD # 0.7 name = ROI config = config rpn 
_ class rpn _ bbox anchors 总结 一下 与 GT 
的 IOU 大于 0.7 与 某一个 GT 的 IOU 最大 
的 那个 anchor 进一步 我们 需要 按照 RCNN 的 思路 
使用 proposal 对 共享 特征 进行 ROI 操作 在 Mask 
RCNN 中 这里 有 两个 创新 ROI 使用 ROI Align 
取代 了 之前 的 ROI Pooling 共享 特征 由 之前 
的 单层 变换 为了 FPN 得到 的 金字塔 多层 特征 
即 mrcnn _ feature _ maps = P2 P3 P4 
P5 其中 创新 点 2 意味着 我们 不同 的 proposal 
对应 去 ROI 的 特征 层 并不相同 所以 我们 需要 
按照 proposal 的 长宽 将 不同 的 proposal 对应 给 
不同 的 特征 层 在 对应 特征 层 上 进行 
ROI 操作 二 实现 分析 下 面会 用到 高维 切片 
函数 这里 先行 给出 讲解 链接 TensorFlow 高级 高维 切片 
gather _ nd 接 前文 bulid 函数 代码 我们 如下 
调入 实现 本节 的 功能 if mode = = training 
else # Network Heads # Proposal classifier and BBox regressor 
heads # output shapes # mrcnn _ class _ logits 
batch num _ rois NUM _ CLASSES classifier logits before 
softmax # mrcnn _ class batch num _ rois NUM 
_ CLASSES classifier probabilities # mrcnn _ bbox deltas batch 
num _ rois NUM _ CLASSES dy dx log dh 
log dw mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox = \ fpn _ classifier _ graph 
rpn _ rois mrcnn _ feature _ maps input _ 
image _ meta config . POOL _ SIZE config . 
NUM _ CLASSES train _ bn = config . TRAIN 
_ BN fc _ layers _ size = config . 
FPN _ CLASSIF _ FC _ LAYERS _ SIZE FPN 
特征 层 分类 函数 纵览 如下 # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # Feature Pyramid Network 
Heads # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def fpn _ classifier _ graph rois feature _ 
maps image _ meta pool _ size num _ classes 
train _ bn = True fc _ layers _ size 
= 1024 Builds the computation graph of the feature pyramid 
network classifier and regressor heads . rois batch num _ 
rois y1 x1 y2 x2 Proposal boxes in normalized coordinates 
. feature _ maps List of feature maps from different 
layers of the pyramid P2 P3 P4 P5 . Each 
has a different resolution . image _ meta batch meta 
data Image details . See compose _ image _ meta 
pool _ size The width of the square feature map 
generated from ROI Pooling . num _ classes number of 
classes which determines the depth of the results train _ 
bn Boolean . Train or freeze Batch Norm layers fc 
_ layers _ size Size of the 2 FC layers 
Returns logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax probs batch num _ rois NUM _ 
CLASSES classifier probabilities bbox _ deltas batch num _ rois 
NUM _ CLASSES dy dx log dh log dw Deltas 
to apply to proposal boxes # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps # Two 1024 FC layers 
implemented with Conv2D for consistency # TimeDistributed 拆 分了 输入 
数据 的 第 1 维 从0/nr 开始 将 完全 一样 
的 模型 独立 的 应用于 拆分 后的/nr 输入 数据 具体 
到 下行 # 就是 将 num _ rois 个 卷积 
应用到 num _ rois 个 维度 为 batch POOL _ 
SIZE POOL _ SIZE channels 的 输入 结果 合并 x 
= KL . TimeDistributed KL . Conv2D fc _ layers 
_ size pool _ size pool _ size padding = 
valid name = mrcnn _ class _ conv1 x # 
batch num _ rois 1 1 1024 x = KL 
. TimeDistributed BatchNorm name = mrcnn _ class _ bn1 
x training = train _ bn x = KL . 
Activation relu x x = KL . TimeDistributed KL . 
Conv2D fc _ layers _ size 1 1 name = 
mrcnn _ class _ conv2 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn2 x 
training = train _ bn x = KL . Activation 
relu x shared = KL . Lambda lambda x K 
. squeeze K . squeeze x 3 2 name = 
pool _ squeeze x # batch num _ rois 1024 
# Classifier head mrcnn _ class _ logits = KL 
. TimeDistributed KL . Dense num _ classes name = 
mrcnn _ class _ logits shared mrcnn _ probs = 
KL . TimeDistributed KL . Activation softmax name = mrcnn 
_ class mrcnn _ class _ logits # BBox head 
# batch num _ rois NUM _ CLASSES * dy 
dx log dh log dw x = KL . TimeDistributed 
KL . Dense num _ classes * 4 activation = 
linear name = mrcnn _ bbox _ fc shared # 
Reshape to batch num _ rois NUM _ CLASSES dy 
dx log dh log dw s = K . int 
_ shape x # 下行 源码 K . reshape inputs 
K . shape inputs 0 + self . target _ 
shape mrcnn _ bbox = KL . Reshape s 1 
num _ classes 4 name = mrcnn _ bbox x 
return mrcnn _ class _ logits mrcnn _ probs mrcnn 
_ bbox 下面 我们 来 分析 一下 该 函数 进入 
函数 首 先调 用了 PyramidROI # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps 这个 class 基本 实现 了 
我们 开篇 所说 的 全部 功能 即 特征 层 分类 
并 ROI ROIAlign 类 首先 我们 依据 计算机 视觉 FPN 
特征 金字塔 网络 中 第三 节 所讲 对 proposal 进行 
分类 注意 的 是 我们 使用 于 网络 中的 hw 
是 归一 化了 的 以 原图 hw 为 单位 长度 
所以 计算 时 需要 还原 对于 公式 而言 w h 
分别 表示 宽度 和 高度 k 是 分配 RoI 的 
level 是 w h = 224 224时 映射 的 level 
注意 两 个 操作 节点 level _ boxes 和 box 
_ indices 第一 个 记录 了 对应 的 level 特征 
层 中 分配 到 的 每个 box 的 坐标 第二个 
则 记录 了 每个 box 对应 的 图片 在 batch 
中的 索引 一个 记录 了 候选框 索引 对应 的 图片 
即 下 文中 的 两个 大块 一个 记录 了 候选框 
的 索引 对应 其 坐标 即 小 黑框 的 坐标 
两者 结合 可以 索引 到 下面 每个 黑色 小 框 
的 坐标 信息 至于 ROI Align 本身 实际 就是 双 
线性插值 使用 内置 API 实现 即可 这里 属于 RPN 网络 
和 RCNN 网络 的 分界线 level _ boxes 和 box 
_ indices 本身 属于 RPN 计算出来 结果 但是 两者 作用于 
feature 后的/nr 输出 Tensor 却是 RCNN 部分 的 输入 但是 
两 部分 的 梯度 不能 相互 流通 的 所以 需要 
tf . stop _ gradient 截断 梯度 传播 # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # ROIAlign 
Layer # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def log2 _ graph x Implementation of Log2 . 
TF doesn t have a native implementation . return tf 
. log x / tf . log 2.0 class PyramidROIAlign 
KE . Layer Implements ROI Pooling on multiple levels of 
the feature pyramid . Params pool _ shape pool _ 
height pool _ width of the output pooled regions . 
Usually 7 7 Inputs boxes batch num _ boxes y1 
x1 y2 x2 in normalized coordinates . Possibly padded with 
zeros if not enough boxes to fill the array . 
image _ meta batch meta data Image details . See 
compose _ image _ meta feature _ maps List of 
feature maps from different levels of the pyramid . Each 
is batch height width channels Output Pooled regions in the 
shape batch num _ boxes pool _ height pool _ 
width channels . The width and height are those specific 
in the pool _ shape in the layer constructor . 
def _ _ init _ _ self pool _ shape 
* * kwargs super PyramidROIAlign self . _ _ init 
_ _ * * kwargs self . pool _ shape 
= tuple pool _ shape def call self inputs # 
num _ boxes 指 的 是 proposal 数目 它们 均会 
作用于 每张 图片 上 只是 不同 的 proposal 作用于 图片 
# 的 特征 级别 不同 我 通过 循环 特征 层 
寻找 符合 的 proposal 应用 ROIAlign # Crop boxes batch 
num _ boxes y1 x1 y2 x2 in normalized coords 
boxes = inputs 0 # Image meta # Holds details 
about the image . See compose _ image _ meta 
image _ meta = inputs 1 # Feature Maps . 
List of feature maps from different level of the # 
feature pyramid . Each is batch height width channels feature 
_ maps = inputs 2 # Assign each ROI to 
a level in the pyramid based on the ROI area 
. y1 x1 y2 x2 = tf . split boxes 
4 axis = 2 h = y2 y1 w = 
x2 x1 # Use shape of first image . Images 
in a batch must have the same size . image 
_ shape = parse _ image _ meta _ graph 
image _ meta image _ shape 0 # h w 
c # Equation 1 in the Feature Pyramid Networks paper 
. Account for # the fact that our coordinates are 
normalized here . # e . g . a 224x224 
ROI in pixels maps to P4 image _ area = 
tf . cast image _ shape 0 * image _ 
shape 1 tf . float32 roi _ level = log2 
_ graph tf . sqrt h * w / 224.0 
/ tf . sqrt image _ area # h w 
已经 归一化 roi _ level = tf . minimum 5 
tf . maximum 2 4 + tf . cast tf 
. round roi _ level tf . int32 # 确 
保值 位于 2 到 5 之间 roi _ level = 
tf . squeeze roi _ level 2 # batch num 
_ boxes # Loop through levels and apply ROI pooling 
to each . P2 to P5 . pooled = box 
_ to _ level = for i level in enumerate 
range 2 6 # tf . where 返回值 格式 坐标 
1 坐标 2 # np . where 返回值 格式 坐标 
1 . x 坐标 2 . x 坐标 1 . 
y 坐标 2 . y ix = tf . where 
tf . equal roi _ level level # 返回 坐标 
表示 第 n 张 图片 的 第 i 个 proposal 
level _ boxes = tf . gather _ nd boxes 
ix # 本 level 的 proposal 数目 4 # Box 
indices for crop _ and _ resize . box _ 
indices = tf . cast ix 0 tf . int32 
# 记录 每个 propose 对应 图片 序号 # Keep track 
of which box is mapped to which level box _ 
to _ level . append ix # Stop gradient propogation 
to ROI proposals level _ boxes = tf . stop 
_ gradient level _ boxes box _ indices = tf 
. stop _ gradient box _ indices # Crop and 
Resize # From Mask R CNN paper We sample four 
regular locations so # that we can evaluate either max 
or average pooling . In fact # interpolating only a 
single value at each bin center without # pooling is 
nearly as effective . # # Here we use the 
simplified approach of a single value per bin # which 
is how it s done in tf . crop _ 
and _ resize # Result this _ level _ num 
_ boxes pool _ height pool _ width channels pooled 
. append tf . image . crop _ and _ 
resize feature _ maps i level _ boxes box _ 
indices self . pool _ shape method = bilinear # 
输入 参数 shape # batch image _ height image _ 
width channels # this _ level _ num _ boxes 
4 # this _ level _ num _ boxes # 
height pool _ width # Pack pooled features into one 
tensor pooled = tf . concat pooled axis = 0 
# batch * num _ boxes pool _ height pool 
_ width channels # Pack box _ to _ level 
mapping into one array and add another # column representing 
the order of pooled boxes box _ to _ level 
= tf . concat box _ to _ level axis 
= 0 # batch * num _ boxes 2 box 
_ range = tf . expand _ dims tf . 
range tf . shape box _ to _ level 0 
1 # batch * num _ boxes 1 box _ 
to _ level = tf . concat tf . cast 
box _ to _ level tf . int32 box _ 
range axis = 1 # batch * num _ boxes 
3 # 截止 到 目前 我们 获取 了 记录 全部 
ROIAlign 结果 feat 集合 的 张量 pooled 和 记录 这些 
feat 相关 信息 的 张量 box _ to _ level 
# 由于 提取 方法 的 原因 此时 的 feat 并 
不是 按照 原始 顺序 排序 先按 batch 然后按 box index 
排序 下面 我们 设法 将之 恢复 顺 # 序 ROIAlign 
作用于 对应 图片 的 对应 proposal 生成 feat # Rearrange 
pooled features to match the order of the original boxes 
# Sort box _ to _ level by batch then 
box index # TF doesn t have a way to 
sort by two columns so merge them and sort . 
# box _ to _ level i 0 表示 的 
是 当前 feat 隶属 的 图片 索引 box _ to 
_ level i 1 表示 的 是 其 box 序号 
sorting _ tensor = box _ to _ level 0 
* 100000 + box _ to _ level 1 # 
batch * num _ boxes ix = tf . nn 
. top _ k sorting _ tensor k = tf 
. shape box _ to _ level 0 . indices 
1 ix = tf . gather box _ to _ 
level 2 ix pooled = tf . gather pooled ix 
# Re add the batch dimension # batch num _ 
boxes y1 x1 y2 x2 batch * num _ boxes 
pool _ height pool _ width channels shape = tf 
. concat tf . shape boxes 2 tf . shape 
pooled 1 axis = 0 pooled = tf . reshape 
pooled shape return pooled # batch num _ boxes pool 
_ height pool _ width channels 初步 分类 / 回归 
经过 ROI 之后 我们 获取 了 众多 shape 一致 的 
小 feat 为了 获取 他们 的 分类 回归 信息 我们 
构建 一系列 并行 的 网络 进行 处理 # Two 1024 
FC layers implemented with Conv2D for consistency # TimeDistributed 拆 
分了 输入 数据 的 第 1 维 从0/nr 开始 将 
完全 一样 的 模型 独立 的 应用于 拆分 后的/nr 输入 
数据 具体 到 下行 # 就是 将 num _ rois 
个 卷积 应用到 num _ rois 个 维度 为 batch 
POOL _ SIZE POOL _ SIZE channels 的 输入 结果 
合并 x = KL . TimeDistributed KL . Conv2D fc 
_ layers _ size pool _ size pool _ size 
padding = valid name = mrcnn _ class _ conv1 
x # batch num _ rois 1 1 1024 x 
= KL . TimeDistributed BatchNorm name = mrcnn _ class 
_ bn1 x training = train _ bn x = 
KL . Activation relu x x = KL . TimeDistributed 
KL . Conv2D fc _ layers _ size 1 1 
name = mrcnn _ class _ conv2 x x = 
KL . TimeDistributed BatchNorm name = mrcnn _ class _ 
bn2 x training = train _ bn x = KL 
. Activation relu x shared = KL . Lambda lambda 
x K . squeeze K . squeeze x 3 2 
name = pool _ squeeze x # batch num _ 
rois 1024 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBox head # batch num _ rois NUM _ CLASSES 
* dy dx log dh log dw x = KL 
. TimeDistributed KL . Dense num _ classes * 4 
activation = linear name = mrcnn _ bbox _ fc 
shared # Reshape to batch num _ rois NUM _ 
CLASSES dy dx log dh log dw s = K 
. int _ shape x # 下行 源码 K . 
reshape inputs K . shape inputs 0 + self . 
target _ shape mrcnn _ bbox = KL . Reshape 
s 1 num _ classes 4 name = mrcnn _ 
bbox x return mrcnn _ class _ logits mrcnn _ 
probs mrcnn _ bbox 返回 如下 mrcnn _ class _ 
logits         batch num _ rois NUM 
_ CLASSES       classifier logits before softmax mrcnn 
_ class                 
batch num _ rois NUM _ CLASSES       
classifier p r o b a b i l i 
t i e s m r c n n _ 
bbox deltas     batch num _ rois NUM _ 
CLASSES dy dx log dh log dw KL . TimeDistributed 
实现 建立 一 系列 同样 架构 的 的 并行 网络结构 
dim0 个 将 dim0 dim1 中的 每个 dim1 作为 输入 
并行 的 计算 输出 附 build 函数 总览 def build 
self mode config Build Mask R CNN architecture . input 
_ shape The shape of the input image . mode 
Either training or inference . The inputs and outputs of 
the model differ accordingly . assert mode in training inference 
# Image size must be dividable by 2 multiple times 
h w = config . IMAGE _ SHAPE 2 # 
1024 1024 3 if h / 2 * * 6 
= int h / 2 * * 6 or w 
/ 2 * * 6 = int w / 2 
* * 6 # 这里 就 限定 了 下 采样 
不会 产生 坐标 误差 raise Exception Image size must be 
dividable by 2 at least 6 times to avoid fractions 
when downscaling and upscaling . For example use 256 320 
384 448 512 . . . etc . # Inputs 
input _ image = KL . Input shape = None 
None config . IMAGE _ SHAPE 2 name = input 
_ image input _ image _ meta = KL . 
Input shape = config . IMAGE _ META _ SIZE 
name = input _ image _ meta if mode = 
= training # RPN GT input _ rpn _ match 
= KL . Input shape = None 1 name = 
input _ rpn _ match dtype = tf . int32 
input _ rpn _ bbox = KL . Input shape 
= None 4 name = input _ rpn _ bbox 
dtype = tf . float32 # Detection GT class IDs 
bounding boxes and masks # 1 . GT Class IDs 
zero padded input _ gt _ class _ ids = 
KL . Input shape = None name = input _ 
gt _ class _ ids dtype = tf . int32 
# 2 . GT Boxes in pixels zero padded # 
batch MAX _ GT _ INSTANCES y1 x1 y2 x2 
in image coordinates input _ gt _ boxes = KL 
. Input shape = None 4 name = input _ 
gt _ boxes dtype = tf . float32 # Normalize 
coordinates gt _ boxes = KL . Lambda lambda x 
norm _ boxes _ graph x K . shape input 
_ image 1 3 input _ gt _ boxes # 
3 . GT Masks zero padded # batch height width 
MAX _ GT _ INSTANCES if config . USE _ 
MINI _ MASK input _ gt _ masks = KL 
. Input shape = config . MINI _ MASK _ 
SHAPE 0 config . MINI _ MASK _ SHAPE 1 
None name = input _ gt _ masks dtype = 
bool else input _ gt _ masks = KL . 
Input shape = config . IMAGE _ SHAPE 0 config 
. IMAGE _ SHAPE 1 None name = input _ 
gt _ masks dtype = bool elif mode = = 
inference # Anchors in normalized coordinates input _ anchors = 
KL . Input shape = None 4 name = input 
_ anchors # Build the shared convolutional layers . # 
Bottom up Layers # Returns a list of the last 
layers of each stage 5 in total . # Don 
t create the thead stage 5 so we pick the 
4th item in the list . if callable config . 
BACKBONE _ C2 C3 C4 C5 = config . BACKBONE 
input _ image stage5 = True train _ bn = 
config . TRAIN _ BN else _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers # TODO add 
assert to varify feature map sizes match what s in 
config P5 = KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c5p5 C5 # 256 P4 = KL . Add 
name = fpn _ p4add KL . UpSampling2D size = 
2 2 name = fpn _ p5upsampled P5 KL . 
Conv2D config . TOP _ DOWN _ PYRAMID _ SIZE 
1 1 name = fpn _ c4p4 C4 P3 = 
KL . Add name = fpn _ p3add KL . 
UpSampling2D size = 2 2 name = fpn _ p4upsampled 
P4 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c3p3 
C3 P2 = KL . Add name = fpn _ 
p2add KL . UpSampling2D size = 2 2 name = 
fpn _ p3upsampled P3 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c2p2 C2 # Attach 3x3 conv to all 
P layers to get the final feature maps . P2 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p2 P2 P3 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p3 P3 P4 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p4 P4 P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p5 P5 # 
P6 is used for the 5th anchor scale in RPN 
. Generated by # subsampling from P5 with stride of 
2 . P6 = KL . MaxPooling2D pool _ size 
= 1 1 strides = 2 name = fpn _ 
p6 P5 # Note that P6 is used in RPN 
but not in the classifier heads . rpn _ feature 
_ maps = P2 P3 P4 P5 P6 mrcnn _ 
feature _ maps = P2 P3 P4 P5 # Anchors 
if mode = = training anchors = self . get 
_ anchors config . IMAGE _ SHAPE # Duplicate across 
the batch dimension because Keras requires it # TODO can 
this be optimized to avoid duplicating the anchors anchors = 
np . broadcast _ to anchors config . BATCH _ 
SIZE + anchors . shape # A hack to get 
around Keras s bad support for constants anchors = KL 
. Lambda lambda x tf . Variable anchors name = 
anchors input _ image else anchors = input _ anchors 
# RPN Model 返回 的 是 keras 的 Module 对象 
注意 keras 中的 Module 对象 是 可 call 的 rpn 
= build _ rpn _ model config . RPN _ 
ANCHOR _ STRIDE # 1 3 256 len config . 
RPN _ ANCHOR _ RATIOS config . TOP _ DOWN 
_ PYRAMID _ SIZE # Loop through pyramid layers layer 
_ outputs = # list of lists for p in 
rpn _ feature _ maps layer _ outputs . append 
rpn p # 保存 各 pyramid 特征 经过 RPN 之后 
的 结果 # Concatenate layer outputs # Convert from list 
of lists of level outputs to list of lists # 
of outputs across levels . # e . g . 
a1 b1 c1 a2 b2 c2 = a1 a2 b1 
b2 c1 c2 output _ names = rpn _ class 
_ logits rpn _ class rpn _ bbox outputs = 
list zip * layer _ outputs # logits2 6 class2 
6 bbox2 6 outputs = KL . Concatenate axis = 
1 name = n list o for o n in 
zip outputs output _ names # batch num _ anchors 
2/4 # 其中 num _ anchors 指 的 是 全部 
特征 层 上 的 anchors 总数 rpn _ class _ 
logits rpn _ class rpn _ bbox = outputs # 
Generate proposals # Proposals are batch N y1 x1 y2 
x2 in normalized coordinates # and zero padded . # 
POST _ NMS _ ROIS _ INFERENCE = 1000 # 
POST _ NMS _ ROIS _ TRAINING = 2000 proposal 
_ count = config . POST _ NMS _ ROIS 
_ TRAINING if mode = = training \ else config 
. POST _ NMS _ ROIS _ INFERENCE # IMAGES 
_ PER _ GPU num _ rois y1 x1 y2 
x2 # IMAGES _ PER _ GPU 取代 了 batch 
之后 说 的 batch 都是 IMAGES _ PER _ GPU 
rpn _ rois = ProposalLayer proposal _ count = proposal 
_ count nms _ threshold = config . RPN _ 
NMS _ THRESHOLD # 0.7 name = ROI config = 
config rpn _ class rpn _ bbox anchors if mode 
= = training # Class ID mask to mark class 
IDs supported by the dataset the image # came from 
. active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
if not config . USE _ RPN _ ROIS # 
Ignore predicted ROIs and use ROIs provided as an input 
. input _ rois = KL . Input shape = 
config . POST _ NMS _ ROIS _ TRAINING 4 
name = input _ roi dtype = np . int32 
# Normalize coordinates target _ rois = KL . Lambda 
lambda x norm _ boxes _ graph x K . 
shape input _ image 1 3 input _ rois else 
target _ rois = rpn _ rois # Generate detection 
targets # Subsamples proposals and generates target outputs for training 
# Note that proposal class IDs gt _ boxes and 
gt _ masks are zero # padded . Equally returned 
rois and targets are zero padded . rois target _ 
class _ ids target _ bbox target _ mask = 
\ D e t e c t i o n 
T a r g e t L a y e 
r config name = proposal _ targets target _ rois 
input _ gt _ class _ ids gt _ boxes 
input _ gt _ masks # Network Heads # TODO 
verify that this handles zero padded ROIs mrcnn _ class 
_ logits mrcnn _ class mrcnn _ bbox = \ 
fpn _ classifier _ graph rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE mrcnn _ mask = build _ fpn _ 
mask _ graph rois mrcnn _ feature _ maps input 
_ image _ meta config . MASK _ POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN # TODO clean up use 
tf . identify if necessary output _ rois = KL 
. Lambda lambda x x * 1 name = output 
_ rois rois # Losses rpn _ class _ loss 
= KL . Lambda lambda x rpn _ class _ 
loss _ graph * x name = rpn _ class 
_ loss input _ rpn _ match rpn _ class 
_ logits rpn _ bbox _ loss = KL . 
Lambda lambda x rpn _ bbox _ loss _ graph 
config * x name = rpn _ bbox _ loss 
input _ rpn _ bbox input _ rpn _ match 
rpn _ bbox class _ loss = KL . Lambda 
lambda x mrcnn _ class _ loss _ graph * 
x name = mrcnn _ class _ loss target _ 
class _ ids mrcnn _ class _ logits active _ 
class _ ids bbox _ loss = KL . Lambda 
lambda x mrcnn _ bbox _ loss _ graph * 
x name = mrcnn _ bbox _ loss target _ 
bbox target _ class _ ids mrcnn _ bbox mask 
_ loss = KL . Lambda lambda x mrcnn _ 
mask _ loss _ graph * x name = mrcnn 
_ mask _ loss target _ mask target _ class 
_ ids mrcnn _ mask # Model inputs = input 
_ image input _ image _ meta input _ rpn 
_ match input _ rpn _ bbox input _ gt 
_ class _ ids input _ gt _ boxes input 
_ gt _ masks if not config . USE _ 
RPN _ ROIS inputs . append input _ rois outputs 
= rpn _ class _ logits rpn _ class rpn 
_ bbox mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois output 
_ rois rpn _ class _ loss rpn _ bbox 
_ loss class _ loss bbox _ loss mask _ 
loss model = KM . Model inputs outputs name = 
mask _ rcnn else # Network Heads # Proposal classifier 
and BBox regressor heads # output shapes # mrcnn _ 
class _ logits batch num _ rois NUM _ CLASSES 
classifier logits before softmax # mrcnn _ class batch num 
_ rois NUM _ CLASSES classifier probabilities # mrcnn _ 
bbox deltas batch num _ rois NUM _ CLASSES dy 
dx log dh log dw mrcnn _ class _ logits 
mrcnn _ class mrcnn _ bbox = \ fpn _ 
classifier _ graph rpn _ rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE # Detections # output is batch num _ 
detections y1 x1 y2 x2 class _ id score in 
# normalized coordinates detections = DetectionLayer config name = mrcnn 
_ detection rpn _ rois mrcnn _ class mrcnn _ 
bbox input _ image _ meta # Create masks for 
detections detection _ boxes = KL . Lambda lambda x 
x . . . 4 detections mrcnn _ mask = 
build _ fpn _ mask _ graph detection _ boxes 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN model = KM . Model input _ image input 
_ image _ meta input _ anchors detections mrcnn _ 
class mrcnn _ bbox mrcnn _ mask rpn _ rois 
rpn _ class rpn _ bbox name = mask _ 
rcnn # Add multi GPU support . if config . 
GPU _ COUNT 1 from mrcnn . parallel _ model 
import ParallelModel model = ParallelModel model config . GPU _ 
COUNT return model 一 模块 概述 上节 的 最后 我们 进行 了 如下 
操作 获取 了 有限 的 proposal # IMAGES _ PER 
_ GPU num _ rois y1 x1 y2 x2 # 
IMAGES _ PER _ GPU 取代 了 batch 之后 说 
的 batch 都是 IMAGES _ PER _ GPU rpn _ 
rois = ProposalLayer proposal _ count = proposal _ count 
nms _ threshold = config . RPN _ NMS _ 
THRESHOLD # 0.7 name = ROI config = config rpn 
_ class rpn _ bbox anchors 总结 一下 与 GT 
的 IOU 大于 0.7 与 某一个 GT 的 IOU 最大 
的 那个 anchor 进一步 我们 需要 按照 RCNN 的 思路 
使用 proposal 对 共享 特征 进行 ROI 操作 在 Mask 
RCNN 中 这里 有 两个 创新 ROI 使用 ROI Align 
取代 了 之前 的 ROI Pooling 共享 特征 由 之前 
的 单层 变换 为了 FPN 得到 的 金字塔 多层 特征 
即 mrcnn _ feature _ maps = P2 P3 P4 
P5 其中 创新 点 2 意味着 我们 不同 的 proposal 
对应 去 ROI 的 特征 层 并不相同 所以 我们 需要 
按照 proposal 的 长宽 将 不同 的 proposal 对应 给 
不同 的 特征 层 在 对应 特征 层 上 进行 
ROI 操作 二 实现 分析 下 面会 用到 高维 切片 
函数 这里 先行 给出 讲解 链接 TensorFlow 高级 高维 切片 
gather _ nd 接 前文 bulid 函数 代码 我们 如下 
调入 实现 本节 的 功能 if mode = = training 
else # Network Heads # Proposal classifier and BBox regressor 
heads # output shapes # mrcnn _ class _ logits 
batch num _ rois NUM _ CLASSES classifier logits before 
softmax # mrcnn _ class batch num _ rois NUM 
_ CLASSES classifier probabilities # mrcnn _ bbox deltas batch 
num _ rois NUM _ CLASSES dy dx log dh 
log dw mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox = \ fpn _ classifier _ graph 
rpn _ rois mrcnn _ feature _ maps input _ 
image _ meta config . POOL _ SIZE config . 
NUM _ CLASSES train _ bn = config . TRAIN 
_ BN fc _ layers _ size = config . 
FPN _ CLASSIF _ FC _ LAYERS _ SIZE FPN 
特征 层 分类 函数 纵览 如下 # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # Feature Pyramid Network 
Heads # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def fpn _ classifier _ graph rois feature _ 
maps image _ meta pool _ size num _ classes 
train _ bn = True fc _ layers _ size 
= 1024 Builds the computation graph of the feature pyramid 
network classifier and regressor heads . rois batch num _ 
rois y1 x1 y2 x2 Proposal boxes in normalized coordinates 
. feature _ maps List of feature maps from different 
layers of the pyramid P2 P3 P4 P5 . Each 
has a different resolution . image _ meta batch meta 
data Image details . See compose _ image _ meta 
pool _ size The width of the square feature map 
generated from ROI Pooling . num _ classes number of 
classes which determines the depth of the results train _ 
bn Boolean . Train or freeze Batch Norm layers fc 
_ layers _ size Size of the 2 FC layers 
Returns logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax probs batch num _ rois NUM _ 
CLASSES classifier probabilities bbox _ deltas batch num _ rois 
NUM _ CLASSES dy dx log dh log dw Deltas 
to apply to proposal boxes # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps # Two 1024 FC layers 
implemented with Conv2D for consistency # TimeDistributed 拆 分了 输入 
数据 的 第 1 维 从0/nr 开始 将 完全 一样 
的 模型 独立 的 应用于 拆分 后的/nr 输入 数据 具体 
到 下行 # 就是 将 num _ rois 个 卷积 
应用到 num _ rois 个 维度 为 batch POOL _ 
SIZE POOL _ SIZE channels 的 输入 结果 合并 x 
= KL . TimeDistributed KL . Conv2D fc _ layers 
_ size pool _ size pool _ size padding = 
valid name = mrcnn _ class _ conv1 x # 
batch num _ rois 1 1 1024 x = KL 
. TimeDistributed BatchNorm name = mrcnn _ class _ bn1 
x training = train _ bn x = KL . 
Activation relu x x = KL . TimeDistributed KL . 
Conv2D fc _ layers _ size 1 1 name = 
mrcnn _ class _ conv2 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn2 x 
training = train _ bn x = KL . Activation 
relu x shared = KL . Lambda lambda x K 
. squeeze K . squeeze x 3 2 name = 
pool _ squeeze x # batch num _ rois 1024 
# Classifier head mrcnn _ class _ logits = KL 
. TimeDistributed KL . Dense num _ classes name = 
mrcnn _ class _ logits shared mrcnn _ probs = 
KL . TimeDistributed KL . Activation softmax name = mrcnn 
_ class mrcnn _ class _ logits # BBox head 
# batch num _ rois NUM _ CLASSES * dy 
dx log dh log dw x = KL . TimeDistributed 
KL . Dense num _ classes * 4 activation = 
linear name = mrcnn _ bbox _ fc shared # 
Reshape to batch num _ rois NUM _ CLASSES dy 
dx log dh log dw s = K . int 
_ shape x # 下行 源码 K . reshape inputs 
K . shape inputs 0 + self . target _ 
shape mrcnn _ bbox = KL . Reshape s 1 
num _ classes 4 name = mrcnn _ bbox x 
return mrcnn _ class _ logits mrcnn _ probs mrcnn 
_ bbox 下面 我们 来 分析 一下 该 函数 进入 
函数 首 先调 用了 PyramidROI # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps 这个 class 基本 实现 了 
我们 开篇 所说 的 全部 功能 即 特征 层 分类 
并 ROI ROIAlign 类 首先 我们 依据 计算机 视觉 FPN 
特征 金字塔 网络 中 第三 节 所讲 对 proposal 进行 
分类 注意 的 是 我们 使用 于 网络 中的 hw 
是 归一 化了 的 以 原图 hw 为 单位 长度 
所以 计算 时 需要 还原 对于 公式 而言 w h 
分别 表示 宽度 和 高度 k 是 分配 RoI 的 
level 是 w h = 224 224时 映射 的 level 
注意 两 个 操作 节点 level _ boxes 和 box 
_ indices 第一 个 记录 了 对应 的 level 特征 
层 中 分配 到 的 每个 box 的 坐标 第二个 
则 记录 了 每个 box 对应 的 图片 在 batch 
中的 索引 一个 记录 了 候选框 索引 对应 的 图片 
即 下 文中 的 两个 大块 一个 记录 了 候选框 
的 索引 对应 其 坐标 即 小 黑框 的 坐标 
两者 结合 可以 索引 到 下面 每个 黑色 小 框 
的 坐标 信息 至于 ROI Align 本身 实际 就是 双 
线性插值 使用 内置 API 实现 即可 这里 属于 RPN 网络 
和 RCNN 网络 的 分界线 level _ boxes 和 box 
_ indices 本身 属于 RPN 计算出来 结果 但是 两者 作用于 
feature 后的/nr 输出 Tensor 却是 RCNN 部分 的 输入 但是 
两 部分 的 梯度 不能 相互 流通 的 所以 需要 
tf . stop _ gradient 截断 梯度 传播 # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # ROIAlign 
Layer # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def log2 _ graph x Implementation of Log2 . 
TF doesn t have a native implementation . return tf 
. log x / tf . log 2.0 class PyramidROIAlign 
KE . Layer Implements ROI Pooling on multiple levels of 
the feature pyramid . Params pool _ shape pool _ 
height pool _ width of the output pooled regions . 
Usually 7 7 Inputs boxes batch num _ boxes y1 
x1 y2 x2 in normalized coordinates . Possibly padded with 
zeros if not enough boxes to fill the array . 
image _ meta batch meta data Image details . See 
compose _ image _ meta feature _ maps List of 
feature maps from different levels of the pyramid . Each 
is batch height width channels Output Pooled regions in the 
shape batch num _ boxes pool _ height pool _ 
width channels . The width and height are those specific 
in the pool _ shape in the layer constructor . 
def _ _ init _ _ self pool _ shape 
* * kwargs super PyramidROIAlign self . _ _ init 
_ _ * * kwargs self . pool _ shape 
= tuple pool _ shape def call self inputs # 
num _ boxes 指 的 是 proposal 数目 它们 均会 
作用于 每张 图片 上 只是 不同 的 proposal 作用于 图片 
# 的 特征 级别 不同 我 通过 循环 特征 层 
寻找 符合 的 proposal 应用 ROIAlign # Crop boxes batch 
num _ boxes y1 x1 y2 x2 in normalized coords 
boxes = inputs 0 # Image meta # Holds details 
about the image . See compose _ image _ meta 
image _ meta = inputs 1 # Feature Maps . 
List of feature maps from different level of the # 
feature pyramid . Each is batch height width channels feature 
_ maps = inputs 2 # Assign each ROI to 
a level in the pyramid based on the ROI area 
. y1 x1 y2 x2 = tf . split boxes 
4 axis = 2 h = y2 y1 w = 
x2 x1 # Use shape of first image . Images 
in a batch must have the same size . image 
_ shape = parse _ image _ meta _ graph 
image _ meta image _ shape 0 # h w 
c # Equation 1 in the Feature Pyramid Networks paper 
. Account for # the fact that our coordinates are 
normalized here . # e . g . a 224x224 
ROI in pixels maps to P4 image _ area = 
tf . cast image _ shape 0 * image _ 
shape 1 tf . float32 roi _ level = log2 
_ graph tf . sqrt h * w / 224.0 
/ tf . sqrt image _ area # h w 
已经 归一化 roi _ level = tf . minimum 5 
tf . maximum 2 4 + tf . cast tf 
. round roi _ level tf . int32 # 确 
保值 位于 2 到 5 之间 roi _ level = 
tf . squeeze roi _ level 2 # batch num 
_ boxes # Loop through levels and apply ROI pooling 
to each . P2 to P5 . pooled = box 
_ to _ level = for i level in enumerate 
range 2 6 # tf . where 返回值 格式 坐标 
1 坐标 2 # np . where 返回值 格式 坐标 
1 . x 坐标 2 . x 坐标 1 . 
y 坐标 2 . y ix = tf . where 
tf . equal roi _ level level # 返回 坐标 
表示 第 n 张 图片 的 第 i 个 proposal 
level _ boxes = tf . gather _ nd boxes 
ix # 本 level 的 proposal 数目 4 # Box 
indices for crop _ and _ resize . box _ 
indices = tf . cast ix 0 tf . int32 
# 记录 每个 propose 对应 图片 序号 # Keep track 
of which box is mapped to which level box _ 
to _ level . append ix # Stop gradient propogation 
to ROI proposals level _ boxes = tf . stop 
_ gradient level _ boxes box _ indices = tf 
. stop _ gradient box _ indices # Crop and 
Resize # From Mask R CNN paper We sample four 
regular locations so # that we can evaluate either max 
or average pooling . In fact # interpolating only a 
single value at each bin center without # pooling is 
nearly as effective . # # Here we use the 
simplified approach of a single value per bin # which 
is how it s done in tf . crop _ 
and _ resize # Result this _ level _ num 
_ boxes pool _ height pool _ width channels pooled 
. append tf . image . crop _ and _ 
resize feature _ maps i level _ boxes box _ 
indices self . pool _ shape method = bilinear # 
输入 参数 shape # batch image _ height image _ 
width channels # this _ level _ num _ boxes 
4 # this _ level _ num _ boxes # 
height pool _ width # Pack pooled features into one 
tensor pooled = tf . concat pooled axis = 0 
# batch * num _ boxes pool _ height pool 
_ width channels # Pack box _ to _ level 
mapping into one array and add another # column representing 
the order of pooled boxes box _ to _ level 
= tf . concat box _ to _ level axis 
= 0 # batch * num _ boxes 2 box 
_ range = tf . expand _ dims tf . 
range tf . shape box _ to _ level 0 
1 # batch * num _ boxes 1 box _ 
to _ level = tf . concat tf . cast 
box _ to _ level tf . int32 box _ 
range axis = 1 # batch * num _ boxes 
3 # 截止 到 目前 我们 获取 了 记录 全部 
ROIAlign 结果 feat 集合 的 张量 pooled 和 记录 这些 
feat 相关 信息 的 张量 box _ to _ level 
# 由于 提取 方法 的 原因 此时 的 feat 并 
不是 按照 原始 顺序 排序 先按 batch 然后按 box index 
排序 下面 我们 设法 将之 恢复 顺 # 序 ROIAlign 
作用于 对应 图片 的 对应 proposal 生成 feat # Rearrange 
pooled features to match the order of the original boxes 
# Sort box _ to _ level by batch then 
box index # TF doesn t have a way to 
sort by two columns so merge them and sort . 
# box _ to _ level i 0 表示 的 
是 当前 feat 隶属 的 图片 索引 box _ to 
_ level i 1 表示 的 是 其 box 序号 
sorting _ tensor = box _ to _ level 0 
* 100000 + box _ to _ level 1 # 
batch * num _ boxes ix = tf . nn 
. top _ k sorting _ tensor k = tf 
. shape box _ to _ level 0 . indices 
1 ix = tf . gather box _ to _ 
level 2 ix pooled = tf . gather pooled ix 
# Re add the batch dimension # batch num _ 
boxes y1 x1 y2 x2 batch * num _ boxes 
pool _ height pool _ width channels shape = tf 
. concat tf . shape boxes 2 tf . shape 
pooled 1 axis = 0 pooled = tf . reshape 
pooled shape return pooled # batch num _ boxes pool 
_ height pool _ width channels 初步 分类 / 回归 
经过 ROI 之后 我们 获取 了 众多 shape 一致 的 
小 feat 为了 获取 他们 的 分类 回归 信息 我们 
构建 一系列 并行 的 网络 进行 处理 # Two 1024 
FC layers implemented with Conv2D for consistency # TimeDistributed 拆 
分了 输入 数据 的 第 1 维 从0/nr 开始 将 
完全 一样 的 模型 独立 的 应用于 拆分 后的/nr 输入 
数据 具体 到 下行 # 就是 将 num _ rois 
个 卷积 应用到 num _ rois 个 维度 为 batch 
POOL _ SIZE POOL _ SIZE channels 的 输入 结果 
合并 x = KL . TimeDistributed KL . Conv2D fc 
_ layers _ size pool _ size pool _ size 
padding = valid name = mrcnn _ class _ conv1 
x # batch num _ rois 1 1 1024 x 
= KL . TimeDistributed BatchNorm name = mrcnn _ class 
_ bn1 x training = train _ bn x = 
KL . Activation relu x x = KL . TimeDistributed 
KL . Conv2D fc _ layers _ size 1 1 
name = mrcnn _ class _ conv2 x x = 
KL . TimeDistributed BatchNorm name = mrcnn _ class _ 
bn2 x training = train _ bn x = KL 
. Activation relu x shared = KL . Lambda lambda 
x K . squeeze K . squeeze x 3 2 
name = pool _ squeeze x # batch num _ 
rois 1024 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBox head # batch num _ rois NUM _ CLASSES 
* dy dx log dh log dw x = KL 
. TimeDistributed KL . Dense num _ classes * 4 
activation = linear name = mrcnn _ bbox _ fc 
shared # Reshape to batch num _ rois NUM _ 
CLASSES dy dx log dh log dw s = K 
. int _ shape x # 下行 源码 K . 
reshape inputs K . shape inputs 0 + self . 
target _ shape mrcnn _ bbox = KL . Reshape 
s 1 num _ classes 4 name = mrcnn _ 
bbox x return mrcnn _ class _ logits mrcnn _ 
probs mrcnn _ bbox 返回 如下 mrcnn _ class _ 
logits         batch num _ rois NUM 
_ CLASSES       classifier logits before softmax mrcnn 
_ class                 
batch num _ rois NUM _ CLASSES       
classifier p r o b a b i l i 
t i e s m r c n n _ 
bbox deltas     batch num _ rois NUM _ 
CLASSES dy dx log dh log dw KL . TimeDistributed 
实现 建立 一 系列 同样 架构 的 的 并行 网络结构 
dim0 个 将 dim0 dim1 中的 每个 dim1 作为 输入 
并行 的 计算 输出 附 build 函数 总览 def build 
self mode config Build Mask R CNN architecture . input 
_ shape The shape of the input image . mode 
Either training or inference . The inputs and outputs of 
the model differ accordingly . assert mode in training inference 
# Image size must be dividable by 2 multiple times 
h w = config . IMAGE _ SHAPE 2 # 
1024 1024 3 if h / 2 * * 6 
= int h / 2 * * 6 or w 
/ 2 * * 6 = int w / 2 
* * 6 # 这里 就 限定 了 下 采样 
不会 产生 坐标 误差 raise Exception Image size must be 
dividable by 2 at least 6 times to avoid fractions 
when downscaling and upscaling . For example use 256 320 
384 448 512 . . . etc . # Inputs 
input _ image = KL . Input shape = None 
None config . IMAGE _ SHAPE 2 name = input 
_ image input _ image _ meta = KL . 
Input shape = config . IMAGE _ META _ SIZE 
name = input _ image _ meta if mode = 
= training # RPN GT input _ rpn _ match 
= KL . Input shape = None 1 name = 
input _ rpn _ match dtype = tf . int32 
input _ rpn _ bbox = KL . Input shape 
= None 4 name = input _ rpn _ bbox 
dtype = tf . float32 # Detection GT class IDs 
bounding boxes and masks # 1 . GT Class IDs 
zero padded input _ gt _ class _ ids = 
KL . Input shape = None name = input _ 
gt _ class _ ids dtype = tf . int32 
# 2 . GT Boxes in pixels zero padded # 
batch MAX _ GT _ INSTANCES y1 x1 y2 x2 
in image coordinates input _ gt _ boxes = KL 
. Input shape = None 4 name = input _ 
gt _ boxes dtype = tf . float32 # Normalize 
coordinates gt _ boxes = KL . Lambda lambda x 
norm _ boxes _ graph x K . shape input 
_ image 1 3 input _ gt _ boxes # 
3 . GT Masks zero padded # batch height width 
MAX _ GT _ INSTANCES if config . USE _ 
MINI _ MASK input _ gt _ masks = KL 
. Input shape = config . MINI _ MASK _ 
SHAPE 0 config . MINI _ MASK _ SHAPE 1 
None name = input _ gt _ masks dtype = 
bool else input _ gt _ masks = KL . 
Input shape = config . IMAGE _ SHAPE 0 config 
. IMAGE _ SHAPE 1 None name = input _ 
gt _ masks dtype = bool elif mode = = 
inference # Anchors in normalized coordinates input _ anchors = 
KL . Input shape = None 4 name = input 
_ anchors # Build the shared convolutional layers . # 
Bottom up Layers # Returns a list of the last 
layers of each stage 5 in total . # Don 
t create the thead stage 5 so we pick the 
4th item in the list . if callable config . 
BACKBONE _ C2 C3 C4 C5 = config . BACKBONE 
input _ image stage5 = True train _ bn = 
config . TRAIN _ BN else _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers # TODO add 
assert to varify feature map sizes match what s in 
config P5 = KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c5p5 C5 # 256 P4 = KL . Add 
name = fpn _ p4add KL . UpSampling2D size = 
2 2 name = fpn _ p5upsampled P5 KL . 
Conv2D config . TOP _ DOWN _ PYRAMID _ SIZE 
1 1 name = fpn _ c4p4 C4 P3 = 
KL . Add name = fpn _ p3add KL . 
UpSampling2D size = 2 2 name = fpn _ p4upsampled 
P4 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c3p3 
C3 P2 = KL . Add name = fpn _ 
p2add KL . UpSampling2D size = 2 2 name = 
fpn _ p3upsampled P3 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c2p2 C2 # Attach 3x3 conv to all 
P layers to get the final feature maps . P2 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p2 P2 P3 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p3 P3 P4 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p4 P4 P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p5 P5 # 
P6 is used for the 5th anchor scale in RPN 
. Generated by # subsampling from P5 with stride of 
2 . P6 = KL . MaxPooling2D pool _ size 
= 1 1 strides = 2 name = fpn _ 
p6 P5 # Note that P6 is used in RPN 
but not in the classifier heads . rpn _ feature 
_ maps = P2 P3 P4 P5 P6 mrcnn _ 
feature _ maps = P2 P3 P4 P5 # Anchors 
if mode = = training anchors = self . get 
_ anchors config . IMAGE _ SHAPE # Duplicate across 
the batch dimension because Keras requires it # TODO can 
this be optimized to avoid duplicating the anchors anchors = 
np . broadcast _ to anchors config . BATCH _ 
SIZE + anchors . shape # A hack to get 
around Keras s bad support for constants anchors = KL 
. Lambda lambda x tf . Variable anchors name = 
anchors input _ image else anchors = input _ anchors 
# RPN Model 返回 的 是 keras 的 Module 对象 
注意 keras 中的 Module 对象 是 可 call 的 rpn 
= build _ rpn _ model config . RPN _ 
ANCHOR _ STRIDE # 1 3 256 len config . 
RPN _ ANCHOR _ RATIOS config . TOP _ DOWN 
_ PYRAMID _ SIZE # Loop through pyramid layers layer 
_ outputs = # list of lists for p in 
rpn _ feature _ maps layer _ outputs . append 
rpn p # 保存 各 pyramid 特征 经过 RPN 之后 
的 结果 # Concatenate layer outputs # Convert from list 
of lists of level outputs to list of lists # 
of outputs across levels . # e . g . 
a1 b1 c1 a2 b2 c2 = a1 a2 b1 
b2 c1 c2 output _ names = rpn _ class 
_ logits rpn _ class rpn _ bbox outputs = 
list zip * layer _ outputs # logits2 6 class2 
6 bbox2 6 outputs = KL . Concatenate axis = 
1 name = n list o for o n in 
zip outputs output _ names # batch num _ anchors 
2/4 # 其中 num _ anchors 指 的 是 全部 
特征 层 上 的 anchors 总数 rpn _ class _ 
logits rpn _ class rpn _ bbox = outputs # 
Generate proposals # Proposals are batch N y1 x1 y2 
x2 in normalized coordinates # and zero padded . # 
POST _ NMS _ ROIS _ INFERENCE = 1000 # 
POST _ NMS _ ROIS _ TRAINING = 2000 proposal 
_ count = config . POST _ NMS _ ROIS 
_ TRAINING if mode = = training \ else config 
. POST _ NMS _ ROIS _ INFERENCE # IMAGES 
_ PER _ GPU num _ rois y1 x1 y2 
x2 # IMAGES _ PER _ GPU 取代 了 batch 
之后 说 的 batch 都是 IMAGES _ PER _ GPU 
rpn _ rois = ProposalLayer proposal _ count = proposal 
_ count nms _ threshold = config . RPN _ 
NMS _ THRESHOLD # 0.7 name = ROI config = 
config rpn _ class rpn _ bbox anchors if mode 
= = training # Class ID mask to mark class 
IDs supported by the dataset the image # came from 
. active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
if not config . USE _ RPN _ ROIS # 
Ignore predicted ROIs and use ROIs provided as an input 
. input _ rois = KL . Input shape = 
config . POST _ NMS _ ROIS _ TRAINING 4 
name = input _ roi dtype = np . int32 
# Normalize coordinates target _ rois = KL . Lambda 
lambda x norm _ boxes _ graph x K . 
shape input _ image 1 3 input _ rois else 
target _ rois = rpn _ rois # Generate detection 
targets # Subsamples proposals and generates target outputs for training 
# Note that proposal class IDs gt _ boxes and 
gt _ masks are zero # padded . Equally returned 
rois and targets are zero padded . rois target _ 
class _ ids target _ bbox target _ mask = 
\ D e t e c t i o n 
T a r g e t L a y e 
r config name = proposal _ targets target _ rois 
input _ gt _ class _ ids gt _ boxes 
input _ gt _ masks # Network Heads # TODO 
verify that this handles zero padded ROIs mrcnn _ class 
_ logits mrcnn _ class mrcnn _ bbox = \ 
fpn _ classifier _ graph rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE mrcnn _ mask = build _ fpn _ 
mask _ graph rois mrcnn _ feature _ maps input 
_ image _ meta config . MASK _ POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN # TODO clean up use 
tf . identify if necessary output _ rois = KL 
. Lambda lambda x x * 1 name = output 
_ rois rois # Losses rpn _ class _ loss 
= KL . Lambda lambda x rpn _ class _ 
loss _ graph * x name = rpn _ class 
_ loss input _ rpn _ match rpn _ class 
_ logits rpn _ bbox _ loss = KL . 
Lambda lambda x rpn _ bbox _ loss _ graph 
config * x name = rpn _ bbox _ loss 
input _ rpn _ bbox input _ rpn _ match 
rpn _ bbox class _ loss = KL . Lambda 
lambda x mrcnn _ class _ loss _ graph * 
x name = mrcnn _ class _ loss target _ 
class _ ids mrcnn _ class _ logits active _ 
class _ ids bbox _ loss = KL . Lambda 
lambda x mrcnn _ bbox _ loss _ graph * 
x name = mrcnn _ bbox _ loss target _ 
bbox target _ class _ ids mrcnn _ bbox mask 
_ loss = KL . Lambda lambda x mrcnn _ 
mask _ loss _ graph * x name = mrcnn 
_ mask _ loss target _ mask target _ class 
_ ids mrcnn _ mask # Model inputs = input 
_ image input _ image _ meta input _ rpn 
_ match input _ rpn _ bbox input _ gt 
_ class _ ids input _ gt _ boxes input 
_ gt _ masks if not config . USE _ 
RPN _ ROIS inputs . append input _ rois outputs 
= rpn _ class _ logits rpn _ class rpn 
_ bbox mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois output 
_ rois rpn _ class _ loss rpn _ bbox 
_ loss class _ loss bbox _ loss mask _ 
loss model = KM . Model inputs outputs name = 
mask _ rcnn else # Network Heads # Proposal classifier 
and BBox regressor heads # output shapes # mrcnn _ 
class _ logits batch num _ rois NUM _ CLASSES 
classifier logits before softmax # mrcnn _ class batch num 
_ rois NUM _ CLASSES classifier probabilities # mrcnn _ 
bbox deltas batch num _ rois NUM _ CLASSES dy 
dx log dh log dw mrcnn _ class _ logits 
mrcnn _ class mrcnn _ bbox = \ fpn _ 
classifier _ graph rpn _ rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE # Detections # output is batch num _ 
detections y1 x1 y2 x2 class _ id score in 
# normalized coordinates detections = DetectionLayer config name = mrcnn 
_ detection rpn _ rois mrcnn _ class mrcnn _ 
bbox input _ image _ meta # Create masks for 
detections detection _ boxes = KL . Lambda lambda x 
x . . . 4 detections mrcnn _ mask = 
build _ fpn _ mask _ graph detection _ boxes 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN model = KM . Model input _ image input 
_ image _ meta input _ anchors detections mrcnn _ 
class mrcnn _ bbox mrcnn _ mask rpn _ rois 
rpn _ class rpn _ bbox name = mask _ 
rcnn # Add multi GPU support . if config . 
GPU _ COUNT 1 from mrcnn . parallel _ model 
import ParallelModel model = ParallelModel model config . GPU _ 
COUNT return model 一 模块 概述 上节 的 最后 我们 进行 了 如下 
操作 获取 了 有限 的 proposal # IMAGES _ PER 
_ GPU num _ rois y1 x1 y2 x2 # 
IMAGES _ PER _ GPU 取代 了 batch 之后 说 
的 batch 都是 IMAGES _ PER _ GPU rpn _ 
rois = ProposalLayer proposal _ count = proposal _ count 
nms _ threshold = config . RPN _ NMS _ 
THRESHOLD # 0.7 name = ROI config = config rpn 
_ class rpn _ bbox anchors 总结 一下 与 GT 
的 IOU 大于 0.7 与 某一个 GT 的 IOU 最大 
的 那个 anchor 进一步 我们 需要 按照 RCNN 的 思路 
使用 proposal 对 共享 特征 进行 ROI 操作 在 Mask 
RCNN 中 这里 有 两个 创新 ROI 使用 ROI Align 
取代 了 之前 的 ROI Pooling 共享 特征 由 之前 
的 单层 变换 为了 FPN 得到 的 金字塔 多层 特征 
即 mrcnn _ feature _ maps = P2 P3 P4 
P5 其中 创新 点 2 意味着 我们 不同 的 proposal 
对应 去 ROI 的 特征 层 并不相同 所以 我们 需要 
按照 proposal 的 长宽 将 不同 的 proposal 对应 给 
不同 的 特征 层 在 对应 特征 层 上 进行 
ROI 操作 二 实现 分析 下 面会 用到 高维 切片 
函数 这里 先行 给出 讲解 链接 TensorFlow 高级 高维 切片 
gather _ nd 接 前文 bulid 函数 代码 我们 如下 
调入 实现 本节 的 功能 if mode = = training 
else # Network Heads # Proposal classifier and BBox regressor 
heads # output shapes # mrcnn _ class _ logits 
batch num _ rois NUM _ CLASSES classifier logits before 
softmax # mrcnn _ class batch num _ rois NUM 
_ CLASSES classifier probabilities # mrcnn _ bbox deltas batch 
num _ rois NUM _ CLASSES dy dx log dh 
log dw mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox = \ fpn _ classifier _ graph 
rpn _ rois mrcnn _ feature _ maps input _ 
image _ meta config . POOL _ SIZE config . 
NUM _ CLASSES train _ bn = config . TRAIN 
_ BN fc _ layers _ size = config . 
FPN _ CLASSIF _ FC _ LAYERS _ SIZE FPN 
特征 层 分类 函数 纵览 如下 # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # Feature Pyramid Network 
Heads # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def fpn _ classifier _ graph rois feature _ 
maps image _ meta pool _ size num _ classes 
train _ bn = True fc _ layers _ size 
= 1024 Builds the computation graph of the feature pyramid 
network classifier and regressor heads . rois batch num _ 
rois y1 x1 y2 x2 Proposal boxes in normalized coordinates 
. feature _ maps List of feature maps from different 
layers of the pyramid P2 P3 P4 P5 . Each 
has a different resolution . image _ meta batch meta 
data Image details . See compose _ image _ meta 
pool _ size The width of the square feature map 
generated from ROI Pooling . num _ classes number of 
classes which determines the depth of the results train _ 
bn Boolean . Train or freeze Batch Norm layers fc 
_ layers _ size Size of the 2 FC layers 
Returns logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax probs batch num _ rois NUM _ 
CLASSES classifier probabilities bbox _ deltas batch num _ rois 
NUM _ CLASSES dy dx log dh log dw Deltas 
to apply to proposal boxes # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps # Two 1024 FC layers 
implemented with Conv2D for consistency # TimeDistributed 拆 分了 输入 
数据 的 第 1 维 从0/nr 开始 将 完全 一样 
的 模型 独立 的 应用于 拆分 后的/nr 输入 数据 具体 
到 下行 # 就是 将 num _ rois 个 卷积 
应用到 num _ rois 个 维度 为 batch POOL _ 
SIZE POOL _ SIZE channels 的 输入 结果 合并 x 
= KL . TimeDistributed KL . Conv2D fc _ layers 
_ size pool _ size pool _ size padding = 
valid name = mrcnn _ class _ conv1 x # 
batch num _ rois 1 1 1024 x = KL 
. TimeDistributed BatchNorm name = mrcnn _ class _ bn1 
x training = train _ bn x = KL . 
Activation relu x x = KL . TimeDistributed KL . 
Conv2D fc _ layers _ size 1 1 name = 
mrcnn _ class _ conv2 x x = KL . 
TimeDistributed BatchNorm name = mrcnn _ class _ bn2 x 
training = train _ bn x = KL . Activation 
relu x shared = KL . Lambda lambda x K 
. squeeze K . squeeze x 3 2 name = 
pool _ squeeze x # batch num _ rois 1024 
# Classifier head mrcnn _ class _ logits = KL 
. TimeDistributed KL . Dense num _ classes name = 
mrcnn _ class _ logits shared mrcnn _ probs = 
KL . TimeDistributed KL . Activation softmax name = mrcnn 
_ class mrcnn _ class _ logits # BBox head 
# batch num _ rois NUM _ CLASSES * dy 
dx log dh log dw x = KL . TimeDistributed 
KL . Dense num _ classes * 4 activation = 
linear name = mrcnn _ bbox _ fc shared # 
Reshape to batch num _ rois NUM _ CLASSES dy 
dx log dh log dw s = K . int 
_ shape x # 下行 源码 K . reshape inputs 
K . shape inputs 0 + self . target _ 
shape mrcnn _ bbox = KL . Reshape s 1 
num _ classes 4 name = mrcnn _ bbox x 
return mrcnn _ class _ logits mrcnn _ probs mrcnn 
_ bbox 下面 我们 来 分析 一下 该 函数 进入 
函数 首 先调 用了 PyramidROI # ROI Pooling # Shape 
batch num _ rois POOL _ SIZE POOL _ SIZE 
channels x = PyramidROIAlign pool _ size pool _ size 
name = roi _ align _ classifier rois image _ 
meta + feature _ maps 这个 class 基本 实现 了 
我们 开篇 所说 的 全部 功能 即 特征 层 分类 
并 ROI ROIAlign 类 首先 我们 依据 计算机 视觉 FPN 
特征 金字塔 网络 中 第三 节 所讲 对 proposal 进行 
分类 注意 的 是 我们 使用 于 网络 中的 hw 
是 归一 化了 的 以 原图 hw 为 单位 长度 
所以 计算 时 需要 还原 对于 公式 而言 w h 
分别 表示 宽度 和 高度 k 是 分配 RoI 的 
level 是 w h = 224 224时 映射 的 level 
注意 两 个 操作 节点 level _ boxes 和 box 
_ indices 第一 个 记录 了 对应 的 level 特征 
层 中 分配 到 的 每个 box 的 坐标 第二个 
则 记录 了 每个 box 对应 的 图片 在 batch 
中的 索引 一个 记录 了 候选框 索引 对应 的 图片 
即 下 文中 的 两个 大块 一个 记录 了 候选框 
的 索引 对应 其 坐标 即 小 黑框 的 坐标 
两者 结合 可以 索引 到 下面 每个 黑色 小 框 
的 坐标 信息 至于 ROI Align 本身 实际 就是 双 
线性插值 使用 内置 API 实现 即可 这里 属于 RPN 网络 
和 RCNN 网络 的 分界线 level _ boxes 和 box 
_ indices 本身 属于 RPN 计算出来 结果 但是 两者 作用于 
feature 后的/nr 输出 Tensor 却是 RCNN 部分 的 输入 但是 
两 部分 的 梯度 不能 相互 流通 的 所以 需要 
tf . stop _ gradient 截断 梯度 传播 # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # ROIAlign 
Layer # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# def log2 _ graph x Implementation of Log2 . 
TF doesn t have a native implementation . return tf 
. log x / tf . log 2.0 class PyramidROIAlign 
KE . Layer Implements ROI Pooling on multiple levels of 
the feature pyramid . Params pool _ shape pool _ 
height pool _ width of the output pooled regions . 
Usually 7 7 Inputs boxes batch num _ boxes y1 
x1 y2 x2 in normalized coordinates . Possibly padded with 
zeros if not enough boxes to fill the array . 
image _ meta batch meta data Image details . See 
compose _ image _ meta feature _ maps List of 
feature maps from different levels of the pyramid . Each 
is batch height width channels Output Pooled regions in the 
shape batch num _ boxes pool _ height pool _ 
width channels . The width and height are those specific 
in the pool _ shape in the layer constructor . 
def _ _ init _ _ self pool _ shape 
* * kwargs super PyramidROIAlign self . _ _ init 
_ _ * * kwargs self . pool _ shape 
= tuple pool _ shape def call self inputs # 
num _ boxes 指 的 是 proposal 数目 它们 均会 
作用于 每张 图片 上 只是 不同 的 proposal 作用于 图片 
# 的 特征 级别 不同 我 通过 循环 特征 层 
寻找 符合 的 proposal 应用 ROIAlign # Crop boxes batch 
num _ boxes y1 x1 y2 x2 in normalized coords 
boxes = inputs 0 # Image meta # Holds details 
about the image . See compose _ image _ meta 
image _ meta = inputs 1 # Feature Maps . 
List of feature maps from different level of the # 
feature pyramid . Each is batch height width channels feature 
_ maps = inputs 2 # Assign each ROI to 
a level in the pyramid based on the ROI area 
. y1 x1 y2 x2 = tf . split boxes 
4 axis = 2 h = y2 y1 w = 
x2 x1 # Use shape of first image . Images 
in a batch must have the same size . image 
_ shape = parse _ image _ meta _ graph 
image _ meta image _ shape 0 # h w 
c # Equation 1 in the Feature Pyramid Networks paper 
. Account for # the fact that our coordinates are 
normalized here . # e . g . a 224x224 
ROI in pixels maps to P4 image _ area = 
tf . cast image _ shape 0 * image _ 
shape 1 tf . float32 roi _ level = log2 
_ graph tf . sqrt h * w / 224.0 
/ tf . sqrt image _ area # h w 
已经 归一化 roi _ level = tf . minimum 5 
tf . maximum 2 4 + tf . cast tf 
. round roi _ level tf . int32 # 确 
保值 位于 2 到 5 之间 roi _ level = 
tf . squeeze roi _ level 2 # batch num 
_ boxes # Loop through levels and apply ROI pooling 
to each . P2 to P5 . pooled = box 
_ to _ level = for i level in enumerate 
range 2 6 # tf . where 返回值 格式 坐标 
1 坐标 2 # np . where 返回值 格式 坐标 
1 . x 坐标 2 . x 坐标 1 . 
y 坐标 2 . y ix = tf . where 
tf . equal roi _ level level # 返回 坐标 
表示 第 n 张 图片 的 第 i 个 proposal 
level _ boxes = tf . gather _ nd boxes 
ix # 本 level 的 proposal 数目 4 # Box 
indices for crop _ and _ resize . box _ 
indices = tf . cast ix 0 tf . int32 
# 记录 每个 propose 对应 图片 序号 # Keep track 
of which box is mapped to which level box _ 
to _ level . append ix # Stop gradient propogation 
to ROI proposals level _ boxes = tf . stop 
_ gradient level _ boxes box _ indices = tf 
. stop _ gradient box _ indices # Crop and 
Resize # From Mask R CNN paper We sample four 
regular locations so # that we can evaluate either max 
or average pooling . In fact # interpolating only a 
single value at each bin center without # pooling is 
nearly as effective . # # Here we use the 
simplified approach of a single value per bin # which 
is how it s done in tf . crop _ 
and _ resize # Result this _ level _ num 
_ boxes pool _ height pool _ width channels pooled 
. append tf . image . crop _ and _ 
resize feature _ maps i level _ boxes box _ 
indices self . pool _ shape method = bilinear # 
输入 参数 shape # batch image _ height image _ 
width channels # this _ level _ num _ boxes 
4 # this _ level _ num _ boxes # 
height pool _ width # Pack pooled features into one 
tensor pooled = tf . concat pooled axis = 0 
# batch * num _ boxes pool _ height pool 
_ width channels # Pack box _ to _ level 
mapping into one array and add another # column representing 
the order of pooled boxes box _ to _ level 
= tf . concat box _ to _ level axis 
= 0 # batch * num _ boxes 2 box 
_ range = tf . expand _ dims tf . 
range tf . shape box _ to _ level 0 
1 # batch * num _ boxes 1 box _ 
to _ level = tf . concat tf . cast 
box _ to _ level tf . int32 box _ 
range axis = 1 # batch * num _ boxes 
3 # 截止 到 目前 我们 获取 了 记录 全部 
ROIAlign 结果 feat 集合 的 张量 pooled 和 记录 这些 
feat 相关 信息 的 张量 box _ to _ level 
# 由于 提取 方法 的 原因 此时 的 feat 并 
不是 按照 原始 顺序 排序 先按 batch 然后按 box index 
排序 下面 我们 设法 将之 恢复 顺 # 序 ROIAlign 
作用于 对应 图片 的 对应 proposal 生成 feat # Rearrange 
pooled features to match the order of the original boxes 
# Sort box _ to _ level by batch then 
box index # TF doesn t have a way to 
sort by two columns so merge them and sort . 
# box _ to _ level i 0 表示 的 
是 当前 feat 隶属 的 图片 索引 box _ to 
_ level i 1 表示 的 是 其 box 序号 
sorting _ tensor = box _ to _ level 0 
* 100000 + box _ to _ level 1 # 
batch * num _ boxes ix = tf . nn 
. top _ k sorting _ tensor k = tf 
. shape box _ to _ level 0 . indices 
1 ix = tf . gather box _ to _ 
level 2 ix pooled = tf . gather pooled ix 
# Re add the batch dimension # batch num _ 
boxes y1 x1 y2 x2 batch * num _ boxes 
pool _ height pool _ width channels shape = tf 
. concat tf . shape boxes 2 tf . shape 
pooled 1 axis = 0 pooled = tf . reshape 
pooled shape return pooled # batch num _ boxes pool 
_ height pool _ width channels 初步 分类 / 回归 
经过 ROI 之后 我们 获取 了 众多 shape 一致 的 
小 feat 为了 获取 他们 的 分类 回归 信息 我们 
构建 一系列 并行 的 网络 进行 处理 # Two 1024 
FC layers implemented with Conv2D for consistency # TimeDistributed 拆 
分了 输入 数据 的 第 1 维 从0/nr 开始 将 
完全 一样 的 模型 独立 的 应用于 拆分 后的/nr 输入 
数据 具体 到 下行 # 就是 将 num _ rois 
个 卷积 应用到 num _ rois 个 维度 为 batch 
POOL _ SIZE POOL _ SIZE channels 的 输入 结果 
合并 x = KL . TimeDistributed KL . Conv2D fc 
_ layers _ size pool _ size pool _ size 
padding = valid name = mrcnn _ class _ conv1 
x # batch num _ rois 1 1 1024 x 
= KL . TimeDistributed BatchNorm name = mrcnn _ class 
_ bn1 x training = train _ bn x = 
KL . Activation relu x x = KL . TimeDistributed 
KL . Conv2D fc _ layers _ size 1 1 
name = mrcnn _ class _ conv2 x x = 
KL . TimeDistributed BatchNorm name = mrcnn _ class _ 
bn2 x training = train _ bn x = KL 
. Activation relu x shared = KL . Lambda lambda 
x K . squeeze K . squeeze x 3 2 
name = pool _ squeeze x # batch num _ 
rois 1024 # Classifier head mrcnn _ class _ logits 
= KL . TimeDistributed KL . Dense num _ classes 
name = mrcnn _ class _ logits shared mrcnn _ 
probs = KL . TimeDistributed KL . Activation softmax name 
= mrcnn _ class mrcnn _ class _ logits # 
BBox head # batch num _ rois NUM _ CLASSES 
* dy dx log dh log dw x = KL 
. TimeDistributed KL . Dense num _ classes * 4 
activation = linear name = mrcnn _ bbox _ fc 
shared # Reshape to batch num _ rois NUM _ 
CLASSES dy dx log dh log dw s = K 
. int _ shape x # 下行 源码 K . 
reshape inputs K . shape inputs 0 + self . 
target _ shape mrcnn _ bbox = KL . Reshape 
s 1 num _ classes 4 name = mrcnn _ 
bbox x return mrcnn _ class _ logits mrcnn _ 
probs mrcnn _ bbox 返回 如下 mrcnn _ class _ 
logits         batch num _ rois NUM 
_ CLASSES       classifier logits before softmax mrcnn 
_ class                 
batch num _ rois NUM _ CLASSES       
classifier p r o b a b i l i 
t i e s m r c n n _ 
bbox deltas     batch num _ rois NUM _ 
CLASSES dy dx log dh log dw KL . TimeDistributed 
实现 建立 一 系列 同样 架构 的 的 并行 网络结构 
dim0 个 将 dim0 dim1 中的 每个 dim1 作为 输入 
并行 的 计算 输出 附 build 函数 总览 def build 
self mode config Build Mask R CNN architecture . input 
_ shape The shape of the input image . mode 
Either training or inference . The inputs and outputs of 
the model differ accordingly . assert mode in training inference 
# Image size must be dividable by 2 multiple times 
h w = config . IMAGE _ SHAPE 2 # 
1024 1024 3 if h / 2 * * 6 
= int h / 2 * * 6 or w 
/ 2 * * 6 = int w / 2 
* * 6 # 这里 就 限定 了 下 采样 
不会 产生 坐标 误差 raise Exception Image size must be 
dividable by 2 at least 6 times to avoid fractions 
when downscaling and upscaling . For example use 256 320 
384 448 512 . . . etc . # Inputs 
input _ image = KL . Input shape = None 
None config . IMAGE _ SHAPE 2 name = input 
_ image input _ image _ meta = KL . 
Input shape = config . IMAGE _ META _ SIZE 
name = input _ image _ meta if mode = 
= training # RPN GT input _ rpn _ match 
= KL . Input shape = None 1 name = 
input _ rpn _ match dtype = tf . int32 
input _ rpn _ bbox = KL . Input shape 
= None 4 name = input _ rpn _ bbox 
dtype = tf . float32 # Detection GT class IDs 
bounding boxes and masks # 1 . GT Class IDs 
zero padded input _ gt _ class _ ids = 
KL . Input shape = None name = input _ 
gt _ class _ ids dtype = tf . int32 
# 2 . GT Boxes in pixels zero padded # 
batch MAX _ GT _ INSTANCES y1 x1 y2 x2 
in image coordinates input _ gt _ boxes = KL 
. Input shape = None 4 name = input _ 
gt _ boxes dtype = tf . float32 # Normalize 
coordinates gt _ boxes = KL . Lambda lambda x 
norm _ boxes _ graph x K . shape input 
_ image 1 3 input _ gt _ boxes # 
3 . GT Masks zero padded # batch height width 
MAX _ GT _ INSTANCES if config . USE _ 
MINI _ MASK input _ gt _ masks = KL 
. Input shape = config . MINI _ MASK _ 
SHAPE 0 config . MINI _ MASK _ SHAPE 1 
None name = input _ gt _ masks dtype = 
bool else input _ gt _ masks = KL . 
Input shape = config . IMAGE _ SHAPE 0 config 
. IMAGE _ SHAPE 1 None name = input _ 
gt _ masks dtype = bool elif mode = = 
inference # Anchors in normalized coordinates input _ anchors = 
KL . Input shape = None 4 name = input 
_ anchors # Build the shared convolutional layers . # 
Bottom up Layers # Returns a list of the last 
layers of each stage 5 in total . # Don 
t create the thead stage 5 so we pick the 
4th item in the list . if callable config . 
BACKBONE _ C2 C3 C4 C5 = config . BACKBONE 
input _ image stage5 = True train _ bn = 
config . TRAIN _ BN else _ C2 C3 C4 
C5 = resnet _ graph input _ image config . 
BACKBONE stage5 = True train _ bn = config . 
TRAIN _ BN # Top down Layers # TODO add 
assert to varify feature map sizes match what s in 
config P5 = KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c5p5 C5 # 256 P4 = KL . Add 
name = fpn _ p4add KL . UpSampling2D size = 
2 2 name = fpn _ p5upsampled P5 KL . 
Conv2D config . TOP _ DOWN _ PYRAMID _ SIZE 
1 1 name = fpn _ c4p4 C4 P3 = 
KL . Add name = fpn _ p3add KL . 
UpSampling2D size = 2 2 name = fpn _ p4upsampled 
P4 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c3p3 
C3 P2 = KL . Add name = fpn _ 
p2add KL . UpSampling2D size = 2 2 name = 
fpn _ p3upsampled P3 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c2p2 C2 # Attach 3x3 conv to all 
P layers to get the final feature maps . P2 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p2 P2 P3 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p3 P3 P4 
= KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 3 3 padding = SAME name = 
fpn _ p4 P4 P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 3 3 
padding = SAME name = fpn _ p5 P5 # 
P6 is used for the 5th anchor scale in RPN 
. Generated by # subsampling from P5 with stride of 
2 . P6 = KL . MaxPooling2D pool _ size 
= 1 1 strides = 2 name = fpn _ 
p6 P5 # Note that P6 is used in RPN 
but not in the classifier heads . rpn _ feature 
_ maps = P2 P3 P4 P5 P6 mrcnn _ 
feature _ maps = P2 P3 P4 P5 # Anchors 
if mode = = training anchors = self . get 
_ anchors config . IMAGE _ SHAPE # Duplicate across 
the batch dimension because Keras requires it # TODO can 
this be optimized to avoid duplicating the anchors anchors = 
np . broadcast _ to anchors config . BATCH _ 
SIZE + anchors . shape # A hack to get 
around Keras s bad support for constants anchors = KL 
. Lambda lambda x tf . Variable anchors name = 
anchors input _ image else anchors = input _ anchors 
# RPN Model 返回 的 是 keras 的 Module 对象 
注意 keras 中的 Module 对象 是 可 call 的 rpn 
= build _ rpn _ model config . RPN _ 
ANCHOR _ STRIDE # 1 3 256 len config . 
RPN _ ANCHOR _ RATIOS config . TOP _ DOWN 
_ PYRAMID _ SIZE # Loop through pyramid layers layer 
_ outputs = # list of lists for p in 
rpn _ feature _ maps layer _ outputs . append 
rpn p # 保存 各 pyramid 特征 经过 RPN 之后 
的 结果 # Concatenate layer outputs # Convert from list 
of lists of level outputs to list of lists # 
of outputs across levels . # e . g . 
a1 b1 c1 a2 b2 c2 = a1 a2 b1 
b2 c1 c2 output _ names = rpn _ class 
_ logits rpn _ class rpn _ bbox outputs = 
list zip * layer _ outputs # logits2 6 class2 
6 bbox2 6 outputs = KL . Concatenate axis = 
1 name = n list o for o n in 
zip outputs output _ names # batch num _ anchors 
2/4 # 其中 num _ anchors 指 的 是 全部 
特征 层 上 的 anchors 总数 rpn _ class _ 
logits rpn _ class rpn _ bbox = outputs # 
Generate proposals # Proposals are batch N y1 x1 y2 
x2 in normalized coordinates # and zero padded . # 
POST _ NMS _ ROIS _ INFERENCE = 1000 # 
POST _ NMS _ ROIS _ TRAINING = 2000 proposal 
_ count = config . POST _ NMS _ ROIS 
_ TRAINING if mode = = training \ else config 
. POST _ NMS _ ROIS _ INFERENCE # IMAGES 
_ PER _ GPU num _ rois y1 x1 y2 
x2 # IMAGES _ PER _ GPU 取代 了 batch 
之后 说 的 batch 都是 IMAGES _ PER _ GPU 
rpn _ rois = ProposalLayer proposal _ count = proposal 
_ count nms _ threshold = config . RPN _ 
NMS _ THRESHOLD # 0.7 name = ROI config = 
config rpn _ class rpn _ bbox anchors if mode 
= = training # Class ID mask to mark class 
IDs supported by the dataset the image # came from 
. active _ class _ ids = KL . Lambda 
lambda x parse _ image _ meta _ graph x 
active _ class _ ids input _ image _ meta 
if not config . USE _ RPN _ ROIS # 
Ignore predicted ROIs and use ROIs provided as an input 
. input _ rois = KL . Input shape = 
config . POST _ NMS _ ROIS _ TRAINING 4 
name = input _ roi dtype = np . int32 
# Normalize coordinates target _ rois = KL . Lambda 
lambda x norm _ boxes _ graph x K . 
shape input _ image 1 3 input _ rois else 
target _ rois = rpn _ rois # Generate detection 
targets # Subsamples proposals and generates target outputs for training 
# Note that proposal class IDs gt _ boxes and 
gt _ masks are zero # padded . Equally returned 
rois and targets are zero padded . rois target _ 
class _ ids target _ bbox target _ mask = 
\ D e t e c t i o n 
T a r g e t L a y e 
r config name = proposal _ targets target _ rois 
input _ gt _ class _ ids gt _ boxes 
input _ gt _ masks # Network Heads # TODO 
verify that this handles zero padded ROIs mrcnn _ class 
_ logits mrcnn _ class mrcnn _ bbox = \ 
fpn _ classifier _ graph rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE mrcnn _ mask = build _ fpn _ 
mask _ graph rois mrcnn _ feature _ maps input 
_ image _ meta config . MASK _ POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN # TODO clean up use 
tf . identify if necessary output _ rois = KL 
. Lambda lambda x x * 1 name = output 
_ rois rois # Losses rpn _ class _ loss 
= KL . Lambda lambda x rpn _ class _ 
loss _ graph * x name = rpn _ class 
_ loss input _ rpn _ match rpn _ class 
_ logits rpn _ bbox _ loss = KL . 
Lambda lambda x rpn _ bbox _ loss _ graph 
config * x name = rpn _ bbox _ loss 
input _ rpn _ bbox input _ rpn _ match 
rpn _ bbox class _ loss = KL . Lambda 
lambda x mrcnn _ class _ loss _ graph * 
x name = mrcnn _ class _ loss target _ 
class _ ids mrcnn _ class _ logits active _ 
class _ ids bbox _ loss = KL . Lambda 
lambda x mrcnn _ bbox _ loss _ graph * 
x name = mrcnn _ bbox _ loss target _ 
bbox target _ class _ ids mrcnn _ bbox mask 
_ loss = KL . Lambda lambda x mrcnn _ 
mask _ loss _ graph * x name = mrcnn 
_ mask _ loss target _ mask target _ class 
_ ids mrcnn _ mask # Model inputs = input 
_ image input _ image _ meta input _ rpn 
_ match input _ rpn _ bbox input _ gt 
_ class _ ids input _ gt _ boxes input 
_ gt _ masks if not config . USE _ 
RPN _ ROIS inputs . append input _ rois outputs 
= rpn _ class _ logits rpn _ class rpn 
_ bbox mrcnn _ class _ logits mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois output 
_ rois rpn _ class _ loss rpn _ bbox 
_ loss class _ loss bbox _ loss mask _ 
loss model = KM . Model inputs outputs name = 
mask _ rcnn else # Network Heads # Proposal classifier 
and BBox regressor heads # output shapes # mrcnn _ 
class _ logits batch num _ rois NUM _ CLASSES 
classifier logits before softmax # mrcnn _ class batch num 
_ rois NUM _ CLASSES classifier probabilities # mrcnn _ 
bbox deltas batch num _ rois NUM _ CLASSES dy 
dx log dh log dw mrcnn _ class _ logits 
mrcnn _ class mrcnn _ bbox = \ fpn _ 
classifier _ graph rpn _ rois mrcnn _ feature _ 
maps input _ image _ meta config . POOL _ 
SIZE config . NUM _ CLASSES train _ bn = 
config . TRAIN _ BN fc _ layers _ size 
= config . FPN _ CLASSIF _ FC _ LAYERS 
_ SIZE # Detections # output is batch num _ 
detections y1 x1 y2 x2 class _ id score in 
# normalized coordinates detections = DetectionLayer config name = mrcnn 
_ detection rpn _ rois mrcnn _ class mrcnn _ 
bbox input _ image _ meta # Create masks for 
detections detection _ boxes = KL . Lambda lambda x 
x . . . 4 detections mrcnn _ mask = 
build _ fpn _ mask _ graph detection _ boxes 
mrcnn _ feature _ maps input _ image _ meta 
config . MASK _ POOL _ SIZE config . NUM 
_ CLASSES train _ bn = config . TRAIN _ 
BN model = KM . Model input _ image input 
_ image _ meta input _ anchors detections mrcnn _ 
class mrcnn _ bbox mrcnn _ mask rpn _ rois 
rpn _ class rpn _ bbox name = mask _ 
rcnn # Add multi GPU support . if config . 
GPU _ COUNT 1 from mrcnn . parallel _ model 
import ParallelModel model = ParallelModel model config . GPU _ 
COUNT return model 