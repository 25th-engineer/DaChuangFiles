Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 模型 初始化 1 创建 模型 并 载入 预 训练 
参数 准备 了 数据集 后 我们 开始 构建 model training 
网络 结构上 一节 已经 介绍 完了 现在 我们 看一看 训练 
时 如何 调用 training 结构 的 网络 如上 所示 我们 
首先 建立 图 结构 详见 上节 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 然后 选择 初始化 参数 
方案 例子 train _ shape . ipynb 中 使用 的 
是 COCO 预 训练 模型 如果 想要 Finds the last 
checkpoint file of the last trained model in themodel directory 
那么 选择 last 选项 载入 参数 方法 如下 注意 几个 
之前 接触 不多 的 操作 载入 h5 文件 使用 模块 
为 h5pykeras model 有 属性 . layers 以 list 形式 
返回 全部 的 层 对象 keras . engine 下 的 
saving 模块 load _ weights _ from _ hdf5 _ 
group _ by _ name 按照 名字 对应 而 load 
_ weights _ from _ hdf5 _ group 按照 记录 
顺序 对应 def load _ weights self filepath by _ 
name = False exclude = None Modified version of the 
corresponding Keras function with the addition of multi GPU support 
and the ability to exclude some layers from loading . 
exclude list of layer names to exclude import h5py # 
Conditional import to support versions of Keras before 2.2 # 
TODO remove in about 6 months end of 2018 try 
from keras . engine import saving except ImportError # Keras 
before 2.2 used the topology namespace . from keras . 
engine import topology as saving if exclude by _ name 
= True if h5py is None raise ImportError ` load 
_ weights ` requires h5py . f = h5py . 
File filepath mode = r if layer _ names not 
in f . attrs and model _ weights in f 
f = f model _ weights # In multi GPU 
training we wrap the model . Get layers # of 
the inner model because they have the weights . keras 
_ model = self . keras _ model layers = 
keras _ model . inner _ model . layers if 
hasattr keras _ model inner _ model \ else keras 
_ model . layers # Exclude some layers if exclude 
layers = filter lambda l l . name not in 
exclude layers if by _ name saving . load _ 
weights _ from _ hdf5 _ group _ by _ 
name f layers else saving . load _ weights _ 
from _ hdf5 _ group f layers if hasattr f 
close f . close # Update the log directory self 
. set _ log _ dir filepath 2 从 h5 
文件 一 窥 load 模式 keras model 的 层 对于 
layer 对象 我们 有 一下 几点 说明 layer . name 
查询 层 对象 的 节点 名称 layer . trainable 层 
对象 是否 可 训练 对于 TimeDistributed 对象 其 . layer 
方法 返回 对象 才 是 我们 要 设定 的 层 
对象 载入 模型 并 查看 layers 如下 查看 名称 如下 
名称 即 我们 在 build 函数 中为 每个 层 设置 
的 名称 和 TensorFlow 一样 参数 载入 依赖 于此 h5 
文件 记录 载入 h5 文件 并 查看 f . attrs 
记录 了 三个 值 第一个 为 字符串 list 后 两个 
均为 字符串 对于 layer _ names 我们 如下 尝试 其 
记录 了 各个 层 的 name 字符串 h5 记录 的 
都是 二进制 形式 需要 转码 在 keras . engine 的 
saving 方法 中 可以 看到 后 两个 记录 的 解析 
实际 测试 一个 是 keras 的 版本号 一个 会 返回 
b tensorflow if keras _ version in f . attrs 
original _ keras _ version = f . attrs keras 
_ version . decode utf8 else original _ keras _ 
version = 1 if backend in f . attrs original 
_ backend = f . attrs backend . decode utf8 
else original _ backend = None layer _ names 记录 
的 字符串 们 可以 视为 h5 文件 索引 其 索引 
对象 为子 h5 对象 子 h5 对象 有 attrs weight 
_ names 也是 字符串 list 可以 索 引子 h5 对象 
其 索 引出 的 便是 参数值 示意 如下 实际 的 
载入 参数 时 keras API 已经 封装 的 很好 了 
不 需要 我们 自己 取 对应 h5 中的 名称 和 
网络 中 的 名称 然后 更新 参数值 交由 saving . 
load _ weights _ from _ hdf5 _ group _ 
by _ name f layers 输入 f 句柄 输入 需要 
载入 参数 的 层 对象 即可 对应 名字 完成 载入 
二 模型 训练 本部 不 讲解 网络结构 主要 介绍 的 
是 训练 步骤 网络结构 介绍 见 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 模型 训练 有 两种 
模式 Only the heads . Here we re freezing all 
the backbone layers and training only the randomly initialized layers 
i . e . the ones that we didn t 
use pre trained weights from MS COCO . To train 
only the head layers pass layers = heads to the 
train function . Fine tune all layers . For this 
simple example it s not necessary but we re including 
it to show the process . Simply pass layers = 
all to train all layers . 1 train 方法 文档 
train 方法 声明 如下 def train self train _ dataset 
val _ dataset learning _ rate epochs layers augmentation = 
None custom _ callbacks = None no _ augmentation _ 
sources = None 文档 说明 如下 Train the model . 
train _ dataset val _ dataset Training and validation Dataset 
objects . learning _ rate The learning rate to train 
withepochs Number of training epochs . Note that previous training 
epochsare considered to be done alreay so this actually determinesthe 
epochs to train in total rather than in this particaularcall 
. layers Allows selecting which layers to train . It 
can be A regular expression to match layer names to 
train One of these predefined values heads The RPN classifier 
and mask heads of the networkall All the layers3 + 
Train Resnet stage 3 and up4 + Train Resnet stage 
4 and up5 + Train Resnet stage 5 and upaugmentation 
Optional . An imgaug https / / github . com 
/ aleju / imgaug augmentation . For example passing imgaug 
. augmenters . Fliplr 0.5 flips images right / left 
50% of the time . You can pass c o 
m p l e x a u g m e 
n t a t i o n s as well 
. This augmentation applies 50% of thetime and when it 
does it flips images right / left half the timeand 
adds a Gaussian blur with a random sigma in range 
0 to 5 . augmentation = imgaug . augmenters . 
Sometimes 0.5 imgaug . augmenters . Fliplr 0.5 imgaug . 
augmenters . GaussianBlur sigma = 0.0 5.0 custom _ callbacks 
Optional . Add custom callbacks to be calledwith the keras 
fit _ generator method . Must be list of type 
keras . callbacks . no _ augmentation _ sources Optional 
. List of sources to exclude foraugmentation . A source 
is string that identifies a dataset and isdefined in the 
Dataset class . 2 模型 准备 & 数据 准备 首先 
对模型 设置 进行 准备 指定 训练 层 时 既可以 输入 
层 名 层 也 可以 输入 预定 的 字符串 输入 
预定 字符串 则 其 解析 规则 见 下面 开头 几行 
最终 获取 layers 变量 记录 要 训练 层 的 名字 
或者 正则表达式 然后 准备 数据 data _ generator 函数 涉及 
预处理 流程 很 繁琐 见 model . py 可以 自行 
查阅 生成 文件 保存 目录 assert self . mode = 
= training Create model in training mode . # Pre 
defined layer regular expressions layer _ regex = { # 
all layers but the backbone heads r mrcnn \ _ 
. * | rpn \ _ . * | fpn 
\ _ . * # From a specific Resnet stage 
and up 3 + r res3 . * | bn3 
. * | res4 . * | bn4 . * 
| res5 . * | bn5 . * | mrcnn 
\ _ . * | rpn \ _ . * 
| fpn \ _ . * 4 + r res4 
. * | bn4 . * | res5 . * 
| bn5 . * | mrcnn \ _ . * 
| rpn \ _ . * | fpn \ _ 
. * 5 + r res5 . * | bn5 
. * | mrcnn \ _ . * | rpn 
\ _ . * | fpn \ _ . * 
# All layers all . * } if layers in 
layer _ regex . keys layers = layer _ regex 
layers # Data generators train _ generator = data _ 
generator train _ dataset self . config shuffle = True 
augmentation = augmentation batch _ size = self . config 
. BATCH _ SIZE no _ augmentation _ sources = 
no _ augmentation _ sources val _ generator = data 
_ generator val _ dataset self . config shuffle = 
True batch _ size = self . config . BATCH 
_ SIZE # Create log _ dir if it does 
not exist if not os . path . exists self 
. log _ dir os . makedirs self . log 
_ dir 3 model 处理 这里 主要 的 步骤 就是 
将 前 一步 的 可 训练 层 名称 传入 函数 
self . set _ trainable layers 设置 对应 层 对象 
的 trainable 属性 为 Trueself . compile 方法 设定 优 
化器 综合 各个 loss 给出 整体 优化 对象 最后 编译 
model # Callbacks callbacks = keras . callbacks . TensorBoard 
log _ dir = self . log _ dir histogram 
_ freq = 0 write _ graph = True write 
_ images = False keras . callbacks . ModelCheckpoint self 
. checkpoint _ path verbose = 0 save _ weights 
_ only = True # Add custom callbacks to the 
list if custom _ callbacks callbacks + = custom _ 
callbacks # Train log \ nStarting at epoch { } 
. LR = { } \ n . format self 
. epoch learning _ rate log Checkpoint Path { } 
. format self . checkpoint _ path self . set 
_ trainable layers self . compile learning _ rate self 
. config . LEARNING _ MOMENTUM # Work around for 
Windows Keras fails on Windows when using # multiprocessing workers 
. See discussion here # https / / github . 
com / matterport / Mask _ RCNN / issues / 
13 # issuecomment 353124009 if os . name is nt 
workers = 0 else workers = multiprocessing . cpu _ 
count # 单机 默认 为 0self . compile 方法 def 
compile self learning _ rate momentum Gets the model ready 
for training . Adds losses regularization and metrics . Then 
calls the Keras compile function . # Optimizer object optimizer 
= keras . optimizers . SGD lr = learning _ 
rate momentum = momentum clipnorm = self . config . 
GRADIENT _ CLIP _ NORM # Add Losses # First 
clear previously set losses to avoid duplication self . keras 
_ model . _ losses = self . keras _ 
model . _ per _ input _ losses = { 
} loss _ names = rpn _ class _ loss 
rpn _ bbox _ loss mrcnn _ class _ loss 
mrcnn _ bbox _ loss mrcnn _ mask _ loss 
for name in loss _ names layer = self . 
keras _ model . get _ layer name if layer 
. output in self . keras _ model . losses 
continue loss = tf . reduce _ mean layer . 
output keep _ dims = True * self . config 
. LOSS _ WEIGHTS . get name 1 . self 
. keras _ model . add _ loss loss # 
Add L2 Regularization # Skip gamma and beta weights of 
batch normalization layers . reg _ losses = keras . 
regularizers . l2 self . config . WEIGHT _ DECAY 
w / tf . cast tf . size w tf 
. float32 for w in self . keras _ model 
. trainable _ weights if gamma not in w . 
name and beta not in w . name self . 
keras _ model . add _ loss tf . add 
_ n reg _ losses # Compile self . keras 
_ model . compile optimizer = optimizer loss = None 
* len self . keras _ model . outputs # 
Add metrics for losses for name in loss _ names 
if name in self . keras _ model . metrics 
_ names continue layer = self . keras _ model 
. get _ layer name self . keras _ model 
. metrics _ names . append name loss = tf 
. reduce _ mean layer . output keepdims = True 
* self . config . LOSS _ WEIGHTS . get 
name 1 . self . keras _ model . metrics 
_ tensors . append loss self . set _ trainable 
方法 def set _ trainable self layer _ regex keras 
_ model = None indent = 0 verbose = 1 
Sets model layers as trainable if their names match the 
given regular expression . # Print message on the first 
call but not on recursive calls if verbose 0 and 
keras _ model is None log Selecting layers to train 
keras _ model = keras _ model or self . 
keras _ model # In multi GPU training we wrap 
the model . Get layers # of the inner model 
because they have the weights . layers = keras _ 
model . inner _ model . layers if hasattr keras 
_ model inner _ model \ else keras _ model 
. layers for layer in layers # Is the layer 
a model if layer . _ _ class _ _ 
. _ _ name _ _ = = Model # 
不 同层 隶属 不同 的 class 但 Model class 是 
单一 的 print In model layer . name self . 
set _ trainable layer _ regex keras _ model = 
layer indent = indent + 4 continue if not layer 
. weights continue # Is it trainable trainable = bool 
re . fullmatch layer _ regex layer . name # 
Update layer . If layer is a container update inner 
layer . if layer . _ _ class _ _ 
. _ _ name _ _ = = TimeDistributed layer 
. layer . trainable = trainable else layer . trainable 
= trainable # Print trainable layer names if trainable and 
verbose 0 log { } { 20 } { } 
. format * indent layer . name layer . _ 
_ class _ _ . _ _ name _ _ 
4 训练 model 最 简单 的 一步 了 调用 keras 
接口 训练 即可 上 一步 定义 的 callbacks 也是 在 
这里 传入 self . keras _ model . fit _ 
generator train _ generator initial _ epoch = self . 
epoch epochs = epochs steps _ per _ epoch = 
self . config . STEPS _ PER _ EPOCH callbacks 
= callbacks validation _ data = val _ generator validation 
_ steps = self . config . VALIDATION _ STEPS 
max _ queue _ size = 100 workers = workers 
use _ multiprocessing = True self . epoch = max 
self . epoch epochs 至此 train 方法 便 自动 的 
开始 了 模型 的 训练 工作 Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 模型 初始化 1 创建 模型 并 载入 预 训练 
参数 准备 了 数据集 后 我们 开始 构建 model training 
网络 结构上 一节 已经 介绍 完了 现在 我们 看一看 训练 
时 如何 调用 training 结构 的 网络 如上 所示 我们 
首先 建立 图 结构 详见 上节 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 然后 选择 初始化 参数 
方案 例子 train _ shape . ipynb 中 使用 的 
是 COCO 预 训练 模型 如果 想要 Finds the last 
checkpoint file of the last trained model in themodel directory 
那么 选择 last 选项 载入 参数 方法 如下 注意 几个 
之前 接触 不多 的 操作 载入 h5 文件 使用 模块 
为 h5pykeras model 有 属性 . layers 以 list 形式 
返回 全部 的 层 对象 keras . engine 下 的 
saving 模块 load _ weights _ from _ hdf5 _ 
group _ by _ name 按照 名字 对应 而 load 
_ weights _ from _ hdf5 _ group 按照 记录 
顺序 对应 def load _ weights self filepath by _ 
name = False exclude = None Modified version of the 
corresponding Keras function with the addition of multi GPU support 
and the ability to exclude some layers from loading . 
exclude list of layer names to exclude import h5py # 
Conditional import to support versions of Keras before 2.2 # 
TODO remove in about 6 months end of 2018 try 
from keras . engine import saving except ImportError # Keras 
before 2.2 used the topology namespace . from keras . 
engine import topology as saving if exclude by _ name 
= True if h5py is None raise ImportError ` load 
_ weights ` requires h5py . f = h5py . 
File filepath mode = r if layer _ names not 
in f . attrs and model _ weights in f 
f = f model _ weights # In multi GPU 
training we wrap the model . Get layers # of 
the inner model because they have the weights . keras 
_ model = self . keras _ model layers = 
keras _ model . inner _ model . layers if 
hasattr keras _ model inner _ model \ else keras 
_ model . layers # Exclude some layers if exclude 
layers = filter lambda l l . name not in 
exclude layers if by _ name saving . load _ 
weights _ from _ hdf5 _ group _ by _ 
name f layers else saving . load _ weights _ 
from _ hdf5 _ group f layers if hasattr f 
close f . close # Update the log directory self 
. set _ log _ dir filepath 2 从 h5 
文件 一 窥 load 模式 keras model 的 层 对于 
layer 对象 我们 有 一下 几点 说明 layer . name 
查询 层 对象 的 节点 名称 layer . trainable 层 
对象 是否 可 训练 对于 TimeDistributed 对象 其 . layer 
方法 返回 对象 才 是 我们 要 设定 的 层 
对象 载入 模型 并 查看 layers 如下 查看 名称 如下 
名称 即 我们 在 build 函数 中为 每个 层 设置 
的 名称 和 TensorFlow 一样 参数 载入 依赖 于此 h5 
文件 记录 载入 h5 文件 并 查看 f . attrs 
记录 了 三个 值 第一个 为 字符串 list 后 两个 
均为 字符串 对于 layer _ names 我们 如下 尝试 其 
记录 了 各个 层 的 name 字符串 h5 记录 的 
都是 二进制 形式 需要 转码 在 keras . engine 的 
saving 方法 中 可以 看到 后 两个 记录 的 解析 
实际 测试 一个 是 keras 的 版本号 一个 会 返回 
b tensorflow if keras _ version in f . attrs 
original _ keras _ version = f . attrs keras 
_ version . decode utf8 else original _ keras _ 
version = 1 if backend in f . attrs original 
_ backend = f . attrs backend . decode utf8 
else original _ backend = None layer _ names 记录 
的 字符串 们 可以 视为 h5 文件 索引 其 索引 
对象 为子 h5 对象 子 h5 对象 有 attrs weight 
_ names 也是 字符串 list 可以 索 引子 h5 对象 
其 索 引出 的 便是 参数值 示意 如下 实际 的 
载入 参数 时 keras API 已经 封装 的 很好 了 
不 需要 我们 自己 取 对应 h5 中的 名称 和 
网络 中 的 名称 然后 更新 参数值 交由 saving . 
load _ weights _ from _ hdf5 _ group _ 
by _ name f layers 输入 f 句柄 输入 需要 
载入 参数 的 层 对象 即可 对应 名字 完成 载入 
二 模型 训练 本部 不 讲解 网络结构 主要 介绍 的 
是 训练 步骤 网络结构 介绍 见 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 模型 训练 有 两种 
模式 Only the heads . Here we re freezing all 
the backbone layers and training only the randomly initialized layers 
i . e . the ones that we didn t 
use pre trained weights from MS COCO . To train 
only the head layers pass layers = heads to the 
train function . Fine tune all layers . For this 
simple example it s not necessary but we re including 
it to show the process . Simply pass layers = 
all to train all layers . 1 train 方法 文档 
train 方法 声明 如下 def train self train _ dataset 
val _ dataset learning _ rate epochs layers augmentation = 
None custom _ callbacks = None no _ augmentation _ 
sources = None 文档 说明 如下 Train the model . 
train _ dataset val _ dataset Training and validation Dataset 
objects . learning _ rate The learning rate to train 
withepochs Number of training epochs . Note that previous training 
epochsare considered to be done alreay so this actually determinesthe 
epochs to train in total rather than in this particaularcall 
. layers Allows selecting which layers to train . It 
can be A regular expression to match layer names to 
train One of these predefined values heads The RPN classifier 
and mask heads of the networkall All the layers3 + 
Train Resnet stage 3 and up4 + Train Resnet stage 
4 and up5 + Train Resnet stage 5 and upaugmentation 
Optional . An imgaug https / / github . com 
/ aleju / imgaug augmentation . For example passing imgaug 
. augmenters . Fliplr 0.5 flips images right / left 
50% of the time . You can pass c o 
m p l e x a u g m e 
n t a t i o n s as well 
. This augmentation applies 50% of thetime and when it 
does it flips images right / left half the timeand 
adds a Gaussian blur with a random sigma in range 
0 to 5 . augmentation = imgaug . augmenters . 
Sometimes 0.5 imgaug . augmenters . Fliplr 0.5 imgaug . 
augmenters . GaussianBlur sigma = 0.0 5.0 custom _ callbacks 
Optional . Add custom callbacks to be calledwith the keras 
fit _ generator method . Must be list of type 
keras . callbacks . no _ augmentation _ sources Optional 
. List of sources to exclude foraugmentation . A source 
is string that identifies a dataset and isdefined in the 
Dataset class . 2 模型 准备 & 数据 准备 首先 
对模型 设置 进行 准备 指定 训练 层 时 既可以 输入 
层 名 层 也 可以 输入 预定 的 字符串 输入 
预定 字符串 则 其 解析 规则 见 下面 开头 几行 
最终 获取 layers 变量 记录 要 训练 层 的 名字 
或者 正则表达式 然后 准备 数据 data _ generator 函数 涉及 
预处理 流程 很 繁琐 见 model . py 可以 自行 
查阅 生成 文件 保存 目录 assert self . mode = 
= training Create model in training mode . # Pre 
defined layer regular expressions layer _ regex = { # 
all layers but the backbone heads r mrcnn \ _ 
. * | rpn \ _ . * | fpn 
\ _ . * # From a specific Resnet stage 
and up 3 + r res3 . * | bn3 
. * | res4 . * | bn4 . * 
| res5 . * | bn5 . * | mrcnn 
\ _ . * | rpn \ _ . * 
| fpn \ _ . * 4 + r res4 
. * | bn4 . * | res5 . * 
| bn5 . * | mrcnn \ _ . * 
| rpn \ _ . * | fpn \ _ 
. * 5 + r res5 . * | bn5 
. * | mrcnn \ _ . * | rpn 
\ _ . * | fpn \ _ . * 
# All layers all . * } if layers in 
layer _ regex . keys layers = layer _ regex 
layers # Data generators train _ generator = data _ 
generator train _ dataset self . config shuffle = True 
augmentation = augmentation batch _ size = self . config 
. BATCH _ SIZE no _ augmentation _ sources = 
no _ augmentation _ sources val _ generator = data 
_ generator val _ dataset self . config shuffle = 
True batch _ size = self . config . BATCH 
_ SIZE # Create log _ dir if it does 
not exist if not os . path . exists self 
. log _ dir os . makedirs self . log 
_ dir 3 model 处理 这里 主要 的 步骤 就是 
将 前 一步 的 可 训练 层 名称 传入 函数 
self . set _ trainable layers 设置 对应 层 对象 
的 trainable 属性 为 Trueself . compile 方法 设定 优 
化器 综合 各个 loss 给出 整体 优化 对象 最后 编译 
model # Callbacks callbacks = keras . callbacks . TensorBoard 
log _ dir = self . log _ dir histogram 
_ freq = 0 write _ graph = True write 
_ images = False keras . callbacks . ModelCheckpoint self 
. checkpoint _ path verbose = 0 save _ weights 
_ only = True # Add custom callbacks to the 
list if custom _ callbacks callbacks + = custom _ 
callbacks # Train log \ nStarting at epoch { } 
. LR = { } \ n . format self 
. epoch learning _ rate log Checkpoint Path { } 
. format self . checkpoint _ path self . set 
_ trainable layers self . compile learning _ rate self 
. config . LEARNING _ MOMENTUM # Work around for 
Windows Keras fails on Windows when using # multiprocessing workers 
. See discussion here # https / / github . 
com / matterport / Mask _ RCNN / issues / 
13 # issuecomment 353124009 if os . name is nt 
workers = 0 else workers = multiprocessing . cpu _ 
count # 单机 默认 为 0self . compile 方法 def 
compile self learning _ rate momentum Gets the model ready 
for training . Adds losses regularization and metrics . Then 
calls the Keras compile function . # Optimizer object optimizer 
= keras . optimizers . SGD lr = learning _ 
rate momentum = momentum clipnorm = self . config . 
GRADIENT _ CLIP _ NORM # Add Losses # First 
clear previously set losses to avoid duplication self . keras 
_ model . _ losses = self . keras _ 
model . _ per _ input _ losses = { 
} loss _ names = rpn _ class _ loss 
rpn _ bbox _ loss mrcnn _ class _ loss 
mrcnn _ bbox _ loss mrcnn _ mask _ loss 
for name in loss _ names layer = self . 
keras _ model . get _ layer name if layer 
. output in self . keras _ model . losses 
continue loss = tf . reduce _ mean layer . 
output keep _ dims = True * self . config 
. LOSS _ WEIGHTS . get name 1 . self 
. keras _ model . add _ loss loss # 
Add L2 Regularization # Skip gamma and beta weights of 
batch normalization layers . reg _ losses = keras . 
regularizers . l2 self . config . WEIGHT _ DECAY 
w / tf . cast tf . size w tf 
. float32 for w in self . keras _ model 
. trainable _ weights if gamma not in w . 
name and beta not in w . name self . 
keras _ model . add _ loss tf . add 
_ n reg _ losses # Compile self . keras 
_ model . compile optimizer = optimizer loss = None 
* len self . keras _ model . outputs # 
Add metrics for losses for name in loss _ names 
if name in self . keras _ model . metrics 
_ names continue layer = self . keras _ model 
. get _ layer name self . keras _ model 
. metrics _ names . append name loss = tf 
. reduce _ mean layer . output keepdims = True 
* self . config . LOSS _ WEIGHTS . get 
name 1 . self . keras _ model . metrics 
_ tensors . append loss self . set _ trainable 
方法 def set _ trainable self layer _ regex keras 
_ model = None indent = 0 verbose = 1 
Sets model layers as trainable if their names match the 
given regular expression . # Print message on the first 
call but not on recursive calls if verbose 0 and 
keras _ model is None log Selecting layers to train 
keras _ model = keras _ model or self . 
keras _ model # In multi GPU training we wrap 
the model . Get layers # of the inner model 
because they have the weights . layers = keras _ 
model . inner _ model . layers if hasattr keras 
_ model inner _ model \ else keras _ model 
. layers for layer in layers # Is the layer 
a model if layer . _ _ class _ _ 
. _ _ name _ _ = = Model # 
不 同层 隶属 不同 的 class 但 Model class 是 
单一 的 print In model layer . name self . 
set _ trainable layer _ regex keras _ model = 
layer indent = indent + 4 continue if not layer 
. weights continue # Is it trainable trainable = bool 
re . fullmatch layer _ regex layer . name # 
Update layer . If layer is a container update inner 
layer . if layer . _ _ class _ _ 
. _ _ name _ _ = = TimeDistributed layer 
. layer . trainable = trainable else layer . trainable 
= trainable # Print trainable layer names if trainable and 
verbose 0 log { } { 20 } { } 
. format * indent layer . name layer . _ 
_ class _ _ . _ _ name _ _ 
4 训练 model 最 简单 的 一步 了 调用 keras 
接口 训练 即可 上 一步 定义 的 callbacks 也是 在 
这里 传入 self . keras _ model . fit _ 
generator train _ generator initial _ epoch = self . 
epoch epochs = epochs steps _ per _ epoch = 
self . config . STEPS _ PER _ EPOCH callbacks 
= callbacks validation _ data = val _ generator validation 
_ steps = self . config . VALIDATION _ STEPS 
max _ queue _ size = 100 workers = workers 
use _ multiprocessing = True self . epoch = max 
self . epoch epochs 至此 train 方法 便 自动 的 
开始 了 模型 的 训练 工作 Github 地址 Mask _ RCNN 计算机 视觉 Mask RCNN _ 
论文 学习 计算机 视觉 Mask RCNN _ 项目 文档 翻译 
计算机 视觉 Mask RCNN _ 推断 网络 其一 总览 计算机 
视觉 Mask RCNN _ 推断 网络 其二 基于 ReNet101 的 
FPN 共享 网络 计算机 视觉 Mask RCNN _ 推断 网络 
其三 RPN 锚 框 处理 和 Proposal 生成 计算机 视觉 
Mask RCNN _ 推断 网络 其四 FPN 和 ROIAlign 的 
耦合 计算机 视觉 Mask RCNN _ 推断 网络 其五 目标 
检测 结果 精炼 计算机 视觉 Mask RCNN _ 推断 网络 
其 六 Mask 生成 计算机 视觉 Mask RCNN _ 推断 
网络 终篇 使用 detect 方法 进行 推断 计算机 视觉 Mask 
RCNN _ 锚 框 生成 计算机 视觉 Mask RCNN _ 
训练 网络 其一 数据集 与 Dataset 类 计算机 视觉 Mask 
RCNN _ 训练 网络 其二 train 网络结构 & 损失 函数 
计算机 视觉 Mask RCNN _ 训练 网络 其三 训练 Model 
一 模型 初始化 1 创建 模型 并 载入 预 训练 
参数 准备 了 数据集 后 我们 开始 构建 model training 
网络 结构上 一节 已经 介绍 完了 现在 我们 看一看 训练 
时 如何 调用 training 结构 的 网络 如上 所示 我们 
首先 建立 图 结构 详见 上节 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 然后 选择 初始化 参数 
方案 例子 train _ shape . ipynb 中 使用 的 
是 COCO 预 训练 模型 如果 想要 Finds the last 
checkpoint file of the last trained model in themodel directory 
那么 选择 last 选项 载入 参数 方法 如下 注意 几个 
之前 接触 不多 的 操作 载入 h5 文件 使用 模块 
为 h5pykeras model 有 属性 . layers 以 list 形式 
返回 全部 的 层 对象 keras . engine 下 的 
saving 模块 load _ weights _ from _ hdf5 _ 
group _ by _ name 按照 名字 对应 而 load 
_ weights _ from _ hdf5 _ group 按照 记录 
顺序 对应 def load _ weights self filepath by _ 
name = False exclude = None Modified version of the 
corresponding Keras function with the addition of multi GPU support 
and the ability to exclude some layers from loading . 
exclude list of layer names to exclude import h5py # 
Conditional import to support versions of Keras before 2.2 # 
TODO remove in about 6 months end of 2018 try 
from keras . engine import saving except ImportError # Keras 
before 2.2 used the topology namespace . from keras . 
engine import topology as saving if exclude by _ name 
= True if h5py is None raise ImportError ` load 
_ weights ` requires h5py . f = h5py . 
File filepath mode = r if layer _ names not 
in f . attrs and model _ weights in f 
f = f model _ weights # In multi GPU 
training we wrap the model . Get layers # of 
the inner model because they have the weights . keras 
_ model = self . keras _ model layers = 
keras _ model . inner _ model . layers if 
hasattr keras _ model inner _ model \ else keras 
_ model . layers # Exclude some layers if exclude 
layers = filter lambda l l . name not in 
exclude layers if by _ name saving . load _ 
weights _ from _ hdf5 _ group _ by _ 
name f layers else saving . load _ weights _ 
from _ hdf5 _ group f layers if hasattr f 
close f . close # Update the log directory self 
. set _ log _ dir filepath 2 从 h5 
文件 一 窥 load 模式 keras model 的 层 对于 
layer 对象 我们 有 一下 几点 说明 layer . name 
查询 层 对象 的 节点 名称 layer . trainable 层 
对象 是否 可 训练 对于 TimeDistributed 对象 其 . layer 
方法 返回 对象 才 是 我们 要 设定 的 层 
对象 载入 模型 并 查看 layers 如下 查看 名称 如下 
名称 即 我们 在 build 函数 中为 每个 层 设置 
的 名称 和 TensorFlow 一样 参数 载入 依赖 于此 h5 
文件 记录 载入 h5 文件 并 查看 f . attrs 
记录 了 三个 值 第一个 为 字符串 list 后 两个 
均为 字符串 对于 layer _ names 我们 如下 尝试 其 
记录 了 各个 层 的 name 字符串 h5 记录 的 
都是 二进制 形式 需要 转码 在 keras . engine 的 
saving 方法 中 可以 看到 后 两个 记录 的 解析 
实际 测试 一个 是 keras 的 版本号 一个 会 返回 
b tensorflow if keras _ version in f . attrs 
original _ keras _ version = f . attrs keras 
_ version . decode utf8 else original _ keras _ 
version = 1 if backend in f . attrs original 
_ backend = f . attrs backend . decode utf8 
else original _ backend = None layer _ names 记录 
的 字符串 们 可以 视为 h5 文件 索引 其 索引 
对象 为子 h5 对象 子 h5 对象 有 attrs weight 
_ names 也是 字符串 list 可以 索 引子 h5 对象 
其 索 引出 的 便是 参数值 示意 如下 实际 的 
载入 参数 时 keras API 已经 封装 的 很好 了 
不 需要 我们 自己 取 对应 h5 中的 名称 和 
网络 中 的 名称 然后 更新 参数值 交由 saving . 
load _ weights _ from _ hdf5 _ group _ 
by _ name f layers 输入 f 句柄 输入 需要 
载入 参数 的 层 对象 即可 对应 名字 完成 载入 
二 模型 训练 本部 不 讲解 网络结构 主要 介绍 的 
是 训练 步骤 网络结构 介绍 见 计算机 视觉 Mask RCNN 
_ 训练 网络 其二 train 网络结构 模型 训练 有 两种 
模式 Only the heads . Here we re freezing all 
the backbone layers and training only the randomly initialized layers 
i . e . the ones that we didn t 
use pre trained weights from MS COCO . To train 
only the head layers pass layers = heads to the 
train function . Fine tune all layers . For this 
simple example it s not necessary but we re including 
it to show the process . Simply pass layers = 
all to train all layers . 1 train 方法 文档 
train 方法 声明 如下 def train self train _ dataset 
val _ dataset learning _ rate epochs layers augmentation = 
None custom _ callbacks = None no _ augmentation _ 
sources = None 文档 说明 如下 Train the model . 
train _ dataset val _ dataset Training and validation Dataset 
objects . learning _ rate The learning rate to train 
withepochs Number of training epochs . Note that previous training 
epochsare considered to be done alreay so this actually determinesthe 
epochs to train in total rather than in this particaularcall 
. layers Allows selecting which layers to train . It 
can be A regular expression to match layer names to 
train One of these predefined values heads The RPN classifier 
and mask heads of the networkall All the layers3 + 
Train Resnet stage 3 and up4 + Train Resnet stage 
4 and up5 + Train Resnet stage 5 and upaugmentation 
Optional . An imgaug https / / github . com 
/ aleju / imgaug augmentation . For example passing imgaug 
. augmenters . Fliplr 0.5 flips images right / left 
50% of the time . You can pass c o 
m p l e x a u g m e 
n t a t i o n s as well 
. This augmentation applies 50% of thetime and when it 
does it flips images right / left half the timeand 
adds a Gaussian blur with a random sigma in range 
0 to 5 . augmentation = imgaug . augmenters . 
Sometimes 0.5 imgaug . augmenters . Fliplr 0.5 imgaug . 
augmenters . GaussianBlur sigma = 0.0 5.0 custom _ callbacks 
Optional . Add custom callbacks to be calledwith the keras 
fit _ generator method . Must be list of type 
keras . callbacks . no _ augmentation _ sources Optional 
. List of sources to exclude foraugmentation . A source 
is string that identifies a dataset and isdefined in the 
Dataset class . 2 模型 准备 & 数据 准备 首先 
对模型 设置 进行 准备 指定 训练 层 时 既可以 输入 
层 名 层 也 可以 输入 预定 的 字符串 输入 
预定 字符串 则 其 解析 规则 见 下面 开头 几行 
最终 获取 layers 变量 记录 要 训练 层 的 名字 
或者 正则表达式 然后 准备 数据 data _ generator 函数 涉及 
预处理 流程 很 繁琐 见 model . py 可以 自行 
查阅 生成 文件 保存 目录 assert self . mode = 
= training Create model in training mode . # Pre 
defined layer regular expressions layer _ regex = { # 
all layers but the backbone heads r mrcnn \ _ 
. * | rpn \ _ . * | fpn 
\ _ . * # From a specific Resnet stage 
and up 3 + r res3 . * | bn3 
. * | res4 . * | bn4 . * 
| res5 . * | bn5 . * | mrcnn 
\ _ . * | rpn \ _ . * 
| fpn \ _ . * 4 + r res4 
. * | bn4 . * | res5 . * 
| bn5 . * | mrcnn \ _ . * 
| rpn \ _ . * | fpn \ _ 
. * 5 + r res5 . * | bn5 
. * | mrcnn \ _ . * | rpn 
\ _ . * | fpn \ _ . * 
# All layers all . * } if layers in 
layer _ regex . keys layers = layer _ regex 
layers # Data generators train _ generator = data _ 
generator train _ dataset self . config shuffle = True 
augmentation = augmentation batch _ size = self . config 
. BATCH _ SIZE no _ augmentation _ sources = 
no _ augmentation _ sources val _ generator = data 
_ generator val _ dataset self . config shuffle = 
True batch _ size = self . config . BATCH 
_ SIZE # Create log _ dir if it does 
not exist if not os . path . exists self 
. log _ dir os . makedirs self . log 
_ dir 3 model 处理 这里 主要 的 步骤 就是 
将 前 一步 的 可 训练 层 名称 传入 函数 
self . set _ trainable layers 设置 对应 层 对象 
的 trainable 属性 为 Trueself . compile 方法 设定 优 
化器 综合 各个 loss 给出 整体 优化 对象 最后 编译 
model # Callbacks callbacks = keras . callbacks . TensorBoard 
log _ dir = self . log _ dir histogram 
_ freq = 0 write _ graph = True write 
_ images = False keras . callbacks . ModelCheckpoint self 
. checkpoint _ path verbose = 0 save _ weights 
_ only = True # Add custom callbacks to the 
list if custom _ callbacks callbacks + = custom _ 
callbacks # Train log \ nStarting at epoch { } 
. LR = { } \ n . format self 
. epoch learning _ rate log Checkpoint Path { } 
. format self . checkpoint _ path self . set 
_ trainable layers self . compile learning _ rate self 
. config . LEARNING _ MOMENTUM # Work around for 
Windows Keras fails on Windows when using # multiprocessing workers 
. See discussion here # https / / github . 
com / matterport / Mask _ RCNN / issues / 
13 # issuecomment 353124009 if os . name is nt 
workers = 0 else workers = multiprocessing . cpu _ 
count # 单机 默认 为 0self . compile 方法 def 
compile self learning _ rate momentum Gets the model ready 
for training . Adds losses regularization and metrics . Then 
calls the Keras compile function . # Optimizer object optimizer 
= keras . optimizers . SGD lr = learning _ 
rate momentum = momentum clipnorm = self . config . 
GRADIENT _ CLIP _ NORM # Add Losses # First 
clear previously set losses to avoid duplication self . keras 
_ model . _ losses = self . keras _ 
model . _ per _ input _ losses = { 
} loss _ names = rpn _ class _ loss 
rpn _ bbox _ loss mrcnn _ class _ loss 
mrcnn _ bbox _ loss mrcnn _ mask _ loss 
for name in loss _ names layer = self . 
keras _ model . get _ layer name if layer 
. output in self . keras _ model . losses 
continue loss = tf . reduce _ mean layer . 
output keep _ dims = True * self . config 
. LOSS _ WEIGHTS . get name 1 . self 
. keras _ model . add _ loss loss # 
Add L2 Regularization # Skip gamma and beta weights of 
batch normalization layers . reg _ losses = keras . 
regularizers . l2 self . config . WEIGHT _ DECAY 
w / tf . cast tf . size w tf 
. float32 for w in self . keras _ model 
. trainable _ weights if gamma not in w . 
name and beta not in w . name self . 
keras _ model . add _ loss tf . add 
_ n reg _ losses # Compile self . keras 
_ model . compile optimizer = optimizer loss = None 
* len self . keras _ model . outputs # 
Add metrics for losses for name in loss _ names 
if name in self . keras _ model . metrics 
_ names continue layer = self . keras _ model 
. get _ layer name self . keras _ model 
. metrics _ names . append name loss = tf 
. reduce _ mean layer . output keepdims = True 
* self . config . LOSS _ WEIGHTS . get 
name 1 . self . keras _ model . metrics 
_ tensors . append loss self . set _ trainable 
方法 def set _ trainable self layer _ regex keras 
_ model = None indent = 0 verbose = 1 
Sets model layers as trainable if their names match the 
given regular expression . # Print message on the first 
call but not on recursive calls if verbose 0 and 
keras _ model is None log Selecting layers to train 
keras _ model = keras _ model or self . 
keras _ model # In multi GPU training we wrap 
the model . Get layers # of the inner model 
because they have the weights . layers = keras _ 
model . inner _ model . layers if hasattr keras 
_ model inner _ model \ else keras _ model 
. layers for layer in layers # Is the layer 
a model if layer . _ _ class _ _ 
. _ _ name _ _ = = Model # 
不 同层 隶属 不同 的 class 但 Model class 是 
单一 的 print In model layer . name self . 
set _ trainable layer _ regex keras _ model = 
layer indent = indent + 4 continue if not layer 
. weights continue # Is it trainable trainable = bool 
re . fullmatch layer _ regex layer . name # 
Update layer . If layer is a container update inner 
layer . if layer . _ _ class _ _ 
. _ _ name _ _ = = TimeDistributed layer 
. layer . trainable = trainable else layer . trainable 
= trainable # Print trainable layer names if trainable and 
verbose 0 log { } { 20 } { } 
. format * indent layer . name layer . _ 
_ class _ _ . _ _ name _ _ 
4 训练 model 最 简单 的 一步 了 调用 keras 
接口 训练 即可 上 一步 定义 的 callbacks 也是 在 
这里 传入 self . keras _ model . fit _ 
generator train _ generator initial _ epoch = self . 
epoch epochs = epochs steps _ per _ epoch = 
self . config . STEPS _ PER _ EPOCH callbacks 
= callbacks validation _ data = val _ generator validation 
_ steps = self . config . VALIDATION _ STEPS 
max _ queue _ size = 100 workers = workers 
use _ multiprocessing = True self . epoch = max 
self . epoch epochs 至此 train 方法 便 自动 的 
开始 了 模型 的 训练 工作 