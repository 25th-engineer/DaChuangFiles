零 参考资料 有关 FPN 的 介绍 见 计算机 视觉 FPN 
特征 金字塔 网络 网络 构架 部分 代码 见 Mask _ 
RCNN / mrcnn / model . py 中 class MaskRCNN 
的 build 方法 的 inference 分支 1 Keras 调用 GPU 
设置 * 指定 GPUimport os os . environ CUDA _ 
VISIBLE _ DEVICES = 2 * * 按需分配 import tensorflow 
as tf import keras . backend . tensorflow _ backend 
as KTF config = tf . ConfigProto config . gpu 
_ options . allow _ growth = True # 不 
全部 占满 显存 按需分配 # config . gpu _ options 
. per _ process _ gpu _ memory _ fraction 
= 0.3 # 指定 分配 30% 空间 sess = tf 
. Session config = config # 设置 session KTF . 
set _ session sess 2 TensorFlow 和 Keras 交互 说明 
下面 的 交互 方法 几乎 都是 对 keras 的 函数 
式 API 操作 的 不过 keras 的 函数 模型 转换 
为 model 对象 也 极为 方便 KM . Model input 
_ tensors output _ tensors 操作 一下 即可 * 使用 
TensorFlow 建立 keras 新的 层 对象 在 网络 中 我们 
可以 看到 大量 的 继承 了 keras . engine . 
Layer 类 的 新 类 这 是因为 如果 TensorFlow 函数 
可以 操作 keras 的 tensor 但是 其 返回 的 TensorFlow 
的 tensor 不能 被 keras 继续 处理 所以 我们 需要 
建立 新的 keras 层 进行 转换 将 tf 的 Tensor 
可 作为 keras 层 的 _ _ init _ _ 
参数 参与 层 构建 在 _ _ call _ _ 
方法 内部 使用 tf 的 函数 进行 细粒度 数据处理 最后 
返回 的 是 keras 层 对象 如果 不 想 使用 
Model 类 的 各种 方便 方法 而 执意 手动 使用 
tf . Session 训练 的话 就 没有 封装 它们 的 
必要 了 keras 的 tensor 可以 直接 送入 TensorFlow 中 
import tensorflow as tf import keras . backend as K 
rpn _ match = tf . placeholder tf . int8 
10 2 tf . where K . equal rpn _ 
match 1 一个 class 实现 例子 如下 注意 需要 推断 
输出 的 shape class PyramidROIAlign KE . Layer Implements ROI 
Pooling on multiple levels of the feature pyramid . Params 
pool _ shape pool _ height pool _ width of 
the output pooled regions . Usually 7 7 Inputs boxes 
batch num _ boxes y1 x1 y2 x2 in normalized 
coordinates . Possibly padded with zeros if not enough boxes 
to fill the array . image _ meta batch meta 
data Image details . See compose _ image _ meta 
feature _ maps List of feature maps from different levels 
of the pyramid . Each is batch height width channels 
Output Pooled regions in the shape batch num _ boxes 
pool _ height pool _ width channels . The width 
and height are those specific in the pool _ shape 
in the layer constructor . def _ _ init _ 
_ self pool _ shape * * kwargs super PyramidROIAlign 
self . _ _ init _ _ * * kwargs 
self . pool _ shape = tuple pool _ shape 
def call self inputs # num _ boxes 指 的 
是 proposal 数目 它们 均会 作用于 每张 图片 上 只是 
不同 的 proposal 作用于 图片 # 的 特征 级别 不同 
我 通过 循环 特征 层 寻找 符合 的 proposal 应用 
ROIAlign # Crop boxes batch num _ boxes y1 x1 
y2 x2 in normalized coords boxes = inputs 0 # 
Image meta # Holds details about the image . See 
compose _ image _ meta image _ meta = inputs 
1 # Feature Maps . List of feature maps from 
different level of the # feature pyramid . Each is 
batch height width channels feature _ maps = inputs 2 
# Assign each ROI to a level in the pyramid 
based on the ROI area . y1 x1 y2 x2 
= tf . split boxes 4 axis = 2 h 
= y2 y1 w = x2 x1 # Use shape 
of first image . Images in a batch must have 
the same size . image _ shape = parse _ 
image _ meta _ graph image _ meta image _ 
shape 0 # h w c # Equation 1 in 
the Feature Pyramid Networks paper . Account for # the 
fact that our coordinates are normalized here . # e 
. g . a 224x224 ROI in pixels maps to 
P4 image _ area = tf . cast image _ 
shape 0 * image _ shape 1 tf . float32 
roi _ level = log2 _ graph tf . sqrt 
h * w / 224.0 / tf . sqrt image 
_ area # h w 已经 归一化 roi _ level 
= tf . minimum 5 tf . maximum 2 4 
+ tf . cast tf . round roi _ level 
tf . int32 # 确 保值 位于 2 到 5 
之间 roi _ level = tf . squeeze roi _ 
level 2 # batch num _ boxes # Loop through 
levels and apply ROI pooling to each . P2 to 
P5 . pooled = box _ to _ level = 
for i level in enumerate range 2 6 # tf 
. where 返回值 格式 坐标 1 坐标 2 # np 
. where 返回值 格式 坐标 1 . x 坐标 2 
. x 坐标 1 . y 坐标 2 . y 
ix = tf . where tf . equal roi _ 
level level # 返回 坐标 表示 第 n 张 图片 
的 第 i 个 proposal level _ boxes = tf 
. gather _ nd boxes ix # 本 level 的 
proposal 数目 4 # Box indices for crop _ and 
_ resize . box _ indices = tf . cast 
ix 0 tf . int32 # 记录 每个 propose 对应 
图片 序号 # Keep track of which box is mapped 
to which level box _ to _ level . append 
ix # Stop gradient propogation to ROI proposals level _ 
boxes = tf . stop _ gradient level _ boxes 
box _ indices = tf . stop _ gradient box 
_ indices # Crop and Resize # From Mask R 
CNN paper We sample four regular locations so # that 
we can evaluate either max or average pooling . In 
fact # interpolating only a single value at each bin 
center without # pooling is nearly as effective . # 
# Here we use the simplified approach of a single 
value per bin # which is how it s done 
in tf . crop _ and _ resize # Result 
this _ level _ num _ boxes pool _ height 
pool _ width channels pooled . append tf . image 
. crop _ and _ resize feature _ maps i 
level _ boxes box _ indices self . pool _ 
shape method = bilinear # 输入 参数 shape # batch 
image _ height image _ width channels # this _ 
level _ num _ boxes 4 # this _ level 
_ num _ boxes # height pool _ width # 
Pack pooled features into one tensor pooled = tf . 
concat pooled axis = 0 # batch * num _ 
boxes pool _ height pool _ width channels # Pack 
box _ to _ level mapping into one array and 
add another # column representing the order of pooled boxes 
box _ to _ level = tf . concat box 
_ to _ level axis = 0 # batch * 
num _ boxes 2 box _ range = tf . 
expand _ dims tf . range tf . shape box 
_ to _ level 0 1 # batch * num 
_ boxes 1 box _ to _ level = tf 
. concat tf . cast box _ to _ level 
tf . int32 box _ range axis = 1 # 
batch * num _ boxes 3 # 截止 到 目前 
我们 获取 了 记录 全部 ROIAlign 结果 feat 集合 的 
张量 pooled 和 记录 这些 feat 相关 信息 的 张量 
box _ to _ level # 由于 提取 方法 的 
原因 此时 的 feat 并 不是 按照 原始 顺序 排序 
先按 batch 然后按 box index 排序 下面 我们 设法 将之 
恢复 顺 # 序 ROIAlign 作用于 对应 图片 的 对应 
proposal 生成 feat # Rearrange pooled features to match the 
order of the original boxes # Sort box _ to 
_ level by batch then box index # TF doesn 
t have a way to sort by two columns so 
merge them and sort . # box _ to _ 
level i 0 表示 的 是 当前 feat 隶属 的 
图片 索引 box _ to _ level i 1 表示 
的 是 其 box 序号 sorting _ tensor = box 
_ to _ level 0 * 100000 + box _ 
to _ level 1 # batch * num _ boxes 
ix = tf . nn . top _ k sorting 
_ tensor k = tf . shape box _ to 
_ level 0 . indices 1 ix = tf . 
gather box _ to _ level 2 ix pooled = 
tf . gather pooled ix # Re add the batch 
dimension # batch num _ boxes y1 x1 y2 x2 
batch * num _ boxes pool _ height pool _ 
width channels shape = tf . concat tf . shape 
boxes 2 tf . shape pooled 1 axis = 0 
pooled = tf . reshape pooled shape return pooled # 
batch num _ boxes pool _ height pool _ width 
channels def compute _ output _ shape self input _ 
shape return input _ shape 0 2 + self . 
pool _ shape + input _ shape 2 1 * 
* keras 的 Lambda 函数 可以 直接 将 TensorFlow 操作 
引入 keraskeras 的 Module 不能 接收 tf 的 tensor 作为 
数据流 所有 需要 使用 KL . Lambda 将之 转化 为 
keras 的 数据 流 如下 这样 将 tf 写好 的 
函数 输出 直接 转 换为 keras 的 Module 可以 接收 
的 类型 和 上面 的 方法 1 相比 这里 的 
lambda 接受 外部 参数 一般 位于 类 的 _ _ 
inti _ _ 中 调 整函数 行为 并不 方便 rpn 
_ bbox = KL . Lambda lambda t tf . 
reshape t tf . shape t 0 1 4 x 
* * * 继承 keras . layer 的 层 对象 
和 方法 1 相比 这种方法 同样 需要 实现 _ _ 
call _ _ 方法 不过 一般 会 super 父 类 
用于 改写 keras 已经 实现 的 层 方法 class BatchNorm 
KL . B a t c h N o r 
m a l i z a t i o n 
Extends the Keras B a t c h N o 
r m a l i z a t i o 
n class to allow a central place to make changes 
if needed . Batch normalization has a negative effect on 
training if batches are small so this layer is often 
frozen via setting in Config class and functions as linear 
layer . def call self inputs training = None Note 
about training values None Train BN layers . This is 
the normal mode False Freeze BN layers . Good when 
batch size is small True don t use . Set 
layer in training mode even when making inferences return super 
self . _ _ class _ _ self . call 
inputs training = training 一 共享 网络 概览 按照 逻辑顺序 
我们 首先 来看 处于 流程图 左上角 的 整张 图 最大 
的 组成 分支 特征提取 网络 可以 看到 本 部分 大致 
分为 以下 几个 部分 即 原图 的 三列 ResNet101 部分 
FPN 的 bottom up 部分 FPN 的 up bottom 部分 
和 横向 连接 部分 最终 特征 重构 部分 二 源码 
浏览 整个 MaskRCNN 类 初始化 之后 的 第一 个 方法 
就是 build 网络 用 的 在 mode 参数 为 inference 
情况下 下面 给 出了 正式 建立 特征提取 网络 之前 的 
class 内部 前置 代码 class MaskRCNN Encapsulates the Mask RCNN 
model functionality . The actual Keras model is in the 
keras _ model property . def _ _ init _ 
_ self mode config model _ dir mode Either training 
or inference config A Sub class of the Config class 
model _ dir Directory to save training logs and trained 
weights assert mode in training inference self . mode = 
mode self . config = config self . model _ 
dir = model _ dir self . set _ log 
_ dir self . keras _ model = self . 
build mode = mode config = config def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 raise Exception Image size must be dividable by 
2 at least 6 times to avoid fractions when downscaling 
and upscaling . # For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training elif mode = = inference # Anchors in normalized 
coordinates input _ anchors = KL . Input shape = 
None 4 name = input _ anchors 这里 强制 要求 
了 图片 裁剪 后 尺度 为 2 ^ n 且 
n = 6 保证 下 采样 后不/nr 产生 小数 整个 
程序 需要 外部 输入 的 变量 inference 模式 仅有 三个 
注意 keras 的 习惯 不同 于 placeholder 上面 代码 的 
shape 没有 包含 batch 实际 shape 是 下面 的 样式 
input _ image 输入 图片 batch None None config . 
IMAGE _ SHAPE 2 input _ image _ meta 图片 
的 信息 包含 形状 预处理 信息 等 后面 会 介绍 
batch config . IMAGE _ META _ SIZE input _ 
anchors 锚 框 batch None 4 ResNet101 部分 接 上面 
build 函数 代码 经由 如 下判断 inference 中 该 参数 
是 字符串 resnet101 所以 进入 else 分支 建立 ResNet 网络图 
# Build the shared convolutional layers . # Bottom up 
Layers # Returns a list of the last layers of 
each stage 5 in total . # Don t create 
the thead stage 5 so we pick the 4th item 
in the list . if callable config . BACKBONE _ 
C2 C3 C4 C5 = config . BACKBONE input _ 
image stage5 = True train _ bn = config . 
TRAIN _ BN else _ C2 C3 C4 C5 = 
resnet _ graph input _ image config . BACKBONE stage5 
= True train _ bn = config . TRAIN _ 
BN 上述 主 函数调用 ResNet 图 构建 代码 如下 其 
包含 应用 shortcut 和 没有 应用 shortcut 两种 子结构 图 
摘自 网上 # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # Resnet Graph # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # Code adopted from # 
https / / github . com / fchollet / deep 
learning models / blob / master / resnet50 . py 
def identity _ block input _ tensor kernel _ size 
filters stage block use _ bias = True train _ 
bn = True The identity _ block is the block 
that has no conv layer at shortcut # Arguments input 
_ tensor input tensor kernel _ size default 3 the 
kernel size of middle conv layer at main path filters 
list of integers the nb _ filters of 3 conv 
layer at main path stage integer current stage label used 
for generating layer names block a b . . . 
current block label used for generating layer names use _ 
bias Boolean . To use or not use a bias 
in conv layers . train _ bn Boolean . Train 
or freeze Batch Norm layers nb _ filter1 nb _ 
filter2 nb _ filter3 = filters conv _ name _ 
base = res + str stage + block + _ 
branch bn _ name _ base = bn + str 
stage + block + _ branch x = KL . 
Conv2D nb _ filter1 1 1 name = conv _ 
name _ base + 2a use _ bias = use 
_ bias input _ tensor x = BatchNorm name = 
bn _ name _ base + 2a x training = 
train _ bn x = KL . Activation relu x 
x = KL . Conv2D nb _ filter2 kernel _ 
size kernel _ size padding = same name = conv 
_ name _ base + 2b use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2b x training = train 
_ bn x = KL . Activation relu x x 
= KL . Conv2D nb _ filter3 1 1 name 
= conv _ name _ base + 2c use _ 
bias = use _ bias x x = BatchNorm name 
= bn _ name _ base + 2c x training 
= train _ bn x = KL . Add x 
input _ tensor x = KL . Activation relu name 
= res + str stage + block + _ out 
x return x def conv _ block input _ tensor 
kernel _ size filters stage block strides = 2 2 
use _ bias = True train _ bn = True 
conv _ block is the block that has a conv 
layer at shortcut # Arguments input _ tensor input tensor 
kernel _ size default 3 the kernel size of middle 
conv layer at main path filters list of integers the 
nb _ filters of 3 conv layer at main path 
stage integer current stage label used for generating layer names 
block a b . . . current block label used 
for generating layer names use _ bias Boolean . To 
use or not use a bias in conv layers . 
train _ bn Boolean . Train or freeze Batch Norm 
layers Note that from stage 3 the first conv layer 
at main path is with subsample = 2 2 And 
the shortcut should have subsample = 2 2 as well 
nb _ filter1 nb _ filter2 nb _ filter3 = 
filters conv _ name _ base = res + str 
stage + block + _ branch bn _ name _ 
base = bn + str stage + block + _ 
branch x = KL . Conv2D nb _ filter1 1 
1 strides = strides name = conv _ name _ 
base + 2a use _ bias = use _ bias 
input _ tensor x = BatchNorm name = bn _ 
name _ base + 2a x training = train _ 
bn x = KL . Activation relu x x = 
KL . Conv2D nb _ filter2 kernel _ size kernel 
_ size padding = same name = conv _ name 
_ base + 2b use _ bias = use _ 
bias x x = BatchNorm name = bn _ name 
_ base + 2b x training = train _ bn 
x = KL . Activation relu x x = KL 
. Conv2D nb _ filter3 1 1 name = conv 
_ name _ base + 2c use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2c x training = train 
_ bn shortcut = KL . Conv2D nb _ filter3 
1 1 strides = strides name = conv _ name 
_ base + 1 use _ bias = use _ 
bias input _ tensor shortcut = BatchNorm name = bn 
_ name _ base + 1 shortcut training = train 
_ bn x = KL . Add x shortcut x 
= KL . Activation relu name = res + str 
stage + block + _ out x return x def 
resnet _ graph input _ image architecture stage5 = False 
train _ bn = True Build a ResNet graph . 
architecture Can be resnet50 or resnet101 stage5 Boolean . If 
False stage5 of the network is not created train _ 
bn Boolean . Train or freeze Batch Norm layers assert 
architecture in resnet50 resnet101 # Stage 1 x = KL 
. ZeroPadding2D 3 3 input _ image x = KL 
. Conv2D 64 7 7 strides = 2 2 name 
= conv1 use _ bias = True x x = 
BatchNorm name = bn _ conv1 x training = train 
_ bn x = KL . Activation relu x C1 
= x = KL . MaxPooling2D 3 3 strides = 
2 2 padding = same x # Stage 2 x 
= conv _ block x 3 64 64 256 stage 
= 2 block = a strides = 1 1 train 
_ bn = train _ bn x = identity _ 
block x 3 64 64 256 stage = 2 block 
= b train _ bn = train _ bn C2 
= x = identity _ block x 3 64 64 
256 stage = 2 block = c train _ bn 
= train _ bn # Stage 3 x = conv 
_ block x 3 128 128 512 stage = 3 
block = a train _ bn = train _ bn 
x = identity _ block x 3 128 128 512 
stage = 3 block = b train _ bn = 
train _ bn x = identity _ block x 3 
128 128 512 stage = 3 block = c train 
_ bn = train _ bn C3 = x = 
identity _ block x 3 128 128 512 stage = 
3 block = d train _ bn = train _ 
bn # Stage 4 x = conv _ block x 
3 256 256 1024 stage = 4 block = a 
train _ bn = train _ bn block _ count 
= { resnet50 5 resnet101 22 } architecture for i 
in range block _ count x = identity _ block 
x 3 256 256 1024 stage = 4 block = 
chr 98 + i train _ bn = train _ 
bn C4 = x # Stage 5 if stage5 x 
= conv _ block x 3 512 512 2048 stage 
= 5 block = a train _ bn = train 
_ bn x = identity _ block x 3 512 
512 2048 stage = 5 block = b train _ 
bn = train _ bn C5 = x = identity 
_ block x 3 512 512 2048 stage = 5 
block = c train _ bn = train _ bn 
else C5 = None return C1 C2 C3 C4 C5 
BN 层 为了 可能 的 扩展 进行 了 封装 不过 
暂时 没什么 扩展 class BatchNorm KL . B a t 
c h N o r m a l i z 
a t i o n Extends the Keras B a 
t c h N o r m a l i 
z a t i o n class to allow a 
central place to make changes if needed . Batch normalization 
has a negative effect on training if batches are small 
so this layer is often frozen via setting in Config 
class and functions as linear layer . def call self 
inputs training = None Note about training values None Train 
BN layers . This is the normal mode False Freeze 
BN layers . Good when batch size is small True 
don t use . Set layer in training mode even 
when making inferences return super self . _ _ class 
_ _ self . call inputs training = training FPN 
处理 部分 接 上面 build 函数 代码 剩下 部分 比较 
简单 和 示意图 对比 几乎 平铺直叙 # Top down Layers 
# TODO add assert to varify feature map sizes match 
what s in config P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 1 1 
name = fpn _ c5p5 C5 # 256 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c4p4 
C4 P3 = KL . Add name = fpn _ 
p3add KL . UpSampling2D size = 2 2 name = 
fpn _ p4upsampled P4 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c3p3 C3 P2 = KL . Add name 
= fpn _ p2add KL . UpSampling2D size = 2 
2 name = fpn _ p3upsampled P3 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c2p2 C2 # Attach 3x3 
conv to all P layers to get the final feature 
maps . P2 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p3 P3 P4 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p4 P4 P5 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p5 P5 # P6 is used for the 5th anchor 
scale in RPN . Generated by # subsampling from P5 
with stride of 2 . P6 = KL . MaxPooling2D 
pool _ size = 1 1 strides = 2 name 
= fpn _ p6 P5 接 上面 build 函数 代码 
最后 我们 提取 的 特征 集合 如下 # Note that 
P6 is used in RPN but not in the classifier 
heads . rpn _ feature _ maps = P2 P3 
P4 P5 P6 mrcnn _ feature _ maps = P2 
P3 P4 P5 其中 rpn _ feature _ maps 对应 
图 中的 实线 输出 送入 RPN 网络 分类 / 回归 
得到 锚 框 的 前景 / 背景 鉴别 结果 而 
mrcnn _ feature _ maps 则是 后面 进行 ROI Align 
时的/nr 切割 目标 附录 build 函数 总览 def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 # 这里 就 限定 了 下 采样 不会 
产生 坐标 误差 raise Exception Image size must be dividable 
by 2 at least 6 times to avoid fractions when 
downscaling and upscaling . For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training # RPN GT input _ rpn _ match = 
KL . Input shape = None 1 name = input 
_ rpn _ match dtype = tf . int32 input 
_ rpn _ bbox = KL . Input shape = 
None 4 name = input _ rpn _ bbox dtype 
= tf . float32 # Detection GT class IDs bounding 
boxes and masks # 1 . GT Class IDs zero 
padded input _ gt _ class _ ids = KL 
. Input shape = None name = input _ gt 
_ class _ ids dtype = tf . int32 # 
2 . GT Boxes in pixels zero padded # batch 
MAX _ GT _ INSTANCES y1 x1 y2 x2 in 
image coordinates input _ gt _ boxes = KL . 
Input shape = None 4 name = input _ gt 
_ boxes dtype = tf . float32 # Normalize coordinates 
gt _ boxes = KL . Lambda lambda x norm 
_ boxes _ graph x K . shape input _ 
image 1 3 input _ gt _ boxes # 3 
. GT Masks zero padded # batch height width MAX 
_ GT _ INSTANCES if config . USE _ MINI 
_ MASK input _ gt _ masks = KL . 
Input shape = config . MINI _ MASK _ SHAPE 
0 config . MINI _ MASK _ SHAPE 1 None 
name = input _ gt _ masks dtype = bool 
else input _ gt _ masks = KL . Input 
shape = config . IMAGE _ SHAPE 0 config . 
IMAGE _ SHAPE 1 None name = input _ gt 
_ masks dtype = bool elif mode = = inference 
# Anchors in normalized coordinates input _ anchors = KL 
. Input shape = None 4 name = input _ 
anchors # Build the shared convolutional layers . # Bottom 
up Layers # Returns a list of the last layers 
of each stage 5 in total . # Don t 
create the thead stage 5 so we pick the 4th 
item in the list . if callable config . BACKBONE 
_ C2 C3 C4 C5 = config . BACKBONE input 
_ image stage5 = True train _ bn = config 
. TRAIN _ BN else _ C2 C3 C4 C5 
= resnet _ graph input _ image config . BACKBONE 
stage5 = True train _ bn = config . TRAIN 
_ BN # Top down Layers # TODO add assert 
to varify feature map sizes match what s in config 
P5 = KL . Conv2D config . TOP _ DOWN 
_ PYRAMID _ SIZE 1 1 name = fpn _ 
c5p5 C5 # 256 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c4p4 C4 P3 = KL 
. Add name = fpn _ p3add KL . UpSampling2D 
size = 2 2 name = fpn _ p4upsampled P4 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 1 1 name = fpn _ c3p3 C3 
P2 = KL . Add name = fpn _ p2add 
KL . UpSampling2D size = 2 2 name = fpn 
_ p3upsampled P3 KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c2p2 C2 # Attach 3x3 conv to all P 
layers to get the final feature maps . P2 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p2 P2 P3 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p3 P3 P4 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p4 P4 P5 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # Note that P6 is used in RPN but 
not in the classifier heads . rpn _ feature _ 
maps = P2 P3 P4 P5 P6 mrcnn _ feature 
_ maps = P2 P3 P4 P5 # Anchors if 
mode = = training anchors = self . get _ 
anchors config . IMAGE _ SHAPE # Duplicate across the 
batch dimension because Keras requires it # TODO can this 
be optimized to avoid duplicating the anchors anchors = np 
. broadcast _ to anchors config . BATCH _ SIZE 
+ anchors . shape # A hack to get around 
Keras s bad support for constants anchors = KL . 
Lambda lambda x tf . Variable anchors name = anchors 
input _ image else anchors = input _ anchors # 
RPN Model 返回 的 是 keras 的 Module 对象 注意 
keras 中的 Module 对象 是 可 call 的 rpn = 
build _ rpn _ model config . RPN _ ANCHOR 
_ STRIDE # 1 3 256 len config . RPN 
_ ANCHOR _ RATIOS config . TOP _ DOWN _ 
PYRAMID _ SIZE # Loop through pyramid layers layer _ 
outputs = # list of lists for p in rpn 
_ feature _ maps layer _ outputs . append rpn 
p # 保存 各 pyramid 特征 经过 RPN 之后 的 
结果 # Concatenate layer outputs # Convert from list of 
lists of level outputs to list of lists # of 
outputs across levels . # e . g . a1 
b1 c1 a2 b2 c2 = a1 a2 b1 b2 
c1 c2 output _ names = rpn _ class _ 
logits rpn _ class rpn _ bbox outputs = list 
zip * layer _ outputs # logits2 6 class2 6 
bbox2 6 outputs = KL . Concatenate axis = 1 
name = n list o for o n in zip 
outputs output _ names # batch num _ anchors 2/4 
# 其中 num _ anchors 指 的 是 全部 特征 
层 上 的 anchors 总数 rpn _ class _ logits 
rpn _ class rpn _ bbox = outputs # Generate 
proposals # Proposals are batch N y1 x1 y2 x2 
in normalized coordinates # and zero padded . # POST 
_ NMS _ ROIS _ INFERENCE = 1000 # POST 
_ NMS _ ROIS _ TRAINING = 2000 proposal _ 
count = config . POST _ NMS _ ROIS _ 
TRAINING if mode = = training \ else config . 
POST _ NMS _ ROIS _ INFERENCE # IMAGES _ 
PER _ GPU num _ rois y1 x1 y2 x2 
# IMAGES _ PER _ GPU 取代 了 batch 之后 
说 的 batch 都是 IMAGES _ PER _ GPU rpn 
_ rois = ProposalLayer proposal _ count = proposal _ 
count nms _ threshold = config . RPN _ NMS 
_ THRESHOLD # 0.7 name = ROI config = config 
rpn _ class rpn _ bbox anchors if mode = 
= training # Class ID mask to mark class IDs 
supported by the dataset the image # came from . 
active _ class _ ids = KL . Lambda lambda 
x parse _ image _ meta _ graph x active 
_ class _ ids input _ image _ meta if 
not config . USE _ RPN _ ROIS # Ignore 
predicted ROIs and use ROIs provided as an input . 
input _ rois = KL . Input shape = config 
. POST _ NMS _ ROIS _ TRAINING 4 name 
= input _ roi dtype = np . int32 # 
Normalize coordinates target _ rois = KL . Lambda lambda 
x norm _ boxes _ graph x K . shape 
input _ image 1 3 input _ rois else target 
_ rois = rpn _ rois # Generate detection targets 
# Subsamples proposals and generates target outputs for training # 
Note that proposal class IDs gt _ boxes and gt 
_ masks are zero # padded . Equally returned rois 
and targets are zero padded . rois target _ class 
_ ids target _ bbox target _ mask = \ 
D e t e c t i o n T 
a r g e t L a y e r 
config name = proposal _ targets target _ rois input 
_ gt _ class _ ids gt _ boxes input 
_ gt _ masks # Network Heads # TODO verify 
that this handles zero padded ROIs mrcnn _ class _ 
logits mrcnn _ class mrcnn _ bbox = \ fpn 
_ classifier _ graph rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE mrcnn _ mask = build _ fpn _ mask 
_ graph rois mrcnn _ feature _ maps input _ 
image _ meta config . MASK _ POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN # TODO clean up use tf 
. identify if necessary output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask # Model inputs = input _ 
image input _ image _ meta input _ rpn _ 
match input _ rpn _ bbox input _ gt _ 
class _ ids input _ gt _ boxes input _ 
gt _ masks if not config . USE _ RPN 
_ ROIS inputs . append input _ rois outputs = 
rpn _ class _ logits rpn _ class rpn _ 
bbox mrcnn _ class _ logits mrcnn _ class mrcnn 
_ bbox mrcnn _ mask rpn _ rois output _ 
rois rpn _ class _ loss rpn _ bbox _ 
loss class _ loss bbox _ loss mask _ loss 
model = KM . Model inputs outputs name = mask 
_ rcnn else # Network Heads # Proposal classifier and 
BBox regressor heads # output shapes # mrcnn _ class 
_ logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax # mrcnn _ class batch num _ 
rois NUM _ CLASSES classifier probabilities # mrcnn _ bbox 
deltas batch num _ rois NUM _ CLASSES dy dx 
log dh log dw mrcnn _ class _ logits mrcnn 
_ class mrcnn _ bbox = \ fpn _ classifier 
_ graph rpn _ rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE # Detections # output is batch num _ detections 
y1 x1 y2 x2 class _ id score in # 
normalized coordinates detections = DetectionLayer config name = mrcnn _ 
detection rpn _ rois mrcnn _ class mrcnn _ bbox 
input _ image _ meta # Create masks for detections 
detection _ boxes = KL . Lambda lambda x x 
. . . 4 detections mrcnn _ mask = build 
_ fpn _ mask _ graph detection _ boxes mrcnn 
_ feature _ maps input _ image _ meta config 
. MASK _ POOL _ SIZE config . NUM _ 
CLASSES train _ bn = config . TRAIN _ BN 
model = KM . Model input _ image input _ 
image _ meta input _ anchors detections mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois rpn 
_ class rpn _ bbox name = mask _ rcnn 
# Add multi GPU support . if config . GPU 
_ COUNT 1 from mrcnn . parallel _ model import 
ParallelModel model = ParallelModel model config . GPU _ COUNT 
return model 零 参考资料 有关 FPN 的 介绍 见 计算机 视觉 FPN 
特征 金字塔 网络 网络 构架 部分 代码 见 Mask _ 
RCNN / mrcnn / model . py 中 class MaskRCNN 
的 build 方法 的 inference 分支 1 Keras 调用 GPU 
设置 * 指定 GPUimport os os . environ CUDA _ 
VISIBLE _ DEVICES = 2 * * 按需分配 import tensorflow 
as tf import keras . backend . tensorflow _ backend 
as KTF config = tf . ConfigProto config . gpu 
_ options . allow _ growth = True # 不 
全部 占满 显存 按需分配 # config . gpu _ options 
. per _ process _ gpu _ memory _ fraction 
= 0.3 # 指定 分配 30% 空间 sess = tf 
. Session config = config # 设置 session KTF . 
set _ session sess 2 TensorFlow 和 Keras 交互 说明 
下面 的 交互 方法 几乎 都是 对 keras 的 函数 
式 API 操作 的 不过 keras 的 函数 模型 转换 
为 model 对象 也 极为 方便 KM . Model input 
_ tensors output _ tensors 操作 一下 即可 * 使用 
TensorFlow 建立 keras 新的 层 对象 在 网络 中 我们 
可以 看到 大量 的 继承 了 keras . engine . 
Layer 类 的 新 类 这 是因为 如果 TensorFlow 函数 
可以 操作 keras 的 tensor 但是 其 返回 的 TensorFlow 
的 tensor 不能 被 keras 继续 处理 所以 我们 需要 
建立 新的 keras 层 进行 转换 将 tf 的 Tensor 
可 作为 keras 层 的 _ _ init _ _ 
参数 参与 层 构建 在 _ _ call _ _ 
方法 内部 使用 tf 的 函数 进行 细粒度 数据处理 最后 
返回 的 是 keras 层 对象 如果 不 想 使用 
Model 类 的 各种 方便 方法 而 执意 手动 使用 
tf . Session 训练 的话 就 没有 封装 它们 的 
必要 了 keras 的 tensor 可以 直接 送入 TensorFlow 中 
import tensorflow as tf import keras . backend as K 
rpn _ match = tf . placeholder tf . int8 
10 2 tf . where K . equal rpn _ 
match 1 一个 class 实现 例子 如下 注意 需要 推断 
输出 的 shape class PyramidROIAlign KE . Layer Implements ROI 
Pooling on multiple levels of the feature pyramid . Params 
pool _ shape pool _ height pool _ width of 
the output pooled regions . Usually 7 7 Inputs boxes 
batch num _ boxes y1 x1 y2 x2 in normalized 
coordinates . Possibly padded with zeros if not enough boxes 
to fill the array . image _ meta batch meta 
data Image details . See compose _ image _ meta 
feature _ maps List of feature maps from different levels 
of the pyramid . Each is batch height width channels 
Output Pooled regions in the shape batch num _ boxes 
pool _ height pool _ width channels . The width 
and height are those specific in the pool _ shape 
in the layer constructor . def _ _ init _ 
_ self pool _ shape * * kwargs super PyramidROIAlign 
self . _ _ init _ _ * * kwargs 
self . pool _ shape = tuple pool _ shape 
def call self inputs # num _ boxes 指 的 
是 proposal 数目 它们 均会 作用于 每张 图片 上 只是 
不同 的 proposal 作用于 图片 # 的 特征 级别 不同 
我 通过 循环 特征 层 寻找 符合 的 proposal 应用 
ROIAlign # Crop boxes batch num _ boxes y1 x1 
y2 x2 in normalized coords boxes = inputs 0 # 
Image meta # Holds details about the image . See 
compose _ image _ meta image _ meta = inputs 
1 # Feature Maps . List of feature maps from 
different level of the # feature pyramid . Each is 
batch height width channels feature _ maps = inputs 2 
# Assign each ROI to a level in the pyramid 
based on the ROI area . y1 x1 y2 x2 
= tf . split boxes 4 axis = 2 h 
= y2 y1 w = x2 x1 # Use shape 
of first image . Images in a batch must have 
the same size . image _ shape = parse _ 
image _ meta _ graph image _ meta image _ 
shape 0 # h w c # Equation 1 in 
the Feature Pyramid Networks paper . Account for # the 
fact that our coordinates are normalized here . # e 
. g . a 224x224 ROI in pixels maps to 
P4 image _ area = tf . cast image _ 
shape 0 * image _ shape 1 tf . float32 
roi _ level = log2 _ graph tf . sqrt 
h * w / 224.0 / tf . sqrt image 
_ area # h w 已经 归一化 roi _ level 
= tf . minimum 5 tf . maximum 2 4 
+ tf . cast tf . round roi _ level 
tf . int32 # 确 保值 位于 2 到 5 
之间 roi _ level = tf . squeeze roi _ 
level 2 # batch num _ boxes # Loop through 
levels and apply ROI pooling to each . P2 to 
P5 . pooled = box _ to _ level = 
for i level in enumerate range 2 6 # tf 
. where 返回值 格式 坐标 1 坐标 2 # np 
. where 返回值 格式 坐标 1 . x 坐标 2 
. x 坐标 1 . y 坐标 2 . y 
ix = tf . where tf . equal roi _ 
level level # 返回 坐标 表示 第 n 张 图片 
的 第 i 个 proposal level _ boxes = tf 
. gather _ nd boxes ix # 本 level 的 
proposal 数目 4 # Box indices for crop _ and 
_ resize . box _ indices = tf . cast 
ix 0 tf . int32 # 记录 每个 propose 对应 
图片 序号 # Keep track of which box is mapped 
to which level box _ to _ level . append 
ix # Stop gradient propogation to ROI proposals level _ 
boxes = tf . stop _ gradient level _ boxes 
box _ indices = tf . stop _ gradient box 
_ indices # Crop and Resize # From Mask R 
CNN paper We sample four regular locations so # that 
we can evaluate either max or average pooling . In 
fact # interpolating only a single value at each bin 
center without # pooling is nearly as effective . # 
# Here we use the simplified approach of a single 
value per bin # which is how it s done 
in tf . crop _ and _ resize # Result 
this _ level _ num _ boxes pool _ height 
pool _ width channels pooled . append tf . image 
. crop _ and _ resize feature _ maps i 
level _ boxes box _ indices self . pool _ 
shape method = bilinear # 输入 参数 shape # batch 
image _ height image _ width channels # this _ 
level _ num _ boxes 4 # this _ level 
_ num _ boxes # height pool _ width # 
Pack pooled features into one tensor pooled = tf . 
concat pooled axis = 0 # batch * num _ 
boxes pool _ height pool _ width channels # Pack 
box _ to _ level mapping into one array and 
add another # column representing the order of pooled boxes 
box _ to _ level = tf . concat box 
_ to _ level axis = 0 # batch * 
num _ boxes 2 box _ range = tf . 
expand _ dims tf . range tf . shape box 
_ to _ level 0 1 # batch * num 
_ boxes 1 box _ to _ level = tf 
. concat tf . cast box _ to _ level 
tf . int32 box _ range axis = 1 # 
batch * num _ boxes 3 # 截止 到 目前 
我们 获取 了 记录 全部 ROIAlign 结果 feat 集合 的 
张量 pooled 和 记录 这些 feat 相关 信息 的 张量 
box _ to _ level # 由于 提取 方法 的 
原因 此时 的 feat 并 不是 按照 原始 顺序 排序 
先按 batch 然后按 box index 排序 下面 我们 设法 将之 
恢复 顺 # 序 ROIAlign 作用于 对应 图片 的 对应 
proposal 生成 feat # Rearrange pooled features to match the 
order of the original boxes # Sort box _ to 
_ level by batch then box index # TF doesn 
t have a way to sort by two columns so 
merge them and sort . # box _ to _ 
level i 0 表示 的 是 当前 feat 隶属 的 
图片 索引 box _ to _ level i 1 表示 
的 是 其 box 序号 sorting _ tensor = box 
_ to _ level 0 * 100000 + box _ 
to _ level 1 # batch * num _ boxes 
ix = tf . nn . top _ k sorting 
_ tensor k = tf . shape box _ to 
_ level 0 . indices 1 ix = tf . 
gather box _ to _ level 2 ix pooled = 
tf . gather pooled ix # Re add the batch 
dimension # batch num _ boxes y1 x1 y2 x2 
batch * num _ boxes pool _ height pool _ 
width channels shape = tf . concat tf . shape 
boxes 2 tf . shape pooled 1 axis = 0 
pooled = tf . reshape pooled shape return pooled # 
batch num _ boxes pool _ height pool _ width 
channels def compute _ output _ shape self input _ 
shape return input _ shape 0 2 + self . 
pool _ shape + input _ shape 2 1 * 
* keras 的 Lambda 函数 可以 直接 将 TensorFlow 操作 
引入 keraskeras 的 Module 不能 接收 tf 的 tensor 作为 
数据流 所有 需要 使用 KL . Lambda 将之 转化 为 
keras 的 数据 流 如下 这样 将 tf 写好 的 
函数 输出 直接 转 换为 keras 的 Module 可以 接收 
的 类型 和 上面 的 方法 1 相比 这里 的 
lambda 接受 外部 参数 一般 位于 类 的 _ _ 
inti _ _ 中 调 整函数 行为 并不 方便 rpn 
_ bbox = KL . Lambda lambda t tf . 
reshape t tf . shape t 0 1 4 x 
* * * 继承 keras . layer 的 层 对象 
和 方法 1 相比 这种方法 同样 需要 实现 _ _ 
call _ _ 方法 不过 一般 会 super 父 类 
用于 改写 keras 已经 实现 的 层 方法 class BatchNorm 
KL . B a t c h N o r 
m a l i z a t i o n 
Extends the Keras B a t c h N o 
r m a l i z a t i o 
n class to allow a central place to make changes 
if needed . Batch normalization has a negative effect on 
training if batches are small so this layer is often 
frozen via setting in Config class and functions as linear 
layer . def call self inputs training = None Note 
about training values None Train BN layers . This is 
the normal mode False Freeze BN layers . Good when 
batch size is small True don t use . Set 
layer in training mode even when making inferences return super 
self . _ _ class _ _ self . call 
inputs training = training 一 共享 网络 概览 按照 逻辑顺序 
我们 首先 来看 处于 流程图 左上角 的 整张 图 最大 
的 组成 分支 特征提取 网络 可以 看到 本 部分 大致 
分为 以下 几个 部分 即 原图 的 三列 ResNet101 部分 
FPN 的 bottom up 部分 FPN 的 up bottom 部分 
和 横向 连接 部分 最终 特征 重构 部分 二 源码 
浏览 整个 MaskRCNN 类 初始化 之后 的 第一 个 方法 
就是 build 网络 用 的 在 mode 参数 为 inference 
情况下 下面 给 出了 正式 建立 特征提取 网络 之前 的 
class 内部 前置 代码 class MaskRCNN Encapsulates the Mask RCNN 
model functionality . The actual Keras model is in the 
keras _ model property . def _ _ init _ 
_ self mode config model _ dir mode Either training 
or inference config A Sub class of the Config class 
model _ dir Directory to save training logs and trained 
weights assert mode in training inference self . mode = 
mode self . config = config self . model _ 
dir = model _ dir self . set _ log 
_ dir self . keras _ model = self . 
build mode = mode config = config def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 raise Exception Image size must be dividable by 
2 at least 6 times to avoid fractions when downscaling 
and upscaling . # For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training elif mode = = inference # Anchors in normalized 
coordinates input _ anchors = KL . Input shape = 
None 4 name = input _ anchors 这里 强制 要求 
了 图片 裁剪 后 尺度 为 2 ^ n 且 
n = 6 保证 下 采样 后不/nr 产生 小数 整个 
程序 需要 外部 输入 的 变量 inference 模式 仅有 三个 
注意 keras 的 习惯 不同 于 placeholder 上面 代码 的 
shape 没有 包含 batch 实际 shape 是 下面 的 样式 
input _ image 输入 图片 batch None None config . 
IMAGE _ SHAPE 2 input _ image _ meta 图片 
的 信息 包含 形状 预处理 信息 等 后面 会 介绍 
batch config . IMAGE _ META _ SIZE input _ 
anchors 锚 框 batch None 4 ResNet101 部分 接 上面 
build 函数 代码 经由 如 下判断 inference 中 该 参数 
是 字符串 resnet101 所以 进入 else 分支 建立 ResNet 网络图 
# Build the shared convolutional layers . # Bottom up 
Layers # Returns a list of the last layers of 
each stage 5 in total . # Don t create 
the thead stage 5 so we pick the 4th item 
in the list . if callable config . BACKBONE _ 
C2 C3 C4 C5 = config . BACKBONE input _ 
image stage5 = True train _ bn = config . 
TRAIN _ BN else _ C2 C3 C4 C5 = 
resnet _ graph input _ image config . BACKBONE stage5 
= True train _ bn = config . TRAIN _ 
BN 上述 主 函数调用 ResNet 图 构建 代码 如下 其 
包含 应用 shortcut 和 没有 应用 shortcut 两种 子结构 图 
摘自 网上 # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # Resnet Graph # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # Code adopted from # 
https / / github . com / fchollet / deep 
learning models / blob / master / resnet50 . py 
def identity _ block input _ tensor kernel _ size 
filters stage block use _ bias = True train _ 
bn = True The identity _ block is the block 
that has no conv layer at shortcut # Arguments input 
_ tensor input tensor kernel _ size default 3 the 
kernel size of middle conv layer at main path filters 
list of integers the nb _ filters of 3 conv 
layer at main path stage integer current stage label used 
for generating layer names block a b . . . 
current block label used for generating layer names use _ 
bias Boolean . To use or not use a bias 
in conv layers . train _ bn Boolean . Train 
or freeze Batch Norm layers nb _ filter1 nb _ 
filter2 nb _ filter3 = filters conv _ name _ 
base = res + str stage + block + _ 
branch bn _ name _ base = bn + str 
stage + block + _ branch x = KL . 
Conv2D nb _ filter1 1 1 name = conv _ 
name _ base + 2a use _ bias = use 
_ bias input _ tensor x = BatchNorm name = 
bn _ name _ base + 2a x training = 
train _ bn x = KL . Activation relu x 
x = KL . Conv2D nb _ filter2 kernel _ 
size kernel _ size padding = same name = conv 
_ name _ base + 2b use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2b x training = train 
_ bn x = KL . Activation relu x x 
= KL . Conv2D nb _ filter3 1 1 name 
= conv _ name _ base + 2c use _ 
bias = use _ bias x x = BatchNorm name 
= bn _ name _ base + 2c x training 
= train _ bn x = KL . Add x 
input _ tensor x = KL . Activation relu name 
= res + str stage + block + _ out 
x return x def conv _ block input _ tensor 
kernel _ size filters stage block strides = 2 2 
use _ bias = True train _ bn = True 
conv _ block is the block that has a conv 
layer at shortcut # Arguments input _ tensor input tensor 
kernel _ size default 3 the kernel size of middle 
conv layer at main path filters list of integers the 
nb _ filters of 3 conv layer at main path 
stage integer current stage label used for generating layer names 
block a b . . . current block label used 
for generating layer names use _ bias Boolean . To 
use or not use a bias in conv layers . 
train _ bn Boolean . Train or freeze Batch Norm 
layers Note that from stage 3 the first conv layer 
at main path is with subsample = 2 2 And 
the shortcut should have subsample = 2 2 as well 
nb _ filter1 nb _ filter2 nb _ filter3 = 
filters conv _ name _ base = res + str 
stage + block + _ branch bn _ name _ 
base = bn + str stage + block + _ 
branch x = KL . Conv2D nb _ filter1 1 
1 strides = strides name = conv _ name _ 
base + 2a use _ bias = use _ bias 
input _ tensor x = BatchNorm name = bn _ 
name _ base + 2a x training = train _ 
bn x = KL . Activation relu x x = 
KL . Conv2D nb _ filter2 kernel _ size kernel 
_ size padding = same name = conv _ name 
_ base + 2b use _ bias = use _ 
bias x x = BatchNorm name = bn _ name 
_ base + 2b x training = train _ bn 
x = KL . Activation relu x x = KL 
. Conv2D nb _ filter3 1 1 name = conv 
_ name _ base + 2c use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2c x training = train 
_ bn shortcut = KL . Conv2D nb _ filter3 
1 1 strides = strides name = conv _ name 
_ base + 1 use _ bias = use _ 
bias input _ tensor shortcut = BatchNorm name = bn 
_ name _ base + 1 shortcut training = train 
_ bn x = KL . Add x shortcut x 
= KL . Activation relu name = res + str 
stage + block + _ out x return x def 
resnet _ graph input _ image architecture stage5 = False 
train _ bn = True Build a ResNet graph . 
architecture Can be resnet50 or resnet101 stage5 Boolean . If 
False stage5 of the network is not created train _ 
bn Boolean . Train or freeze Batch Norm layers assert 
architecture in resnet50 resnet101 # Stage 1 x = KL 
. ZeroPadding2D 3 3 input _ image x = KL 
. Conv2D 64 7 7 strides = 2 2 name 
= conv1 use _ bias = True x x = 
BatchNorm name = bn _ conv1 x training = train 
_ bn x = KL . Activation relu x C1 
= x = KL . MaxPooling2D 3 3 strides = 
2 2 padding = same x # Stage 2 x 
= conv _ block x 3 64 64 256 stage 
= 2 block = a strides = 1 1 train 
_ bn = train _ bn x = identity _ 
block x 3 64 64 256 stage = 2 block 
= b train _ bn = train _ bn C2 
= x = identity _ block x 3 64 64 
256 stage = 2 block = c train _ bn 
= train _ bn # Stage 3 x = conv 
_ block x 3 128 128 512 stage = 3 
block = a train _ bn = train _ bn 
x = identity _ block x 3 128 128 512 
stage = 3 block = b train _ bn = 
train _ bn x = identity _ block x 3 
128 128 512 stage = 3 block = c train 
_ bn = train _ bn C3 = x = 
identity _ block x 3 128 128 512 stage = 
3 block = d train _ bn = train _ 
bn # Stage 4 x = conv _ block x 
3 256 256 1024 stage = 4 block = a 
train _ bn = train _ bn block _ count 
= { resnet50 5 resnet101 22 } architecture for i 
in range block _ count x = identity _ block 
x 3 256 256 1024 stage = 4 block = 
chr 98 + i train _ bn = train _ 
bn C4 = x # Stage 5 if stage5 x 
= conv _ block x 3 512 512 2048 stage 
= 5 block = a train _ bn = train 
_ bn x = identity _ block x 3 512 
512 2048 stage = 5 block = b train _ 
bn = train _ bn C5 = x = identity 
_ block x 3 512 512 2048 stage = 5 
block = c train _ bn = train _ bn 
else C5 = None return C1 C2 C3 C4 C5 
BN 层 为了 可能 的 扩展 进行 了 封装 不过 
暂时 没什么 扩展 class BatchNorm KL . B a t 
c h N o r m a l i z 
a t i o n Extends the Keras B a 
t c h N o r m a l i 
z a t i o n class to allow a 
central place to make changes if needed . Batch normalization 
has a negative effect on training if batches are small 
so this layer is often frozen via setting in Config 
class and functions as linear layer . def call self 
inputs training = None Note about training values None Train 
BN layers . This is the normal mode False Freeze 
BN layers . Good when batch size is small True 
don t use . Set layer in training mode even 
when making inferences return super self . _ _ class 
_ _ self . call inputs training = training FPN 
处理 部分 接 上面 build 函数 代码 剩下 部分 比较 
简单 和 示意图 对比 几乎 平铺直叙 # Top down Layers 
# TODO add assert to varify feature map sizes match 
what s in config P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 1 1 
name = fpn _ c5p5 C5 # 256 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c4p4 
C4 P3 = KL . Add name = fpn _ 
p3add KL . UpSampling2D size = 2 2 name = 
fpn _ p4upsampled P4 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c3p3 C3 P2 = KL . Add name 
= fpn _ p2add KL . UpSampling2D size = 2 
2 name = fpn _ p3upsampled P3 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c2p2 C2 # Attach 3x3 
conv to all P layers to get the final feature 
maps . P2 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p3 P3 P4 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p4 P4 P5 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p5 P5 # P6 is used for the 5th anchor 
scale in RPN . Generated by # subsampling from P5 
with stride of 2 . P6 = KL . MaxPooling2D 
pool _ size = 1 1 strides = 2 name 
= fpn _ p6 P5 接 上面 build 函数 代码 
最后 我们 提取 的 特征 集合 如下 # Note that 
P6 is used in RPN but not in the classifier 
heads . rpn _ feature _ maps = P2 P3 
P4 P5 P6 mrcnn _ feature _ maps = P2 
P3 P4 P5 其中 rpn _ feature _ maps 对应 
图 中的 实线 输出 送入 RPN 网络 分类 / 回归 
得到 锚 框 的 前景 / 背景 鉴别 结果 而 
mrcnn _ feature _ maps 则是 后面 进行 ROI Align 
时的/nr 切割 目标 附录 build 函数 总览 def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 # 这里 就 限定 了 下 采样 不会 
产生 坐标 误差 raise Exception Image size must be dividable 
by 2 at least 6 times to avoid fractions when 
downscaling and upscaling . For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training # RPN GT input _ rpn _ match = 
KL . Input shape = None 1 name = input 
_ rpn _ match dtype = tf . int32 input 
_ rpn _ bbox = KL . Input shape = 
None 4 name = input _ rpn _ bbox dtype 
= tf . float32 # Detection GT class IDs bounding 
boxes and masks # 1 . GT Class IDs zero 
padded input _ gt _ class _ ids = KL 
. Input shape = None name = input _ gt 
_ class _ ids dtype = tf . int32 # 
2 . GT Boxes in pixels zero padded # batch 
MAX _ GT _ INSTANCES y1 x1 y2 x2 in 
image coordinates input _ gt _ boxes = KL . 
Input shape = None 4 name = input _ gt 
_ boxes dtype = tf . float32 # Normalize coordinates 
gt _ boxes = KL . Lambda lambda x norm 
_ boxes _ graph x K . shape input _ 
image 1 3 input _ gt _ boxes # 3 
. GT Masks zero padded # batch height width MAX 
_ GT _ INSTANCES if config . USE _ MINI 
_ MASK input _ gt _ masks = KL . 
Input shape = config . MINI _ MASK _ SHAPE 
0 config . MINI _ MASK _ SHAPE 1 None 
name = input _ gt _ masks dtype = bool 
else input _ gt _ masks = KL . Input 
shape = config . IMAGE _ SHAPE 0 config . 
IMAGE _ SHAPE 1 None name = input _ gt 
_ masks dtype = bool elif mode = = inference 
# Anchors in normalized coordinates input _ anchors = KL 
. Input shape = None 4 name = input _ 
anchors # Build the shared convolutional layers . # Bottom 
up Layers # Returns a list of the last layers 
of each stage 5 in total . # Don t 
create the thead stage 5 so we pick the 4th 
item in the list . if callable config . BACKBONE 
_ C2 C3 C4 C5 = config . BACKBONE input 
_ image stage5 = True train _ bn = config 
. TRAIN _ BN else _ C2 C3 C4 C5 
= resnet _ graph input _ image config . BACKBONE 
stage5 = True train _ bn = config . TRAIN 
_ BN # Top down Layers # TODO add assert 
to varify feature map sizes match what s in config 
P5 = KL . Conv2D config . TOP _ DOWN 
_ PYRAMID _ SIZE 1 1 name = fpn _ 
c5p5 C5 # 256 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c4p4 C4 P3 = KL 
. Add name = fpn _ p3add KL . UpSampling2D 
size = 2 2 name = fpn _ p4upsampled P4 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 1 1 name = fpn _ c3p3 C3 
P2 = KL . Add name = fpn _ p2add 
KL . UpSampling2D size = 2 2 name = fpn 
_ p3upsampled P3 KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c2p2 C2 # Attach 3x3 conv to all P 
layers to get the final feature maps . P2 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p2 P2 P3 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p3 P3 P4 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p4 P4 P5 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # Note that P6 is used in RPN but 
not in the classifier heads . rpn _ feature _ 
maps = P2 P3 P4 P5 P6 mrcnn _ feature 
_ maps = P2 P3 P4 P5 # Anchors if 
mode = = training anchors = self . get _ 
anchors config . IMAGE _ SHAPE # Duplicate across the 
batch dimension because Keras requires it # TODO can this 
be optimized to avoid duplicating the anchors anchors = np 
. broadcast _ to anchors config . BATCH _ SIZE 
+ anchors . shape # A hack to get around 
Keras s bad support for constants anchors = KL . 
Lambda lambda x tf . Variable anchors name = anchors 
input _ image else anchors = input _ anchors # 
RPN Model 返回 的 是 keras 的 Module 对象 注意 
keras 中的 Module 对象 是 可 call 的 rpn = 
build _ rpn _ model config . RPN _ ANCHOR 
_ STRIDE # 1 3 256 len config . RPN 
_ ANCHOR _ RATIOS config . TOP _ DOWN _ 
PYRAMID _ SIZE # Loop through pyramid layers layer _ 
outputs = # list of lists for p in rpn 
_ feature _ maps layer _ outputs . append rpn 
p # 保存 各 pyramid 特征 经过 RPN 之后 的 
结果 # Concatenate layer outputs # Convert from list of 
lists of level outputs to list of lists # of 
outputs across levels . # e . g . a1 
b1 c1 a2 b2 c2 = a1 a2 b1 b2 
c1 c2 output _ names = rpn _ class _ 
logits rpn _ class rpn _ bbox outputs = list 
zip * layer _ outputs # logits2 6 class2 6 
bbox2 6 outputs = KL . Concatenate axis = 1 
name = n list o for o n in zip 
outputs output _ names # batch num _ anchors 2/4 
# 其中 num _ anchors 指 的 是 全部 特征 
层 上 的 anchors 总数 rpn _ class _ logits 
rpn _ class rpn _ bbox = outputs # Generate 
proposals # Proposals are batch N y1 x1 y2 x2 
in normalized coordinates # and zero padded . # POST 
_ NMS _ ROIS _ INFERENCE = 1000 # POST 
_ NMS _ ROIS _ TRAINING = 2000 proposal _ 
count = config . POST _ NMS _ ROIS _ 
TRAINING if mode = = training \ else config . 
POST _ NMS _ ROIS _ INFERENCE # IMAGES _ 
PER _ GPU num _ rois y1 x1 y2 x2 
# IMAGES _ PER _ GPU 取代 了 batch 之后 
说 的 batch 都是 IMAGES _ PER _ GPU rpn 
_ rois = ProposalLayer proposal _ count = proposal _ 
count nms _ threshold = config . RPN _ NMS 
_ THRESHOLD # 0.7 name = ROI config = config 
rpn _ class rpn _ bbox anchors if mode = 
= training # Class ID mask to mark class IDs 
supported by the dataset the image # came from . 
active _ class _ ids = KL . Lambda lambda 
x parse _ image _ meta _ graph x active 
_ class _ ids input _ image _ meta if 
not config . USE _ RPN _ ROIS # Ignore 
predicted ROIs and use ROIs provided as an input . 
input _ rois = KL . Input shape = config 
. POST _ NMS _ ROIS _ TRAINING 4 name 
= input _ roi dtype = np . int32 # 
Normalize coordinates target _ rois = KL . Lambda lambda 
x norm _ boxes _ graph x K . shape 
input _ image 1 3 input _ rois else target 
_ rois = rpn _ rois # Generate detection targets 
# Subsamples proposals and generates target outputs for training # 
Note that proposal class IDs gt _ boxes and gt 
_ masks are zero # padded . Equally returned rois 
and targets are zero padded . rois target _ class 
_ ids target _ bbox target _ mask = \ 
D e t e c t i o n T 
a r g e t L a y e r 
config name = proposal _ targets target _ rois input 
_ gt _ class _ ids gt _ boxes input 
_ gt _ masks # Network Heads # TODO verify 
that this handles zero padded ROIs mrcnn _ class _ 
logits mrcnn _ class mrcnn _ bbox = \ fpn 
_ classifier _ graph rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE mrcnn _ mask = build _ fpn _ mask 
_ graph rois mrcnn _ feature _ maps input _ 
image _ meta config . MASK _ POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN # TODO clean up use tf 
. identify if necessary output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask # Model inputs = input _ 
image input _ image _ meta input _ rpn _ 
match input _ rpn _ bbox input _ gt _ 
class _ ids input _ gt _ boxes input _ 
gt _ masks if not config . USE _ RPN 
_ ROIS inputs . append input _ rois outputs = 
rpn _ class _ logits rpn _ class rpn _ 
bbox mrcnn _ class _ logits mrcnn _ class mrcnn 
_ bbox mrcnn _ mask rpn _ rois output _ 
rois rpn _ class _ loss rpn _ bbox _ 
loss class _ loss bbox _ loss mask _ loss 
model = KM . Model inputs outputs name = mask 
_ rcnn else # Network Heads # Proposal classifier and 
BBox regressor heads # output shapes # mrcnn _ class 
_ logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax # mrcnn _ class batch num _ 
rois NUM _ CLASSES classifier probabilities # mrcnn _ bbox 
deltas batch num _ rois NUM _ CLASSES dy dx 
log dh log dw mrcnn _ class _ logits mrcnn 
_ class mrcnn _ bbox = \ fpn _ classifier 
_ graph rpn _ rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE # Detections # output is batch num _ detections 
y1 x1 y2 x2 class _ id score in # 
normalized coordinates detections = DetectionLayer config name = mrcnn _ 
detection rpn _ rois mrcnn _ class mrcnn _ bbox 
input _ image _ meta # Create masks for detections 
detection _ boxes = KL . Lambda lambda x x 
. . . 4 detections mrcnn _ mask = build 
_ fpn _ mask _ graph detection _ boxes mrcnn 
_ feature _ maps input _ image _ meta config 
. MASK _ POOL _ SIZE config . NUM _ 
CLASSES train _ bn = config . TRAIN _ BN 
model = KM . Model input _ image input _ 
image _ meta input _ anchors detections mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois rpn 
_ class rpn _ bbox name = mask _ rcnn 
# Add multi GPU support . if config . GPU 
_ COUNT 1 from mrcnn . parallel _ model import 
ParallelModel model = ParallelModel model config . GPU _ COUNT 
return model 零 参考资料 有关 FPN 的 介绍 见 计算机 视觉 FPN 
特征 金字塔 网络 网络 构架 部分 代码 见 Mask _ 
RCNN / mrcnn / model . py 中 class MaskRCNN 
的 build 方法 的 inference 分支 1 Keras 调用 GPU 
设置 * 指定 GPUimport os os . environ CUDA _ 
VISIBLE _ DEVICES = 2 * * 按需分配 import tensorflow 
as tf import keras . backend . tensorflow _ backend 
as KTF config = tf . ConfigProto config . gpu 
_ options . allow _ growth = True # 不 
全部 占满 显存 按需分配 # config . gpu _ options 
. per _ process _ gpu _ memory _ fraction 
= 0.3 # 指定 分配 30% 空间 sess = tf 
. Session config = config # 设置 session KTF . 
set _ session sess 2 TensorFlow 和 Keras 交互 说明 
下面 的 交互 方法 几乎 都是 对 keras 的 函数 
式 API 操作 的 不过 keras 的 函数 模型 转换 
为 model 对象 也 极为 方便 KM . Model input 
_ tensors output _ tensors 操作 一下 即可 * 使用 
TensorFlow 建立 keras 新的 层 对象 在 网络 中 我们 
可以 看到 大量 的 继承 了 keras . engine . 
Layer 类 的 新 类 这 是因为 如果 TensorFlow 函数 
可以 操作 keras 的 tensor 但是 其 返回 的 TensorFlow 
的 tensor 不能 被 keras 继续 处理 所以 我们 需要 
建立 新的 keras 层 进行 转换 将 tf 的 Tensor 
可 作为 keras 层 的 _ _ init _ _ 
参数 参与 层 构建 在 _ _ call _ _ 
方法 内部 使用 tf 的 函数 进行 细粒度 数据处理 最后 
返回 的 是 keras 层 对象 如果 不 想 使用 
Model 类 的 各种 方便 方法 而 执意 手动 使用 
tf . Session 训练 的话 就 没有 封装 它们 的 
必要 了 keras 的 tensor 可以 直接 送入 TensorFlow 中 
import tensorflow as tf import keras . backend as K 
rpn _ match = tf . placeholder tf . int8 
10 2 tf . where K . equal rpn _ 
match 1 一个 class 实现 例子 如下 注意 需要 推断 
输出 的 shape class PyramidROIAlign KE . Layer Implements ROI 
Pooling on multiple levels of the feature pyramid . Params 
pool _ shape pool _ height pool _ width of 
the output pooled regions . Usually 7 7 Inputs boxes 
batch num _ boxes y1 x1 y2 x2 in normalized 
coordinates . Possibly padded with zeros if not enough boxes 
to fill the array . image _ meta batch meta 
data Image details . See compose _ image _ meta 
feature _ maps List of feature maps from different levels 
of the pyramid . Each is batch height width channels 
Output Pooled regions in the shape batch num _ boxes 
pool _ height pool _ width channels . The width 
and height are those specific in the pool _ shape 
in the layer constructor . def _ _ init _ 
_ self pool _ shape * * kwargs super PyramidROIAlign 
self . _ _ init _ _ * * kwargs 
self . pool _ shape = tuple pool _ shape 
def call self inputs # num _ boxes 指 的 
是 proposal 数目 它们 均会 作用于 每张 图片 上 只是 
不同 的 proposal 作用于 图片 # 的 特征 级别 不同 
我 通过 循环 特征 层 寻找 符合 的 proposal 应用 
ROIAlign # Crop boxes batch num _ boxes y1 x1 
y2 x2 in normalized coords boxes = inputs 0 # 
Image meta # Holds details about the image . See 
compose _ image _ meta image _ meta = inputs 
1 # Feature Maps . List of feature maps from 
different level of the # feature pyramid . Each is 
batch height width channels feature _ maps = inputs 2 
# Assign each ROI to a level in the pyramid 
based on the ROI area . y1 x1 y2 x2 
= tf . split boxes 4 axis = 2 h 
= y2 y1 w = x2 x1 # Use shape 
of first image . Images in a batch must have 
the same size . image _ shape = parse _ 
image _ meta _ graph image _ meta image _ 
shape 0 # h w c # Equation 1 in 
the Feature Pyramid Networks paper . Account for # the 
fact that our coordinates are normalized here . # e 
. g . a 224x224 ROI in pixels maps to 
P4 image _ area = tf . cast image _ 
shape 0 * image _ shape 1 tf . float32 
roi _ level = log2 _ graph tf . sqrt 
h * w / 224.0 / tf . sqrt image 
_ area # h w 已经 归一化 roi _ level 
= tf . minimum 5 tf . maximum 2 4 
+ tf . cast tf . round roi _ level 
tf . int32 # 确 保值 位于 2 到 5 
之间 roi _ level = tf . squeeze roi _ 
level 2 # batch num _ boxes # Loop through 
levels and apply ROI pooling to each . P2 to 
P5 . pooled = box _ to _ level = 
for i level in enumerate range 2 6 # tf 
. where 返回值 格式 坐标 1 坐标 2 # np 
. where 返回值 格式 坐标 1 . x 坐标 2 
. x 坐标 1 . y 坐标 2 . y 
ix = tf . where tf . equal roi _ 
level level # 返回 坐标 表示 第 n 张 图片 
的 第 i 个 proposal level _ boxes = tf 
. gather _ nd boxes ix # 本 level 的 
proposal 数目 4 # Box indices for crop _ and 
_ resize . box _ indices = tf . cast 
ix 0 tf . int32 # 记录 每个 propose 对应 
图片 序号 # Keep track of which box is mapped 
to which level box _ to _ level . append 
ix # Stop gradient propogation to ROI proposals level _ 
boxes = tf . stop _ gradient level _ boxes 
box _ indices = tf . stop _ gradient box 
_ indices # Crop and Resize # From Mask R 
CNN paper We sample four regular locations so # that 
we can evaluate either max or average pooling . In 
fact # interpolating only a single value at each bin 
center without # pooling is nearly as effective . # 
# Here we use the simplified approach of a single 
value per bin # which is how it s done 
in tf . crop _ and _ resize # Result 
this _ level _ num _ boxes pool _ height 
pool _ width channels pooled . append tf . image 
. crop _ and _ resize feature _ maps i 
level _ boxes box _ indices self . pool _ 
shape method = bilinear # 输入 参数 shape # batch 
image _ height image _ width channels # this _ 
level _ num _ boxes 4 # this _ level 
_ num _ boxes # height pool _ width # 
Pack pooled features into one tensor pooled = tf . 
concat pooled axis = 0 # batch * num _ 
boxes pool _ height pool _ width channels # Pack 
box _ to _ level mapping into one array and 
add another # column representing the order of pooled boxes 
box _ to _ level = tf . concat box 
_ to _ level axis = 0 # batch * 
num _ boxes 2 box _ range = tf . 
expand _ dims tf . range tf . shape box 
_ to _ level 0 1 # batch * num 
_ boxes 1 box _ to _ level = tf 
. concat tf . cast box _ to _ level 
tf . int32 box _ range axis = 1 # 
batch * num _ boxes 3 # 截止 到 目前 
我们 获取 了 记录 全部 ROIAlign 结果 feat 集合 的 
张量 pooled 和 记录 这些 feat 相关 信息 的 张量 
box _ to _ level # 由于 提取 方法 的 
原因 此时 的 feat 并 不是 按照 原始 顺序 排序 
先按 batch 然后按 box index 排序 下面 我们 设法 将之 
恢复 顺 # 序 ROIAlign 作用于 对应 图片 的 对应 
proposal 生成 feat # Rearrange pooled features to match the 
order of the original boxes # Sort box _ to 
_ level by batch then box index # TF doesn 
t have a way to sort by two columns so 
merge them and sort . # box _ to _ 
level i 0 表示 的 是 当前 feat 隶属 的 
图片 索引 box _ to _ level i 1 表示 
的 是 其 box 序号 sorting _ tensor = box 
_ to _ level 0 * 100000 + box _ 
to _ level 1 # batch * num _ boxes 
ix = tf . nn . top _ k sorting 
_ tensor k = tf . shape box _ to 
_ level 0 . indices 1 ix = tf . 
gather box _ to _ level 2 ix pooled = 
tf . gather pooled ix # Re add the batch 
dimension # batch num _ boxes y1 x1 y2 x2 
batch * num _ boxes pool _ height pool _ 
width channels shape = tf . concat tf . shape 
boxes 2 tf . shape pooled 1 axis = 0 
pooled = tf . reshape pooled shape return pooled # 
batch num _ boxes pool _ height pool _ width 
channels def compute _ output _ shape self input _ 
shape return input _ shape 0 2 + self . 
pool _ shape + input _ shape 2 1 * 
* keras 的 Lambda 函数 可以 直接 将 TensorFlow 操作 
引入 keraskeras 的 Module 不能 接收 tf 的 tensor 作为 
数据流 所有 需要 使用 KL . Lambda 将之 转化 为 
keras 的 数据 流 如下 这样 将 tf 写好 的 
函数 输出 直接 转 换为 keras 的 Module 可以 接收 
的 类型 和 上面 的 方法 1 相比 这里 的 
lambda 接受 外部 参数 一般 位于 类 的 _ _ 
inti _ _ 中 调 整函数 行为 并不 方便 rpn 
_ bbox = KL . Lambda lambda t tf . 
reshape t tf . shape t 0 1 4 x 
* * * 继承 keras . layer 的 层 对象 
和 方法 1 相比 这种方法 同样 需要 实现 _ _ 
call _ _ 方法 不过 一般 会 super 父 类 
用于 改写 keras 已经 实现 的 层 方法 class BatchNorm 
KL . B a t c h N o r 
m a l i z a t i o n 
Extends the Keras B a t c h N o 
r m a l i z a t i o 
n class to allow a central place to make changes 
if needed . Batch normalization has a negative effect on 
training if batches are small so this layer is often 
frozen via setting in Config class and functions as linear 
layer . def call self inputs training = None Note 
about training values None Train BN layers . This is 
the normal mode False Freeze BN layers . Good when 
batch size is small True don t use . Set 
layer in training mode even when making inferences return super 
self . _ _ class _ _ self . call 
inputs training = training 一 共享 网络 概览 按照 逻辑顺序 
我们 首先 来看 处于 流程图 左上角 的 整张 图 最大 
的 组成 分支 特征提取 网络 可以 看到 本 部分 大致 
分为 以下 几个 部分 即 原图 的 三列 ResNet101 部分 
FPN 的 bottom up 部分 FPN 的 up bottom 部分 
和 横向 连接 部分 最终 特征 重构 部分 二 源码 
浏览 整个 MaskRCNN 类 初始化 之后 的 第一 个 方法 
就是 build 网络 用 的 在 mode 参数 为 inference 
情况下 下面 给 出了 正式 建立 特征提取 网络 之前 的 
class 内部 前置 代码 class MaskRCNN Encapsulates the Mask RCNN 
model functionality . The actual Keras model is in the 
keras _ model property . def _ _ init _ 
_ self mode config model _ dir mode Either training 
or inference config A Sub class of the Config class 
model _ dir Directory to save training logs and trained 
weights assert mode in training inference self . mode = 
mode self . config = config self . model _ 
dir = model _ dir self . set _ log 
_ dir self . keras _ model = self . 
build mode = mode config = config def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 raise Exception Image size must be dividable by 
2 at least 6 times to avoid fractions when downscaling 
and upscaling . # For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training elif mode = = inference # Anchors in normalized 
coordinates input _ anchors = KL . Input shape = 
None 4 name = input _ anchors 这里 强制 要求 
了 图片 裁剪 后 尺度 为 2 ^ n 且 
n = 6 保证 下 采样 后不/nr 产生 小数 整个 
程序 需要 外部 输入 的 变量 inference 模式 仅有 三个 
注意 keras 的 习惯 不同 于 placeholder 上面 代码 的 
shape 没有 包含 batch 实际 shape 是 下面 的 样式 
input _ image 输入 图片 batch None None config . 
IMAGE _ SHAPE 2 input _ image _ meta 图片 
的 信息 包含 形状 预处理 信息 等 后面 会 介绍 
batch config . IMAGE _ META _ SIZE input _ 
anchors 锚 框 batch None 4 ResNet101 部分 接 上面 
build 函数 代码 经由 如 下判断 inference 中 该 参数 
是 字符串 resnet101 所以 进入 else 分支 建立 ResNet 网络图 
# Build the shared convolutional layers . # Bottom up 
Layers # Returns a list of the last layers of 
each stage 5 in total . # Don t create 
the thead stage 5 so we pick the 4th item 
in the list . if callable config . BACKBONE _ 
C2 C3 C4 C5 = config . BACKBONE input _ 
image stage5 = True train _ bn = config . 
TRAIN _ BN else _ C2 C3 C4 C5 = 
resnet _ graph input _ image config . BACKBONE stage5 
= True train _ bn = config . TRAIN _ 
BN 上述 主 函数调用 ResNet 图 构建 代码 如下 其 
包含 应用 shortcut 和 没有 应用 shortcut 两种 子结构 图 
摘自 网上 # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # Resnet Graph # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # # # # # 
# # # # # # Code adopted from # 
https / / github . com / fchollet / deep 
learning models / blob / master / resnet50 . py 
def identity _ block input _ tensor kernel _ size 
filters stage block use _ bias = True train _ 
bn = True The identity _ block is the block 
that has no conv layer at shortcut # Arguments input 
_ tensor input tensor kernel _ size default 3 the 
kernel size of middle conv layer at main path filters 
list of integers the nb _ filters of 3 conv 
layer at main path stage integer current stage label used 
for generating layer names block a b . . . 
current block label used for generating layer names use _ 
bias Boolean . To use or not use a bias 
in conv layers . train _ bn Boolean . Train 
or freeze Batch Norm layers nb _ filter1 nb _ 
filter2 nb _ filter3 = filters conv _ name _ 
base = res + str stage + block + _ 
branch bn _ name _ base = bn + str 
stage + block + _ branch x = KL . 
Conv2D nb _ filter1 1 1 name = conv _ 
name _ base + 2a use _ bias = use 
_ bias input _ tensor x = BatchNorm name = 
bn _ name _ base + 2a x training = 
train _ bn x = KL . Activation relu x 
x = KL . Conv2D nb _ filter2 kernel _ 
size kernel _ size padding = same name = conv 
_ name _ base + 2b use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2b x training = train 
_ bn x = KL . Activation relu x x 
= KL . Conv2D nb _ filter3 1 1 name 
= conv _ name _ base + 2c use _ 
bias = use _ bias x x = BatchNorm name 
= bn _ name _ base + 2c x training 
= train _ bn x = KL . Add x 
input _ tensor x = KL . Activation relu name 
= res + str stage + block + _ out 
x return x def conv _ block input _ tensor 
kernel _ size filters stage block strides = 2 2 
use _ bias = True train _ bn = True 
conv _ block is the block that has a conv 
layer at shortcut # Arguments input _ tensor input tensor 
kernel _ size default 3 the kernel size of middle 
conv layer at main path filters list of integers the 
nb _ filters of 3 conv layer at main path 
stage integer current stage label used for generating layer names 
block a b . . . current block label used 
for generating layer names use _ bias Boolean . To 
use or not use a bias in conv layers . 
train _ bn Boolean . Train or freeze Batch Norm 
layers Note that from stage 3 the first conv layer 
at main path is with subsample = 2 2 And 
the shortcut should have subsample = 2 2 as well 
nb _ filter1 nb _ filter2 nb _ filter3 = 
filters conv _ name _ base = res + str 
stage + block + _ branch bn _ name _ 
base = bn + str stage + block + _ 
branch x = KL . Conv2D nb _ filter1 1 
1 strides = strides name = conv _ name _ 
base + 2a use _ bias = use _ bias 
input _ tensor x = BatchNorm name = bn _ 
name _ base + 2a x training = train _ 
bn x = KL . Activation relu x x = 
KL . Conv2D nb _ filter2 kernel _ size kernel 
_ size padding = same name = conv _ name 
_ base + 2b use _ bias = use _ 
bias x x = BatchNorm name = bn _ name 
_ base + 2b x training = train _ bn 
x = KL . Activation relu x x = KL 
. Conv2D nb _ filter3 1 1 name = conv 
_ name _ base + 2c use _ bias = 
use _ bias x x = BatchNorm name = bn 
_ name _ base + 2c x training = train 
_ bn shortcut = KL . Conv2D nb _ filter3 
1 1 strides = strides name = conv _ name 
_ base + 1 use _ bias = use _ 
bias input _ tensor shortcut = BatchNorm name = bn 
_ name _ base + 1 shortcut training = train 
_ bn x = KL . Add x shortcut x 
= KL . Activation relu name = res + str 
stage + block + _ out x return x def 
resnet _ graph input _ image architecture stage5 = False 
train _ bn = True Build a ResNet graph . 
architecture Can be resnet50 or resnet101 stage5 Boolean . If 
False stage5 of the network is not created train _ 
bn Boolean . Train or freeze Batch Norm layers assert 
architecture in resnet50 resnet101 # Stage 1 x = KL 
. ZeroPadding2D 3 3 input _ image x = KL 
. Conv2D 64 7 7 strides = 2 2 name 
= conv1 use _ bias = True x x = 
BatchNorm name = bn _ conv1 x training = train 
_ bn x = KL . Activation relu x C1 
= x = KL . MaxPooling2D 3 3 strides = 
2 2 padding = same x # Stage 2 x 
= conv _ block x 3 64 64 256 stage 
= 2 block = a strides = 1 1 train 
_ bn = train _ bn x = identity _ 
block x 3 64 64 256 stage = 2 block 
= b train _ bn = train _ bn C2 
= x = identity _ block x 3 64 64 
256 stage = 2 block = c train _ bn 
= train _ bn # Stage 3 x = conv 
_ block x 3 128 128 512 stage = 3 
block = a train _ bn = train _ bn 
x = identity _ block x 3 128 128 512 
stage = 3 block = b train _ bn = 
train _ bn x = identity _ block x 3 
128 128 512 stage = 3 block = c train 
_ bn = train _ bn C3 = x = 
identity _ block x 3 128 128 512 stage = 
3 block = d train _ bn = train _ 
bn # Stage 4 x = conv _ block x 
3 256 256 1024 stage = 4 block = a 
train _ bn = train _ bn block _ count 
= { resnet50 5 resnet101 22 } architecture for i 
in range block _ count x = identity _ block 
x 3 256 256 1024 stage = 4 block = 
chr 98 + i train _ bn = train _ 
bn C4 = x # Stage 5 if stage5 x 
= conv _ block x 3 512 512 2048 stage 
= 5 block = a train _ bn = train 
_ bn x = identity _ block x 3 512 
512 2048 stage = 5 block = b train _ 
bn = train _ bn C5 = x = identity 
_ block x 3 512 512 2048 stage = 5 
block = c train _ bn = train _ bn 
else C5 = None return C1 C2 C3 C4 C5 
BN 层 为了 可能 的 扩展 进行 了 封装 不过 
暂时 没什么 扩展 class BatchNorm KL . B a t 
c h N o r m a l i z 
a t i o n Extends the Keras B a 
t c h N o r m a l i 
z a t i o n class to allow a 
central place to make changes if needed . Batch normalization 
has a negative effect on training if batches are small 
so this layer is often frozen via setting in Config 
class and functions as linear layer . def call self 
inputs training = None Note about training values None Train 
BN layers . This is the normal mode False Freeze 
BN layers . Good when batch size is small True 
don t use . Set layer in training mode even 
when making inferences return super self . _ _ class 
_ _ self . call inputs training = training FPN 
处理 部分 接 上面 build 函数 代码 剩下 部分 比较 
简单 和 示意图 对比 几乎 平铺直叙 # Top down Layers 
# TODO add assert to varify feature map sizes match 
what s in config P5 = KL . Conv2D config 
. TOP _ DOWN _ PYRAMID _ SIZE 1 1 
name = fpn _ c5p5 C5 # 256 P4 = 
KL . Add name = fpn _ p4add KL . 
UpSampling2D size = 2 2 name = fpn _ p5upsampled 
P5 KL . Conv2D config . TOP _ DOWN _ 
PYRAMID _ SIZE 1 1 name = fpn _ c4p4 
C4 P3 = KL . Add name = fpn _ 
p3add KL . UpSampling2D size = 2 2 name = 
fpn _ p4upsampled P4 KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 1 1 name = 
fpn _ c3p3 C3 P2 = KL . Add name 
= fpn _ p2add KL . UpSampling2D size = 2 
2 name = fpn _ p3upsampled P3 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c2p2 C2 # Attach 3x3 
conv to all P layers to get the final feature 
maps . P2 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p2 P2 P3 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p3 P3 P4 = KL . Conv2D config . TOP 
_ DOWN _ PYRAMID _ SIZE 3 3 padding = 
SAME name = fpn _ p4 P4 P5 = KL 
. Conv2D config . TOP _ DOWN _ PYRAMID _ 
SIZE 3 3 padding = SAME name = fpn _ 
p5 P5 # P6 is used for the 5th anchor 
scale in RPN . Generated by # subsampling from P5 
with stride of 2 . P6 = KL . MaxPooling2D 
pool _ size = 1 1 strides = 2 name 
= fpn _ p6 P5 接 上面 build 函数 代码 
最后 我们 提取 的 特征 集合 如下 # Note that 
P6 is used in RPN but not in the classifier 
heads . rpn _ feature _ maps = P2 P3 
P4 P5 P6 mrcnn _ feature _ maps = P2 
P3 P4 P5 其中 rpn _ feature _ maps 对应 
图 中的 实线 输出 送入 RPN 网络 分类 / 回归 
得到 锚 框 的 前景 / 背景 鉴别 结果 而 
mrcnn _ feature _ maps 则是 后面 进行 ROI Align 
时的/nr 切割 目标 附录 build 函数 总览 def build self 
mode config Build Mask R CNN architecture . input _ 
shape The shape of the input image . mode Either 
training or inference . The inputs and outputs of the 
model differ accordingly . assert mode in training inference # 
Image size must be dividable by 2 multiple times h 
w = config . IMAGE _ SHAPE 2 # 1024 
1024 3 if h / 2 * * 6 = 
int h / 2 * * 6 or w / 
2 * * 6 = int w / 2 * 
* 6 # 这里 就 限定 了 下 采样 不会 
产生 坐标 误差 raise Exception Image size must be dividable 
by 2 at least 6 times to avoid fractions when 
downscaling and upscaling . For example use 256 320 384 
448 512 . . . etc . # Inputs input 
_ image = KL . Input shape = None None 
config . IMAGE _ SHAPE 2 name = input _ 
image input _ image _ meta = KL . Input 
shape = config . IMAGE _ META _ SIZE name 
= input _ image _ meta if mode = = 
training # RPN GT input _ rpn _ match = 
KL . Input shape = None 1 name = input 
_ rpn _ match dtype = tf . int32 input 
_ rpn _ bbox = KL . Input shape = 
None 4 name = input _ rpn _ bbox dtype 
= tf . float32 # Detection GT class IDs bounding 
boxes and masks # 1 . GT Class IDs zero 
padded input _ gt _ class _ ids = KL 
. Input shape = None name = input _ gt 
_ class _ ids dtype = tf . int32 # 
2 . GT Boxes in pixels zero padded # batch 
MAX _ GT _ INSTANCES y1 x1 y2 x2 in 
image coordinates input _ gt _ boxes = KL . 
Input shape = None 4 name = input _ gt 
_ boxes dtype = tf . float32 # Normalize coordinates 
gt _ boxes = KL . Lambda lambda x norm 
_ boxes _ graph x K . shape input _ 
image 1 3 input _ gt _ boxes # 3 
. GT Masks zero padded # batch height width MAX 
_ GT _ INSTANCES if config . USE _ MINI 
_ MASK input _ gt _ masks = KL . 
Input shape = config . MINI _ MASK _ SHAPE 
0 config . MINI _ MASK _ SHAPE 1 None 
name = input _ gt _ masks dtype = bool 
else input _ gt _ masks = KL . Input 
shape = config . IMAGE _ SHAPE 0 config . 
IMAGE _ SHAPE 1 None name = input _ gt 
_ masks dtype = bool elif mode = = inference 
# Anchors in normalized coordinates input _ anchors = KL 
. Input shape = None 4 name = input _ 
anchors # Build the shared convolutional layers . # Bottom 
up Layers # Returns a list of the last layers 
of each stage 5 in total . # Don t 
create the thead stage 5 so we pick the 4th 
item in the list . if callable config . BACKBONE 
_ C2 C3 C4 C5 = config . BACKBONE input 
_ image stage5 = True train _ bn = config 
. TRAIN _ BN else _ C2 C3 C4 C5 
= resnet _ graph input _ image config . BACKBONE 
stage5 = True train _ bn = config . TRAIN 
_ BN # Top down Layers # TODO add assert 
to varify feature map sizes match what s in config 
P5 = KL . Conv2D config . TOP _ DOWN 
_ PYRAMID _ SIZE 1 1 name = fpn _ 
c5p5 C5 # 256 P4 = KL . Add name 
= fpn _ p4add KL . UpSampling2D size = 2 
2 name = fpn _ p5upsampled P5 KL . Conv2D 
config . TOP _ DOWN _ PYRAMID _ SIZE 1 
1 name = fpn _ c4p4 C4 P3 = KL 
. Add name = fpn _ p3add KL . UpSampling2D 
size = 2 2 name = fpn _ p4upsampled P4 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 1 1 name = fpn _ c3p3 C3 
P2 = KL . Add name = fpn _ p2add 
KL . UpSampling2D size = 2 2 name = fpn 
_ p3upsampled P3 KL . Conv2D config . TOP _ 
DOWN _ PYRAMID _ SIZE 1 1 name = fpn 
_ c2p2 C2 # Attach 3x3 conv to all P 
layers to get the final feature maps . P2 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p2 P2 P3 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p3 P3 P4 = 
KL . Conv2D config . TOP _ DOWN _ PYRAMID 
_ SIZE 3 3 padding = SAME name = fpn 
_ p4 P4 P5 = KL . Conv2D config . 
TOP _ DOWN _ PYRAMID _ SIZE 3 3 padding 
= SAME name = fpn _ p5 P5 # P6 
is used for the 5th anchor scale in RPN . 
Generated by # subsampling from P5 with stride of 2 
. P6 = KL . MaxPooling2D pool _ size = 
1 1 strides = 2 name = fpn _ p6 
P5 # Note that P6 is used in RPN but 
not in the classifier heads . rpn _ feature _ 
maps = P2 P3 P4 P5 P6 mrcnn _ feature 
_ maps = P2 P3 P4 P5 # Anchors if 
mode = = training anchors = self . get _ 
anchors config . IMAGE _ SHAPE # Duplicate across the 
batch dimension because Keras requires it # TODO can this 
be optimized to avoid duplicating the anchors anchors = np 
. broadcast _ to anchors config . BATCH _ SIZE 
+ anchors . shape # A hack to get around 
Keras s bad support for constants anchors = KL . 
Lambda lambda x tf . Variable anchors name = anchors 
input _ image else anchors = input _ anchors # 
RPN Model 返回 的 是 keras 的 Module 对象 注意 
keras 中的 Module 对象 是 可 call 的 rpn = 
build _ rpn _ model config . RPN _ ANCHOR 
_ STRIDE # 1 3 256 len config . RPN 
_ ANCHOR _ RATIOS config . TOP _ DOWN _ 
PYRAMID _ SIZE # Loop through pyramid layers layer _ 
outputs = # list of lists for p in rpn 
_ feature _ maps layer _ outputs . append rpn 
p # 保存 各 pyramid 特征 经过 RPN 之后 的 
结果 # Concatenate layer outputs # Convert from list of 
lists of level outputs to list of lists # of 
outputs across levels . # e . g . a1 
b1 c1 a2 b2 c2 = a1 a2 b1 b2 
c1 c2 output _ names = rpn _ class _ 
logits rpn _ class rpn _ bbox outputs = list 
zip * layer _ outputs # logits2 6 class2 6 
bbox2 6 outputs = KL . Concatenate axis = 1 
name = n list o for o n in zip 
outputs output _ names # batch num _ anchors 2/4 
# 其中 num _ anchors 指 的 是 全部 特征 
层 上 的 anchors 总数 rpn _ class _ logits 
rpn _ class rpn _ bbox = outputs # Generate 
proposals # Proposals are batch N y1 x1 y2 x2 
in normalized coordinates # and zero padded . # POST 
_ NMS _ ROIS _ INFERENCE = 1000 # POST 
_ NMS _ ROIS _ TRAINING = 2000 proposal _ 
count = config . POST _ NMS _ ROIS _ 
TRAINING if mode = = training \ else config . 
POST _ NMS _ ROIS _ INFERENCE # IMAGES _ 
PER _ GPU num _ rois y1 x1 y2 x2 
# IMAGES _ PER _ GPU 取代 了 batch 之后 
说 的 batch 都是 IMAGES _ PER _ GPU rpn 
_ rois = ProposalLayer proposal _ count = proposal _ 
count nms _ threshold = config . RPN _ NMS 
_ THRESHOLD # 0.7 name = ROI config = config 
rpn _ class rpn _ bbox anchors if mode = 
= training # Class ID mask to mark class IDs 
supported by the dataset the image # came from . 
active _ class _ ids = KL . Lambda lambda 
x parse _ image _ meta _ graph x active 
_ class _ ids input _ image _ meta if 
not config . USE _ RPN _ ROIS # Ignore 
predicted ROIs and use ROIs provided as an input . 
input _ rois = KL . Input shape = config 
. POST _ NMS _ ROIS _ TRAINING 4 name 
= input _ roi dtype = np . int32 # 
Normalize coordinates target _ rois = KL . Lambda lambda 
x norm _ boxes _ graph x K . shape 
input _ image 1 3 input _ rois else target 
_ rois = rpn _ rois # Generate detection targets 
# Subsamples proposals and generates target outputs for training # 
Note that proposal class IDs gt _ boxes and gt 
_ masks are zero # padded . Equally returned rois 
and targets are zero padded . rois target _ class 
_ ids target _ bbox target _ mask = \ 
D e t e c t i o n T 
a r g e t L a y e r 
config name = proposal _ targets target _ rois input 
_ gt _ class _ ids gt _ boxes input 
_ gt _ masks # Network Heads # TODO verify 
that this handles zero padded ROIs mrcnn _ class _ 
logits mrcnn _ class mrcnn _ bbox = \ fpn 
_ classifier _ graph rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE mrcnn _ mask = build _ fpn _ mask 
_ graph rois mrcnn _ feature _ maps input _ 
image _ meta config . MASK _ POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN # TODO clean up use tf 
. identify if necessary output _ rois = KL . 
Lambda lambda x x * 1 name = output _ 
rois rois # Losses rpn _ class _ loss = 
KL . Lambda lambda x rpn _ class _ loss 
_ graph * x name = rpn _ class _ 
loss input _ rpn _ match rpn _ class _ 
logits rpn _ bbox _ loss = KL . Lambda 
lambda x rpn _ bbox _ loss _ graph config 
* x name = rpn _ bbox _ loss input 
_ rpn _ bbox input _ rpn _ match rpn 
_ bbox class _ loss = KL . Lambda lambda 
x mrcnn _ class _ loss _ graph * x 
name = mrcnn _ class _ loss target _ class 
_ ids mrcnn _ class _ logits active _ class 
_ ids bbox _ loss = KL . Lambda lambda 
x mrcnn _ bbox _ loss _ graph * x 
name = mrcnn _ bbox _ loss target _ bbox 
target _ class _ ids mrcnn _ bbox mask _ 
loss = KL . Lambda lambda x mrcnn _ mask 
_ loss _ graph * x name = mrcnn _ 
mask _ loss target _ mask target _ class _ 
ids mrcnn _ mask # Model inputs = input _ 
image input _ image _ meta input _ rpn _ 
match input _ rpn _ bbox input _ gt _ 
class _ ids input _ gt _ boxes input _ 
gt _ masks if not config . USE _ RPN 
_ ROIS inputs . append input _ rois outputs = 
rpn _ class _ logits rpn _ class rpn _ 
bbox mrcnn _ class _ logits mrcnn _ class mrcnn 
_ bbox mrcnn _ mask rpn _ rois output _ 
rois rpn _ class _ loss rpn _ bbox _ 
loss class _ loss bbox _ loss mask _ loss 
model = KM . Model inputs outputs name = mask 
_ rcnn else # Network Heads # Proposal classifier and 
BBox regressor heads # output shapes # mrcnn _ class 
_ logits batch num _ rois NUM _ CLASSES classifier 
logits before softmax # mrcnn _ class batch num _ 
rois NUM _ CLASSES classifier probabilities # mrcnn _ bbox 
deltas batch num _ rois NUM _ CLASSES dy dx 
log dh log dw mrcnn _ class _ logits mrcnn 
_ class mrcnn _ bbox = \ fpn _ classifier 
_ graph rpn _ rois mrcnn _ feature _ maps 
input _ image _ meta config . POOL _ SIZE 
config . NUM _ CLASSES train _ bn = config 
. TRAIN _ BN fc _ layers _ size = 
config . FPN _ CLASSIF _ FC _ LAYERS _ 
SIZE # Detections # output is batch num _ detections 
y1 x1 y2 x2 class _ id score in # 
normalized coordinates detections = DetectionLayer config name = mrcnn _ 
detection rpn _ rois mrcnn _ class mrcnn _ bbox 
input _ image _ meta # Create masks for detections 
detection _ boxes = KL . Lambda lambda x x 
. . . 4 detections mrcnn _ mask = build 
_ fpn _ mask _ graph detection _ boxes mrcnn 
_ feature _ maps input _ image _ meta config 
. MASK _ POOL _ SIZE config . NUM _ 
CLASSES train _ bn = config . TRAIN _ BN 
model = KM . Model input _ image input _ 
image _ meta input _ anchors detections mrcnn _ class 
mrcnn _ bbox mrcnn _ mask rpn _ rois rpn 
_ class rpn _ bbox name = mask _ rcnn 
# Add multi GPU support . if config . GPU 
_ COUNT 1 from mrcnn . parallel _ model import 
ParallelModel model = ParallelModel model config . GPU _ COUNT 
return model 