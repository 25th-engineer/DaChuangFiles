原文地址：http://bbs.pinggu.org/bigdata/
大数据概念
"大数据"是一个体量特别大，数据类别特别大的数据集，并且这样的数据集无法用传统数据库工具对其内容进行抓取、管理和处理。
"大数据"首先是指数据体量(volumes)?大，指代大型数据集，一般在10TB?规模左右，但在实际应用中，很多企业用户把多个数据集放在一起，已经形成了PB级的数据量；
其次是指数据类别(variety)大，数据来自多种数据源，数据种类和格式日渐丰富，已冲破了以前所限定的结构化数据范畴，囊括了半结构化和非结构化数据。
接着是数据处理速度（Velocity）快，在数据量非常庞大的情况下，也能够做到数据的实时处理。
最后一个特点是指数据真实性（Veracity）高，随着社交数据、企业内容、交易与应用数据等新数据源的兴趣，传统数据源的局限被打破，企业愈发需要有效的信息之力以确保其真实性及安全性。
"大数据"是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。从数据的类别上看，"大数据"指的是无法使用传统流程或工具处理或分析的信息。它定义了那些超出正常处理范围和大小、迫使用户采用非传统处理方法的数据集。
大数据的分析
从所周知，大数据已经不简简单单是数据大的事实了，而最重要的现实是对大数据进行分析，只有通过分析才能获取很多智能的，深入的，有价值的信息。那么越来越多的应用涉及到大数据，而这些大数据的属性，包括数量，速度，多样性等等都是呈现了大数据不断增长的复杂性，所以大数据的分析方法在大数据领域就显得尤为重要，可以说是决定最终信息是否有价值的决定性因素。基于如此的认识，大数据分析普遍存在的方法理论有哪些呢？
大数据分析的五个基本方面：
1、可视化分析（Analytic Visualizations）
大数据分析的使用者有大数据分析专家，同时还有普通用户，但是他们二者对于大数据分析最基本的要求就是可视化分析，因为可视化分析能够直观的呈现大数据特点，同时能够非常容易被读者所接受，就如同看图说话一样简单明了。
2、数据挖掘算法（Data Mining Algorithms）
大数据分析的理论核心就是数据挖掘算法，各种数据挖掘的算法基于不同的数据类型和格式才能更加科学的呈现出数据本身具备的特点，也正是因为这些被全世界统计学家所公认的各种统计方法（可以称之为真理）才能深入数据内部，挖掘出公认的价值。另外一个方面也是因为有这些数据挖掘的算法才能更快速的处理大数据，如果一个算法得花上好几年才能得出结论，那大数据的价值也就无从说起了。
3、预测性分析能力（Predictive Analytic Capabilities）
大数据分析最终要的应用领域之一就是预测性分析，从大数据中挖掘出特点，通过科学的建立模型，之后便可以通过模型带入新的数据，从而预测未来的数据。
4、语义引擎（Semantic Engines）
大数据分析广泛应用于网络数据挖掘，可从用户的搜索关键词、标签关键词、或其他输入语义，分析，判断用户需求，从而实现更好的用户体验和广告匹配。
5、数据质量和数据管理（Data Quality and Master Data Management）
大数据分析离不开数据质量和数据管理，高质量的数据和有效的数据管理，无论是在学术研究还是在商业应用领域，都能够保证分析结果的真实和有价值。 大数据分析的基础就是以上五个方面，当然更加深入大数据分析的话，还有很多很多更加有特点的、更加深入的、更加专业的大数据分析方法。
大数据技术
数据采集：ETL工具负责将分布的、异构数据源中的数据如关系数据、平面数据文件等抽取到临时中间层后进行清洗、转换、集成，最后加载到数据仓库或数据集市中，成为联机分析处理、数据挖掘的基础。
数据存取：关系数据库、NOSQL、SQL等。
基础架构：云存储、分布式文件存储等。
数据处理：自然语言处理(NLP，NaturalLanguageProcessing)是研究人与计算机交互的语言问题的一门学科。处理自然语言的关键是要让计算机"理解"自然语言，所以自然语言处理又叫做自然语言理解(NLU，NaturalLanguage Understanding)，也称为计算语言学(Computational Linguistics。一方面它是语言信息处理的一个分支，另一方面它是人工智能(AI, Artificial Intelligence)的核心课题之一。
统计分析：假设检验、显著性检验、差异分析、相关分析、T检验、方差分析、卡方分析、偏相关分析、距离分析、回归分析、简单回归分析、多元回归分析、逐步回归、回归预测与残差分析、岭回归、logistic回归分析、曲线估计、因子分析、聚类分析、主成分分析、因子分析、快速聚类法与聚类法、判别分析、对应分析、多元对应分析（最优尺度分析）、bootstrap技术等等。
数据挖掘：分类 （Classification）、估计（Estimation）、预测（Prediction）、相关性分组或关联规则（Affinity grouping or association rules）、聚类（Clustering）、描述和可视化、Description and Visualization）、复杂数据类型挖掘(Text, Web ,图形图像，视频，音频等)
模型预测：预测模型、机器学习、建模仿真。
结果呈现：云计算、标签云、关系图等。
大数据特点
要理解大数据这一概念，首先要从"大"入手，"大"是指数据规模，大数据一般指在10TB(1TB=1024GB)规模以上的数据量。大数据同过去的海量数据有所区别，其基本特征可以用4个V来总结(Vol-ume、Variety、Value和Veloc-ity)，即体量大、多样性、价值密度低、速度快。
第一，数据体量巨大。从TB级别，跃升到PB级别。
第二，数据类型繁多，如前文提到的网络日志、视频、图片、地理位置信息，等等。
第三，价值密度低。以视频为例，连续不间断监控过程中，可能有用的数据仅仅有一两秒。
第四，处理速度快。1秒定律。最后这一点也是和传统的数据挖掘技术有着本质的不同。物联网、云计算、移动互联网、车联网、手机、平板电脑、PC以及遍布地球各个角落的各种各样的传感器，无一不是数据来源或者承载的方式。
大数据技术是指从各种各样类型的巨量数据中，快速获得有价值信息的技术。解决大数据问题的核心是大数据技术。目前所说的"大数据"不仅指数据本身的规模，也包括采集数据的工具、平台和数据分析系统。大数据研发目的是发展大数据技术并将其应用到相关领域，通过解决巨量数据处理问题促进其突破性发展。因此，大数据时代带来的挑战不仅体现在如何处理巨量数据从中获取有价值的信息，也体现在如何加强大数据技术研发，抢占时代发展的前沿。
当下我国大数据研发建设应在以下四个方面着力
一是建立一套运行机制。大数据建设是一项有序的、动态的、可持续发展的系统工程，必须建立良好的运行机制，以促进建设过程中各个环节的正规有序，实现统合，搞好顶层设计。
二是规范一套建设标准。没有标准就没有系统。应建立面向不同主题、覆盖各个领域、不断动态更新的大数据建设标准，为实现各级各类信息系统的网络互连、信息互通、资源共享奠定基础。
三是搭建一个共享平台。数据只有不断流动和充分共享，才有生命力。应在各专用数据库建设的基础上，通过数据集成，实现各级各类指挥信息系统的数据交换和数据共享。
四是培养一支专业队伍。大数据建设的每个环节都需要依靠专业人员完成，因此，必须培养和造就一支懂指挥、懂技术、懂管理的大数据建设专业队伍。
大数据处理
周涛：大数据处理数据时代理念的三大转变：要全体不要抽样，要效率不要绝对精确，要相关不要因果。
具体的大数据处理方法确实有很多，但是根据笔者长时间的实践，总结了一个普遍适用的大数据处理流程，并且这个流程应该能够对大家理顺大数据的处理有所帮助。整个处理流程可以概括为四步，分别是采集、导入和预处理、统计和分析，最后是数据挖掘。
大数据处理之一：采集
大数据的采集是指利用多个数据库来接收发自客户端（Web、App或者传感器形式等）的数据，并且用户可以通过这些数据库来进行简单的查询和处理工作。比如，电商会使用传统的关系型数据库MySQL和Oracle等来存储每一笔事务数据，除此之外，Redis和MongoDB这样的NoSQL数据库也常用于数据的采集。
在大数据的采集过程中，其主要特点和挑战是并发数高，因为同时有可能会有成千上万的用户来进行访问和操作，比如火车票售票网站和淘宝，它们并发的访问量在峰值时达到上百万，所以需要在采集端部署大量数据库才能支撑。并且如何在这些数据库之间进行负载均衡和分片的确是需要深入的思考和设计。
大数据处理之二：导入/预处理
虽然采集端本身会有很多数据库，但是如果要对这些海量数据进行有效的分析，还是应该将这些来自前端的数据导入到一个集中的大型分布式数据库，或者分布式存储集群，并且可以在导入基础上做一些简单的清洗和预处理工作。也有一些用户会在导入时使用来自Twitter的Storm来对数据进行流式计算，来满足部分业务的实时计算需求。
导入与预处理过程的特点和挑战主要是导入的数据量大，每秒钟的导入量经常会达到百兆，甚至千兆级别。
大数据处理之三：统计/分析
统计与分析主要利用分布式数据库，或者分布式计算集群来对存储于其内的海量数据进行普通的分析和分类汇总等，以满足大多数常见的分析需求，在这方面，一些实时性需求会用到EMC的GreenPlum、Oracle的Exadata，以及基于MySQL的列式存储Infobright等，而一些批处理，或者基于半结构化数据的需求可以使用Hadoop。
统计与分析这部分的主要特点和挑战是分析涉及的数据量大，其对系统资源，特别是I/O会有极大的占用。
大数据处理之四：挖掘
与前面统计和分析过程不同的是，数据挖掘一般没有什么预先设定好的主题，主要是在现有数据上面进行基于各种算法的计算，从而起到预测（Predict）的效果，从而实现一些高级别数据分析的需求。比较典型算法有用于聚类的Kmeans、用于统计学习的SVM和用于分类的NaiveBayes，主要使用的工具有Hadoop的Mahout等。该过程的特点和挑战主要是用于挖掘的算法很复杂，并且计算涉及的数据量和计算量都很大，常用数据挖掘算法都以单线程为主。
整个大数据处理的普遍流程至少应该满足这四个方面的步骤，才能算得上是一个比较完整的大数据处理。