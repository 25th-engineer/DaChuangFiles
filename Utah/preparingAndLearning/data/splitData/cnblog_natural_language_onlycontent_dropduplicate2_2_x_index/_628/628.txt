注：博文转载、语料库使用，请注明提供者、来源以及空间提供方。
免责声明：此语料库仅供自然语言处理的业余爱好者研究和交流，禁止用于任何商业用途（包括在资源内部链接广告等行为）。
感谢网易新闻中心、腾讯新闻中心、凤凰新闻中心以及新浪新闻中心提供新闻素材。新闻著作权归以上网站所有，任何人未经上述公司允许不得抄袭。
语料库下载地址：
http://download.cnblogs.com/finallyliuyu/corpus.rar
(注意：有网友提出要MSSQL2000数据库的MDF版本数据，这样在2000以上的数据库上可以进行附加。所以给出MDF,LDF格式的语料库下载地址：MDF版本语料库下载地址)
语料素材来源： 　    凤凰新闻中心、网易新闻中心、腾讯新闻中心、新浪新闻中心。
语料库整理提供者：  finallyliuyu
语料库空间提供方： 博客园
（
无偿提供
）
说明：
1、此语料库非职务作品，由本人在业余时间搜集整理，
免费提供给对NLP狂热的业余爱好者学习研究使用；本人是自然语言处理的业余爱好者，在类别定义等方面都可能存在一些欠缺，欢迎大家提出宝贵意见和建议；
2、下载地址提供的是MS SQL2000数据库的备份文件。使用此数据库，您需要安装 MS SQL2000 server，然后将corpus.rar解压并还原。压缩包大小为54.8M，共包含39247篇新闻，分为历史、军事、文化、读书、教育、IT、娱乐、社会与法制等八个类别。历史类、文化类、读书类新闻来自于凤凰网，IT类的新闻全部来自tech.qq，教育类的新闻来自edu.qq，娱乐类的新闻来自网易。社会与法制类的新闻来自于新浪和腾讯的几个版面；
3、需要特别注意的是，有的新闻在开头处有大量空白，因此在查询数据库ArticleText字段中有大片空白的，不是空新闻，是整个新闻体截断显示的缘故。
4、有关语料库的其他情况，请参考《献给热衷于自然语言处理的业余爱好者的中文新闻分类语料库之一》。
我本人在此语料库做过的验证性实验有：《KL语义距离计算系列》 《Kmeans聚类系列》。今后会接着用此语料库以及搜狗实验室提供的新闻分类语料库做一些有关分类特征词选择方面的算法研究和文本分类器性能分析的实验，敬请大家关注。
感谢DUDU在
博客园
无偿
帮忙提供空间
也感谢博客园团队。衷心祝愿你们越办越好！
欢迎加入自然语言处理业余研究小组共同研究讨论：http://space.cnblogs.com/group/NLP/