中文主要有：NLTK，FoolNLTK，HanLP（java版本），pyhanlp（python版本），Ansj，THULAC，结巴分词，FNLP，哈工大LTP，中科院ICTCLAS分词，GATE，SnowNLP，东北大学NiuTrans，NLPIR，；
英文主要有：NLTK，Genism，TextBlob，Stanford NLP，Spacy。英文的开源NLP工具主要参见StackoverFlow-java or python for nlp
相关问题&文章：
（1）如何用 Python 中的 NLTK 对中文进行分析和处理？ 这个问题下的回答也详说了其他的语音处理包
（2）中文分词项目总结
详细介绍
HanLP：HanLP是由一系列模型与算法组成的Java工具包，目标是普及自然语言处理在生产环境中的应用。HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。
开发语言：Java
网址：hankcs/HanLP
开发机构：大快搜索
协议：Apache-2.0
功能：非常多，主要有中文分词，词性标注，命名实体识别，关键词提取，自动摘要，短语提取，拼音转换，简繁转换，文本推荐，依存句法分析，文本分类：情感分析，word2vec，语料库工具
活跃度：github star 超过4千5，近期（201711）仍在保持更新
Ansj中文分词：一个基于n-Gram+CRF+HMM的中文分词的java实现.
开发语言：Java
网址：NLPchina/ansj_seg
协议：Apache License 2.0
功能：中文分词. 中文姓名识别 . 用户自定义词典,关键字提取，自动摘要，关键字标记
性能：分词速度达到每秒钟大约200万字左右（mac air下测试），准确率能达到96%以上
活跃度：github star 数量超过3500，近期（2017.11）仍在保持更新
THULAC：一个高效的中文词法分析工具包，具有中文分词和词性标注功能。
开发语言：
网址：THULAC：一个高效的中文词法分析工具包
开发机构：清华大学自然语言处理与社会人文计算实验室
协议：研究目的免费开放源代码，商用目的需洽谈许可证
功能：中文分词和词性标注
感谢石墨用户@hain 的补充
Synonyms: 中文近义词工具包
开发语言：Python
网址：https://github.com/huyingxi/Synonyms
开发机构：个人
协议：MIT
功能：获取近义词集合，句子相似度计算
性能：见网站
活跃度：～1k Star
结巴分词：Python中文分词组件
开发语言：Python
网址：fxsjy/jieba
开发机构：
协议：MIT授权协议
功能：中文分词
FNLP：FNLP主要是为中文自然语言处理而开发的工具包，也包含为实现这些任务的机器学习算法和数据集。
开发语言：
网址： FudanNLP/fnlp
开发机构：复旦
协议：LGPL3.0许可证。
功能：信息检索： 文本分类 新闻聚类；中文处理： 中文分词 词性标注 实体名识别 关键词抽取 依存句法分析 时间短语识别；结构化学习： 在线学习 层次分类 聚类
Genism：Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora. Target audience is the natural language processing (NLP) and information retrieval (IR) community.
开发语言：Python
网址：RaRe-Technologies/gensim
协议：LGPL-2.1 license
活跃度：github star数超过五千，近期（201711）仍在更新
TextBlob：Simple, Pythonic, text processing--Sentiment analysis, part-of-speech tagging, noun phrase extraction, translation, and more.
开发语言：Python
网址：sloria/TextBlob
功能：情感分析、词性标注、翻译等
活跃度：github star 超过4千，近期（201711）仍在更新
Spacy：spaCy is a library for advanced Natural Language Processing in Python and Cython. It's built on the very latest research, and was designed from day one to be used in real products. spaCy comes with pre-trained statistical models and word vectors, and currently supports tokenization for 20+ languages. It features the fastest syntactic parser in the world, convolutional neural network models for tagging, parsing and named entity recognition and easy deep learning integration. It's commercial open-source software, released under the MIT license.
开发语言：python
协议：MIT协议
功能： 功能很多，如tagging, parsing and named entity recognition等
性能：功能强大，支持二十多种语言（然而目前还不支持中文，可以阅读官方文档了解更多信息https://spacy.io/usage/），号称是工业级强度的Python NLP工具包，区别于学术性质更浓的Python NLTK
活跃度：star 超过7千，近期（201711）仍非常活跃
作者：鉴津Jackie
链接：www.zhihu.com/question/19929473/answer/264555333
来源：知乎