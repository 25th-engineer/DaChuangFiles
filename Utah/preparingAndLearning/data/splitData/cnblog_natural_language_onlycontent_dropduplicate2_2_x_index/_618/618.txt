概 述
HanLP 是基于 Java开发的 NLP工具包，由一系列模型与算法组成，目标是普及自然语言处理在生产环境中的应用。而且 HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点，因此十分好上手，本文就结合 Spring Boot来将 HanLP用起来！
下载 HanLP数据和程序
由于 HanLP库将数据与代码分离，因此我们需要分别下载所需数据和 jar包：
（1）所需 data数据包下载地址为 data.zip
（2）所需 jar包下载地址为 hanlp-release.zip
工程搭建
（1）创建一个普通的 Spring Boot工程，不赘述
（2）引入 HanLP数据 和 配置
下载完成以后，首先解压 hanlp-release.zip压缩包，然后将解压出的 HanLP的 jar包引入 Spring Boot工程，然后需要来放置 HanLP所需配置和数据：
（1）将解压后 hanlp-release.zip压缩包中的 hanlp.properties配置文件置于项目的 resources资源目录下
（2）然后解压 data.zip压缩包，将解压出的 data目录同样至于 resources目录下（ data 中的数据包很重要，是 HanLP工作所需的词典和模型 ）
创建 IO适配器
HanLP 提供了IO适配器，用户可以实现其提供的 com.hankcs.hanlp.corpus.io.IIOAdapter 接口以在不同的平台（HDFS、Redis等）上运行HanLP，默认的 IO适配器 IOAdapter = com.hankcs.hanlp.corpus.io.FileIOAdapter 是基于普通文件系统的。
接下来我们重写一下 IOAdapter类，使用读写静态资源文件的方法来读取HanLP所需的词典和模型数据（ 即resources目录下刚放置的 data目录 ）
然后我们配置一下 HanLP的配置文件hanlp.properties，有两处需要改为以下配置：
root=   // 我们不再需要这种指定data目录的方式
IOAdapter=cn.codesheep.springbt_hanlp_userdefine.config.ResourceFileIoAdapter // 指定自定义的IOAdapter
好，现在项目就可以工作了，我们接下来写几个测试用例测试体验一把 ！
实验测试
随便写几个例子来感受一番：
分词功能
@Test
public void testSegment() {
System.out.println( HanLP.segment("www.codesheep.cn是一个技术博客！") );
}
分词结果如下：
[www/nx, ./w, codesheep/nx, ./w, cn/nx, 是/vshi, 一个/mq, 技术/n, 博客/n, ！/w]
每个词段后的 /nx，/w之类的是 HanLP定义的词性，可以去看 HanLP的接口来获取详情
文本推荐
三个关键字的语句推荐结果为：
机器学习  →  [人工智能如今是非常火热的一门技术”]
危机公共  →  [威廉王子发表演说 呼吁保护野生动物]mayun     →  [《时代》年度人物最终入围名单出炉 普京马云入选]
关键字提取
@Test
public void testKeyExtract() {
String content = "苹果公司（Apple Inc. ）是美国一家高科技公司。由史蒂夫·乔布斯、斯蒂夫·沃兹尼亚克和罗·韦恩(Ron Wayne)等人于1976年4月1日创立，" + "并命名为美国苹果电脑公司（Apple Computer Inc. ），2007年1月9日更名为苹果公司，总部位于加利福尼亚州的库比蒂诺。"; List<String> keywordList = HanLP.extractKeyword(content, 5); System.out.println(keywordList);
｝
提取结果为：
[公司, 苹果, 美国, Inc, Apple]
体验一番我们发现其自带的模型、字典等数据给出的实验效果已经是非常不错了，而且用户还可以自定义或修改 data目录下的模型、字典等数据来满足特定需求，因此还是十分强大的。
作者：CodeSheep
來源：简书