CMUSphinx系列目录
http://www.cnblogs.com/yin52133/archive/2012/06/21/2557219.html - （一）基本运行测试 http://www.cnblogs.com/yin52133/archive/2012/07/12/2587282.html - （二）自然语言处理原理研究 http://www.cnblogs.com/yin52133/archive/2012/07/12/2587419.html - （三）小范围语音英文识别 http://www.cnblogs.com/yin52133/archive/2012/07/12/2588201.html - （四）小范围语音中文识别 http://www.cnblogs.com/yin52133/archive/2012/06/22/2558806.html - （五）错误调试 http://www.cnblogs.com/yin52133/archive/2012/07/12/2588418.html - （六）我的目标和几个想像的方案（闲置中）
这几天忙完了一阵子，打算继续研究下语音识别
文中都是根据自己的简单测试得到的结论，可能有很多错误，发现问题，欢迎一起讨论
先说一下一般的语音识别流程；以下内容很多都是看自吴军博士的《数学之美》这本书
sphinx语音识别其实是基于统计语言模型的
它主要靠language model（lm），Hidden Markov Model（hmm）模型识别语音。
其中lm模型是统计语料得到的模型，语料就是用于训练的文本库，Dic里面保存的就是训练用的语料库里出现过的语料和对应的发音
而lm模型里存的是语料的组合概率，
先设p（w1）是word w1在文章中出现的概率
//很显然有数据的情况下这个很好统计，遍历就行了
P（w1，w2）w1.w2是连续出现的概率
P（w2|w1）是已知W1已出现的情况下w2
假设识别sentence的概率用P（S）表示
P（S）=P（w1，w2，...wn） 表示单词集w1，w2，。。。wn连续出现并生成S的概率
使用条件概率公式S 把整个公式替换成
P（sentence） = P（w1）*P（w2|w1）*P（w3|w2）。。。P（wn|w1，w2.。。wn-1）
再用马尔科夫假设精简成
P（sentence） = P（w1）*P（w2|w1）*P（w3|w2）。。。P（wn|wn-1）的问题
而
P（wi|wi-1） = P（wi-1，wi） / P（wi）
然后P(wi,|wi-1)和p（wi）都可以从语料统计出来
最终就能得到P（sentence）。而lm模型存储的就是这些p（wi-1，wi）这些概率统计值
实际识别就是算出Max{P(sentence)}的过程
然后是hmm 隐马尔科夫模型
这个模型先不说具体原理，你就知道是声音信号到文字之间映射统计表
因为同样发音下可能也有很多类似的单词，这时候就靠声音的组合来判断识别的颗粒度和识别了。
用hmm识别的时候肯定会调用lm模型，因为最终的识别就是声音道文字，先靠hmm模型的统计值计算出最可能出现的一些集合，
再根据lm模型在这些集合之间计算出概率最高的集合，而那个集合就是输出的语句了。
有兴趣的可以去看《数学之美》或者其他相关书籍
然后再回到pocketSphinx上，我们可以知道识别一条语音至少需要
*.dic *.lm(或者*.DMP) 还有hmm模型
其中 *.dic是整个语料库，包含了改系统能支持的所有单词和对应的发音
*.lm就是统计语言模型
hmm是隐马尔科夫模型、信号到实际数据的识别  这先不要管
我认为的识别流程应该是这样的
hmm依赖lm和dic
lm和dic是靠txt生成的
然后hmm对我们录制的音频流，再使用dic和lm识别
而训练需要的分别是wav和语料库
大量的wav用于使系统更准确的弄出
实际音频到理论音频数据的（也就是训练hmm）
而大量的语料库是用于训练lm
建立统计模型（训练语言模型）
举个例子
整句和单词举个例子就是
dic里面
open 发音 close 发音 door 发音 button 发音
这样的话
识别单词是
识别出来close；door；button；open什么的就靠dic发音映射表，对照判断
而你要识别连续的单词、如open door ，close button就需要靠大量数据或者手动的修改语言模型
还是open close door button这例子
你在lm里把句首 open close 出现的概率提高（接近100%）
然后 door button在句首出现的概率降低到 （接近 0%）
然后在第二个位置的概率弄反
这样的话、他的语法结构就能接近 (open|close) (door|button)
这种形式，可以变相提高整句的识别能力
就是说一句话一个语音流输入它的库可能会把它分离成小的单词流
采样后和语音库（*.dic）匹配
然后第一个有几个备选，再给这些备选+第二个（第二个又是概率里面拿）
得到模糊的串经过语言统计模型然后返回总体可能性最大的。
所以我们最关键就是准确的单词发音映射表还有统计语言模型（*.lm）
而统计语言模型这需要大量的样例数据获得更为准确的概率，也能进一步获取更为准确的结果