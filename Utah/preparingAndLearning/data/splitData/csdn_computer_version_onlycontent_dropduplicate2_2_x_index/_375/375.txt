计算机视觉入门（转载汇总）
一，基本知识
1.1图像和视频，你要知道的概念
图像
一张图片包含了：维数、高度、宽度、深度、通道数、颜色格式、数据首地址、结束地址、数据量等等。
图像深度：存储每个像素所用的位数（bits）
当一个像素占用的位数越多时，它所能表现的颜色就更多，更丰富。
举例：一张400*400的8位图，这张图的原始数据量是多少？像素值如果是整型的话，取值范围是多少？
1，原始数据量计算：400 * 400 * ( 8/8 )=160,000Bytes
(约为160K)
2，取值范围：2的8次方，0~255
图片格式与压缩：常见的图片格式JPEG，PNG，BMP等本质上都是图片的一种压缩编码方式
举例：JPEG压缩
1，将原始图像分为8*8的小块，每个block里有64pixels。
2，将图像中每个8*8的block进行DCT变换（越是复杂的图像，越不容易被压缩）
3，不同的图像被分割后，每个小块的复杂度不一样，所以最终的压缩结果也不一样
视频
原始视频=图片序列。
视频中的每张有序图片称为“帧（frame）”。压缩后的视频，会采取各种算法减少数据的容量，其中IPB就是最常见的。
I帧：表示关键帧，可以理解为这一幅画面的完整保留；解码时只需要本帧数据就可以完成（因为包含完整画面）
P帧：表示的是这一帧跟之前的一个关键帧（或P帧）的差别，解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。（也就是差别帧，P帧没有完整画面数据，只有与前一帧画面差别的数据）
B帧：表示双向差别帧，记录的本帧与前后帧的差别（具体比较复杂，有4种情况），换言之，要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，要通过前后画面与本帧数据的叠加取得最终的画面。B帧压缩率高，但是解码比较麻烦。
码率：码率越大，体积越大；码率越小，体积越小。
码率就是数据传输时单位时间传送的数据位数，一般我们用的单位是kbps即千位每秒。也就是取样率（并不等同于采样率，采样率用的单位是Hz，表示每秒采样的次数），单位时间内取样率越大，精度就越高，处理出来的文件就越接近原始文件，但是文件体积与取样率是成正比的，所以几乎所有的编码格式重视的都是如何用最低的码率达到最少的失真，围绕这个核心衍生出来cbr（固定码率）与vbr（可变码率），码率越高越清晰，反之则画面粗糙而且多马赛克。
帧率：影响画面流畅度，与画面流畅度成正比：帧率越大，画面越流畅；帧率越小，画面越有跳动感。如果码率为变量，则帧率也会影响体积，帧率越高，每秒钟经过的画面就越多，需要的码率也越高，体积也越大。
帧率就是在一秒钟时间里传输的图片的帧数，也可以理解为图形处理器每秒钟刷新的次数。
分辨率：影响图像大小，与图像大小成正比；分辨率越高，图像越大；分辨率越低，图像越小。
清晰度：在码率一定的情况下，分辨率与清晰度成反比关系：分辨率越高，图像越不清晰，分辨率越低，图像越清晰
在分辨率一定的情况下，码率与清晰度成正比关系：码率越高，图像越清晰；码率越低，图像越不清晰
带宽、帧率：例如在ADSL线路上传输图像，上行带宽只有512Kbps，但要传输4路CIF分辨率的图像。按照常规，CIF分辨率建议码率是512Kbps，那么照此计算就只能传一路，降低码率势必会影响图像质量。那么为了确保图像质量，就必须降低帧率，这样一来，即便降低码率也不会影响图像质量，但在图像的连贯性上会有影响。：
1.2摄像机
摄像机的分类：
监控摄像机（网络摄像机和摸你摄像机）
不同行业需求的摄像机（超宽动态摄像机、红外摄像机、热成像摄像机等）
智能摄像机
工业摄像机
当前的摄像机硬件我们可以分为监控摄像机、专业行业应用的摄像机、智能摄像机和工业摄像机。而在监控摄像机里面，当前用的比较多的两个类型一个叫做网络摄像机，一个叫做模拟摄相机，他们主要是成像的原理不太一样。
网络摄像机一般比传统模拟摄相机的清晰度要高一些，模拟摄像机当前应该说是慢慢处于一个淘汰的状态，它可以理解为是上一代的监控摄像机，而网络摄像机是当前的一个主流的摄相机，大概在 13 年的时候，可能市场上 70% 到 80% 多都是模拟摄像机，而现在可能 60% 到 70% 都是的网络摄像机。
除此之外，不同的行业其时会有特定的相机，想超宽动态摄像机以及红外摄像机、热成像摄像机，都是在专用的特定的领域里面可能用到的，而且他获得的画面跟图像是完全不一样的。如果我们要做图像处理跟计算机视觉分析，什么样的相机对你更有利，我们要学会利用硬件的优势。
如果是做研究的话一般是可以控制我们用什么样的摄相机，但如果是在实际的应用场景，这个把控的可能性会稍微小一点，但是在这里你要知道，有些问题可能你换一种硬件，它就能够很好的被解决，这是一个思路。
还有些问题你可能用算法弄了很久也没能解决，甚至是你的效率非常差，成本非常高，但是稍稍换一换硬件，你会发现原来的问题都不存在了，都被很好的解决了，这个就是硬件对你的一个新的处境了。
包括现在还有智能摄像机、工业摄像机，工业摄像机一般的价格也会比较贵，因为他专用于各种工业领域，或者是做一些精密仪器，高精度高清晰度要求的摄像机。
1.3 CPU和GPU
接下来给大家讲一下 CPU 跟 GPU，如果说你要做计算机视觉跟图像处理，那么肯定跳不过 GPU 运算，GPU 运算这一块可能也是接下来需要学习或者自学的一个知识点。
因为可以看到，当前大部分关于计算机视觉的论文，很多实现起来都是用 GPU 去实现的，但是在应用领域，因为 GPU 的价格比较昂贵，所以 CPU 的应用场景相对来说还是占大部分。
而 CPU 跟 GPU 的差别主要在哪里呢？ 它们的差别主要可以在两个方面去对比，第一个叫性能，第二个叫做吞吐量。
性能，换言之，性能会换成另外一个单词叫做 Latency（低延时性）。低延时性就是当你的性能越好，你处理分析的效率越高，相当于你的延时性就越低，这个是性能。另外一个叫做吞吐量，吞吐量的意思就是你同时能够处理的数据量。
而 CPU 跟 GPU 的差别在哪里呢？主要就在于这两个地方，CPU 它是一个高性能，就是超低延时性的，他能够快速的去做复杂运算，并且能达到一个很好的性能要求。而 GPU是以一个叫做运算单元为格式的，所以他的优点不在于低延时性，因为他确实不善于做复杂运算，他每一个处理器都非常的小，相对来说会很弱，但是它可以让它所有的弱处理器，同时去做处理，那相当于他就能够同时处理大量的数据，那这个就意味着它的吞吐量非常大，所以 CPU重视的是性能，GPU重视的是吞吐量。
所以大部分时候，GPU 他会跟另外一个词语联系在一起，叫做并行计算，意思就是它可以同时做大量的线程运算，为什么图像会特别适合用 GPU 运算呢？这是因为 GPU 它最开始的设计就是叫做图形处理单元，它的意思就是我可以把每一个像素，分割为一个线程去运算，每一个像素只做一些简单的运算，这个就是最开始图形处理器出现的原理。
它要做图形渲染的时候，要计算的是每一个像素的变换。所以每一个像素变换的计算量是很小很小的，可能就是一个公式的计算，计算量很少，它可以放在一个简单的计算单元里面去做计算，那这个就是 CPU 跟 GPU 的差别。
基于这样的差别，我们才会去设计什么时候用 CPU，什么时候用 GPU。如果你当前设计的算法，它的并行能力不是很强，从头到尾从上到下都是一个复杂的计算，没有太多可并性的地方，那么即使你用了 GPU，也不能帮助你很好提升计算性能。
所以，不要说别人都在用 GPU 那你就用 GPU，我们要了解的是为什么要用 GPU ，以及什么样的情况下用 GPU，它效果能够发挥出来最好。
二，计算机视觉介绍
计算机视觉包括两个主要研究维度：语义感知(Semantic)、几何属性(Geometry)
2.1 计算机视觉的基础
数字图像处理
空域分析及变换（Sobel，拉普拉斯，高斯，中值等）
频域分析及变换（Fourier & Wavelet Transform）
模板匹配，金字塔，滤波器组
特征数据操作：主成分分析/PCA，奇异值分解/SVD，聚类/Cluster
图像特征及描述
颜色特征（RBG，HSV，Lab等）
几何特征（Edge，Corner，Blob等）
纹理特征（HOG，LBP，Gabor等）
局部特征（SIFT，SURF，FAST等）
2.2 计算机视觉问题解决方案
方式
特征提取
决策模型
传统方式
SIFT，HOG， Raw Pixel …
SVM， Random Forest， Linear Regression …
深度学习
CNN …
CNN …
传统的计算机视觉对待问题的解决方案基本上都是遵循： 图像预处理 → 提取特征 → 建立模型（分类器/回归器） → 输出 的流程。 而在深度学习中，大多问题都会采用端到端（End to End）的解决思路，即从输入到输出一气呵成。
2.2.1 深度监督学习在计算机视觉中的应用
图像分类(Image Classification)
卷积神经网络CNN
对应有没有问题？，有的话，给出属于某类概率的多少？
图像检测(Image Detection)
区域卷积神经网络R-CNN,Fast R-CNN,Faster R-CNN,YOLO,SSD等知名框架
对应目标在哪儿问题？，用矩形框框出目标
图像分割(Image Segmentation)
全卷积神经网络FCN
对应每个像素的类别问题？，用不同颜色画出图像中所有类别的区域轮廓
图像识别(Image Identification)
人脸识别、车牌识别、字符识别、行为识别等
对应内容是什么问题？
注意它和Image Verification的区别？
图像描述(Image Captioning)
迭代神经网络(Vanilla-RNN，LSTM，GRU)
图像问答(Image Question Answering)
迭代神经网络RNN
2.2.2 强化学习
在监督学习任务中，我们都是给定样本一个固定标签，然后去训练模型，可是，在真实环境中，我们很难给出所有样本的标签，这时候，强化学习就派上了用场。简单来说，我们给定一些奖励或惩罚，强化学习就是让模型自己去试错，模型自己去优化怎么才能得到更多的分数。2016年大火的AlphaGo就是利用了强化学习去训练，它在不断的自我试错和博弈中掌握了最优的策略。
2.2.3 深度无监督学习（Deep Unsupervised Learning）–预测学习
图片生成
GAN之后相继出现了条件生成对抗网络(Conditional Generative Adversarial Nets)和信息生成对抗网络(InfoGAN),深度卷积生成对抗网络(Deep Convolutional Generative Adversarial Network, DCGAN),
当前生成对抗网络把触角伸到了视频预测领域，众所周知，人类主要是靠视频序列来理解自然界的，图片只占非常小的一部分，当人工智能学会理解视频后，它也真正开始显现出威力了。
三，学习资料
3.0 数学
微积分：比如图像找边缘即求微分在数字图像里是做差分（离散化）啦，光流算法里用到泰勒级数啦，空间域转频域的傅立叶变换啦，还有牛顿法、梯度下降、最小二乘等等这些都用的特别普遍了。
概率论与统计：这个比较高深，是应用在机器学习领域里最重要的数序分支。应用比如：条件概率、相关系数、最大似然、大数定律、马尔可夫链等等。 浙大的《概率论与数理统计》感觉还行，够用。
线性代数与矩阵：数字图像本身就是以矩阵的形式呈现的，多个向量组成的样本也是矩阵这种形式非常常见，大多机器学习算法里每个样本都是以向量的形式存在的，多个矩阵叠加则是以张量(tensor)的形式存在google深度学习库tensorflow的字面意思之一。具体应用，比如：世界坐标系->相机坐标系->图像坐标系之间的转换，特征值、特征向量，范数等。 推荐国外的上课教材《线性代数》。因为浙大的那本教材感觉实在不太行，买过之后还是又买了这本。
凸优化：这个需要单独拎出来说一下。因为太多问题（尤其机器学习领域）都是优化问题（求最优），凸优化是里面最简单的形式，所以大家都在想办法怎么把一般的优化问题转化为凸优化问题。至于单纯的凸优化理论，好像已经比较成熟了。在机器学习里，经常会看到什么求对偶问题、KKT条件等，潜下心花两天学一学。 建议备一份高校关于凸优化的教学课件，大家对这一块毕竟比较生，缺乏系统感。比如北大的《凸优化》课程。这些数学知识没必要系统学习，效率低又耗时。毕竟大家都有本科的基础，够了。一般用到的时候学，学完之后总结一下。
3.1 计算机基础系列
《深入理解计算机系统》 对计算机编程最底层的东西有了更深入的认识
《鸟哥的Linux私房菜》基础篇 包括指令与Linux系统深入理解 机器学习与深度学习等相关项目大多都在Linux系统下进行
3.2 编程语言系列
C++：
《C++Primer》作者：Stanley Lippman, Josée Lajoie, and Barbara E. Moo (更新到C++11) （不要和 C++ Primer Plus–Stephen Prata搞混了）近1千页，本书透彻的介绍了C++，以浅显和详细的方式讲到C++语言差不多所有内容。2012年8月发行的第五版包含C++11的内容
电子书：第三版（中文）、第四版（中文）、第五版（英文版）
《EffectiveC++》作者：Scott Meyers 本书以瞄准成为C++程序员必读的第二本书籍而写，Scott Meyers成功了。早期的版本面向从C语言转过来的程序员。第三版修改为面向从类似Jave等语言转来的程序员。内容覆盖了50多个很容易记住的条款，每个条款深入浅出（并且有趣）讲到了你可能没有考虑过的C++规则。
电子书：第三版（英文）、第三版（中文)
数据结构的话推荐B站上浙大陈姥姥将的数据结构，算法的话推荐B站上小象学院林沐讲的面试算法LeetCode刷题班的课程
3.3 视觉知识
计算机视觉实在很广了，目前比较热门的方向总体上分为两大块：一块是深度学习，一块做SLAM。它们的研究点区别在哪呢？深度学习这一群体侧重于解决识别感知（是什么）问题，SLAM侧重于解决几何测量（在哪里）问题ICCV研讨会：实时SLAM的未来以及深度学习与SLAM的比较。拿机器人来说，如果你想要它走到你的冰箱面前而不撞到墙壁，那就需要使用 SLAM；如果你想要它能识别并拿起冰箱中的物品，那就需要用到深度学习机器人抓取时怎么定位的？用什么传感器来检测？。当然这两方面在research上也有互相交叉融合的趋势。 不过在学习这些之前，一般都会先掌握下传统的计算机视觉知识，也就是图像处理这一部分了。我之前大致总结过一次：
计算机视觉初级部分知识体系。这些基础知识的理解还是挺有必要的，有助于你理解更高层知识的本质，比如为什么会出现deeplearning等这些新的理论知识（感觉有点像读史了，给你智慧和自由）。这一部分学习资料的话还是挺推荐浅墨的《OpenCV3编程入门》 也可以看他的博客。当然他的书有一个问题就是涉及理论知识太少，所以推荐自己再另备一本偏理论一点的图像处理相关的书，我手边放的是《数字图像处理：原理与实践》，差强人意吧。
参考书
第一本叫《Computer Vision：Models, Learning and Inference》written by Simon J.D. prince，这个主要讲的更适合入门级别的，因为这本书里面配套了非常多的代码，Matlab 代码，C 的代码都有，配套了非常多的学习代码，以及参考资料、文献，都配得非常详细，所以它很适合入门级别的同学去看。
第二本《Computer Vision：Algorithms and Applications》written by Richard Szeliski，这是一本非常经典，非常权威的参考资料，这本书不是用来看的，是用来查的，类似于一本工具书，它是涵盖面最广的一本参考书籍，所以一般会可以当成工具书去看，去查阅。
第三本《OpenCV3编程入门》作者：毛星云，冷雪飞 ，如果想快速的上手去实现一些项目，可以看看这本书，它可以教你动手实现一些例子，并且学习到 OpenCV 最经典、最广泛的计算机视觉开源库。
公开课：
Stanford CS223B
比较适合基础，适合刚刚入门的同学，跟深度学习的结合相对来说会少一点，不会整门课讲深度学习，而是主要讲计算机视觉，方方面面都会讲到。
Stanford CS231N
这个应该不用介绍了，一般很多人都知道，这个是计算机视觉和深度学习结合的一门课，我们上 YouTube 就能够看到，这门课的授课老师就是李飞飞老师，如果说不知道的话可以查一下，做计算机视觉的话，此人算是业界和学术界的“执牛耳”了。
3.4 机器学习
计算机视觉中使用的机器学习方法个人感觉不算多，早期的时候会用SVM做分类，现在基本都用深度学习选特征+分类。原因在于统计机器学习这一块虽然方法不少，但是基本都无法应对图像这么大的数据量。 不过大家在学习过程中很容易接触到各种机器学习方法的名字因为现在大数据分析、机器学习、语音识别、计算机视觉等这些其实分得不是很开，然后不自觉地就会去了解和学习。这样我感觉总体来说是好的。不过在学习一些暂时用不着的算法时，个人感觉没必要做的太深：重在理解其思想，抓住问题本质，了解其应用方向。
下面分开介绍一下传统机器学习算法和深度神经网络。
传统机器学习一般也就决策树、神经网络、支持向量机、boosting、贝叶斯网等等吧。方法挺多的，同一类方法不同的变形更多。除了这些监督式学习，还有非监督学习、半监督学习、强化学习。当然还有一些降维算法（如PCA）等。对这些个人整体把握的也不是特别好，太多了。
学习资料，吴恩达的coursera课程《Machine Learning》，还有李航的《统计学习方法》和周志华的《机器学习》，两本在国内机器学习界成为经典的书。
deeplearning，漫天飞的各种资源。可以看一看李宏毅的一天搞懂深度学习课件 youtube上有一个一天搞懂深度學習–學習心得；李飞飞的CS231n课程，网易云课堂有大数据文摘翻译的中文字幕版课程，知乎专栏智能单元有CS231N课程翻译（非常好）；三巨头之一Yoshua Bengio的新作《DEEP LEARNING》，目前已有中译版本 （《Deep Learning》Written by lan Goodfellow and YoshuaBengio ）。
3.5 文献
arxiv链接 ：每天去更新一下别人最新的工作
计算视觉的顶会
ICCV：国际计算机视觉大会
CVPR：国际计算机视觉与模式识别大会
ECCV：欧洲计算机视觉大会
里程碑式的文献
先熟悉所在方向的发展历程，历程中的里程碑式的文献必须要精读。
例如，深度学习做目标检测，RCNN、Fast RCNN、Fater RCNN、SPPNET、SSD和YOLO等模型；又例如，深度学习做目标跟踪，DLT、SO-DLT等等；再例如，对抗网络GAN、CGAN、DCGAN、LAPGAN等等。
文献汇总
CV Papers