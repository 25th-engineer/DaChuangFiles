作为人类，你本能地知道豹子比摩托车更接近猫，但我们训练大多数人工智能的方式让它们忽略了这些关系。在《科学机器人》杂志上发表的一篇新论文中，作者写道，在我们的算法中构建相似性的概念，可能会让算法变得更加强大。
卷积神经网络已经彻底改变了计算机视觉领域，在一些最具挑战性的视觉任务上，机器的表现已经超过了人类。但我们训练它们分析图像的方式与人类学习的方式非常不同，KTH皇家理工学院副教授Atsuto Maki说。
他写道：“想象一下，你两岁时，有人问你在一张豹纹照片中看到了什么。”“你可能会回答‘一只猫’，而你的父母可能会说，‘是的，不完全一样，但很相似。’”
相比之下，我们训练神经网络的方式很少给予这种部分信任。他们通常被训练对正确的标签有很高的信心，认为所有错误的标签，无论是“猫”还是“摩托车”，都是错误的。Maki说，这是一个错误，因为忽略了一些事情可以“更少出错”的事实意味着你没有利用培训数据中的所有信息。
即使当模型以这种方式训练时，分配给不正确标签的概率也会有很小的差异，这可以告诉你模型如何很好地将它学到的东西推广到看不见的数据。
如果你给一个模型看一张豹子的照片，它给“猫”的概率是5%，给“摩托车”的概率是1%，这表明它意识到猫比摩托车更接近豹子这一事实。相反，如果数字是相反的，这意味着模型还没有学会猫和豹相似的广泛特征，这在分析新数据时可能是有帮助的。
Maki说，如果我们能够提高识别类之间相似性的能力，我们就应该能够创建更灵活的模型，从而更好地进行泛化。最近的研究表明，一种称为正则化的方法的变化可能有助于我们实现这一目标。
神经网络容易问题称为“过度拟合”,指倾向于过多注意小细节和噪声具体训练集，当这种情况发生时，模型将执行优化他们的训练数据但不佳时应用于看不见的测试数据没有这些特定的怪癖。
正则化用于规避这个问题，通常通过降低网络学习所有这些不必要信息的能力，从而提高其泛化到新数据的能力。技术是多种多样的，但通常涉及修改网络的结构或人工神经元之间权重的强度。
然而，最近，研究人员提出了新的正则化方法，通过在所有类别中鼓励更广泛的概率分布来发挥作用。Maki说，这本质上帮助他们捕捉更多的类相似性，从而提高他们的概括能力。
谷歌大脑研究人员在深度学习先驱杰弗里·辛顿的带领下，于2017年设计了一种这样的方法。他们在训练过程中引入了一种惩罚，直接惩罚模型输出中过于自信的预测，以及一种称为标签平滑的技术，这种技术可以防止最大概率变得比其他所有技术都大得多。这意味着正确标签的概率更低，而错误标签的概率更高，这被发现可以提高模型在从图像分类到语音识别等各种任务中的性能。
另一个来自Maki本人，他在2017年也实现了同样的目标，但是通过抑制模型特征向量的高值——描述一个对象所有重要特征的数学构造。这对输出概率的分布具有连锁效应，也有助于提高各种图像分类任务的性能。
虽然这种方法还处于早期阶段，但人类能够利用这些相似性来更有效地学习的事实表明，将这些相似性结合起来的模型是有希望的。Maki指出，它在机器人抓取等应用中尤其有用，在这些应用中，区分各种相似的物体非常重要。
大连人流医院哪家好 mobile.84239650.cn