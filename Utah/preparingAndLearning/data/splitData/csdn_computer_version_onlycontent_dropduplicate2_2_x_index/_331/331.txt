继续之前的计算机视觉课程的学习：
Lecture 6 物体
人类对于物体的感知是连续感知和分类感知的混合，在大层面下，分类感知起主要作用，比如看到的物体，我们都会下意识地根据颜色来进行类别分类。而在小尺度下，例如我们要仔细分辨一块瓷砖内花纹之间有什么区别，这个时候，连续感知更多地帮助我们对物体进行认知。当然，涉及到认知层面，必然会跟文化因素，经验，任务和注意力有关。
类别的分类是非常重要的，虽然我们不知道物体的类别，也可以得到相应的3D形状，纹理，材料特性这些研究对象的信息，但是，物体的类别还封装好了物体的一些行为属性，即物体能做什么（C++里面，类除了数据成员外，还有表明能实现什么功能的函数成员）。
如椅子类别：
上面椅子是否可以坐的例子可以认为是直接感知（direct perception），具有形式简单，容易定义的特点。但是直接感知存在一个问题：它是依赖于观察者的（observer dependent）。对于看上去，结构非常相似的物体，对它们的感知（或认知）却应该是不一样才行。
虽然外形是一样的，却是两个截然相反的对象。这个时候就需要非直接感知了。
接下来讨论的是：哪一级的感知才是正确的感知？
比如说我们对汽车的认知是：2~4个门，4个轮子，1块天花板，2个前灯，还有挡风玻璃。但是，假如我们正考虑买车，要考虑的方面就要更具体了。
入门级分类：将物体分为典型类别和非典型类别，通常不需要科属种那样详细的分类。
经典的分类方法是基于物体组成部分来分的，要确定哪些部分对于分类是必要且有用的，然后把这些组成部件进行抽象，用基本形状如长方块，圆环等来表示，要考虑部件的相对空间位置。
这里还介绍了一种常用的分类器构造方法：boosting（提升）：将简单已得到的弱分类器叠加起来，就能boosting成一个强分类器。
Lecture 7 场景
场景和物体的关系：场景是人类能够进行活动的地方，不仅仅是物体的组合，是有其属性和功能的。
在人的记忆中，场景是一个比存在的物体更容易记住的对象。
那么，通过什么能够得到图像中场景的规律？
塑造环境的物理过程。如，图中存在很多雪，可能是在高山上。
场景中的功能性约束。如，存在很多书本还有电脑，可能是书房。
观察者视角的约束。
人与外部世界的交互。
自然场景和人工场景的分类（我本科毕设也利用了这个特性）：
特写视角和大场景的分类：
上面这两种都是用傅里叶变换的频谱特性进行简单的分类。下面利用Gist描述子进行更具体的分类：
Gist描述子是用Gabor对原图进行4个尺度8个方向卷积得到32个特征图，然后把每个特征图分为16个区域，求每个区域的平均特征，再把4*8*16=512维的特征组合起来，得到Gist描述子。
还有一些通过词袋（bag of words）的方法：SIFT特征，视觉词，金字塔匹配，SVM分类等等进行场景分类。
Lecture 8 场景
这个Lecture继续讲场景分类，从近邻法开始，提到场景分类中，图片量级非常大，所以必须采用快速高效的特征编码方式-二值编码及对应的距离汉明距离。
SVM有三种核来得到决策边界，分别是：
线性核：
k(x,xm)=xTxm
k(x, x_m) = x^T x_m
径向基函数：
k(x,xm)=exp(−|x−xm|2/σ2)
k(x, x_m) = exp(−|x − x_m|^2/σ^2)
直方图交叉(Histogram intersection)：
k(x,xm)=sumi(min(x(i),xm(i)))
k(x,x_m) = sum_i(min(x(i), x_m(i)))
直方图交叉核函数，相当于求
x
x和
xm
x_m的交集和。
Lecture 9 上下文
仍然跟场景分类和识别有关。用一个隐马尔科夫模型来进行位置的估计：
通过一系列的实验，researchers发现：
在合适场景下出现的物体检测准确率更高
场景的连续性会影响物体检测
这体现了上下文的重要性。
人类最低场景识别的分辨率为32*32，上下文有以下三种模型：
但是上下文是依赖以物体检测的，假如，检测产生了错误，那么上下文会使得错误进一步累加。
Lecture 10 不变特征
不变特征是指，随着外界环境的变化，对自身特征来说，影响不大的特征集合，比如能适应光线的变化，有恰好的纹理变化，跟物体表明一一对应。常用在：图像配准；3维重建；运动跟踪；物体检测；索引；机器人导航等。
后面都是介绍一些常见的特征描述子如Harris, good features to track（opencv里面的）等，这里就不在赘述了。
Lecture 11 边缘
这里提到的Canny边缘检测器，其他地方有非常详细的论述，然后是基于亮度，色彩和纹理信息的物体轮廓检测方法：
纹理信息及怎么综合是一个难点，通过上图的统计可知，一般来说，亮度大，亮度梯度大，颜色梯度大，纹理梯度也同时大（甚至都是极大值）的位置处存在轮廓。
剩下的都是一些常见的方法：如距离变换，HOG（梯度方向直方图），在以往的博客或者别人的博客中都有论述过。
Lecture 12 分割
仅有边缘信息对于很多任务是不够的，不同物体的轮廓会重叠在一起，只有把它们按照不同的物体分割开来，才能算是有用的边缘信息。
分割是一个全局操作。人对边缘信息有上百种组合分割的准则：
而这通常也是使得人眼出现错觉的原因。
用聚类来分割：如k-means，means shift。
基于图理论的分割：如最小割，归一化分割。
总结：MIT的课程比起本校研究生的相关课程，理论广而深，内容多且杂，学到的都是必须而且基础的知识，对于跟上日新月异的计算机视觉的发展是非常有好处的。剩下的一些课程是人脸检测，3维运动和一些贝叶斯统计的一些知识，我没有接触过很多相关的知识，所以这里就告一段落了。这是MIT2010年的课程，之后会出2017年课程总结博客，以便学习到更新更系统的领域知识。