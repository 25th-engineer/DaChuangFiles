计算机视觉相关面经总结
1. 梯度下降：为什么多元函数在负梯度方向下降最快？
答： linkhttps://blog.csdn.net/llwleon/article/details/79237053
2. 神经网络中正确使用dropout
答： linkhttps://blog.csdn.net/VioletHan7/article/details/81012993
3. 表达式为max(x,y)的激活函数，反向传播时，x、y上的梯度如何计算？
答：较大的输入的梯度为1，较小输入的梯度为0；即较小的输入对输出没有影响；另一个值较大，它通过最大值运算门输出，所以最后只会得到较大输入值的梯度。这也是最大值门是梯度路由的原因。
前向传播时，最大值往前传播；反向传播时，会把梯度分配给输入值最大的线路，这就是一个梯度路由。
4. 目标检测中常接触的概念：混合高斯模型、光流法、卡尔曼滤波等？
答： 混合高斯模型：http://www.cnblogs.com/mindpuzzle/archive/2013/04/24/3036447.html
光流法：https://blog.csdn.net/carson2005/article/details/7581642
卡尔曼滤波：https://blog.csdn.net/carson2005/article/details/7367135
5. 每个项目中的衡量指标是什么，公开数据集是什么，你实现的效果如何？
答：1）显著性检测的衡量指标：（详细解释） 2）显著性检测公开数据集： 3）自己项目实现相关指标：
6. 介绍resnet和GoogLeNet中的inception module的结构？（CNN结构的了解程度）
答： linkhttps://zhuanlan.zhihu.com/p/33020995
7. 逻辑回归实现多分类？
答：两种方式：1）多个二分类的LR分类器；2）不在输出0/1两种类别，用softmax来实现多类别。
8. CNN中反向传播过程实现？
答： linkhttps://blog.csdn.net/login_sonata/article/details/77488383
9. Tensorflow中卷积操作是怎样实现的？（感觉这种问题是逃不掉的，可惜没搞太懂）
答： linkhttps://blog.csdn.net/qq_23225317/article/details/79678285
10. LR与SVM的异同
答： linkhttps://www.cnblogs.com/zhizhan/p/5038747.html
11. 如何处理样本不均衡问题？
答：https://blog.csdn.net/heyongluoyao8/article/details/49408131
12. 介绍SVM，为什么要求对偶呢？
答: linkhttp://guoze.me/2014/11/26/svm-knowledge/
感觉转换成对偶问题，有一个重要的点就是，原问题求解是基于样本空间，也就是说和样本的数量是密切相关的，但是对偶问题的解是和样本的特征相关的。即从样本空间转换到了特征空间？
13. 过拟合欠拟合及其背后的本质，偏差、方差角度如何理解？
答：主要从训练集和测试集上来理解，比较好理解。偏差体现的是训练集上对于数据的集合程度，而偏差是测试集上模型的波动情况（或者说是，当数据集有波动了，模型的拟合情况如何，也就是泛化性能）
14. VGG16、ResNet、GoogleNet的区别？
答：整理资料中有，从网络规模，层间关系，应用提升来讲。（说出每一个网络最优秀的创新点）
15. RF、GBDT区别--并从方差、偏差理论上解释bagging和boosting的区别。
答：串行和并行本质上就和方差、偏差相关。bagging属于并行的集成算法，每个基学习器的训练集都是随机取样（有放回）得到的，因此具有一定的独立性，所以说在训练中，多个基学习器是独立进行的，所以他们的方差就比较小，这是这种结构自身就带有的，所以说，bagging主要的是要降低偏差，实现比较好的拟合效果，所以说一般RF的每个树的深度都会比较深（15层左右）；而对于boosting是串行的集成方式，并且当前的基学习器是基于上一个学习器学习误差进行训练，主要目的是降低误差（也就是对错分样本增加权重、或者是对上次的误差进行确定梯度进行训练新模型），本质上就是一次一次降低误差（偏差）的过程，使得模型在训练集上拟合的非常好，所以说偏差也就自动的降低了，而boosting最需要做的是降低方差，所以说GBDT中的基学习器树比较浅，层数一般5-10层就有不错的效果，基学习器层数少，模型就简单，一般越简单的模型方差越低，就越不容易过拟合。（奥克姆剃刀原理）