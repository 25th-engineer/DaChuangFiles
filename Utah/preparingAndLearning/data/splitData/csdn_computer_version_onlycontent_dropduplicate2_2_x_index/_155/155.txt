传统的职业人格测试，需要人工填写人格测试题，通过回答问题的结果判断一个人的人格特征，或者通过测评人员多次查看视频，主观判断一个人物的人格。视频识别技术日益成熟，能够智能识别人脸的特征值变化。如果能把视频识别和人物人格特征分析相结合，那么人物人格特征分析可以不用人工参与，由计算机即可完成人物人格特征的分析，极大的提高了职 业人格测试的便利性。为克服上述缺点，本发明的目的在于提供一种视频图像识别人格特征的方法，通过解码分析视频图像来识别人脸特征，进而获得相关的职业人格测试结果。
为了达到以上目的，采用的技术方案是：根据视频图像识别人格特征的方法，根据视频中区域的变化量来获得人物的细微表情变化和肢体动作变化，包括以下步骤：
基于人工智能技术改进的技术方案为：根据视频图像识别人格特征的方法，针对多个参考测定人进行人格评估测定得到多项人格特征因素评分值；采集参考测定人的人眼闭合频率、人脸移动轨迹、皱眉频率、手部动作轨迹，将上述数据导入人格预警模型内分析人物人格，得出人物人格特征报告，其中包括习惯性眨眼、人物是否有摇头的习惯、习惯性皱眉、录制视频时习惯性手部动作，并通过上述内容综合判断职业人员的人格情况。通过视频识别技术和人物人格特征分析技术相结合，通过采集人眼闭合度识别、眉心周色素量识别、人脸中心位置识别、手部中心位置识别、人物动作的变化量来智能识别人物人格特征。
1)职业人员先进行视频沟通，结束后将该视频进行解码，将视频的内容解析成多张连续的图片；
2)针对解析后的每张图片中的人眼闭合度、人脸中心位置、眉心周色素量和手部中心位置四个区域进行静态分析；
3)将每张静态分析后的图片数据依次输入视频动态分析模块中，对每张图片的四个区域进行依次比对，进而获得四个区域的变化量，获得人眼闭合频率、人脸移动轨迹、皱眉频率、手部动作轨迹；
4)根据以上数据导入人格预警模型内分析人物人格，得出人物人格特征报告，其中包括习惯性眨眼、人物是否有摇头的习惯、习惯性皱眉、录制视频时习惯性手部动作，并通过上述内容综合判断职业人员的人格情况。
通过视频识别技术和人物人格特征分析技术相结合，通过采集人眼闭合度识别、眉心周色素量识别、人脸中心位置识别、手部中心位置识别、人物动作的变化量来智能识别人物人格特征。
所述人格预警模型的建立包括：选择多个参考测定人员进行人格评估测定得到作为参考测定人的人格特征因素真实基准评分的多项人格特征因素评分值；采集多个所述参考测定人员正常视频沟通的视频片段，对所述视频片段进行预处理并提取四个区域特征，并统计其特征值；将每一个参考测定人的多项人格特征因素评分值以及视频片段输入人格预警模型内，并在人格预警模型形成不同人格特征的基础数据。
参考测定人员进行人格评估测定具体是指进行大五人格测试、明尼苏达多重人格测试、卡特尔16人格测试中的一种。这样提高预警模型的基础数据的标准性，使其能够更好的预测人格特征。
人眼闭合频率的计算如下：闭合频率＝C/T，C为总闭合次数，T 为总时间；其中要求视频帧率不小于1000ms/T×R，其中T为人眨眼的时间，R 为采样真实系数。
皱眉频率＝C/T(次/分钟)，C为总皱眉次数，T为总时间。
人脸移动轨迹长度＝从0到t总时间长度内，相邻两帧的移动长度之和，x取值范围从0到t，n的取值范围从0到t；x为时间坐标，n为纵向坐标。
手部动作轨迹长度＝从0到t总时间长度内，相邻两帧的移动长度之和，x取值范围从0到t，n的取值范围从0到t；x为时间坐标，n为纵向坐标。
一、建立人格预警模型。
1.1)选择多个参考测定人员进行人格评估测定得到作为参考测定人的人格特征因素真实基准评分的多项人格特征因素评分值。本实施例中，针对选择的多个参考测定人进行人格评估测定具体是指进行大五人格测试(Big Five)，得出各个参考测定人神经质性(Neuroticism)、外向性(Extroversion)、开放性 (Openness)、随和性(Agreeableness)、尽责性(Conscientiousness)五项人格特征因素评分值。此外，针对多个参考测定人进行人格评估还可以采用明尼苏达多重人格测试或者卡特尔16人格测试等，其结果同样也可以得到多项人格特征因素评分值，人格特征因素评分值的项数会由于具体的人格评估测定方法不同而有所不同。
1.2)采集多个所述参考测定人员正常视频沟通的视频片段，对所述视频片段进行预处理并提取人眼闭合度、人脸中心位置、眉心周色素量和手部中心位置四个区域特征，并统计其特征值。采集的人脸部位如所示，包括眉心区域1、人眼区域2、人鼻区域3。本实施例中，共选择个参考测定人，预先对每个参考测定人进行人格确认，预先将其归纳在相应的五大人格类型中。每个参考测定人进行一段20分钟的视频对话，提取每段视频片段中相关人员的细微表情变化和肢体动作变化，并将其输入人格预警模型内形成不同人格特征的基础数据。
如所示的人眼闭合度变化曲线，主要包括时间坐标轴(T)、纵向坐标轴(X)、人眼闭合度曲线。该图的数据来源于视频的智能识别，识别的结果中包括人员闭合度大小，随之时间推移，模拟成二维坐标图。由该坐标图，可以计算出人眼闭合频率，达到预测人物人格特征的目的。人眼闭合频率的计算如下：
人眨眼的平均时间为100ms，为了保证动态曲线更接近真实，所以要求视频帧率不小于1000ms/T×R，其中T为人眨眼的时间，R为采样真实系数。闭合频率＝C/T(次/分钟)，C为总闭合次数，T为总时间。
如所示的眉心周色素变化曲线，主要包括时间坐标轴(T)、纵向坐标轴(X)、眉心周色素变化曲线。该图的数据来源于视频的智能识别，识别的结果中包括人物眉心像素大小，随之时间推移，模拟成二维坐标图。由该坐标图，可以计算出人物皱眉频率，达到预测人物人格特征的目的。皱眉频率的计算如下：
皱眉频率＝C/T(次/分钟)，C为总皱眉次数，T为总时间。
如所示的人脸中心位置变化曲线，主要包括时间坐标轴(y)、横向坐标轴(x)，纵向坐标轴(T)、人脸中心位置变化曲线。该图的数据来源于视频的智能识别，识别的结果中包括人脸中心位置，随之时间推移，模拟成三维坐标图。由该坐标图，可以计算出人物头部移动轨迹，达到预测人物人格特征的目的。人物头部移动轨迹的计算如下：
人物头部移动轨迹长度＝从0到t总时间长度内，相邻两帧的移动长度之和， x取值范围从0到t，n的取值范围从0到t。
如所示的手部中心位置变化曲线，主要包括时间坐标轴(y)、横向坐标轴(x)，纵向坐标轴(T)、手部中心位置变化曲线。该图的数据来源于视频的智能识别，识别的结果中包括手部中心位置，随之时间推移，模拟成三维坐标图。由该坐标图，可以计算出手部中心位置移动轨迹，达到预测人物人格特征的目的。手部中心位置移动轨迹的计算如下：
手部中心位置移动轨迹长度＝从0到t总时间长度内，相邻两帧的移动长度之和，x取值范围从0到t，n的取值范围从0到t。
为了根据视频图像识别出人格特征，需要经过如下步骤：
1)先进行视频沟通，结束后将该视频进行解码，将视频的内容解析成多张连续的图片；
2)针对解析后的每张图片中的人眼闭合度、人脸中心位置、眉心周色素量和手部中心位置四个区域进行静态分析；
3)将每张静态分析后的图片数据依次输入视频动态分析模块中，对每张图片的四个区域进行依次比对，进而获得四个区域的变化量，获得人眼闭合频率、人脸移动轨迹、皱眉频率、手部动作轨迹；
4)根据以上数据导入人格预警模型内分析人物人格，得出人物人格特征报告，其中包括习惯性眨眼、人物是否有摇头的习惯、习惯性皱眉、录制视频时习惯性手部动作，并通过上述内容综合判断职业人员的人格情况。
本发明通过视频识别技术和人物人格特征分析技术相结合，通过采集人眼闭合度识别、眉心周色素量识别、人脸中心位置识别、手部中心位置识别、人物动作的变化量来智能识别人物人格特征。