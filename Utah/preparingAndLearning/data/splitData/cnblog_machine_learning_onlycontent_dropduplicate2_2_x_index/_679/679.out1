根据 网上 的 相关 博客 总结 了 一下 机器学习 中的 
这 两个 概念 参考 博客 见 文末 生成 模型 无穷 
样本 = = 概率密度 模型 = 生成 模型 = = 
预测 判别 模型 有限 样本 = = 判别函数 = 预测模型 
= = 预测 机器学习 中的 模型 一般 分为 两类 判别 
模型 生成 模型 这是 对 问题 的 两种 不同 的 
审视 角度 假设 我们 要 学习 一个 算法 区分 大象 
和狗/nr 假设 输入 是 重量 鼻子 长度 等 特征 判别 
模型 和 生成 模型 以 两种 不同 的 思路 解决 
这个 问题 判别 模型 根据 训练 集 找到 一个 两 
种 动物 的 一个 差别 决策 边界 然后 根据 输入 
的 特征 比如 重量 鼻子 长度 等 看 这个 特种 
落在 决策 边界 的 哪 一边 生成 模型 根据 大象 
的 特征 学习 一个 大象 的 模型 总结 一个 大象 
长 什么样 的 规律 然后 也 学习 一个 狗 的 
模型 为了 分类 一个 新的 物种 我们 看 这个 物种 
和 哪个 模型 更加 匹配 形式化 的 描述 两种 模型 
判别 模型 Discriminative Model 直接 学习 的 是 决策函数 y 
= f x 或者 条件概率 p y | x 或者 
输入 X 和 label { 0 1 } 的 一种 
映射 关系 利用 正负 例和 分类 标签 关注 在 判别 
模型 的 边缘 分布 更多 用来 直接 解决 给定 的 
问题 而不 侧重于 建模 建模 的 目标 是 主要 特点 
寻找 不同 类别 之间 的 最优 分类 面 反映 的 
是 异类 数据 之间 的 差异 优点 是 分类 边界 
更 灵活 比 使用 纯 概率 方法 或 生产 模型 
得到 的 更 高级 能 清晰 的 分辨 出 多类 
或 某一 类 与 其他 类 之间 的 差异 特征 
在 聚 类 viewpoint changes partial occlusion and scale variations 
中 的 效果 较好 适用于 较多 类别 的 识别 判别 
模型 的 性能 比 生成 模型 要 简单 比较 容易 
学习 缺点 是 不能 反映 训练 数据 本身 的 特性 
能力 有限 可以 告诉 你 的 是 1 还是 2 
但 没 办法 把 整个 场景 描述 出来 形式 和 
结构 上 不如 生成式 模型 优雅 类似于 黑盒 变量 之间 
的 关系 不 明确 常见 判别 模型 逻辑 回归 svm 
传统 的 神经 网络 Nearest Neighbor GRF 条件 随 机场 
LDA 线性 判别分析 Boosting 线性 回归 k 近邻 最大熵 模型 
生成 模型 Generative Model 学习 的 是 联合 概率 p 
x y 由于 p x y = p x | 
y * p y 即 我们 需要 学习 的 是 
p x | y 和p/nr y 就 上面 给 的 
例子 如果 y 表示 一个 动物 是 狗 y = 
0 或者 大象 y = 1 那么 p x | 
y = 0 对 狗 的 特征 进行 建模 p 
x | y = 1 是 对 大象 的 特征 
进行 建模 p y 可以 假设 其 服从 伯努利 分布 
因为 y 只有 0 1 两种 取值 建模 目标 如下 
上面 的 式子 之所以 可以忽略 p x 因为 对 训练 
集 的 输入 x 来说 p x 是 一个 常量 
                    
                    
                    
                  本文 
地址 模型 训练 好 以后 对于 输入 的 x 我们 
可以 根据 一下 贝叶斯 公式 来 计算 P y | 
x 然后 看 p y = 0 | x 和p/nr 
y = 1 | x 哪个 较大 就 划分 给 
那一类 即 生成 模型 和 判别 模型 的 最终 目标 
都是 p y | x 只不过 生成 模型 的 目标 
转换成 了 另一种 形式 主要 特点 一般 主要 是 对 
后验/nr 概率 建模 从 统计 的 角度 表示 数据 的 
分布 情况 能够 反映 同类 数据 本身 的 相似 度 
只 关注 自己 的 inclass 本身 不 关心 到底 decision 
boundary 在哪 优点 实际上 带 的 信息 要比 判别 模型 
丰富 有/v 更强/i 的/uj 解释力/n 研究/vn 单类/nr 问题/n 比/p 判别/v 
模型/n 灵活性/n 强/a 模型/n 可以/c 通过/p 增量/n 学习/v 得到/v 能/v 
用于/v 数据/n 不/d 完整/a 的/uj 情况/n 缺点/n 学习 和 计算 
过程 比较 复杂 常见 生成 模型 GDA 高斯 判别分析 朴素 
贝叶斯 贝叶斯 网络 Mixtures of Multinomials 高斯 混合模型 Mixtures of 
Experts 隐 马尔科夫 模型 Sigmoidal Belief Networks 马尔科夫 随 机场 
LDA 潜在 狄立克 雷 分配 下面 是 全文 转 zouxy09 
的 文章生成 模型 与 判别 模型 讲 的 很详细 一直 
在 看 论文 的 过程 中 遇到 这个 问题 折腾 
了 不少 时间 然后 是 下面 的 一点 理解 不 
知道 正确 否 若 有错误 还望 各位 前辈 不吝指正 以免 
小弟 一错再错 在此 谢过 一 决策函数 Y = f X 
或者 条件 概率分布 P Y | X 监督 学习 的 
任务 就是 从 数据 中 学习 一个 模型 也叫 分类器 
应用 这一 模型 对 给定 的 输入 X 预测 相应 
的 输出 Y 这个 模型 的 一般 形式 为 决策函数 
Y = f X 或者 条件 概率分布 P Y | 
X 决策函数 Y = f X 你 输入 一个 X 
它 就 输出 一个 Y 这个 Y 与 一个 阈值 
比较 根据 比较 结果 判定 X 属于 哪个 类别 例如 
两类 w1 和 w2 分类 问题 如果 Y 大于 阈值 
X 就 属于 类 w1 如果 小于 阈值 就 属于 
类 w2 这样 就 得到 了 该 X 对应 的 
类别 了 条件 概率分布 P Y | X 你 输入 
一个 X 它 通过 比较 它 属于 所有 类 的 
概率 然后 输出 概率 最大 的 那个 作为 该 X 
对应 的 类别 例如 如果 P w1 | X 大于 
P w2 | X 那么 我们 就 认为 X 是 
属于 w 1类 的 所以 上面 两个 模型 都 可以 
实现 对 给定 的 输入 X 预测 相应 的 输出 
Y 的 功能 实际上 通过 条件 概率分布 P Y | 
X 进行 预测 也是 隐含 着 表 达成 决策函数 Y 
= f X 的 形式 的 例如 也是 两类 w1 
和 w2 那么 我们 求 得了 P w1 | X 
和P/nr w2 | X 那么 实际上 判别函数 就 可以 表示 
为 Y = P w1 | X / P w2 
| X 如果 Y 大于 1 或者 某个 阈值 那么 
X 就 属于 类 w1 如果 小于 阈值 就 属于 
类 w2 而 同样 很 神奇 的 一件 事 是 
实际上 决策函数 Y = f X 也是 隐含 着 使用 
P Y | X 的 因为 一般 决策函数 Y = 
f X 是 通过 学习 算法 使 你 的 预测 
和 训练 数据 之间 的 误差 平方 最小化 而 贝叶斯 
告诉 我们 虽然 它 没有 显 式 的 运用 贝叶斯 
或者 以 某种 形式 计算 概率 但 它 实际上 也是 
在 隐含 的 输出 极大 似 然 假设 MAP 假设 
也 就是说 学习 器 的 任务 是 在 所有 假设 
模型 有 相等 的 先验概率 条件 下 输出 极大 似 
然 假设 所以 呢 分类器 的 设计 就是 在 给定 
训练 数据 的 基础 上 估计 其 概率模型 P Y 
| X 如果 可以估计 出来 那么 就 可以 分类 了 
但是 一般来说 概率模型 是 比较 难 估计 的 给 一堆 
数给 你 特别 是 数不多 的 时候 你 一般 很难 
找到 这些 数 满足 什么 规律 吧 那 能否 不 
依赖 概率模型 直接 设计 分类器 呢 事实上 分类器 就是 一个 
决策函数 或 决策 面 如果/c 能够/v 从要/nr 解决/v 的/uj 问题/n 
和/c 训练样本/n 出发/v 直接/ad 求出/v 判别函数/n 就 不用 估计 概率模型 
了 这 就是 决策函数 Y = f X 的 伟大 
使命 了 例如 支持 向量 机 我 已经 知道 它 
的 决策函数 分类 面 是 线性 的 了 也 就是 
可以 表示 成Y=/nr f X = WX + b 的 
形式 那么 我们 通过 训练 样 本来 学习 得到 W 
和b的/nr 值 就 可以 得到 Y = f X 了 
还有 一种 更 直接 的 分类 方法 它 不用 事先 
设计 分类器 而是 只 确定 分类 原则 根据 已知 样本 
训练样本 直接 对 未知 样本 进行 分类 包括 近邻 法 
它 不会 在 进行 具体 的 预测 之前 求出 概率模型 
P Y | X 或者 决策函数 Y = f X 
而是 在 真正 预测 的 时候 将 X 与 训练 
数据 的 各类 的 Xi 比较 和 哪些 比较 相似 
就 判断 它 X 也 属于 Xi 对应 的 类 
实际上 说 了 那么 多 也 不 知道 自己 表达 
清楚 了 没有 那/r 我们/r 是/v 谈/v 生成/v 模型/n 和/c 
判别/v 模型/n 上面 到底 啰嗦 了 那么 多 到底 有啥 
阴谋 啊 呵呵 往下 说 就 知道 了 二 生成 
方法 和 判别 方法 监督 学习 方法 又分 生成 方法 
Generative approach 和 判别 方法 Discriminative approach 所 学到 的 
模型 分别 称为 生成 模型 Generative Model 和 判别 模型 
Discriminative Model 咱们 先谈 判别 方法 因为/c 它/r 和/c 前面/f 
说/v 的/uj 都/d 差不多/l 比较 容易 明白 判别 方法 由 
数据 直接 学习 决策函数 Y = f X 或者 条件 
概率分布 P Y | X 作为 预测 的 模型 即 
判别 模型 基本 思想 是 有限 样本 条件 下 建立 
判别函数 不考虑 样本 的 产生 模型 直接 研究 预测模型 典型 
的 判别 模型 包括 k 近邻 感知 级 决策树 支持 
向量 机 等 生成 方法 由 数据 学习 联合 概率密度 
分布 P X Y 然后 求出 条件 概率分布 P Y 
| X 作为 预测 的 模型 即 生成 模型 P 
Y | X = P X Y / P X 
基本 思想 是 首先 建立 样本 的 联合 概率 概率密度 
模型 P X Y 然后 再 得到 后验/nr 概率 P 
Y | X 再 利用 它 进行 分类 就像 上面 
说 的 那样 注意 了 哦 这里 是 先 求出 
P X Y 才得到 P Y | X 的 然后 
这个 过程 还得 先 求出 P X P X 就是 
你 的 训练 数据 的 概率分布 哎 刚才 说 了 
需要 你 的 数据 样本 非常多 的 时候 你 得到 
的 P X 才能 很好 的 描述 你 数据 真正 
的 分布 例如 你 投硬币 你 试了 100次 得到 正面 
的 次数 和你的/nr 试验 次数 的 比 可能 是 3/10 
然后 你 直觉 告诉 你 可能 不对 然后 你 再 
试了 500次 哎 这次 正面 的 次数 和你的/nr 试验 次数 
的 比 可能 就 变成 4/10 这时候 你 半信半疑 不相信 
上帝 还有 一个 手 所以 你 再试 200000次 这时候 正面 
的 次数 和你的/nr 试验 次数 的 比 就 可以 当成 
是 正面 的 概率 了 就 变成 5/10 了 这时候 
你 就 觉得 很 靠谱 了 觉得 自己 就是 那个 
上帝 了 呵呵 真 啰嗦 还 差点 离 题了 还有 
一个 问题 就是 在 机器学习 领域 有个/nr 约定俗成 的 说法 
是 不要 去学 那些 对 这个 任务 没用 的 东西 
例如 对于 一个 分类 任务 对 一个 给定 的 输入 
x 将 它 划分 到 一个 类 y 中 那么 
如果 我们 用 生成 模型 p x y = p 
y | x . p x 那么 我们 就 需要 
去 对 p x 建模 但这 增加 了 我们 的 
工作量 这 让 我们 很 不爽 除了 上面 说 的 
那个 估计 得到 P X 可能 不 太 准确 外 
实际上 因为 数据 的 稀疏 性 导致 我们 都是被/nr 强迫 
地 使用 弱 独立性 假 设去 对 p x 建模 
的 所以 就 产生 了 局限性 所以 我们 更 趋向 
于 直观 的 使用 判别 模型 去 分类 这样 的 
方法 之所以 称为 生成 方法 是 因为 模型表示 了 给定 
输入 X 产生 输出 Y 的 生成 关系 用于 随机 
生成 的 观察 值 建模 特别是在 给定 某些 隐藏 参数 
情况 下 典型 的 生成 模型 有 朴素 贝叶斯 和隐/nr 
马尔科夫 模型 等 三 生成 模型 和 判别 模型 的 
优缺点 在 监督 学习 中 两种 方法 各有 优缺点 适合 
于 不同 条件 的 学习 问题 生成 方法 的 特点 
上面 说到 生成 方法 学习 联合 概率密度 分布 P X 
Y 所以 就 可以 从 统计 的 角度 表示 数据 
的 分布 情况 能够 反映 同类 数据 本身 的 相似 
度 但 它 不 关心 到底 划分 各类 的 那个 
分类 边界 在哪 生成 方法 可以 还原 出 联合 概率分布 
P Y | X 而 判别 方法 不能 生成 方法 
的 学习 收敛 速度 更快 即 当 样本容量 增加 的 
时候 学到 的 模型 可以 更快 的 收敛 于 真实 
模型 当 存在 隐 变量 时 仍 可以 用 生成 
方法 学习 此时 判别 方法 就 不能 用 判别 方法 
的 特点 判别 方法 直接 学习 的 是 决策函数 Y 
= f X 或者 条件 概率分布 P Y | X 
不能 反映 训练 数据 本身 的 特性 但 它 寻找 
不同 类别 之间 的 最优 分类 面 反映 的 是 
异类 数据 之间 的 差异 直接 面对 预测 往往 学习 
的 准确率 更高 由于 直接 学习 P Y | X 
或 P X 可以 对 数据 进行 各种 程度 上 
的 抽象 定义 特征 并 使用 特征 因此 可以 简化 
学习 问题 四 生成 模型 和 判别 模型 的 联系 
由 生成 模型 可以 得到 判别 模型 但 由 判别 
模型 得不到 生成 模型 五 再 形象 点 可以 吗 
例如 我们 有一个 输入 数据 x 然后 我们 想将 它 
分类 为 标签 y 迎面 走 过来 一个 人 你 
告诉 我 这个 是 男 的 还是 女 的 生成 
模型 学习 联合 概率分布 p x y 而 判别 模型 
学习条件 概率分布 p y | x 下面 是 个 简单 
的 例子 例如 我们 有 以下 x y 形式 的 
数据 1 0 1 0 2 0 2 1 那么 
p x y 是 y = 0     y 
= 1 x = 1 | 1/2     0x 
= 2 | 1/4     1/4 而 p y 
| x 是 y = 0     y = 
1 x = 1 | 1         
0x = 2 | 1/2     1/2 我们 为了 
将 一个 样本 x 分类 到 一个 类 y 最 
自然 的 做法 就是 条件 概率分布 p y | x 
这 就是 为什么 我们 对 其 直接 求 p y 
| x 方法 叫做 判别 算法 而 生成 算法 求 
p x y 而 p x y 可以 通过 贝叶斯 
方法 转化 为 p y | x 然后 再用 其 
分类 但是 p x y 还有 其他 作用 例如 你 
可以 用 它 去 生成 x y 对 再 假如 
你 的 任务 是 识别 一个 语音 属于 哪种 语言 
例如 对面 一个 人 走过 来 和你说/nr 了 一句话 你 
需要 识别 出 她说 的 到底 是 汉语 英语 还 
是 法语 等 那么 你 可以 有 两种 方法 达到 
这个 目的 1 学习 每一种 语言 你 花了/nr 大量 精力 
把 汉语 英语/nz 和/c 法语/nz 等/u 都/d 学会/n 了/ul 我 
指 的 学会 是 你 知道 什么样 的 语音 对应 
什么样 的 语言 然后 再 有人 过来 对 你 哄 
你 就 可以 知道 他 说 的 是 什么 语音 
你 就 可以 骂 他 是 米国 人 还是 小日本 
了 呵呵 切勿 将 政治 掺杂 在 技术 里面 2 
不去 学习 每一种 语言 你 只 学习 这些 语言 模型 
之间 的 差别 然后再 分类 意思/n 是/v 指/n 我/r 学会/n 
了/ul 汉语/nz 和/c 英语/nz 等/u 语言/n 的/uj 发音/n 是/v 有/v 
差别/d 的/uj 我 学会 这种 差别 就 好了 那么 第一 
种 方法 就是 生成 方法 第二 种 方法 是 判别 
方法 生成 算法 尝试 去找 到底 这个 数据 是 怎么 
生成 的 产生 的 然后再 对 一个 信号 进行 分类 
基于 你 的 生成 假设 那么 那个 类别 最 有可能 
产生 这个 信号 这个 信号 就 属于 那个/nr 类别 判别 
模型 不关心 数据 是 怎么 生成 的 它 只 关心 
信号 之间 的 差别 然后 用 差别 来 简单 对 
给定 的 一个 信号 进行 分类 六 对于 跟踪 算法 
跟踪 算法 一般来说 可以 分为 两类 基于 外观 模型 的 
生成 模型 或者 基于 外观 模型 的 判别 模型 生成 
模型 一般 是 学习 一个 代表 目标 的 模型 然后 
通过 它 去 搜索 图像 区域 然后 最小化 重构 误差 
类似于 生成 模型 描述 一个 目标 然后 就是 模式匹配 了 
在 图像 中 找到 和 这个 模型 最 匹配 的 
区域 就是 目标 了 判别 模型 将 跟踪 问题 看成 
一个 二 分类 问题 然后 找到 目标 和 背景 的 
决策 边界 它 不管 目标 是 怎么 描述 的 那只 
要知道 目标 和 背景 的 差别 在哪 然后 你 给 
一个 图像 它 看 它 处于 边界 的 那 一边 
就 归为 哪 一类 参考 生成 模型 与 判别 模型 
判别 模型 生成 模型 与 朴素 贝叶斯 方法 判别式 模型 
与 生成式 模型 判别 模型 和 生成 模型 ML Step 
By Step 4 版权 声明 转载 请 注明 出处 http 
/ / www . cnblogs . com / TenosDoIt / 
p / 3721074 . html 