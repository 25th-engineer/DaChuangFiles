目录 线性代数 一 基本知识 二 向量 操作 三 矩阵 运算 
概率论 与 随机 过程 一 概率 与 分布 1.1 条件概率 
与 独立 事件 1.2 联合 概率分布 二 期望 三 方差 
3.1 方差 3.2 协方差 与 相关 系数 3.3 协方差 矩阵 
四 大数 定律 及 中心 极限 定理 4.1 切比雪夫 不等式 
4.2 大数定理 4.3 中心 极限 定理 五 不确定性 来源 六 
常见 概率分布 6.1 均匀分布 6.2 二项分布 6.3 高斯分布 6.4 指数分布 
6.5 拉普拉斯 分布 6.6 狄拉克 分布 6.7 多项式 分布 与 
狄里/nr 克雷 分布 6.8 混合 概率分布 七 先验 分布 与 
后验/nr 分布 八 测度论 九 信息论 数值 计算 一 数值 
稳定性 1.1 近似 误差 1.2 softmax 函 数二 Conditioning 三 
梯度 下 降法 四 海森 矩阵 4.1 二阶 导数 4.2 
海森 矩阵 4.3 海森 矩阵 与 学习率 4.4 驻点 与 
全局 极 小点 四 牛顿 法五/nr 拟 牛顿 法 5.1 
原理 5.2 DFP 算法 5.2 BFGS 算法 5.3 Broyden 类 
算法 六 约束 优化 6.1 原理 6.2 KKT 方法 线性代数 
一 基本知识 本文 中 所有 的 向量 都是 列 向量 
的 形式 \ \ mathbf { \ vec x } 
= x _ 1 x _ 2 \ cdots x 
_ n ^ T = \ begin { bmatrix } 
x _ 1 \ \ x _ 2 \ \ 
\ vdots \ \ x _ n \ end { 
bmatrix } \ 本书 中 所有 的 矩 \ \ 
mathbf X \ in \ mathbb R ^ { m 
\ times n } \ 都 表示 为 \ \ 
mathbf X = \ begin { bmatrix } x _ 
{ 1 1 } & x _ { 1 2 
} & \ cdots & x _ { 1 n 
} \ \ x _ { 2 1 } & 
x _ { 2 2 } & \ cdots & 
x _ { 2 n } \ \ \ vdots 
& \ vdots & \ ddots & \ vdots \ 
\ x _ { m 1 } & x _ 
{ m 2 } & \ cdots & x _ 
{ m n } \ \ \ end { bmatrix 
} \ 简写 为 \ x _ { i j 
} _ { m \ times n } \ 或 
\ x _ { i j } _ { m 
\ times n } \ 矩阵 的 F 范数 设 
矩 \ \ mathbf A = a _ { i 
j } _ { m \ times n } \ 
则 其 F 范数 为 \ | | \ mathbf 
A | | _ F = \ sqrt { \ 
sum _ { i j } a _ { i 
j } ^ { 2 } } \ 它 是 
向量 \ L _ 2 \ 范数 的 推广 矩阵的迹 
设 矩 \ \ mathbf A = a _ { 
i j } _ { m \ times n } 
\ $ \ mathbf A $ 的 迹 为 \ 
tr \ mathbf A = \ sum _ { i 
} a _ { i i } \ 迹 的 
性质 有 \ \ mathbf A \ 的 F 范 
数等 \ \ mathbf A \ mathbf A ^ T 
\ 的 迹 的 平方根 \ | | \ mathbf 
A | | _ F = \ sqrt { tr 
\ mathbf A \ mathbf A ^ { T } 
} \ \ \ mathbf A \ 的 迹 等 
\ \ mathbf A ^ T \ 的 迹 \ 
tr \ mathbf A = tr \ mathbf A ^ 
{ T } \ 交换律 假设 \ \ mathbf A 
\ in \ mathbb R ^ { m \ times 
n } \ mathbf B \ in \ mathbb R 
^ { n \ times m } \ 则有 \ 
tr \ mathbf A \ mathbf B = tr \ 
mathbf B \ mathbf A \ 结合律 \ tr \ 
mathbf A \ mathbf B \ mathbf C = tr 
\ mathbf C \ mathbf A \ mathbf B = 
tr \ mathbf B \ mathbf C \ mathbf A 
\ 二 向量 操作 一组 向 \ \ mathbf { 
\ vec v } _ 1 \ mathbf { \ 
vec v } _ 2 \ cdots \ mathbf { 
\ vec v } _ n \ 是 线性 相关 
的 指 存在 一组 不全 为零 的 实 \ a 
_ 1 a _ 2 \ cdots a _ n 
\ 使得 \ \ sum _ { i = 1 
} ^ { n } a _ i \ mathbf 
{ \ vec v } _ i = \ mathbf 
{ \ vec 0 } \ 一组 向 \ \ 
mathbf { \ vec v } _ 1 \ mathbf 
{ \ vec v } _ 2 \ cdots \ 
mathbf { \ vec v } _ n \ 是 
线性 无关 的 当 且 仅 \ a _ i 
= 0 i = 1 2 \ cdots n \ 
时 才有 \ \ sum _ { i = 1 
} ^ { n } a _ i \ mathbf 
{ \ vec v } _ i = \ mathbf 
{ \ vec 0 } \ 一个 向量空间 所 包含 
的 最大 线性 无关 向量 的 数目 称作 该 向量空间 
的 维数 三维 向量 的 点积 \ \ mathbf { 
\ vec u } \ cdot \ mathbf { \ 
vec v } = u _ xv _ x + 
u _ yv _ y + u _ zv _ 
z = | \ mathbf { \ vec u } 
| | \ mathbf { \ vec v } | 
\ cos \ mathbf { \ vec u } \ 
mathbf { \ vec v } \ 三维 向量 的 
叉积 \ \ mathbf { \ vec w } = 
\ mathbf { \ vec u } \ times \ 
mathbf { \ vec v } = \ begin { 
bmatrix } \ mathbf { \ vec i } & 
\ mathbf { \ vec j } & \ mathbf 
{ \ vec k } \ \ u _ x 
& u _ y & u _ z \ \ 
v _ x & v _ y & v _ 
z \ \ \ end { bmatrix } \ 其 
\ \ mathbf { \ vec i } \ mathbf 
{ \ vec j } \ mathbf { \ vec 
k } \ 分别 \ x y z \ 轴 
的 单位向量 \ \ mathbf { \ vec u } 
= u _ x \ mathbf { \ vec i 
} + u _ y \ mathbf { \ vec 
j } + u _ z \ mathbf { \ 
vec k } \ quad \ mathbf { \ vec 
v } = v _ x \ mathbf { \ 
vec i } + v _ y \ mathbf { 
\ vec j } + v _ z \ mathbf 
{ \ vec k } \ $ \ mathbf { 
\ vec u } $ 和 \ \ mathbf { 
\ vec v } \ 的 叉积 垂直于 \ \ 
mathbf { \ vec u } \ mathbf { \ 
vec v } \ 构成 的 平面 其 方向 符合 
右手 规则 叉积 的 模 等于 \ \ mathbf { 
\ vec u } \ mathbf { \ vec v 
} \ 构成 的 平行四边形 的 面积 \ \ mathbf 
{ \ vec u } \ times \ mathbf { 
\ vec v } = \ mathbf { \ vec 
v } \ times \ mathbf { \ vec u 
} \ $ \ mathbf { \ vec u } 
\ times \ mathbf { \ vec v } \ 
times \ mathbf { \ vec w } = \ 
mathbf { \ vec u } \ cdot \ mathbf 
{ \ vec w } \ mathbf { \ vec 
v } \ mathbf { \ vec u } \ 
cdot \ mathbf { \ vec v } \ mathbf 
{ \ vec w } $ 三维 向量 的 混合 
积 \ \ mathbf { \ vec u } \ 
\ mathbf { \ vec v } \ \ mathbf 
{ \ vec w } = \ mathbf { \ 
vec u } \ times \ mathbf { \ vec 
v } \ cdot \ mathbf { \ vec w 
} = \ mathbf { \ vec u } \ 
cdot \ mathbf { \ vec v } \ times 
\ mathbf { \ vec w } \ \ = 
\ begin { vmatrix } u _ x & u 
_ y & u _ z \ \ v _ 
x & v _ y & v _ z \ 
\ w _ x & w _ y & w 
_ z \ end { vmatrix } = \ begin 
{ vmatrix } u _ x & v _ x 
& w _ x \ \ u _ y & 
v _ y & w _ y \ \ u 
_ z & v _ z & w _ z 
\ end { vmatrix } \ 其 物理 意义 为 
\ \ mathbf { \ vec u } \ mathbf 
{ \ vec v } \ mathbf { \ vec 
w } \ 为 三个 棱边 所 围成 的 平行 
六面体 的 体积 \ \ mathbf { \ vec u 
} \ mathbf { \ vec v } \ mathbf 
{ \ vec w } \ 构成 右手 系 时 
该 平行 六面体 的 体积 为 正号 两个 向量 的 
并 矢 给定 两个 向 \ \ mathbf { \ 
vec x } = x _ 1 x _ 2 
\ cdots x _ n ^ { T } \ 
mathbf { \ vec y } = y _ 1 
y _ 2 \ cdots y _ m ^ { 
T } \ 则 向量 的 并 矢 记作 \ 
\ mathbf { \ vec x } \ mathbf { 
\ vec y } = \ begin { bmatrix } 
x _ 1y _ 1 & x _ 1y _ 
2 & \ cdots & x _ 1y _ m 
\ \ x _ 2y _ 1 & x _ 
2y _ 2 & \ cdots & x _ 2y 
_ m \ \ \ vdots & \ vdots & 
\ ddots & \ vdots \ \ x _ ny 
_ 1 & x _ ny _ 2 & \ 
cdots & x _ ny _ m \ \ \ 
end { bmatrix } \ 也 记 \ \ mathbf 
{ \ vec x } \ otimes \ mathbf { 
\ vec y } \ 或 \ \ mathbf { 
\ vec x } \ mathbf { \ vec y 
} ^ { T } \ 三 矩阵 运算 给定 
两个 矩 \ \ mathbf A = a _ { 
i j } \ in \ mathbb R ^ { 
m \ times n } \ mathbf B = b 
_ { i j } \ in \ mathbb R 
^ { m \ times n } \ 定义 阿达马 
积 Hadamard product 又 称作 逐 元素 积 \ \ 
mathbf A \ circ \ mathbf B = \ begin 
{ bmatrix } a _ { 1 1 } b 
_ { 1 1 } & a _ { 1 
2 } b _ { 1 2 } & \ 
cdots & a _ { 1 n } b _ 
{ 1 n } \ \ a _ { 2 
1 } b _ { 2 1 } & a 
_ { 2 2 } b _ { 2 2 
} & \ cdots & a _ { 2 n 
} b _ { 2 n } \ \ \ 
vdots & \ vdots & \ ddots & \ vdots 
\ \ a _ { m 1 } b _ 
{ m 1 } & a _ { m 2 
} b _ { m 2 } & \ cdots 
& a _ { m n } b _ { 
m n } \ end { bmatrix } \ 克罗 
内积 Kronnecker product \ \ mathbf A \ otimes \ 
mathbf B = \ begin { bmatrix } a _ 
{ 1 1 } \ mathbf B & a _ 
{ 1 2 } \ mathbf B & \ cdots 
& a _ { 1 n } \ mathbf B 
\ \ a _ { 2 1 } \ mathbf 
B & a _ { 2 2 } \ mathbf 
B & \ cdots & a _ { 2 n 
} \ mathbf B \ \ \ vdots & \ 
vdots & \ ddots & \ vdots \ \ a 
_ { m 1 } \ mathbf B & a 
_ { m 2 } \ mathbf B & \ 
cdots & a _ { m n } \ mathbf 
B \ end { bmatrix } \ \ \ mathbf 
{ \ vec x } \ mathbf { \ vec 
a } \ mathbf { \ vec b } \ 
mathbf { \ vec c } \ \ n \ 
阶 向量 \ \ mathbf A \ mathbf B \ 
mathbf C \ mathbf X \ \ n \ 阶 
方阵 则有 \ \ frac { \ partial \ mathbf 
{ \ vec a } ^ { T } \ 
mathbf { \ vec x } } { \ partial 
\ mathbf { \ vec x } } = \ 
frac { \ partial \ mathbf { \ vec x 
} ^ { T } \ mathbf { \ vec 
a } } { \ partial \ mathbf { \ 
vec x } } = \ mathbf { \ vec 
a } \ \ \ frac { \ partial \ 
mathbf { \ vec a } ^ { T } 
\ mathbf X \ mathbf { \ vec b } 
} { \ partial \ mathbf X } = \ 
mathbf { \ vec a } \ mathbf { \ 
vec b } ^ { T } = \ mathbf 
{ \ vec a } \ otimes \ mathbf { 
\ vec b } \ in \ mathbb R ^ 
{ n \ times n } \ \ \ frac 
{ \ partial \ mathbf { \ vec a } 
^ { T } \ mathbf X ^ { T 
} \ mathbf { \ vec b } } { 
\ partial \ mathbf X } = \ mathbf { 
\ vec b } \ mathbf { \ vec a 
} ^ { T } = \ mathbf { \ 
vec b } \ otimes \ mathbf { \ vec 
a } \ in \ mathbb R ^ { n 
\ times n } \ \ \ frac { \ 
partial \ mathbf { \ vec a } ^ { 
T } \ mathbf X \ mathbf { \ vec 
a } } { \ partial \ mathbf X } 
= \ frac { \ partial \ mathbf { \ 
vec a } ^ { T } \ mathbf X 
^ { T } \ mathbf { \ vec a 
} } { \ partial \ mathbf X } = 
\ mathbf { \ vec a } \ otimes \ 
mathbf { \ vec a } \ \ \ frac 
{ \ partial \ mathbf { \ vec a } 
^ { T } \ mathbf X ^ { T 
} \ mathbf X \ mathbf { \ vec b 
} } { \ partial \ mathbf X } = 
\ mathbf X \ mathbf { \ vec a } 
\ otimes \ mathbf { \ vec b } + 
\ mathbf { \ vec b } \ otimes \ 
mathbf { \ vec a } \ \ \ frac 
{ \ partial \ mathbf A \ mathbf { \ 
vec x } + \ mathbf { \ vec a 
} ^ { T } \ mathbf C \ mathbf 
B \ mathbf { \ vec x } + \ 
mathbf { \ vec b } } { \ partial 
\ mathbf { \ vec x } } = \ 
mathbf A ^ { T } \ mathbf C \ 
mathbf B \ mathbf { \ vec x } + 
\ mathbf { \ vec b } + \ mathbf 
B ^ { T } \ mathbf C \ mathbf 
A \ mathbf { \ vec x } + \ 
mathbf { \ vec a } \ \ \ frac 
{ \ partial \ mathbf { \ vec x } 
^ { T } \ mathbf A \ mathbf { 
\ vec x } } { \ partial \ mathbf 
{ \ vec x } } = \ mathbf A 
+ \ mathbf A ^ { T } \ mathbf 
{ \ vec x } \ \ \ frac { 
\ partial \ mathbf X \ mathbf { \ vec 
b } + \ mathbf { \ vec c } 
^ { T } \ mathbf A \ mathbf X 
\ mathbf { \ vec b } + \ mathbf 
{ \ vec c } } { \ partial \ 
mathbf X } = \ mathbf A + \ mathbf 
A ^ { T } \ mathbf X \ mathbf 
{ \ vec b } + \ mathbf { \ 
vec c } \ mathbf { \ vec b } 
^ { T } \ \ \ frac { \ 
partial \ mathbf { \ vec b } ^ { 
T } \ mathbf X ^ { T } \ 
mathbf A \ mathbf X \ mathbf { \ vec 
c } } { \ partial \ mathbf X } 
= \ mathbf A ^ { T } \ mathbf 
X \ mathbf { \ vec b } \ mathbf 
{ \ vec c } ^ { T } + 
\ mathbf A \ mathbf X \ mathbf { \ 
vec c } \ mathbf { \ vec b } 
^ { T } \ 如 \ f \ 是 
一元函数 则 其 逐 元 向量 函数 为 \ f 
\ mathbf { \ vec x } = f x 
_ 1 f x _ 2 \ cdots f x 
_ n ^ { T } \ 其 逐 矩阵 
函数 为 \ f \ mathbf X = \ begin 
{ bmatrix } f x _ { 1 1 } 
& f x _ { 1 2 } & \ 
cdots & f x _ { 1 n } \ 
\ f x _ { 2 1 } & f 
x _ { 2 2 } & \ cdots & 
f x _ { 2 n } \ \ \ 
vdots & \ vdots & \ ddots & \ vdots 
\ \ f x _ { m 1 } & 
f x _ { m 2 } & \ cdots 
& f x _ { m n } \ \ 
\ end { bmatrix } \ 其 逐 元 导数 
分别为 \ f ^ { \ prime } \ mathbf 
{ \ vec x } = f ^ { \ 
prime } x1 f ^ { \ prime } x2 
\ cdots f ^ { \ prime } x _ 
n ^ { T } \ \ f ^ { 
\ prime } \ mathbf X = \ begin { 
bmatrix } f ^ { \ prime } x _ 
{ 1 1 } & f ^ { \ prime 
} x _ { 1 2 } & \ cdots 
& f ^ { \ prime } x _ { 
1 n } \ \ f ^ { \ prime 
} x _ { 2 1 } & f ^ 
{ \ prime } x _ { 2 2 } 
& \ cdots & f ^ { \ prime } 
x _ { 2 n } \ \ \ vdots 
& \ vdots & \ ddots & \ vdots \ 
\ f ^ { \ prime } x _ { 
m 1 } & f ^ { \ prime } 
x _ { m 2 } & \ cdots & 
f ^ { \ prime } x _ { m 
n } \ \ \ end { bmatrix } \ 
各种 类型 的 偏 导数 标量 对 标量 的 偏 
导数 \ \ frac { \ partial u } { 
\ partial v } \ 标量 对 向量 \ n 
\ 维 向量 的 偏 导数 \ \ frac { 
\ partial u } { \ partial \ mathbf { 
\ vec v } } = \ frac { \ 
partial u } { \ partial v _ 1 } 
\ frac { \ partial u } { \ partial 
v _ 2 } \ cdots \ frac { \ 
partial u } { \ partial v _ n } 
^ { T } \ 标量 对 矩阵 \ m 
\ times n \ 阶 矩阵 的 偏 导数 \ 
\ frac { \ partial u } { \ partial 
\ mathbf V } = \ begin { bmatrix } 
\ frac { \ partial u } { \ partial 
V _ { 1 1 } } & \ frac 
{ \ partial u } { \ partial V _ 
{ 1 2 } } & \ cdots & \ 
frac { \ partial u } { \ partial V 
_ { 1 n } } \ \ \ frac 
{ \ partial u } { \ partial V _ 
{ 2 1 } } & \ frac { \ 
partial u } { \ partial V _ { 2 
2 } } & \ cdots & \ frac { 
\ partial u } { \ partial V _ { 
2 n } } \ \ \ vdots & \ 
vdots & \ ddots & \ vdots \ \ \ 
frac { \ partial u } { \ partial V 
_ { m 1 } } & \ frac { 
\ partial u } { \ partial V _ { 
m 2 } } & \ cdots & \ frac 
{ \ partial u } { \ partial V _ 
{ m n } } \ end { bmatrix } 
\ 向量 \ m \ 维 向量 对 标量 的 
偏 导数 \ \ frac { \ partial \ mathbf 
{ \ vec u } } { \ partial v 
} = \ frac { \ partial u _ 1 
} { \ partial v } \ frac { \ 
partial u _ 2 } { \ partial v } 
\ cdots \ frac { \ partial u _ m 
} { \ partial v } ^ { T } 
\ 向量 \ m \ 维 向量 对 向量 \ 
n \ 维 向量 的 偏 导数 雅可比 矩阵 行 
优先 \ \ frac { \ partial \ mathbf { 
\ vec u } } { \ partial \ mathbf 
{ \ vec v } } = \ begin { 
bmatrix } \ frac { \ partial u _ 1 
} { \ partial v _ 1 } & \ 
frac { \ partial u _ 1 } { \ 
partial v _ 2 } & \ cdots & \ 
frac { \ partial u _ 1 } { \ 
partial v _ n } \ \ \ frac { 
\ partial u _ 2 } { \ partial v 
_ 1 } & \ frac { \ partial u 
_ 2 } { \ partial v _ 2 } 
& \ cdots & \ frac { \ partial u 
_ 2 } { \ partial v _ n } 
\ \ \ vdots & \ vdots & \ ddots 
& \ vdots \ \ \ frac { \ partial 
u _ m } { \ partial v _ 1 
} & \ frac { \ partial u _ m 
} { \ partial v _ 2 } & \ 
cdots & \ frac { \ partial u _ m 
} { \ partial v _ n } \ end 
{ bmatrix } \ 如果 为 列 优先 则为 上面 
矩阵 的 转置 矩阵 \ m \ times n \ 
阶 矩阵 对 标量 的 偏 导数 \ \ frac 
{ \ partial \ mathbf U } { \ partial 
v } = \ begin { bmatrix } \ frac 
{ \ partial U _ { 1 1 } } 
{ \ partial v } & \ frac { \ 
partial U _ { 1 2 } } { \ 
partial v } & \ cdots & \ frac { 
\ partial U _ { 1 n } } { 
\ partial v } \ \ \ frac { \ 
partial U _ { 2 1 } } { \ 
partial v } & \ frac { \ partial U 
_ { 2 2 } } { \ partial v 
} & \ cdots & \ frac { \ partial 
U _ { 2 n } } { \ partial 
v } \ \ \ vdots & \ vdots & 
\ ddots & \ vdots \ \ \ frac { 
\ partial U _ { m 1 } } { 
\ partial v } & \ frac { \ partial 
U _ { m 2 } } { \ partial 
v } & \ cdots & \ frac { \ 
partial U _ { m n } } { \ 
partial v } \ end { bmatrix } \ 对于 
矩阵的迹 有 下列 偏 导数 成立 \ \ frac { 
\ partial tr f \ mathbf X } { \ 
partial \ mathbf X } = f ^ { \ 
prime } \ mathbf X ^ { T } \ 
\ \ frac { \ partial tr \ mathbf A 
\ mathbf X \ mathbf B } { \ partial 
\ mathbf X } = \ mathbf A ^ { 
T } \ mathbf B ^ { T } \ 
\ \ frac { \ partial tr \ mathbf A 
\ mathbf X ^ { T } \ mathbf B 
} { \ partial \ mathbf X } = \ 
mathbf B \ mathbf A \ \ \ frac { 
\ partial tr \ mathbf A \ otimes \ mathbf 
X } { \ partial \ mathbf X } = 
tr \ mathbf A \ mathbf I \ \ \ 
frac { \ partial tr \ mathbf A \ mathbf 
X \ mathbf B \ mathbf X } { \ 
partial \ mathbf X } = \ mathbf A ^ 
{ T } \ mathbf X ^ { T } 
\ mathbf B ^ { T } + \ mathbf 
B ^ { T } \ mathbf X \ mathbf 
A ^ { T } \ \ \ frac { 
\ partial tr \ mathbf X ^ { T } 
\ mathbf B \ mathbf X \ mathbf C } 
{ \ partial \ mathbf X } = \ mathbf 
B ^ { T } + \ mathbf B \ 
mathbf X \ mathbf C \ mathbf C ^ { 
T } \ \ \ frac { \ partial tr 
\ mathbf C ^ { T } \ mathbf X 
^ { T } \ mathbf B \ mathbf X 
\ mathbf C } { \ partial \ mathbf X 
} = \ mathbf B \ mathbf X \ mathbf 
C + \ mathbf B ^ { T } \ 
mathbf X \ mathbf C ^ { T } \ 
\ \ frac { \ partial tr \ mathbf A 
\ mathbf X \ mathbf B \ mathbf X ^ 
{ T } \ mathbf C } { \ partial 
\ mathbf X } = \ mathbf A ^ { 
T } \ mathbf C ^ { T } \ 
mathbf X \ mathbf B ^ { T } + 
\ mathbf C \ mathbf A \ mathbf X \ 
mathbf B \ \ \ frac { \ partial tr 
\ mathbf A \ mathbf X \ mathbf B + 
\ mathbf C \ mathbf A \ mathbf X \ 
mathbf B + \ mathbf C } { \ partial 
\ mathbf X } = 2 \ mathbf A ^ 
{ T } \ mathbf A \ mathbf X \ 
mathbf B + \ mathbf C \ mathbf B ^ 
{ T } \ 假 \ \ mathbf U = 
f \ mathbf X \ 是 关 \ \ mathbf 
X \ 的 矩阵 值 函数 \ f \ mathbb 
R ^ { m \ times n } \ rightarrow 
\ mathbb R ^ { m \ times n } 
\ \ g \ mathbf U \ 是 关 \ 
\ mathbf U \ 的 实值函数 $ g \ mathbb 
R ^ { m \ times n } \ rightarrow 
\ mathbb R $ 则 下面 链式法则 成立 \ \ 
frac { \ partial g \ mathbf U } { 
\ partial \ mathbf X } = \ left \ 
frac { \ partial g \ mathbf U } { 
\ partial x _ { i j } } \ 
right _ { m \ times n } = \ 
begin { bmatrix } \ frac { \ partial g 
\ mathbf U } { \ partial x _ { 
1 1 } } & \ frac { \ partial 
g \ mathbf U } { \ partial x _ 
{ 1 2 } } & \ cdots & \ 
frac { \ partial g \ mathbf U } { 
\ partial x _ { 1 n } } \ 
\ \ frac { \ partial g \ mathbf U 
} { \ partial x _ { 2 1 } 
} & \ frac { \ partial g \ mathbf 
U } { \ partial x _ { 2 2 
} } & \ cdots & \ frac { \ 
partial g \ mathbf U } { \ partial x 
_ { 2 n } } \ \ \ vdots 
& \ vdots & \ ddots & \ vdots \ 
\ \ frac { \ partial g \ mathbf U 
} { \ partial x _ { m 1 } 
} & \ frac { \ partial g \ mathbf 
U } { \ partial x _ { m 2 
} } & \ cdots & \ frac { \ 
partial g \ mathbf U } { \ partial x 
_ { m n } } \ \ \ end 
{ bmatrix } \ \ = \ left \ sum 
_ { k } \ sum _ { l } 
\ frac { \ partial g \ mathbf U } 
{ \ partial u _ { k l } } 
\ frac { \ partial u _ { k l 
} } { \ partial x _ { i j 
} } \ right _ { m \ times n 
} = \ left tr \ left \ left \ 
frac { \ partial g \ mathbf U } { 
\ partial \ mathbf U } \ right ^ { 
T } \ frac { \ partial \ mathbf U 
} { \ partial x _ { i j } 
} \ right \ right _ { m \ times 
n } \ 概率论 与 随机 过程 一 概率 与 
分布 1.1 条件概率 与 独立 事件 条件概率 已 \ A 
\ 事件 发生 的 条件 \ B \ 发生 的 
概率 记 \ P B \ mid A \ 它 
等于 事 \ AB \ 的 概率 相对 于事 \ 
A \ 的 概率 即 \ P B \ mid 
A = \ frac { P AB } { P 
A } \ 其中 必须 \ P A \ gt 
0 \ 条件概率 分布 的 链式法则 对 \ n \ 
个 随机 变 \ \ mathbf x _ 1 \ 
mathbf x _ 2 \ cdots \ mathbf x _ 
n \ 有 \ P \ mathbf x _ 1 
\ mathbf x _ 2 \ cdots \ mathbf x 
_ n = P \ mathbf x _ 1 \ 
prod _ { i = 2 } ^ { n 
} P \ mathbf x _ i \ mid \ 
mathbf x _ 1 \ cdots \ mathbf x _ 
{ i 1 } \ 两个 随 机变 \ \ 
mathbf x \ mathbf y \ 相互 独立 的 数学 
描述 \ \ forall x \ in \ mathcal X 
\ forall y \ in \ mathcal Y P \ 
mathbf x = x \ mathbf y = y = 
P \ mathbf x = x P \ mathbf y 
= y \ 记作 \ \ mathbf x \ bot 
\ mathbf y \ 两个 随 机变 \ \ mathbf 
x \ mathbf y \ 关于 随 机变 \ \ 
mathbf z \ 条件 独立 的 数学 描述 \ \ 
forall x \ in \ mathcal X \ forall y 
\ in \ mathcal Y \ forall z \ in 
\ mathcal Z \ \ P \ mathbf x = 
x \ mathbf y = y \ mid \ mathbf 
z = z = P \ mathbf x = x 
\ mid \ mathbf z = z P \ mathbf 
y = y \ mid \ mathbf z = z 
\ 记作 \ \ mathbf x \ bot \ mathbf 
y \ mid \ mathbf z \ 1.2 联合 概率分布 
定 \ { \ mathbf x } \ \ { 
\ mathbf y } \ 的 联合 分布 为 \ 
P a b = P \ { { \ mathbf 
x } \ le a { \ mathbf y } 
\ le b \ } \ infty \ lt a 
b \ lt + \ infty \ \ { \ 
mathbf x } \ 的 分布 可以 从 联合 分布 
中 得到 \ P _ { \ mathbf x } 
a = P \ { { \ mathbf x } 
\ le a \ } = P \ { { 
\ mathbf x } \ le a { \ mathbf 
y } \ le \ infty \ } = P 
a \ infty \ infty \ lt a \ lt 
+ \ infty \ 类似 的 \ { \ mathbf 
y } \ 的 分布 可以 从 联合 分布 中 
得到 \ P _ { \ mathbf y } b 
= P \ { { \ mathbf y } \ 
le b \ } = P \ { { \ 
mathbf x } \ le \ infty { \ mathbf 
y } \ le b \ } = P \ 
infty b \ infty \ lt b \ lt + 
\ infty \ \ { \ mathbf x } \ 
\ { \ mathbf y } \ 都是 离散 随机变量 
时 定 \ { \ mathbf x } \ \ 
{ \ mathbf y } \ 的 联合 概率 质量 
函数 为 \ p x y = P \ { 
{ \ mathbf x } = x { \ mathbf 
y } = y \ } \ \ { \ 
mathbf x } \ \ { \ mathbf y } 
\ 的 概率 质量 函数 分布 为 \ p _ 
{ \ mathbf x } x = \ sum _ 
{ y \ \ p x y \ gt 0 
} p x y \ \ p _ { \ 
mathbf y } y = \ sum _ { x 
\ \ p x y \ gt 0 } p 
x y \ \ { \ mathbf x } \ 
\ { \ mathbf y } \ 联合 地 连续 
时 即 存在 函 \ p x y \ 使得 
对于 所有 的 实数集 \ A \ \ B \ 
满足 \ P \ { { \ mathbf x } 
\ in A { \ mathbf y } \ in 
B \ } = \ int _ B \ int 
_ A p x y dx dy \ 则 函 
\ p x y \ 称 \ { \ mathbf 
x } \ \ { \ mathbf y } \ 
的 概率密度函数 联合 分布 为 \ P a b = 
P \ { { \ mathbf x } \ le 
a { \ mathbf y } \ le b \ 
} = \ int _ { \ infty } ^ 
{ a } \ int _ { \ infty } 
^ { b } p x y dx dy \ 
\ { \ mathbf x } \ \ { \ 
mathbf y } \ 的 概率密度函数 以及 分布 函数 分别为 
\ P _ { \ mathbf x } a = 
\ int _ { \ infty } ^ { a 
} \ int _ { \ infty } ^ { 
\ infty } p x y dx dy = \ 
int _ { \ infty } ^ { a } 
p _ { \ mathbf x } x dx \ 
\ P _ { \ mathbf y } b = 
\ int _ { \ infty } ^ { \ 
infty } \ int _ { \ infty } ^ 
{ b } p x y dx dy = \ 
int _ { \ infty } ^ { b } 
p _ { \ mathbf y } y dy \ 
\ p _ { \ mathbf x } x = 
\ int _ { \ infty } ^ { \ 
infty } p x y dy \ \ p _ 
{ \ mathbf y } y = \ int _ 
{ \ infty } ^ { \ infty } p 
x y dx \ 二 期望 期望 是 概率分布 的 
泛 函 函数 的 函数 离散 型 随 机变 \ 
{ \ mathbf x } \ 的 期望 \ \ 
mathbb E { \ mathbf x } = \ sum 
_ { i = 1 } ^ { \ infty 
} x _ ip _ i \ 若 级数 不 
收敛 则 期望 不存在 连续性 随 机变 \ { \ 
mathbf x } \ 的 期望 \ \ mathbb E 
{ \ mathbf x } = \ int _ { 
\ infty } ^ { \ infty } xp x 
dx \ 若 极限 不 收敛 则 期望 不存在 期望 
描述 了 随机 变量 的 平均 情况 衡量 了 随机 
变 \ { \ mathbf x } \ 的 均值 
定理 \ { \ mathbf y } = g { 
\ mathbf x } \ 均为 随机变量 \ g \ 
cdot \ 是 连续函数 \ { \ mathbf x } 
\ 为 离散 型 随机变量 \ { \ mathbf y 
} \ 的 期望 存在 则 \ \ mathbb E 
{ \ mathbf y } = \ mathbb E g 
{ \ mathbf x } = \ sum _ { 
i = 1 } ^ { \ infty } g 
x _ i p _ i \ \ { \ 
mathbf x } \ 为 连续型 随机变量 \ { \ 
mathbf y } \ 的 期望 存在 则 \ \ 
mathbb E { \ mathbf y } = \ mathbb 
E g { \ mathbf x } = \ int 
_ { \ infty } ^ { \ infty } 
g x p x dx \ 该 定理 的 意义 
在于 当 \ \ mathbb E { \ mathbf y 
} \ 时 不必 计算 \ { \ mathbf y 
} \ 的 分布 只需要 利 \ { \ mathbf 
x } \ 的 分布 即可 该 定理 可以 推广 
至 两个 或者 两个 以上 随机变量 的 情况 此时 \ 
\ mathbb E Z = \ mathbb E g { 
\ mathbf x } { \ mathbf y } = 
\ int _ { \ infty } ^ { \ 
infty } \ int _ { \ infty } ^ 
{ \ infty } g x y p x y 
dxdy \ 上述 公式 也 记 做 \ \ mathbb 
E _ { \ mathbf x \ sim P } 
g x = \ sum _ { x } g 
x p x \ \ \ mathbb E _ { 
\ mathbf x \ sim P } g x = 
\ int g x p x dx \ \ \ 
mathbb E _ { \ mathbf x \ mathbf y 
\ sim P } g x \ int g x 
y p x y dxdy \ 期望 性质 常数 的 
期望 就是 常数 本身 对 常 \ C \ 有 
\ \ mathbb E C { \ mathbf x } 
= C \ mathbb E { \ mathbf x } 
\ 对 两个 随 机变 \ { \ mathbf x 
} { \ mathbf y } \ 有 \ \ 
mathbb E { \ mathbf x } + { \ 
mathbf y } = \ mathbb E { \ mathbf 
x } + \ mathbb E { \ mathbf y 
} \ 该 结论 可 以 推广 到 任意 有限 
个 随机变量 之和 的 情况 对 两个 相互 独立 的 
随机变量 有 \ \ mathbb E { \ mathbf x 
} { \ mathbf y } = \ mathbb E 
{ \ mathbf x } \ mathbb E { \ 
mathbf y } \ 该 结论 可 以 推广 到 
任意 有限 个 相互 独立 的 随机变量 之 积 的 
情况 三 方差 3.1 方差 对 随 机变 \ { 
\ mathbf x } \ \ \ mathbb E { 
\ mathbf x } \ mathbb E { \ mathbf 
x } ^ { 2 } \ 存在 则 称 
它 \ { \ mathbf x } \ 的 方差 
记 \ Var { \ mathbf x } \ \ 
{ \ mathbf x } \ 的 标准 差 为 
方差 的 开平方 即 \ Var { \ mathbf x 
} = \ mathbb E { \ mathbf x } 
\ mathbb E { \ mathbf x } ^ { 
2 } \ \ \ sigma = \ sqrt { 
Var { \ mathbf x } } \ 方 差度 
量了 随机变量 \ { \ mathbf x } \ 与 
期望值 偏离 的 程度 衡 量了 \ { \ mathbf 
x } \ 取值 分散 程度 的 一个 尺度 由于 
绝对值 \ | { \ mathbf x } \ mathbb 
E { \ mathbf x } | \ 带有 绝对值 
不方便 运算 因此 采用 平方 来 计算 又 因为 \ 
| { \ mathbf x } \ mathbb E { 
\ mathbf x } | ^ 2 \ 是 一个 
随机变量 因此 对 它 取 期望 即得 \ { \ 
mathbf x } \ 与 期望值 偏离 的 均值 根据 
定义 可知 \ Var { \ mathbf x } = 
\ mathbb E { \ mathbf x } \ mathbb 
E { \ mathbf x } ^ { 2 } 
= \ mathbb E { \ mathbf x } ^ 
{ 2 } \ mathbb E { \ mathbf x 
} ^ { 2 } \ \ Var f \ 
mathbf x = \ mathbb E f \ mathbf x 
\ mathbb E f \ mathbf x ^ { 2 
} \ 对于 一个 期望 \ \ mu \ 方差 
\ \ sigma ^ { 2 } \ sigma \ 
ne 0 \ 的 随机 变 \ { \ mathbf 
x } \ 随 机变 \ { \ mathbf x 
} ^ { * } = \ frac { { 
\ mathbf x } \ mu } { \ sigma 
} \ 的 数学期望 为 0 方差 为 1 \ 
{ \ mathbf x } ^ { \ ast } 
\ \ { \ mathbf x } \ 的 标准化 
变量 方差 的 性质 常数 的 方差 恒 为 0对 
常 \ C \ \ Var C { \ mathbf 
x } = C ^ { 2 } Var { 
\ mathbf x } \ 对 两个 随 机变 \ 
{ \ mathbf x } { \ mathbf y } 
\ 有 $ Var { \ mathbf x } + 
{ \ mathbf y } = Var { \ mathbf 
x } + Var { \ mathbf y } + 
2 \ mathbb E { \ mathbf x } \ 
mathbb E { \ mathbf x } { \ mathbf 
y } \ mathbb E { \ mathbf y } 
$ 当 \ { \ mathbf x } \ 和 
\ { \ mathbf y } \ 相互 独立 时 
有 $ Var { \ mathbf x } + { 
\ mathbf y } = Var { \ mathbf x 
} + Var { \ mathbf y } $ 可以 
推广 至 任意 有限 多个 相互 独立 的 随机变量 之和 
的 情况 \ Var { \ mathbf x } = 
0 \ 的 充要条件 \ { \ mathbf x } 
\ 以 概率 1 取 常数 3.2 协方差 与 相关 
系数 对于 二维 随 机变 \ { \ mathbf x 
} { \ mathbf y } \ 可以 讨论 描 
\ { \ mathbf x } \ \ { \ 
mathbf y } \ 之间 相互 关系 的 数字 特征 
定义 $ \ mathbb E { \ mathbf x } 
\ mathbb E { \ mathbf x } { \ 
mathbf y } \ mathbb E { \ mathbf y 
} $ 为 随机变量 \ { \ mathbf x } 
\ 与 \ { \ mathbf y } \ 的 
协方差 记作 $ Cov { \ mathbf x } { 
\ mathbf y } = \ mathbb E { \ 
mathbf x } \ mathbb E { \ mathbf x 
} { \ mathbf y } \ mathbb E { 
\ mathbf y } $ 定义 \ \ rho _ 
{ { \ mathbf x } { \ mathbf y 
} } = \ frac { Cov { \ mathbf 
x } { \ mathbf y } } { \ 
sqrt { Var { \ mathbf x } } \ 
sqrt { Var { \ mathbf y } } } 
\ 为 随机变量 \ { \ mathbf x } \ 
与 \ { \ mathbf y } \ 的 相关 
系数 它 是 协方差 的 归一化 由 定义 可知 \ 
Cov { \ mathbf x } { \ mathbf y 
} = Cov { \ mathbf y } { \ 
mathbf x } \ \ Cov { \ mathbf x 
} { \ mathbf x } = Var { \ 
mathbf x } \ \ Var { \ mathbf x 
} + { \ mathbf y } = Var { 
\ mathbf x } + Var { \ mathbf y 
} + 2Cov { \ mathbf x } { \ 
mathbf y } \ 协方差 的 性质 $ Cov a 
{ \ mathbf x } b { \ mathbf y 
} = abCov { \ mathbf x } { \ 
mathbf y } $ \ a b \ 为 常数 
$ Cov { \ mathbf x } _ 1 + 
{ \ mathbf x } _ 2 { \ mathbf 
y } = Cov { \ mathbf x } _ 
1 { \ mathbf y } + Cov { \ 
mathbf x } _ 2 { \ mathbf y } 
$ \ Cov f \ mathbf x g \ mathbf 
y = \ mathbb E f \ mathbf x \ 
mathbb E f \ mathbf x g \ mathbf y 
\ mathbb E g \ mathbf y \ \ \ 
rho f \ mathbf x g \ mathbf y = 
\ frac { Cov f \ mathbf x g \ 
mathbf y } { \ sqrt { Var f \ 
mathbf x } \ sqrt { Var g \ mathbf 
y } } \ 协方差 的 物理 意义 协方差 的 
绝对值 越大 说明 两个 随机变量 都 远离 它们 的 均值 
协方差 如果 为 正 则 说明 两个 随机变量 同时 趋向于 
取 较大 的 值 如果 为 负 则 说明 一个 
随 变量 趋向于 取 较大 的 值 另一个 随机变量 趋向于 
取 较小 的 值 两个 随机变量 的 独立性 可以 导出 
协方差 为零 但是 两 个 随机 变量 的 协方差 为零 
无法 导出 独立性 因为 独立性 也 包括 没有 非 线性关系 
有 可能 两个 随机变量 是非 独立 的 但是 协方差 为零 
假设 随 机变 \ \ mathbf x \ sim U 
1 1 \ 定义 随 机变 \ \ mathbf s 
\ 的 概率分布 函数 为 \ P \ mathbf s 
= 1 = \ frac 12P \ mathbf s = 
1 = \ frac 12 \ 定义 随 机变 \ 
\ mathbf y = \ mathbf { sx } \ 
则 随 机变 \ \ mathbf x \ mathbf y 
\ 是非 独立 的 但是 有 \ Cov \ mathbf 
x \ mathbf y = 0 \ 相关 系数 的 
物理 意义 考虑 以 随 机变 \ { \ mathbf 
x } \ 的 线性 函 \ a + b 
{ \ mathbf x } \ 来 近似 表 \ 
{ \ mathbf y } \ 以 均方 误差 \ 
e = \ mathbb E { \ mathbf y } 
a + b { \ mathbf x } ^ { 
2 } = \ mathbb E { \ mathbf y 
} ^ { 2 } + b ^ { 2 
} \ mathbb E { \ mathbf x } ^ 
{ 2 } + a ^ { 2 } 2b 
\ mathbb E { \ mathbf x } { \ 
mathbf y } + 2ab \ mathbb E { \ 
mathbf x } 2a \ mathbb E { \ mathbf 
y } \ 来 衡量 \ a + b { 
\ mathbf x } \ 近似 表 \ { \ 
mathbf y } \ 的 好坏 程度 \ e \ 
越小 表示 近似 程度 越高 为 求得 最好 的 近似 
则 \ a b \ 分别 取 偏 导数 得到 
\ a _ 0 = \ mathbb E { \ 
mathbf y } b _ 0 \ mathbb E { 
\ mathbf x } = \ mathbb E { \ 
mathbf y } \ mathbb E { \ mathbf x 
} \ frac { Cov { \ mathbf x } 
{ \ mathbf y } } { Var { \ 
mathbf x } } \ \ b _ 0 = 
\ frac { Cov { \ mathbf x } { 
\ mathbf y } } { Var { \ mathbf 
x } } \ \ \ min e = \ 
mathbb E { \ mathbf y } a _ 0 
+ b _ 0 { \ mathbf x } ^ 
{ 2 } = 1 \ rho ^ { 2 
} _ { { \ mathbf x } { \ 
mathbf y } } Var { \ mathbf y } 
\ 因此 有 以下 定理 \ | \ rho _ 
{ { \ mathbf x } { \ mathbf y 
} } | \ le 1 \ \ | . 
. . | \ 是 绝对值 \ | \ rho 
_ { { \ mathbf x } { \ mathbf 
y } } | = 1 \ 的 充要条件 是 
存在 常数 \ a b \ 使得 \ P \ 
{ { \ mathbf y } = a + b 
{ \ mathbf x } \ } = 1 \ 
\ | \ rho _ { { \ mathbf x 
} { \ mathbf y } } | \ 较大 
时 \ e \ 较小 表明 随 机变 \ { 
\ mathbf x } \ \ { \ mathbf y 
} \ 联系 较 紧密 于 \ \ rho _ 
{ { \ mathbf x } { \ mathbf y 
} } \ 是 一个 表 \ { \ mathbf 
x } \ \ { \ mathbf y } \ 
之间 线性关系 紧密 程度 的 量 \ \ rho _ 
{ { \ mathbf x } { \ mathbf y 
} } = 0 \ 时 \ { \ mathbf 
x } \ \ { \ mathbf y } \ 
不相关 不相关 是 就 线性关系 来讲 的 而 相互 独立 
是 一般 关系 而言 的 相互 独立 一定 不 相关 
不相关 则 未必 独立 3.3 协方差 矩阵 矩 \ { 
\ mathbf x } \ \ { \ mathbf y 
} \ 是 随机变量 若 \ \ mathbb E { 
\ mathbf x } ^ { k } k = 
1 2 \ cdots \ 存在 则 称 它 为 
\ { \ mathbf x } \ 的 \ k 
\ 阶 原点矩 简称 \ k \ 阶 矩 若 
\ \ mathbb E { \ mathbf x } \ 
mathbb E { \ mathbf x } ^ { k 
} k = 2 3 \ cdots \ 存在 则 
称 它 为 \ { \ mathbf x } \ 
的 \ k \ 阶 中心矩 若 \ \ mathbb 
E { \ mathbf x } ^ { k } 
{ \ mathbf y } ^ { l } k 
l = 1 2 \ cdots \ 存在 则 称 
它 为 \ { \ mathbf x } \ 和 
\ { \ mathbf y } \ 的 $ k 
+ l $ 阶 混合 矩 若 \ \ mathbb 
E { \ mathbf x } \ mathbb E { 
\ mathbf x } ^ { k } { \ 
mathbf y } \ mathbb E { \ mathbf y 
} ^ { l } k l = 1 2 
\ cdots \ 存在 则 称 它 为 \ { 
\ mathbf x } \ 和 \ { \ mathbf 
y } \ 的 \ k + l \ 阶 
混合 中心矩 因此 期望 是 一 阶 原点矩 方差 是 
二阶 中心矩 协方差 是 二阶 混合 中心矩 协方差 矩阵 二维 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ 有 四个 
二阶 中心矩 设 他们 都 存在 记作 \ \ begin 
{ align } c _ { 11 } & = 
\ mathbb E { \ mathbf x } _ 1 
\ mathbb E { \ mathbf x } _ 1 
^ { 2 } \ \ c _ { 12 
} & = \ mathbb E { \ mathbf x 
} _ 1 \ mathbb E { \ mathbf x 
} _ 1 { \ mathbf x } _ 2 
\ mathbb E { \ mathbf x } _ 2 
\ \ c _ { 21 } & = \ 
mathbb E { \ mathbf x } _ 2 \ 
mathbb E { \ mathbf x } _ 2 { 
\ mathbf x } _ 1 \ mathbb E { 
\ mathbf x } _ 1 \ \ c _ 
{ 22 } & = \ mathbb E { \ 
mathbf x } _ 2 \ mathbb E { \ 
mathbf x } _ 2 ^ { 2 } \ 
\ \ end { align } \ 这个 矩阵 称作 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ 的 协方差 
矩阵 \ n \ 维 随 机变 \ { \ 
mathbf x } _ 1 { \ mathbf x } 
_ 2 \ cdots { \ mathbf x } _ 
n \ 的 二阶 混合 中心 \ c _ { 
ij } = Cov { \ mathbf x } _ 
i { \ mathbf x } _ j = \ 
mathbb E { \ mathbf x } _ i \ 
mathbb E { \ mathbf x } _ i { 
\ mathbf x } _ j \ mathbb E { 
\ mathbf x } _ j i j = 1 
2 \ cdots n \ 都 存在 则 称 矩阵 
\ \ mathbf C = \ begin { bmatrix } 
c _ { 11 } & c _ { 12 
} & \ cdots & c _ { 1n } 
\ \ c _ { 21 } & c _ 
{ 22 } & \ cdots & c _ { 
2n } \ \ \ vdots & \ vdots & 
\ ddots & \ vdots \ \ c _ { 
n1 } & c _ { n2 } & \ 
cdots & c _ { nn } \ \ \ 
end { bmatrix } \ \ n \ 维 随 
机变 \ { \ mathbf x } _ 1 { 
\ mathbf x } _ 2 \ cdots { \ 
mathbf x } _ n \ 的 协方差 矩阵 由于 
\ c _ { ij } = c _ { 
ji } i \ ne j i j = 1 
2 \ cdots n \ 因此 协方差 矩阵 是个 对称 
阵 通 \ n \ 维 随机变量 的 分布 是 
不 知道 的 或者 太 复杂 以致 数学 上 不容 
易处理 因此 实际 中 协方差 矩阵 非常重要 四 大数 定律 
及 中心 极限 定理 4.1 切比雪夫 不等式 切比雪夫 不等式 随 
机变 \ { \ mathbf x } \ 具 有期 
\ \ mathbb E { \ mathbf x } = 
\ mu \ 方 \ Var { \ mathbf x 
} = \ sigma ^ { 2 } \ 对于 
任意 正 \ \ varepsilon \ 不等式 \ P \ 
{ | { \ mathbf x } \ mu | 
\ ge \ varepsilon \ } \ le \ frac 
{ \ sigma ^ { 2 } } { \ 
varepsilon ^ { 2 } } \ 成立 其 意义 
是 对于 距 $ \ mathbb E { \ mathbf 
x } $ 足够 远 的 地方 距离 大于 等 
\ \ varepsilon \ 事件 出现 的 概率 是 小于 
等 $ \ frac { \ sigma ^ { 2 
} } { \ varepsilon ^ { 2 } } 
$ 即 事件 出现 在 区 \ \ mu \ 
varepsilon \ mu + \ varepsilon \ 的 概率 大 
\ 1 \ frac { \ sigma ^ { 2 
} } { \ varepsilon ^ { 2 } } 
\ 该 不等式 给出 了 随机 变 \ { \ 
mathbf x } \ 在 分布 未知 的 情况 下 
事 \ \ { | { \ mathbf x } 
\ mu | \ le \ varepsilon \ } \ 
的 下限 估计 \ P \ { | { \ 
mathbf x } \ mu | \ lt 3 \ 
sigma \ } \ ge 0.8889 \ 证明 \ P 
\ { | { \ mathbf x } \ mu 
| \ ge \ varepsilon \ } = \ int 
_ { | x \ mu | \ ge \ 
varepsilon } p x dx \ le \ int _ 
{ | x \ mu | \ ge \ varepsilon 
} \ frac { | x \ mu | ^ 
{ 2 } } { \ varepsilon ^ { 2 
} } p x dx \ \ \ le \ 
frac { 1 } { \ varepsilon ^ { 2 
} } \ int _ { \ infty } ^ 
{ \ infty } x \ mu ^ { 2 
} p x dx = \ frac { \ sigma 
^ { 2 } } { \ varepsilon ^ { 
2 } } \ 切比雪夫 不等式 的 特殊 情况 设 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ cdots { 
\ mathbf x } _ n \ cdots \ 相互 
独立 且 具有 相同 的 数学 期望 和 方差 $ 
\ mathbb E { \ mathbf x } _ k 
= \ mu Var { \ mathbf x } _ 
k = \ sigma ^ { 2 } k = 
1 2 \ cdots $ 作 \ n \ 个 
随机 变量 的 算术 平均 $ \ overline { \ 
mathbf x } = \ frac { 1 } { 
n } \ sum _ { k = 1 } 
^ { n } { \ mathbf x } _ 
k $ 则 对于 任意 正 $ \ varepsilon $ 
有 \ \ lim _ { n \ rightarrow \ 
infty } P \ { | \ overline { \ 
mathbf x } \ mu | \ lt \ varepsilon 
\ } = \ lim _ { n \ rightarrow 
\ infty } P \ { | \ frac { 
1 } { n } \ sum _ { k 
= 1 } ^ { n } { \ mathbf 
x } _ k \ mu | \ lt \ 
varepsilon \ } = 1 \ 证明 \ \ mathbb 
E \ frac { 1 } { n } \ 
sum _ { k = 1 } ^ { n 
} { \ mathbf x } _ k = \ 
mu \ \ Var \ frac { 1 } { 
n } \ sum _ { k = 1 } 
^ { n } { \ mathbf x } _ 
k = \ frac { \ sigma ^ { 2 
} } { n } \ 有 切比雪夫 不等式 以 
\ n \ 趋于 无穷 时 可以 证明 详细 过程 
省略 4.2 大数定理 依 概率 收敛 \ { \ mathbf 
y } _ 1 { \ mathbf y } _ 
2 \ cdots { \ mathbf y } _ n 
\ cdots \ 是 一个 随机变量 序列 \ a \ 
是 一个 常数 若 对于 任意 正 $ \ varepsilon 
$ 有 \ \ lim _ { n \ rightarrow 
\ infty } P \ { | { \ mathbf 
y } _ { n } a | \ le 
\ varepsilon \ } = 1 \ 则 称 序 
\ { \ mathbf y } _ 1 { \ 
mathbf y } _ 2 \ cdots { \ mathbf 
y } _ n \ cdots \ 依 概率 收敛 
\ a \ 记作 \ { \ mathbf y } 
_ { n } \ stackrel { P } { 
\ rightarrow } a \ 依 概率 收敛 的 两个 
含义 收敛 表明 这 是 一个 随机变量 序列 而 不是 
某个 随机变量 且 序列 是 无限 长 而 不是 有 
限长 依 概率 表明 序列 无穷 远处 的 随机变量 \ 
{ \ mathbf y } _ { \ infty } 
\ 的 分布 规律 为 绝 大 部分 分布 于点/nr 
\ a \ 极少数 位于 \ a \ 之外 且 
分布 于 \ a \ 之外 的 事件 发生 的 
概率 之和 为 0 大数定理 一 设 随 机变 \ 
{ \ mathbf x } _ 1 { \ mathbf 
x } _ 2 \ cdots { \ mathbf x 
} _ n \ cdots \ 相互 独立 且 具有 
相同 的 数学 期望 和 方差 $ \ mathbb E 
{ \ mathbf x } _ k = \ mu 
Var { \ mathbf x } _ k = \ 
sigma ^ { 2 } k = 1 2 \ 
cdots $ 则 序列 $ \ overline { \ mathbf 
x } = \ frac { 1 } { n 
} \ sum _ { k = 1 } ^ 
{ n } { \ mathbf x } _ k 
$ 依 概率 收敛 \ \ mu \ \ \ 
overline { \ mathbf x } \ stackrel { P 
} { \ rightarrow } \ mu \ 这里 并 
没有 要求 随机变量 \ { \ mathbf x } _ 
1 { \ mathbf x } _ 2 \ cdots 
{ \ mathbf x } _ n \ cdots \ 
同 分布 伯努利 大数定理 \ n _ A \ \ 
n \ 次 独立 重复 实验 中 事 \ A 
\ 发生 的 次数 \ p \ 是 事 \ 
A \ 在 每次 试验 中 发生 的 概率 则 
对于 任意 正 $ \ varepsilon $ 有 \ \ 
lim _ { n \ rightarrow \ infty } P 
\ { | \ frac { n _ { A 
} } { n } p | \ lt \ 
varepsilon \ } = 1 \ \ or \ quad 
\ lim _ { n \ rightarrow \ infty } 
P \ { | \ frac { n _ { 
A } } { n } p | \ ge 
\ varepsilon \ } = 0 \ 即 当 独立 
重复 实验 执行 非常大 的 次数 时 事件 \ A 
\ 发生 的 频率 逼近 于它的/nr 概率 辛钦 定理 设 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ cdots { 
\ mathbf x } _ n \ cdots \ 相互 
独立 服从 同一 分布 且 具有 相同 的 数学 期望 
$ \ mathbb E { \ mathbf x } _ 
k = \ mu k = 1 2 \ cdots 
$ 则 对于 任意 正 $ \ varepsilon $ 有 
\ \ lim _ { n \ rightarrow \ infty 
} P \ { | \ frac { 1 } 
{ n } \ sum _ { k = 1 
} ^ { n } { \ mathbf x } 
_ k \ mu | \ lt \ varepsilon \ 
} = 1 \ 这里 并 没有 要求 随机变量 \ 
{ \ mathbf x } _ 1 { \ mathbf 
x } _ 2 \ cdots { \ mathbf x 
} _ n \ cdots \ 的 方差 存在 伯努利 
大数定理 是 亲 钦 定理 的 特殊 情况 4.3 中心 
极限 定理 独立 同 分布 的 中心 极限 定理 设 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ cdots { 
\ mathbf x } _ n \ 独立 同 分布 
且 具有 数学期望 和 方差 \ \ mathbb E { 
\ mathbf x } _ k = \ mu Var 
{ \ mathbf x } _ k = \ sigma 
^ { 2 } \ gt 0 k = 1 
2 \ cdots \ 则 随机变量 之 \ \ overline 
{ { \ mathbf x } _ n } = 
\ sum _ { k = 1 } ^ { 
n } { \ mathbf x } _ k \ 
的 标准 变化 量 \ { \ mathbf y } 
_ n = \ frac { \ overline { { 
\ mathbf x } _ n } \ mathbb E 
\ overline { { \ mathbf x } _ n 
} } { \ sqrt { Var \ overline { 
{ \ mathbf x } _ n } } } 
= \ frac { \ overline { { \ mathbf 
x } _ n } n \ mu } { 
\ sqrt n \ sigma } \ 的 概率分布 函 
\ F _ n x \ 对于 任 \ x 
\ 满足 \ \ lim _ { n \ rightarrow 
\ infty } F _ n x = \ lim 
_ { n \ rightarrow \ infty } P \ 
{ { \ mathbf y } _ n \ le 
x \ } \ \ = \ lim _ { 
n \ rightarrow \ infty } P \ { \ 
frac { \ sum _ { k = 1 } 
^ { n } { \ mathbf x } _ 
k n \ mu } { \ sqrt n \ 
sigma } \ le x \ } \ \ = 
\ int _ { \ infty } ^ { x 
} \ frac { 1 } { \ sqrt { 
2 \ pi } } e ^ { t ^ 
{ 2 } / 2 } dt = \ Phi 
x \ 其 物理 意义 为 均值 方差 为 \ 
\ mu \ sigma ^ { 2 } \ 的 
独立 同 分布 的 随机变量 \ { \ mathbf x 
} _ 1 { \ mathbf x } _ 2 
\ cdots { \ mathbf x } _ n \ 
之和 \ \ overline { { \ mathbf x } 
_ n } = \ sum _ { k = 
1 } ^ { n } { \ mathbf x 
} _ k \ 的 标准 变化 量 \ { 
\ mathbf y } _ n \ 当 \ n 
\ 充分 大 时 其 分布 近似 与 标准 正态分布 
即 \ \ overline { { \ mathbf x } 
_ n } = \ sum _ { k = 
1 } ^ { n } { \ mathbf x 
} _ k \ 在 \ n \ 充分 大 
时 其 分布 近似于 \ N n \ mu n 
\ sigma ^ { 2 } \ 一般 情况 下 
很难 求出 \ n \ 个 随机变量 之和 的 分布 
函数 因此当 \ n \ 充分 大 时 可以 通过 
正态分布 来做 理论上 的 分析 或者 计算 Liapunov 定理 设 
随 机变 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ cdots { 
\ mathbf x } _ n \ cdots \ 相互 
独立 具有 数学期望 和 方差 \ \ mathbb E { 
\ mathbf x } _ k = \ mu _ 
k Var { \ mathbf x } _ k = 
\ sigma _ k ^ { 2 } \ gt 
0 k = 1 2 \ cdots \ 记 \ 
B _ n ^ { 2 } = \ sum 
_ { k = 1 } ^ { n } 
\ sigma _ k ^ { 2 } \ 若 
存在 正 \ \ delta \ 使得 \ n \ 
rightarrow \ infty \ 时 \ \ frac { 1 
} { B _ n ^ { 2 + \ 
delta } } \ sum _ { k = 1 
} ^ { n } \ mathbb E | { 
\ mathbf x } _ k \ mu _ k 
| ^ { 2 + \ delta } \ rightarrow 
0 \ 则 随机变量 之 \ \ overline { { 
\ mathbf x } _ n } = \ sum 
_ { k = 1 } ^ { n } 
{ \ mathbf x } _ k \ 的 标准 
变化 量 \ Z _ n = \ frac { 
\ overline { { \ mathbf x } _ n 
} \ mathbb E \ overline { { \ mathbf 
x } _ n } } { \ sqrt { 
Var \ overline { { \ mathbf x } _ 
n } } } = \ frac { \ overline 
{ { \ mathbf x } _ n } \ 
sum _ { k = 1 } ^ { n 
} \ mu _ k } { B _ n 
} \ 的 概率分布 函 \ F _ n x 
\ 对于 任 \ x \ 满足 \ \ lim 
_ { n \ rightarrow \ infty } F _ 
n x = \ lim _ { n \ rightarrow 
\ infty } P \ { Z _ n \ 
le x \ } \ \ = \ lim _ 
{ n \ rightarrow \ infty } P \ { 
\ frac { \ sum _ { k = 1 
} ^ { n } { \ mathbf x } 
_ k \ sum _ { k = 1 } 
^ { n } \ mu _ k } { 
B _ n } \ le x \ } \ 
\ = \ int _ { \ infty } ^ 
{ x } \ frac { 1 } { \ 
sqrt { 2 \ pi } } e ^ { 
t ^ { 2 } / 2 } dt = 
\ Phi x \ 其 物理 意义 为 相互 独立 
的 随机变量 \ { \ mathbf x } _ 1 
{ \ mathbf x } _ 2 \ cdots { 
\ mathbf x } _ n \ cdots \ 之和 
\ \ overline { { \ mathbf x } _ 
n } = \ sum _ { k = 1 
} ^ { n } { \ mathbf x } 
_ k \ 的 衍生 随机变量 序 \ Z _ 
n = \ frac { \ overline { { \ 
mathbf x } _ n } \ sum _ { 
k = 1 } ^ { n } \ mu 
_ k } { B _ n } \ 当 
\ n \ 充分 大 时 其 分布 近似 与 
标准 正态分布 这里 并 不 要求 \ { \ mathbf 
x } _ 1 { \ mathbf x } _ 
2 \ cdots { \ mathbf x } _ n 
\ cdots \ 同 分布 Demoiver Laplace 定理 设 随机变量 
序 \ \ eta _ n n = 1 2 
. . . \ 服从 参数 \ n p 0 
\ lt p \ lt 1 \ 的 二项分布 则 
对于 任 \ x \ 有 \ \ lim _ 
{ n \ rightarrow \ infty } P \ { 
\ frac { \ eta _ n np } { 
\ sqrt { np 1 p } } \ le 
x \ } = \ int _ { \ infty 
} ^ { x } \ frac { 1 } 
{ \ sqrt { 2 \ pi } } e 
^ { t ^ { 2 } \ mid 2 
} dt = \ Phi x \ 该 定理 表明 
正态分布 是 二项分布 的 极限 分布 当 \ n \ 
充分 大 时 可以 利用 正态分布 来 计算 二项分布 的 
概率 五 不确定性 来源 机器学习 中 不确定性 有 三个 来源 
模型 本身 固有 的 随机性 如 量子力学 中的 粒子 动力学 
方程 不 完全 的 观测 即使 是 确定性 系统 当 
无法 观测 所有 驱动 变量 时 结果 也 是 随机 
的 不 完全 建模 有时 必须 放弃 一些 观测 信息 
如 机器人 建模 中 虽然 可以 精确 观察 机器人 周围 
每个 对象 的 位置 但在 预测 这些 对象 将来 的 
位置 时 对 空间 进行 了 离散化 则 位置 预测 
将 带有 不确定性 六 常见 概率分布 6.1 均匀分布 离散 随机变量 
的 均匀分布 假 \ \ mathbf x \ \ k 
\ 个 取值 \ x _ 1 x _ 2 
\ cdots x _ k \ 则 均匀分布 的 概率密度函数 
probability mass function PMF 为 \ P \ mathbf x 
= x _ i = \ frac 1k \ quad 
i = 1 2 \ cdots k \ 连续 随机变量 
的 均匀分布 假 \ \ mathbf x \ 在 a 
b 上 均匀分布 则 其 概率密度函数 probability density function PDF 
为 \ p \ mathbf x = x = \ 
begin { cases } 0 & x \ notin a 
b \ \ \ frac { 1 } { b 
a } & x \ in a b \ \ 
\ end { cases } \ 6.2 二项分布 伯努利 分布 
二项分布 参数 \ \ phi \ in 0 1 \ 
随 机变 \ \ mathbf x \ in \ { 
0 1 \ } \ 概率分布 函数 为 \ P 
\ mathbf x = x = \ phi ^ { 
x } 1 \ phi ^ { 1 x } 
\ x \ in \ { 0 1 \ } 
\ 期望 \ \ mathbb E _ { \ mathbf 
x } x = \ phi \ 方差 \ Var 
_ { \ mathbf x } x = \ phi 
1 \ phi \ categorical 分布 它 是 二项分布 的 
推广 也 称作 multinoulli 分布 假设 随 机变 \ \ 
mathbf x \ in \ { 1 2 \ cdots 
K \ } \ 其 概率分布 函数 为 \ P 
\ mathbf x = 1 = \ theta _ 1 
\ \ P \ mathbf x = 2 = \ 
theta _ 2 \ \ \ vdots \ \ P 
\ mathbf x = K 1 = \ theta _ 
{ K 1 } \ \ P \ mathbf x 
= K = 1 \ sum _ { i = 
1 } ^ { K 1 } \ theta _ 
i \ \ \ 其 \ \ theta _ i 
\ 为 参数 它 满 \ \ theta _ i 
\ in 0 1 \ \ \ sum _ { 
i = 1 } ^ { K 1 } \ 
theta _ i \ in 0 1 \ 6.3 高斯分布 
6 . 3.1 一维 正态分布 正态分布 的 概率密度函数 为 \ 
p x = \ frac { 1 } { \ 
sqrt { 2 \ pi } \ sigma } e 
^ { x \ mu ^ { 2 } / 
2 \ sigma ^ { 2 } } \ infty 
\ lt x \ lt \ infty \ 其 $ 
\ mu \ sigma \ sigma \ gt 0 $ 
为 常数 若 随机变量 \ { \ mathbf x } 
\ 的 概率密度函数 如上所述 则 称 \ { \ mathbf 
x } \ 服从 参数 为 \ \ mu \ 
sigma \ 的 正态分布 或者 高斯分布 记作 \ { \ 
mathbf x } \ sim N \ mu \ sigma 
^ { 2 } \ 特别 的 当 \ \ 
mu = 0 \ sigma = 1 \ 时 称为 
标准 正态分布 其 概率密度函数 记作 \ \ varphi x \ 
分布 函数 记作 \ \ Phi x \ 为了 计算 
方便 有时 也 记作 \ \ mathcal N x \ 
mu \ beta ^ { 1 } = \ sqrt 
{ \ frac { \ beta } { 2 \ 
pi } } \ exp \ left \ frac { 
1 } { 2 } \ beta x \ mu 
^ { 2 } \ right \ 其 \ \ 
beta \ in 0 \ infty \ 正态分布 是 很多 
应用 中 的 合理 选择 如果 某个 随机变量 取值 范围 
是 实数 且 对 它 的 概率分布 一无所知 通常会 假设 
它 服从 正态分布 有 两个 原因 支持 这 一 选择 
建模 的 任务 的 真实 分布 通常 都 确实 接近 
正态分布 中心 极限 定理 表明 多个 独立 随机变量 的 和 
近似 正态分布 在 具有 相同 方差 的 所有 可能 的 
概率分布 中 正态分布 的 熵 最大 即 不确定性 最大 正态分布 
的 概率密度 函数性质 曲线 关于 \ x = \ mu 
\ 对称 曲线 在 \ x = \ mu \ 
时取 最大值 曲线 在 $ x = \ mu \ 
pm \ sigma $ 处 有 拐点 参 \ \ 
mu \ 决定 曲线 的 位置 \ \ sigma \ 
决定 图形 的 胖瘦 \ { \ mathbf x } 
\ sim N \ mu \ sigma ^ { 2 
} \ 则 \ \ frac { { \ mathbf 
x } \ mu } { \ sigma } \ 
sim N 0 1 \ 有限 个 相互 独立 的 
正 态 随机变量 的 线性组合 仍然 服从 正态分布 正态分布 的 
期望 就 \ \ mu \ 方差 就 \ \ 
sigma ^ { 2 } \ 若 随 机变 \ 
{ \ mathbf x } _ i \ sim N 
\ mu _ i \ sigma _ i ^ { 
2 } i = 1 2 \ cdots n \ 
且 它们 相互 独立 则 它们 的 线性组合 \ C 
_ 1 { \ mathbf x } _ 1 + 
C _ 2 { \ mathbf x } _ 2 
+ \ cdots + C _ n { \ mathbf 
x } _ n \ 其中 \ C _ 1 
C _ 2 \ cdots C _ n \ 不全是 
为 0 的 常数 仍然 服从 正态分布 且 \ C 
_ 1 { \ mathbf x } _ 1 + 
C _ 2 { \ mathbf x } _ 2 
+ \ cdots + C _ n { \ mathbf 
x } _ n \ sim N \ sum _ 
{ i = 1 } ^ { n } C 
_ i \ mu _ i \ sum _ { 
i = 1 } ^ { n } C _ 
i ^ { 2 } \ sigma _ i ^ 
{ 2 } \ 6 . 3.2 多维 正态分布 二维 
正 态 随 机变 \ { \ mathbf x } 
_ 1 { \ mathbf x } _ 2 \ 
的 概率 密度 为 \ p x _ 1 x 
_ 2 = \ \ \ frac { 1 } 
{ 2 \ pi \ sigma _ 1 \ sigma 
_ 2 \ sqrt { 1 \ rho ^ { 
2 } } } \ exp \ { \ frac 
{ 1 } { 2 1 \ rho ^ { 
2 } } \ frac { x _ 1 \ 
mu _ 1 ^ { 2 } } { \ 
sigma _ 1 ^ { 2 } } 2 \ 
rho \ frac { x _ 1 \ mu _ 
1 x _ 2 \ mu _ 2 } { 
\ sigma _ 1 \ sigma _ 2 } + 
\ frac { x _ 2 \ mu _ 2 
^ { 2 } } { \ sigma _ 2 
^ { 2 } } \ } \ 可以 计算出 
\ p _ { \ mathbf x } x = 
\ frac { 1 } { \ sqrt { 2 
\ pi } \ sigma _ 1 } e ^ 
{ x \ mu _ 1 ^ { 2 } 
/ 2 \ sigma _ 1 ^ { 2 } 
} \ infty \ lt x \ lt \ infty 
\ \ p _ { \ mathbf y } y 
= \ frac { 1 } { \ sqrt { 
2 \ pi } \ sigma _ 2 } e 
^ { y \ mu _ 2 ^ { 2 
} / 2 \ sigma _ 2 ^ { 2 
} } \ infty \ lt y \ lt \ 
infty \ \ \ mathbb E { \ mathbf x 
} = \ mu _ 1 \ \ \ mathbb 
E { \ mathbf y } = \ mu _ 
2 \ \ Var { \ mathbf x } = 
\ sigma _ 1 ^ { 2 } \ \ 
Var { \ mathbf y } = \ sigma _ 
2 ^ { 2 } \ \ Cov { \ 
mathbf x } { \ mathbf y } = \ 
int _ { \ infty } ^ { \ infty 
} \ int _ { \ infty } ^ { 
\ infty } x \ mu _ 1 y \ 
mu _ 2 p x y dxdy = \ rho 
\ sigma _ 1 \ sigma _ 2 \ \ 
\ rho _ { { \ mathbf x } { 
\ mathbf y } } = \ rho \ 引入 
矩阵 \ \ mathbf { \ vec { \ mathbf 
x } } = \ begin { bmatrix } x 
_ 1 \ \ x _ 2 \ end { 
bmatrix } \ quad \ mathbf { \ vec \ 
mu } = \ begin { bmatrix } \ mu 
_ 1 \ \ \ mu _ 2 \ end 
{ bmatrix } \ \ \ mathbf { \ Sigma 
} = \ begin { bmatrix } c _ { 
11 } & c _ { 12 } \ \ 
c _ { 21 } & c _ { 22 
} \ end { bmatrix } = \ begin { 
bmatrix } \ sigma _ 1 ^ { 2 } 
& \ rho \ sigma _ 1 \ sigma _ 
2 \ \ \ rho \ sigma _ 1 \ 
sigma _ 2 & \ sigma _ 2 ^ { 
2 } \ end { bmatrix } \ \ \ 
mathbf \ Sigma \ \ { \ mathbf x } 
_ 1 { \ mathbf x } _ 2 \ 
的 协方差 矩阵 其 行列式 \ \ det \ mathbf 
{ \ Sigma } = \ sigma _ 1 ^ 
{ 2 } \ sigma _ 2 ^ { 2 
} 1 \ rho ^ { 2 } \ 其 
逆 矩阵 为 \ \ mathbf { \ Sigma } 
^ { 1 } = \ frac { 1 } 
{ \ det \ mathbf \ Sigma } \ begin 
{ bmatrix } \ sigma _ 2 ^ { 2 
} & \ rho \ sigma _ 1 \ sigma 
_ 2 \ \ \ rho \ sigma _ 1 
\ sigma _ 2 & \ sigma _ 1 ^ 
{ 2 } \ end { bmatrix } \ 于 
\ { \ mathbf x } _ 1 { \ 
mathbf x } _ 2 \ 的 概率密度函数 可以 写 
\ \ mathbf { \ vec { \ mathbf x 
} } \ mathbf { \ vec \ mu } 
^ { T } \ 表示 矩阵 的 转置 \ 
p x _ 1 x _ 2 = \ frac 
{ 1 } { 2 \ pi \ det \ 
mathbf \ Sigma ^ { 1 / 2 } } 
\ exp \ { \ frac 12 \ mathbf { 
\ vec { \ mathbf x } } \ mathbf 
{ \ vec \ mu } ^ { T } 
\ mathbf \ Sigma ^ { 1 } \ mathbf 
{ \ vec { \ mathbf x } } \ 
mathbf { \ vec \ mu } \ } \ 
其中 均 \ \ mu _ 1 \ mu _ 
2 \ 决定 了 曲面 的 位置 本例 中 均值 
都为 0 标准 \ \ sigma _ 1 \ sigma 
_ 2 \ 决定 了 曲面 的 陡峭 程度 本例 
中 方差 都为 1 \ \ rho \ 决定了 协方差 
矩阵 的 形状 从而 决定 了 曲面 的 形状 \ 
\ rho = 0 \ 时 协方差 矩阵 对角线 非零 
其他 位置 均 为零 此 时 表示 随机变量 之间 不 
相关 此时 的 联合 分布 概率函数 形状 如下 图 所示 
曲面 在 \ z = 0 \ 平面 的 截面 
是个 圆形 \ \ rho = 0.5 \ 时 协方差 
矩阵 对角线 非零 其他 位置 均 为零 此 时 表示 
随机变量 之间 相关 此时 的 联合 分布 概率函数 形状 如下 
图 所示 曲面 在 \ z = 0 \ 平面 
的 截面 是个 椭圆 相当于 圆形 沿着 直线 \ y 
= x \ 方向 压缩 \ \ rho = 1 
\ 时 协方差 矩阵 对角线 非零 其他 位置 均 为零 
此 时 表示 随机变量 之间 完全 相关 此时 的 联合 
分布 概率函数 形状 为 曲面 在 \ z = 0 
\ 平面 的 截面 是 直线 \ y = x 
\ 相当于 圆形 沿着 直线 \ y = x \ 
方向 压缩 成 一条 直线 由于 \ \ rho = 
1 \ 会 导致 除数 为 0 因此 这里 给出 
\ \ rho = 0.9 \ 多维 正 态 随 
机变 \ { \ mathbf x } _ 1 { 
\ mathbf x } _ 2 \ cdots { \ 
mathbf x } _ n \ 引入 列矩阵 \ \ 
mathbf { \ vec { \ mathbf x } } 
= \ begin { bmatrix } x _ 1 \ 
\ x _ 2 \ \ \ vdots \ \ 
x _ n \ end { bmatrix } \ quad 
\ mathbf { \ vec \ mu } = \ 
begin { bmatrix } \ mu _ 1 \ \ 
\ mu _ 2 \ \ \ vdots \ \ 
\ mu _ n \ end { bmatrix } = 
\ begin { bmatrix } \ mathbb E { \ 
mathbf x } _ 1 \ \ \ mathbb E 
{ \ mathbf x } _ 2 \ \ \ 
vdots \ \ \ mathbb E { \ mathbf x 
} _ n \ end { bmatrix } \ \ 
\ mathbf \ Sigma \ \ { \ mathbf x 
} _ 1 { \ mathbf x } _ 2 
\ cdots { \ mathbf x } _ n \ 
的 协方差 矩阵 则 \ p x _ 1 x 
_ 2 x _ 3 \ cdots x _ n 
= \ frac { 1 } { 2 \ pi 
^ { n / 2 } \ det \ mathbf 
\ Sigma ^ { 1/2 } } \ exp \ 
{ \ frac 12 \ mathbf { \ vec { 
\ mathbf x } } \ mathbf { \ vec 
\ mu } ^ { T } \ mathbf \ 
Sigma ^ { 1 } \ mathbf { \ vec 
{ \ mathbf x } } \ mathbf { \ 
vec \ mu } \ } \ 记 做 \ 
\ mathcal N \ mathbf { \ vec x } 
\ mathbf { \ vec \ mu } \ mathbf 
\ Sigma = \ sqrt { \ frac { 1 
} { 2 \ pi ^ { n } det 
\ mathbf \ Sigma } } \ exp \ left 
\ frac 12 \ mathbf { \ vec x \ 
vec \ mu } ^ { T } \ mathbf 
\ Sigma ^ { 1 } \ mathbf { \ 
vec x \ vec \ mu } \ right \ 
\ n \ 维 正态变量 具有 下列 四条 性质 \ 
n \ 维 正态变量 的 每一个 分量 都是 正态变量 反之 
\ { \ mathbf x } _ 1 { \ 
mathbf x } _ 2 \ cdots { \ mathbf 
x } _ n \ 都是 正态变量 且 相互 独立 
\ { \ mathbf x } _ 1 { \ 
mathbf x } _ 2 \ cdots { \ mathbf 
x } _ n \ \ n \ 维 正态变量 
\ n \ 维 随 机变 \ { \ mathbf 
x } _ 1 { \ mathbf x } _ 
2 \ cdots { \ mathbf x } _ n 
\ 服 \ n \ 维 正态分布 的 充要条件 \ 
{ \ mathbf x } _ 1 { \ mathbf 
x } _ 2 \ cdots { \ mathbf x 
} _ n \ 的 任意 线性组合 \ l _ 
1 { \ mathbf x } _ 1 + l 
_ 2 { \ mathbf x } _ 2 + 
\ cdots + l _ n { \ mathbf x 
} _ n \ 服从 一维 正态分布 其 \ l 
_ 1 l _ 2 \ cdots l _ n 
\ 不 全为 0 \ { \ mathbf x } 
_ 1 { \ mathbf x } _ 2 \ 
cdots { \ mathbf x } _ n \ 服 
\ n \ 维 正态分布 \ { \ mathbf y 
} _ 1 { \ mathbf y } _ 2 
\ cdots { \ mathbf y } _ k \ 
\ { \ mathbf x } _ j j = 
1 2 \ cdots n \ 的 线性函数 \ { 
\ mathbf y } _ 1 { \ mathbf y 
} _ 2 \ cdots { \ mathbf y } 
_ k \ 也 服从 多维 正态分布 这一 性质 称为 
正态变量 的 线性变换 不变性 \ { \ mathbf x } 
_ 1 { \ mathbf x } _ 2 \ 
cdots { \ mathbf x } _ n \ 服 
\ n \ 维 正态分布 \ { \ mathbf x 
} _ 1 { \ mathbf x } _ 2 
\ cdots { \ mathbf x } _ n \ 
相互 独 \ \ L o n g l e 
f t r i g h t a r r 
o w \ \ { \ mathbf x } _ 
1 { \ mathbf x } _ 2 \ cdots 
{ \ mathbf x } _ n \ 两两 不相关 
6.4 指数分布 指数分布 概率密度函数 \ p x \ lambda = 
\ begin { cases } 0 & x \ lt0 
\ \ \ frac { \ lambda } { \ 
exp \ lambda x } & x \ ge0 \ 
\ \ end { cases } \ 期望 \ \ 
mathbb E _ { \ mathbf x } x = 
\ frac { 1 } { \ lambda } \ 
方差 \ Var _ { \ mathbf x } x 
= \ frac { 1 } { \ lambda ^ 
{ 2 } } \ 6.5 拉普拉斯 分布 拉普拉斯 分布 
概率密度函数 \ p x \ mu \ gamma = \ 
frac { 1 } { 2 \ gamma } \ 
exp \ left \ frac { | x \ mu 
| } { \ gamma } \ right \ 期望 
\ \ mathbb E _ { \ mathbf x } 
x = \ mu \ 方差 \ Var _ { 
\ mathbf x } x = 2 \ gamma ^ 
{ 2 } \ 6.6 狄拉克 分布 狄拉克 分布 假设 
所有 的 概率 都 集中 在 一 \ \ mu 
\ 上 则 对应 的 概率密度函数 为 \ p x 
= \ delta x \ mu \ 其 \ \ 
delta \ cdot \ 为 狄拉克 函数 其 性质 为 
\ \ delta x = 0 \ forall x \ 
neq 0 \ int _ { \ infty } ^ 
{ \ infty } \ delta x dx = 1 
\ 狄拉克 分布 的 一个 典型用途 就是 定义 连续型 随机变量 
的 经验 分布 函数 假设 数据 集中 有样 \ \ 
mathbf { \ vec x } _ 1 \ mathbf 
{ \ vec x } _ 2 \ cdots \ 
mathbf { \ vec x } _ N \ 则 
定义 经验 分布 函数 \ \ hat p \ mathbf 
{ \ vec x } = \ frac 1N \ 
sum _ { i = 1 } ^ { N 
} \ delta \ mathbf { \ vec x } 
\ mathbf { \ vec x } _ i \ 
它 就是 对 每个 样本 赋予 了 一个 概率 质 
\ \ frac 1N \ 对于 离散 型 随机变量 的 
经验 分布 则 经验 分布 函数 就是 multinoulli 分布 它 
简单 地 等于 训练 集中 的 经验 频率 经验 分布 
的 两个 作用 通过 查看 训练 集 样本 的 经验 
分布 从而 指定 该 训练 集 的 样本 采样 的 
分布 保证 采样 之后 的 分布 不 失真 经验 分布 
就是 使得 训练 数据 的 可能性 最大化 的 概率密度函数 6.7 
多项式 分布 与 狄里/nr 克雷 分布 多项式 分布 的 质量 
密度 函数 \ Mult m _ 1 m _ 2 
\ cdots m _ K \ vec \ mu N 
= \ frac { N } { m _ 1 
m _ 2 \ cdots m _ K } \ 
prod _ { k = 1 } ^ { K 
} \ mu _ k ^ { m _ k 
} \ 它 \ \ mu _ 1 + \ 
mu _ 2 + \ cdots + \ mu _ 
K ^ { m _ 1 + m _ 2 
+ \ cdots + m _ K } \ 的 
多项式 展开 的 形式 狄利克雷 分布 的 概率密度函数 \ Dir 
\ vec \ mu \ vec \ alpha = \ 
frac { \ Gamma \ sum _ { k = 
1 } ^ { K } \ alpha _ k 
} { \ sum _ { k = 1 } 
^ { K } \ Gamma \ alpha _ k 
} \ prod _ { k = 1 } ^ 
{ K } \ mu _ k ^ { \ 
alpha _ k 1 } \ 可以 看到 多项式 分布 
与 狄里/nr 克雷 分布 的 概率密度函数 非常 相似 区别 仅仅 
在于 前面 的 归一化 项 多项式 分布 是 针对 离散 
型 随机变量 通过/p 求和/v 获取/v 概率/n 狄里/nr 克雷/nr 分布/v 时/n 
针对/p 连续型/n 随机变量/l 通过 求积分 来 获取 概率 6.8 混合 
概率分布 混合 概率分布 它 组合 了 其他 几个 分量 的 
分布 来 组成 在 每次 生成 样本 中 首先 通过 
multinoulli 分布 来 决定 选 用 哪个 分量 然后 由该 
分量 的 分布 函 数来 生成 样本 其 概率分布 函数 
为 \ P \ mathbf x = \ sum _ 
{ i } P c = i P \ mathbf 
x \ mid c = i \ 其 \ P 
c = i \ 为 一个 multinoulli 分布 \ c 
\ 的 取值 范围 就是 各 分量 的 编号 前面 
介绍 的 连续型 随机变量 的 经验 分布 函数 就是 一个 
混合 概率分布 的 例子 此 \ P c = i 
= \ frac 1N \ 混合 概率分布 可以 通过 简单 
的 概率分布 创建 更 复杂 的 概率分布 一个 常见 的 
例子 是 混合 高斯 模型 其 \ P \ mathbf 
x \ mid c = i \ 为 高斯 模型 
每个 分量 都有 对应 的 参 \ \ mathbf { 
\ vec \ mu } _ i \ mathbf \ 
Sigma _ i \ 有些 混合 高斯 模型 有 更强 
的 约束 如 \ \ forall i \ mathbf \ 
Sigma _ i = \ mathbf \ Sigma \ 更进一步 
还 可以 要求 \ \ mathbf \ Sigma \ 为 
一个 对角 矩阵 混合 高斯 模型 是 一个 通用 的 
概率密度函数 逼近 工具 任何 平滑 的 概率密度函数 都 可以 通过 
足够 多 分量 的 混合 高斯 模型 来 逼近 七 
先验 分布 与 后验/nr 分布 在 贝叶斯 学派 中 先验 
分布 + 数据 似 然 = 后验/nr 分布 例如 假设 
需要 识别 一大 箱 苹果 中的 好 苹果 坏 苹果 
的 概率 根据 你 对 苹果 好 坏 的 认知 
给出 先验 分布 为 50个 好 苹果 和 50个 坏 
苹果 现在 你 拿出 10个 苹果 发现 有 8个 好 
苹果 2个 坏 苹果 根据 数据 你 得到 后验/nr 分布 
为 58个 好 苹果 52个 坏 苹果 再 拿出 10个 
苹果 发现 有 9个 好 苹果 1个 坏 苹果 根据 
数据 你 得到 后验/nr 分布 为 67个 好 苹果 53个 
坏 苹果 这样 不断 重复 下去 不断 更新 后验/nr 分布 
当 一箱 苹果 清点 完毕 则 得到 了 最终 的 
后验/nr 分布 在 这里 如果 不 使用 先验 分布 仅仅 
清点 这 箱 苹果 中 的 好坏 则 得到 的 
分布 只能 代表 这 一箱 苹果 采用 了 先验 分布 
之后 得到 的 分布 可以 认为 是 所有 箱子 里 
的 苹果 的 分布 先验 分布 时 给出 的 好 
坏 苹果 的 个数 也 就是 频数 越大 则 先验 
分布 越占 主导地位 假 设好 苹果 的 概率 \ p 
\ 则 抽 \ N \ 个 苹果 中 好 
苹果 个数 \ k \ 个 的 概率 为 一个 
二项分布 \ Binom k \ mid p N = C 
_ N ^ kp ^ k 1 p ^ { 
N k } \ 其 \ C _ N ^ 
k \ 为 组合 数 现在 的 问题 是 好 
苹果 的 概 \ p \ 不再 固定 而是 服从 
一个 分布 假 设好 苹果 的 概 \ p \ 
的 先验 分布 为 贝塔 分布 \ Beta p \ 
alpha \ beta = \ frac { \ Gamma \ 
alpha + \ beta } { \ Gamma \ alpha 
\ Gamma \ beta } p ^ { \ alpha 
1 } 1 p ^ { \ beta 1 } 
\ 则 后验/nr 概率 为 \ P p \ mid 
k N \ alpha \ beta = \ frac { 
P k \ mid p N \ times P p 
\ alpha \ beta } { P k N \ 
alpha \ beta } \ \ \ propto P k 
\ mid p N \ times P p \ alpha 
\ beta = C _ N ^ kp ^ k 
1 p ^ { N k } \ times \ 
frac { \ Gamma \ alpha + \ beta } 
{ \ Gamma \ alpha \ Gamma \ beta } 
p ^ { \ alpha 1 } 1 p ^ 
{ \ beta 1 } \ \ \ propto p 
^ { k + \ alpha 1 } 1 p 
^ { N k + \ beta 1 } \ 
归一化 之后 得到 后验/nr 概率 为 \ P p \ 
mid k N \ alpha \ beta = \ frac 
{ \ Gamma \ alpha + \ beta + N 
} { \ Gamma \ alpha + k \ Gamma 
\ beta + N k } p ^ { k 
+ \ alpha 1 } 1 p ^ { N 
k + \ beta 1 } \ 好 苹果 概 
\ p \ 的 先验 分布 的 期望 为 \ 
\ mathbb E p = \ frac { \ alpha 
} { \ alpha + \ beta } \ 好 
苹果 概 \ p \ 的 后验/nr 分布 的 期望 
为 \ \ mathbb E p \ mid k = 
\ frac { \ alpha + k } { \ 
alpha + \ beta + N } \ 根据上述 例子 
所述 好 苹果 的 先验概率 的 期望 为 \ \ 
frac { 50 } { 50 + 50 } = 
\ frac 12 \ 进行 第一轮 数据 校验 之后 好 
苹果 的 后验/nr 概率 的 期望 为 \ \ frac 
{ 50 + 8 } { 50 + 50 + 
10 } = \ frac { 58 } { 110 
} \ 如果 \ \ alpha \ 视为 先验 的 
好 苹果 数量 \ \ beta \ 视为 先验 的 
坏 苹果 数量 \ N \ 表示 箱子 中 苹果 
的 数量 \ k \ 表示 箱子 中的 好 苹果 
数量 相应 的 \ N k \ 就是 箱子 中 
坏 苹果 的 数量 则 好 苹果 的 先验概率 分布 
的 期望 后验/nr 概率分布 的 期望 符合 人们 的 生活 
经验 这里/r 使用/v 先验/n 分布/v 和后验/nr 分布/v 的/uj 期望/v 因 
\ p \ 是 一个 随机变量 若想 通过 一个 数值 
来 刻 画好 苹果 的 可能性 则用 期望 较好 更 
一般 的 如果 苹果 不 仅仅 分为 好 坏 两种 
而是 分作 尺寸 1 尺寸 2 . . . 尺 
\ K \ 等 \ N \ 个 苹果 中 
\ m _ 1 \ 个 尺寸 1 的 苹果 
\ m _ 2 \ 个 尺寸 2 的 苹果 
. . . \ m _ K \ 个 尺 
\ K \ 的 苹果 的 概率 服从 多项式 分布 
\ Mult m _ 1 m _ 2 \ cdots 
m _ K \ vec \ mu N = \ 
frac { N } { m _ 1 m _ 
2 \ cdots m _ K } \ prod _ 
{ k = 1 } ^ { K } \ 
mu _ k ^ { m _ k } \ 
其中 苹果 为 尺寸 1 的 概率 \ \ mu 
_ 1 \ 尺寸 2 的 概率 \ \ mu 
_ 2 \ . . . 尺 \ K \ 
的 概率 \ \ mu _ K \ \ N 
= \ sum _ { k = 1 } ^ 
Km _ k \ 假设 苹果 尺寸 的 先验概率 分布 
为 狄利克雷 分布 \ Dir \ vec \ mu \ 
vec \ alpha = \ frac { \ Gamma \ 
sum _ { k = 1 } ^ { K 
} \ alpha _ k } { \ sum _ 
{ k = 1 } ^ { K } \ 
Gamma \ alpha _ k } \ prod _ { 
k = 1 } ^ { K } \ mu 
_ k ^ { \ alpha _ k 1 } 
\ 苹果 尺寸 的 先验概率 分布 的 期望 为 \ 
\ mathbb E \ vec \ mu = \ left 
\ frac { \ alpha _ 1 } { \ 
sum _ { k = 1 } ^ K \ 
alpha _ k } \ frac { \ alpha _ 
2 } { \ sum _ { k = 1 
} ^ K \ alpha _ k } \ cdots 
\ frac { \ alpha _ K } { \ 
sum _ { k = 1 } ^ K \ 
alpha _ k } \ right \ 则/d 苹果/n 尺寸/n 
的/uj 后验/nr 概率分布/n 也为/i 狄里/nr 克雷/nr 分布/v \ Dir \ 
vec \ mu \ vec \ alpha + \ mathbf 
{ \ vec m } = \ frac { \ 
Gamma N + \ sum _ { k = 1 
} ^ { K } \ alpha _ k } 
{ \ sum _ { k = 1 } ^ 
{ K } \ Gamma \ alpha _ k + 
m _ k } \ prod _ { k = 
1 } ^ { K } \ mu _ k 
^ { \ alpha _ k + m _ k 
1 } \ 苹果 尺寸 的 后验/nr 概率分布 的 期望 
为 \ \ mathbb E \ vec \ mu = 
\ left \ frac { \ alpha _ 1 + 
m _ 1 } { N + \ sum _ 
{ k = 1 } ^ K \ alpha _ 
k } \ frac { \ alpha _ 2 + 
m _ 2 } { N + \ sum _ 
{ k = 1 } ^ K \ alpha _ 
k } \ cdots \ frac { \ alpha _ 
K + m _ K } { N + \ 
sum _ { k = 1 } ^ K \ 
alpha _ k } \ right \ 八 测度论 测度 
为零 非 正式化 的 提法 是 如果 集合 中的 点 
的 数量 可以 忽略不计 则 该 集合 的 测度 为零 
如 二维 空间 中 的 直线 的 测度 为零 而 
正方形 的 测度 非零 几乎 处处 相等 不 满足 条件 
的 那些 点 组成 的 集合 的 测度 为零 假设 
随 机变 \ \ mathbf x \ mathbf y \ 
满 \ \ mathbf y = g \ mathbf x 
\ 且 函 \ g \ cdot \ 满足 处处 
连续 可导 且 存在 反函数 则有 \ p _ { 
\ mathbf x } x = p _ { \ 
mathbf y } g x \ left | \ frac 
{ \ partial g x } { \ partial x 
} \ right | \ 或者 等价 地 \ p 
_ { \ mathbf y } y = p _ 
{ \ mathbf x } g ^ { 1 } 
y \ left | \ frac { \ partial x 
} { \ partial y } \ right | \ 
如果 扩展到 高维空间 则有 \ p _ { \ mathbf 
x } \ mathbf { \ vec x } = 
p _ { \ mathbf y } g \ mathbf 
{ \ vec x } \ left | \ det 
\ left \ frac { \ partial g \ mathbf 
{ \ vec x } } { \ partial \ 
mathbf { \ vec x } } \ right \ 
right | \ 并不 \ p _ { \ mathbf 
y } y = p _ { \ mathbf x 
} g ^ { 1 } y \ 这是 因 
\ g \ cdot \ 引起 了 空间 扭曲 从而 
导 \ \ int p _ { \ mathbf x 
} g x dx \ neq 1 \ 其实 我们 
有 \ | p _ { \ mathbf y } 
g x dy | = | p _ { \ 
mathbf x } x dx | \ 求解 该 方程 
即 得到 上述 解 九 信息论 信息论 背后 的 原理 
是 从不 太 可能 发生 的 事件 中 能学 到 
更多 的 有用 信息 发生 可能性 较大 的 事件 包含 
较少 的 信息 发生 可能性 较小 的 事件 包含 较多 
的 信息 独立 事件 包含 额外 的 信息 对 于事 
\ \ mathbf x = x \ 定义 自 信息 
self information 为 \ I x = \ log P 
x \ 自 信息 仅仅 处理 单个 输出 但是 如果 
计算 自 信息 的 期望 它 就是 熵 \ H 
\ mathbf x = \ mathbb E _ { \ 
mathbf x \ sim P } I x = \ 
mathbb E _ { \ mathbf x \ sim P 
} \ log P x \ 记 \ H P 
\ 熵 刻画 了 按照 真实 分 \ P \ 
来 识别 一个样 本所 需要 的 编码 长度 的 期望 
即 平均 编码 长度 如 含有 4个 字母 A B 
C D 的 样本 集中 真实 分 \ P = 
\ frac 12 \ frac 12 0 0 \ 则 
只 需要 1位 编码 即可 识别 样本 KL 散度 对于 
给定 的 随机 变 \ \ mathbf x \ 它 
的 两个 概率分布 函 \ P x \ \ Q 
x \ 的 区别 可以 用 KL 散度 来 度量 
\ D _ { KL } P | | Q 
= \ mathbb E _ { \ mathbf x \ 
sim P } \ left \ log \ frac { 
P x } { Q x } \ right = 
\ mathbb E _ { \ mathbf x \ sim 
P } \ left \ log P x \ log 
Q x \ right \ KL 散度 非 负 当 
它 为 0时 当且仅当 P 和Q是/nr 同一 个 分布 对于 
离散 型 随机变量 或者 两个 分布 几乎 处处 相等 对于 
连续型 随机变量 \ D _ { KL } P | 
| Q \ neq D _ { KL } Q 
| | P \ 交叉 熵 cross entropy \ H 
P Q = H P + D _ { KL 
} P | | Q = \ mathbb E _ 
{ \ mathbf x \ sim P } \ log 
Q x \ 交叉 熵 刻画 了 使用 错误 分 
\ Q \ 来 表示 真实 分 \ P \ 
中的 样本 的 平均 编码 长度 \ D _ { 
KL P | | Q } \ 刻画 了 错误 
分 \ Q \ 编码 真实 分 \ P \ 
带来 的 平均 编码 长度 的 增量 数值 计算 一 
数值 稳定性 1.1 近似 误差 在 计算机 中 执行 数学 
运算 需要 使用 有限 的 比特 位 来 表达 实数 
这会 引入 近似 误差 近似 误差 可以 在 多步 数值 
运算 中 传递 积累 从而/c 导致/v 理论/n 上/f 成功/a 的/uj 
算法/n 失败/v 数值/n 算法/n 设计/vn 时要/nr 考虑/v 将/d 累计/v 误差/n 
最小/a 化上/i 溢出/v overflow/w 和下/nr 溢出/v underflow/w 一种 严重 的 
误差 是 下 溢出 当 接近 零 的 数字 四舍五入 
为 零时 发生 下溢 出 许多 函数 在 参数 为 
零和 参数 为 一个 非常 小 的 正数 时 行为 
是 不同 的 如 对数函数 要求 自变量 大于 零 除法 
中 要求 除数 非零 另一种 严重 的 误差 是 上 
溢出 当 数值 非常大 超过 了 计算机 的 表示 范围 
时 发生 上 溢出 1.2 softmax 函数 一个 数值 稳定性 
的 例子 是 softmax 函数 \ \ mathbf { \ 
vec x } = x _ 1 x _ 2 
\ cdots x _ n ^ { T } \ 
则 softmax 函数 定义 为 \ \ text { softmax 
} \ mathbf { \ vec x } = \ 
left \ frac { \ exp x _ 1 } 
{ \ sum _ { j = 1 } ^ 
{ n } \ exp x _ j } \ 
frac { \ exp x _ 2 } { \ 
sum _ { j = 1 } ^ { n 
} \ exp x _ j } \ cdots \ 
frac { \ exp x _ n } { \ 
sum _ { j = 1 } ^ { n 
} \ exp x _ j } \ right ^ 
{ T } \ 当 所有 \ x _ i 
\ 都 等于 常 \ c \ 时 softmax 函数 
的 每个 分量 的 理论值 都 \ \ frac 1n 
\ 考虑 \ c \ 是 一个 非常 大 的 
负数 比如 趋近 负无穷 此时 \ \ exp c \ 
下 溢出 此时 $ \ frac { \ exp c 
} { \ sum _ { j = 1 } 
^ { n } \ exp c } $ 分母 
为零 结果 未定义 考虑 \ c \ 是 一个 非常 
大 的 正数 比如 趋近 正无穷 此时 \ \ exp 
c \ 上 溢出 $ \ frac { \ exp 
c } { \ sum _ { j = 1 
} ^ { n } \ exp c } $ 
的 结果 未定义 解决 的 办法 是 \ \ mathbf 
{ \ vec z } = \ mathbf { \ 
vec x } \ max _ i x _ i 
\ 则 $ \ text { softmax } \ mathbf 
{ \ vec z } $ 的 \ i \ 
个 分量 为 \ \ text { softmax } \ 
mathbf { \ vec z } _ i = \ 
frac { \ exp z _ i } { \ 
sum _ { j = 1 } ^ { n 
} \ exp z _ j } = \ frac 
{ \ exp \ max _ k x _ k 
\ exp z _ i } { \ exp \ 
max _ k x _ k \ sum _ { 
j = 1 } ^ { n } \ exp 
z _ j } \ \ = \ frac { 
\ exp z _ i + \ max _ k 
x _ k } { \ sum _ { j 
= 1 } ^ { n } \ exp z 
_ j + \ max _ k x _ k 
} \ \ = \ frac { \ exp x 
_ i } { \ sum _ { j = 
1 } ^ { n } \ exp x _ 
j } \ \ = \ text { softmax } 
\ mathbf { \ vec x } _ i \ 
当 $ \ mathbf { \ vec x } $ 
的 分量 较 小时 $ \ mathbf { \ vec 
z } $ 的 分量 至少 有 一个 为零 从而 
导致 \ \ text { softmax } \ mathbf { 
\ vec z } _ i \ 的 分母 至少 
有 一项 为 1 从而 解决 了 下 溢出 的 
问题 当 $ \ mathbf { \ vec x } 
$ 的 分量 较大 时 \ \ text { softmax 
} \ mathbf { \ vec z } _ i 
\ 相当于 分子 分母 同时 除以 一个 非常 大 的 
数 \ \ exp \ max _ i x _ 
i \ 从而 解决 了 上 溢出 还有 个 问题 
$ \ mathbf { \ vec x } $ 的 
分量 较 小时 \ \ text { softmax } \ 
mathbf { \ vec x } _ i \ 的 
计算 结果 可能 为 0 此 \ \ log \ 
text { softmax } \ mathbf { \ vec x 
} \ 趋向于 负无穷 非 数值 稳定 的 因此 需要 
设计 专门 的 函数 来 计 \ \ log \ 
text { softmax } \ 而 不是 \ \ text 
{ softmax } \ 的 结果 传递 \ \ log 
\ 函数 通常 \ \ text { softmax } \ 
函数 的 输出 作为 模型 的 输出 由于 一般 使用 
样本 的 交叉 熵 作为 目标函数 因此 需要 用 \ 
\ text { softmax } \ 输出 的 对数 当 
从头 开始 实现 一个 数值 算法 时 需要 考虑 数值 
稳定性 当 使用 现有 的 数值 计算 库 时 不 
需要 考虑 数值 稳定性 softmax 名字 的 来源 是 hardmax 
hardmax 把 一个 向 $ \ mathbf { \ vec 
x } $ 映 射成 向 \ 0 \ cdots 
0 1 0 \ cdots 0 ^ T \ 即 
\ \ mathbf { \ vec x } \ 最大 
元素 的 位置 填充 1 其它 位置 填充 0 softmax 
会在 这些 位置 填充 0.0 ~ 1.0 之间 的 值 
如 某个 概率值 二 C o n d i t 
i o n i n g C o n d 
i t i o n i n g 刻画 了 
一个 函数 的 如下 特性 当 函数 的 输入 发生 
了 微小 的 变化 时 函数 的 输出 的 变化 
有 多大 对于 Conditioning 较大 的 函数 在 数值 计算 
中 可能 有 问题 因为 函数 输入 的 舍入 误差 
可能 导致 函数 输出 的 较大 变化 对于 方 \ 
\ mathbf A \ in \ mathbb R ^ { 
n \ times n } \ 其 条件 数 condition 
number 为 \ \ text { condition number } = 
\ max _ { 1 \ le i j \ 
le n i \ ne j } \ left | 
\ frac { \ lambda _ i } { \ 
lambda _ j } \ right | \ 其 \ 
\ lambda _ i i = 1 2 \ cdots 
n \ \ \ mathbf A \ 的 特征值 方阵 
的 条件 数 就是 最大 的 特征值 除以 最小 的 
特征值 当 方阵 的 条件 数 很大 时 矩阵 的 
求 逆 将对 误差 特别 敏感 即 \ \ mathbf 
A \ 的 一个 很小 的 扰动 将 导致 其 
逆 矩阵 一个 非常 明显 的 变化 条 件数 是 
矩阵 本身 的 特性 它 会 放大 那些 包含 矩阵 
求 逆运算 过程 中 的 误差 三 梯度 下 降法 
梯度 下 降法 是 求解 无约束 最优化 问题 的 一种 
常见 方法 优点 是 实现 简单 对于 函数 \ f 
\ mathbb R ^ { n } \ rightarrow \ 
mathbb R \ 输入 为 多维 的 假设 输 \ 
\ mathbf { \ vec x } = x _ 
1 x _ 2 \ cdots x _ n ^ 
{ T } \ 则 定义 梯度 \ \ nabla 
_ { \ mathbf { \ vec x } } 
f \ mathbf { \ vec x } = \ 
left \ frac { \ partial } { \ partial 
x _ 1 } f \ mathbf { \ vec 
x } \ frac { \ partial } { \ 
partial x _ 2 } f \ mathbf { \ 
vec x } \ cdots \ frac { \ partial 
} { \ partial x _ n } f \ 
mathbf { \ vec x } \ right ^ { 
T } \ 驻点 满足 \ \ nabla _ { 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } = \ mathbf { 
\ vec 0 } \ 沿着 方 \ \ mathbf 
{ \ vec u } \ 的 方向 导数 directional 
derivative 定义 为 \ \ lim _ { \ alpha 
\ rightarrow 0 } \ frac { f \ mathbf 
{ \ vec x } + \ alpha \ mathbf 
{ \ vec u } f \ mathbf { \ 
vec x } } { \ alpha } \ 其 
\ \ mathbf { \ vec u } \ 为 
单位向量 方向 导数 就是 \ \ frac { \ partial 
} { \ partial \ alpha } f \ mathbf 
{ \ vec x } + \ alpha \ mathbf 
{ \ vec u } \ 根据 链式法则 它 也 
等于 \ \ mathbf { \ vec u } ^ 
{ T } \ nabla _ { \ mathbf { 
\ vec x } } f \ mathbf { \ 
vec x } \ 为了 最小 \ f \ 则 
寻找 一个 方向 沿着 该 方向 函数值 减少 的 速度 
最快 换句话说 就是 增加 最慢 即 \ \ min _ 
{ \ mathbf { \ vec u } } \ 
mathbf { \ vec u } ^ { T } 
\ nabla _ { \ mathbf { \ vec x 
} } f \ mathbf { \ vec x } 
\ \ s . t . \ quad | | 
\ mathbf { \ vec u } | | _ 
2 = 1 \ 假 \ \ mathbf { \ 
vec u } \ 与 梯度 的 夹角 \ \ 
theta \ 则 目标函数 等于 \ | | \ mathbf 
{ \ vec u } | | _ 2 | 
| \ nabla _ { \ mathbf { \ vec 
x } } f \ mathbf { \ vec x 
} | | _ 2 \ cos \ theta \ 
考虑 \ | | \ mathbf { \ vec u 
} | | _ 2 = 1 \ 以及 梯度 
的 大小 \ \ theta \ 无关 于是 上述问题 转化 
为 \ \ min _ \ theta \ cos \ 
theta \ 于是 \ \ theta ^ { * } 
= \ pi \ \ \ mathbf { \ vec 
u } \ 沿着 梯度 的 相反 的 方向 即 
梯度 的 方向 是 函数值 增加 最快 的 方向 梯度 
的 相反 方向 是 函数值 减小 的 最快 的 方向 
可以 沿着 负 梯度 的 方向 来 降 \ f 
\ 的 值 这 就是 梯度 下 降法 根据 梯度 
下 降法 为了 寻 \ f \ 的 最 小点 
迭代 过程 为 \ \ mathbf { \ vec x 
} ^ { \ prime } = \ mathbf { 
\ vec x } \ epsilon \ nabla _ { 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } \ 迭代 结束 条件 
为 梯度 向 \ \ nabla _ { \ mathbf 
{ \ vec x } } f \ mathbf { 
\ vec x } \ 的 每个 成分 为零 或者 
非常 接近 零 \ \ epsilon \ 为 学习率 它 
是 一个 正数 决定了 迭代 的 步长 选择 学习率 有 
多种 方法 一种 方法 是 选 \ \ epsilon \ 
为 一个 小 的 正 的 常数 另一种 方法 是 
给定 多 \ \ epsilon \ 然后 选择 使 \ 
f \ mathbf { \ vec x } \ epsilon 
\ nabla _ { \ mathbf { \ vec x 
} } f \ mathbf { \ vec x } 
\ 最小 的 那个 值 作为 本次 迭代 的 学习率 
即 选择 一个 使得 目标函数 下降 最大 的 学习 率 
这种 做法 叫做 线性 搜索 line search 第三 种 方法 
是 求得 \ f \ mathbf { \ vec x 
} \ epsilon \ nabla _ { \ mathbf { 
\ vec x } } f \ mathbf { \ 
vec x } \ 取 极小值 \ \ epsilon \ 
即 求解 最优化 问题 \ \ epsilon ^ { * 
} = \ arg \ min _ { \ epsilon 
\ epsilon \ gt 0 } f \ mathbf { 
\ vec x } \ epsilon \ nabla _ { 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } \ 这种 方法 也 
称作 最速 下 降法 在 最速 下 降法 中 假设 
相邻 的 三个 迭代 点 分别为 \ \ mathbf { 
\ vec x } ^ { k } \ mathbf 
{ \ vec x } ^ { k + 1 
} \ mathbf { \ vec x } ^ { 
k + 2 } \ 可以 证明 \ \ mathbf 
{ \ vec x } ^ { k + 1 
} \ mathbf { \ vec x } ^ { 
k } \ cdot \ mathbf { \ vec x 
} ^ { k + 2 } \ mathbf { 
\ vec x } ^ { k + 1 } 
= 0 \ 即 相邻 的 两次 搜索 的 方向 
是 正交 的 证明 \ \ mathbf { \ vec 
x } ^ { k + 1 } = \ 
mathbf { \ vec x } ^ { k } 
\ epsilon ^ { k } \ nabla _ { 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } ^ { k } 
\ \ \ mathbf { \ vec x } ^ 
{ k + 2 } = \ mathbf { \ 
vec x } ^ { k + 1 } \ 
epsilon ^ { k + 1 } \ nabla _ 
{ \ mathbf { \ vec x } } f 
\ mathbf { \ vec x } ^ { k 
+ 1 } \ \ \ 根据 最优化 问题 有 
\ \ epsilon ^ { k + 1 } = 
\ arg \ min _ { \ epsilon \ epsilon 
\ gt 0 } f \ mathbf { \ vec 
x } ^ { k + 1 } \ epsilon 
\ nabla _ { \ mathbf { \ vec x 
} } f \ mathbf { \ vec x } 
^ { k + 1 } \ \ \ rightarrow 
\ frac { \ partial f \ mathbf { \ 
vec x } ^ { k + 1 } \ 
epsilon \ nabla _ { \ mathbf { \ vec 
x } } f \ mathbf { \ vec x 
} ^ { k + 1 } } { \ 
partial \ epsilon } \ mid _ { \ epsilon 
= \ epsilon ^ { k + 1 } } 
= 0 \ \ \ rightarrow \ nabla _ { 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } ^ { k + 
2 } \ cdot \ nabla _ { \ mathbf 
{ \ vec x } } f \ mathbf { 
\ vec x } ^ { k + 1 } 
= 0 \ \ \ rightarrow \ mathbf { \ 
vec x } ^ { k + 1 } \ 
mathbf { \ vec x } ^ { k } 
\ cdot \ mathbf { \ vec x } ^ 
{ k + 2 } \ mathbf { \ vec 
x } ^ { k + 1 } = 0 
\ 此时 迭代 的 路线 是 锯齿形 的 因此 收敛 
速度 较慢 某些 情况下 如果 梯度 向 \ \ nabla 
_ { \ mathbf { \ vec x } } 
f \ mathbf { \ vec x } \ 的 
形式 比较 简单 则 可以 直接 求 解方程 \ \ 
nabla _ { \ mathbf { \ vec x } 
} f \ mathbf { \ vec x } = 
\ mathbf { \ vec 0 } \ 此时 不用 
任何 迭代 直接 获得 解析 解 梯度 下降 算法 输入 
目标函数 \ f \ mathbf { \ vec x } 
\ 梯度 函数 $ g \ mathbf { \ vec 
x } = \ nabla f \ mathbf { \ 
vec x } $ 计算精度 \ e \ 输出 \ 
f \ mathbf { \ vec x } \ 的 
极小 \ \ mathbf { \ vec x } ^ 
* \ 算法 步骤 选取 初始 \ \ mathbf { 
\ vec x } ^ { 0 } \ in 
\ mathbb R ^ { n } \ \ k 
= 0 \ 计 \ f \ mathbf { \ 
vec x } ^ { k } \ 计算 梯 
\ \ mathbf { \ vec g } _ k 
= g \ mathbf { \ vec x } ^ 
{ k } \ 若 梯 \ | \ mathbf 
{ \ vec g } _ k | \ lt 
e \ 则 停止 迭代 \ \ mathbf { \ 
vec x } ^ * = \ mathbf { \ 
vec x } \ 即 此时 导数 为 0 若 
梯 \ | \ mathbf { \ vec g } 
_ k | \ ge e \ 则 \ \ 
mathbf { \ vec p } _ k = \ 
mathbf { \ vec g } _ k \ \ 
\ epsilon _ k \ \ \ epsilon _ k 
= \ min _ { \ epsilon \ le 0 
} f \ mathbf { \ vec x } ^ 
{ k } + \ epsilon \ mathbf { \ 
vec p } _ k \ 通常 这也 是个 最小化 
问题 但是 可以 给定 一系列 \ \ epsilon _ k 
\ 的 值 如 10 1 0.1 0.01 0.001 0.0001 
然后 从中 挑选 \ \ mathbf { \ vec x 
} ^ { k + 1 } = \ mathbf 
{ \ vec x } ^ { k } + 
\ epsilon _ k \ mathbf { \ vec p 
} _ k \ 计 \ f \ mathbf { 
\ vec x } ^ { k + 1 } 
\ 若 \ | f \ mathbf { \ vec 
x } ^ { k + 1 } f \ 
mathbf { \ vec x } ^ { k } 
| \ lt e \ 或者 \ | \ mathbf 
{ \ vec x } ^ { k + 1 
} \ mathbf { \ vec x } ^ { 
k } | \ lt e \ 时 停止 迭代 
\ \ mathbf { \ vec x } ^ * 
= \ mathbf { \ vec x } \ 否则 
令 \ k = k + 1 \ 计算 梯度 
\ \ mathbf { \ vec g } _ k 
= g \ mathbf { \ vec x } ^ 
{ k } \ 继续 迭代 当 目标函数 是 凸函数 
时 梯度 下 降法 的 解是/nr 全局 最优 的 通常 
情况下 梯度 下 降法 的 解不/nr 保证 是 全局 最优 
的 梯度 下 降法 的 收敛 速度 未必 是 最快 
的 四 海森 矩阵 4.1 二阶 导数 二阶 导 \ 
f ^ { \ prime \ prime } x \ 
刻画 了 曲率 假设 有 一个 二次函数 实际 任务 中 
很多 函数 不是 二次 的 但是 在 局部 可 以近 
似为 二次函数 如果 函数 的 二阶 导数 为零 则 它 
是 一条 直线 如果 梯度 为 1 则 当 沿着 
负 梯度 的 步 长为 \ \ epsilon \ 时 
函数值 减少 \ \ epsilon \ 如果 函数 的 二阶 
导数 为 负 则 函数 向下 弯曲 如果 梯度 为 
1 则 当 沿着 负 梯度 的 步 长为 \ 
\ epsilon \ 时 函数值 减少 的 量 大于 \ 
\ epsilon \ 如果 函数 的 二阶 导数 为 正 
则 函数 向上 弯曲 如果 梯度 为 1 则 当 
沿着 负 梯度 的 步 长为 \ \ epsilon \ 
时 函数值 减少 的 量 少于 \ \ epsilon \ 
4.2 海森 矩阵 当 函数 输入 为 多维 时 定义 
海森 矩阵 \ \ mathbf H f \ mathbf { 
\ vec x } = \ begin { bmatrix } 
\ frac { \ partial ^ { 2 } } 
{ \ partial x _ 1 \ partial x _ 
1 } f & \ frac { \ partial ^ 
{ 2 } } { \ partial x _ 1 
\ partial x _ 2 } f & \ cdots 
& \ frac { \ partial ^ { 2 } 
} { \ partial x _ 1 \ partial x 
_ n } f \ \ \ frac { \ 
partial ^ { 2 } } { \ partial x 
_ 2 \ partial x _ 1 } f & 
\ frac { \ partial ^ { 2 } } 
{ \ partial x _ 2 \ partial x _ 
2 } f & \ cdots & \ frac { 
\ partial ^ { 2 } } { \ partial 
x _ 2 \ partial x _ n } f 
\ \ \ vdots & \ vdots & \ ddots 
& \ vdots \ \ \ frac { \ partial 
^ { 2 } } { \ partial x _ 
n \ partial x _ 1 } f & \ 
frac { \ partial ^ { 2 } } { 
\ partial x _ n \ partial x _ 2 
} f & \ cdots & \ frac { \ 
partial ^ { 2 } } { \ partial x 
_ n \ partial x _ n } f \ 
end { bmatrix } \ 即 海森 矩阵 的 \ 
i \ \ j \ 列 元素 为 \ \ 
mathbf H _ { i j } = \ frac 
{ \ partial ^ { 2 } } { \ 
partial x _ i \ partial x _ j } 
f \ mathbf { \ vec x } \ 当 
二阶 偏 导 是 连续 时 海森 矩阵 是 对称 
阵 即有 \ \ mathbf H = \ mathbf H 
^ { T } \ 在 深度 学习 中 大多数 
海森 矩阵 都是 对称 阵 对于 特定 方 \ \ 
mathbf { \ vec d } \ 上 的 二阶 
导数 为 \ \ mathbf { \ vec d } 
^ T \ mathbf H \ mathbf { \ vec 
d } \ 如果 \ \ mathbf { \ vec 
d } \ 是 海森 矩阵 的 特征向量 则 该 
方向 的 二阶 导数 就是 对应 的 特征值 如果 \ 
\ mathbf { \ vec d } \ 不是 海森 
矩阵 的 特征向量 则 该 方向 的 二阶 导数 就是 
所有 特征值 的 加权 平均 权重 在 0 1 之间 
且 与 \ \ mathbf { \ vec d } 
\ 夹角 越小 的 特征向量 对应 的 特征值 具有 更大 
的 权重 最大 特征值 确定 了 最大 二阶 导数 最小 
特征值 确定 最小 二阶 导数 4.3 海森 矩阵 与 学习率 
\ f \ mathbf { \ vec x } \ 
\ \ mathbf { \ vec x } _ 0 
\ 处 泰勒 展开 \ f \ mathbf { \ 
vec x } \ approx f \ mathbf { \ 
vec x } _ 0 + \ mathbf { \ 
vec x } \ mathbf { \ vec x } 
_ 0 ^ { T } \ mathbf { \ 
vec g } + \ frac 12 \ mathbf { 
\ vec x } \ mathbf { \ vec x 
} _ 0 ^ { T } \ mathbf H 
\ mathbf { \ vec x } \ mathbf { 
\ vec x } _ 0 \ 其 \ \ 
mathbf { \ vec g } \ \ \ mathbf 
{ \ vec x } _ 0 \ 处 的 
梯度 \ \ mathbf H \ \ \ mathbf { 
\ vec x } _ 0 \ 处 的 海森 
矩阵 根据 梯度 下 降法 \ \ mathbf { \ 
vec x } ^ { \ prime } = \ 
mathbf { \ vec x } \ epsilon \ nabla 
_ { \ mathbf { \ vec x } } 
f \ mathbf { \ vec x } \ 应用在 
\ \ mathbf { \ vec x } _ 0 
\ 有 \ f \ mathbf { \ vec x 
} _ 0 \ epsilon \ mathbf { \ vec 
g } \ approx f \ mathbf { \ vec 
x } _ 0 \ epsilon \ mathbf { \ 
vec g } ^ { T } \ mathbf { 
\ vec g } + \ frac 12 \ epsilon 
^ { 2 } \ mathbf { \ vec g 
} ^ { T } \ mathbf H \ mathbf 
{ \ vec g } \ 第一项 代表 函数 在 
点 \ \ mathbf { \ vec x } _ 
0 \ 处 的 值 第二项 代表 由于 斜率 的 
存在 导致 函数值 的 变化 第三项 代表 由于 曲率 的 
存在 对于 函数值 变化 的 矫正 注意 如 \ \ 
frac 12 \ epsilon ^ { 2 } \ mathbf 
{ \ vec g } ^ { T } \ 
mathbf H \ mathbf { \ vec g } \ 
较大 则 很 有可能 导致 沿着 负 梯度 的 方向 
函数值 反而 增加 如 \ \ mathbf { \ vec 
g } ^ { T } \ mathbf H \ 
mathbf { \ vec g } \ le 0 \ 
则无 \ \ epsilon \ 取 多大 的 值 可以 
保证 函数值 是 减小 的 如 \ \ mathbf { 
\ vec g } ^ { T } \ mathbf 
H \ mathbf { \ vec g } \ gt 
0 \ 则 学习 \ \ epsilon \ 不能 太大 
\ \ epsilon \ 太大 则 函数值 增加 根 \ 
f \ mathbf { \ vec x } _ 0 
\ epsilon \ mathbf { \ vec g } f 
\ mathbf { \ vec x } _ 0 \ 
lt 0 \ 有 \ \ epsilon \ lt \ 
frac { \ mathbf { 2 \ vec g } 
^ { T } \ mathbf { \ vec g 
} } { \ mathbf { \ vec g } 
^ { T } \ mathbf H \ mathbf { 
\ vec g } } \ 考虑 最速 下 降法 
选择 使 \ f \ 下降 最快 \ \ epsilon 
\ 则有 \ \ epsilon ^ { * } = 
\ arg \ min _ { \ epsilon \ epsilon 
\ gt 0 } f \ mathbf { \ vec 
x } _ 0 \ epsilon \ mathbf { \ 
vec g } \ 求 \ \ frac { \ 
partial } { \ partial \ epsilon } f \ 
mathbf { \ vec x } _ 0 \ epsilon 
\ mathbf { \ vec g } = 0 \ 
有 \ \ epsilon ^ { * } = \ 
frac { \ mathbf { \ vec g } ^ 
{ T } \ mathbf { \ vec g } 
} { \ mathbf { \ vec g } ^ 
{ T } \ mathbf H \ mathbf { \ 
vec g } } \ 根 \ \ mathbf { 
\ vec g } ^ { T } \ mathbf 
H \ mathbf { \ vec g } \ gt 
0 \ 很 明显 有 $ \ epsilon ^ { 
* } \ lt \ frac { \ mathbf { 
2 \ vec g } ^ { T } \ 
mathbf { \ vec g } } { \ mathbf 
{ \ vec g } ^ { T } \ 
mathbf H \ mathbf { \ vec g } } 
$ 由于 海森 矩阵 为 实 对称 阵 因此 它 
可以 进行 特征值 分解 假设 其 特征值 从大到/nr 小排 列为 
\ \ lambda _ 1 \ lambda _ 2 \ 
cdots \ lambda _ n \ 其 瑞利 商 \ 
R \ mathbf { \ vec x } = \ 
frac { \ mathbf { \ vec x } ^ 
{ T } \ mathbf H \ mathbf { \ 
vec x } } { \ mathbf { \ vec 
x } ^ { T } \ mathbf { \ 
vec x } } \ mathbf { \ vec x 
} \ ne \ mathbf { \ vec 0 } 
\ 可以 证明 \ \ lambda _ n \ le 
R \ mathbf { \ vec x } \ le 
\ lambda _ 1 \ \ \ lambda _ 1 
= \ max _ { \ mathbf { \ vec 
x } \ ne \ mathbf { \ vec 0 
} } R \ mathbf { \ vec x } 
\ \ \ lambda _ n = \ min _ 
{ \ mathbf { \ vec x } \ ne 
\ mathbf { \ vec 0 } } R \ 
mathbf { \ vec x } \ 根据 \ \ 
epsilon ^ { * } = \ frac { \ 
mathbf { \ vec g } ^ { T } 
\ mathbf { \ vec g } } { \ 
mathbf { \ vec g } ^ { T } 
\ mathbf H \ mathbf { \ vec g } 
} = \ frac { 1 } { R \ 
mathbf { \ vec g } } \ 可知 海森 
矩阵 决定了 学习率 的 取值 范围 最坏 的 情况 下 
梯度 \ \ mathbf { \ vec g } \ 
与 海森 矩阵 最大 特征值 \ \ lambda _ 1 
\ 对应 的 特征 向量 平行 则 此时 最优 学习率 
为 \ \ frac { 1 } { \ lambda 
_ 1 } \ 4.4 驻点 与 全局 极 小点 
满足 导数 为零 的 点 \ f ^ { \ 
prime } x = 0 \ 称作 驻点 驻点 可能 
为 下面 三种 类型 之一 局部 极 小点 在 \ 
x \ 的 一个 邻 域内 该点 的 值 最小 
局部 极 大点 在 \ x \ 的 一个 邻 
域内 该点 的 值 最大 鞍点 既 不是 局部 极小 
也 不是 局部 极大 全局 极 小点 \ x ^ 
{ * } = \ arg \ min _ x 
f x \ 全局 极 小点 可能 有 一个 或者 
多个 在 深度 学习 中 目标函数 很可能 具有 非常 多 
的 局部 极 小点 以及 许多 位于 平坦 区域 的 
鞍点 这 使得 优化 非常 不利 因此 通常 选取 一个 
非常 低 的 目标 函数值 而不 一定 要 是 全局 
最小值 二阶 导数 可以 配 合一 阶 导数 来 决定 
驻点 的 类型 局部 极 小点 \ f ^ { 
\ prime } x = 0 f ^ { \ 
prime \ prime } x \ gt 0 \ 局部 
极 大点 \ f ^ { \ prime } x 
= 0 f ^ { \ prime \ prime } 
x \ lt 0 \ \ f ^ { \ 
prime } x = 0 f ^ { \ prime 
\ prime } x = 0 \ 驻点 的 类型 
可能 为 任意 三者 之一 对于 多维 的 情况 类似 
局部 极 小点 $ \ nabla _ { \ mathbf 
{ \ vec x } } f \ mathbf { 
\ vec x } = 0 $ 且 海森 矩阵 
为 正定 的 即 所有 的 特征值 都是 正 的 
当 海森 矩阵 为 正定 时 任意 方向 的 二阶 
偏 导数 都是 正 的 局部 极 大点 $ \ 
nabla _ { \ mathbf { \ vec x } 
} f \ mathbf { \ vec x } = 
0 $ 且 海森 矩阵 为 负 定 的 即 
所有 的 特征值 都是 负 的 当 海森 矩阵 为 
负 定时 任意 方向 的 二阶 偏 导数 都是 负 
的 $ \ nabla _ { \ mathbf { \ 
vec x } } f \ mathbf { \ vec 
x } = 0 $ 且 海森 矩阵 的 特征值 
中 至少 一个 正值 至少 一个 负值 时 为 鞍点 
当 海森 矩阵 非 上述 情况 时 驻点 类型 无法 
判断 下图 \ f \ mathbf { \ vec x 
} = x _ 1 ^ { 2 } x 
_ 2 ^ { 2 } \ 在 原点 附近 
的 等值线 其 海森 矩阵 为 一正一负 沿着 \ x 
_ 1 \ 方向 曲线 向上 沿着 \ x _ 
2 \ 方向 曲线 向下 鞍点 就是 在 一个 横截面 
内 的 局部 极小值 另一个 横截面 内 的 局部 极大值 
四 牛顿 法 梯度 下 降法 有个 缺陷 它 未能 
利用 海森 矩阵 的 信息 当 海森 矩阵 的 条件 
数 较大 时 不同 方向 的 梯度 的 变化 差异 
很大 在 某些 方向 上 梯度 变化 很快 在 有些 
方向 上 梯度 变化 很慢 梯度 下 降法 未能 利用 
海森 矩阵 也就 不 知道 应该 优先 搜索 导数 长期 
为 负 的 方向 本质 上 应该 沿着 负 梯度方向 
搜索 但是 沿着 该 方向 的 一段 区间 内 如果 
导数 一直 为 负 则 可以 直接 跨过 该 区间 
前提 是 必须 保证 该 区间 内 该 方向 导数 
一直 为 负 当 海森 矩阵 的 条件 数 较大 
时 也 难以 选择 合适 的 步长 步长 必须 足够 
小 从而 能够 适应 较强 曲率 的 地方 对应 着 
较大 的 二阶 导数 即 该 区域 比较 陡峭 但是 
如果 步长 太小 对于 曲率 较小 的 地方 对应 着 
较小 的 二阶 导数 即 该 区域 比较 平缓 则 
推进 太慢 曲率 刻画 弯曲 程度 曲率 越大 则 曲率半径 
越小 下图 是 利用 梯度 下 降法 寻找 函数 最小值 
的 路径 该 函数 是 二次函数 海森 矩阵 条 件数 
为 5 表明 最大 曲率 是 最小 曲率 的 5倍 
红线 为 梯度 下降 的 搜索 路径 它 没有 用 
最速 下 降法 而是 用到 线性 搜索 如果 是 最速 
下 降法 则 相邻 两 次 搜索 的 方向 正交 
牛顿 法 结合 了 海森 矩阵 考虑 泰勒 展开式 \ 
f \ mathbf { \ vec x } \ approx 
f \ mathbf { \ vec x } _ 0 
+ \ mathbf { \ vec x } \ mathbf 
{ \ vec x } _ 0 ^ { T 
} \ mathbf { \ vec g } + \ 
frac 12 \ mathbf { \ vec x } \ 
mathbf { \ vec x } _ 0 ^ { 
T } \ mathbf H \ mathbf { \ vec 
x } \ mathbf { \ vec x } _ 
0 \ 其 \ \ mathbf { \ vec g 
} \ \ \ mathbf { \ vec x } 
_ 0 \ 处 的 梯度 \ \ mathbf H 
\ \ \ mathbf { \ vec x } _ 
0 \ 处 的 海森 矩阵 如 \ \ mathbf 
{ \ vec x } \ 为 极值 点 则有 
\ \ frac { \ partial } { \ partial 
\ mathbf { \ vec x } } f \ 
mathbf { \ vec x } = \ mathbf { 
\ vec 0 } \ 则有 \ \ mathbf { 
\ vec x } ^ { * } = \ 
mathbf { \ vec x } _ 0 \ mathbf 
H ^ { 1 } \ mathbf { \ vec 
g } \ 当 \ f \ 是个 正定 的 
二次型 则/d 牛顿/nr 法/l 直接/ad 一次/m 就/d 能/v 到达/v 最小值/l 
点/m 当/t \ f \ 不是 正定 的 二次型 则 
可以 在 局部 近似 为 正定 的 二次型 那么 则 
采用 多次 牛顿 法 即可 到达 最小值 点 一维 情况 
下 梯度/n 下/f 降法/n 和/c 牛顿/nr 法的/nr 原理/n 展示/v 梯度 
下 降法 下一次 迭代 的 \ \ mathbf { \ 
vec x } ^ { k + 1 } = 
\ mathbf { \ vec x } ^ { k 
} \ epsilon _ k \ nabla f \ mathbf 
{ \ vec x } \ 对于 一维 的 情况 
可以 固定 \ \ epsilon _ k = \ eta 
\ 由于 随着 迭代 的 推进 \ f ^ { 
\ prime } x \ 绝对值 是 减小 的 直到 
0 因此 越 靠近 极值 点 \ \ Delta x 
\ 越小 牛顿 法 目标 \ \ nabla f \ 
mathbf { \ vec x } = 0 \ 在 
一维 情况 下 就是 求 \ f ^ \ prime 
x = 0 \ 牛顿 法的/nr 方法 是 \ x 
= x ^ { k } \ \ y = 
f ^ { \ prime } x \ 切线 该 
切线 过 \ x ^ { k } f ^ 
{ \ prime } x ^ { k } \ 
该 切线 \ x \ 轴上 的 交点 就是 \ 
x ^ { k + 1 } = x ^ 
{ k } \ frac { f ^ { \ 
prime } x ^ { k } } { f 
^ { \ prime \ prime } x ^ { 
k } } \ 推广 到 多维 情况 下 就是 
\ \ mathbf { \ vec x } ^ { 
k + 1 } = \ mathbf { \ vec 
x } ^ { k } \ mathbf H _ 
k ^ { 1 } \ mathbf { \ vec 
g } _ k \ 当 位于 一个 极小值 点 
附近 时 牛顿/nr 法比/nr 梯度/n 下/f 降法/n 能/v 更快/d 地/uv 
到达/v 极小值/n 点/m 如果 在 一个 鞍点 附近 牛顿 法 
效果 很差 而 梯度 下 降法 此时 效果 较好 除非 
负 梯度 的 方向 刚好 指向 了 鞍点 仅仅 利用 
了 梯度 的 优化 算法 如 梯度 下 降法 称作 
一 阶 优化 算法 同时 利用 了 海森 矩阵 的 
优化 算法 如 牛顿 法 称作 二阶 优化 算法 牛顿 
法 算法 输入 目标函数 \ f \ mathbf { \ 
vec x } \ 梯度 \ g \ mathbf { 
\ vec x } = \ nabla f \ mathbf 
{ \ vec x } \ 海森 矩阵 \ \ 
mathbf H \ mathbf { \ vec x } \ 
精度 要求 \ e \ 输出 \ f \ mathbf 
{ \ vec x } \ 的 极小值 \ \ 
mathbf { \ vec x } ^ * \ 算法 
步骤 选取 初始 \ \ mathbf { \ vec x 
} ^ { 0 } \ in \ mathbb R 
^ { n } \ \ k = 0 \ 
计 \ \ mathbf { \ vec g } _ 
k = g \ mathbf { \ vec x } 
^ { k } \ \ | \ mathbf { 
\ vec g } _ k | \ lt e 
\ 则 停止 计算 得到 近似 \ \ mathbf { 
\ vec x } = \ mathbf { \ vec 
x } ^ * \ \ | \ mathbf { 
\ vec g } _ k | \ ge e 
\ 则 计算 \ \ mathbf H _ k = 
\ mathbf H \ mathbf { \ vec x } 
^ { k } \ 并 求 \ \ mathbf 
{ \ vec p } _ k \ mathbf H 
_ k \ mathbf { \ vec p } _ 
k = \ mathbf { \ vec g } _ 
k \ 置 \ \ mathbf { \ vec x 
} ^ { k + 1 } = \ mathbf 
{ \ vec x } ^ { k } + 
\ mathbf { \ vec p } _ k \ 
置 \ k = k + 1 \ 计算 \ 
\ mathbf { \ vec g } _ k = 
g \ mathbf { \ vec x } ^ { 
k } \ 迭代 梯度 下 降法 中 每一 \ 
\ mathbf { \ vec x } \ 增加 的 
方向 一定 是 梯度 相反 的 方 \ \ epsilon 
_ k \ nabla _ k \ 增加 的 幅度 
由 \ \ epsilon _ k \ 决定 若 跨度 
过大 容易 引发 震荡 而 牛顿 法中/nr 每一 \ \ 
mathbf { \ vec x } \ 增加 的 方向 
是 梯度 增速 最大 的 反方 \ \ mathbf H 
_ k ^ { 1 } \ nabla _ k 
\ 它 通常 情况下 与 梯度 不 共线 增加 的 
幅度 已经 包含 在 $ \ mathbf H _ k 
^ { 1 } $ 中 也 可以 乘以 学习率 
作为 幅度 的 系数 深度 学习 中 的 目标 函数 
非常复杂 无法 保证 可以 通过 上述 优化 算法 进行 优化 
因此 有时会 限定 目标函数 具有 Lipschitz 连续 或者 其 导数 
Lipschitz 连续 Lipschitz 连续 的 定义 对于 函数 \ f 
\ 存在 一个 Lipschitz 常数 \ \ mathcal L \ 
使得 \ \ forall \ mathbf { \ vec x 
} \ forall \ mathbf { \ vec y } 
| f \ mathbf { \ vec x } f 
\ mathbf { \ vec y } | \ le 
\ mathcal L | | \ mathbf { \ vec 
x } \ mathbf { \ vec y } | 
| _ 2 \ Lipschitz 连续 的 意义 是 输入 
的 一个 很小 的 变化 会引起 输出 的 一个 很小 
的 变化 与之 相反 的 是 输入 的 一个 很小 
的 变化 会引起 输出 的 一个 很大 的 变化 凸 
优化 在 某些 特殊 的 领域 取得 了 巨大 的 
成功 但是 在 深度 学习 中 大多数 优化 问题 都 
难以 用 凸 优化 来 描述 凸 优化 的 重要性 
在 深度 学习 中 大大降低 凸 优化 仅仅 作为 一些 
深度 学习 算法 的 子程序 五 拟 牛顿 法 5.1 
原理 在 牛顿 法的/nr 迭代 中 需要 计算 海森 矩阵 
的 逆 矩 \ \ mathbf H ^ { 1 
} \ 这一 计算 比较复杂 可以 考虑 用 一个 \ 
n \ 阶 矩阵 \ \ mathbf G _ k 
= G \ mathbf { \ vec x } ^ 
{ k } \ 来 近似 代替 \ \ mathbf 
H ^ { 1 } _ k = H ^ 
{ 1 } \ mathbf { \ vec x } 
^ { k } \ 先看 海森 矩阵 满足 的 
条件 \ \ mathbf { \ vec g } _ 
{ k + 1 } \ mathbf { \ vec 
g } _ k = \ mathbf H _ k 
\ mathbf { \ vec x } ^ { k 
+ 1 } \ mathbf { \ vec x } 
^ { k } \ 令 \ \ mathbf { 
\ vec y } _ k = \ mathbf { 
\ vec g } _ { k + 1 } 
\ mathbf { \ vec g } _ k \ 
vec \ delta _ k = \ mathbf { \ 
vec x } ^ { k + 1 } \ 
mathbf { \ vec x } ^ { k } 
\ 则有 \ \ mathbf { \ vec y } 
_ k = \ mathbf H _ k \ vec 
\ delta _ k \ 或者 \ \ mathbf H 
_ k ^ { 1 } \ mathbf { \ 
vec y } _ k = \ vec \ delta 
_ k \ 这 称为 拟 牛顿 条件 根据 牛顿 
法的/nr 迭代 \ \ mathbf { \ vec x } 
^ { k + 1 } = \ mathbf { 
\ vec x } ^ { k } \ mathbf 
H _ k ^ { 1 } \ mathbf { 
\ vec g } _ k \ 将 \ f 
\ mathbf { \ vec x } \ 在 \ 
\ mathbf { \ vec x } ^ { k 
} \ 的 一 阶 泰勒 展开 \ f \ 
mathbf { \ vec x } ^ { k + 
1 } = f \ mathbf { \ vec x 
} ^ { k } + f \ mathbf { 
\ vec x } ^ { k } \ mathbf 
{ \ vec x } ^ { k + 1 
} \ mathbf { \ vec x } ^ { 
k } \ \ = f \ mathbf { \ 
vec x } ^ { k } + \ mathbf 
{ \ vec g } _ k ^ { T 
} \ mathbf H _ k ^ { 1 } 
\ mathbf { \ vec g } _ k = 
f \ mathbf { \ vec x } ^ { 
k } \ mathbf { \ vec g } _ 
k ^ { T } \ mathbf H ^ { 
1 } _ k \ mathbf { \ vec g 
} _ k \ \ \ mathbf H _ k 
\ 是 正定矩阵 时 总 \ f \ mathbf { 
\ vec x } ^ { k + 1 } 
f \ mathbf { \ vec x } ^ { 
k } \ 因此/c 每次/r 都是/nr 沿着/p 函数/n 递减/v 的/uj 
方向/n 迭代/v 拟/v 牛顿/nr 法/l 如果/c 选/zg \ \ mathbf 
G _ k \ 作 \ \ mathbf H _ 
k ^ { 1 } \ 的 近似 时 \ 
\ mathbf G _ k \ 同样 要 满足 两个 
条件 \ \ mathbf G _ k \ 必须 是 
正定 的 \ \ mathbf G _ k \ 满足 
拟 牛顿 条件 \ \ mathbf G _ { k 
+ 1 } \ mathbf { \ vec y } 
_ k = \ vec \ delta _ k \ 
因 \ \ mathbf G _ 0 \ 是 给定 
的 初始 化 条件 所以 下标 \ k + 1 
\ 开始 按照 拟 牛顿 条件 在 每次 迭代 中 
可以 选择 更新 矩 \ \ mathbf G _ { 
k + 1 } = \ mathbf G _ k 
+ \ Delta \ mathbf G _ k \ 正定矩阵 
定义 \ \ mathbf M \ \ n \ times 
n \ 阶 方阵 如果 对 任何 非零 向 \ 
\ mathbf { \ vec x } \ 都 \ 
\ mathbf { \ vec x } ^ { T 
} \ mathbf M \ mathbf { \ vec x 
} \ gt 0 \ 就 \ \ mathbf M 
\ 正定矩阵 正定矩阵 判定 判定 定理 1 对称 阵 \ 
\ mathbf M \ 为 正定 的 充分 必要条件 是 
\ \ mathbf M \ 的 特征值 全为 正 判定 
定理 2 对称 阵 \ \ mathbf M \ 为 
正定 的 充分 必要条件 是 \ \ mathbf M \ 
的 各阶 顺序 主 子式 都为 正 判定 定理 3 
任意 阵 \ \ mathbf M \ 为 正定 的 
充分 必要条件 是 \ \ mathbf M \ 合同 于 
单位阵 正定矩阵 的 性质 正定矩阵 一定 是非 奇异 的 奇异 
矩阵 的 定义 若 \ n \ times n \ 
阶 矩阵 \ \ mathbf M \ 为 奇异 阵 
则 其 的 行列式 为零 即 \ | \ mathbf 
M | = 0 \ 正定矩阵 的 任一 主子 矩阵 
也是 正定矩阵 若 \ \ mathbf M \ \ n 
\ times n \ 阶 对称 正定矩阵 则 存在 唯一 
的 主 对角线 元素 都是 正数 的 下 三角 阵 
\ \ mathbf L \ 使得 \ \ mathbf M 
= \ mathbf L \ mathbf L ^ { T 
} \ 此 分解 式 称为 正定矩阵 的 乔列/nr 斯基 
Cholesky 分解 若 \ \ mathbf M \ 为 \ 
n \ times n \ 阶 正定矩阵 则 \ \ 
mathbf M \ 为 \ n \ times n \ 
阶 可逆矩阵 正定矩阵 在 某个 合同变换 下 可 化为 标准型 
即 对角 矩阵 所有 特征值 大于 零 的 对称矩阵 也是 
正定矩阵 合同 矩阵 两个 实 对称 矩 \ \ mathbf 
A \ \ \ mathbf B \ 是 合同 的 
当且仅当 存在 一个 可逆 矩 \ \ mathbf P \ 
使 \ \ mathbf A = \ mathbf P ^ 
{ T } \ mathbf B \ mathbf P \ 
\ \ mathbf A \ 的 合同变换 对 某个 可逆矩阵 
\ \ mathbf P \ 对 \ \ mathbf A 
\ 执行 \ \ mathbf P ^ { T } 
\ mathbf A \ mathbf P \ 5.2 DFP 算法 
DFP 算法 Davidon Fletcher Powell 选 \ \ mathbf G 
_ { k + 1 } \ 的 方法 是 
假设 每一步 迭代 \ \ mathbf G _ { k 
+ 1 } \ 是 \ \ mathbf G _ 
k \ 加上 两个 附加 项 构成 \ \ mathbf 
G _ { k + 1 } = \ mathbf 
G _ k + \ mathbf P _ k + 
\ mathbf Q _ k \ 其 \ \ mathbf 
P _ k \ mathbf Q _ k \ 是 
待定 矩阵 此时 有 \ \ mathbf G _ { 
k + 1 } \ mathbf { \ vec y 
} _ k = \ mathbf G _ k \ 
mathbf { \ vec y } _ k + \ 
mathbf P _ k \ mathbf { \ vec y 
} _ k + \ mathbf Q _ k \ 
mathbf { \ vec y } _ k \ 为了 
满足 拟 牛顿 条件 可以 取 \ \ mathbf P 
_ k \ mathbf { \ vec y } _ 
k = \ vec \ delta _ k \ quad 
\ mathbf Q _ k \ mathbf { \ vec 
y } _ k = \ mathbf G _ k 
\ mathbf { \ vec y } _ k \ 
这样 \ \ mathbf P _ k \ mathbf Q 
_ k \ 不止 一个 例如 取 \ \ mathbf 
P _ k = \ frac { \ vec \ 
delta _ k \ vec \ delta _ k ^ 
{ T } } { \ vec \ delta _ 
k ^ { T } \ mathbf { \ vec 
y } _ k } \ quad \ mathbf Q 
_ k = \ frac { \ mathbf G _ 
k \ mathbf { \ vec y } _ k 
\ mathbf { \ vec y } _ k ^ 
{ T } \ mathbf G _ k } { 
\ mathbf { \ vec y } _ k ^ 
{ T } \ mathbf G _ k \ mathbf 
{ \ vec y } _ k } \ 这 
\ \ vec \ delta _ k \ mathbf { 
\ vec y } _ k \ 都是 列 向量 
则 迭代 公式 为 \ \ mathbf G _ { 
k + 1 } = \ mathbf G _ k 
+ \ frac { \ vec \ delta _ k 
\ vec \ delta _ k ^ { T } 
} { \ vec \ delta _ k ^ { 
T } \ mathbf { \ vec y } _ 
k } \ frac { \ mathbf G _ k 
\ mathbf { \ vec y } _ k \ 
mathbf { \ vec y } _ k ^ { 
T } \ mathbf G _ k } { \ 
mathbf { \ vec y } _ k ^ { 
T } \ mathbf G _ k \ mathbf { 
\ vec y } _ k } \ 其中 的 
向 \ \ vec \ delta _ k \ mathbf 
{ \ vec y } _ k \ 都是 列 
向量 可以 证明 如果 初始 矩 \ \ mathbf G 
_ 0 \ 是 正定 的 则 迭代 过程 中 
每个 矩 \ \ mathbf G _ k \ 都是 
正定 的 DFP 算法 输入 目标函数 \ f \ mathbf 
{ \ vec x } \ 梯度 \ g \ 
mathbf { \ vec x } = \ nabla f 
\ mathbf { \ vec x } \ 精度 要求 
\ e \ 输出 \ f \ mathbf { \ 
vec x } \ 的 极小值 \ \ mathbf { 
\ vec x } ^ * \ 算法 步骤 选取 
初始 \ \ mathbf { \ vec x } ^ 
{ 0 } \ in \ mathbb R ^ { 
n } \ \ \ mathbf G _ 0 \ 
为 正定 对称矩阵 \ k \ = 0 计 \ 
\ mathbf { \ vec g } _ k = 
g \ mathbf { \ vec x } ^ { 
k } \ \ | \ mathbf { \ vec 
g } _ k | \ lt e \ 则 
停止 计算 得到 近似 \ \ mathbf { \ vec 
x } = \ mathbf { \ vec x } 
^ * \ \ | \ mathbf { \ vec 
g } _ k | \ ge e \ 则 
计算 \ \ mathbf { \ vec p } _ 
k = \ mathbf G _ k \ mathbf { 
\ vec g } _ k \ 一维 搜索 求 
\ \ epsilon _ k \ \ \ epsilon _ 
k = \ min _ { \ epsilon \ ge 
0 } f \ mathbf { \ vec x } 
^ { k } + \ epsilon \ mathbf { 
\ vec p } _ k \ 设置 \ \ 
mathbf { \ vec x } ^ { k + 
1 } = \ mathbf { \ vec x } 
^ { k } + \ epsilon _ k \ 
mathbf { \ vec p } _ k \ 计算 
\ \ mathbf { \ vec g } _ { 
k + 1 } = g \ mathbf { \ 
vec x } ^ { k + 1 } \ 
若 \ | \ mathbf { \ vec g } 
_ { k + 1 } | \ lt \ 
varepsilon \ 则 停止 计算 得到 近似解 \ \ mathbf 
{ \ vec x } = \ mathbf { \ 
vec x } ^ * \ 否则 计算 \ \ 
mathbf G _ { k + 1 } \ 置 
\ k = k + 1 \ 计算 \ \ 
mathbf { \ vec p } _ k = \ 
mathbf G _ k \ mathbf { \ vec g 
} _ k \ 迭代 DFP 算法 中 每一 \ 
\ mathbf { \ vec x } \ 增加 的 
方向 \ \ mathbf G _ k \ nabla _ 
k \ 的 方向 增加 的 幅度 \ \ epsilon 
_ k \ 决定 若 跨度 过大 容易 引发 震荡 
5.2 BFGS 算法 BFGS 是 最 流行 的 拟 牛顿 
算法 DFP 算法 中 \ \ mathbf G _ k 
\ 逼 \ \ mathbf H ^ { 1 } 
\ 换个 角度 可以用 矩 \ \ mathbf B _ 
k \ 逼近 海森 矩 \ \ mathbf H \ 
此时 对应 的 拟 牛顿 条件 为 \ \ mathbf 
B _ { k + 1 } \ vec \ 
delta _ k = \ mathbf { \ vec y 
} _ k \ 因 \ \ mathbf B _ 
0 \ 是 给定 的 初始 化 条件 所以 下标 
\ k + 1 \ 开始 令 \ \ mathbf 
B _ { k + 1 } = \ mathbf 
B _ k + \ mathbf P _ k + 
\ mathbf Q _ k \ 有 \ \ mathbf 
B _ { k + 1 } \ vec \ 
delta _ k = \ mathbf B _ k \ 
vec \ delta _ k + \ mathbf P _ 
k \ vec \ delta _ k + \ mathbf 
Q _ k \ vec \ delta _ k \ 
可以 \ \ mathbf P _ k \ vec \ 
delta _ k = \ mathbf { \ vec y 
} _ k \ mathbf Q _ k \ vec 
\ delta _ k = \ mathbf B _ k 
\ vec \ delta _ k \ 寻找 合适 \ 
\ mathbf P _ k \ mathbf Q _ k 
\ 可以 得到 BFGS 算法 矩阵 \ \ mathbf B 
_ { k + 1 } \ 的 迭代 公式 
\ \ mathbf B _ { k + 1 } 
= \ mathbf B _ k + \ frac { 
\ mathbf { \ vec y } _ k \ 
mathbf { \ vec y } _ k ^ { 
T } } { \ mathbf { \ vec y 
} _ k ^ { T } \ vec \ 
delta _ k } \ frac { \ mathbf B 
_ k \ vec \ delta _ k \ vec 
\ delta _ k ^ { T } \ mathbf 
B _ k } { \ vec \ delta _ 
k ^ { T } \ mathbf B _ k 
\ vec \ delta _ k } \ 其中 的 
向 \ \ vec \ delta _ k \ mathbf 
{ \ vec y } _ k \ 都是 列 
向量 可以 证明 \ \ mathbf B _ 0 \ 
是 正定 的 则 迭代 过程 中 每个 矩 \ 
\ mathbf B _ k \ 都是 正定 的 BFGS 
算法 输入 目标函数 \ f \ mathbf { \ vec 
x } \ 梯度 \ g \ mathbf { \ 
vec x } = \ nabla f \ mathbf { 
\ vec x } \ 精度 要求 \ \ e 
\ 输出 \ f \ mathbf { \ vec x 
} \ 的 极小值 \ \ mathbf { \ vec 
x } ^ * \ 算法 步骤 选取 初始 \ 
\ mathbf { \ vec x } ^ { 0 
} \ in \ mathbb R ^ { n } 
\ \ \ mathbf B _ 0 \ 为 正定 
对称矩阵 \ k \ = 0 计 \ \ mathbf 
{ \ vec g } _ k = g \ 
mathbf { \ vec x } ^ { k } 
\ \ | \ mathbf { \ vec g } 
_ k | \ lt e \ 则 停止 计算 
得到 近似 \ \ mathbf { \ vec x } 
= \ mathbf { \ vec x } ^ * 
\ \ | \ mathbf { \ vec g } 
_ k | \ ge e \ 则 \ \ 
mathbf B _ k \ mathbf { \ vec p 
} _ k = \ mathbf { \ vec g 
} _ k \ 求 \ \ mathbf { \ 
vec p } _ k \ 这里 表面 上看 需要 
对 矩阵 求 逆 但是 实际 \ \ mathbf B 
_ k ^ { 1 } \ 有 迭代 公式 
根据 Sherman Morrison 公式 以 \ \ mathbf B _ 
k \ 的 迭代 公式 可以 得 \ \ mathbf 
B _ k ^ { 1 } \ 的 迭代 
公式 一维 搜索 \ \ epsilon _ k \ \ 
\ epsilon _ k = \ min _ { \ 
epsilon \ ge 0 } f \ mathbf { \ 
vec x } ^ { k } + \ epsilon 
\ mathbf { \ vec p } _ k \ 
设 \ \ mathbf { \ vec x } ^ 
{ k + 1 } = \ mathbf { \ 
vec x } ^ { k } + \ epsilon 
_ k \ mathbf { \ vec p } _ 
k \ 计 \ \ mathbf { \ vec g 
} _ { k + 1 } = g \ 
mathbf { \ vec x } ^ { k + 
1 } \ \ | \ mathbf { \ vec 
g } _ { k + 1 } | \ 
lt e \ 则 停止 计算 得到 近似 \ \ 
mathbf { \ vec x } = \ mathbf { 
\ vec x } ^ * \ 否则 计算 置 
\ = k + 1 \ \ \ mathbf B 
_ k \ mathbf { \ vec p } _ 
k = \ mathbf { \ vec g } _ 
k \ 求 \ \ mathbf { \ vec p 
} _ k \ 迭代 BFPS 算法 中 每一 \ 
\ mathbf { \ vec x } \ 增加 的 
方向 \ \ mathbf B _ k ^ { 1 
} \ nabla _ k \ 的 方向 增加 的 
幅度 \ \ epsilon _ k \ 决定 若 跨度 
过大 容易 引发 震荡 5.3 Broyden 类 算法 若 \ 
\ mathbf G _ k = \ mathbf B _ 
k ^ { 1 } \ mathbf G _ { 
k + 1 } = \ mathbf B _ { 
k + 1 } ^ { 1 } \ 则 
对 式子 \ \ mathbf B _ { k + 
1 } = \ mathbf B _ k + \ 
frac { \ mathbf { \ vec y } _ 
k \ mathbf { \ vec y } _ k 
^ { T } } { \ mathbf { \ 
vec y } _ k ^ { T } \ 
vec \ delta _ k } \ frac { \ 
mathbf B _ k \ vec \ delta _ k 
\ vec \ delta _ k ^ { T } 
\ mathbf B _ k } { \ vec \ 
delta _ k ^ { T } \ mathbf B 
_ k \ vec \ delta _ k } \ 
使用 两次 Sherman Morrison 公式 可得 \ \ mathbf G 
_ { k + 1 } = \ mathbf I 
\ frac { \ vec \ delta _ k \ 
mathbf { \ vec y } _ k ^ { 
T } } { \ vec \ delta _ k 
^ { T } \ mathbf { \ vec y 
} _ k } \ mathbf G _ k \ 
mathbf I \ frac { \ vec \ delta _ 
k \ mathbf { \ vec y } _ k 
^ { T } } { \ vec \ delta 
_ k ^ { T } \ mathbf { \ 
vec y } _ k } ^ { T } 
+ \ frac { \ vec \ delta _ k 
\ vec \ delta _ k ^ { T } 
} { \ vec \ delta _ k ^ { 
T } \ mathbf { \ vec y } _ 
k } \ 其中 的 向 \ \ vec \ 
delta _ k \ mathbf { \ vec y } 
_ k \ 都是 列 向量 令 DFP 算法 获得 
\ \ mathbf G _ { k + 1 } 
\ 的 迭代 公式 记作 \ \ mathbf G ^ 
{ DFP } = \ mathbf G _ k + 
\ frac { \ vec \ delta _ k \ 
vec \ delta _ k ^ { T } } 
{ \ vec \ delta _ k ^ { T 
} \ mathbf { \ vec y } _ k 
} \ frac { \ mathbf G _ k \ 
mathbf { \ vec y } _ k \ mathbf 
{ \ vec y } _ k ^ { T 
} \ mathbf G _ k } { \ mathbf 
{ \ vec y } _ k ^ { T 
} \ mathbf G _ k \ mathbf { \ 
vec y } _ k } \ 由 BFGS 算法 
获得 \ \ mathbf G _ { k + 1 
} \ 的 迭代 公式 记作 \ \ mathbf G 
^ { BFGS } = \ mathbf I \ frac 
{ \ vec \ delta _ k \ mathbf { 
\ vec y } _ k ^ { T } 
} { \ vec \ delta _ k ^ { 
T } \ mathbf { \ vec y } _ 
k } \ mathbf G _ k \ mathbf I 
\ frac { \ vec \ delta _ k \ 
mathbf { \ vec y } _ k ^ { 
T } } { \ vec \ delta _ k 
^ { T } \ mathbf { \ vec y 
} _ k } ^ { T } + \ 
frac { \ vec \ delta _ k \ vec 
\ delta _ k ^ { T } } { 
\ vec \ delta _ k ^ { T } 
\ mathbf { \ vec y } _ k } 
\ 他们 都 满足 拟 牛顿 条件 所以 他们 的 
线性组合 \ \ mathbf G _ { k + 1 
} = \ alpha \ mathbf G ^ { DFP 
} + 1 \ alpha \ mathbf G ^ { 
BFGS } \ 也 满足 拟 牛顿 条件 而且 是 
正定 的 其 \ 0 \ le \ alpha \ 
le 1 \ 这样 获得 了 一族 拟 牛顿 法 
称为 Broyden 类 算法 Sherman Morrison 公式 假 \ \ 
mathbf A \ \ n \ 阶 可逆矩阵 \ \ 
mathbf { \ vec u } \ mathbf { \ 
vec v } \ \ n \ 维 列 向量 
\ \ mathbf A + \ mathbf { \ vec 
u } \ mathbf { \ vec v } ^ 
{ T } \ 也是 可逆矩阵 则 \ \ mathbf 
A + \ mathbf { \ vec u } \ 
mathbf { \ vec v } ^ { T } 
^ { 1 } = \ mathbf A ^ { 
1 } \ frac { \ mathbf A ^ { 
1 } \ mathbf { \ vec u } \ 
mathbf { \ vec v } ^ { T } 
\ mathbf A ^ { 1 } } { 1 
+ \ mathbf { \ vec v } ^ { 
T } \ mathbf A ^ { 1 } \ 
mathbf { \ vec u } } \ 六 约束 
优化 6.1 原理 在 有的 最优化 问题 中 希望 输 
\ \ mathbf { \ vec x } \ 位于 
特定 的 集 \ \ mathbb \ 中 这 称作 
约束 优化 问题 集 \ \ mathbb \ 内 的 
点 \ \ mathbf { \ vec x } \ 
称作 可行 解 集合 \ \ mathbb \ 也 称作 
可行 域 约束 优化 的 一个 简单 方法 是 对 
梯度 下降 法 进行 修改 每次 迭代 后 将 得到 
的 新 \ \ mathbf { \ vec x } 
\ 映 射到 集 \ \ mathbb \ 中 如果 
使用 线性 搜索 则 每次 只 搜索 那些 使得 新 
\ \ mathbf { \ vec x } \ 位于 
集 \ \ mathbb \ 中的 那 \ \ epsilon 
\ 另 一个 做法 将 线性 搜索 得到 的 新的 
\ \ mathbf { \ vec x } \ 映 
射到 集合 \ \ mathbb \ 中 或者 在 线性 
搜索 之前 将 梯度 投影 到 可行 域 的 切空间 
内 6.2 KKT 方法 在 约束 最优化 问题 中 常常 
利用 拉格朗日 对偶性 将 原始 问题 转换 为 对偶 问题 
通过 求解 对偶 问题 而 得到 原始 问题 的 解 
约束 最优化 问题 的 原始 问题 假 \ f \ 
mathbf { \ vec x } c _ i \ 
mathbf { \ vec x } h _ j \ 
mathbf { \ vec x } \ 是 定义 \ 
\ mathbb R ^ { n } \ 上 的 
连续 可微 函数 考虑 约束 最优化 问题 \ \ min 
_ { \ mathbf { \ vec x } \ 
in \ mathbb R ^ { n } } f 
\ mathbf { \ vec x } \ \ s 
. t . \ quad c _ i \ mathbf 
{ \ vec x } \ le 0 i = 
1 2 \ cdots k \ \ quad h _ 
j \ mathbf { \ vec x } = 0 
j = 1 2 \ cdots l \ 可行 域 
由 等式 和 不等式 确定 \ \ mathbb = \ 
{ \ mathbf { \ vec x } \ mid 
c _ i \ mathbf { \ vec x } 
\ le 0 i = 1 2 \ cdots k 
\ \ quad h _ j \ mathbf { \ 
vec x } = 0 j = 1 2 \ 
cdots l \ } \ 6 . 2.1 原始 问题 
引入 拉格朗日 函数 \ L \ mathbf { \ vec 
x } \ vec \ alpha \ vec \ beta 
= f \ mathbf { \ vec x } + 
\ sum _ { i = 1 } ^ { 
k } \ alpha _ ic _ i \ mathbf 
{ \ vec x } + \ sum _ { 
j = 1 } ^ { l } \ beta 
_ jh _ j \ mathbf { \ vec x 
} \ 这 \ \ mathbf { \ vec x 
} = x ^ { 1 } x ^ { 
2 } \ cdots x ^ { n } ^ 
{ T } \ in \ mathbb R ^ { 
n } \ alpha _ i \ beta _ j 
\ 是 拉格朗日 乘子 \ \ alpha _ i \ 
ge 0 \ \ L \ mathbf { \ vec 
x } \ vec \ alpha \ vec \ beta 
\ 是 \ \ mathbf { \ vec x } 
\ vec \ alpha \ vec \ beta \ 的 
多元 非 线性函数 定义 函数 \ \ theta _ P 
\ mathbf { \ vec x } = \ max 
_ { \ vec \ alpha \ vec \ beta 
\ \ \ alpha _ i \ ge 0 } 
L \ mathbf { \ vec x } \ vec 
\ alpha \ vec \ beta \ 其 中下 \ 
P \ 表示 原始 问题 则有 \ \ theta _ 
P \ mathbf { \ vec x } = \ 
begin { cases } f \ mathbf { \ vec 
x } & \ text { if $ \ mathbf 
{ \ vec x } $ statisfy original problem s 
constraint } \ \ + \ infty & \ text 
{ or else . } \ end { cases } 
\ \ \ mathbf { \ vec x } \ 
满足 原 问题 的 约束 则 很容易 证 \ L 
\ mathbf { \ vec x } \ vec \ 
alpha \ vec \ beta = f \ mathbf { 
\ vec x } + \ sum _ { i 
= 1 } ^ { k } \ alpha _ 
ic _ i \ mathbf { \ vec x } 
\ le f \ mathbf { \ vec x } 
\ 等号 \ \ alpha _ i = 0 \ 
时 取到 \ \ mathbf { \ vec x } 
\ 不满足 原 问题 的 约束 若 不满足 $ c 
_ i \ mathbf { \ vec x } \ 
le 0 $ 设 违反 的 为 \ c _ 
{ i0 } \ mathbf { \ vec x } 
\ gt 0 \ 则 令 \ \ vec \ 
alpha _ { i0 } \ rightarrow \ infty \ 
\ L \ mathbf { \ vec x } \ 
vec \ alpha \ vec \ beta = f \ 
mathbf { \ vec x } + \ sum _ 
{ i = 1 } ^ { k } \ 
alpha _ ic _ i \ mathbf { \ vec 
x } \ rightarrow \ infty \ 若 不满足 $ 
h _ j \ mathbf { \ vec x } 
= 0 $ 设 违反 的 为 \ h _ 
{ j0 } \ mathbf { \ vec x } 
\ ne 0 \ 则 令 \ \ vec \ 
beta _ { j0 } h _ { j0 } 
\ mathbf { \ vec x } \ rightarrow \ 
infty \ \ L \ mathbf { \ vec x 
} \ vec \ alpha \ vec \ beta = 
f \ mathbf { \ vec x } + \ 
sum _ { i = 1 } ^ { k 
} \ alpha _ ic _ i \ mathbf { 
\ vec x } + \ vec \ beta _ 
{ j0 } h _ { j0 } \ mathbf 
{ \ vec x } \ rightarrow \ infty \ 
考虑 极小 化 问题 \ \ min _ { \ 
mathbf { \ vec x } } \ theta _ 
P \ mathbf { \ vec x } = \ 
min _ { \ mathbf { \ vec x } 
} \ max _ { \ vec \ alpha \ 
vec \ beta \ \ \ alpha _ i \ 
ge 0 } L \ mathbf { \ vec x 
} \ vec \ alpha \ vec \ beta \ 
则 该 问题 是 与 原始 最优化 问题是 等价 的 
即 他们 有 相同 的 问题 \ \ min _ 
{ \ mathbf { \ vec x } } \ 
max _ { \ vec \ alpha \ vec \ 
beta \ \ \ alpha _ i \ ge 0 
} L \ mathbf { \ vec x } \ 
vec \ alpha \ vec \ beta \ 称为 广义 
拉格朗日 函数 的 极大 极 小问题 为了 方便 定义 原始 
问题 的 最优 值 为 \ p ^ { * 
} = \ min _ { \ mathbf { \ 
vec x } } \ theta _ P \ mathbf 
{ \ vec x } \ 6 . 2.2 对偶 
问题 对偶 问题 定 \ \ theta _ D \ 
vec \ alpha \ vec \ beta = \ min 
_ \ mathbf { \ vec x } L \ 
mathbf { \ vec x } \ vec \ alpha 
\ vec \ beta \ 考虑 极大 \ \ theta 
_ D \ vec \ alpha \ vec \ beta 
\ 即 \ \ max _ { \ vec \ 
alpha \ vec \ beta \ \ \ alpha _ 
i \ ge 0 } \ theta _ D \ 
vec \ alpha \ vec \ beta = \ max 
_ { \ vec \ alpha \ vec \ beta 
\ \ \ alpha _ i \ ge 0 } 
\ min _ { \ mathbf { \ vec x 
} } L \ mathbf { \ vec x } 
\ vec \ alpha \ vec \ beta \ 问题 
\ \ max _ { \ vec \ alpha \ 
vec \ beta \ \ \ alpha _ i \ 
ge 0 } \ min _ { \ mathbf { 
\ vec x } } L \ mathbf { \ 
vec x } \ vec \ alpha \ vec \ 
beta \ 称为 广义 拉格朗日 函数 的 极大 极 小问题 
可以 将 广义 拉格朗日 函数 的 极大 极小 问题 表示 
为 约束 最优化 问题 \ \ max _ { \ 
vec \ alpha \ vec \ beta \ \ \ 
alpha _ i \ ge 0 } \ theta _ 
D \ vec \ alpha \ vec \ beta = 
\ max _ { \ vec \ alpha \ vec 
\ beta \ \ \ alpha _ i \ ge 
0 } \ min _ { \ mathbf { \ 
vec x } } L \ mathbf { \ vec 
x } \ vec \ alpha \ vec \ beta 
\ \ s . t . \ alpha _ i 
\ ge 0 i = 1 2 \ cdots k 
\ 称为 原始 问题 的 对偶 问题 定义 对偶 问题 
的 最优 值 \ d ^ * = \ max 
_ { \ vec \ alpha \ vec \ beta 
\ \ \ alpha _ i \ ge 0 } 
\ theta _ D \ vec \ alpha \ vec 
\ beta \ 6 . 2.3 原始 问题 与 对偶 
问题 关系 定理 一 若 原 问题 和 对偶 问题 
具有 最优 值 则 \ d ^ { * } 
= \ max _ { \ vec \ alpha \ 
vec \ beta \ \ \ vec \ alpha _ 
i \ ge 0 } \ min _ { \ 
mathbf { \ vec x } } L \ mathbf 
{ \ vec x } \ vec \ alpha \ 
vec \ beta \ le \ min _ { \ 
mathbf { \ vec x } } \ max _ 
{ \ vec \ alpha \ vec \ beta \ 
\ \ vec \ alpha _ i \ ge 0 
} L \ mathbf { \ vec x } \ 
vec \ alpha \ vec \ beta = p ^ 
{ * } \ 推论 一 \ \ mathbf { 
\ vec x } ^ { * } \ 为 
原始 问题 的 可行 解 \ \ theta _ P 
\ mathbf { \ vec x } ^ { * 
} \ 的 值 \ p ^ { * } 
\ \ \ vec \ alpha ^ { * } 
\ vec \ beta ^ { * } \ 为 
对偶 问题 的 可行 解 \ \ theta _ D 
\ vec \ alpha ^ { * } \ vec 
\ beta ^ { * } \ 值 \ d 
^ { * } \ 如果 \ p ^ { 
* } = d ^ { * } \ \ 
\ mathbf { \ vec x } ^ { * 
} \ vec \ alpha ^ { * } \ 
vec \ beta ^ { * } \ 分别 为 
原始 问题 和 对偶 问题 的 最优 解 定理 二 
假设 函 \ f \ mathbf { \ vec x 
} \ \ c _ i \ mathbf { \ 
vec x } \ 为 凸函数 \ h _ j 
\ mathbf { \ vec x } \ 是 仿射 
函数 并且 假设 不等式 约 \ c _ i \ 
mathbf { \ vec x } \ 是 严格 可行 
的 即 存 \ \ mathbf { \ vec x 
} \ 对于 所 \ i \ \ c _ 
i x \ lt 0 \ 则 存 \ \ 
mathbf { \ vec x } ^ { * } 
\ vec \ alpha ^ { * } \ vec 
\ beta ^ { * } \ 使得 \ \ 
mathbf { \ vec x } ^ { * } 
\ 是 原始 问 \ \ min _ { \ 
mathbf { \ vec x } } \ theta _ 
P \ mathbf { \ vec x } \ 的 
解 \ \ vec \ alpha ^ { * } 
\ vec \ beta ^ { * } \ 是 
对偶 问 \ \ max _ { \ vec \ 
alpha \ vec \ beta \ \ \ alpha _ 
i \ ge 0 } \ theta _ D \ 
vec \ alpha \ vec \ beta \ 的 解 
并 \ p ^ { * } = d ^ 
{ * } = L \ mathbf { \ vec 
x } ^ { * } \ vec \ alpha 
^ { * } \ vec \ beta ^ { 
* } \ 定理 三 假设 函 \ f \ 
mathbf { \ vec x } \ \ c _ 
i \ mathbf { \ vec x } \ 为 
凸函数 \ h _ j \ mathbf { \ vec 
x } \ 是 仿射 函数 并且 假设 不等式 约 
\ c _ i \ mathbf { \ vec x 
} \ 是 严格 可行 的 即 存 \ \ 
mathbf { \ vec x } \ 对于 所 \ 
i \ \ c _ i x \ lt 0 
\ 则 存 \ \ mathbf { \ vec x 
} ^ { * } \ vec \ alpha ^ 
{ * } \ vec \ beta ^ { * 
} \ 使 \ \ mathbf { \ vec x 
} ^ { * } \ 是 原始 问 \ 
\ min _ { \ mathbf { \ vec x 
} } \ theta _ P \ mathbf { \ 
vec x } \ 的 解 \ \ vec \ 
alpha ^ { * } \ vec \ beta ^ 
{ * } \ 是 对偶 问 \ \ max 
_ { \ vec \ alpha \ vec \ beta 
\ \ \ alpha _ i \ ge 0 } 
\ theta _ D \ vec \ alpha \ vec 
\ beta \ 的 解的/nr 充要条件 是 \ \ mathbf 
{ \ vec x } ^ { * } \ 
vec \ alpha ^ { * } \ vec \ 
beta ^ { * } \ 满足 下面 的 Karush 
kuhn Tucker KKT 条件 \ \ nabla _ \ mathbf 
{ \ vec x } L \ mathbf { \ 
vec x } ^ { * } \ vec \ 
alpha ^ { * } \ vec \ beta ^ 
{ * } = 0 \ \ \ nabla _ 
\ vec \ alpha L \ mathbf { \ vec 
x } ^ { * } \ vec \ alpha 
^ { * } \ vec \ beta ^ { 
* } = 0 \ \ \ nabla _ \ 
vec \ beta L \ mathbf { \ vec x 
} ^ { * } \ vec \ alpha ^ 
{ * } \ vec \ beta ^ { * 
} = 0 \ \ \ vec \ alpha ^ 
{ * } _ ic _ i \ mathbf { 
\ vec x } ^ { * } = 0 
i = 1 2 \ cdots k \ \ c 
_ i \ mathbf { \ vec x } ^ 
{ * } \ le 0 i = 1 2 
\ cdots k \ \ \ vec \ alpha ^ 
{ * } _ i \ ge 0 i = 
1 2 \ cdots k \ \ h _ j 
\ mathbf { \ vec x } ^ { * 
} = 0 j = 1 2 \ cdots l 
\ 仿射 函数 仿射 函数 即由 1 阶 多项式 构成 
的 函数 一般 形式 \ f \ mathbf { \ 
vec x } = \ mathbf A \ mathbf { 
\ vec x } + b \ 这里 \ \ 
mathbf A \ 是 一 \ m \ times k 
\ 矩阵 \ \ mathbf { \ vec x } 
\ 是 一 \ k \ 维 列 向量 \ 
b \ 是 一 \ m \ 维 列 向量 
它 实际上 反映 了 一种 从 \ k \ 维 
到 \ m \ 维 的 空间 映射 关系 凸函数 
\ f \ 为 定义 在 区 \ I \ 
上 的 函数 若 \ I \ 上 的 任意 
两 \ \ mathbf { \ vec x } _ 
1 \ mathbf { \ vec x } _ 2 
\ 和 任意 的 实 \ \ lambda \ in 
0 1 \ 总 \ f \ lambda \ mathbf 
{ \ vec x } _ 1 + 1 \ 
lambda \ mathbf { \ vec x } _ 2 
\ ge \ lambda f \ mathbf { \ vec 
x } _ 1 + 1 \ lambda f \ 
mathbf { \ vec x } _ 2 \ \ 
f \ 称 \ I \ 上 的 凸函数 本文 
转载自 华校 专 老师 博客 博客地址 http / / www 
. huaxiaozhuan . com / 