机器学习 需要 从 已知 的 数据 学习 出 需要 的 
模型 在线 算法 需要 及时 处理 收集 的 数据 并 
给出 预测 或 建议 结果 并 更新 模型 通用 的 
在线 学习 算法 步骤 如下 1 . 收集 和 学习 
现有 的 数据 2 . 依据 模型 或 规则 做出 
决策 给出 结果 3 . 根据 真实 的 结果 来 
训练 和 学习 规则 或 模型 常用 的 在线 学习 
算法 Perception 感知器 PA passive perceptionPA IPA IIVoted P e 
r c e p t i o n c o 
n f i d e n c e weighted linear 
linear classification 基于 置信度 加权 的 线性 分类器 Weight Majority 
algorithmAROW adaptive regularization of weighted vector 加 权向量 的 自适应 
正则化 NHERD Normal Herd 正 态 这里 收集 了 一些 
算法 伪代码 代码 然后 配上 语言 描述 就 清晰 多了 
感知器 Perception 线性 分类器 是 一个 利用 超平面 来 进行 
二 分类 的 分类器 每次 利用 新的 数据 实例 预测 
比对 更新 来 调整 超平面 的 位置 相对于 SVM 感知器 
不要 每类 数据 与 分类 面的 间隔 最大化 平均 感知器 
Average Perception 线性 分类器 其 学习 的 过程 与 Perception 
感知器 的 基本 相同 只不过 它 将 所有 的 训练 
过程 中 的 权值 都 保留 下来 然后 求 均值 
优点 克服 由于 学习 速率 过大 所 引起 的 训练 
过程 中 出现 的 震荡 现象 即 超平面 围着 一个 
中心 忽左忽右 之类 . . . Passive Aggressive Perception 修正 
权值 时 增加 了 一个 参数 Tt 预测 正确 时 
不 需要 调整 权值 预测 错误 时 主动 调整 权值 
并 可以 加入 松弛 变量 的 概念 形成 其 算法 
的 变种 优点 能 减少 错误 分类 的 数目 而且 
适用 于不/nr 可分 的 噪声 情况 Tt 有三种 计算方法 a 
. Tt =   lt / | | Xt | 
| ^ 2 b . Tt =   min { 
C lt / | | Xt | | ^ 2 
} c .   Tt =   lt / | 
| Xt | | ^ 2 + 1 / 2C 
分别 对应 PA PA I PA II 算法 三种 类型 
Voted Perception 存储 和 使用 所有 的 错误 的 预测 
向量 优点 实现 对 高维 数据 的 分类 克服 训练 
过程 中 的 震荡 训练 时间 比 SVM 要好 缺点 
不能 保证 收敛 Confidence Weight 线性 分类器 每个 学习 参数 
都 有个 信任度 概率 信任度 小 的 参数 更 应该 
学习 所以 会 得到 更 频繁 的 修改 机会 信任度 
用 参数 向量 的 高斯分布 表示 权值 w 符合 高斯分布 
N u 离差 阵 而 由 w * x 的 
结果 可以 预测 其 分类 的 结果 并对 高斯分布 的 
参数 进行 更新 这种 方法 能 提供 分类 的 准确性 
并 加快 学习 速度 其 理论 依据 在 在于 算法 
正确 的 预测 概率 不小于 高斯分布 的 一个 值 AROW 
adaptive regularition of weighted vector 具有 的 属性 大 间隔 
训练 large margin training 置信度 权值 confidence weight 处理 不 
可分 数据 噪声 non separable 相对于 SOP second of perception 
PA CW 在 噪声 情况下 其 效果 会 更好 . 
Normal herding 线性/n 分类器/n NHerd/w 算法/n 在/p 计算/v 全/a 协方差/n 
阵/n 和/c 对角/n 协方差/n 阵/n 时/n 比 AROW 更加 的 
积极 Weight Majority 每个 维度 都 可以 作为 一个 分类器 
进行 预测 然后 依据 权值 综合 所 有结果 给 出 
一个 最终 的 预测 依据 最终 的 预测 和 实际 
测量 结果 调整 各 个 维度 的 权值 即 更新 
模型 易于 实施 错误 界 比较 小 可 推导 Voted 
Perception 存储 和 使用 所有 的 错误 的 预测 向量 
优点 实现 对 高维 数据 的 分类 克服 训练 过程 
中 的 震荡 训练 时间 比 SVM 要好 缺点 不能 
保证 收敛 