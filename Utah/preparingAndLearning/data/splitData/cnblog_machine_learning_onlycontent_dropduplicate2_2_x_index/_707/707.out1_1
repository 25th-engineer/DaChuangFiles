然后 看 的 是 机器 学习 这 一块 因为 偏 
理论 可以 先 看完 其他 的 实践 再看 http / 
/ www . cnblogs . com / shishanyuan / p 
/ 4747761 . html 机器学习 是 用 数据 或 以往 
的 经验 以此 优化 计算机程序 的 性能 标准   一种 
经常 引用 的 英文 定义 是 A computer program is 
said to learn from experience E with respect to some 
class of tasks T and performance measure P if its 
performance at tasks in T as measured by P improves 
with experience E 可以 看出 机器学习 强调 三个 关键词 算法 
经验 效果 其 处理 过程 如下 图 所示 上图 表明 
机器学习 是 数据 通过 算法 构建 出 模型 并对 模型 
进行 评估 评估 的 性能 如果 达到 要求 就 拿 
这个 模型 来 测试 其他 的 数据 如果 达 不到 
要求 就 要 调整 算法 来 重新 建立 模型 再次 
进行 评估 如此 循环往复 最终 获得 满意 的 经验 来 
处理 其他 的 数据 1.2   机器 学习 的 分类 
另外 这 一篇 文章 里 也有 数据挖掘 机器学习 的 分类 
和 应用 场景 对比 着看 http / / www . 
cnblogs . com / charlesblc / p / 6126346 . 
html1 . 2.1   监督 学习 监督 是从 给定 的 
训练 数据 集中 学习 一个 函数 模型 当 新的 数据 
到 来时 可以 根据 这个 函数 模型 预测 结果 监督 
学习 的 训练 集 要求 包括 输入 和 输出 也 
可以 说 是 特征 和 目标 训练 集中 的 目标 
是 由人 标注 标量 的 在 监督 式 学习 下 
输入 数据 被 称为 训练 数据 每组 训练 数据 有 
一个 明确 的 标识 或 结果 如对 防 垃圾 邮件 
系统 中 垃圾邮件 非 垃圾邮件 对 手写 数字 识别 中的 
1 2 3 等 在 建立 预测模型 时 监督 式 
学习 建立 一个 学习 过程 将 预测 结果 与 训练 
数据 的 实际 结果 进行 比较 不断 调整 预测模型 直到 
模型 的 预测 结果 达到 一个 预期 的 准确率 常见 
的 监督 学习 算法 包括 回归分析 和 统计 分类 l 
    二元 分类 是 机器 学习 要 解决 的 
基本 问题 将 测试数据 分成 两个 类 如 垃圾 邮件 
的 判别 房贷 是否 允许 等 问题 的 判断 l 
    多元 分类 是 二元 分类 的 逻辑 延伸 
例如 在 因特网 的 流 分类 的 情况 下 根据 
问题 的 分类 网页 可以 被 归类 为 体育 新闻 
技术 等 依此类推 监督 学习 常常 用于 分类 因 为 
目标 往往 是 让 计算机 去 学习 我们 已经 创 
建好 的 分类 系统 数字 识别 再一次 成为 分类 学习 
的 常见 样本 一般来说 对于 那些 有用 的 分类 系统 
和 容易 判断 的 分类 系统 分类 学习 都 适用 
监督 学习 是 训练 神经 网络 和 决策树 的 最 
常见 技术 神经/n 网络/n 和/c 决策树/n 技术/n 高度/n 依赖/v 于/p 
事先/d 确定/v 的/uj 分类/n 系统/n 给出/v 的/uj 信息/n 对于 神经网络 
来说 分类 系统 用于 判断 网络 的 错误 然后 调整 
网络 去 适应 它 对于 决策树 分类 系统 用来 判断 
哪些 属性 提供 了 最多 的 信息 如此一来 可以 用 
它 解决 分类 系统 的 问题 1 . 2.2   
无 监督 学习 与 监督 学习 相比 无 监督 学习 
的 训练 集 没有人 为 标注 的 结果 在 非 
监督 式 学习 中 数据 并不 被 特别 标识 学习 
模型 是 为了 推断出 数据 的 一些 内在 结构 常见 
的 应用 场景 包括 关联 规则 的 学习 以及 聚 
类 等 常见 算法 包括 Apriori 算法 和k/nr Means 算法 
这类 学习类型 的 目标 不是 让 效用函数 最大化 而是 找到 
训练 数据 中的 近似 点 聚 类 常常 能 发现 
那些 与 假设 匹配 的 相当 好 的 直观 分类 
例如 基于 人口 统计 的 聚合 个体 可能会 在 一个 
群体 中 形成 一个 富有 的 聚合 以及 其他 的 
贫穷 的 聚合 非 监督 学习 看起来 非常 困难 目标 
是 我们 不 告诉 计算机 怎么做 而是 让 它 计算机 
自己 去 学习 怎样 做 一些 事情 非 监督 学习 
一般 有 两种 思路 第 一种 思路 是 在 指导 
Agent 时不 为其 指定 明确 的 分类 而是 在 成功 
时 采用 某种 形式 的 激励 制度 需要 注意 的 
是 这类 训练 通常会 置于 决策 问题 的 框架 里 
因为 它 的 目标 不是 产生 一个 分类 系统 而是 
做 出 最大 回报 的 决定 这种 思路 很好 地 
概括 了 现实 世界 Agent 可以 对 那些 正确 的 
行为 做出 激励 并对 其他 的 行为 进行 处罚 1/m 
./i 2.3/mx  /i 半/m 监督/vn 学习/v 主要/b 考虑/v 如何/r 利用/n 
少量/m 的/uj 标注/v 样本/n 和/c 大量/n 的/uj 未/d 标注/v 样本/n 
进行/v 训练/vn 和/c 分类/n 的/uj 问题/n 半 监督 学习 对于 
减少 标注 代价 提高 学习 机器 性能 具有 非常 重大 
的 实际 意义 主要 算法 有 五类 基于 概率 的 
算法 在 现有 监督 算法 基础 上 进行 修改 的 
方法 直接 依赖 于聚类/nr 假设 的 方法 等 . 在此 
学习 方式 下 输入 数据 部分 被 标识 部分 没有 
被 标识 这种 学习 模型 可以 用来 进行 预测 但是 
模型 首先 需要 学习 数据 的 内在 结构 以便 合理 
地 组织 数据 来 进行 预测 应用 场景 包括 分类 
和 回归 算法 包括 一些 对 常用 监督 式 学习 
算法 的 延伸 这些 算法 首先 试图 对 未 标识 
数据 进行 建模 在此 基础上 再 对 标识 的 数据 
进行 预测 如 图论 推理 算法 Graph Inference 或者 拉普拉斯 
支持 向量 机 Laplacian SVM 等 分类 和 回归 的 
区别 在于 输出 变量 的 类型 定量 输出 称为 回归 
或者 说是 连续变量 预测 定性 输出 称为 分类 或者 说是 
离散 变量 预测 举个 例子 预测 明天 的 气温 是 
多少 度 这 是 一个 回归 任务 预测 明天 是 
阴 晴 还是 雨 就是 一个 分类 任务 半 监督 
学习 从 诞生 以来 主要 用于 处理 人工合成 数据 无 
噪声 干扰 的 样本 数据 是 当前 大 部分 半 
监督 学习 方法 使用 的 数据 而在 实际 生活 中 
用到 的 数据 却 大部分 不是 无 干扰 的 通常 
都 比较 难以 得到 纯 样本数据 1 . 2.4   
强化 学习 在 这种 学习 模式 下 输入 数据 作为 
对 模型 的 反馈 不像 监督 模型 那样 输入 数据 
仅仅 是 作为 一个 检查 模型 对错 的 方式 在 
强化 学习 下 输入 数据 直接 反馈 到 模型 模型 
必须 对此 立刻 做出 调整 常见 的 应用 场景 包括 
动态 系统 以及 机器人 控制 等 常见 算法 包括 Q 
Learning   以及 时间差 学习 Temporal difference learning 总结 在 
企业 数据 应用 的 场景 下 人们 最 常用 的 
可能 就是 监督 式 学习 和非/nr 监督 式 学习 的 
模型 在 图像 识别 等 领域 由于 存在 大量 的 
非 标识 的 数据 和 少量 的 可 标识 数据 
目 前半 监督 式 学习 是 一个 很热 的 话题 
而 强化 学习 更多 地 应用 在 机器人 控制 及 
其他 需要 进行 系统 控制 的 领域 1.3   机器 
学习 的 常见 算法 常见 的 机器学习 算法 有 l 
    构造 条件概率 回归分析 和 统计 分类 l   
  人工神经网络 l     决策树 l     高斯 
过程 回归 l     线性 判别分析 l     
最近 邻居 法 l     感知器 l     
径向 基 函数 核 l     支持 向量 机 
l     通过 再生 模型 构造 概率密度函数 l   
  最大 期望 算法 l     graphical model 包括 
贝叶斯 网 和 Markov 随 机场 l     Generative 
Topographic Mapping l     近似 推断 技术 l   
  马尔可夫 链 蒙特卡罗 方法 l     变分法 l 
    最优化 大多数 以上 方法 直接 或者 间接 使用 
最 优化 算法 根据 算法 的 功能 和 形式 的 
类似性 我们 可以 把 算法 分类 比如说 基于 树 的 
算法 基于 神经 网络 的 算法 等等 当然 机器 学习 
的 范围 非常 庞大 有些 算法 很难 明确 归类 到 
某一 类 而 对于 有些 分类 来说 同一 分类 的 
算法 可以 针对 不同 类型 的 问题 下面 用 一些 
相对 比较 容易 理解 的 方式 来 解析 一些 主要 
的 机器学习 算法 1 . 3.1   回归 算法 回归 
算法 是 试图 采用 对 误差 的 衡量 来 探索 
变量 之间 的 关系 的 一类 算法 回归 算法 是 
统计 机器 学习 的 利器 在 机器学习 领域 人们 说起 
回归 有时候 是 指 一类 问题 有时候 是 指 一类 
算法 这 一点 常常 会使 初学者 有所 困惑 常见 的 
回归 算法 包括 最小二乘 法 Ordinary Least Square 逻辑 回归 
Logistic Regression 逐步 式 回归 Stepwise Regression 多元 自适应 回归 
样条 Multivariate Adaptive Regression Splines 以及 本地 散 点 平滑 
估计 Locally Estimated Scatterplot Smoothing 1 . 3.2   基于 
实例 的 算法 基于 实例 的 算法 常常 用来 对 
决策 问题 建立 模型 这样 的 模型 常常 先 选取 
一批 样本数据 然后 根据 某些 近似 性 把 新 数据 
与 样本数据 进行 比较 通过 这种 方式 来 寻找 最佳 
的 匹配 因此 基于 实例 的 算法 常常 也 被 
称为 赢家 通吃 学习 或者 基于 记忆 的 学习 常见 
的 算法 包括   k Nearest Neighbor KNN 学习 矢量 
量化 Learning Vector Quantization   LVQ 以及 自组织 映射 算法 
Self Organizing Map SOM 1 . 3.3   正则化 方法 
正则化 方法 是 其他 算法 通常 是 回归 算法 的 
延伸 根据 算法 的 复杂度 对 算法 进行 调整 正则化 
方法 通常 对 简单 模型 予以 奖励 而对 复杂 算法 
予以 惩罚 常见 的 算法 包括 Ridge Regression Least Absolute 
Shrinkage and Selection Operator LASSO 以及 弹性 网络 Elastic Net 
1 . 3.4   决策树 学习 决策树 算法 根据 数据 
的 属性 采用 树状 结构 建立 决策模型 决策树 模型 常常 
用 来 解决 分类 和 回归 问题 常见 的 算法 
包括 分类 及 回归 树 Classification And Regression Tree   
CART   ID3 Iterative Dichotomiser 3 C 4.5 Chi squared 
Automatic Interaction Detection CHAID Decision Stump 机 森林 Random Forest 
多元 自适应 回归 样条 MARS 以及 梯度 推进机 Gradient Boosting 
Machine GBM 1 . 3.5   贝叶斯 学习 贝叶斯 方法 
算法 是 基于 贝叶 斯定理 的 一类 算法 主要 用来 
解决 分类 和 回归 问题 常见 算法 包括 朴素 贝叶斯 
算法 平均 单 依赖 估计 Averaged One Dependence Estimators   
AODE 以及   Bayesian Belief Network BBN 1 . 3.6 
  基于 核 的 算法 基于 核 的 算法 中最 
著名 的 莫过于 支持 向量 机 SVM 了 基于 核 
的 算法 把 输入 数据 映射 到 一个 高阶 的 
向量空间 在 这些 高阶 向量空间 里 有些 分类 或者 回归 
问题 能够 更 容易 解决 常见 的 基于 核 的 
算法 包括 支持 向量 机 Support Vector Machine SVM 径向 
基 函数 Radial Basis Function RBF 以及 线性 判别分析 Linear 
Discriminate Analysis LDA 等 1 . 3.7   聚 类 
算法 聚 类 就像 回归 一样 有时候 人们 描述 的 
是 一类 问题 有时候 描述 的 是 一类 算法 聚 
类 算法 通常 按照 中心点 或者 分层 的 方式 对 
输入 数据 进行 归并 所有 的 聚 类 算法 都 
试图 找到 数据 的 内在 结构 以便 按照 最大 的 
共同点 将 数据 进行 归类 常见 的 聚 类 算法 
包括   k Means   算法 以及 期望 最大化 算法 
Expectation Maximization EM 1 . 3.8   关联 规则学习 关联 
规则学习 通过 寻找 最 能够 解释 数据 变量 之间 关系 
的 规则 来找 出 大量 多元 数据 集中 有用 的 
关联 规则 常见 算法 包括   Apriori 算法 和 /nr Eclat 
  算法 等 1 . 3.9   人工神经网络 算法 人工神经网络 
算法 模拟 生物 神经网络 是 一类 模式匹配 算法 通常 用于 
解决 分类 和 回归 问题 人工神经网络 是 机器 学习 的 
一个 庞大 的 分支 有 几百 种 不同 的 算法 
其中 深度 学习 就是 其中 的 一类 算法 我们 会 
单独 讨论 重要 的 人工神经网络 算法 包括 感知器 神经网络 Perceptron 
Neural Network 反向 传递 Back Propagation Hopfield   网络 自组织 
映射 Self Organizing Map SOM 学习 矢量 量化 Learning Vector 
Quantization LVQ 1 . 3.10   深度 学习 算法 深度 
学习 算法 是 对 人工 神经 网络 的 发展 在 
近期 赢得 了 很多 关注 特别 是 百度 也 开始 
发力 深度 学习 后 更是 在 国内 引起 了 很多 
关注 在 计算 能力 变得 日益 廉价 的 今天 深度 
学习 试图 建立 大得多 也 复杂 得多 的 神经 网络 
很多 深度 学习 的 算法 是 半 监督 式 学习 
算法 用来 处理 存在 少量 未 标识 数据 的 大 
数据集 常见 的 深度 学习 算法 包括 受限 波尔兹曼 机 
Restricted Boltzmann Machine RBN   Deep Belief Networks DBN 卷积 
网络 Convolutional Network 堆栈 式 自动 编码器 Stacked Auto encoders 
1 . 3.11   降低 维度 算法 像 聚 类 
算法 一样 降低 维度 算法 试图 分析 数据 的 内在 
结构 不过 降低 维度 算法 是以 非 监督 学习 的 
方式 试图 利用 较少 的 信息 来 归纳 或者 解释 
数据 这类 算法 可以 用于 高维 数据 的 可视化 或者 
用来 简化 数据 以便 监督 式 学习 使用 常见 的 
算法 包括 主 成份 分析 Principle Component Analysis   PCA 
偏 最小二乘 回归 Partial Least Square Regression PLS   Sammon 
  映射 多维 尺度 Multi Dimensional Scaling MDS 投影 追踪 
Projection Pursuit 等 1 . 3.12   集成 算法 集成 
算法 用 一些 相对 较弱 的 学习 模型 独立 地 
对 同样 的 样本 进行 训练 然后 把 结果 整合 
起来 进行 整体 预测 集成 算法 的 主要 难点 在于 
究竟 集成 哪些 独立 的 较弱 的 学习 模型 以及 
如何 把 学习 结果 整合 起来 这是 一类 非常 强大 
的 算法 同时 也 非常 流行 常见 的 算法 包括 
Boosting Bootstrapped Aggregation Bagging AdaBoost 堆叠 泛化 Stacked Generalization Blending 
梯度 推进机 Gradient Boosting Machine GBM 随机 森林 Random Forest 
2 Spark MLlib 介绍 Spark 之所以 在 机器 学习 方面 
具有 得天独厚 的 优势 有 以下 几 点 原因 1 
机器学习/i 算法/n 一般/a 都有/nr 很多/m 个/q 步骤/n 迭代计算/i 的/uj 过程/n 
机器 学习 的 计算 需要 在 多次 迭代 后 获得 
足够 小 的 误差 或者 足够 收敛 才会 停止 迭代 
时 如果 使用 Hadoop 的 MapReduce 计算 框架 每次 计算 
都要 读 / 写 磁盘 以及 任务 的 启动 等 
工作 这回 导致 非常大 的 I / O 和 CPU 
消耗 而 Spark 基于 内存 的 计算 模型 天生 就 
擅长 迭代计算 多个 步骤 计算 直接 在 内存 中 完成 
只有/c 在/p 必要/d 时/n 才会/i 操作/v 磁盘/n 和/c 网络/n 所以 
说 Spark 正是 机器 学习 的 理想 的 平台 2 
从 通信 的 角度 讲 如果 使用 Hadoop 的 MapReduce 
计算 框架 JobTracker/w 和/c TaskTracker/w 之间/f 由于/c 是/v 通过/p heartbeat/w 
的/uj 方式/n 来/v 进行/v 的/uj 通信/l 和/c 传递数据/n 会 导致 
非常 慢 的 执行 速度 而 Spark 具有 出色 而 
高效 的 Akka 和 Netty 通信 系统 通信 效率 极高 
MLlib Machine Learnig lib   是 Spark 对 常用 的 
机器学习 算法 的 实现 库 同时 包括 相关 的 测试 
和 数据 生成器 Spark 的 设计 初衷 就是 为了 支持 
一些 迭代 的 Job   这 正好 符合 很多 机器学习 
算法 的 特点 在 Spark 官方 首页 中 展示 了 
Logistic Regression 算法 在 Spark 和 Hadoop 中 运行 的 
性能 比较 如图 下图 所示 可以 看出 在 Logistic Regression 
的 运算 场景 下 Spark 比 Hadoop 快了 100倍 以上 
MLlib 目前 支持 4种 常见 的 机器 学习 问题   
分类 回归 聚 类 和 协同 过滤 MLlib 在 Spark 
整个 生态 系统 中 的 位置 如图 下图 所示 注 
非常 好 把 Spark 上面 的 这 四类 都用 熟了 
MLlib 基于 RDD 天生 就 可以 与 Spark SQL GraphX 
Spark Streaming 无缝 集成 以 RDD 为 基石 4 个子 
框架 可 联手 构建 大 数据 计算中心 MLlib 是 MLBase 
一部分 其中 MLBase 分为 四 部分 MLlib MLI ML Optimizer 
和 MLRuntime l     ML Optimizer 会 选择 它 
认为 最 适合 的 已经 在 内部 实现 好了 的 
机器学习 算法 和 相关 参数 来 处理 用户 输入 的 
数据 并 返回 模型 或 别的/nr 帮助 分析 的 结果 
l     MLI   是 一个 进行 特征 抽取 
和 高级 ML 编程 抽象 的 算法 实现 的 API 
或 平台 l     MLlib 是 Spark 实现 一些 
常见 的 机器学习 算法 和 实用程序 包括 分类 回归 聚 
类 协同 过滤 降 维 以及 底层 优化 该算 法 
可以 进行 可 扩充 l   MLRuntime   基于 Spark 
计算 框架 将 Spark 的 分布式计算 应用到 机器学习 领域 3 
Spark MLlib 架构 解析 从 架构图 可以 看出 MLlib 主要 
包含 三 个 部分 l     底层 基础 包括 
Spark 的 运行库 矩阵 库 和 向量 库 l   
  算 法库 包含 广义 线性 模型 推荐 系统 聚 
类 决策树 和 评估 的 算法 l     实用程序 
包括 测试数据 的 生成 外部 数据 的 读入 等功能 3.1 
  MLlib 的 底层 基础 解析 底层 基础 部分 主要 
包括 向量 接口 和 矩阵 接口 这两种 接口 都会 使用 
Scala 语言 基于 Netlib 和 BLAS / LAPACK 开发 的 
线性代数 库 Breeze MLlib 支持 本地 的 密集 向量 和 
稀疏 向量 并且 支持 标量 向量 MLlib 同时 支持 本地 
矩阵 和 分布式 矩阵 支持 的 分布式 矩阵 分为 RowMatrix 
IndexedRowMatrix CoordinateMatrix 等 关于 密集型 和 稀疏 型 的 向量 
Vector 的 示例 如下 所示 疏 矩阵 在 含有 大量 
非零 元素 的 向量 Vector 计算 中会 节省 大量 的 
空间 并 大幅度提高 计算速度 如下 图 所示 标量 LabledPoint 在 
实际 中 也被 大量 使用 例如/v 判断/v 邮件/n 是否/v 为/p 
垃圾/n 邮件/n 时就/nr 可以/c 使用/v 类似/v 于/p 以下/f 的/uj 代码/n 
可以 把 表示 为 1.0 的 判断 为 正常 邮件 
而 表示 为 0.0 则 作为 垃圾邮件 来 看待 对于 
矩阵 Matrix 而言 本地 模式 的 矩阵 如下 所示 分布式 
矩阵 如下 所示 RowMatrix 直接 通过 RDD Vector 来 定义 
并 可以 用来 统计 平均数 方差 协 同方 差等 而 
IndexedRowMatrix 是 带有 索引 的 Matrix 但 其 可以 通过 
toRowMatrix 方法来 转换 为 RowMatrix 从而 利用 其 统计 功能 
代码 示例 如下 所示 CoordinateMatrix 常 用于 稀疏 性比 较高 
的 计算 中 是由 RDD MatrixEntry 来 构建 的 MatrixEntry 
是 一个 Tuple 类型 的 元素 其中 包含 行 列 
和 元素 值 代码 示例 如下 所示 3.2   MLlib 
的 算法 库 分析 下图 是 MLlib 算 法库 的 
核心 内容 分析 一些 Spark 中 常用 的 算法 3 
. 2.1   分类 算法 分类 算法 属于 监督 式 
学习 使用 类 标签 已知 的 样本 建立 一个 分类 
函数 或 分类 模型 应用 分类 模型 能把 数据库 中的 
类 标签 未知 的 数据 进行 归类 分类 在 数据 
挖掘 中 是 一项 重要 的 任务 目前 在 商业 
上 应用 最多 常见 的 典型 应用 场景 有 流失 
预测 精确 营销 客户 获取 个 性偏好 等 MLlib   
目前 支持 分类 算法 有 逻辑 回归 支持 向量 机 
朴素 贝叶斯 和 决策树 案例 导入 训练 数据集 然后 在 
训练 集上 执行 训练 算法 最后 在 所得 模型 上 
进行 预测 并 计算 训练 误差 import org . apache 
. spark . SparkContext import org . apache . spark 
. mllib . classification . SVMWithSGD import org . apache 
. spark . mllib . regression . LabeledPoint / / 
加载 和 解析 数据文件 val data = sc . textFile 
mllib / data / sample _ svm _ data . 
txt val parsedData = data . map { line = 
val parts = line . split LabeledPoint parts 0 . 
toDouble parts . tail . map x = x . 
toDouble . toArray } / / 设置 迭代 次数 并 
进行 进行 训练 val numIterations = 20 val model = 
SVMWithSGD . train parsedData numIterations / / 统计 分类 错误 
的 样本 比例 val labelAndPreds = parsedData . map { 
point = val prediction = model . predict point . 
features point . label prediction } val trainErr = labelAndPreds 
. filter r = r . _ 1 = r 
. _ 2 . count . toDouble / parsedData . 
count println Training Error = + trainErr 3 . 2.2 
  回归 算法 回归 算法 属于 监督 式 学习 每个/r 
个体/n 都/d 有一个/i 与之/i 相/v 关联/ns 的/uj 实数/n 标签/n 并且 
我们 希望 在 给出 用于 表示 这些 实体 的 数值 
特征 后 所 预测 出 的 标签 值 可以 尽可能 
接近 实际 值 MLlib   目前 支持 回归 算法 有 
线性 回归 岭回归 Lasso 和 决策树 案例 导入 训练 数据集 
将其 解析 为 带 标签 点 的 RDD 使用   
L i n e a r R e g r 
e s s i o n W i t h 
G D   算法 建立 一个 简单 的 线性 模型 
来 预测 标签 的 值 最后 计算 均方差 来 评估 
预测值 与 实际 值 的 吻 合度 import org . 
apache . spark . mllib . regression . L i 
n e a r R e g r e s 
s i o n W i t h G D 
import org . apache . spark . mllib . regression 
. LabeledPoint / / 加载 和 解析 数据文件 val data 
= sc . textFile mllib / data / ridge data 
/ lpsa . data val parsedData = data . map 
{ line = val parts = line . split LabeledPoint 
parts 0 . toDouble parts 1 . split . map 
x = x . toDouble . toArray } / / 
设置 迭代 次数 并 进行 训练 val numIterations = 20 
val model = L i n e a r R 
e g r e s s i o n W 
i t h G D . train parsedData numIterations / 
/ 统计 回归 错误 的 样本 比例 val valuesAndPreds = 
parsedData . map { point = val prediction = model 
. predict point . features point . label prediction } 
val MSE = valuesAndPreds . map { case v p 
= math . pow v p 2 } . reduce 
_ + _ / valuesAndPreds . count println training Mean 
Squared Error = + MSE 3 . 2.3   聚 
类 算法 聚 类 算法 属于 非 监督 式 学习 
通常 被 用于 探索性 的 分析 是 根据 物以类聚 的 
原理 将 本身 没有 类别 的 样本 聚集 成 不同 
的 组 这样 的 一组 数据 对象 的 集合 叫做 
簇 并且 对 每 一个 这样 的 簇 进行 描述 
的 过程 它 的 目的 是 使得 属于 同 一簇 
的 样本 之间 应该 彼此 相似 而 不同 簇 的 
样本 应该 足够 不相似 常见 的 典型 应用 场景 有 
客户 细分 客户 研究 市场 细分 价值 评估 MLlib   
目前 支持 广泛 使用 的 KMmeans 聚 类 算法 案例 
导入 训练 数据集 使用   KMeans   对象 来 将 
数据 聚 类 到 两个 类 簇 当中 所需 的 
类 簇 个数 会被 传递 到 算法 中 然后 计算 
集 内 均方差 总和   WSSSE 可以 通过 增加 类 
簇 的 个数   k   来 减小 误差 实际上 
最优 的 类 簇 数 通常 是   1 因为 
这 一点 通常 是 WSSSE 图 中的 低谷 点 import 
org . apache . spark . mllib . clustering . 
KMeans / / 加载 和 解析 数据文件 val data = 
sc . textFile kmeans _ data . txt val parsedData 
= data . map _ . split . map _ 
. toDouble / / 设置 迭代 次数 类 簇 的 
个数 val numIterations = 20 val numClusters = 2 / 
/ 进行 训练 val clusters = KMeans . train parsedData 
numClusters numIterations / / 统计 聚 类 错误 的 样本 
比例 val WSSSE = clusters . computeCost parsedData println Within 
Set Sum of Squared Errors = + WSSSE 3 . 
2.4   协同 过滤 协同 过滤 常被 应用于 推荐 系统 
这些 技术 旨在 补充 用户 商品 关联矩阵 中所 缺失 的 
部分 MLlib 当前 支持 基于 模型 的 协同 过滤 其中 
用户 和 商品 通过 一 小组 隐 语义 因子 进行 
表达 并且 这些 因子 也 用于 预测 缺失 的 元素 
案例 导入 训练 数据集 数据 每 一行 由 一个 用户 
一个 商品 和 相应 的 评分 组成 假设 评分 是 
显性 的 使用 默认 的 ALS . train 方法 通过 
计算 预测出 的 评分 的 均方差 来 评估 这个 推荐 
模型 import org . apache . spark . mllib . 
recommendation . ALS import org . apache . spark . 
mllib . recommendation . Rating / / 加载 和 解析 
数据文件 val data = sc . textFile mllib / data 
/ als / test . data val ratings = data 
. map _ . split match { case Array user 
item rate = Rating user . toInt item . toInt 
rate . toDouble } / / 设置 迭代 次数 val 
numIterations = 20 val model = ALS . train ratings 
1 20 0.01 / / 对 推荐 模型 进行 评分 
val usersProducts = ratings . map { case Rating user 
product rate = user product } val predictions = model 
. predict usersProducts . map { case Rating user product 
rate = user product rate } val ratesAndPreds = ratings 
. map { case Rating user product rate = user 
product rate } . join predictions val MSE = ratesAndPreds 
. map { case user product r1 r2 = math 
. pow r1 r2 2 } . reduce _ + 
_ / ratesAndPreds . count println Mean Squared Error = 
+ MSE 3.3   MLlib 的 实用程序 分析 实用程序 部分 
包括 数据 的 验证 器 Label 的 二元 和 多元 
的 分析器 多种 数据 生成器 数据 加载 器 更多 api 
介绍 可以 参考   http / / spark . apache 
. org / docs / 2 . 0.1 / ml 
guide . html 下面 是 实战 部分 http / / 
www . cnblogs . com / shishanyuan / p / 
4747778 . html 采用 了 三个 案例 分别 对应 聚 
类 回归 和 协同 过滤 的 算法 我 觉得 很好 
需要 每 一个 都在/nr 实际 系统 中 试一下 实战 部分 
的 内容 请 移步 http / / www . cnblogs 
. com / charlesblc / p / 6159187 . html 
完 