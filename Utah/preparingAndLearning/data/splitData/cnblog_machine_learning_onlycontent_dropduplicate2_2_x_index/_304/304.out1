什么 是 模式识别 Pattern Recognition 按照 Bishop 的 定义 模式识别 
就是 用 机器 学习 的 算法 从 数据 中 挖掘 
出 有用 的 pattern 人们 很早 就 开始 学习 如何 
从 大量 的 数据 中 发现 隐藏 在 背后 的 
pattern 例如 16/m 世纪/n 的/uj Kepler/w 从他的/nr 老师/n Tycho/w 搜集/v 
的/uj 大量/n 有/v 关于/p 行星/n 运动/vn 的/uj 数据/n 中/f 发现/v 
了/ul 天体/n 运行/v 的/uj 规律/n 并 直接 导致 了 牛顿 
经典力学 的 诞生 然而 这种 依赖 于 人类 经验 的 
启发式 的 模式识别 过程 很难 复制 到 其他 的 领域 
中 例如 手写 数字 的 识别 这 就 需要 机器 
学习 的 技术 了 顺便 提 一下 开普勒 定律 在 
物理学 中 只是 一种 唯 象 的 理论 它 只对 
物理 事实 抽象 出 概括性 的 描述 而 没有 解释 
内在 的 原因 也 就是 牛顿 的 万有 引力定律 其实 
在 更高 的 层次 上 万有引力 也 是 一种 唯 
象 的 理论 它 的 解释 由 量子 引力理论 给出 
这也 意味着 在 大 数据 的 机器学习 时代 我们 挖掘 
出来 的 知识 更多 的 也 只是 一种 相关性 的 
规律 在 手写 数字 识别 的 问题 中 一 部分 
手写 图片 作为 训练 集 training set 被 用来 学习 
一个 事先 给定 的 模型 的 参数 另一 部分 图片 
作为 测试 集 test set 被 用来 评估 学习 到 
的 模型 在 新 数据 上 的 泛化 能力 generalization 
训练 集 与 测试 集 里 的 手写 图片 对应 
的 数字 都是/nr 已知 的 这些 数字 又被 称之为 目标 
向量 target vector 是 模型 学习 的 分类 目标 一个 
机器学习 算法 最终 得到 的 结果 就是 一个 将 输入 
变量 \ x \ 这里 的 手写 数字 图片 映射 
到 目标 向量空间 里 的 函数 \ y x \ 
一般来说 在 模型 训练 之前 都有/nr 一个/m 数据/n 预处理/vn preprocess 
的 过程 例如 在 识别 手写 数字 的 问题 中 
我们 需要 先将 训练 集 里 的 图片 变换 到 
同一个 尺寸 下 从而 使 模型 的 训练 更加 统一 
这个 过程 也 被 称之为 特征提取 feature extraction 同时 预处理 
后的/nr 特征 往往 也 会使 模型 的 计算 更加 高效 
要 注意 的 是 如果 我们 对 训练 集 里 
的 数据 进行 了 预处理 那么 对于 测试 集 里 
的 数据 我们 也 要 进行 同样 的 操作 对于 
那些 训练样本 中 带有 目标 向量 的 机器 学习 问题 
我们 称之为 有 监督 学习 supervised learning 例如 前面 提到 
的 手写 数字 识别 问题 进一步 地 如果 目标 向量 
是 离散 的 我们 称之为 分类 classification 问题 反之 如果 
目标 向量 是 连续 的 我们 称之为 回归 regression 问题 
另一类 机器学习 问题 的 训练样本 仅有 输入 变量 的 特征 
我们 称之为 无 监督 学习 例如 对 数据 中 相似 
样本 的 归并 聚 类 问题 最后 一 类 机器学习 
问题 被 称之为 强化 学习 reinforcement learning 它 是 寻求 
在 一个 给定 状态下 的 行为 决策 以 最大化 最终 
的 收益 象棋 AI 就是 一个 典型 的 强化 学习 
的 例子 与 有 监督 学习 不同 强化 学习 要 
解决 的 问题 没有 标 记好 的 输出 但 往往 
会 通过 与 环境 的 互动 来 改变 自己 的 
状态 和 收益 并 因此 而 学习 到 什么 是 
一个 好 的 输出 注意 强化 学习 的 每一步 决策 
不仅 会 影响 到 当下 的 收益 还 会 影响 
未来 的 回报 这就 涉及 到 一个 信用分配 credit assignment 
的 问题 即 如何 将 最终 的 回报 分配 到 
导致 该 回报 的 每一步 的 决策 上 强化 学习 
另 一个 特征 是 在 exploration 和 exploitation 之间 的 
trade － off 对 任意 一个 的 过度 偏向 都会 
产生 较差 的 结果 接下来 我们 将 从 一个 具体 
的 例子 入手 展现 机器学习 过程 里 的 一些 基本 
概念 然后 我们 将 简单 介绍 机器学习 理论 的 三大 
基础 概率论 probability theory 决策论 decision theory 和 信息论 information 
theory 一个 例子 多项式 拟 合作 为 例子 我们 通过 
一个 带 随机噪声 的 产生 函数 \ sin 2 { 
\ pi } x \ 来 构造 训练 数据 并 
期望 一个 机器学习 算法 能从 有限 的 数据 中 学习 
到 这个 正弦函数 这种 数据 的 构造 方式 暗合 真实世界 
的 法则 即 数据 在 遵循 一条 潜在 的 规律 
同时 也 充满 了 不确定性 后面 我们 会 看到 我们 
是 如何 在 一个 概率论 的 框架 下 描述 这种 
不确定性 同时 给 出 一个 最好 的 预测 我们 可以 
用 一个 多项式 函 数来 拟合 训练 数据 这 是因为 
任意 一个 连续 可导 的 函数 总 可以 通过 多项式 
展开来 逼近 \ y x w = w _ 0 
+ w _ 1x + w _ 2x ^ 2 
+ . . . + w _ Mx ^ M 
= \ sum _ { j = 0 } ^ 
{ M } { w _ jx ^ j } 
\ 注意 尽管 这个 函数 是 关于 \ x \ 
的 非线性 函数 但却 是 关于 系数 \ w \ 
的 线性函数 类似 多项式 函数 这种 相对 于 未知 参数 
是 线性 的 模型 具有 一些 重要 的 性质 我们 
称之为 线性 模型 linear model 我们 通过 最小化 一个 误差函数 
error function 来 求解 模型 的 参数 误差函数 是 关于 
参数 \ w \ 的 一个 函数 它 衡量 我们 
的 预测 值 \ y x w \ 与 真实 
值 \ t \ 的 差距 一个 常用 的 误差函数 
是 误差 平方和 它 的 基本 形式 如下 \ E 
w = \ frac { 1 } { 2 } 
\ sum _ { n = 1 } ^ { 
N } { \ { y x _ n w 
t _ n \ } ^ 2 } \ 在后面 
介绍 到 最大 似 然 法时/nr 我们 会 看到 误差函数 
为什么 会 取 这种 形式 令 这个 函数 对 \ 
w \ 的 一 阶 偏 导 等于 0 得到 
\ M ＋ 1 \ 个 一 阶 方程组 就 
可以 求 解出 最优 拟合 参数 \ w ^ * 
\ 了 然而 我们 还有 一个 问题 如何 确定 模型 
的 阶数 \ M \ 这也 被 称之为 模型 选择 
model comparison or model selection 问题 我们 可以 通过 评估 
模型 在 新 数据 集上 的 泛化 能力 来 衡量 
模型 的 好坏 具体来说 我们 从 训练 集中 抽取 一 
部分 数据 作为 验证 集 validation set 对于 \ M 
\ 的 每一种 可能 取值 我们 先用 余下 的 训练 
集 找到 最优 的 参数 \ w ^ * \ 
然后 再在 验证 集上 评估 这个 模型 的 误差 \ 
E w ^ * \ 或者 是 root mean square 
error \ E _ { RMS } = \ sqrt 
{ { 2E w ^ * } / { N 
} } \ 我们 将 选择 泛化 误差 最小 的 
模型 作为 最终 的 模型 通过 这种 方式 我们 发现 
\ M \ 取值 过低 模型 有 可能 会 欠 
拟合 under fitting 而 \ M \ 取值 过高 模型 
又有 可能会 过拟合 over fitting 这是 为什么 呢 理论上 一个 
低阶 的 多项式 函数 只是 更 高阶 的 多项式 函数 
的 一个 特例 而 一个 高阶 的 多项式 也 更加 
逼近 真实 的 产生 函数 \ sin 2 { \ 
pi } x \ 因此 高阶 的 模型 似乎 没道理 
比 低阶 模型 的 表现 更差 但是 如果 我们 仔细 
观察 那些 过拟合 的 高阶 模型 学习 到 的 参数 
\ w \ 会 发现 它们 的 量纲 往往 异乎寻常 
的 大 这 使得 模型 虽然 可以 准确 地 预估 
训练 集中 的 数据 但也 展现出 了 巨大 的 波动性 
换句话说 强大 的 高阶 模型 过多 地 学习 了 训练 
数据 中 的 噪声 如果 我们 引入 更多 的 训练 
数据 这种 过拟合 的 问题 会 得到 一定 程度 的 
缓解 简而言之 虽然 模型 越 复杂 解释 能力 也 越强 
但 我们 往往 需要 更多 的 数据 来 训练 一个 
复杂 的 模型 后面 会 发现 这种 过拟合 本质上 是 
由于 最大 似 然 法 这类 对模型 参数 进行 点估计 
的 算法 所 带来 的 bias 造成 的 通过 一种 
贝叶斯 的 方法 我们 可以 从 根本 上 避免 过拟合 
的 问题 一种 在 有限 的 数据 集 下 也能 
训练 一个 高阶 模型 的 技术 是 正则化 regularization 即在 
传统 的 误差函数 中 引入 一个 对 参数 \ w 
\ 量纲 的 惩罚 项 以 抑制 \ w \ 
的 过度 发散 \ \ tilde { E } w 
= \ frac { 1 } { 2 } \ 
sum _ { n = 1 } ^ { N 
} { \ { y x _ n w t 
_ n \ } ^ 2 } + \ frac 
{ \ lambda } { 2 } | | w 
| | ^ 2 \ 其中 \ | | w 
| | ^ 2 = w _ 1 ^ 2 
+ w _ 2 ^ 2 + . . . 
+ w _ M ^ 2 \ 参数 \ \ 
lambda \ 控制/v 正则/n 项和/nr 误差/n 项的/nr 相对/d 权重/n 对于 
一个 合适 的 \ \ lambda \ 取值 我们 用 
较少 的 数据 也 可以 训练 出 一个 泛化 的 
高阶 模型 然而 过低 或 过高 的 \ \ lambda 
\ 依然 会 导致 过拟合 或 欠 拟合 的 问题 
本质上 正则化 只是 将 对模型 复杂度 的 控制 由 模型 
的 阶数 \ M \ 转移 到 了 惩罚 因子 
\ \ lambda \ 上 我们 依然 需要 一个 验证 
集 来 优化 模型 的 复杂度 概率论 在 模式识别 和 
机器 学习 的 研究 领域 里 不确定性 uncertainty 是 一个 
非常 核心 的 概念 接下来 要 介绍 的 概率论 为 
不确定性 的 量化 提供 了 一个 统一 的 框架 因此 
也 构成 了 整个 机器学习 研究 的 理论 基础 基本 
知识 点 概率 的 基本 定义 由 频率 学派 给出 
在 一系列 试验 中 某一 事件 发生 的 频率 称之为 
该 事件 发生 的 概率 从 这个 定义 出发 我们 
很容易 得到 概率论 的 两个 基本 法则 sum rule 和 
product rule \ p X = \ sum _ { 
Y } { p X Y } \ \ p 
X Y = p Y | X p X \ 
其中 \ p X \ 对应 \ X \ 发生 
的 边际 概率 marginal probability \ p X Y \ 
对应 \ X \ 和\/nr Y \ 同时 发生 的 
联合 概率 joint probability \ p Y | X \ 
对应 给定 \ X \ 下 \ Y \ 发生 
的 条件 概率 conditional probability 这 两个 公式 构成 了 
我们 将要 用到 的 所有 概率论 知识 的 基础 由 
product rule 出发 同时 结合 联合 概率 的 对称性 我们 
立即 得到 一个 十分 重要 的 公式 贝叶 斯定理 Bayes 
theorem \ p Y | X = \ frac { 
p X | Y p Y } { p X 
} \ 贝叶 斯定理 给 出了 后验/nr 概率 posterior probability 
\ p Y | X \ 和 先验概率 prior probability 
\ p Y \ 之间 的 关系 贝叶斯 概率 然而 
并非 所有 随机 事件 的 发生 都是 可 重复 的 
因此 我们 很难 用 频率 学派 的 观点 解释 诸如 
明天 有雨 这类 事件 发生 的 概率 对这 类 事件 
的 不确定性 的 衡量 就是 概率 的 贝叶斯 解释 Bayesian 
view 回到 之前 的 多项式 拟合 的 例子 从 频率 
学派 的 角度 来看 我们 将 目标 变量 \ t 
\ 视为 一个 随机变量 似乎 更加 合理 可以 通过 固定 
输入 变量 \ x \ 的 值 统计 \ t 
\ 的 频率分布 而从 贝叶斯 学派 的 观点 来看 我们 
可以 将 模型 的 参数 \ w \ 甚至 是 
整个 模型 视为 一个 随机变量 衡量 它们 的 不确定性 尽管 
\ w \ 是 不可 重复 的 具体来说 假设 我们 
知道 了 \ w \ 的 先验 概率分布 \ p 
w \ 那么 通过 贝叶斯 公式 我们/r 可以/c 将/d 这一/i 
先验概率/l 转化/v 为/p 给定/v 观测/vn 数据/n 后的后/nr 验/v 概率/n \/i 
p w | D \ \ p w | D 
= \ frac { p D | w p w 
} { p D } \ 从而 我们 得到 了 
一个 已知 数据 \ D \ 下 关于 模型 参数 
\ w \ 的 不确定性 的 定量 表达 在 这个 
公式 里 概率分布 \ p D | w \ 又 
被 称为 似 然 函数 likilihood function 它 给出 了 
不同 \ w \ 下 数据集 \ D \ 发生 
的 概率 从而 贝叶 斯定理 又 可以 写成 \ posterior 
\ propto likelihood \ times prior \ 无论是 在 频率 
学派 还是 贝叶斯 学派 的 框架 下 似 然 函数 
都 扮演 着 重要 的 角色 不同 的 是 频率 
学派 认为 模型 的 参数 是 固定 的 观测 到 
的 数据 则是 给定 参 数下 的 一个 随机事件 因此 
他们 通过 一种 叫做 最大 似 然 法 maximum likelihood 
的 方法 来 预估 参数 即 寻找 使 观测 到 
的 数据集 \ D \ 发生 的 概率 最大 的 
参数 \ w \ 后面 我们 将 会 看到 最大 
似 然 法与/nr 前面 提到 的 最小化 误差函数 的 关系 
而 贝叶斯 学派 则 认为 模型 的 参数 服从 一个 
概率分布 因此 似 然 函数 只是 获取 后验/nr 概率 的 
桥梁 关于 频率 学派 和 贝叶斯 学派 孰 优 孰 
劣 的 问题 各家 各 执 一言 此处 不做 讨论 
只需 知道 PRML 这本书 更多 的 是 介绍 贝叶斯 学派 
的 观点 而 Andrew 在 Coursera 上 的 课 则是 
频率 学派 的 经典 观点 高斯分布 关于 高斯分布 的 定义 
和 性质 很多 概率论 的 书上 都有 介绍 这里 不再 
赘述 本/r 小节/n 主要/b 介绍/v 如何/r 运用/vn 频率/n 学派/n 的/uj 
最大/a 似/d 然/c 法从/nr 一堆/m 服从/v 高斯分布/nr 的/uj 数据/n 中/f 
拟/v 合出/v 分布/v 的/uj 参数/n \ \ mu \ 与 
\ \ sigma ^ 2 \ 由 独立 同 分布 
假定 我们 的 数据集 \ \ mathbf { x } 
= x _ 1 . . . x _ D 
^ T \ 在 给定 参数 \ \ mu \ 
和\/nr \ sigma ^ 2 \ 下 的 条件 概率分布 
为 \ p \ mathbf { x } | \ 
mu \ sigma ^ 2 = \ prod _ { 
n = 1 } ^ N { \ mathcal { 
N } x _ n | \ mu \ sigma 
^ 2 } \ 这 就是 高斯分布 的 似 然 
函数 对 这个 似 然 函数 取 对数 后面 我们 
会 看到 如何 从 信息熵 的 角度 来 解释 这 
一 行为 我们 得到 \ \ ln { p \ 
mathbf { x } | \ mu \ sigma ^ 
2 } = \ frac { 1 } { 2 
\ sigma ^ 2 } \ sum _ { n 
= 1 } ^ N { x _ n \ 
mu ^ 2 } \ frac { N } { 
2 } \ ln { \ sigma ^ 2 } 
\ frac { N } { 2 } \ ln 
{ 2 \ pi } \ 将 上式 分别 对 
\ \ mu \ 和\/nr \ sigma ^ 2 \ 
求导 并 令其 等于 0 我们 得到 了 \ \ 
mu \ 和\/nr \ sigma ^ 2 \ 的 最大 
似 然 预估 \ \ mu _ { ML } 
= \ frac { 1 } { N } \ 
sum _ { n = 1 } ^ N { 
x _ n } \ \ \ sigma ^ 2 
_ { ML } = \ frac { 1 } 
{ N } \ sum _ { n = 1 
} ^ N { x _ n \ mu _ 
{ ML } ^ 2 } \ 等式 右边 都是 
关于 数据集 \ \ mathbf { x } \ 的 
函数 可以 证明 通过 这种 方法 得到 的 参数 预估 
是 有偏/nr bias 的 \ E \ mu _ { 
ML } = \ mu \ \ E \ sigma 
^ 2 _ { ML } = \ frac { 
N 1 } { N } \ sigma ^ 2 
\ 也 就是说 我们 会 低估 underestimate 真实 的 分布 
方差 一般来说 模型 的 参数 越多 复杂度 越高 由/p 最大/a 
似/d 然/c 法/l 预估/vn 出来/v 的/uj 参数/n 越/d 不准确/i 而 
这种 有偏的/nr 预估 是 导致 模型 过拟合 的 根本 原因 
过度 拟合 了 训练样本 而 偏离 了 真实世界 不过 注意到 
随着 样本数 \ N \ 的 增长 这种 偏 差会 
越来越 小 这就 解释 了 为什么 增大 训练样本 的 容量 
可 以 一定 程度 上 缓解 过拟合 的 问题 回到 
多项式 拟合 接下来 我们 将 回到 多项式 拟合 的 例子 
看看 在 统计学 的 视角 下 频率 学派 和 贝叶斯 
学派 各自 是 如何 解决 这个 问题 的 在 多项式 
拟合 的 问题 中 我们 的 目标 是 在 由 
\ N \ 个 输入 变量 \ \ mathbf { 
x } = x _ 1 . . . x 
_ N ^ T \ 及其 对应 的 目标 值 
\ \ mathbf { t } = t _ 1 
. . . t _ N ^ T \ 构成 
的 训练 集 的 基础 上 对 新 输入 变量 
\ x \ 的 目标 值 \ t \ 做出 
预测 用 概率 语言 来 描述 我们 可以 将 目标 
变量 \ t \ 的 这种 不确定性 用 一个 概率分布 
来 表达 我们 假定 \ t \ 服从 以 \ 
y x w \ 为 均值 的 高斯分布 \ p 
t | x w \ beta = \ mathcal { 
N } t | y x w \ beta ^ 
{ 1 } \ 有了 \ t \ 的 概率分布 
我们 就 可以 用 最大 似 然 法在/nr 训练 集上 
求解 模型 的 参数 \ w \ 和\/nr \ beta 
\ \ \ ln { p \ mathbf { t 
} | \ mathbf { x } w \ beta 
} = \ frac { \ beta } { 2 
} \ sum _ { n = 1 } ^ 
N { \ { y x _ n w t 
_ n \ } ^ 2 } + \ frac 
{ N } { 2 } \ ln { \ 
beta } \ frac { N } { 2 } 
\ ln { 2 \ pi } \ 我们 发现 
略去 与 \ w \ 无关 的 后 两项 后 
我们 得到 了 前文 提到 的 误差函数 也 就是说 对于 
\ w \ 的 求解 而言 最大/a 似/d 然/c 法/l 
等价/n 于/p 最小化/l 误差/n 平方和/nr 我们 的 误差函数 是 在 
目标 变量 服从 高斯分布 的 假定 下用 最大 似 然 
法 推导 出来 的 一个 自然 结果 注意 这 一 
结论 与 \ y x w \ 的 具体 形式 
无关 一旦 得到 了 \ w \ 和\/nr \ beta 
\ 的 最大 似 然 估计 我们 就 可以 对 
新 变量 \ x \ 的 目标 值 做出 预估 
注意 这里 是 对 \ t \ 的 分布 预估 
predictive distribution 而非 点估计 point estimate 在 后面 的 decision 
theory 章节 中 会 介绍 如何 从 预估 的 分布 
得到 预测值 以上 是 频率 学 派对 多项式 拟合 算法 
的 解释 而在 贝叶斯 学派 看来 参数 \ w \ 
也 是 一个 随机变量 假定 \ w \ 的 先验 
分布 是 一个 服从 均值 为 0 的 多元 高斯分布 
\ p w | \ alpha = \ mathcal { 
N } w | 0 \ alpha ^ { 1 
} I \ 其中 \ \ alpha \ 被 称为 
模型 的 超验 参数 hyperparameters 则由 贝叶 斯定理 \ w 
\ 在 给定 训练 集上 的 后验/nr 分布 为 \ 
p w | \ mathbf { x } \ mathbf 
{ t } \ alpha \ beta \ propto p 
\ mathbf { t } | \ mathbf { x 
} w \ alpha \ beta \ times p w 
| \ alpha \ 我们 可以 通过 最大化 这个 后验/nr 
概率 来 找出 最 合适 的 \ w \ 这个 
方法 被 称之为 最大 后验/nr 概率法 maximum posterior 简称 MAP 
对 上式 取 对数 并 代入 似 然 函数 和 
先验概率 的 分布 函数 后 我们 发现 最大/a 后验/nr 概率/n 
等价/n 于/p 最小化/l 带/v 正则/n 项的/nr 平方/q 误差函数/i \ \ 
frac { 1 } { 2 } \ sum _ 
{ n = 1 } ^ N { \ { 
y x _ n w t _ n \ } 
^ 2 } + \ frac { \ alpha } 
{ 2 \ beta } w ^ Tw \ 这 
句话 也 可以 这么 理解 通过 引入 均值 为 0 
的 高斯分布 先验 函数 我们 对 \ w \ 的 
大小 进行 了 限定 也 就是说 带 正则 项的/nr 误差函数 
是 在 目标 变量 模型 参数均 服从 高斯分布 的 假 
定下 用 最大 后验/nr 概率法 推导 出来 的 一个 自然 
结果 同样 的 这个 结论 与 \ y x w 
\ 的 具体 形式 无关 不过 虽然 我们 引 入了 
\ w \ 的 先验 概率分布 MAP 依然 只是 对 
\ w \ 的 点估计 类似 最大 似 然 法 
这种 方法 最大 的 问题 在于 给出 的 估计值 往往 
是 有偏的/nr 即 \ E w _ { MAP } 
\ neq w \ 而 贝叶斯 学派 的 精髓 在于 
从\/nr w \ 的 后验/nr 概率分布 出发 我们 可以 进一步 
得到 在 给定 训练 集 \ \ mathbf { x 
} \ 和\/nr \ mathbf { t } \ 的 
条件 下 新 变量 \ x \ 的 目标 值 
\ t \ 的 后验/nr 概率分布 \ p t | 
x \ mathbf { x } \ mathbf { t 
} \ \ p t | x \ mathbf { 
x } \ mathbf { t } = \ int 
{ p t | x w p w | \ 
mathbf { x } \ mathbf { t } dw 
} \ 假定 \ \ alpha \ 和\/nr \ beta 
\ 都是 模型 的 超验 参数 总结 一下 频率 学派 
和 贝叶斯 学派 的 区别 频率 学派 贝叶斯 学派 目标 
变量 \ t \ \ p t \ | x 
w \ \ p t \ | x \ mathbf 
{ x } \ mathbf { t } \ 模型 
参数 \ w \ 显 式 常量 隐式 随机变量/l 模型/n 
优化/vn 算法/n 最大/a 似/d 然/c 法/l 最大/a 后验/nr 概率法/n 1 
优化 目标函数 \ \ frac { 1 } { 2 
} \ sum _ { n = 1 } ^ 
N { \ { y x _ n w t 
_ n \ } ^ 2 } \ \ \ 
frac { 1 } { 2 } \ sum _ 
{ n = 1 } ^ N { \ { 
y x _ n w t _ n \ } 
^ 2 } + \ frac { \ alpha } 
{ 2 \ beta } w ^ Tw \ 决策理论 
Decision Theory 一个 具体 的 机器 学习 问题 的 解决 
包括 两个 过程 推断 inference 和 决策 decision 前者 在 
概率 学 的 框架 下 告诉 我们 \ p \ 
mathbf { x } t \ 的 分布 后者 则 
借助 决策理论 decision theory 告诉 我们 在 这个 联合 概率分布 
下 的 最优 反应 例 如对 \ t \ 的 
预估 等 一旦 解决 了 推断 的 问题 决策 的 
过程 就 显得 异常 简单 分类 问题 的 决策 对于 
分类 问题 而言 我们 寻求 一个 将 输入 变量 \ 
\ mathbf { x } \ 映射 到 某一个 分类上 
的 法则 这个 法 则将 \ \ mathbf { x 
} \ 的 向量空间 划 分成 了 不同 的 区域 
\ \ mathcal { R } _ k \ 我们 
称之为 decision region 位于 \ \ mathcal { R } 
_ k \ 里 的 点 \ \ mathbf { 
x } \ 都被 映 射到 类 \ C _ 
k \ 上 相应 的 decision region 之间 的 边界 
我们 称之为 decision boundaries 或 decision surfaces 如何 找到 这个 
决策 面 呢 假定 我们 的 决策 目标 是 使得 
误 分类 的 概率 尽可能 地 小 借助 概率论 我们 
有 \ p mistake = 1 p correct = 1 
\ sum _ { k = 1 } ^ K 
{ \ int _ { \ mathcal { R } 
_ k } } { p \ mathbf { x 
} C _ k d \ mathbf { x } 
} \ 显然 为了 让 \ p mistake \ 尽可能 
地 小 \ \ mathcal { R } _ k 
\ 应 是由 那些 使得 \ p \ mathbf { 
x } C _ k \ 最大 的 点 构成 
的 集合 即 对于 \ \ mathbf { x } 
\ in \ mathcal { R } _ k \ 
满足 \ p \ mathbf { x } C _ 
k \ geq p \ mathbf { x } C 
_ j \ 由于 \ p \ mathbf { x 
} C _ k ＝ p C _ k | 
\ mathbf { x } p \ mathbf { x 
} \ 也 就是说 我们 应将 \ \ mathbf { 
x } \ 映 射到 后验/nr 概率 \ p C 
_ k | \ mathbf { x } \ 最大 
的 类 \ C _ k \ 上 但 真实 
的 问题 也许 要 更 复杂 一些 例如 对 癌症 
患者 的 诊断 错误 的 将 一个 癌症 患者 诊断 
为 健康 远比 将 一个 健康 的 人 误诊 为 
癌症 要 严重 的 多 因此 就有 了 损失 矩阵 
loss function 的 概念 损失 矩阵 \ L \ 中的 
元素 \ L _ { kj } \ 用来 评估 
当 类 \ C _ k \ 被 误 分类 
为 \ C _ j \ 时 带来 的 损失 
显然 对 任意 的 类 \ C _ k \ 
总有 \ L _ { kk } = 0 \ 
此时 我们 的 决策 目标 是 最小化 期望 损失 函数 
同样地 借助 概率论 的 知识 我们 有 \ E L 
= \ sum _ k \ sum _ j \ 
int _ { \ mathcal { R } _ j 
} { L _ { kj } p \ mathbf 
{ x } C _ k d \ mathbf { 
x } } \ 类 似地 我们 选取 那些 使 
\ \ sum _ k L _ { kj } 
p \ mathbf { x } C _ k \ 
最小 的 点 \ \ mathbf { x } \ 
构成 的 集合 为 类 \ C _ j \ 
的 decision region \ \ mathcal { R } _ 
j \ 即 对于 \ \ mathcal { R } 
_ j \ 里 的 \ \ mathbf { x 
} \ 总有 \ \ sum _ k L _ 
{ kj } p \ mathbf { x } C 
_ k \ leq \ sum _ k L _ 
{ ki } p \ mathbf { x } C 
_ k \ 再次 回顾 推断 过程 在 前面 对分 
类 问题 决策 阶段 的 讨论 中 我们 发现 我们 
可以 在 推断 阶段 预估 \ { \ mathbf { 
x } } \ 和\/nr C _ k \ 的 
联合 概率分布 \ p \ mathbf { x } C 
_ k \ 也 可以 预估 \ C _ k 
\ 的 后验/nr 条件概率 \ p C _ k | 
\ mathbf { x } \ 事实上 我们 也 可以 
将 两个 阶段 整合 为 一个 过程 直接 学习 \ 
{ \ mathbf { x } } \ 到 \ 
C _ k \ 的 映射 这三种 不同 的 解决 
问题 的 思路 对应 了 三种 不同 的 模型 产生 
式 模型 generative models 产生 式 模型 是 指 那些 
在 推断 阶段 隐式 或 显 式 地 对 输入 
变量 \ \ mathbf { x } \ 的 分布 
进行 了 建模 的 模型 由 贝叶斯 公式 我们 可以 
用 \ \ mathbf { x } \ 的 条件 
概率 \ p \ mathbf { x } | C 
_ k \ 和\/nr C _ k \ 的 先验概率 
\ p C _ k \ 计算 \ C _ 
k \ 的 后验/nr 概率 \ p C _ k 
| \ mathbf { x } = \ frac { 
p \ mathbf { x } | C _ k 
p C _ k } { p \ mathbf { 
x } } \ 在 得到 \ C _ k 
\ 的 后验/nr 概率 后 进入 决策 阶段 分类 这个 
过程 等价 于对/nr 联合 概率分布 \ p \ mathbf { 
x } C _ k \ 进行 建模 上式 中的 
分子 判别式 模型 discriminative models 判别式 模型 是 指 那些 
在 推断 阶段 直接 对 目标 变量 的 后验/nr 概率 
进行 建模 的 模型 例如 前面 提到 的 多项式 拟合 
模型 判别式 函数 discriminant function 通过 一个 判别式 函数 \ 
f \ mathbf { x } \ 可以 将 输入 
变量 \ \ mathbf { x } \ 直接 映射 
到 一个 类 标上 省去 了 对 概率分布 的 预估 
Andrew 在 Coursera 上 的 课程 里 提到 的 假说 
Hypothesis 就是 这类 函数 总的来说 三类 模型 各有利弊 相对 来讲 
产生 式 模型 最为 复杂 也 需要 最多 的 训练 
数据 但是 由于 可以 对 输入 变量 的 分布 进行 
预估 功能上 也 最为 强大 而 我们 用 的 最多 
的 一般 是 判别式 模型 由于 引入 了 对 后验/nr 
概率 的 预估 使得 我们 可以 方便 的 处理 非平衡 
样本 问题 以及 多 模型 的 融合 这是 简单 的 
判别式 函数 所 不具备 的 回归 问题 的 决策 与 
分类 问题 类似 回归 问题 的 决策 阶段 也是 要从 
目标 变量 的 概率分布 中 选择 一个 特定 的 预估 
值 以 最小化 某个 损失 函数 回归 问题 的 损失 
函数 为 \ E L = \ int \ int 
L t y \ mathbf { x } p \ 
mathbf { x } t d \ mathbf { x 
} dt \ 积 分项 的 意思 是 对于 输入 
变量 \ \ mathbf { x } \ 和 真实 
目标值 \ t \ 我们 的 预估 目标值 \ y 
\ mathbf { x } \ 带来 的 期望 损失 
一般 \ L t y \ mathbf { x } 
\ 被 定义 为 平方 误差 和的/nr 形式 最小化 这个 
损失 函数 我们 得到 解 \ y \ mathbf { 
x } = E _ t t | \ mathbf 
{ x } \ 这个 条件 期望 也 被 称之为 
回归 函数 regression function 在 前面 的 多项式 拟合 的 
问题 中 我们 假定 了 目标 变量 \ t \ 
服 从 一个 高斯分布 并用 最大 似 然 法 或 
Bayesian 的 方法 估计 出了 模型 的 参数 而 通过 
这里 的 回归 函数 我们 才 最终 得到 了 \ 
t \ 的 一个 预 估值 类 似地 回归 问题 
也 有三种 建模 方式 产生 式 模型 判别式 模型 和 
判别式 函数 这里 不再 赘述 信息论 Information Theory 如果说 概率论 
给 出了 对 不确定性 的 一个 描述 信息论 则 给 
出了 对 不确定性 程度 的 一种 度量 这种 度量 就是 
信息熵 信息熵 我们 可以 从 三种 不同 的 角度 理解 
信息熵 的 定义 概率 学 如果 我们 问 一个 随机 
事件 的 发生 会 传递 多少 信息量 显然 一个 确定 
事件 的 发生 传递 的 信息量 为 0 而 一个 
小 概率 事件 的 发生 会 传递 更多 的 信息量 
因此 我们 对 信息量 记作 \ h x \ 的 
定义 应该 与 随机事件 发生 的 概率 \ p x 
\ 有关 另一方面 两个 独立 事件 同时 发生 所 传递 
的 信息 量 应该 是 这 两个 事件 各自 发生 
的 信息量 之和 即 \ h x y = h 
x + h y \ 由 这 两个 性质 出发 
我们 可以 证明 信息量 \ h x \ 必然 遵循 
\ p x \ 的 对数 形式 \ h x 
＝ log _ { 2 } p x \ 进一步 
地 我们 定义 一个 随机变量 \ x \ 的 信息 
熵 为其 传递 的 信息量 的 期望值 \ H x 
= \ sum p x log _ { 2 } 
p x \ 信息学 在对 信息熵 的 第一 种 解读 
中 我们 并 没有 解释 为什么 对 信息量 的 定义 
采用 了 以 自然数 2 为 底 的 对数 Shannon 
给出 了 一个 信息学 的 解释 信息熵 等价 于 编码 
一个 随机 变量 的 状态 所需 的 最短 位数 bits 
对于 一个 均匀分布 的 随机变量 这是 显而易见 的 而 对于 
非 均匀分布 的 随机变量 我们 可以 通过 对 高频 事件 
采用 短 编码 低频 事件 采用 长 编码 的 方式 
来 缩短 平均 编码 长度 物理学 在 热力学 中 我们 
也 接触 到 熵 的 定义 一种 对 系统 无序 
程度 的 度量 熵 越大 系统 的 无序 程度 越高 
这里 熵 被 定义 为 一个 宏观态 对应 微观 态 
个数 的 对数 与 热力学 熵 类似 信息熵 度量 了 
一个 随机 变量 的 不确定 程度 信息熵 越大 随机变量 的 
不确定性 越高 我们 也 可以 将 信息熵 的 定义 拓展 
到 连续型 的 随机变量 定义 为 微分 熵 differential entropy 
\ H x = \ int { p x \ 
ln { p x } } dx \ 如果 从 
信息熵 的 原始 定义 出发 我们 会 发现 微分 熵 
的 定义 和 信息熵 相差 了 一个 极 大项 \ 
\ ln { \ Delta } \ 这 意味着 连续变量 
本质上 不 可能 做到 精确 的 编码 结合 拉格朗日 法 
我们/r 可以/c 推/v 导出/v 信息熵/n 和/c 微分/n 熵/g 最大/a 时/n 
对应/vn 的/uj 分布/v 对于 离散 的 随机变量 信息熵 最大 时 
对应 着 一个 均匀分布 对于 连续 的 随机变量 微分 熵 
最大 时 对应 着 一个 高斯分布 注意 对于 微分 熵 
的 最大值 求解 需要 增加 一 阶 矩 和 二阶 
矩 两个 约束条件 条件 熵 交叉 熵 与 互信息 从 
信息熵 的 第一 定义 我们 很 容易 写出 条件 信息熵 
的 计算 公式 \ H y | x = \ 
int \ int p y x \ ln { p 
y | x } dydx \ 容易 证明 \ H 
x y = H y | x + H x 
\ 也 就是说 \ x \ \ y \ 联合 
分布 的 不确定 度 等于 \ x \ 的 不 
确定 度 与 知道 \ x \ 后\/nr y \ 
的 不 确定 度 之和 交叉 熵 relative entropy 又 
被 称为 KL divergence 衡量 了 两个 分布 的 不 
相似性 它 定义 了 用 一个 预估 分布 \ q 
x \ 近似 一个 未知 分布 \ p x \ 
时 对 \ x \ 进行 编码 所 需要 的 
额外 期望 信息量 \ KL p \ | q = 
\ int p x \ ln { q x } 
dx \ int p x \ ln { p x 
} dx = \ int p x \ ln { 
\ { \ frac { q x } { p 
x } \ } dx } \ 交叉 熵 越大 
两个 分布 越 不相似 可以 证明 交叉 熵 不满足 对称性 
\ KL p \ | q \ neq KL q 
\ | p \ 且 \ KL p \ | 
q \ geq 0 \ 当且仅当 \ q x = 
p x \ 时 等号 成立 我们 可以 用 交叉 
熵 的 概念 来 对 一个 机器学习 模型 的 参数 
进行 预估 假设 我们 有 一堆 抽样 自 某 未知 
分布 \ p x \ 的 数据 我们 试图 用 
一个 带 参数 的 模型 \ q x | \ 
theta \ 去 拟合 它 一条 可行 的 思路 是 
选择 使 \ p x \ 和\/nr q x | 
\ theta \ 的 交叉 熵 尽可能 小 的 参数 
\ \ theta \ 虽然 我们 不 知道 \ p 
x \ 的 真实 分布 但 由 蒙特卡洛 方法 我们 
可以 从 抽样 数据 中 得到 \ KL p \ 
| q \ 的 近似值 \ KL p \ | 
q \ simeq \ sum _ { n = 1 
} ^ { N } \ { \ ln { 
q x _ n | \ theta } + \ 
ln { p x _ n } \ } \ 
略去 与 \ \ theta \ 无关 项 我们 发现 
我们 得到 的 是 一个 似 然 函数 的 负 
对数 也 就是说 最小化 模型 预估 分布 与 真实 分布 
的 交叉 熵 等价 于 前面 提到 的 最大 似 
然 法 这 也从 信息熵 的 角度 解释 了 为什么 
要对 似 然 函数 取 对数 的 原因 另 一个 
重要 的 概念 是 互信息 mutual information 用来 衡量 两个 
随机变量 \ x \ \ y \ 的 相关性 互信息 
有 两种 定义 方式 \ p x y \ 和\/nr 
p x p y \ 的 交叉 熵 定义 \ 
I x y = KL p x y \ | 
p x p y = \ int \ int { 
p x y \ ln { \ frac { p 
x p y } { p x y } } 
} dxdy \ 当 \ x \ \ y \ 
相互 独立 时 \ p x y = p x 
p y \ 此时 \ I x y = 0 
\ 由 KL 定义 出发 我们 可以 推 导出 互 
信息 的 条件 熵 定义 \ I x y = 
H x H x | y = H y H 
y | x \ 因此 \ x \ \ y 
\ 的 互信息 可以 理解 为 知道 其中 一个 随机 
变量 的 取值 后 另 一个 随机 变量 的 不确定 
度 的 降低 当 \ I x y = H 
x \ 时 意味着 \ y \ 的 发生 确定 
了 \ x \ 的 发生 即 两个 随机变量 完全 
相关 通常 贝叶斯 学派 不会 对 模型 的 参数 进行 
点估计 因此 也 不会 用 MAP 算法 优化 模型 把/p 
最大/a 后验/nr 概率/n 算法/n 和/c 下面/f 的/uj 优化/vn 目标函数/i 放在/v 
这里/r 只是/c 为了/p 和/c 频率/n 学派/n 的/uj 最大/a 似/d 然/c 
法/l 进行/v 对比/v ↩ 