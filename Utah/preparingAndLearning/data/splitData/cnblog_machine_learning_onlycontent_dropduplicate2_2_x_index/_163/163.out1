主页 apachecn . org Github @ ApacheCN 暂时 下线 社区 
暂时 下线 cwiki 知识库 自 媒体 平台 微博 @ ApacheCN 
知乎 @ ApacheCNCSDN 简书 OSChina 博客园 我们 不是 Apache 的 
官方 组织 / 机构 / 团体 只是 Apache 技术 栈 
以及 AI 的 爱好者 合作 or 侵权 请 联系 fonttian 
fonttian @ gmail . com | 请 抄送 一份 到 
apachecn @ 163 . com 预处理 离散化 等值 分箱 等量 
分箱 独 热 one hot 标准化 最小 最大 min maxz 
scorel2 标准化 归一化 特征选择 ANOVA 信息 增益 / 信息 增益 
率 模型 验证 评价 指标 回归 MSER 方 分类 准确率 
精确 率 召回率 F1 得分 宏 平均 F1 微 平均 
F1 聚 类 互信息 轮廓 距离 交叉 验证 K 折 
网格 搜索 最优化 方法 梯度 下降 随机 梯度 下降 SGD/w 
牛顿/nr 法/拟/nr 牛顿/nr 法动/nr 量法/i RMSPropAdam/w 传统/n 机器学习/i 基本概念/l 欠/v 
拟合/v //i 过拟合/i 距离/n 汉明/nz 距离/n 曼哈顿/ns 距离/n 欧几里得/ns 距离/n 
切比雪夫/i 距离/n 余弦/nr 相似/v 度/zg pearson/w 相似 度 损失 函数 
MSE 交叉 熵 Hinge 线性 模型 线性 回归 Lasso / 
岭回归 正则化 逻辑 回归 softmax 回归 支持 向量 机 拉格朗日 
对偶 软 边界 支持 向量 机 核 方法 树 和 
森林 决策树 随机 森林 GDBT / XGBoostLightGBM 集成 学习 B 
a g g i n g B o o s 
t i n g A d a b o o 
s t B l e n d i n g 
/ StackingKNN 聚 类 KMenas 层次 聚 类 凝 聚聚 
类 分裂 聚 类 DBSCAN 谱 聚 类 高斯 混合模型 
GMM 概率 图 朴素 贝叶斯 隐 马尔科夫 HMM 降 维 
PCA / SVDT SNE 深度 学习 基本 概念 正向 传播 
反向 传播 激活 函数 s i g m o i 
d s o f t m a x t a 
n h R e L U E L U L 
e a k y ReLU 丢弃 Dropout 微调 Fine Tune 
批量 归一化 BatchNorm 前馈 神经网络 DNN / 多层 感知机 MLP 
输入 层 隐 层 输出 层 卷积 神经网络 CNN/w 层/q 
卷积/n 层/q 池化层/nr 全/a 连接/v 层/q 经典/n 结构/n L/w e/w 
N/w e/w t/w A/w l/w e/w x/w N/w e/w t/w 
Z/w F/w N/w e/w t/w G/w o/w o/w g/w L/w 
e/w N/w e/w t/w V/w G/w G/w R/w e/w s/w 
N/w e/w t/w D/w e/w n/w s/w e/w N/w e/w 
t/w 循环/vn 神经网络/n RNN 循环 层 经典 结构 LSTMGRUBiLSTM 注意力 
Seq2Seq 自 编码器 栈 式 自 编码器 稀疏 自 编码器 
去 噪 自 编码器 变分 自 编码器 生成 对抗 网络 
GANDCGAN 应用领域 待 扩展 推荐 系统 机器 视觉 CV 自然语言 
处理 NLP 生物 信息 常用工具 数据分析 NumPyPandas 科学计算 SciPy 可视化 
M a t p l o t l i b 
e a b o r n 机器学习 scikit learn / 
s k l e a r n X G B 
o o s t L i g h t G 
B M 深度 学习 K e r a s T 
e n s o r F l o w P 
y T o r c h 