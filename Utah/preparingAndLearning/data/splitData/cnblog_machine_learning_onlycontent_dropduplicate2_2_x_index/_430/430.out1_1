在 机器学习 Machine learning 领域 主要 有 三类 不同 的 
学习 方法 监督 学习 Supervised learning 非 监督 学习 Unsupervised 
learning 半 监督 学习 Semi supervised learning 监督 学习 通过 
已 有的 一 部分 输入 数据 与 输出 数据 之间 
的 相应 关系 生成 一个 函数 将 输入 映射 到 
合适 的 输出 比如 分类 非 监督 学习 直接 对 
输入 数据集 进行 建模 比如 聚 类 半 监督 学习 
综合/vn 利用/n 有类标/nr 的/uj 数据/n 和/c 没有/v 类/q 标/n 的/uj 
数据/n 来 生成 合适 的 分类 函数 一 监督 学习 
1 监督 式 学习 Supervised learning 是 一个 机器学习 中 
的 方法 能够 由 训练 资料 中 学到 或 建立 
一个 模式 learning model 并 依此 模式 猜 測 新的 
实例 训练 资料 是由 输入 物件 一般 是 向量 和 
预期 输出 所 组成 函数 的 输出 能够 是 一个 
连续 的 值 称为 回归分析 或是 预 測 一个 分类 
标签 称作 分类 2 一个 监督 式 学习者 的 任务 
在 观察 完 一些 训练 范例 输入 和 预期 输出 
后 去 预 測 这个 函数 对 不论什么 可能 出现 
的 输入 的 值 的 输出 要 达到 此 目的 
学习者 必须 以 合理 见 归纳 偏向 的 方式 从 
现有 的 资料 中 一般化 到 非 观察到 的 情况 
在 人类 和 动物 感知 中 则 通常 被 称为 
概念学习 concept learning 3 监督 式 学习 有 两种 形态 
的 模型 最 一般 的 监督 式 学习 产生 一个 
全域 模型 会将 输入 物件 相 应到 预期 输出 而 
还有 一种 则是 将 这样 的 相应 实 作 在 
一个 区域 模型 如 案例 推 论及 近期 邻居 法 
为了 解决 一个 给定 的 监督 式 学习 的 问题 
手写 辨识 必须 考虑 下面 步骤 1 决定 训练 资料 
的 范例 的 形态 在做 其他 事前 project/w 师应/nr 决定/v 
要/v 使用/v 哪种/r 资料/n 为/p 范例/n 譬如 可能 是 一个 
手写 字符 或 一 整个 手写 的 词汇 或 一行 
手写 文字 2 搜集 训练 资料 这 资料 需要 具有 
真实 世界 的 特征 所以 能够 由 人类 专家 或 
机器 或传感器 的 測/zg 量/n 中/f 得到/v 输入/v 物件/n 和其相/nr 
相应/v 输出/v 3 决定 学习 函数 的 输入 特征 的 
表示法 学习 函数 的 精确度 与 输入 的 物件 怎样 
表示 是 有 非常 大 的 关联度 传统上 输入 的 
物件 会被 转成 一个 特征向量 包括 了 很多 关于 描写 
叙述 物件 的 特征 由于 维数 灾难 的 关系 特征 
的 个数 不宜 太多 但 也要 足够 大 才干 准确 
的 预 測 输出 4 决定 要 学习 的 函数 
和其/nr 相应 的 学习 算法 所 使用 的 数据 结构 
譬如 project/w 师/ng 可能/v 选择/v 人工神经网络/n 和/c 决策树/n 5 完毕 
设计 project 师 接着 在 搜集 到 的 资料 上 
跑 学习 算法 能够 借 由 将 资料 跑在 资料 
的 子集 称为 验证 集 或 交叉 验证 cross validation 
上来 调整 学习 算法 的 參 数 參 数 调整 
后 算法/n 能够/v 执行/v 在/p 不同/a 于/p 训练/vn 集/q 的/uj 
測/zg 试/v 集上/i 另外/c 对/p 于/p 监督/vn 式/k 学习/v 所/c 
使用/v 的/uj 词汇/n 则是/i 分类/n 现 著 有著 各式 的 
分类器 各自 都有 强项 或 弱项 分类器 的 表现 非常 
大 程度 上 地 跟 要被 分类 的 资料 特性 
有关 并 没有 某一 单一 分类器 能够 在 全部 给定 
的 问题 上 都 表现 最好 这 被 称为 天下 
没有 白吃 的 午餐 理论 各式 的 经验法则 被用 来比 
較 分类器 的 表现 及 寻找 会 决定 分类器 表现 
的 资料 特性 决定 适合 某一 问题 的 分类器 仍旧 
是 一项 艺术 而非 科学 眼下 最 广泛 被 使用 
的 分类器 有 人工神经网络 支持 向量 机 近期 邻居 法 
高斯 混合模型 朴素 贝叶斯 方法 决策树 和 径向 基 函数 
分类 二 无 监督 式 学习 1 无 监督 式 
学习 Unsupervised Learning 是 人工智能 网络 的 一种 算法 algorithm 
其 目的 是 去 对 原始 资料 进行 分类 以便 
了解 资料 内部结构 有别于 监督 式 学习 网络 无 监督 
式 学习 网络 在 学习 时 并不 知道 其 分类 
结果 是否 正确 亦即 没有 受到 监督 式 增强 告诉 
它 何种 学习 是 正确 的 其 特点 是 仅对 
此种 网络 提供 输入 范例 而 它 会 自己 主动 
从 这些 范例 中 找出 其 潜在 类别 规则 当 
学习 完成 并经 測 试 后 也能够 将之 应用 到 
新的 案例 上 2 无 监督 学习 里 典型 的 
样例 就是 聚 类 了 聚 类 的 目的 在于 
把 相似 的 东西 聚在一起 而 我们 并不 关心 这 
一类 是 什么 因此 一个 聚 类 算法 通常 仅仅 
须要 知道 怎样 计算 相似 度 就 能够 開始 工作 
了 三 半 监督 学习 1 半 监督 学习 的 
基本 思想 是 利用 数据分布 上 的 模型 如果 建立 
学习 器 对 未 标签 样本 进行 标签 形式化 描写 
叙述 为 给定 一个 来自 某 未知 分布 的 样本 
集 = L ∪ U 当中 L 是 已 标签 
样 本集 L = { x1 y1 x2 y2 x 
| L | y | L | } U 是 
一个 未 标签 样 本集 U = { x 1 
x 2 x | U | } 希望 得到 函数 
f X → Y 能够 准确 地 对 样本 x 
预 測 其 标签 y 这个 函数 可能 是 參 
数 的 如 最大 似 然 法 可能 是 非 
參 数 的 如 最 邻近 法 神经 网络法 支持 
向量 机 法等/nr 也 可能 是 非 数值 的 如 
决策树 分类 当中 x 与 x   均为 d 维 
向量 yi ∈ Y 为 样本 x i 的 标签 
| L | 和|U/nr | 分别为 L 和U/nr 的 大小 
即 所 包括 的 样本 数 半 监督 学习 就是 
在 样 本集 上 寻找 最优 的 学习 器 怎样 
综合 利用 已 标签 例子 和未/nr 标签 例子 是 半 
监督 学习 须要 解决 的 问题 2 半/m 监督/vn 学习/v 
问题/n 从/p 样本/n 的/uj 角度/n 而言/c 是/v 利用/n 少量/m 标注/v 
样本/n 和/c 大量/n 未/d 标注/v 样本/n 进行/v 机器学习/i 从 概率 
学习 角度 可 理解 为 研究 怎样 利用 训练样本 的 
输入 边缘 概率 P x 和 条件 输出 概率 P 
y | x 的 联系 设计 具有 良好 性能 的 
分类器 这样 的 联系 的 存在 是 建立 在 某些 
如果 的 基础上 的 即 聚 类 如果 cluster   
assumption 和 流形 如果 maniford assumption 