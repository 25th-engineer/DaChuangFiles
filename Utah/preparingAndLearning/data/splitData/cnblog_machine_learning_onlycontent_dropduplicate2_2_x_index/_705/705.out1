深度 学习 vs 机器学习 vs 模式识别 模式识别 智能 程序 的 
诞生 机器学习 从 样本 中 学习 的 智能 程序 深度 
学习 一统江湖 的 架构 受 宠爱 最多 的 就是 被 
用在 大规模 图像识别 任务 中的 卷积 神经网络 1 机器学习 就像 
是 一个 真正 的 冠军 一样 持续 昂首 而上 2 
模式识别 一 开始 主要 是 作为 机器 学习 的 代名词 
模式识别 正在 慢慢 没落 和 消亡 3 深度 学习 是个 
崭新 的 和 快速 攀升 的 领域 1 . SVM 
经常 使用 的 核 函数 有 1 线性 核 函数 
2 多项式 核 3 径向 基 核 RBF 4 傅里叶 
核 5 样条 核 6 Sigmoid 核 函数 2 . 
  序列 模式 挖掘 算法 指 挖掘 相对 时间 或 
其他 模式 出现 频率 高的/nr 模式 典型 的 应用 还是 
限于 离散 型 的 序列 Apriori 类 算法 包括 AprioriAll 
和 GSP 等 在 序列 模式 挖掘 中 FreeSpan 和 
PrefixSpan 是 两个 常用 的 算法 其中 PrefixSpan 是从 FreeSpan 
中 推导 演化 而来 的 这 两个 算法 都比/nr 传统 
的 Apriori like 的 序列 模式 挖掘 算法 GSP 都 
有效 而 PrefixSpan 又比 FreeSpan 又 更 有效 这 是因为 
PrefixSpan 的 收缩 速度 比 FreeSpan 还要 更 快些 典型 
应用 商场 挖掘 即 用户 几次 购买 行为 间 的 
联系 可以 采取 更 有 针对性 的 营销 措施 类似于 
Apriori 算法 大体 分为 候 选集 产生 候 选集 计数 
以及 扩展 分类 三个 阶段 与 AprioriAll 算法 相比 GSP 
算法 统计 较少 的 候选 集 并且 在 数据 转换 
过程 中 不 需要 事先 计算 频繁 集 3 . 
序列 模式 VS 关联 规则 问题 序列 模式 挖掘 关联 
规则 挖掘 数据集 序列 数据库 事务 数据库 关注点 单项 间 
在 同一 事务 内 以及 事务 间 的 关系 单项 
间 在 同一 事务 内 的 关系 .   类 
域 界面 方程 法中/nr 求 线性 不可 分 情况 下 
分类 问题 近似 或 精确 解的/nr 方法 是 神经网络 处理 
不 可分 现象 5 . 特征选择 方法 信息 增益 信息 
增益 率 基尼系数 6 .   基于 核 的 算法 
支持 向量 机 Support Vector Machine SVM 径向 基 函数 
Radial Basis Function RBF 线性 判别分析 Linear Discriminate Analysis LDA 
等 7 .   数据清理 中 处理 缺失 值 的 
方法 是 数据清理 中 处理 缺失 值 的 方法 有 
两种 删 除法 1 删除 观察 样本 2 删除 变量 
当 某个 变量 缺失 值 较多 且 对 研究 目标 
影响 不大 时 可以 将 整个 变量 整体 删除 3 
使用 完整 原始 数据分析 当 数据 存在 较多 缺失 而其 
原始数据 完整 时 可以 使用 原始数据 替代 现有 数据 进行 
分析 4 改变 权重 当 删除 缺失 数据 会 改变 
数据结构 时 通过 对 完整 数据 按照 不同 的 权重 
进行 加权 可以 降低 删除 缺失 数据 带来 的 偏差 
查 补法 均值 插补 回归 插补 抽样 填补 等 成对 
删除 与 改变 权重 为 一类 估算/v 与/p 查/v 补法/i 
为/p 一类/m 8/m ./i  /i 下列/v 哪个/r 不/d 属于/v CRF/w 
模型/n 对于/p HMM/w 和/c MEMM/w 模型/n 的/uj 优势/n BA . 
特征 灵活   B . 速度快   C . 可容纳 
较多 上下文 信息   D . 全局 最优 首先 CRF 
HMM 隐 马 模型 MEMM 最大熵 隐 马 模型 都常/nr 
用来/v 做/v 序列/n 标注/v 的/uj 建模/n ./i 隐/n 马/n 模型/n 
一个/m 最大/a 的/uj 缺点/n 就是/d 由于/c 其/r 输出/v 独立性/n 假设/vn 
导致 其 不能 考虑 上下文 的 特征 限制/v 了/ul 特征/n 
的/uj 选择/v 最大熵/i 隐/n 马/n 模型/n 则/d 解决/v 了/ul 隐/n 
马的/nr 问题/n 可以 任意 选择 特征 但 由于 其 在 
每一 节点 都要/nr 进行 归一化 所以 只能 找到 局部 的 
最优 值 同时 也 带来 了 标记 偏见 的 问题 
即 凡是 训练 语 料中 未 出现 的 情况 全都 
忽略 掉 条件 随 机场 则 很好 的 解决 了 
这一 问题 他 并不 在 每一个 节点 进行 归一化 而是 
所有 特征 进行 全局 归一化 因此 可以 求得 全局 的 
最优 值 9 .   KNN 和K/nr Means 的 区别 
KNNK Means1 . KNN 是 分类 算法 2 . 监督 
学习 3 . 喂给 它 的 数据集 是 带 label 
的 数据 已经 是 完全 正确 的 数据 1 . 
K Means 是 聚 类 算法 2 . 非 监督 
学习 3 . 喂给 它 的 数据集 是 无 label 
的 数据 是 杂乱无章 的 经过 聚 类 后才 变得 
有点 顺序 先 无序 后 有序 没有 明显 的 前期 
训练 过程 属于 memory based learning 有 明显 的 前期 
训练 过程 K 的 含义 来 了 一个 样本 x 
要给 它 分类 即 求出 它 的 y 就从 数据 
集中 在 x 附近 找 离 它 最近 的 K 
个数 据点 这 K 个数 据点 类别 c 占 的 
个数 最多 就把 x 的 label 设为 cK 的 含义 
K 是 人工 固 定好 的 数字 假设 数据 集合 
可以 分为 K 个 簇 由于 是 依靠 人工 定好 
需要 一点 先验 知识 相似点 都 包含 这样 的 过程 
给定 一个点 在 数据 集中 找 离 它 最近 的 
点 即 二者 都用 到了 NN Nears Neighbor 算法 一般用 
KD 树 来 实现 NN 10 .   以下 哪个 
是 常见 的 时间 序列 算法 模型 BA . RSIB 
. MACDC .   ARMAD .   KDJ 时间 序列 
模型 是 指 采用 某种 算法 可以 是 神经 网络 
ARMA 等 模拟 历史数据 找出 其中 的 变化 规律 时间 
序列 算法 模型 主要有 移动 平均 算法 指数 平滑 算法 
及 ARMA ARIMA 方法 