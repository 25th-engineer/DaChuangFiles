为什么 不去 读 顶级 会议 上 的 论文 适 应于 
机器学习 计算机 视觉 和 人工智能 看了 版 上 很多 贴子 
发现 很多 版友 都在 问 热门 研究 方向 最 新方法 
等 有 同学 建议 国内 某 教授 的 教材 或者 
CNKI 或者 某些 SCI 期刊 每当 看到 这种 问题 我 
都 有点 纳闷 为什么 不去 读 顶级 会议 上 的 
论文 我 无意 否认 以上 文献 的 价值 但是 在 
机器学习 计算机 视觉 和 人工智能 领域 顶级 会议 才 是 
王道 国内 教材 和 CNKI 上 的 基本 是 N 
年前 老掉牙 的 东西 有人 会 质疑 这些 会议 都 
只是 EI 是的 这 的确 非常 特殊 在 许多 其它 
领域 会议 都是 盛会 比如 society of neuroscience 的 会议 
每次/r 都有/nr 上万/m 人/n 参加/v 带个 abstract 和 poster 就 
可以 去 但在 所 讨论 的 几个 领域 顶级 会议 
的 重要性 无论 怎么 强调 都 不为过 可以 从 以下 
几点 说明 1 因为 机器学习 计算机 视觉 和 人工智能 领域 
发展 非常 迅速 新的 工作 层出不穷 如果把 论文 投到 期刊 
上 一/m 两年/m 后/f 刊出/v 时就/nr 有点/n out/w 了/ul 因此 
大 部分 最新 的 工作 都 首先 发表 在 顶级 
会议 上 这些 顶级 会议 完全 能 反映 热门 研究 
方向 最 新方法 2 很多 经典 工作 大家 可能 引 
的 是 某 顶级 期刊 上 的 论文 这 是因为 
期刊论文 表述 得 比较 完整 实验 充分 但 实际上 很多 
都是在/nr 顶级 会议 上 首发 比如 PLSA Latent Dirichlet Allocation 
等 3 如果 注意 这些 领域 大牛 的 pulications 不难 
发现 他们 很 非常 看重 这些 顶级 会议 很多 人 
是 80% 的 会议 + 20% 的 期刊 即 然 
大牛 们 把 最新 工作 发在 顶级 会议 上 有 
什么 理由 不去 读 顶级 会议 1 以下 是 不 
完整 的 列表 但 基本 覆盖 机器学习 顶级 会议 NIPS 
ICML UAI AISTATS 期刊 JMLR ML Trends in ML IEEE 
T NN 计算机 视觉 和 图像 识别 ICCV CVPR ECCV 
期刊 IEEE T PAMI IJCV IEEE T IP 人工智能 IJCAI 
AAAI 期刊 AI 另外 相关 的 还有 SIGRAPH KDD ACL 
SIGIR WWW 等 特别 是 如果 做 机器学习 必须 地 
把 近 4年 的 NIPS ICML 翻 几遍 如果 做 
计算机 视觉 要把 近 4年 的 ICCV CVPR NIPS ICML 
翻 几遍 2 另外 补充 一下 大部分 顶级 会议 的 
论文 都 能从 网上 免费 下载 到 比如 CV 方面 
http / / www . cvpapers . com / index 
. html NIPS http / / books . nips . 
cc / JMLR 期刊 http / / jmlr . csail 
. mit . edu / papers / COLT 和 ICML 
每 年度 的 官网 http / / www . cs 
. mcgill . ca / ~ colt2009 / proceedings . 
html 希望 这些 信息 对 大家 有点 帮助 3 说 
些 自己 的 感受 我 的 研究 方向 主要 是 
统计 学习 和 概率 图 模型 但对 计算机 视觉 和 
计算 神经科学 都有 涉及 对 Data mining 和 IR 也 
有些 了解 这些 领域 从/p 方法/n 和/c 模型/n 的/uj 角度/n 
看/v 统计模型 包括 probabilistic graphical model 和 statistical learning theory 
是 主流 也 是 非常 有 影响力 的 方法 有个 
非常 明显 的 趋势 重要 的 方法 和 模型 最先 
在 NIPS 或 ICML 出现 然后 应用到 CV IR 和 
MM 虽然 具体 问题 和 应用 也 很重要 但 多 
关注 和 结合 这些 方法 也很 有意义 对于 这个 领域 
的 牛 人们 以上 全是 浅显 的 废话 完全 可以 
无视 欢迎 讨论 