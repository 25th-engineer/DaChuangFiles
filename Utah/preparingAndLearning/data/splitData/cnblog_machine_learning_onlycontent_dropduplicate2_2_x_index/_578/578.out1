最近 在跟 台大 的 这个 课程 觉得 不错 想把 学习 
笔记 发出来 跟 大家 分享 下 有错误 希望 大家 指正 
一 机器学习 是 什么 感觉 和 /nr Tom M . Mitchell 
的 定义 几乎 一致 A computer program is said to 
learn from   experience   E with respect to some 
class of tasks T and performance measure   P if 
its performance at tasks in T as measured by P 
improves with experience E . 简而言之 就是 我们 想 要 
机器 在 某些 方面 有 提高 如 搜索 排名 的 
质量 即 NDCG 提高 就 给 机器 一些 数据 用户 
的 点击 数据 等 各种 然后 让 机器 获得 某些 
经验 Learning to rank 的 一种 模型 也 就是 数学公式 
这里有 点 需要 强调 那 就是 提高 指标 必须 要 
有 某种 指标 可以 量化 这种 提高 这点 还是 很 
关键 的 工业界 做 机器学习 首先 关注 data 其次 就是 
有无 成型 的 measurement 可以 使 Precision / Recall 也 
可以 是 NDCG 等 二 什么 时候 可以 用 机器学习 
其实 就 三要素 有规律 可以 学习 编程 很难 做到 有 
能够 学习 到 规律 的 数据 编程 很难 做到 可以 
有 多种 大 部分 原因 是 系统 太 复杂 很难 
用 Rule based 的 东西 去 解决 例如 搜索 排名 
现在 影响 排名 的 因素 有超多/nr 几百种 不 可能 去 
想出 这些 因素 的 规则 因此 这时候 用 机器学习 就是 
恰到好处 特别 是 移动 互联网 的 今天 用户 更 容易 
接触 互联网 产生 的 数据 越来越 多 那么 要 找到 
某些 不 容易 实现 的 规律 用 机器学习 就是 很好 
的 了 这 也是 为啥 机器学习 这么 火 其实 我 
学 机器学习 不 仅仅 是 一种 投资 肯定 它 未来 
的 发展前途 我 想做 的 事情 还有 一点 就是 通过 
它 更 深刻 的 理解 人脑 的 学习 过程 提高 
自己 的 学习 效率 和 思维 能力 三 具体 如何 
用 机器学习 输入 是 两个 1 data 2 假设 集合 
Data 如何 使用 通过 提取 出 feature vector 来 使用 
也 就是 那个 training examples 假设 集合 是 用来 选取 
最终 f 的 也 就是说 输出 就是 f 或 近似 
f 四 第一 个 机器学习 算法 PLA Perceptron Learning Algorithm 
课程 讲述 这个 算法 的 总体 思路 如下 典型 的 
提出 问题 分析 问题 以及 解决 问题 通过 信用卡 问题 
引入 PLA 对 问题 用 数学 抽象 并 得到 目标函数 
详细 解释 PLA 迭代 学习 过程 证明 PLA 学习 的 
过程 可以 收敛 并会 得到 最优 解 分析 PLA 优缺点 
并 提出 克服缺点 的 一些 方法 这个 算法 本质上 是 
线性 分类器 针对 给定 的 feature vector 给出 Yes 或者 
No 的 回答 下面 是 用 这个 算法 去 解决 
信用卡 问题 的 数学 抽象 这里 的 思想 在于 朴素 
的 把 从 用户 信息 抽 出来 的 一些 feature 
年龄 等 量化 并 组成 vector 然后 乘以 一个 权重 
向量 并 设定 一个 阈值 大于 这个 阈值 就 表示 
好 小于 表示 不好 很明显 这个 式子 的 未知 变量 
有 两个 实际 只有 一个 权重 向量 wi 1 = 
i = d 阈值 下面 设为 0 做 一点 小小的 
变形 使得 式子 更加 紧凑 还有 就是 从 这个 模型 
可以 知道 regression model 也 可以 解决 classification 问题 转化 
的 思想 下面 是 这个 算法 的 核心 定义 了 
学习 目标 之后 如何 学习 这里 的 学习 是 如何 
得到 最终 的 直线 去 区分 data 这个 算法 的 
精髓 之处 在于 如何 做到 做错 能改 其 循环 是 
不断 遍历 feature vector 找到 错误 的 点 Yn 和 
当前 Wt * Xn 不符合 然后 校正 Wt 那么 为什么 
要 这样 校正 因为 这样 可以 保证 Wt 越来越 靠近 
perfect 直线 Wf ps . 暂时 没 想到 正向 思维 
是 如何 得到 这个 式子 的 课程 像 大多数 课本 
一样 用 逆向思维 给予 介绍 就是 在 给定 这样 能够 
做 的 情况 下 去 证明 即 证明 为什么 这样 
做 可以 不断 接近 目标 以及 最终 一定 会 停止 
下面 道出 了 PLA 终止 的 条件 这个 是 比较 
容易 想到 的 如果 不能 用 直线 去 区分 data 
线性 不可分 肯定 是 解决 不了 的 所以 必须 要 
满足 线性 可分 其实 问题 的 关键 在于 如何 方便 
的 知道 某些 数据 是否 线性 可分 这个 在 课程 
中 目前 没有 涉及 一种 简单 的 解决 方法 是 
画出来 直观 的 去看 这个 我 觉得 不是 好 方法 
这 两页 PPT 比较复杂 其实 就是 在 利用 条件 证明 
下面 重新 组织 下 给出 思路 因为 Latex 用 中文 
不太 爽 就用 英文 了 五 PLA 的 优缺点 为了 
应对 Noisy 我们 不 可能 得到 完美 的 直线 那么 
怎么 衡量 当前 得到 的 直线 能够 满足 要求 呢 
凭直觉 我们 知道 如果 当前 直线 犯错 越少 越好 对 
所有 data 于是 有了/nr 下面 的 改进 算法 Pocket PLA 
本质 上 就是 在 改错 的 时候 多做 一步 判断 
当前 改 正犯 的 错 是否 比 之前 更小 也 
就是 贪心 选择 上 了 一周 台大 的 这个 课程 
感觉 老师 还是 很 负责任 特别 是 循循善诱 的 教学 
方式 真正 是 站在 学生 的 角度 考虑 问题 更 
重要 的 是 我 很 欣赏 课程 的 脉络 其 
由 几个 关键 问题 引出 整套 课程 这 和 如何 
阅读 一 本书 里面 带着 问题 阅读 很像 其实 学习 
也 是 如此 这点 必须 赞 一下 也 做个 小 
广告 目前 大家 都在/nr 推荐 Ng 教授 的 课程 我 
觉得 这个 课程 也 值得 推荐 参考资料 Coursera 台大 机器学习 
基石 注 除了 证明 其他 授课 ppt 都 来源于 课程 
