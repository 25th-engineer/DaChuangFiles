在 Ubuntu 下 安装 Python 模块 通常 有3/nr 种方法 1 
使用 apt get 2 使用 pip 命令 推荐 3 easy 
_ instal 可 安装 方法 参考 转 linux/w 和/c windows/w 
下/f 安装/v python/w 集成/v 开发/v 环境/n 及其/c python/w 包 /nr 二 
安装 参考 Install Python packages on Ubuntu 14.04 使用/v pip/w 
安装/v 以下/f 包时/nr 可能/v 会/v 出现/v 问题/n 某些 基础 库 
缺失 导致 安装 失败 所以 可确定 系统 中 是否 存在 
以下 基础 库 Ubuntu dependenciesA variety of Ubuntu specific packages 
are needed by Python packages . These are libraries compilers 
fonts etc . I ll detail these here along with 
install commands . Depending on what you want to install 
you might not need all of these . General development 
/ build $ sudo apt get install build essential python 
devCompilers / code integration $ sudo apt get install gfortran 
$ sudo apt get install swigNumerical / algebra packages $ 
sudo apt get install libatlas dev $ sudo apt get 
install liblapack devFonts for matplotlib $ sudo apt get install 
libfreetype6 libfreetype6 devMore fonts for matplotlib on Ubuntu Server 14.04 
– see comment at end of post – added 2015 
/ 03/06 $ sudo apt get install libxft devGraphviz for 
pygraphviz networkx etc . $ sudo apt get install graphviz 
libgraphviz devIPython require pandoc for document conversions printing etc . 
$ sudo apt get install pandocTinkerer dependencies $ sudo apt 
get install libxml2 dev libxslt dev zlib1g devThat s it 
now we start installing the Python packages . 安装 列表 
1 numpy scipy2 pandas Powerful data structures for data analysis 
time   series and statistics3 statsmodels4 matplotlib pyplot pylab5 libsvm6 
jieba 分词 7 scikit learn 工具包 8 Theano 深度 学习 
9 wikipedia Wikipedia API for Python10 gensim11 Pattern12 NLTK Natural 
Language Toolkit   自然语言 处理 工具包 1 numpy Python 的 
语言 扩展 定义 了 数字 的 数组 和 矩阵 提供 
了 存储 单一 数据类型 的 多维 数组 ndarray 和 矩阵 
matrix scipy 其 在 numpy 的 基础 上 增加 了 
众多 的 数学 科学 以及 工程 计算 中 常用 的 
模块 例如 线性代数 常 微分方程 数值 求解 信号处理 图像处理 稀疏 
矩阵 等等 2 pandas 直接 处理 和 操作 数据 的 
主要 package 提供 了 dataframe 等 方便 处理 表格 数据 
的 数据 结构 安装 如下 pip 方法 import pandas as 
pd df = pd . read _ csv https / 
/ archive . ics . uci . edu / ml 
/ machine learning databases / iris / iris . data 
header = None print df3 statsmodels 统计 和 计量 经济学 
的 package 包含 了 用于 参数 评估 和 统计 测试 
的 实用工具 Python 中的 结构化 数据分析 利器 Pandas 简介 17 
September 2013 Pandas 是 python 的 一个 数据 分析 包 
最初 由 AQR Capital Management 于 2008年 4月 开发 并于 
2009 年底 开源 出来 目前/t 由/p 专注/v 于/p Python/w 数据包/n 
开发/v 的/uj PyData/w 开发/v team/w 继续/v 开发/v 和/c 维护/v 属于 
PyData 项目 的 一部分 Pandas 最初 被 作为 金融 数据 
分析 工具 而 开发 出来 因此 pandas 为 时间 序列 
分析 提供 了 很好 的 支持 Pandas 的 名称 来自于 
面板 数据 panel data 和 python 数据分析 data analysis panel 
data 是 经济学 中 关于 多维 数据集 的 一个 术语 
在 Pandas 中 也 提供 了 panel 的 数据 类型 
这篇文章 会 介绍 一些 Pandas 的 基本 知识 偷了 些 
懒 其中 采用 的 例子 大 部分 会 来自 官方 
的 10 分钟 学 Pandas 我会 加上 个人 的 理解 
帮助 大家 记忆 和 学习 Pandas 中的 数据结构 Series 一维 
数组 与 Numpy 中的 一维 array 类似 二者 与 Python 
基本 的 数据结构 List 也很 相近 其 区别 是 List 
中的 元素 可以 是 不同 的 数据 类型 而 Array 
和 Series 中 则 只允许 存储 相同 的 数据 类型 
这样 可以 更 有效 的 使用 内存 提高 运算 效率 
Time Series 以 时间 为 索引 的 Series DataFrame 二维 
的 表格 型 数据结构 很多 功能 与 R 中的 data 
. frame 类似 可以 将 DataFrame 理解为 Series 的 容器 
以下 的 内容 主要 以 DataFrame 为主 Panel 三维 的 
数组 可以 理解 为 DataFrame 的 容器 more 创建 DataFrame 
首先 引入 Pandas 及 Numpy import pandas as pd import 
numpy as np 官方 推荐 的 缩写 形式 为 pd 
你 可以 选择 其他 任意 的 名称 DataFrame 是 二维 
的 数据结构 其 本质 是 Series 的 容器 因此 DataFrame 
可以 包含 一个 索引 以及 与 这些 索引 联合 在 
一起 的 Series 由于 一个 Series 中的 数据类型 是 相同 
的 而 不同 Series 的 数据结构 可以 不同 因此 对于 
DataFrame 来说 每 一列 的 数据 结构 都是/nr 相同 的 
而 不同 的 列 之间 则 可以 是 不同 的 
数据 结构 或者 以 数据库 进行 类比 DataFrame 中的 每 
一行 是 一个 记录 名称 为 Index 的 一个 元素 
而每 一列 则为 一个 字段 是 这个 记录 的 一个 
属性 创建 DataFrame 有 多种 方式 以 字典 的 字典 
或 Series 的 字典 的 结构 构建 DataFrame 这时候 的 
最外面 字典 对应 的 是 DataFrame 的 列 内嵌 的 
字典 及 Series 则是 其中 每个 值 d = { 
one pd . Series 1 . 2 . 3 . 
index = a b c two pd . Series 1 
. 2 . 3 . 4 . index = a 
b c d } df = pd . DataFrame d 
可以 看到 d 是 一个 字典 其中 one 的 值 
为 Series 有 3个 值 而 two 为 Series 有 
4个 值 由 d 构建 的 为 一个 4行 2列 
的 DataFrame 其中 one 只有 3个 值 因此 d 行 
one 列为 NaN Not a Number Pandas 默认 的 缺失 
值 标记 从 列表 的 字典 构建 DataFrame 其中 嵌套 
的 每个 列表 List 代表 的 是 一个 列 字典 
的 名字 则是 列 标签 这里 要 注意 的 是 
每个 列表 中 的 元素 数量 应该 相同 否则 会 
报错 ValueError arrays must all be same length 从 字典 
的 列表 构建 DataFrame 其中 每个 字典 代表 的 是 
每条 记录 DataFrame 中的 一行 字典 中 每个 值 对应 
的 是 这条 记录 的 相关 属性 d = { 
one 1 two 1 } { one 2 two 2 
} { one 3 two 3 } { two 4 
} df = pd . DataFrame d index = a 
b c d columns = one two df . index 
. name = index 以上 的 语句 与 以 Series 
的 字典 形式 创建 的 DataFrame 相同 只是 思路 略有不同 
一个 是 以 列为 单位 构建 将 所有 记录 的 
不同 属性 转化 为 多个 Series 行 标签 冗余 另 
一个 是 以 行为 单位 构建 将 每条 记录 转化 
为 一个 字典 列 标签 冗余 使用 这种 方式 如果 
不 通过 columns 指定 列 的 顺序 那么 列 的 
顺序 会 是 随机 的 个人 经验 是 对于 从 
一些 已经 结构化 的 数据 转化 为 DataFrame 似乎 前者 
更 方便 而 对于 一些 需要 自己 结构化 的 数据 
比如 解析 Log 文件 特别 是 针对 较大 数据量 时 
似乎 后者 更 方便 创建 了 DataFrame 后 可以 通过 
index . name 属性 为 DataFrame 的 索引 指 定名称 
DataFrame 转换 为 其他 类型 df . to _ dict 
outtype = dict outtype 的 参数 为 dict list series 
和 records dict 返回 的 是 dict of dict list 
返回 的 是 列表 的 字典 series 返回 的 是 
序列 的 字典 records 返回 的 是 字典 的 列表 
查看 数据 head/w 和/c tail/w 方法/n 可以/c 显示/v DataFrame/w 前/f 
N/w 条/n 和后N/nr 条/n 记录/n N 为 对应 的 参数 
默认值 为 5 这 通常 是 拿到 DataFrame 后的/nr 第一 
个 命令 可以 方便 的 了解 数据 内容 和 含义 
df . head one two index a 1 1 b 
2 2 c 3 3 d NaN 4 4 rows 
× 2 columns R 中的 对应 函数 head df df 
. tail one two index a 1 1 b 2 
2 c 3 3 d NaN 4 4 rows × 
2 columns index 行 和 columns 列 属性 可以获得 DataFrame 
的 行 和列的/nr 标签 这也 是 了解 数据 内容 和 
含义 的 重要 步骤 df . index Index u a 
u b u c u d dtype = object 查看 
字段名 df . columns Index u one u two dtype 
= object decribe 方法 可以 计算 各个 列 的 基本 
描述统计 值 包含 计数 平均数 标准差 最大值 最小值 及 4 
分位差 df . describe one two count 3.0 4.000000 mean 
2.0 2.500000 std 1.0 1.290994 min 1.0 1.000000 25% 1.5 
1.750000 50% 2.0 2.500000 75% 2.5 3.250000 max 3.0 4.000000 
8 rows × 2 columns R 中的 对应 函数 summary 
df 行列 转置 df . T index a b c 
d one 1 2 3 NaN two 1 2 3 
4 2 rows × 4 columns 排序 DataFrame 提供 了 
多种 排序 方式 df . sort _ index axis = 
1 ascending = False sort _ index 可以 以 轴 
的 标签 进行 排序 axis 是 指 用于 排序 的 
轴 可选/v 的/uj 值/n 有/v 0/m 和1/nr 默认 为 0 
即行 标签 Y 轴 1 为 按照 列 标签 排序 
ascending 是 排序 方式 默认 为 True 即 降序 排列 
df . sort columns = two df . sort columns 
= one two ascending = 0 1 DataFrame 也 提供 
按照 指定 列 进行 排序 可以 仅 指定 一个 列 
作为 排序 标准 以 单独 列名 作为 columns 的 参数 
也 可以 进行 多重 排序 columns 的 参数 为 一个 
列名 的 List 列名 的 出现 顺序 决定 排序 中的 
优先级 在 多重 排序 中 ascending 参数 也为 一个 List 
分别 与 columns 中的 List 元素 对应 读写 数据 DataFrame 
可以 方便 的 读写 数据文件 最 常见 的 文件 为 
CSV 或 Excel Pandas 读写 Excel 文件 需要 openpyxl Excel 
2007 xlrd / xlwt Excel 2003 从 CSV 中 读取数据 
df = pd . read _ csv foo . csv 
R 中的 对应 函数 df = read . csv foo 
. csv 将 DataFrame 写入 CSV df . to _ 
csv foo . csv R 中的 对应 函数 df . 
to . csv foo . csv 从 Excel 中 读取数据 
xls = ExcelFile foo . xlsx xls . parse sheet1 
index _ col = None na _ values = NA 
先 定义 一个 Excel 文件 用 xls . parse 解析 
sheet1 的 内容 index _ col 用于 指定 index 列 
na _ values 定义 缺失 值 的 标识 将 DataFrame 
写入 Excel 文件 df . to _ excel foo . 
xlsx sheet _ name = sheet1 默认 的 sheet 为 
sheet1 也 可以 指定 其他 sheet 名 数据 切片 通过 
下标 选取 数据 df one df . one 以上 两个 
语句 是 等效 的 都是 返回 df 名称 为 one 
列 的 数据 返回 的 为 一个 Series df 0 
3 df 0 下标 索引 选取 的 是 DataFrame 的 
记录 与 List 相同 DataFrame 的 下标 也 是从 0 
开始 区间 索引 的话 为 一个 左闭右/nr 开 的 区间 
即 0 3 选取 的 为 1 3 三条 记录 
与此 等价 还 可以 用 起始 的 索引 名称 和 
结束 索引 名称 选取 数据 df a b 有一点 需要 
注意 的 是 使用 起始 索引 名称 和 结束 索引 
名称 时 也会 包含 结束 索引 的 数据 以上 两种 
方式 返回 的 都是 DataFrame 使用 标签 选取 数据 df 
. loc 行 标签 列 标签 df . loc a 
b # 选取 ab 两行 数据 df . loc one 
# 选取 one 列 的 数据 df . loc 的 
第一 个 参数 是 行 标签 第二个 参数 为 列 
标签 可选 参数 默认 为 所有 列 标签 两个 参数 
既 可以 是 列表 也 可以 是 单个 字符 如果 
两个 参数 都为 列表 则 返回 的 是 DataFrame 否则 
则为 Series 使用 位置 选取 数据 df . iloc 行 
位置 列 位置 df . iloc 1 1 # 选取 
第二行 第二列 的 值 返回 的 为 单个 值 df 
. iloc 0 2 # 选取 第一行 及 第三 行 
的 数据 df . iloc 0 2 # 选取 第一行 
到 第三 行 不 包含 的 数据 df . iloc 
1 # 选取 所有 记录 的 第一 列 的 值 
返回 的 为 一个 Series df . iloc 1 # 
选取 第一行 数据 返回 的 为 一个 Series PS loc 
为 location 的 缩写 iloc 则为 integer & location 的 
缩写 更 广义 的 切片 方式 是 使用 . ix 
它 自动 根据 你 给 到 的 索引 类型 判断 
是 使用 位置 还是 标签 进行 切片 df . ix 
1 1 df . ix a b 通过 逻辑 指针 
进行 数据 切片 df 逻辑 条件 df df . one 
= 2 # 单个 逻辑 条件 df df . one 
= 1 & df . one 3 # 多个 逻辑 
条件 组合 这种 方式 获得 的 数据 切片 都是 DataFrame 
基本 运算 Pandas 支持 基本 的 运算 及 向 量化 
运算 df . mean # 计算 列 的 平均值 参数 
为 轴 可选 值 为 0 或 1 . 默认 
为 0 即 按照 列 运算 df . sum 1 
# 计算 行 的 和 df . apply lambda x 
x . max x . min # 将 一个 函数 
应用到 DataFrame 的 每 一列 这里 使用 的 是 匿名 
lambda 函数 与 R 中 apply 函数 类似 设置 索引 
df . set _ index one 重命名 列 df . 
rename columns = { u one 1 } inplace = 
True 查看 每个 列 的 数据类型 df . dtypes R 
中的 对应 函数 str df 查看 最大值 / 最小值 pd 
. Series . max pd . Series . idxmax 重设 
索引 df . reset _ index inplace = True 改变 
数据类型 df A . astype float 计算 Series 每个 值 
的 频率 df A . value _ counts R 的 
对应 函数 table df A 字符 方法 pandas 提供 许多 
向 量化 的 字符 操作 你 可以 在 str 属性 
中 找到 它们 s . str . lower s . 
str . len s . str . contains pattern DataFrame 
的 合并 Contact ds = { one 4 two 2 
} { one 5 two 3 } { one 6 
two 4 } { two 7 three 10 } dfs 
= pd . DataFrame ds index = e f g 
h # # 构建 一个 新的 DataFrame dfs df _ 
t = pd . concat df dfs # 合并 两个 
DataFrame Merge 类似 SQL 中的 Join 操作 left = pd 
. DataFrame { key foo1 foo2 lval 1 2 } 
right = pd . DataFrame { key foo1 foo2 rval 
4 5 } # 构建 了 两个 DataFrame pd . 
merge left right on = key # 按照 key 列 
将 两个 DataFrame join 在 一起 DataFrame 中的 Group by 
df = pd . DataFrame { A foo bar foo 
bar foo bar foo foo B one one two three 
two two one three C randn 8 D randn 8 
} df . groupby A . sum # 按照 A 
列 的 值 分组 求和 df . groupby A B 
. sum # # 按照 A B 两列 的 值 
分组 求和 对应 R 函数 tapply 在 实际 应用 中 
先 定义 groups 然后再 对 不同 的 指标 指定 不同 
计算 方式 groups = df . groupby A # 按照 
A 列 的 值 分组 求和 groups B . sum 
# # 按照 A 列 的 值 分组 求 B 
组 和 groups B . count # # 按照 A 
列 的 值 分组 B 组 计数 默认 会 以 
groupby 的 值 作为 索引 如果 不 将 这些 值 
作为 索引 则 需要 使用 as _ index = False 
df . groupby A B as _ index = False 
. sum 构建 透视 表 使用/v pivot/w _/i table/w 和/c 
crosstab/w 都/d 可以/c 创建/v 数据透视/i 表/v df = pd . 
DataFrame { A one one two three * 3 B 
A B C * 4 C foo foo foo bar 
bar bar * 2 D np . random . randn 
12 E np . random . randn 12 } pd 
. pivot _ table df values = D rows = 
A B cols = C # 以 A B 为 
行 标签 以 C 为 列 标签 将 D 列 
的 值 汇总 求和 pd . crosstab rows = A 
B cols = C values = D # 以 A 
B 为 行 标签 以 C 为 列 标签 将 
D 列 的 值 汇总 求和 时间 序列 分析 时间 
序列 也是 Pandas 的 一个 特色 时间 序列 在 Pandas 
中 就是 以 Timestamp 为 索引 的 Series pandas 提供 
to _ datetime 方法 将 代表 时间 的 字符 转化 
为 Timestamp 对象 s = 2013 09 16 21 00 
00 ts = pd . to _ datetime s 有时 
我们 需要 处理 时区/nr 问题 ts = pd . to 
_ datetime s utc = True . tz _ convert 
Asia / Shanghai 构建 一个 时间 序列 rng = pd 
. date _ range 1 / 1/2012 periods = 5 
freq = M ts = pd . Series randn len 
rng index = rng Pandas 提供 resample 方法 对 时间 
序列 的 时间 粒度 进行 调整 ts _ h = 
ts . resample H how = count # M 5Min 
1s 以上 是 将 时间 序列 调整 为 小时 还 
可以 支持 月 M 分钟 Min 甚至 秒 s 等 
画图 Pandas 也 支持 一定 的 绘图 功能 需要 安装 
matplot 模块 比如 前面 创建 的 时间 序列 通过 plot 
就 可以 绘制 出 折线图 也 可以 使用 hist 命令 
绘制 频率分布 的 直方图 关于 Panda 作图 请 查看 另一 
篇 博文 用 Pandas 作图 以上 是 关于 Pandas 的 
简单 介绍 其实 除了 Pandas 之外 Python 还 提供 了 
多个 科学计算 包 比如 Numpy Scipy 以及 数据 挖掘 的 
包 Scikit Learn Orage NLTK 等 感 兴趣 的 同学 
可以 了解 一下 python 17 数据 科学 3 dataframe 1 
Pandas 2 数据分析 1 时间 序列 分析 1View Code4 matplotlib 
pyplot pylab 用于 生成 统计图 pyplot 和 pylab 属于 matplotlib 
的 子 模块 所以 只 需 安装 matplotlib 就 会有 
pyplot 和 pylab 的 了 The difference between pylab and 
pyplot is that the former imports numpy into its namespace 
. This was to make it behave more similarly with 
matlab . Using pyplot instead of pylab is preferred now 
because it is cleaner .   Python 一般 使用 Matplotlib 
制作 统计 图形 用 它 自己 的 说法 是 让 
简单 的 事情 简单 让 复杂 的 事情 变得 可能 
你 说 国外 的 码 农 咋 这么 会 说 
我 就 整 不 出来 这 工整 的 句子 用 
它 可以 制作 折线图 直方图 条形图 散点图 饼图 谱图/i 等等/u 
你/r 能/v 想到/v 的/uj 和/c 想不到/l 的/uj 统计/v 图形/n 这些 
图形 可以 导出 为 多种 具有 出版 质量 的 格式 
此外 它 和 ipython 结合 使用 确实 方便 谁 用 
谁知道 在 Matplotlib 里面 经常 使用 到 的 是 pylab 
和 pyplot 它 之间 的 区别 在于 pyplot 是 封装 
好 的 调用 matplotlib 底层 制 图库 的 接口 制图 
时 用户 不用 关心 底层 的 实现 而 pylab 则 
是 为了 使用者 的 方便 将 numpy 和 pyplot 的 
功能 集中 在 了 一个 命名 空间 中 这么 解释 
可能 还是 不 太 清楚 因此 在 此次 举个 例子 
1 2 3 4 5 6 7 8 9 1 
0 1 1 1 2 1 3 1 4 1 
5 1 6 1 7 1 8 1 9 i 
m p o r t pylabimport numpy as npimport matplotlib 
. pyplot as pltpylab . randn 2 3 array 1.22356117 
0.62786477 0.02927331 1.11739661 1.64112491 2.24982297 np . random . randn 
2 3 array 1.41691502 1.43500335 0.68452086 0.53925581 0.18478012 0.0126745 pylab 
. hist 1 1 1 2 3 3 plt . 
hist 1 1 1 2 3 3 从 上面 的 
例子 可以 看在 pylab 中 可以 使用 numpy 中 的 
一些 方法 而在 pyplot 中 不能 使用 numpy 的 方法 
pylab 和 pyplot 都可以 制作 统计 图形 5 libsvm svm 
模型 的 一个 库 附 安装 方法 先从 网站 下载 
LibSVM 的 安装包 http / / www . csie . 
ntu . edu . tw / ~ cjlin / cgi 
bin / libsvm . cgi + http / / www 
. csie . ntu . edu . tw / ~ 
cjlin / libsvm + tar . gz 然后 解压 从 
终端 进入 解压 目录 输入 make 例如 我 下载 的 
是 libsvm 3.20 . tar . gzcd / home / 
eple / Downloads / libsvm 3.20 make 然后 进入 python 
目录 同样 输入 make 该 步骤 会 生成 libsvm . 
so . 2 cd python / make 好了 搞定 为了 
测试 是否 成功 在 终端 启动 python 输入 附上 官方 
提供 的 例子 Quick Start = = = = = 
= = = = = = There are two levels 
of usage . The high level one uses utility functionsin 
svmutil . py and the usage is the same as 
the LIBSVM MATLAB interface . from svmutil import * # 
Read data in LIBSVM format y x = svm _ 
read _ problem . . / heart _ scale m 
= svm _ train y 200 x 200 c 4 
p _ label p _ acc p _ val = 
svm _ predict y 200 x 200 m # Construct 
problem in python format # Dense data y x = 
1 1 1 0 1 1 0 1 # Sparse 
data y x = 1 1 { 1 1 3 
1 } { 1 1 3 1 } prob = 
svm _ problem y x param = svm _ parameter 
t 0 c 4 b 1 m = svm _ 
train prob param 但是 要在 Pycharm 下 这样 做 还是 
不够 的 还 需要 把 libsvm 3.18 / python / 
* py 文件 放到 / usr / lib / python2 
. 7 / dist packages 中 libsvm . so . 
2 放到 / usr / lib / python2 . 7 
/ 中 sudo cp * . py / usr / 
lib / python2 . 7 / dist packages sudo cp 
/ home / eple / Downloads / libsvm 3.20 / 
libsvm . so . 2 / usr / lib / 
python2 . 7OK 6 jieba 中文分词 工具 附 安装 方法 
结巴 中文分词 做 最好 的 Python 中文分词 组件 Jieba Chinese 
for to stutter Chinese text segmentation built to be the 
best Python Chinese word segmentation module . 特点 支持 三种 
分 词模式 精确 模式 试图 将 句子 最 精确地 切开 
适合 文本 分析 全 模式 把/p 句子/n 中/f 所有/b 的/uj 
可以/c 成词的/nr 词语/n 都/d 扫描/v 出来/v 速度 非常 快 但是 
不能 解决 歧义 搜索引擎 模式 在 精确 模式 的 基础 
上 对 长词 再次 切分 提高 召回率 适合 用于 搜索引擎 
分词 支持 繁体 分词 支持 自定义 词典 MIT 授权 协议 
在线 演示 http / / jiebademo . ap01 . aws 
. af . cm / 网站 代码 https / / 
github . com / fxsjy / jiebademo 安装 说明 代码 
对 Python 2/3 均 兼容 全自动 安装 easy _ install 
jieba 或者 pip install jieba / pip3 install jieba 半自动 
安装 先 下载 http / / pypi . python . 
org / pypi / jieba / 解压 后 运行 python 
setup . py install 手动 安装 将 jieba 目录 放置 
于 当前目录 或者 site packages 目录 通过 import jieba 来 
引用 7 scikit learn 工具包 是 一个 基于 SciPy 和 
Numpy 的 开源 机器学习 模块 包括 分类 回归 聚 类 
系列 算法 主要 算法 有 SVM 逻辑 回归 朴素 贝叶斯 
Kmeans DBSCAN 等 也 提供 了 一些 语料库 英文 简介 
Scikit learn   is a Python module integrating a wide 
range of state of the art machine learning algorithms for 
medium scale supervised and unsupervised problems . This package focuses 
on bringing machine learning to non specialists using a general 
purpose high level language . Emphasis is put on ease 
of use performance documentation and API consistency . It has 
minimal dependencies and is distributed under the simplified BSD license 
encouraging its use in both academic and commercial settings . 
Source code binaries and documentation can be downloaded from http 
/ / scikit learn . sourceforge . net . 项目 
主页 https / / pypi . python . org / 
pypi / scikit learn / http / / scikit learn 
. org / https / / github . com / 
scikit learn / scikit learn 附 安装 方法 1 在 
Ubuntu 源 上 可以 直接 找到 该 工具包 如 下图 
直接 安装 附 安装 方法 2 pip8 Theano 深度 学习 
Theano 是 一个 机器学习 库 允许 你 定义 优化 和 
评估 涉及 多维 数组 的 数学 表达式 这 可能 是 
其它 库 开发商 的 一个 挫折 点 与 scikit learn 
一样 Theano 也 很好 地 整合 了 NumPy 库 GPU 
的 透明 使用 使得 Theano 可以 快速 并且 无错 地 
设置 这 对于 那些 初学者 来说 非常 重要 然而 有些 
人 更多 的 是 把 它 描述 成 一个 研究 
工具 而 不是 当作 产品 来 使用 因此 要 按需 
使用 Theano 最好 的 功能 之一 是 拥有 优秀 的 
参考 文档 和 大量 的 教程 事实上 多亏 了此 库 
的 流行 程度 使 你 在 寻找 资源 的 时候 
不会 遇到 太多 的 麻烦 比如 如何 得到 你 的 
模型 以及 运行 等 安装 如下 9 wikipedia Wikipedia   
is a Python library that makes it easy to access 
and parse data from WikipediaSearch Wikipedia get article summaries get 
data like links and images from a page and more 
. Wikipedia wraps the   MediaWiki APIso you can focus 
on using Wikipedia data not getting it . 下面 我 
说明 在 Ubuntu 下 的 安装 10 gensim 依赖 NumPy 
和 SciPy 这 两 大 Python 科学计算 工具包 一种 简单 
的 安装 方法 是 pip install gensim 的 这个 官方 
安装 页面 很 详细 的 列举 了 兼容 的 Python 
和 NumPy SciPy 的 版本 号 以及 安装 步骤 感 
兴趣 的 同学 可以 直接 参考 下面 我 说明 在 
Ubuntu 下 的 安装 11 Pattern   Github http / 
/ github . com / clips / pattern 此 库 
更像 是 一个 全套 库 因为 它 不仅 提供 了 
一些 机器学习 算法 而且 还 提供 了 工具 来 帮助 
你 收集 和 分析 数据 数据挖掘 部分 可以 帮助 你 
收集 来自 谷歌 推特 和 维基百科 等 网络 服务 的 
数据 它 也 有一个 Web 爬虫 和 HTML DOM 解析器 
引入 这些 工具 的 优点 就是 在 同一 个 程序 
中 收集 和 训练 数据 显得 更加 容易 在 文档 
中 有个 很好 的 例子 使用 一堆 推 文来/nr 训练 
一个 分类器 用来 区分 一个 推 文是/nr win 还是 fail 
1 from pattern . web import Twitter 2 from pattern 
. en import tag 3 from pattern . vector import 
KNN count 4 5 twitter knn = Twitter KNN 6 
7 for i in range 1 3 8 for tweet 
in twitter . search # win OR # fail start 
= i count = 100 9 s = tweet . 
text . lower 10 p = # win in s 
and WIN or FAIL 11 v = tag s 12 
v = word for word pos in v if pos 
= = JJ # JJ = adjective 13 v = 
count v # { sweet 1 } 14 if v 
15 knn . train v type = p 16 17 
print knn . classify sweet potato burger 18 print knn 
. classify stupid autocorrect 首先 使用 twitter . search 通过 
标签 # win 和 # fail 来 收集 推 文 
数据 然后 利用 从推/nr 文中 提取 的 形容词 来 训练 
一个 K 近邻 KNN 模型 经过 足够 的 训练 你 
会 得到 一个 分类器 仅仅 只需 15行 代码 还不错 擅长 
自然语言 处理 NLP 和 分类 12 NLTK Natural Language Toolkit 
参考 Installing NLTKInstalling NLTK D a t a F A 
Q W i k i A P I N L 
T K is a leading platform for building Python programs 
to work with human language data . It provides easy 
to use interfaces to   over 50 corpora and lexical 
resources   such as WordNet along with a suite of 
text processing libraries for classification tokenization stemming tagging parsing and 
semantic reasoning wrappers for industrial strength NLP libraries and an 
active   discussion forum . NLTK has been called a 
wonderful tool for teaching and working in computational linguistics using 
Python and an amazing library to play with natural language 
. 入门 指导 Natural Language Processing with Python   provides 
a practical introduction to programming for language processing . Written 
by the creators of NLTK it guides the reader through 
the fundamentals of writing Python programs working with corpora categorizing 
text analyzing linguistic structure and more . The book is 
being updated for Python 3 and NLTK 3 . The 
original Python 2 version is still available at   http 
/ / nltk . org / book _ 1ed . 
安装 NLTK Install NLTK run   sudo   pip   
install user   U   nltkInstall Numpy optional run   
sudo   pip   install   U   numpyTest installation 
run   python   then type   import   nltkFor 
older versions of Python it might be necessary to install 
setuptools seehttp / / pypi . python . org / 
pypi / setuptools and to install pip sudo   easy 
_ install   pip . 安装 NLTK 语料 因为 标注 
数据 等 功能 需要 调 用 数据 所以 需要 下载 
NLTK 数据包 For central installation on a multi user machine 
do the following from an administrator account . Run the 
Python interpreter and type the commands import nltk nltk . 
download A new window should open showing the NLTK Downloader 
. Click on the File menu and select Change Download 
Directory . For central installation set this to   C 
\ nltk _ data   Windows / usr / local 
/ share / nltk _ data   Mac or   
/ usr / share / nltk _ data   Unix 
. Next select the packages or collections you want to 
download . 输入 nltk . download 就会 弹出 窗口 供 
选择 一般/a 选择/v book/w 可/v 安装/v 所有/b 语料/n 和包等/nr Some 
simple things you can do with NLTK Tokenize and tag 
some text import nltk sentence = At eight o clock 
on Thursday morning . . . Arthur didn t feel 
very good . tokens = nltk . word _ tokenize 
sentence tokens At eight o clock on Thursday morning Arthur 
did n t feel very good . tagged = nltk 
. pos _ tag tokens tagged 0 6 At IN 
eight CD o clock JJ on IN Thursday NNP morning 
NN Identify named entities entities = nltk . chunk . 
ne _ chunk tagged entities Tree S At IN eight 
CD o clock JJ on IN Thursday NNP morning NN 
Tree PERSON Arthur NNP did VBD n t RB feel 
VB very RB good JJ . . Display a parse 
tree from nltk . corpus import treebank t = treebank 
. parsed _ sents wsj _ 0001 . mrg 0 
t . draw NB . If you publish work that 
uses NLTK please cite the NLTK book as follows Bird 
Steven Edward Loper and Ewan Klein 2009   Natural Language 
Processing with Python . O Reilly Media Inc . 