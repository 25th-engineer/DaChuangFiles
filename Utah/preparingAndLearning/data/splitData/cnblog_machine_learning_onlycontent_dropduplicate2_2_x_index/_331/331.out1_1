作者 Spark 链接 https / / www . zhihu . 
com / question / 37069477 / answer / 132387124 来源 
知乎 著作权 归 作者 所有 商业 转载 请 联系 作者 
获得 授权 非商业 转载 请 注明 出处 在 回归 问题 
和 一些 机器学习 算法 中 以及 训练 神经 网络 的 
过程 中 通常 需要 对 原始 数据 进行 中心化 Zero 
centered 或者 Mean subtraction 处理 和 标准化 Standardization 或 Normalization 
处理 目的 通过 中心化 和 标准化 处理 得到 均值 为 
0 标准差 为 1 的 服从 标准 正态分布 的 数据 
计算 过程 由 下式 表示 下面 解释 一下 为什么 需要 
使用 这些 数据 预处理 步骤 在 一些 实际 问题 中 
我们 得到 的 样本 数据 都是/nr 多个 维度 的 即 
一个 样本 是 用 多个 特征 来 表征 的 比如 
在 预测 房价 的 问题 中 影响 房价 的 因素 
有 房子 面积 卧室 数量 等 我们 得到 的 样本 
数据 就是 这样 一些 样本点 这里 的 又 被 称为 
特征 很显然 这些 特征 的 量纲 和数 值得 量级 都是 
不 一样 的 在 预测 房价 时 如果 直接 使用 
原始 的 数据 值 那么 他们 对 房价 的 影响 
程度 将 是 不 一样 的 而 通过 标准化 处理 
可以 使得 不同 的 特征 具有 相同 的 尺度 Scale 
这样 在 使用 梯度 下 降法 学习 参数 的 时候 
不同 特征 对 参数 的 影响 程度 就 一样 了 
简言之 当 原始数据 不同 维 度上 的 特征 的 尺度 
单位 不 一致 时 需要 标准化 步骤 对 数据 进行 
预处理 下 图中 以 二维 数据 为例 左图 表示 的 
是 原始数据 中间 的 是 中心化 后的/nr 数据 数据 被 
移动 大原 点 周围 右图 将 中心化 后的/nr 数据 除以 
标准差 得到 为 标准化 的 数据 可以 看出 每个 维 
度上 的 尺度 是 一致 的 红色 线段 的 长度 
表示 尺度 & amp amp lt img src = https 
/ / pic4 . zhimg . com / v2 d 
2 3 2 d b 4 4 5 4 1 
8 e 9 e d f 4 0 4 7 
6 7 e f 4 4 1 7 8 9 
f _ b . jpg data rawwidth = 1031 data 
rawheight = 355 class = origin _ image zh lightbox 
thumb width = 1031 data original = https / / 
pic4 . zhimg . com / v2 d 2 3 
2 d b 4 4 5 4 1 8 e 
9 e d f 4 0 4 7 6 7 
e f 4 4 1 7 8 9 f _ 
r . jpg & amp amp gt 其实 在 不同 
的 问题 中 中心化 和 标准化 有着 不同 的 意义 
比如 在 训练 神经 网络 的 过程 中 通过 将 
数据 标准化 能够 加速 权重 参数 的 收敛 另外 对于 
主 成分 分析 PCA 问题 也 需要 对 数据 进行 
中心化 和 标准化 等 预处理 步骤 