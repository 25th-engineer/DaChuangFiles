版权 声明 本文 由 LeftNotEasy 发布 于 http / / 
leftnoteasy . cnblogs . com 本文 可以 被 全部 的 
转载 或者 部分 使用 但 请 注明 出处 如果 有 
问题 请 联系 wheeleast @ gmail . com 前言 第二篇 
的 文章 中 谈到 和/c 部门/n 老/a 大一/l 宁/l 出去/v 
outing/w 的/uj 时候/n 他 给了 我 相当多 的 机器 学习 
的 建议 里面 涉及 到 很多 的 算法 的 意义 
学习 方法 等等 一 宁 上次 给 我 提到 如果 
学习 分类 算法 最好 从 线性 的 入手 线性 分类器 
最 简单 的 就是 LDA 它 可以 看做 是 简化 
版 的 SVM 如果 想 理解 SVM 这种 分类器 那/r 
理解/v LDA/w 就是/d 很/zg 有/v 必要/d 的/uj 了/ul 谈到 LDA 
就 不得不 谈谈 PCA PCA 是 一个 和 LDA 非常 
相关 的 算法 从 推导 求解 到 算法 最终 的 
结果 都 有着 相当 的 相似 本次 的 内容 主要 
是 以 推导 数学公式 为主 都 是从 算法 的 物理 
意义 出发 然后 一步 一步 最终 推导 到 最终 的 
式子 LDA/w 和/c PCA/w 最终/d 的/uj 表现/v 都是/i 解/v 一个/m 
矩阵/n 特征值/n 的/uj 问题/n 但是 理解 了 如何 推导 才能 
更 深刻 的 理解 其中 的 含义 本次 内容 要求 
读者 有 一些 基本 的 线性代数 基础 比如说 特征值 特征向量 
的 概念 空间 投影 点乘 等 的 一些 基本 知识 
等 除此之外 的 其他 公式 我 都 尽量 讲得 更简单 
清楚 LDA LDA 的 全称 是 Linear Discriminant Analysis 线性 
判别分析 是 一种 supervised learning 有些 资料 上 也 称为 
是 Fisher s Linear Discriminant 因为 它 被 Ronald Fisher 
发明 自 1936年 Discriminant 这次 词 我 个人 的 理解 
是 一个 模型 不 需要 去 通过 概率 的 方法 
来 训练 预测 数据 比如说 各种 贝叶斯 方法 就 需要 
获取 数据 的 先验 后验/nr 概率 等等 LDA 是 在 
目前 机器学习 数据挖掘 领域 经典 且 热门 的 一个 算法 
据我所知 百度 的 商务 搜索 部 里面 就用 了 不少 
这 方面 的 算法 LDA 的 原理 是 将带 上 
标签 的 数据 点 通过 投影 的 方法 投影 到 
维度 更低 的 空间 中 使得 投 影后 的 点 
会 形成 按 类别 区分 一簇 一簇 的 情况 相同 
类别 的 点 将 会在 投 影后 的 空间 中 
更 接近 要说 明白 LDA 首先 得 弄明白 线性 分类器 
Linear Classifier 因为 LDA 是 一种 线性 分类器 对于 K 
分类 的 一个 分 类 问题 会有 K 个 线性函数 
当 满足条件 对于 所有 的 j 都有 Yk Yj 的 
时候 我们 就 说 x 属于 类别 k 对于 每一个 
分类 都 有一个 公式 去 算 一个 分值 在 所有 
的 公式 得到 的 分值 中 找 一个 最大 的 
就是 所属 的 分类 了 上式 实际上 就是 一种 投影 
是 将 一个 高维 的 点 投影 到 一条 高维 
的 直线 上 LDA 最 求 的 目标 是 给 
出 一个 标注 了 类别 的 数据 集 投影 到 
了 一条 直线 之后 能够使 得点 尽量 的 按 类别 
区分开 当 k = 2 即 二分 类 问题 的 
时候 如下 图 所示 红色 的 方形 的 点 为 
0类 的 原始 点 蓝色 的 方形 点 为 1类 
的 原始 点 经过 原点 的 那条 线 就是 投影 
的 直线 从 图上 可以 清楚 的 看到 红色 的 
点 和 蓝色 的 点 被 原点 明显 的 分开了 
这个 数据 只是 随便 画 的 如果在 高维 的 情况 
下 看 起来 会 更好 一点 下面 我 来 推导 
一下 二 分类 LDA 问题 的 公式 假设 用来 区分 
二 分类 的 直线 投影 函数 为 LDA 分类 的 
一个 目标 是 使得 不同 类别 之间 的 距离 越远 
越好 同一 类别 之中 的 距离 越近/nr 越好 所以 我们 
需要 定义 几个 关键 的 值 类别 i 的 原始 
中心点 为 Di 表示 属于 类别 i 的 点 类别 
i 投 影后 的 中心点 为 衡量 类别 i 投 
影后 类别 点 之间 的 分散 程度 方差 为 最终 
我们 可以 得到 一个 下面 的 公式 表示 LDA 投影 
到 w 后的/nr 损失 函数 我们 分类 的 目标 是 
使得 类别 内 的 点 距离 越近/nr 越好 集中 类别 
间 的 点 越远 越好 分母 表示 每 一个 类别 
内 的 方差 之和 方差 越大 表示 一个 类别 内 
的 点 越 分散 分子 为 两个 类别 各自 的 
中心 点 的 距离 的 平方 我们 最大化 J w 
就 可以 求出 最优 的 w 了 想要 求出 最优 
的 w 可以 使用 拉格朗日 乘子 法 但是 现在 我们 
得到 的 J w 里面 w 是 不能 被 单独 
提 出来 的 我们 就 得想 办法 将 w 单独 
提出来 我们 定义 一个 投影 前 的 各类 别 分散 
程度 的 矩阵 这个 矩阵 看 起来 有 一点 麻烦 
其实 意思 是 如果 某 一个 分类 的 输入 点 
集 Di 里面 的 点 距离 这个 分类 的 中心店 
mi 越近/nr 则 Si 里面 元素 的 值 就 越小 
如果 分类 的 点 都 紧紧 地 围绕 着 mi 
则 Si 里面 的 元素 值 越更/nr 接近 0 . 
带入 Si 将 J w 分母 化为 同样 的 将 
J w 分子 化为 这样 损失 函数 可以 化成 下面 
的 形式 这样 就 可以 用 最 喜欢 的 拉格朗日 
乘子 法了/nr 但是 还有 一个 问题 如果 分子 分母 是 
都 可以 取 任意 值 的 那就 会 使得 有 
无穷 解 我们 将 分母 限制 为 长度 为 1 
这是 用 拉格朗日 乘子 法 一个 很 重要 的 技巧 
在 下面 将 说 的 PCA 里面 也会 用到 如果 
忘记了 请 复习 一下 高数/nr 并 作为 拉格朗日 乘子 法的/nr 
限制 条件 带入 得到 这样 的 式子 就是 一个 求 
特征值 的 问题 了 对于 N N 2 分类 的 
问题 我 就 直接 写出 下面 的 结论 了 这 
同样 是 一个 求 特征值 的 问题 我们 求出 的 
第 i 大 的 特征向量 就是 对应 的 Wi 了 
这里 想 多 谈谈 特征值 特征值 在 纯数学 量子力学 固体力学 
计算机/n 等/u 等/u 领域/n 都有/nr 广泛/a 的/uj 应用/v 特征值 表示 
的 是 矩阵 的 性质 当 我们 取到 矩阵 的 
前 N 个 最大 的 特征值 的 时候 我们 可以 
说 提取 到 的 矩阵 主要 的 成分 这个 和 
之后 的 PCA 相关 但是 不是 完全 一样 的 概念 
在 机器学习 领域 不少 的 地方 都要 用到 特征值 的 
计算 比如说 图像识别 pagerank LDA 还有 之后 将 会 提到 
的 PCA 等等 下图 是 图像 识别 中 广泛 用到 
的 特征 脸 eigen face 提取 出 特征 脸 有 
两个 目的 首先 是 为了 压缩 数据 对于 一张 图片 
只需要 保存 其 最重要 的 部分 就是 了 然后 是 
为了 使得 程序 更容易 处理 在 提取 主要 特征 的 
时候 很多 的 噪声 都被 过滤 掉了 跟 下面 将 
谈到 的 PCA 的 作用 非常 相关 特征值 的 求法 
有 很多 求 一个 D * D 的 矩阵 的 
时间 复杂度 是 O D ^ 3 也 有 一些 
求 Top M 的 方法 比如说 power method 它 的 
时间 复杂度 是 O D ^ 2 * M 总体 
来说 求 特征值 是 一个 很 费 时间 的 操作 
如果 是 单机 环境 下 是 很 局限 的 PCA 
主 成分 分析 PCA 与 LDA 有着 非常 近似 的 
意思 LDA 的 输入 数据 是 带 标签 的 而 
PCA 的 输入 数据 是 不带 标签 的 所以 PCA 
是 一种 unsupervised learning LDA 通常 来说 是 作为 一个 
独立 的 算法 存在 给定 了 训练 数据 后 将会 
得到 一 系列 的 判别函数 discriminate function 之后 对于 新 
的 输入 就 可以 进行 预测 了 而 PCA 更像 
是 一个 预处理 的 方法 它 可以 将 原本 的 
数据 降低 维度 而 使得 降低 了 维度 的 数据 
之间 的 方差 最大 也 可以 说 投影 误差 最小 
具体 在 之后 的 推导 里面 会 谈到 方差 这个东西 
是个 很 有趣 的 有些 时候 我们 会 考虑 减少 
方差 比如说 训练 模型 的 时候 我们 会 考虑 到 
方差 偏差 的 均衡 有的 时候 我们 会 尽量 的 
增大 方差 方差 就像 是 一种 信仰 强哥/nr 的话 不 
一定会 有很/nr 严密 的 证明 从 实践 来说 通过 尽量 
增大 投影 方差 的 PCA 算法 确实 可以 提高 我们 
的 算法 质量 说 了 这么 多 推推 公式 可以 
帮助 我们 理解 我 下面 将 用两 种 思路 来 
推导 出 一个 同样 的 表达式 首先 是 最大 化 
投 影后 的 方差 其次是 最小化 投 影后 的 损失 
投影 产生 的 损失 最小 最大化 方差法 假设 我们 还是 
将 一个 空间 中的 点 投影 到 一个 向量 中去 
首先 给出 原 空间 的 中心点 假设 u1 为 投影 
向量 投影 之后 的 方差 为 上面 这个 式子 如果 
看懂 了 之前 推导 LDA 的 过程 应该 比较 容易 
理解 如果 线性代数 里面 的 内容 忘记了 可以 再 温习 
一下 优化 上式 等号 右边 的 内容 还是 用 拉格朗日 
乘子 法 将 上式 求导 使 之为 0 得到 这 
是 一个 标准 的 特征值 表达式 了 λ 对应 的 
特征 值 u 对应 的 特征 向量 上式 的 左边 
取得 最大值 的 条件 就是 λ 1 最大 也 就是 
取得 最大 的 特征值 的 时候 假设 我们 是 要将 
一个 D 维 的 数据 空间 投影 到 M 维 
的 数据 空间 中 M D 那 我们 取 前 
M 个 特征向量 构成 的 投影 矩阵 就是 能够 使得 
方差 最大 的 矩阵 了 最小化 损 失法 假设 输入 
数据 x 是 在 D 维空间 中的 点 那么 我们 
可以 用 D 个 正交 的 D 维 向量 去 
完全 的 表示 这个 空间 这个 空间 中 所有 的 
向量 都 可以 用 这 D 个 向量 的 线性组合 
得到 在 D 维空间 中 有 无穷 多种 可能 找 
这 D 个 正交 的 D 维 向量 哪个 组合 
是 最 合适 的 呢 假设 我们 已经 找到 了 
这 D 个 向量 可以 得到 我们 可以 用 近似 
法来/nr 表示 投 影后 的 点 上式 表示 得到 的 
新的 x 是由 前 M 个 基 的 线性组合 加上 
后D/nr M 个 基 的 线性组合 注意 这里 的 z 
是 对于 每个 x 都 不同 的 而 b 对于 
每个 x 是 相同 的 这样 我们 就 可以 用 
M 个数 来 表示 空间 中 的 一个 点 也 
就是 使得 数据 降 维 了 但是 这样 降 维 
后的/nr 数据 必然 会 产生 一些 扭曲 我们 用 J 
描述 这种 扭曲 我们 的 目标 是 使得 J 最小 
上式 的 意思 很 直观 就是 对于 每 一个 点 
将 降 维 后的点/nr 与 原始 的 点 之间 的 
距离 的 平方和 加起来 求 平均值 我们 就 要 使得 
这个 平均值 最小 我们 令 将 上面 得到 的 z 
与 b 带入 降 维 的 表达式 将 上式 带入 
J 的 表达式 得到 再 用上 拉普拉斯 乘子 法 此处 
略 可以 得到 取得 我们 想要 的 投影 基 的 
表达式 为 这里 又是 一个 特征值 的 表达式 我们 想要 
的 前 M 个 向量 其实 就是 这里 最大 的 
M 个 特征值 所 对应 的 特征向量 证明 这个 还 
可以 看看 我们 J 可以 化为 也 就是 当 误差 
J 是由 最小 的 D M 个 特征值 组成 的 
时候 J 取得 最小值 跟 上面 的 意思 相同 下图 
是 PCA 的 投影 的 一个 表示 黑色 的 点 
是 原始 的 点 带 箭头 的 虚线 是 投影 
的 向量 Pc1 表示 特征值 最大 的 特征向量 pc2 表示 
特征值 次大 的 特征向量 两者 是 彼此 正交 的 因为 
这 原本 是 一个 2 维 的 空间 所以 最多 
有 两个 投影 的 向量 如果 空间维度 更高 则 投影 
的 向量 会 更多 总结 本次 主要 讲 了 两种 
方法 PCA 与 LDA 两者 的 思想 和 计算 方法 
非常 类似 但是 一个 是 作为 独立 的 算法 存在 
另一个 更多 的 用于 数据 的 预处理 的 工作 另外 
对于 PCA 和 LDA 还有 核 方法 本次 的 篇幅 
比较 大了 先 不说 了 以后 有 时间 再谈 参考资料 
prml bishop introduce to LDA 对不起 这个 真 没有 查到 
出处 