在做 数据 处理 时 需要用 到 不同 的 手法 如 
特征 标准化 主 成分 分析 等等 会 重复 用到 某些 
参数 sklearn 中 提供 了 管道 可以 一次性 的 解决 
该 问题 先 展示 先 通常 的 做法 import pandas 
as pd from sklearn . preprocessing import StandardScaler from sklearn 
. decomposition import PCA from sklearn . linear _ model 
import L o g i s t i c R 
e g r e s s i o n df 
= pd . read _ csv wdbc . csv X 
= df . iloc 2 . values y = df 
. iloc 1 . values # 标准化 sc = StandardScaler 
X _ train _ std = sc . fit _ 
transform X _ train X _ test _ std = 
sc . transform X _ test # 主 成分 分析 
PCA pca = PCA n _ components = 2 X 
_ train _ pca = pca . fit _ transform 
X _ train _ std X _ test _ pca 
= pca . transform X _ test _ std # 
逻辑 斯蒂 回归 预测 lr = L o g i 
s t i c R e g r e s 
s i o n random _ state = 1 lr 
. fit X _ train _ pca y _ train 
y _ pred = lr . predict X _ test 
_ pca 先 对 数据 标准化 然后 做主 成分 分析 
降 维 最后 做 回归 预测 现在 使用 管道 from 
sklearn . pipeline import Pipeline pipe _ lr = Pipeline 
sc StandardScaler pca PCA n _ components = 2 lr 
L o g i s t i c R e 
g r e s s i o n random _ 
state = 1 pipe _ lr . fit X _ 
train y _ train pipe _ lr . score X 
_ test y _ test Pipeline 对象 接收 元组 构成 
的 列表 作为 输入 每个 元组 第一个 值 作为 变量名 
元组 第二 个 元素 是 sklearn 中的 transformer 或 Estimator 
管道 中间 每一步 由 sklearn 中的 transformer 构成 最后 一步 
是 一个 Estimator 我们 的 例子 中 管道 包含 两个 
中间 步骤 一个 StandardScaler 和 一个 PCA 这俩 都是 transformer 
逻辑 斯蒂 回归 分类器 是 Estimator 当 管道 pipe _ 
lr 执行 fit 方法 时 首先 StandardScaler 执行 fit 和 
transform 方法 然后 将 转换 后的/nr 数据 输入 给 PCA 
PCA 同样 执行 fit 和 transform 方法 最后 将 数据 
输入 给 L o g i s t i c 
R e g r e s s i o n 
训练 一个 LR 模型 对于 管道 来说 中间 有 多少 
个 transformer 都可以 工作 方式 如 下 使用 管道 减少 
了 很多 代码 量 现在 回归模型 的 评估 和调参/nr 训练 
机器学习 模型 的 关键 一步 是 要 评估 模型 的 
泛化 能力 如果 我们 训 练好 模型 后 还是 用 
训练 集 取 评估 模型 的 性能 这 显然 是 
不 符合 逻辑 的 一个 模型 如果 性能 不好 要么 
是 因为 模型 过于 复杂 导致 过拟合 高 方差 要么 
是 模型 过于 简单 导致 导致 欠 拟合 高 偏差 
可是 用 什么 方法 评价 模型 的 性能 呢 这 
就是 这 一节 要 解决 的 问题 你 会 学习 
到 两种 交叉 验证 计数 holdout 交叉 验证 和k折/nr 交叉 
验证 来 评估 模型 的 泛化 能力 一 holdout 交叉 
验证 评估 模型 性能 holdout 方法 很 简单 就是 将 
数据集 分为 训练 集 和 测试 集 前者 用于 训练 
后者 用于 评估 如果 在 模型 选择 的 过程 中 
我们 始终 用 测试 集 来 评价 模型 性能 这 
实际上 也 将 测试 集 变相 地 转为 了 训练 
集 这时候 选择 的 最优 模型 很 可能 是 过拟合 
的 更好 的 holdout 方法 是 将 原始 训练 集 
分为 三 部分 训练 集 验证 集 和 测试 集 
训练 机 用于 训练 不同 的 模型 验证 集 用于 
模型 选择 而/c 测试/vn 集/q 由于/c 在/p 训练/vn 模型/n 和/c 
模型/n 选择/v 这/r 两步/m 都/d 没有/v 用到/v 对于 模型 来说 
是 未知 数据 因此 可以 用于 评估 模型 的 泛化 
能力 下图 展示 了 holdout 方法 的 步骤 缺点 它 
对 数据 分割 的 方式 很 敏感 如果 原始 数据集 
分割 不当 这 包括 训练 集 验证 集 和 测试 
集 的 样本 数 比例 以及/c 分割/v 后/f 数据/n 的/uj 
分布/v 情况/n 是否/v 和/c 原始/v 数据集/i 分布/v 情况/n 相同/d 等等/u 
所以 不同 的 分割 方式 可能 得到 不同 的 最优 
模型 参 数二 K 折 交叉 验证 评估 模型 性能 
k 折 交叉 验证 的 过程 第一步 我们 使用 不 
重复抽样 将 原始数据 随机 分为 k 份 第二步 k 1份 
数据 用于 模型 训练 剩下 那 一份 数据 用于 测试 
模型 然后 重复 第二步 k 次 我们 就 得到 了 
k 个 模型 和他的/nr 评估 结果 译者 注 为了 减小 
由于 数据 分割 引入 的 误差 通常 k 折 交叉 
验证 要 随机 使用 不同 的 划分 方法 重复 p 
次 常见 的 有 10次 10 折 交叉 验证 然后 
我们 计算 k 折 交叉 验证 结果 的 平均值 作为 
参数 / 模型 的 性能 评估 使用 k 折 交叉 
验证 来 寻找 最优 参数 要比 holdout 方法 更 稳定 
一旦 我们 找到 最优 参数 要 使用 这组 参数 在 
原始 数据集 上 训练 模型 作为 最终 的 模型 k 
折 交叉 验证 使用 不 重复 采样 优点 是 每个 
样本 只会在 训练 集 或 测试 中 出现 一次 这样 
得到 的 模型 评估 结果 有 更低 的 方法 下图 
演示 了 10 折 交叉 验证 10次 10 折 交叉 
验证 我 的 理解 是 将 按 十种 划分 方法 
每次 将 数据 随机 分成 k 分 k 1份 训练 
k 份 测试 获取 十个 模型 和 评估 结果 然后 
取 10次 的 平均值 作为 性能 评估 from sklearn . 
model _ selection import t r a t i f 
i e d K F o l d p i 
p e _ lr = Pipeline sc StandardScaler pca PCA 
n _ components = 2 lr L o g i 
s t i c R e g r e s 
s i o n random _ state = 1 pipe 
_ lr . fit X _ train y _ train 
kfold = StratifiedKFold y = y _ train n _ 
folds = 10 random _ state = 1 scores = 
for k train test in enumerate kfold pipe _ lr 
. fit X _ train train y _ train train 
score = pipe _ lr . score X _ train 
test y _ train test scores . append scores print 
Fold % s Class dist . % s Acc % 
. 3f % k + 1 np . bincount y 
_ train train score print CV accuracy % . 3f 
+ / % . 3f % np . mean scores 
np . std scores 更 简单 的 方法 from sklearn 
. model _ selection import StratifiedKFold pipe _ lr = 
Pipeline sc StandardScaler pca PCA n _ components = 2 
lr L o g i s t i c R 
e g r e s s i o n random 
_ state = 1 pipe _ lr . fit X 
_ train y _ train scores = cross _ val 
_ score estimator = pipe _ lr X = X 
_ train y = y _ train cv = 10 
n _ jobs = 1 print CV accuracy scores % 
s % scores print CV accuracy % . 3f + 
/ % . 3f % np . mean scores np 
. std scores cv 即 k 三 学习曲线 调试 算法 
from sklearn . model _ selection import learning _ curve 
pipe _ lr = Pipeline scl StandardScaler clf L o 
g i s t i c R e g r 
e s s i o n penalty = l2 random 
_ state = 0 train _ sizes train _ scores 
test _ scores = learning _ curve estimator = pipe 
_ lr X = X _ train y = y 
_ train train _ sizes = np . linspace 0.1 
1.0 10 cv = 10 n _ jobs = 1 
train _ mean = np . mean train _ scores 
axis = 1 train _ std = np . std 
train _ scores axis = 1 test _ mean = 
np . mean test _ scores axis = 1 test 
_ std = np . std test _ scores axis 
= 1 plt . plot train _ sizes train _ 
mean color = blue marker = 0 markersize = 5 
label = training accuracy plt . fill _ between train 
_ sizes train _ mean + train _ std train 
_ mean train _ std alpha = 0.15 color = 
blue plt . plot train _ sizes test _ mean 
color = green linestyle = marker = s markersize = 
5 label = validation accuracy plt . fill _ between 
train _ sizes test _ mean + test _ std 
test _ mean test _ std alpha = 0.15 color 
= green plt . grid plt . xlabel Number of 
training samples plt . ylabel Accuracy plt . legend loc 
= lower right plt . ylim 0.8 1.0 plt . 
show learning _ curve 中的 train _ sizes 参数 控制 
产生 学习曲线 的 训练 样本 的 绝对 / 相对 数量 
此处 我们 设置 的 train _ sizes = np . 
linspace 0.1 1.0 10 将 训练 集 大小 划分为 10个 
相等 的 区间 learning _ curve 默认 使用 分层 k 
折 交叉 验证 计算 交叉 验证 的 准确率 我们 通过 
cv 设置 k 上图 中 可以 看到 模型 在 测试 
集 表现 很好 不过/c 训练/vn 集/q 和/c 测试/vn 集/q 的/uj 
准确率/n 还是/c 有/v 一段/m 小/a 间隔/n 可能 是 模型 有点 
过拟合 四 验证 曲线 解决 过拟合 和欠/nr 拟合 调试 算法 
验证 曲线 和 学习曲线 很 相近 不同 的 是 这里 
画出 的 是 不同 参 数下 模型 的 准确率 而不是 
不同 训练 集 大小 下 的 准确率 from sklearn . 
model _ selection import validation _ curve param _ range 
= 0.001 0.01 0.1 1.0 10.0 100.0 pipe _ lr 
= Pipeline scl StandardScaler clf L o g i s 
t i c R e g r e s s 
i o n penalty = l2 random _ state = 
0 train _ scores test _ scores = validation _ 
curve estimator = pipe _ lr X = X _ 
train y = y _ train param _ name = 
clf _ _ C param _ range = param _ 
range cv = 10 train _ mean = np . 
mean train _ scores axis = 1 train _ std 
= np . std train _ scores axis = 1 
test _ mean = np . mean test _ scores 
axis = 1 test _ std = np . std 
test _ scores axis = 1 plt . plot param 
_ range train _ mean color = blue marker = 
o markersize = 5 label = training accuracy plt . 
fill _ between param _ range train _ mean + 
train _ std train _ mean train _ std alpha 
= 0.15 color = blue plt . plot param _ 
range test _ mean color = green linestyle = marker 
= s markersize = 5 label = validation accuracy plt 
. fill _ between param _ range test _ mean 
+ test _ std test _ mean test _ std 
alpha = 0.15 color = green plt . grid plt 
. xscale log plt . xlabel Parameter C plt . 
ylabel Accuracy plt . legend loc = lower right plt 
. ylim 0.8 1.0 plt . show 我们 得到 了 
参数 C 的 验证 曲线 和 learning _ curve 方法 
很像 validation _ curve 方法 使用 采样 k 折 交叉 
验证 来 评估 模型 的 性能 在 validation _ curve 
内部 我们 设定 了 用来 评估 的 参数 这里 是 
C 也 就是 LR 的 正则 系数 的 倒数 观察 
上图 最好 的 C 值 是 0.1 总之 我们 可以 
使用 学习曲线 判断 算法 是否 拟合 程度 欠 拟合 或者 
过拟合 然后 使用 验证 曲线 评估 参数 获取 最好 的 
参数 机器学习 算法 中有 两类 参数 从 训练 集中 学习 
到 的 参数 比如 逻辑 斯蒂 回归 中的 权重 参数 
另一类 是 模型 的 超 参数 也 就是 需要 人工 
设定 的 参数 比如 正则 项 系数 或者 决策树 的 
深度 权重 参数 可以 通过 验证 曲线 来 获取 最好 
的 参数 而 超 参数 则 可以 使用 网格 搜索 
调 参 五 网格 搜索 调 参 调试 算法 网格 
搜索 其实 就是 暴力 搜索 事先 为 每个 参数 设定 
一组 值 然后 穷举 各种 参数 组合 找到 最好 的 
那组/nr from sklearn . model _ selection import GridSearchCV from 
sklearn . svm import SVC pipe _ svc = Pipeline 
scl StandardScaler clf SVC random _ state = 1 param 
_ range = 0.0001 0.001 0.01 0.1 1.0 10.0 100.0 
1000.0 param _ grid = { clf _ _ C 
param _ range clf _ _ kernel linear } { 
clf _ _ C param _ range clf _ _ 
gamma param _ range clf _ _ kernel rbf } 
gs = GridSearchCV estimator = pipe _ svc param _ 
grid = param _ grid scoring = accuracy cv = 
10 n _ jobs = 1 gs = gs . 
fit X _ train y _ train print gs . 
best _ score _ print gs . best _ params 
_ GridSearchCV 中 param _ grid 参数 是 字典 构成 
的 列表 对于 线性 SVM 我们 只 评估 参数 C 
对于 RBF 核 SVM 我们 评估 C 和 gamma 最后 
我们 通过 best _ parmas _ 得到 最优 参数 组合 
sklearn 人性化 的 一点 是 我们 可以 直接 利用 最优 
参数 建模 best _ estimator _ clf = gs . 
best _ estimator _ clf . fit X _ train 
y _ train print Test accuracy % . 3f % 
clf . score X _ test y _ test 网格 
搜索 虽然 不错 但是 穷举 过于 耗时 sklearn 中 还 
实现 了 随机搜索 使用 R a n d o m 
i z e d e a r c h C 
V 类 随机 采样 出 不同 的 参数 组合 六 
嵌套 交叉 验证 选择 算法 结合 k 折 交叉 验证 
和 网格 搜索 是 调 参 的 好手 段 可是 
如果 我们 想 从 茫茫 算法 中 选择 最 合适 
的 算法 用 什么 方法 呢 这 就是 下面 要 
介绍 的 嵌套 交叉 验证 嵌套 交叉 验证 外层 有一个 
k 折 交叉 验证 将 数据 分为 训练 集 和 
测试 集 还有 一个 内部 交叉 验证 用于 选择 模型 
算法 下图 演示 了 一个 5 折 外层 交叉 沿 
则 和2折/nr 内部 交叉 验证 组成 的 嵌套 交叉 验证 
也 被 称为 5 * 2 交叉 验证 sklearn 中 
如下 使用 嵌套 交叉 验证 svc 的 精确度 gs = 
GridSearchCV estimator = pipe _ svc param _ grid = 
param _ grid scoring = accuracy cv = 10 n 
_ jobs = 1 scores = cross _ val _ 
score gs X y scoring = accuracy cv = 5 
print CV accuracy % . 3f + / % . 
3f % np . mean scores np . std scores 
决策树 分类器 精确度 gs = GridSearchCV estimator = D e 
c i s i o n T r e e 
C l a s s i f i e r 
random _ state = 0 param _ grid = { 
max _ depth 1 2 3 4 5 6 7 
None } scoring = accuracy cv = 5 scores = 
cross _ val _ score gs X _ train y 
_ train scoring = accuracy cv = 5 print CV 
accuracy % . 3f + / % . 3f % 
np . mean scores np . std scores 比较 下 
两者 的 精确度 即可 知道 那种 算法 更加 合适 七 
混淆 矩阵 性能评价 指标 除了 准确率 还有 不少 评价 指标 
如 查准率 查全率 F1 值 等 混淆 矩阵 confusion matrix 
能够 展示 学习 算法 表现 的 矩阵 混淆 矩阵 是 
一个 平方 矩阵 其中 记录 了 一个 分类器 的 TP 
true positive TN true negative FP false positive 和 FN 
false negative from sklearn import metrics metrics . calinski _ 
harabaz _ score input y _ pred python 实现 混淆 
矩阵 其实 就是 一个 2 * 2 的 矩阵 TP 
实际 为真 判断 成功 判断 为真 的 个数 FN 实际 
为真 判断 错误 判断 为 假 FP 实际 为 假 
判断 错误 判断 为真 TN 实际 为 假 判断 成功 
判断 为 假 摘自 https / / www . gitbook 
. com / book / ljalphabeta / python 