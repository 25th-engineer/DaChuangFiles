摘要 本文 对 支持 向量 机 做了 简单 介绍 并对 
线性 可分 支持 向量 分类机 线性 支持 向量 分类机 以及 
核 函数 做了 详细 介绍 最近 一直 在 看 机器学习 
实战 这本书 因为 自己 本身 很想 深入 的 了解 机器学习 
算法 加之 想学 python 就在 朋友 的 推荐 之下 选择 
了 这 本书 进行 学习 今天 学习 支持 向量 机 
Support Vector Machines SVM 这个 无论是 在 模式识别 还是 机器学习 
等 领域 都 赫赫有名 的 工具 支持 向量 机 是 
一项 借助于 最优化 方法 来 解决 机器学习 问题 的 新 
工具 最初 由 V . Vapnik 等人 提出 近几年来/l 其/r 
在/p 理论/n 研究/vn 和/c 算法/n 实现/v 等/u 方面/n 都/d 取得/v 
了/ul 很大/a 的/uj 进展/vn 开始 成为 克服 维数 灾难 和过/nr 
学习 等 困难 的 强有力 的 手段 一   最大 
间隔 分隔 数据 我们 知道 分类 的 目的 是 学会 
一个 分类器 将 数据库 中 的 数据 映 射到 给定 
类别 中 的 某一个 实现 对 未知 数据 类别 的 
预测 对于 二维 数据集 将 数据集 分 隔开 的 直线 
称为 分隔 超平面 如果 分隔 的 是 三维 的 分类 
的 就是 面 如果 是 更 高维 的 就是 超平面 
将 分类 的 决策 边界 统称为 超平面 分布 在 超平面 
一侧 的 所有 数据 都 属于 某个 类别 而 分布 
在 另 一侧 的 所有 数据 都 属于 另 一个 
类别 那么 对于 分类 而言 合理 的 构建 分类器 就 
尤为 重要 了 怎样才能 构造 分类器 使得 分类 结果 更为 
可信 下面 举个 例子 说明 对于 左图 坐标 中 的 
两类 图形 如果 让 你 画 一条线 合理 的 将 
它们 分开 你 会 如何 怎样 划分 这 分法 可就 
多了 到底 哪种 分法 最好 呢 我们 可以 引入 一个 
实际 问题 假设 这 两类 图形 分别 代替 的 是 
两个 居民区 现 要在 两 居民 区 之间 修 一条路 
那么 该 怎么 修 我 想 大多数 人 都会 选择 
那条 红线 吧 这条路 权衡 了 远 和近/nr 也 可以 
理解 为 折中 相对 于 每个 点 而言 都是 最 
公平 的 该 例子 就 可以 看成 是 在 样本 
中 寻找 超平面 将 不同 类别 分开 那么 为了 更好 
的 分类 就要 使得 不同 类别 之间 的 间隔 最大 
间隔 指 的 是 点到 分隔 面的 距离 这样 如果 
分 错 或者 在 有限 数据 上 训练 分类器 的话 
也能 最大 程度 的 保证 分类器 的 健壮 上述 例子 
是 在 二维 平面 中 寻找 超平面 直接 用 肉眼 
就 可以 抉择 然而 如果 是 三维 或者 更 高维 
的 情况 单凭 人类 肉眼 是 无能为力 的 但 机智 
的 我们 是 可以 通过 计算机 来 寻找 啊 通过 
相应 的 数学 知识 建立 对应 的 数学 模型 通过 
计算机 来 求解 这种 寻找 超平面 分类 思想 就是 SVM 
的 思想 下来 我们 学习 支持 向量 机 二 支持 
向量 机 用于 分类 的 SVM 本质上 是 一个 二类 
分类 模型 SVM 属于 监督 学习 目的 是 在给 定 
一个 包含 正 例和 反例 的 样本 集合 中 寻找 
一个 超平面 对 样本 中的 正 例和 反例 进行 分割 
同时 保证 正 例和 反例 之间 的 间隔 最大 这样 
使得 分类 结果 更为 可信 而且 对于 未知 的 新 
样本 才能 有 更好 的 分类 预测 能力 为了 达到 
类别 之间 间隔 最大 我们 不 需要 考虑 所 有点 
只 需要 让 离 分隔 超平面 最近 的 点 距离 
分隔 面的 距离 尽可能 远 即可 想想也是 很有 道理 的 
这里 距离 分隔 超平面 最近 的 那些 点 就是 支持 
向量 下面 来 讲述 一下 SVM 的 原理 首先 需要 
给定 N 个 训练样本 { x1 y1 x2 y2 xn 
yn } 其中 x 是 d 维 向量 表明 了 
每个 样本 具有 d 个 属性 yi 指 的 是 
类别 并且 yi 属于 { 1 1 } 目的 是 
寻找 一个 实值函数 g x 使得 可以 用 分类 函数 
f x = sgn g x 推断 任意 一个 样本 
x 所 对应 的 y 值 1 线性 可分 支持 
向量 机 线性 可分 SVM 就是 用 上述 的 N 
个 样本 去 训练 学习 得到 一个 线性 分类器 也 
就是 得 到 一个 超平面 f x = sgn w 
• x + b 线性 可分 表明 当 w • 
x + b 0时 对应 的 f x = 1 
相应 的 当 w • x + b 0时 对应 
的 f x = 1 而 w • x + 
b   = 0 就是 所 要 寻找 的 超平面 
此时 对应 的 超平面 为 硬 间隔 超平面 接下来 我们 
就 来 寻找 这个 超平面 基于 之前 的 分析 这里 
我们 需要 将 样本 分成 两类 且 保证 分隔 面 
到这 两类 中 最近 的 点 的 距离 尽可能 的 
远 下面 我们 结合 数学 公式 进行 分析 如上 图 
所示 我们 要 寻找 一个 超平面 最大 的 分隔 这两个 
类 保证 这 两个 类别 之间 的 距离 尽可能 大 
问题 可以 转化 为 最大化 这 两个 类别 中 距离 
分隔 面 最近 的 点 支持 向量 之间 的 距离 
首先 在 上图 中找到 两个 和 这个 超平面 平行 且 
距离 相等 的 超平面 w • x + b   
= 1 和w•/nr x + b   = 1 保证 
在 这 两个 超平面 之间 没有 任何 样本点 很容易 想象 
这 两个 超平面 势必 包含 的 是 距离 分隔 超平面 
最近 的 点 那么 问题 就 可 转化 为 最大化 
这两个 超平面 之间 的 距离 进而 结合 相关 的 数学 
知识 因为 超平面 均 二维 则 它们 之间 的 距离 
可表示 为 d = | 1 + 1 | / 
sqrt w12 + w22 = 2 / | | w 
| | 问题 就是 最大化 2 / | | w 
| | 可以 转化 为 最小化 | | w | 
| 最后 结合 两个 超平面 之间 没有 任何 样本点 这个 
约束 则有 对于 任何 一个 正 样本 yi = + 
1 它 都要 处于 w • x + b   
= 1 这个 超平面 的 右边 即要 保证 y = 
  w • x + b = + 1 同理 
对于 任何 一个 负 样本 yi = 1 它 都要 
处于 w • x + b = 1 的 左边 
也 就是 要 保证 y =   w • x 
+ b   = 1 于是/nr 可以 合 并为 yi 
  w • xi + b = 1 于是 寻找 
最优 超平面 的 问题 就 可以 转化 为 二次 规划 
问题 min | | w | | 2/2 s . 
t .   yi   w • xi + b 
= 1     i = 1 2 . . 
. N 该 问题 的 特点 是 目标函数 是 凸函数 
范数 均为 凸函数 并且 约束条件 为 线性 则 可以 引入 
lagrange 函数 进而 根据 wolf 对偶 的 定义 将 原 
问题 的 各 变量 偏 导 置 零 有 进而 
带入 拉格朗日 函数 可将 问题 转化 为 原 问题 的 
拉格朗日 对偶 问题 求解 上述 问题 的 最优 解 计算 
w * 和b*/nr 由 KKT 互补 条件 可得 只有 当 
xi 为 支持 向量 的 时候 对应 的 ai * 
才为 正 否则 皆为 0 选择 a * 的 一个 
正 分量 计算 可得 由此 可以 构造 分类 超平面 w 
* • x + b * = 0 由此 求得 
决策函数 进而 得到 分类 函数 从而 对 未知 类别 进行 
分类 根据 KKT 的 条件 只有 当 xi 为 支持 
向量 的 时候 对应 的 ai * 才为 正 否则 
皆为 0 所以 我们 只需 求得 新来 的 样本 和 
支持 向量 的 内积 然后 运算 即可 2 线性 支持 
向量 分类机 上面 所 分析 的 是 样本点 线性 可分 
的 情况 我们 在 寻找 硬 间隔 超平面 时 首先 
是 找到 了 两个 分类 边界 并 假定 所有 的 
样本点 都在 这两个 分类 边界 以外 但 现实 不 总是 
那么 尽 人意 下面 这种 情况 也 势必 会 遇到 
这幅/r 图/n 里正/i 类/q 和负类/nr 都/d 有点/n 跑到/i 另类 的 
地盘 这时候 就 找 不到 一条 直线 将 它们 分开了 
那要 如何 才能 折中 呢 对于 这种 数据 点 有 
一定 程度 偏离 超平面 的 情况 我们 仍然 能 继续 
使用 超平面 进行 划分 只是 这时 要对 间隔 进行 软化 
构造 软 间隔 超平面 简言之 就是 在 两个 分类 边界 
之间 允许 出现 样本点 这类 样本点 被称为 边界 支持 向量 
这种 向量 机 成为 线性 支持 向量 分类机 如下 图 
所示 上面 提到 需要 对 该 问题 软化 那么 如何 
软化 呢 就是 要 引入 松弛 变量 从而 得到 软化 
之后 针对于 原 问题 的 约束 条件 为 松弛 变量 
的 设置 允许 了 某些 样本点 出现 在 对方 的 
区域 中 当 松弛 变量 充分 大 时 样本点 总是 
满足 上述 的 约束条件 但 也是 要 设法 避免 取值 
太大 为此 我们 可以 重新 调整 目标函数 引入 惩罚 因子 
C 对 离群 点 进行 惩罚 则 二次 规划 问题 
转化 为 其中 C 0 对应 的 拉格朗日 函数 为 
对应 原 问题 的 对偶 问题 为 我们 发现 与 
线性 可分 模型 中 知识 多了 C = a 这个 
约束条件 按照 之前 的 方法 同理 计 算得 分类 函数 
为 其中 C 为 无穷大 时 就 等价 于 线性 
可分 的 情形 3 核 函数 上面 讲述 的 是 
线性 支持 向量 分类机 其中 允许 一定 程度 上 的 
离群 点 那 若是 样本点 真的 是 线型 不可分 呢 
那 就得 采用 核 函数 进行 处理 了 联系 到 
T . M . Cover 的 模式 可分性 定理 一个 
复杂 的 模式 分析 问题 映 射到 高维空间 后 会比 
在 低 维空间 线性 可分 核 方法 就是 通过 非 
线性映射 将 原始数据 通过 特征 映射 嵌入 到 新的 特征 
空间 Hilbert 空间 发现 数据 在 特征 空间 上 的 
线性 模式 进而 选取 相应 的 核 函数 利用 输入 
计算 内积 根据 对偶 解法 可得 算法 所 需要 的 
信息 位于 特征 空间 上 数据 点 之间 的 内积 
维数 过大 时会/nr 影响 算法 的 高效 性 所以 将 
内积 作为 输入 特征 的 直接 函数 更 高效 的 
计算 内积 减少 了 算法 的 时间 复杂度 常用 的 
核 函数 有 基于 上述 分析 对于 线性 不可分的 样本点 
问题 就 转化 为 在 Hilbert 空间 中 寻找 超平面 
相应 的 转化 为 二次 规划 问题 其 中核 函数 
K 满足条件 我们 再次 选用 RBF 核 函数 得到 拉格朗日 
对偶 问题 相应 的 计算 求得 分类 函数 为 接下来 
就 可以 据此 对 线性 不可分 问题 进行 分类 了 
因为 大多数 的 a * 是 0 所以 我们 只 
需要 计算 新 样本 和 少量 的 训练 样本 的 
核 函数 求和 去 符号 就可 完成 新 样本 的 
分类 了 而 采用 不同 的 核 函数 相当于 采用 
不同 的 相似 度 对 样本 进行 分类 至此 关于 
支持 向量 机 的 相关 知识 大致 就 学习 完了 
之后 的 一些 细节 也 将 继续 学习 