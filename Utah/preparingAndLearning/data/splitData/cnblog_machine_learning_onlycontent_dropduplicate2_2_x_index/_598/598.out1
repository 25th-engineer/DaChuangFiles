本文 机器学习 库 使用 的 部分 代码 来源于 spark1 . 
0.0 官方 文档 mllib 是 spark 对 机器学习 算法 和 
应用 的 实现 库 包括 分类 回归 聚 类 协同 
过滤 降 维 等 本文 的 主要 内容 为 如何 
使用 scala 语言 创建 sbt 工程 实现 机器学习 算法 并 
进行 本地 和 集群 的 运行 初学者 建议 先在 RDD 
交互式 模式 下 按 行 输入 代码 以 熟悉 scala 
架构 若想 了解 SBT 等 相关 信息 可 参见 这里 
1 . SVM linear support vector machine 新建 SimpleSVM 目录 
在 SimpleSVM 目 录下 创建 如下 的 目录 结构 simple 
. sbt 文件 内容 如下 name = SimpleSVM Project version 
= 1.0 scalaVersion = 2 . 10.4 l i b 
r a r y D e p e n d 
e n c i e s + = org . 
apache . spark % % spark core % 1 . 
0.0 l i b r a r y D e 
p e n d e n c i e s 
+ = org . apache . spark % % spark 
mllib % 1 . 0.0 resolvers + = Akka Repository 
at http / / repo . akka . io / 
releases / PS 由于 该 应用 需要 调用 mllib 因此 
要 特别 注意 在 l i b r a r 
y D e p e n d e n c 
i e s 加入 spark mllib 否则 会 编译 不 
通过 的 哦 SimpleApp . scala 文件 内容 如下 import 
org . apache . spark . SparkContext import org . 
apache . spark . mllib . classification . SVMWithSGD import 
org . apache . spark . mllib . evaluation . 
B i n a r y C l a s 
s i f i c a t i o n 
M e t r i c s import org . 
apache . spark . mllib . regression . LabeledPoint import 
org . apache . spark . mllib . linalg . 
Vectors import org . apache . spark . mllib . 
util . MLUtils import org . apache . spark . 
SparkContext . _ import org . apache . spark . 
SparkConf object SimpleApp { def main args Array String { 
val conf = new SparkConf . setAppName SimpleSVM Application val 
sc = new SparkContext conf val data = MLUtils . 
loadLibSVMFile sc mllib / test50 . txt val splits = 
data . randomSplit Array 0.6 0.4 seed = 11L val 
training = splits 0 . cache val test = splits 
1 val numIterations = 100 val model = SVMWithSGD . 
train training numIterations model . clearThreshold val scoreAndLabels = test 
. map { point = val score = model . 
predict point . features score point . label } val 
metrics = new B i n a r y C 
l a s s i f i c a t 
i o n M e t r i c s 
scoreAndLabels val auROC = metrics . areaUnderROC println Area under 
ROC = + auROC } } PS 由于 我们 之前 
在 spark 配置 过程 中将 hadoop 路径 配置 好了 因此 
这里 的 输入 路径 mllib / test50 . txt 实际 
上为 HDFS 文件系统 中的 文件 存储 位置 与 hadoop 配置文件 
core site . xml 中的 name 相关 具体 可 参见 
这里 这个 地方 很 容易 出错 因此 需要 先将 test50 
. txt 文件 put 到 hdfs 上面 另外 test50 . 
txt 文件 为 libsvm 文件 的 输入 格式 实例 如下 
编译 cd ~ / SimpleSVMsbt package       # 
打包 过程 时间 可能 会 比较 长 最后 会 出现 
success XXXPS 成功 后会/nr 生成 许多 文件   target / 
scala 2.10 / simplesvm project _ 2.10 1.0 . jar 
等 本地 运行 spark submit class SimpleApp master local target 
/ scala 2.10 / simplesvm project _ 2.10 1.0 . 
jar 集群 运行 spark submit class SimpleApp master spark / 
/ master 7077 target / scala 2.10 / simplesvm project 
_ 2.10 1.0 . jar 结果 PS 若 希望 在 
算法 中 添加 正则 项 因子 可将 SimpleApp . scala 
文件 修改 如下 import org . apache . spark . 
mllib . optimization . L1Updater val svmAlg = new SVMWithSGD 
svmAlg . optimizer . setNumIterations 200 . setRegParam 0.1 . 
setUpdater new L1Updater val modelL1 = svmAlg . run training 
2 . 逻辑 回归 Logistic Regression 同理 若要 实现 逻辑 
回归 算法 则 只需 将 SimpleApp . scala 文件 中的 
SVMWithSGD 替换 为   L o g i s t 
i c R e g r e s s i 
o n W i t h G D 3 . 
协同 过滤 Collaborative filtering 文件系统 如上 所示 协同 过滤 算法 
可以 将 只需 将 SimpleApp . scala 文件 进行 如下 
修改 import org . apache . spark . mllib . 
recommendation . ALS import org . apache . spark . 
mllib . recommendation . Rating import org . apache . 
spark . mllib . linalg . Vectors import org . 
apache . spark . SparkContext import org . apache . 
spark . SparkContext . _ import org . apache . 
spark . SparkConf object SimpleApp { def main args Array 
String { val conf = new SparkConf . setAppName SimpleCF 
Application val sc = new SparkContext conf val data = 
sc . textFile mllib / test . data val ratings 
= data . map _ . split match { case 
Array user item rate = Rating user . toInt item 
. toInt rate . toDouble } val rank = 10 
val numIterations = 5 val model = ALS . train 
ratings rank numIterations 0.01 val usersProducts = ratings . map 
{ case Rating user product rate = user product } 
val predictions = model . predict usersProducts . map { 
case Rating user product rate = user product rate } 
val ratesAndPreds = ratings . map { case Rating user 
product rate = user product rate } . join predictions 
val MSE = ratesAndPreds . map { case user product 
r1 r2 = val err = r1 r2 err * 
err } . mean println Mean Squared Error = + 
MSE } } PS 同理 mllib / test . data 
存储 于 HDFS 文件系统 为 示例 数据 本地 运行 spark 
submit class SimpleApp master local target / scala 2.10 / 
simplecf project _ 2.10 1.0 . jar 集群 运行 spark 
submit class SimpleApp master spark / / master 7077 target 
/ scala 2.10 / simplecf project _ 2.10 1.0 . 
jar 结果 PS 可以 加入 alpha 参数 控制 val alpha 
= 0.01 val model = ALS . trainImplicit ratings rank 
numIterations alpha 同理 聚 类 算法 降 维 方法 代码 
可 参见 这里 本文 为 原创 博客 若 转载 请 
注明 出处 