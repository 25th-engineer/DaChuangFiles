摘要 本文 简单 叙述 了 如何 用 聚 类 来 
通过 投票 记录 分析 美国 参议员 的 实际 政治 倾向 
声明 本文 的 内容 非 原创 但 经过 本人 翻译 
和 总结 而来 转载 请 注明 出处 本文 内容 来源 
https / / www . dataquest . io / mission 
/ 60 / clustering basics/w 在/p 前面/f 的/uj 两篇/m 文章/n 
中/f 使用/v 的/uj 线性/n 回归/v 和/c 分类/n 都/d 属于/v 有/v 
监督/vn 的/uj 机器学习/i 根据 已有 的 数据 训练 模型 然后 
预测 未知 的 数据 而无 监督 的 学习 则 不是 
尝试 预测 任何东西 而是 寻找 数据 中 的 特征 在 
无 监督 学习 中 有 一个 重要 的 方法 称为 
聚 类 聚 类 算法 是 把 具有 相同 特征 
的 数据 聚集 在 一组 原始数据 展现 在 美国 的 
参议院 要 通过 一项 法律 时 需要 由 参议员 来 
投票 而 这些 议员 主要 来自 于 两个 政党 共和党 
Democrats 和 民主党 Republicans 现在 使用 的 数据 就是 这些 
议员 的 投票 记录 每 一行 代表 了 一个 议员 
的 情况 party – 所属 政党 D 代表 共和党 R 
代表 民主党 I 代表 无党派 第三列 之后 都 代表 了 
某 一个 法案 的 投票 情况 1 代表 赞成 0 
代表 反对 0.5 代表 弃权 import pandas votes = pandas 
. read _ csv 114 _ congress . csv 统计 
一下 每个 政党 的 人数 print votes party . value 
_ counts 聚 类 算法 计算 距离 为了 把 具有 
相同 特征 的 议员 聚集 在 一组 就 需要 衡量 
两个 议员 的 特征 究竟 有 多么 的 接近 在 
这里 使用 的 是 欧几里德 距离 计算公式 譬如 取 前 
两个 议员 的 记录 来 进行 计算 这 是 他们 
的 投票 结果 计算结果 d = 1.73 在 python 中 
计算 欧几里德 距离 可以 通过 scikit learn 库 的 euclidean 
_ distances 方法 现在 仍然 计算 前 两个 议员 的 
距离 from sklearn . metrics . pairwise import euclidean _ 
distances print euclidean _ distances votes . iloc 0 3 
votes . iloc 1 3 # 因为 前 三列 不是 
数字 类型 所以 要 排除 前 三列 的 数据 聚 
类 接下来 会 使用 k means 聚 类 算法 来 
根据 欧几里德 距离 来 将 数据 进行 分组 聚集 每 
一组 都会 有一个 中心点 然后 计算 每个 议员 到 这个 
中心点 的 距离 再 将该 议员 分配 到 距离 最小 
的 那个 中心点 所属 的 组 中 下面 使用 scikit 
learn 库 来 训练 一个 k means 模型 因 为 
主要 有 两个 政党 所以 分为 两组 即可 import pandas 
as pd from sklearn . cluster import KMeans # n 
_ clusters 参数 指定 分组 数量 random _ state = 
1 用来 重现 同样 的 结果 kmeans _ model = 
KMeans n _ clusters = 2 random _ state = 
1 # 通过 fit _ transform 方法 来 训练 模型 
senator _ distances = kmeans _ model . fit _ 
transform votes . iloc 3 生成 的 是 一个 ndarray 
每 一行 代表 了 一个 议员 第一列 代表 了 该 
议员 与 第一 组 中心点 的 距离 第二列 代表 了 
该 议员 与 第二 组 中心点 的 距离 统计 经过 
上面 的 计算 现在 要 统计 在 每 一组 中 
究竟 分布 着 多少 个 来自 于 不同 政党 的 
议员 类似于 透视图 使用 Pandas 中的 crosstab 方法 可以 进行 
统计 该 方法 需要 两个 向量 或者 Series 作为 参数 
来 进行 统计 labels = kmeans _ model . labels 
_ print pd . crosstab labels votes party 上面 语句 
中的 labels 变量 的 结果 如下 在 ndarray 中的 每个 
元素 代表 了 一个 议员 所属 的 组 编号 其 
编号 取其 距离 最小 的 那组/nr 上面 的 结果 显示 
第一组 包含 了 41个 民主党 议员 和 两个 无党派 议员 
第二组 包含 了 3个 民主党 议员 和 54个 共和党 议员 
看 起来 有 3个 民主党 议员 的 政治 倾向 更 
偏于 共和党 而这 三位 仁兄 就是 democratic _ outliers = 
votes labels = = 1 & votes party = = 
D 数据 可视化 在 上面 的 计算 中 已经 把 
每位 议员 到 两个 组 的 举例 计算 出来 了 
现在 将 这 两个 距离 数据 分别 作为 x 和y/nr 
坐标 然后 做 一个 散点图 并且 根据 它们 的 组编 
号 进行 不同 着色 plt . scatter x = senator 
_ distances 0 y = senator _ distances 1 c 
= labels plt . show 寻找 激进分子 可以 根据 上面 
计算 的 每个 议员 与 组 的 距离 来 判断 
一个 议员 是否 属于 激进分子 最 激进 的 议员 就是 
那些 远离 一个组 中心点 最远 的 数据 点 而 处于 
两个 中心点 的 数 据点 则 表明 这 是 比较 
温和 的 议员 要 衡量 这个 激进 程度 可以 通过 
对 两个 距离 计算 结果 进行 指数 运算 来 放大 
差异性 例如 对于 某个 激进 议员 extremist = 3.4 . 
24 和 温和 议员 moderate = 2.6 2 如果 只是 
简单 相加 其 结果 就会 得到 3.4 + . 24 
= 3.64 和 2.6 + 2 = 4.6 看 起来 
他们 之间 的 差距 并 不大 然而 将 它们 分别 
进行 立方 运算 再 相加 3.4 * * 3 + 
. 24 * * 3 = 39.3 和 2.6 * 
* 3 + 2 * * 3 = 25.5 就能 
体现 他们 之间 的 差异性 了 extremism = senator _ 
distances * * 3 . sum axis = 1 votes 
extremism = extremism votes . sort extremism inplace = True 
ascending = False # 根据 激进 性 进行 降序 排序 
总结 聚 类 是 一个 用来 寻找 数据 特征 的 
强有力 的 方法 在 使用 有 监督 的 机器 学习 
方法 并 没有 取得 进展 时 可以 尝试 使用 无 
监督 的 学习 方法 通常 来说 在 使用 有 监督 
学习 方法 之前 先 使用 无 监督 学习 方法 是 
一个 不错 的 开始 