前言 Alpha Go 在 16年 以 4 1 的 战绩 
打败 了 李世石 17年 又以 3 0 的 战绩 战胜 
了 中国 围棋 天才 柯洁 这 真是 科技界 振奋人心 的 
进步 伴随 着 媒体 的 大量 宣传 此事 变成 了 
妇孺皆知 的 大事件 大家 又 开始 激烈 的 讨论 机器 
人 什么 时候 会 取代 人类 统治 世界 的 问题 
其实 人工智能 在 上世纪 5 60 年代 就 开始 进入 
了 理论 研究 阶段 人们 在 不断 探索 人工智能 技术 
的 同时 也 担忧 起 机器人 会不会 替代 人类 然而 
现实 比 理想 残酷 的 多 由于 当时 各种 条件 
的 限制 理论 基础 技术 基础 数据 基础 硬件 性能 
等 人工智能 相关 的 项目 进度 缓慢 也 缺少 实际 
成效 研发 资金 社会 关注度 也 越来越 低 人工智能 进入 
第一 次 低谷期 到了 80 年代 卡内基 梅隆 大学 为 
数字 设备 公司 设计 了 一套 名为 XCON 的 专家系统 
这 是 一种 采用 人工智能 程序 的 系统 可以 简单 
的 理解 为 知识库 + 推理机 的 组合 XCON 是 
一套 具有 完整 专业 知识 和 经验 的 计算机 智能系统 
人工智能 再一次 被 各国 政府 和 科研 机构 看好 大量 
的 资金 投入 到 研发 中 但是 好景不长 几年/m 后/f 
随着/p 苹果/n 和/c IBM/w 公司/n 研发/l 出/v 了/ul 性能/n 强劲/a 
的/uj PC/w 机/n 导致 专家系统 变得 没有 竞争力 人工智能 发展 
又一次 进入 寒冬 随后 若干年 人工智能 的 发展 趋于平稳 和 
低调 时间 来到 21 世纪 随着 互联网 的 普及 大量 
数据 被 积累 下来 摩尔定律 一次 又一次 的 被 证实 
计算机硬件 性 能以 极快 的 速度 在 增长 云 的 
普及 让 普通 大众 也 能 轻松 拥有 调度 大量 
算 力 的 机会 人工智能 不再 是 科学家 和 专业 
人员 在 实验室 才能 研究 的 东西 了 数据 + 
算 力 + 易得 这 几 方面 的 因素 结合 
之后 将 人工智能 再一次 推向 了 高潮 可能 这一 波 
热潮 又是 人工智能 发展 史上 的 一个 波峰 未来 人工智能 
还有 很长 的 路 要走 但 目前 的 人工智能 发展 
已经 惠及 到 商业 领域 在 这样 一种 技术 + 
商业 的 结合 中 我 个人 还是 很 看好 这 
次 浪潮 的 尤其 是 在 看过 最强 大脑 中 
百度 在 图像 音频 方面 的 人工智能 技术 发展 到 
这样 一个 水平 之后 图像识别 已经 超 超越 了 人类 
大脑 对 图像 的 识别 能力 声音 识别 也 几乎 
和 人类 最高 水平 持平 很 希望 自己 也 可以 
有 机会 涉足 到 这个 领域 中 机器学习 基础 入门 
知识 机器学习 是 人工智能 的 一个 分支 主要 是 通过 
数据 + 算法 来 训练 得出 模型 再用 模型 来 
预测 数据 的 一种 技术 刚 开始 接触 机器学习 发现 
基础理论 中 好多 都是 大学 里 学过 的 数理 知识 
一直以来 困扰 我 的 大学 为什么 要 学 这些东西 的 
谜团 总算 被 解开 了 我 个人 做了 Web 开发 
近 十载 大 部分 是 应用级 的 很少 涉及 数理 
算法 看来 今后 还要 慢慢 拾起 这些 知识 不过 刚 
开始 入门 可以 循序渐进 先 弄懂 机器学习 是 怎么 回事 
动手 做 一个 Hello world 然后 再 逐步 深入 原理 
层面 的 知识 要 涉足 机器学习 最好会 一种 编程语言 这点 
上 我们 程序员 有 先天 优势 目前 用于 机器 学习 
的 主流 语言 是 Python 和R/nr R 我 个人 还没 
研究 过 个人 觉得 Python 是 一个 比 较好 的 
选择 流 行度 高 上手 难度 低 科学计算 类库 丰富 
语法 精简 如果 本身 就 有 其他 面向对象 的 编程语言 
基础 不到 一周 就 可以 基本 掌握 Python 了 机器学习 
从 从业 分布 来看 可以 分成 基础 算法 研究 设计师 
和应/nr ban 用 zhuan 两个 领域 其中 大 部分 人 
都是 在 应 ban 用 zhuan 这个 领域 如果 从 
技术 层面 来看 机器学习 分成 监督 学习 无 监督 学习 
以及 半 监督 学习 如何 来 区分 呢 首先 解释 
下 机器学习 中的 几个 名词 特性 Features 其实 就是 数据 
分类器 Classifier 其实 就是 算法 标签 Labels 其实 就是 种类 
模型 Models 其实 就是 最终 输出 的 分类 公式 监督 
学习 就是 在 有 标签 的 前提 下 找到 一种 
最 合适 的 分类器 分析 特性 和 标签 之间 的 
关系 无 监督 学习 就是 没有 标签 的 前提 下 
将 数据 进行 聚 类 Clusting 半 监督 学习 就是 
部分 特性 有 标签 部分 则 没有 的 状况 大部分 
特性 可能 是 没有 标签 的 情况 下 进行 分类 
监督 学习 相对 来说 最 简单 由 已知 特性 和 
标签 利用 合适 的 分类器 训 练出 模型 再以 模型 
套 用到 数据 中 来 预测 出 数据 的 标签 
当然 分类器 并不 需要 我们 自己 来 发明创造 我们 大 
部分 人 也没 这个 能力 做 这些 事情 所有 的 
理论 研究 科学论证 代码 实现 都是/nr 现成 的 Python 中 
有 很多 相关 类库 比如 scikit learn 应用 层面 的 
机器学习 其实 就是 通过 不停 的 调 参 收集 更多 
的 数据 变换 算法 选取 合适 的 特征 数据 等 
工作 来 找到 一种 更 精准 的 预测 模型 的 
工作 Hello World In Machine Learning 假设 我们 现在 需要 
区分 皮球 以 直径 15cm 25cm 之间 的 球 为例 
和 甜瓜 的 图片 如果 是 传统 的 硬 编码 
的 方式 来 写 代码 的话 可能 需要 写 几百 
上 千个 if else 才能 完成 一个 基本 的 算法 
而且 可扩展性 特别 差 比如 如果 图片 是 黑白 的 
或者 图 片中 有 干扰 物品 那 可能 需要 修改 
源代码 添加 更多 的 if else 来 增加 准确度 更糟 
的 是 真正 执行 的 时候 会 遇到 很多 事先 
没有 预料 到 的 特殊 情况 但 如果 通过 机器学习 
这个 事情 可能 就 会 变得 很 简单 大致 步骤 
如下 将 图片 转换成 特征向量 这个 进阶 知识 不在 本篇 
中 涉及 决定 一种 合适 当前 场景 的 分类器 结合 
1中 得到 的 特征 和 2中 得到 的 分类器 训 
练出 模型 用 模型 中 的 公式 预测 数据 估算 
出 其 属于 某个 标签 的 可能性 最大 可能性 的 
那个 即 模型 推算出 的 结果 数据 准备 转换 过程 
略 假设 共 N 条 数据 转换 得到 的 特性 
如下 直径 厘米 形状 颜色 标签 2 4 r o 
u n d w h i t e m e 
l o n 3 5 e l l i p 
s e w h i t e m e l 
o n 2 4 r o u n d o 
r a n g e b a l l 2 
4 e l l i p s e y e 
l l o w m e l o n 2 
2 r o u n d y e l l 
o w b a l l . . . . 
. . . . . . . . 实现 代码 
features = 24 round white 35 ellipse white 24 round 
orange 24 ellipse yellow 22 round yellow . . . 
labels = melon melon ball melon ball 我们 知道 计算机 
处理 基础 数据 类型 的 速度 由 快 及 慢 
为 bool int float string . . . 因此 我们 
在 处理 数据 的 过程 中 需要/v 把/p 原始/v 数据抽象/l 
成/n 计算机/n 能/v 最快/d 处理/v 的/uj 数据/n 类型/n 因为 机器学习 
运算量 极大 因此 上面 的 代码 经过 转换 之后 # 
round 1 ellipse 2 # white 1 orange 2 yellow 
3 features = 24 1 1 35 2 1 24 
1 2 24 2 3 22 1 3 # melon 
1 ball 2 labels = 1 1 2 1 2 
这里 顺便 提 一下 大部分 机器学习 中 都 是以 GPU 
的 性能 来 衡量 处理 速度 的 而 不是 我们 
一般 使用 的 CPU 这 是因为 GPU 的 物理 架构 
和 CPU 不 一样 GPU 是 专门 为了 处理 图像 
而 设计 的 它 对 浮点数 的 处理 速度 是 
CPU 的 数十 倍 乃至 数百倍 而 机器学习 基本上 可以 
看做 是 对 浮点数 的 大量 运算 因此 GPU 更 
适合 在 机器学习 领域 被 使用 算法 选取 机器学习 中 
解决 一个 问题 的 算法 并 不是 唯一 的 同 
一个 问题 可以 适用 不同 的 算法 来 解决 一般 
都会 在 效率 和 准确率 之间 做 权衡 本例 中 
我们 使用 决策树 Deccision Tree 作为 Classifier 关于 决策树 可 
参考 https / / baike . baidu . com / 
item / % E 5% 86% B 3% E 7% 
AD % 96% E 6% A 0% 91 实现 代码 
from sklearn import tree . . . # 实例 化 
classifier clf = tree . D e c i s 
i o n T r e e C l a 
s s i f i e r 训练 模型 scikit 
learn 的 classifier 中 通过 方法 fit features labels 来 
训练 模型 其 返回值 即 我们 所需 的 模型 实现 
代码 . . . clf = tree . fit features 
labels . . . 预测 数据 有了 模型 我们 就 
可以 对 今后 的 数据 进行 预测 以 得出 label 
值 从而 达到 对其 归类 的 目的 实现 代码 . 
. . # 假设 现在 有 一个 数据 23 round 
white 我们 想 知道 他 应该 数据 什么 类型 先 
将其 转换 为 23 1 1 然后 调用 模型 的 
predict 方法 print clf . predict 23 1 1 . 
. . 得到 的 结果 为 # 代表 机器学习 测算 
得出 结果 是 melon 1 完整 代码 from sklearn import 
tree # round 1 ellipse 2 # white 1 orange 
2 yellow 3 features = 24 1 1 35 2 
1 24 1 2 24 2 3 22 1 3 
# melon 1 ball 2 labels = 1 1 2 
1 2 # 实例 化 classifier clf = tree . 
D e c i s i o n T r 
e e C l a s s i f i 
e r # 训练 clf = clf . fit features 
labels print clf . predict 23 1 1 后记 上例 
中 如果 通过 真正 的 人工智能 肉眼 来看 23 round 
white 被 推算 为 melon 的 准确度 其实 并不 高 
因为 23 round white 归类 为 ball 也 完全 是 
可以 的 上文 提到 过 机器学习 其实 就是 不停 的 
寻找 合适 的 数据 和 算法 以 提升 准确率 的 
过程 想要 提升 准确率 我们 可以 有 以下 思路 加大 
训练 样本量 训练样本 必须 和 训练 效率 做好 权衡 另外 
最好 避免 重复 的 特性 浪费 算 力 比如 有了/nr 
直径 这 列 就 不 需要 半径 周长 这样 的 
特性 了 这 三者 代表 的 是 一个 意思 变换 
算法 可以 选用 更 高级 的 算法 或者 多个 算法 
组合 但 必须 在 准确度 和 效率 之间 做好 权衡 
抽象 出 更多 的 特性 数据 比如 本例 中 如果 
有 办法 抽象 出 质量 这样 的 特性 那 对于 
预测 准确率 会有 极大 的 提升 至此 为止 我们 机器 
学习 的 Hello World 程序 已经 完成 了 也 基本 
了解 了 机器 学习 是 怎么 回事 是不是 还 挺 
有意思 的 本文 在 我 的 博客园 和我的/nr 个人 博客 
上 同步 发布 作者 保留版权 转载 请 注明 来源 