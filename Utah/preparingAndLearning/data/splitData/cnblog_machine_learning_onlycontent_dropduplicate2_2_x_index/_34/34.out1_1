1 .   Alternating Least SquareALS Alternating Least Square 交替 
最小二乘 法 在 机器 学习 中 特指 使用 最 小二 
乘法 的 一种 协同 推荐算法 如下 图 所示 u 表示 
用户 v 表示 商品 用户 给 商品 打分 但是 并 
不是 每 一个 用户 都 会给 每一种 商品 打分 比如 
用户 u6 就 没有 给 商品 v3 打分 需要 我们 
推断 出来 这 就是 机器 学习 的 任务 由于 并 
不是 每个 用户 给 每种 商品 都 打了 分 可以 
假设 ALS 矩阵 是 低 秩 的 即 一个 m 
* n 的 矩阵 是由 m * k 和k*/nr n 
两个 矩阵 相乘 得到 的 其中 k m n Am 
× n = Um × k × Vk × n 
这种 假设 是 合理 的 因为/c 用户/n 和/c 商品/n 都/d 
包含/v 了/ul 一些/m 低/a 维度/ns 的/uj 隐藏/v 特征/n 比如 我们 
只要 知道 某个 人 喜欢 碳酸饮料 就 可以 推断 出 
他 喜欢 百世 可乐 可口可乐 芬达 而 不 需要 明确 
指出 他 喜欢 这三种 饮料 这里 的 碳酸饮料 就 相当于 
一个 隐藏 特征 上面 的 公式 中 Um × k 
表示 用户 对 隐藏 特征 的 偏好 Vk × n 
表示 产品 包含 隐藏 特征 的 程度 机器 学习 的 
任务 就是 求出 Um × k 和 Vk × n 
可知 uiTvj 是 用户 i 对 商品 j 的 偏好 
使用 Frobenius 范数 来 量化 重构 U 和V/nr 产生 的 
误差 由于 矩阵 中 很多 地方 都是/nr 空白 的 即 
用户 没有 对 商品 打分 对于 这种 情况 我们 就 
不用 计算 未知 元了/nr 只 计算 观察到 的 用户 商品 
集合 R 这样 就 将 协同 推荐 问题 转换成 了 
一个 优化 问题 目标函数 中 U 和V/nr 相互 耦合 这 
就 需要 使用 交替 二 乘 算法 即 先 假设 
U 的 初始值 U 0 这样 就 将 问题 转化成 
了 一个 最小二乘 问题 可以 根据 U 0 可以 计算出 
V 0 再 根据 V 0 计算出 U 1 这样 
迭代 下去 直到 迭代 了 一定 的 次数 或者 收敛 
为止 虽然 不能 保证 收敛 的 全局 最优 解 但是 
影响 不大 2 . MLlib 的 ALS 实现 MLlib 的 
ALS 采用 了 数据 分区 结构 即将 U 分解成 u1 
u2 u3 . . . um V 分解成 v1 v2 
v3 . . . vn 相关 的 u 和v/nr 存放 
在 同一个 分区 从而 减少 分 区间 数据 交换 的 
成本 比如 通过 U 计算 V 时 存储 u 的 
分区 是 P1 P2 . . . 存储 v 的 
分区 是 Q1 Q2 . . . 需要 将 不同 
的 u 发送 给 不同 的 Q 存放 这个 关系 
的 块 称作 OutBlock 在 P 中 计算 v 时 
需要 哪些 u 存放 这个 关系 的 块 称作 InBlock 
比如 R 中有 a12 a13 a15 u1 存放在 P1 v2 
v3 存放在 Q2 v5 存放在 Q3 则 需要 将 P1 
中的 u1 发送给 Q2 和 Q3 这个 信息 存储 在 
OutBlock R 中有 a12 a32 因此 计算 v2 需要 u1 
和 u3 这个 信息 存储 在 InBlock 直接 上 代码 
import org . apache . log4j . { Level Logger 
} import org . apache . spark . { SparkConf 
SparkContext } import org . apache . spark . mllib 
. recommendation . ALS import org . apache . spark 
. mllib . recommendation . Rating / * * * 
Created by Administrator on 2017 / 7/19 . * / 
object ALSTest01 { def main args Array String = { 
/ / 设置 运行 环境 val conf = new SparkConf 
. setAppName ALS 01 . setMaster spark / / master 
7077 . setJars Seq E \ \ Intellij \ \ 
Projects \ \ MachineLearning \ \ MachineLearning . jar val 
sc = new SparkContext conf Logger . getRootLogger . setLevel 
Level . WARN / / 读取 样本数据 并 解析 val 
dataRDD = sc . textFile hdfs / / master 9000 
/ ml / data / test . data val ratingRDD 
= dataRDD . map _ . split match { case 
Array user item rate = Rating user . toInt item 
. toInt rate . toDouble } / / 拆分/v 成/n 
训练/vn 集/q 和/c 测试/vn 集/q val dataParts = ratingRDD . 
randomSplit Array 0.8 0.2 val trainingRDD = dataParts 0 val 
testRDD = dataParts 1 / / 建立 ALS 交替 最小二乘 
算法 模型 并 训练 val rank = 10 val numIterations 
= 10 val alsModel = ALS . train trainingRDD rank 
numIterations 0.01 / / 预测 val user _ product = 
trainingRDD . map { case Rating user product rate = 
user product } val predictions = alsModel . predict user 
_ product . map { case Rating user product rate 
= user product rate } val r a t e 
s A n d P r e d i c 
t i o n s = trainingRDD . map { 
case Rating user product rate = user product rate } 
. join predictions val MSE = r a t e 
s A n d P r e d i c 
t i o n s . map { case user 
product r1 r2 = val err = r1 r2 err 
* err } . mean println Mean Squared Error = 
+ MSE println User + \ t + Products + 
\ t + Rate + \ t + Prediction r 
a t e s A n d P r e 
d i c t i o n s . collect 
. foreach rating = { println rating . _ 1 
. _ 1 + \ t + rating . _ 
1 . _ 2 + \ t + rating . 
_ 2 . _ 1 + \ t + rating 
. _ 2 . _ 2 } } } 其中 
ALS . train 函数 的 4个 参数 分别 是 训练 
用 的 数据 集 特征 数量 迭代 次数 和 正则 
因子 运行 结果 可见 预测 结果 还是 非常 准确 的 
