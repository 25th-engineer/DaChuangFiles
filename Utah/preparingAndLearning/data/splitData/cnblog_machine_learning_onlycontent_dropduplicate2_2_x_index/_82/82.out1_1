C 4.5 算法 C 4.5 算法 的 核心 思想 是 
ID3 算法 是 ID3 算法 的 改进 用 信息 增益 
率 来 选择 属性 克服 了 用 信息 增益 来 
选择 属性 时 变相 选择 取值 多 的 属性 的 
不足 在 树 的 构造 过程 中 进行 剪枝 能 
处理 非 离散化 数据 能 处理 不 完整 数据 优点 
产生 的 分类 规则 易于 理解 准确率 高 缺点 在 
构造 过程 中 需要 对 数据 集 进行 多次 的 
顺序 扫描 和 排序 因而 导致 算法 的 低效 C 
4.5 算法 只 适合 于 能够 驻留 内存 的 数据 
集 当 训练 集 大得 无法 在 内存 容纳 时 
程序 无法 运行 K means 算法 简单 的 聚 类 
吧 n 个 对象 根据 他们 的 属性 分为 k 
个 类 k n 算法 的 核心 是 要 优化 
失真 函数 J 使其 收敛 到 局部 最小值 而不是 全局 
最小值 \ J = \ sum _ { n = 
1 } ^ { N } \ sum _ { 
k = 1 } ^ { K } r _ 
{ nk } | | x _ n u _ 
k | | ^ 2 \ \ r _ { 
nk } \ 表示 n 数据 第 k 个 类 
\ u _ k \ 是 第 k 个 类 
中心 值 然后 求出 最优 的 \ u _ k 
\ \ u _ k = \ frac { \ 
sum r _ { nk } x _ n } 
{ \ sum _ { n } r _ { 
nk } } \ 优点 算法 速度快 缺点 分组 的 
数目 k 是 一个 输入 参数 不 适合 的 k 
可能 返回 较差 的 结果 朴素 贝叶斯 算法 朴素 贝叶斯 
法是/nr 基于 贝叶 斯定理 与 特征 条件 独立 假设 的 
分类 方法 算法 的 基础 是 概率 问题 分类 原理 
是 通过 某 对象 的 先验概率 利用 贝叶斯 公式 计算 
出 其后 验 概率 即 该 对象 属于 某一 类 
的 概率 选择 具有 最大 后验/nr 概率 的 类 作为 
该 对象 所属 的 类 朴素 贝叶斯 假设 是 约束性 
很强 的 假设 假设 特征 条件 独立 但 朴素 贝叶斯 
算法 简单 快速 具有 较小 的 出错率 在 朴素 贝叶斯 
的 应用 中 主要 研究 了 电子 邮件 过滤 以及 
文本 分类 研究 K 最 近邻 算法 缺点 K 值 
需要 预先 设定 而不能 自适 应当 样本 不 平衡 时 
如 一个 类 的 样本容量 很大 二 其他 类 样本容量 
很小 有 可能 导致 当 输入 一个 新 样本 时 
该 样本 的 K 个 邻居 中 大容量 类 的 
样本 占多数 该 算法 适用于 对 样本 容量 比 较大 
的 类 域 进行 自动 分类 EM 最大 期望 算法 
EM 算法 是 基于 模型 的 聚 类 算法 是 
在 概率模型 中 寻找 参数 最大 思 然 估计 的 
算法 其中 概率模型 依赖于 无法 观测 的 隐藏 变量 E 
步 估计 隐含 变量 M 步 估计 其他 参数 交替 
将 极值 推向 最大 EM 算法 比 K means 算法 
计算 复杂 收敛 较慢 不适合 大 规模 数据集 和 高维 
数据 但 比 K means 算法 计算 结构 稳定 准确 
EM 算法 经常 用 在 机器 学习 和 计算机 视觉 
的 数据 集聚 data clustering 领域 PageRank 算法 Google 的 
页面 排序算法 基于 从 许多 优质 的 网页 链接 过来 
的 网页 必定 还是 优质 网页 的 回归 关系 来 
判定 所有 网页 的 重要性 一个人 有 越多 牛逼 的 
朋友 他 牛逼 的 概率 就 越大 优点 完全 独立 
于 查询 只 依赖于 网页 链接 结构 可以 离线 计算 
缺点 PageRank 算法 忽略 了 网页 搜索 的 时效性 旧 
网页 排序 很高 存在 时间 长 积累 了 大量 的 
in links 拥有 最新 资讯 的 网页 排名 却 很低 
因为 它们 几乎 没有 in links AdaBoostAdaboost 是 一种 迭代 
算法 其 核心 思想 是 针对 同 一个 训练 集 
训练 不同 的 分类器 弱 分类器 然后 把 这些 弱 
分类器 集合起来 构成 一个 更强 的 最终 分类器 强 分类器 
算法 本事 该 百诺 数据分布 来 实现 的 它 根据 
每 次 训练 集中 每一个 样本 的 分类 是否 正确 
以及 上 一次 的 总体 分类 准确率 来 确定 没 
个 样本 的 权值 将 修改 过 权值 的 新 
数据集 送给 下层 分类器 进行 训练 最后 将 每次 训练 
得到 的 分类器 最后 融合 起来 作为 最后 的 决策 
分类器 算法 流程 先 通过 对 N 个 训练样本 的 
学习 得到 第一个 弱 分类器 将 分 错 的 样本 
和 其他 的 新 数据 一起 构成 一个 新的 N 
个 训练样本 通过学习 得到 第二 个 弱 分类器 讲 前面 
都分错/nr 的 样本 加上 新 的 样本 构成 另 一个 
新的 N 个 训练样本 集 通过 学习 得 到 第三 
个 弱 分类器 如此 反复 最终 得到 经过 提升 的 
强 分类器 目前 AdaBoost 算法 广泛 的 应用 于 人脸 
检测 目标 识别 等 领域 Apriori 算法 Apriori 算法 是 
一种 挖掘 关联 规则 的 算法 用于 挖掘 其 内涵 
的 未知 的 却又 实际 存在 的 数据 关系 其 
核心 是 基于 两 阶段 频 集 思想 的 递推 
算法 Apriori 算法 的 两个 阶段 寻找 频繁 项集/nr 有/v 
频繁/a 项集找/nr 关联/ns 规则/n 算法 缺点 在 每一步 产生 侯选 
项目 集 时 循环 产生 的 组合 过多 没有 排除 
不 应该 参与 组合 的 元素 每次 计算 项集的/nr 支持 
度 时 都对 数据库 中 的 全部 记录 进行 了 
一遍 扫描 比较 需要 很大 的 I / O 负载 
SVM 支持 向量 机 支持 向量 机 是 一种 基于 
分类 边界 的 方法 基本原理 如果 训练 数据分布 在 二维 
平 面上 的 点 它们 按照 其 分类 聚集 在 
不同 的 区域 基于 分类 边界 的 分类 算法 的 
目标 是 通过训练 找到 这些 分类 之间 的 边界 对于 
多维 数据 N 维 可以 将 他们 视为 N 维空间 
中的 点 而 分类 边界 就是 N 维空间 中的 面 
称为 超 面 线性 分类器 使用 超平面 类型 的 边界 
非线性 分类器 使用 超曲面 支持 向量 机 的 原理 是 
将 低维 空间 的 点映 射到 高维空间 使 它们 成为 
线性 可分 再使用 线性 划分 的 原理 来 判断 分类 
边界 在 高维空间 中 是 一种 线性 划分 而在 原有 
的 数据 空间 中 是 一种 非线性 划分 CART 树 
决策树 的 分类 方法 基于 最小 距离 的 基尼指数 估计 
函数 用来 决定 由该 子 数据集 生成 的 决策树 的 
拓展 形 如果 目标 变量 是 标称 的 称为 分类 
树 如果 目标 变量 是 连续 的 称为 回归 树 
优点 非常灵活 可以允许 有 部分 错分 成本 还可 指定 先验 
概率分布 可 使用 自动 的 成本 复杂性 剪枝 来 得到 
归纳 性 更强 的 树 面对 存在 缺失 值 变量 
数多 等 问题 时 CART 数 显得 非常 稳健 