决策树 学习 从 今天 开始 坚持 每天 学习 一个 机器 
学习 的 新知识 加油 决策树 学习 是 应用 最广 的 
归纳推理 算法 之一 是 一种 逼近 离散 值 目标函数 的 
方法 在 这种 方法 中 学习 到 的 函数 被 
表示 为 一颗 决策树 决策树 表示法 决策树 通过 把 实例 
从根/nr 结点 排列 到 某个 叶子 结点 来 分类 实例 
叶子 结点 即为 实例 所属 的 分类 树上 的 每一个 
结点 指定 了 对 实例 的 某个 属性 的 测试 
并且 该 结点 的 每一个 后继 分支 对应 于该/nr 属性 
的 一个 可能 值 分类 实例 的 方法 是 从这 
棵树 的 根 节点 开始 册数 这个 结点 指定 的 
属性 然后 按照 给定 实例 的 该 属性 对应 的 
树枝 向下 移动 然后 这个 过程 再以 新 结点 为 
根 的 子树 上 重复 上图 画出 了 一颗 典型 
的 学习 到 的 决策树 这颗 决策树 根据 天气 情况 
分类 星期六 上午 是否 适合 打网球 貌似 很多 机器学习 和 
数据 挖掘 的 书籍 提到 这个 决策树 的 时候 都是 
说 的 这个 例子 汗 不过 呢 我们 还 可以 
根据 这颗 决策树 写出 对应 的 表达式 决策树 学习 的 
适用 问题 实例 是由 属性 值 对 pair 表示 的 
目标 函数 具有 离散 的 输出 值 可能 需要 析取 
的 描述 训练 数据 可以 包含 错误 训练 数据 可以 
包含 缺少 属性值 的 实例 决策树 学习 的 应用 列举 
根据 疾病 分类 患者 根据 起因 分类 设备 故障 根据 
拖欠 支付 的 可能性 分类 贷款 申请 决策树 学习 的 
算法 ID3 基本 的 ID3 算法 通过 自顶向下 构造 决策树 
来 进行 学习 构造 过程 是从 哪一个 属性 将从 树 
的 根 结点 被 测试 这个 问题 开始 的 我们 
使用 统计 测试 来 确定 每 一个 实例 属性 单独 
分类 训练 样例 的 能力 分类 能力 最好 的 属性 
即 信息 增益 最大 的 属性 被 选作 树 的 
根 结点 的 测试 然后 为 根 结点 属性 的 
每个 可能 值 产生 一个 分支 并把 训练 样例 排列 
到 适当 的 分支 之下 然后 重复 整个 过程 用 
每个 分支 结点 关联 的 训练 样例 来 选取 在 
该点 被 测试 的 最佳 属性 这 形成 了 对 
合格 决策树 的 贪婪 搜索 也 就是 算法 从不 回溯 
重新考虑 以前 的 选择 熵 表示 了 任意 样例 集 
的 纯度 假定 为 训练 集 的 目标 属性 C 
有m个/nr 可能 的 类 标号 值 C = { C1 
C2 C3 Cm } 每个 类 标号 值 相应 的 
概率 为 p1 p2 p3 pm 那么 训练 集 的 
信息 熵 定义 为 Entropy S = Entropy p1 p2 
pm = p1 * log2 p1 + p2 * log2 
p2 + pm * log2 pm 信息 增益 一个 属性 
的 信息 增益 就是 由于 使用 这个 属性 分割 样例 
而 导致 的 期望 熵 降低 假设 训练 集为 并用 
属性 A 来 划分 那么 属性 A 的 信息 增益 
Gain S A 为 训练 集 的 熵 减去 按 
属性 A 划分 后的/nr 子集 的 熵 即 Gain S 
A = Entropy S Entropy _ A S Entropy _ 
A S = abs Si / abs S Entropy Si 
Si 表示 描述 属性 A 的 离散 值 的 集合 
abs Si 表示 属性 A 当前 这个 值 的 个数 
ID3 算法 的 优势 和 不足 它 是 关于 现有 
属性 的 有限 离散 值 函数 的 一个 完整 空间 
但是 当 遍历 决策树 空 间时 ID3 仅 维护 单一 
的 当前 假设 这样 就 失去 了 表示 所有 一致 
假设 带来 的 优势 而且 ID3 算法 在 搜索 中 
不 进行 回溯 每 当在 树 的 某一 层次 选择 
了 一个 属性 进行 测试 它 不会 再 回溯 重新 
考虑 这个 选择 所以 它 易受 无 回溯 的 爬山 
搜索 中 的 常见 风险 影响 收敛 到 局部 最优 
的 答案 而 不是 全局 最优 的 决策树 学习 的 
归纳 偏置 如果 给 定 一个 训练 样例 的 集合 
那么 通常 有 很多 决策树 与 这些 样例 一致 所以 
要 描述 ID3 算法 的 归纳 偏置 应该 找到 它 
从 所有 一致 的 假设 中 选择 一个 的 根据 
ID3 从 这些 决策树 中会 选择 哪 一个 呢 它 
会 选择 在 使用 简答 到 复杂 的 爬山 算法 
遍历 可能 的 树 空间 时 遇到 的 第一 个 
可 接受 的 树 总结 的 说 ID3 归纳 偏置 
的 搜索 策 略为 较短 的 树 比 较长 的 
树 优先 那些 信息 增 益高 的 属性 更 靠近 
根 结点 的 树 优先 为什么 短 的 假设 优先 
假设 物理学家 优先选择 行星 运动 简单 的 解释 而 不用 
复杂 的 解释 为什么 一种 解释 是 短 假设 的 
数量 少于 长 假设 的 数量 所以 找 到 一个 
短 的 但 同时 与 训练 数据 拟合 的 假设 
的 可能性 较小 相反 常常 有 很多 非常 复杂 的 
假设 拟合 当前 的 训练 数据 但却 无法 正确 地 
泛化 到 后来 的 数据 比如 考虑 决策树 假设 500个 
结点 的 决策树 比 5个 结点 的 决策树 多得多 如果 
给 定 一个 20个 训练 样例 的 集合 可以 预期 
能够 找到 很多 500个 结点 的 决策树 与 训练 数据 
一致 而 如果 一个 5个 结点 的 决策树 也 可以 
完美 的 拟合 这些 数据 当然 是 出乎意料 的 所以 
我们 会 相信 5个 结点 的 树 不太 可能 是 
统计 巧合 因而 优先选择 这个 5个 结点 的 决策树 的 
假设 而不 选择 500个 结点 的 处理 决策树 学习 的 
常见问题 避免 过度 拟合 数据 对于 一个 假设 当 存在 
其他 的 假设 对 训练 数据 样例 的 拟合 比 
它 差 但 事实上 在 实例 的 整个 分布 中 
表现 得 却更 好时 我们 说 这个 假设 过度 拟合 
避免 决策树 学习 中 的 过度 拟合 的 方法 被 
分为 两类 及早 停止 树 增长 在 ID3 算法 完美 
分类 训练 数据 之前 就 停止 树 增长 后修/nr 剪法 
即 允许 树 过度 拟合 数据 然后 对 这个 树 
进行 后 修剪 在 实践 中 证实 第二 种 方法 
后 修剪 更加 成功 的 实施 准则 1 使用 与 
训练 样例 截然不同 的 一套 分离 的 样例 来/v 评估/vn 
通过/p 后/f 修剪/v 方法/n 从/p 树上/s 修剪/v 结点/n 的/uj 效用/n 
2 使用 所有 可用 数据 进行 训练 但是 进行 统计 
测试 来 估计 扩展 或 修剪 一个 特定 的 结点 
是否 有可能 改善 在 训练 集合 外 的 实例 上 
的 性能 3 使用 一个 明确 的 标准 来 衡量 
训练 样 例和 决策树 的 复杂度 当 这个 编码 的 
长度 最 小时 停止 树 增长 合并 连续 值 的 
属性 我们 最初 的 ID3 定义 被 限制 为 取 
离散 值 的 属性 所以 我们 可以 先把 连续 值 
属性 的 值域 分割为 离散 的 区间 集合 例如 对于 
连续 值 的 属性 A 算法 可以 动态 的 创建 
一个 新的 布尔 属性 Ac 如果 A c 那么 Ac 
为真 否 则为 假 这样 就把 连续 值 的 属性 
的 值 离散 化了 属性 选择 的 其他 度量 标准 
有 一些 极端 的 例子 里 采取 信息 增益 来 
作为 选择 树 的 结点 的 优先 性 有时 这 
棵树 虽然 可以 理想 的 分类 训练 数据 但是 对于 
实例 的 数据 的 性能 非常 差 不是 一个 很好 
的 预测器 所以 我们 选择 了 新的 度量 标准 增益 
比率 增益 比率 的 计算 方法 先 略过 这个 我 
在 后面 的 总结 里 会 详细 的 讲解 到 
处理 缺少 属性值 的 训练 样例 赋 给 属性 A 
决策 结点 n 的 训练 样例 中 该 属性 的 
最 常见 值 为 属性 A 的 每个 可能 值 
赋予 一个 概率 处理 不同 代价 的 属性 在 某些 
学习 任务 中 实例 的 属性 可能 与 代价 相关 
例如 在 学习 分类 疾病 时 我们 可能 以 这些 
属性 来 描述 患者 体温 活 组织 切片检查 脉搏 血液 
化验 结果 等 这些 属性 在 代价 方面 差别 非常大 
对于 这样 的 任务 我们 将 优先选择 尽可能 使用 低 
代价 属性 的 决策树 通过 引入 一个 代价 项到属/nr 性选择 
度量 中 我们 可以 用 信息 增益 除以 属性 的 
代价 这样 我们 就 可以 使 低 代价 的 属性 
会被 优先选择 仅/d 当/t 需要/v 产生/n 可靠/v 的/uj 分类/n 时/n 
我们/r 才/d 依赖/v 高/a 代价/n 属性/n 