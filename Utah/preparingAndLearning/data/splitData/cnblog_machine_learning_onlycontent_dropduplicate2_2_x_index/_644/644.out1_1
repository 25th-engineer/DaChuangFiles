机器学习 定义 1959年 Arthur Samuel 曾经 这样 定义 机器学习 Field 
of study that gives computers the ability to learn without 
being explicitly programmed . Samuel 本人 也 写 了 一个 
西洋棋 的 程序 通过 让 这个 程序 练习 下 西洋棋 
一万次 使得 这个 西洋棋 程序 的 棋艺 比 自己 还要 
高超 1998年 Tom Mitchell 对 机器学习 给出 了 一个 更加 
正式 的 定义 A computer program is said to learn 
from experience E with respect to some task T and 
some performance measure P if its performance on T as 
measured by P improves with experience E . 这个 定义 
比较 专业 甚至 还 有点 押韵 课程内容 监督 学习 supervised 
learning 监督 学习 就是 给 出 一组 特征 也 给出 
特征 所 对应 的 结果 以此 来 推测 另外 的 
特征 所 对应 的 结果 比如说 给出 某一 地区 房子 
的 面积 大小 卧室 数量 以及 它们 所 对应 的 
价格 以此 来 预测 给定 面积 大小 卧室 数量 的 
另外 一些 房子 的 价格 学习理论 learning theory 介绍 一些 
theory 无 监督 学习 unsupervised learning 无 监督 学习 就是 
给 出 一些 特征 但是 不 给出 这些 特征 所 
对应 的 结果 以此 来 判断 这些 特征 之间 有什们/nr 
结构 关系 聚 类 问题 就是 无 监督 学习 的 
一个 例子 强化 学习 reinforcement learning 强化 学习 就是 不断 
做出 决策 比如 无人 驾驶 飞机 只有 不断 做 一些 
良好 的 决策 这个 飞机 才能 持续 飞行 监督 学习 
定义 几个 符号 m 样本 数量 # training examples x 
输入 值 又成 为特征 input variables / features y 输出 
值 又叫 目标值 output variables / target variables x y 
训练样本 training examples 第 i 个 训练样本 ith training examples 
x i y i 监督 学习 思路 为了 设计 学习 
算法 我们 第一 步 要做 的 决定 就是 怎样 表示 
h 即 预测 函数 倘若 给定 某一 地区 房间 的 
大小 以及 对应 的 价格 那么 这 只有 一个 特征 
我们 就 可以 令 若将 theta 看成 向量 那么 也 
可以 写成 如果 给 出 两个 特征 那么 可以 将 
预测 函数 写成 假设 X0 = 1 那么 预测 函数 
就 可以 写成 当 特征 有n个/nr 时 依次 类推 实际上 
我们 希望 自己 的 预测 值 与 实际 值 之间 
的 差距 要 小 一些 即 尽 量小 即 目标 
是 前面 乘以 1/2 是 为了 之后 数学 计算 的 
方便性 定义 函数 J 我们 的 目标 就是 求出 参数 
theta 使得 J 取值 最小 寻找 theta 的 算法 搜寻 
算法 search algorithm 应为 一类 算法 统称 算法 思想 1 
. 先给 定 一个 特定 的 theta 例如 可以 让 
theta 取 零 向量 2 . 改变 theta 的 值 
让 J 变小 不断 重复 以 求得 最小 J 梯度 
下降 gradient descent 算法 思想 给定 某一 特定 的 theta 
值 然后 重复 此 操作 其中 = 是 赋值 操作 
alpha 称作 学习 速度 若 只有 一个 样本点 那么 此时 
可以 将 theta 的 更新 操作 更 改为 同理可证 若有 
m 个 训练样本 则 更新 操作 应该 为 以上 的 
梯度 下降 算法 称作 批 梯度 下降 算法 batch gradient 
descent 这种 算法 要 遍历 整个 样本 若 样本 很大 
则 可以 使 用 随机 梯度 下降 算法 也称 增量 
梯度 下降 算法 stochastic gradient descent also incremental gradient descent 
此 算法 的 基本 思想 为 循环 { for j 
= 1 to m { for all i } } 
这个 算法 的 好处 就是 不用 每次 都要 遍历 所有 
的 样本 为了 开始 学习 仅仅 需要 查看 第一 个 
样本 但是 这个 算法 不会 精确 的 收敛 到 全局 
的 最小值 正规 方程组 normal equation 定义 一下 矩阵 求导 
求过 导 后的/nr 矩阵 是 一个 n + 1 维 
向量 此时 梯度 下降 算法 的 更新 可以 写成 矩阵 
求导 的 进一步 说明 如果 A 是 n * n 
的 矩阵 那么 tr A 即 A 的 迹 就 
等于 A 矩阵 对角线 元素 之和 trAB = trBAtrABC = 
trCAB = trBCAtra = a a 为 实数 定义 几个 
矩阵 对 上述 另 上述 J 的 梯度 等于 0 
经过 推到 就会 得出 正规 方程组 得出 