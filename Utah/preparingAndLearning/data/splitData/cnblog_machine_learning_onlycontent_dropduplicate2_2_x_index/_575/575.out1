最近 在看 机器学习 实战 这本书 因为 自己 本身 很想 深入 
的 了解 机器学习 算法 加之 想学 python 就在 朋友 的 
推荐 之下 选择 了 这 本书 进行 学习 一 . 
K 近邻 算法 KNN 概述 最简单 最 初级 的 分类器 
是 将 全部 的 训练 数据 所 对应 的 类别 
都 记录 下来 当 测试 对象 的 属性 和 某个 
训练 对象 的 属性 完全 匹配 时 便 可以 对 
其 进行 分类 但是 怎么 可能 所有 测试 对象 都会/nr 
找到 与之 完全 匹配 的 训练 对象 呢 其次 就是 
存在 一个 测试 对象 同时 与 多个 训练 对象 匹配 
导致 一个 训练 对 象被 分到 了 多个 类 的 
问题 基于 这些 问题 呢 就 产生 了 KNN KNN 
是 通过 测量 不同 特征值 之间 的 距离 进行 分类 
它 的 思路 是 如果 一个 样本 在 特征 空间 
中的 k 个 最 相似 即 特征 空间 中最 邻近 
的 样本 中 的 大多数 属于 某 一个 类别 则 
该 样本 也 属于 这个 类别 其中 K 通常 是 
不大 于 20 的 整数 KNN 算法 中 所 选择 
的 邻居 都是/nr 已经 正确 分类 的 对象 该 方法 
在 定 类 决策 上 只 依据 最 邻近 的 
一个 或者 几个 样本 的 类别 来 决定 待 分 
样本 所属 的 类别 下面 通过 一个 简单 的 例子 
说明 一下 如 下图 绿色 圆 要被 决定 赋予 哪个 
类 是 红色 三角形 还是 蓝色 四方形 如果 K = 
3 由于 红色 三角形 所占 比例 为 2/3 绿色 圆 
将被 赋予 红色 三角形 那个 类 如果 K = 5 
由于 蓝色 四方形 比例 为 3/5 因此 绿色 圆 被 
赋予 蓝色 四方形 类 由此 也 说明了 KNN 算法 的 
结果 很大 程度 取决于 K 的 选择 在 KNN 中 
通过 计算 对象 间 距离 来 作为 各个 对象 之间 
的 非 相似性 指标 避免 了 对象 之间 的 匹配 
问题 在 这里 距离 一般 使用 欧氏距离 或 曼哈顿 距离 
同时 KNN 通过 依据 k 个 对象 中 占优 的 
类别 进行 决策 而 不是 单一 的 对象 类别 决策 
这两点 就是 KNN 算法 的 优势 接下来 对 KNN 算法 
的 思想 总结 一下 就是 在 训练 集中 数据 和 
标签 已知 的 情况 下 输入 测试数据 将 测试 数据 
的 特征 与 训练 集中 对应 的 特征 进行 相互 
比较 找到 训练 集中 与之 最为 相似 的 前 K 
个 数据 则 该 测试数据 对应 的 类别 就是 K 
个 数据 中 出现 次数 最多 的 那个 分类 其 
算法 的 描述 为 1 计算 测试数据 与 各个 训练 
数据 之间 的 距离 2 按照 距离 的 递增 关系 
进行 排序 3 选取 距离 最小 的 K 个 点 
4 确定 前 K 个 点 所在 类别 的 出现 
频率 5 返回 前 K 个 点中 出现 频率 最高 
的 类别 作为 测试数据 的 预测 分类 二 . python 
实现 首先 呢 需要 说明 的 是 我 用 的 
是 python3 . 4.3 里面 有 一些 用法 与 2.7 
还是 有些 出入 建立 一个 KNN . py 文件 对 
算法 的 可行性 进行 验证 如下 # coding utf 8 
from numpy import * import operator # # 给出 训练 
数据 以及 对应 的 类别 def createDataSet group = array 
1.0 2.0 1.2 0.1 0.1 1.4 0.3 3.5 labels = 
A A B B return group labels # # # 
通过 KNN 进行 分类 def classify input dataSe t label 
k dataSize = dataSet . shape 0 # # # 
# 计算 欧式 距离 diff = tile input dataSize 1 
dataSet sqdiff = diff * * 2 squareDist = sum 
sqdiff axis = 1 # # # 行向量 分别 相加 
从而 得到 新 的 一个 行向量 dist = squareDist * 
* 0.5 # # 对 距离 进行 排序 sortedDistIndex = 
argsort dist # # argsort 根据 元素 的 值 从大到/nr 
小 对 元素 进行 排序 返回 下标 classCount = { 
} for i in range k voteLabel = label sortedDistIndex 
i # # # 对 选取 的 K 个 样本 
所属 的 类别 个数 进行 统计 classCount voteLabel = classCount 
. get voteLabel 0 + 1 # # # 选取 
出现 的 类别 次数 最多 的 类别 maxCount = 0 
for key value in classCount . items if value maxCount 
maxCount = value classes = key return classes 接下来 在 
命令行 窗口 输入 如下 代码 # * coding utf 8 
* import sys sys . path . append . . 
. 文件 路径 . . . import KNN from numpy 
import * dataSet labels = KNN . createDataSet input = 
array 1.1 0.3 K = 3 output = KNN . 
classify input dataSet labels K print 测试数据 为 input 分类 
结果 为 output 回车 之后 的 结果 为 测试数据 为 
1.1   0.3 分类 为 A 答案 符合 我们 的 
预期 要 证明 算法 的 准确性 势必 还 需要 通过 
处理 复杂 问题 进行 验证 之后 另行 说明 这是 第一次 
用 python 编 的 一个 小 程序 势必 会 遇到 
各种 问题 在 此次 编程 调试 过程 中 遇到 了 
如下 问题 1 导入 . py 文件 路径 有 问题 
因此 需要 在 最开始 加 如下 代码 import syssys . 
path . append 文件 路径 这样 就 不会 存在 路径 
有误 的 问题 了 2 在 python 提示 代码 存在 
问题 时 一定 要 及时 改正 改正 之后 保存 之后 
再 执行 命令行 这 一点 跟 MATLAB 是 不 一样 
的 所以在 python 中 最好 是 敲 代码 的 同时 
在 命令 行中 一段 一段 的 验证 3   在 
调用 文件 时函/nr 数名 一定 要 写 正确 否则 会 
出现 module object has no attribute creatDataSet 4   int 
object has no attribute kclassify 这个 问题 出现 的 原因 
是 之前 我 讲 文件 保存 名为 k . py 
在 执行 output = K . classify input dataSet labels 
K 这 一句 就 会 出错 根据 函 数式 编程 
的 思想 每个 函数 都 可以 看 为 是 一个 
变量 而将 K 赋值 后 调用 k . py 时就会/nr 
出现 问题 三 MATLAB 实现 之前 一直 在 用 MATLAB 
做 聚 类 算法 的 一些 优化 其次 就是 数模 
的 一些 常用 算法 对于 别的 算法 还 真是 没有 
上手 编过 基础 还在 思想 还在 当然 要 动手 编 
一下 也是 不 希望 在 学 python 的 同时 对 
MATLAB 逐渐 陌生 吧 走走停停 停 很 重要 首先 建立 
KNN . m 文件 如下 % % KNN clear all 
clc % % data trainData = 1.0 2.0 1.2 0.1 
0.1 1.4 0.3 3.5 trainClass = 1 1 2 2 
testData = 0.5 2.3 k = 3 % % distance 
row = size trainData 1 col = size trainData 2 
test = repmat testData row 1 dis = zeros 1 
row for i = 1 row diff = 0 for 
j = 1 col diff = diff + test i 
j trainData i j . ^ 2 end dis 1 
i = diff . ^ 0.5 end % % sort 
jointDis = dis trainClass sortDis = sortrows jointDis sortDisClass = 
sortDis % % find class = sort 2 1 k 
member = unique class num = size member max = 
0 for i = 1 num count = find class 
= = member i if count max max = count 
label = member i end end disp 最终 的 分类 
结果 为 fprintf % d \ n label 运行 之后 
的 结果 是 最终 的 分类 结果 为 2 和 
预期 结果 一样 三 实战 之前 对 KNN 进行 了 
一个 简单 的 验证 今天 我们 使用 KNN 改进 约会 
网站 的 效果 个人 理解 这个 问题 也 可以 转化 
为 其它 的 比如 各个 网站 迎合 客户 的 喜好 
所 作出 的 推荐 之类 的 当然 今天 的 这个 
例子 功能 也 实在 有限 在 这里 根据 一 个人 
收集 的 约会 数据 根据 主要 的 样本 特征 以及 
得到 的 分类 对 一些 未知 类别 的 数据 进行 
分类 大致 就是 这样 我 使用 的 是 python 3 
. 4.3 首先 建立 一个 文件 例如 date . py 
具体 的 代码 如下 # coding utf 8 from numpy 
import * import operator from collections import Counter import matplotlib 
import matplotlib . pyplot as plt # # # 导入 
特征 数据 def file2matrix filename fr = open filename contain 
= fr . readlines # # # 读取 文件 的 
所有 内容 count = len contain returnMat = zeros count 
3 classLabelVector = index = 0 for line in contain 
line = line . strip # # # 截取 所有 
的 回车 字符 listFromLine = line . split \ t 
returnMat index = listFromLine 0 3 # # # 选取 
前 三个 元素 存储 在 特征 矩阵 中 classLabelVector . 
append listFromLine 1 # # # 将 列表 的 最后 
一 列 存储 到 向量 classLabelVector 中 index + = 
1 # # 将 列表 的 最后 一 列 由 
字符串 转化 为 数字 便于 以后 的 计算 dictClassLabel = 
Counter classLabelVector classLabel = kind = list dictClassLabel for item 
in classLabelVector if item = = kind 0 item = 
1 elif item = = kind 1 item = 2 
else item = 3 classLabel . append item return returnMat 
classLabel # # # # # 将 文本 中 的 
数据 导入到 列表 # # 绘图 可以 直观 的 表示 
出 各 特征 对 分类 结果 的 影响 程度 datingDataMat 
datingLabels = file2matrix D \ python \ Mechine learing in 
Action \ KNN \ datingTestSet . txt fig = plt 
. figure ax = fig . add _ subplot 111 
ax . scatter datingDataMat 0 datingDataMat 1 15.0 * array 
datingLabels 15.0 * array datingLabels plt . show # # 
归一化 数据 保证 特征 等 权重 def autoNorm dataSet minVals 
= dataSet . min 0 maxVals = dataSet . max 
0 ranges = maxVals minVals normDataSet = zeros shape dataSet 
# # 建立 与 dataSet 结构 一样 的 矩阵 m 
= dataSet . shape 0 for i in range 1 
m normDataSet i = dataSet i minVals / ranges return 
normDataSet ranges minVals # # KNN 算法 def classify input 
dataSet label k dataSize = dataSet . shape 0 # 
# # # 计算 欧式 距离 diff = tile input 
dataSize 1 dataSet sqdiff = diff * * 2 squareDist 
= sum sqdiff axis = 1 # # # 行向量 
分别 相加 从而 得到 新 的 一个 行向量 dist = 
squareDist * * 0.5 # # 对 距离 进行 排序 
sortedDistIndex = argsort dist # # argsort 根据 元素 的 
值 从大到/nr 小 对 元素 进行 排序 返回 下标 classCount 
= { } for i in range k voteLabel = 
label sortedDistIndex i # # # 对 选取 的 K 
个 样本 所属 的 类别 个数 进行 统计 classCount voteLabel 
= classCount . get voteLabel 0 + 1 # # 
# 选取 出现 的 类别 次数 最多 的 类别 maxCount 
= 0 for key value in classCount . items if 
value maxCount maxCount = value classes = key return classes 
# # 测试 选取 10% 测试 def datingTest rate = 
0.10 datingDataMat datingLabels = file2matrix D \ python \ Mechine 
learing in Action \ KNN \ datingTestSet . txt normMat 
ranges minVals = autoNorm datingDataMat m = normMat . shape 
0 testNum = int m * rate errorCount = 0.0 
for i in range 1 testNum classifyResult = classify normMat 
i normMat testNum m datingLabels testNum m 3 print 分类 
后的/nr 结果 为 classifyResult print 原 结果 为 datingLabels i 
if classifyResult = datingLabels i errorCount + = 1.0 print 
误 分率 为 errorCount / float testNum # # # 
预测 函数 def classifyPerson resultList = 一点也 不 喜欢 有一丢/nr 
丢 喜欢 灰常 喜欢 percentTats = float input 玩 视频 
所占 的 时间 比 miles = float input 每年 获得 
的 飞行 常客 里程数 iceCream = float input 每周 所 
消费 的 冰淇淋 公升 数 datingDataMat datingLabels = file2matrix D 
\ python \ Mechine learing in Action \ KNN \ 
datingTestSet2 . txt normMat ranges minVals = autoNorm datingDataMat inArr 
= array miles percentTats iceCream classifierResult = classify inArr minVals 
/ ranges normMat datingLabels 3 print 你 对 这个 人 
的 喜欢 程度 resultList classifierResult 1 新建 test . py 
文件 了解 程序 的 运行 结果 代码 # coding utf 
8 from numpy import * import operator from collections import 
Counter import matplotlib import matplotlib . pyplot as plt import 
sys sys . path . append D \ python \ 
Mechine learing in Action \ KNN import date date . 
classifyPerson 运行 结果 如 下图 以上 是 对 本次 算法 
的 整理 和 总结 