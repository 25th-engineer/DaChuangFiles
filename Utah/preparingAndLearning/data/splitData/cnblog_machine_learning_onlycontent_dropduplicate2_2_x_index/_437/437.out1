在 机器学习 表现 不佳 的 原因 要么 是 过度 拟合 
或 欠 拟合 数据 机器学习 中的 逼近 目标函数 过程 监督 
式 机器学习 通常 理解为 逼近 一个 目标函数 f f 此 
函数 映射 输入 变量 X 到 输出 变量 Y . 
Y = f X Y = f X 这种/r 特性/n 
描述/v 可以/c 用于/v 定义/n 分类/n 和/c 预测/vn 问题/n 和/c 机器学习/i 
算法/n 的/uj 领域/n 从 训练 数据 中 学习 目标 函数 
的 过程 中 我们 必须 考虑 的 问题 是 模型 
在 预测 新 数据 时的/nr 泛化 性能 泛化 好坏 是 
很 重要 的 因为 我 们 收集 到 的 数据 
只是 样本 其 带有 噪音 并且 是 不 完全 的 
机器学习 中的 泛化 在 In 机器学习 中 我们 描述 从 
训练 数据 学习 目标 函数 的 学习 过程 为 归纳 
性 的 学习 归纳 与 特别 的 样本 中 学习 
到 通用 的 概念 有关 而 这 就是 监督 式 
机器学习 致力于 解决 的 问题 这与 推演 不同 其/r 主要/b 
是/v 另一种/i 解决/v 问题/n 和/c 寻求/v 从/p 通常/d 的/uj 规则/n 
中/f 找寻/v 特别/d 的/uj 内容/n 泛化 即是 机器学习 模型 学习 
到 的 概念 在 它 处于 学习 的 过程 中 
时 模型 没有 遇 见过 的 样本 时候 的 表现 
好 的 机器学习 模型 的 模板 目标 是 从 问题 
领域内 的 训练 数据 到 任意 的 数据 上 泛化 
性能 良好 这 让 我们 可以 在 未来 对 模型 
没有 见过 的 数据 进行 预测 在 机器学习 领域 中 
当 我们 讨论 一个 机器学习 模型 学习 和 泛化 的 
好坏 时 我们 通常 使用 术语 过拟合/i 和欠/nr 拟合/v ./i 
过拟合/i 和欠/nr 拟合/v 是/v 机器学习/i 算法/n 表现/v 差/a 的/uj 两/m 
大/a 原因/n 统计 拟 合在 统计学 中 拟合 指 的 
是 你 逼近 目标函数 的 远近 程度 这个 术语 同样 
可以 用于 机器学习 中 因为 监督 式 机器学习 算法 的 
目标 也是 逼近 一 个 未知 的 潜在 映射函数 其 
把 输入 变量 映 射到 输出 变量 统计学 通常 通过 
用于 描述 函数 和 目标函数 逼近 的 吻合 程度 来 
描述 拟合 的 好坏 这类 理论 中 的 一些 在 
机器 学习 中 也是 有用 的 例如 计算 残差 但是 
一些 技巧 假设 我们 已经 知道 了 我们 要 逼近 
的 函数 这 和 机器 学习 的 场景 就 不同 
了 如果 我们 已经 知道 了 目标 函数 的 形式 
我们 将 可以 直接 用 它 来做 预测 而 不是 
从一 堆有 噪音 的 数据 中 把 它 费力 的 
学习 出来 机器学习 中的 过拟合 过拟合 指 的 是 referstoa 
模型 对于 训练 数据 拟合 程度 过当 的 情况 当 
某个 模型 过度 的 学习 训练 数据 中 的 细节 
和 噪音 以至于 模型 在 新的 数据 上 表现 很差 
我们 称 过拟合 发生 了 这 意味着 训练 数据 中 
的 噪音 或者 随机 波动 也 被 当做 概念 被 
模型 学习 了 而 问题 就 在于 这些 概念 不 
适用 于 新的 数据 从而 导致 模型 泛化 性能 的 
变差 过拟合 更 可能 在 无 参数 非线性 模型 中 
发生 因为 学习 目标 函数 的 过程 是 易变 的 
具有 弹性 的 同样 的 许多 的 无 参数 器 
学习 算法 也 包括 限制 约束 模型 学习 概念 多少 
的 参数 或者 技巧 例如 决策树 就是 一种 无 参数 
机器学习 算法 非常 有 弹性 并且 容易 受 过拟合 训练 
数据 的 影响 这种 问题 可以 通过 对 学习 过后 
的 树 进行 剪枝 来 解决 这种 方法 就是 为了 
移除 一些 其 学习 到 的 细节 机器学习/i 中的/i 欠/v 
拟合/v 欠/v 拟合/v 指/n 的/uj 是/v 模型/n 在/p 训练/vn 和/c 
预测/vn 时/n 表现/v 都/d 不好/d 的/uj 情况/n 一个 欠 拟合 
的 机器学习 模型 不是 一个 良好 的 模型 并且 由于 
在 训练 数据 上 表现 不好 这是 显然 的 欠 
拟合 通常 不 被 讨论 因为 给 定 一个 评估 
模型 表现 的 指标 的 情况 下 欠 拟合 很容易 
被 发现 矫正 方法 是 继续 学习 并且 试着 更换 
机器学习 算法 虽然 如此 欠 拟合 与 过拟合 形成 了 
鲜明 的 对照 机器学习 中 好 的 拟 合理 想上 
你 肯定 想 选择 一个 正好 介于 欠 拟合 和 
过拟合 之间 的 模型 这 就是 我们 学习 的 目标 
但是 实际上 很 难达到 为了 理解 这个 目标 我们 可以 
观察 正在 学习 训练 数据 机器学习 算法 的 表现 我们 
可以 把 这个 过程 划分为 分别 是 训练 过程 和 
测试过程 随着 时间 进行 算法 不断 地 学习 模型/n 在/p 
训练/vn 数据/n 和/c 测试/vn 数据/n 上/f 的/uj 错误/n 都在/nr 不断/d 
下降/v 但是 如果 我们 学习 的 时间 过长 的话 模型 
在 训练 数据 上 的 表现 将 继续 下降 这 
是因为 模型 已经 过拟合 并且 学习 到 了 训练 数据 
中的 不 恰当 的 细节 以及 噪音 同时 测试数据 集上 
的 错误率 开始 上升 也 即是 模型 的 泛化 能力 
在 下降 这个 完美 的 临界点 就 处于 测试 集上 
的 错误率 开始 上升 时 此时 模型 在 训练 集 
和 测试 集上 都有 良好 的 表现 你 可以 用 
你 自己 喜爱 的 机器学习 算法 来 实践 这个 实验 
而在 实践 中 这 通常 是 无用 的 因为 在 
测试 数据 上 运用 这个 技巧 来 选择 训练 停止 
的 时机 这 意味着 这个 测试 集 对于 我们 并 
不是 不 可见 的 或者 单独 的 衡量 标准 数据 
的 一些 知识 许多 有用 的 知识 已经 泄露 到了 
训练 过程 通常 有 两种 手段 可以 帮助 你 找到 
这个 完美 的 临界点 重 采样 方法 和 验证 集 
方法 如何 限制 过拟合 过拟合 和欠/nr 拟合 可以 导致 很差 
的 模型 表现 但是 到 目前 为止 大部分 机器学习 实际 
应用 时的/nr 问题 都是 过拟合 过拟合 是个 问题 因 为 
训练 数据 上 的 机器学习 算法 的 评价 方法 与 
我们 最 关心 的 实际上 的 评价 方法 也 就是 
算法 在 位置 数据 上 的 表现 是 不 一样 
的 当/t 评价/n 机器学习/i 算法/n 时/n 我们/r 有/v 两者/n 重要/a 
的/uj 技巧/n 来/v 限制/v 过拟合/i 使用 重 采样 来 评价 
模型 效能 保留 一 个 验证 数据集 最 流行 的 
重 采样 技术 是 k 折 交叉 验证 指 的 
是 在 训练 数据 的 子集 上 训练 和 测试 
模型 k 次 同时 建立 对于 机器学习 模型 在 未知 
数据 上 表现 的 评估 验证 集 只是 训练 数据 
的 子集 你 把 它 保留 到 你 进行 机器学习 
算法 的 最后 才 使用 在 训练 数据 上 选择 
和 调谐 机器学习 算法 之后 我们 在 验证 集上 在 
对于 模型 进行 评估 以便 得到 一些 关于 模型 在 
未知 数据 上 的 表现 的 认知 对于 机器学习 使用 
交叉 验证 在 未知 数据 上 进行 验证 模型 效能 
是 一种 良好 的 标准 如果 你 拥有 数据 使用 
验证 集 也 是 一种 良好 的 实践 进一步 阅读 
如果 你 想 学习 更多 关于 机器学习 中的 泛化 过拟合 
和欠/nr 拟合 的 知识 本节 列举 了 一些 相关 的 
推荐 资源 维基百科 上 的 泛化 维基百科 上 过拟合 维基百科 
上 的 归纳推理 维基百科 上 的 感应 问题 Quora 上 
的 过拟合 的 直观 解释 总结 本文 中 你 学习 
了 机器 学习 就 是以 感应 方法 来 解决问题 你 
学习 了 泛化 是 一种 关于 模型 学习 到 的 
知识 在 未知 数据 上 表现 程度 的 概念 描述 
最后 你 学习 了 机器 学习 中 的 术语 泛化 
中的 过拟合 与 欠 拟合 过拟合 在 训练 数据 上 
表现 良好 在 未知 数据 上 表现 差 欠 拟合 
在/p 训练/vn 数据/n 和/c 未知/v 数据/n 上/f 表现/v 都/d 很差/i 
原文/n 链接/n Overfitting and Underfitting With Machine Learning Algorithms 