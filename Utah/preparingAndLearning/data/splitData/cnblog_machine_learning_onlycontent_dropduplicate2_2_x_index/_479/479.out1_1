将 Mahout on Spark 中的 机器学习 算法 和 MLlib 中 
支持 的 算法 统计 如下 主要 针对 MLlib 进行 总结 
分类 与 回归 分类 和 回归 是 监督 式 学习 
监督 式 学习 是 指 使用 有 标签 的 数据 
LabeledPoint 进行 训练 得到 模型 后 使用 测试数据 预测 结果 
其中 标签 数据 是 指 已知 结果 的 特征 数据 
分类 和 回归 的 区别 预测 结果 的 变量 类型 
分类 预测 出来 的 变量 是 离散 的 比如 对 
邮件 的 分类 垃圾 邮件 和非/nr 垃圾邮件 对于 二元 分类 
的 标签 是 0 和1/nr 对于 多元 分类 标签 范围 
是 0 ~ C 1 C 表示 类别 数目 回归 
预测 出来 的 变量 是 连续 的 比如 根据 年龄 
和 体重 预测 身高 线性 回归 线性 回归 是 回归 
中最 常用 的 方法 之一 是 指用 特征 的 线性组合 
来 预测 输出 值 线性 回归 算法 可以 使用 的 
类有 L i n e a r R e g 
r e s s i o n W i t 
h G D R i d g e R e 
g r e s s i o n W i 
t h G D L a s s o W 
i t h G D r i d g e 
regression   使用 L2 正规化 Lasso 使用 L1 正规化 参数 
stepSize 梯度 下降 的 步数 numIterations 迭代 次数 设置 intercept 
是否 给 数据 加上 一个 干扰 特征 或者 偏差 特征 
一个 始 终值 为 1 的 特征 默认 不 增加 
false { stepSize 1.0 numIterations 100 m i n i 
B a t c h F r a c t 
i o n 1.0 } 模型 的 使用 1 对 
数据 进行 预测 使用 model . predict 2 获取数据 特征 
的 权重 model . weights 模型 的 评估 均方 误差 
例子 import org . apache . spark . { SparkContext 
SparkConf } import org . apache . spark . mllib 
. regression . LabeledPoint import org . apache . spark 
. mllib . regression . L i n e a 
r R e g r e s s i o 
n M o d e l import org . apache 
. spark . mllib . regression . L i n 
e a r R e g r e s s 
i o n W i t h G D import 
org . apache . spark . mllib . linalg . 
Vectors / * * * Created by Edward on 2016 
/ 9/21 . * / object LinearRegression { def main 
args Array String { val conf SparkConf = new SparkConf 
. setAppName LinearRegression . setMaster local val sc = new 
SparkContext conf / / Load and parse the data val 
data = sc . textFile data / mllib / ridge 
data / lpsa . data val parsedData = data . 
map { line = val parts = line . split 
LabeledPoint parts 0 . toDouble Vectors . dense parts 1 
. split . map _ . toDouble } . cache 
/ / Building the model val numIterations = 100 val 
model = L i n e a r R e 
g r e s s i o n W i 
t h G D . train parsedData numIterations / / 
var lr = new L i n e a r 
R e g r e s s i o n 
W i t h G D . setIntercept true / 
/ val model = lr . run parsedData / / 
获取 特征 权重 及 干扰 特征 println weights % s 
intercept % s . format model . weights model . 
intercept / / Evaluate model on training examples and compute 
training error val valuesAndPreds = parsedData . map { point 
= val prediction = model . predict point . features 
point . label prediction } / / 计算 均方 误差 
val MSE = valuesAndPreds . map { case v p 
= math . pow v p 2 } . mean 
println training Mean Squared Error = + MSE / / 
Save and load model model . save sc myModelPath val 
sameModel = L i n e a r R e 
g r e s s i o n M o 
d e l . load sc myModelPath } } 数据 
0.4307829 1.63735562648104 2.00621178480549 1.86242597251066 1.02470580167082 0 . 522940888712441 0 . 
863171185425945 1.04215728919298 0 . 864466507337306 0.1625189 1.98898046126935 0 . 722008756122123 
0 . 787896192088153 1.02470580167082 0 . 522940888712441 0 . 863171185425945 
1.04215728919298 0 . 864466507337306 0.1625189 1.57881887548545 2.1887840293994 1.36116336875686 1.02470580167082 0 
. 522940888712441 0 . 863171185425945 0 . 342627053981254 0 . 
155348103855541 0.1625189 2.16691708463163 0 . 807993896938655 0 . 787896192088153 1.02470580167082 
0 . 522940888712441 0 . 863171185425945 1.04215728919298 0 . 864466507337306 
0.3715636 0 . 507874475300631 0 . 458834049396776 0 . 250631301876899 
1.02470580167082 0 . 522940888712441 0 . 863171185425945 1.04215728919298 0 . 
864466507337306 0.7654678 2.03612849966376 0 . 933954647105133 1.86242597251066 1.02470580167082 0 . 
522940888712441 0 . 863171185425945 1.04215728919298 0 . 864466507337306 . . 
. 数据 第一列 表示 标签 数据 也 就是 结果 数据 
其他 列 表示 特征 数据 预测 就是 再 给 一组 
特征 数据 预测 结果 结果 weights 0 . 5808575763272221 0 
. 1 8 9 3 0 0 0 1 4 
8 2 9 4 6 9 7 6 0 . 
2803086929991066 0 . 1110834181777876 0 . 4010473965597895 0 . 5603061626684255 
0 . 5804740464000981 0 . 8742741176970946 intercept 0 . 0training 
Mean Squared Error = 6 . 207597210613579 逻辑 回归 是 
一种 二元 分类 方法 也是 多类 分类 方法 逻辑 回归 
可以 使用 的 方法 L o g i s t 
i c R e g r e s s i 
o n W i t h L B F G 
建议 使用 这个 L o g i s t i 
c R e g r e s s i o 
n W i t h G D 参数 与 线性 
回归 类似 模型 的 使用 1 对 数据 进行 预测 
使用 model . predict 2 获取数据 特征 的 权重 model 
. weights 模型 的 评估 二元 分类 AUC Area Under 
roc Curve import org . apache . spark . { 
SparkContext SparkConf } import org . apache . spark . 
SparkContext import org . apache . spark . mllib . 
classification . { L o g i s t i 
c R e g r e s s i o 
n W i t h L B F G L 
o g i s t i c R e g 
r e s s i o n M o d 
e l } import org . apache . spark . 
mllib . evaluation . { B i n a r 
y C l a s s i f i c 
a t i o n M e t r i 
c s M u l t i c l a 
s s M e t r i c s } 
import org . apache . spark . mllib . regression 
. LabeledPoint import org . apache . spark . mllib 
. util . MLUtils / * * * Created by 
Edward on 2016 / 9/21 . * / object L 
o g i s t i c R e g 
r e s s i o n { def main 
args Array String { val conf SparkConf = new SparkConf 
. setAppName L o g i s t i c 
R e g r e s s i o n 
. setMaster local val sc SparkContext = new SparkContext conf 
/ / Load training data in LIBSVM format . val 
data = MLUtils . loadLibSVMFile sc data / mllib / 
sample _ libsvm _ data . txt / / Split 
data into training 60% and test 40% . val splits 
= data . randomSplit Array 0.6 0.4 seed = 11L 
val training = splits 0 . cache val test = 
splits 1 / / Run training algorithm to build the 
model val model = new L o g i s 
t i c R e g r e s s 
i o n W i t h L B F 
G . setNumClasses 10 . run training model . setThreshold 
0.8 / / Compute raw scores on the test set 
. val p r e d i c t i 
o n A n d L a b e l 
s = test . map { case LabeledPoint label features 
= val prediction = model . predict features prediction label 
} / / 多元 矩阵 / / Get evaluation metrics 
. / / val metrics = new M u l 
t i c l a s s M e t 
r i c s p r e d i c 
t i o n A n d L a b 
e l s / / val precision = metrics . 
precision / / println Precision = + precision / / 
二元 矩阵 val metrics = new B i n a 
r y C l a s s i f i 
c a t i o n M e t r 
i c s p r e d i c t 
i o n A n d L a b e 
l s / / 通过 ROC 对模型 进行 评估 值 
趋 近于 1 receiver operating characteristic ROC 接受者 操作 特征 
曲 线下 面积 val auROC Double = metrics . areaUnderROC 
println Area under ROC = + auROC / / 通过 
PR 对模型 进行 评估 值 趋 近于 1 precision recall 
PR 精确 率 val underPR Double = metrics . areaUnderPR 
println Area under PR = + underPR / / Save 
and load model model . save sc myModelPath val sameModel 
= L o g i s t i c R 
e g r e s s i o n M 
o d e l . load sc myModelPath } } 
支持 向量 机 Support Vector Machines SVMs 分类 算法 二元 
分类 算法 和 逻辑 回归 二元 分类 相似 import org 
. apache . spark . { SparkContext SparkConf } import 
org . apache . spark . mllib . classification . 
{ SVMModel SVMWithSGD } import org . apache . spark 
. mllib . evaluation . B i n a r 
y C l a s s i f i c 
a t i o n M e t r i 
c s import org . apache . spark . mllib 
. util . MLUtils / * * * Created by 
Edward on 2016 / 9/21 . * / object SVMs 
{ def main args Array String { val conf SparkConf 
= new SparkConf . setAppName SVM . setMaster local val 
sc SparkContext = new SparkContext conf / / Load training 
data in LIBSVM format . val data = MLUtils . 
loadLibSVMFile sc data / mllib / sample _ libsvm _ 
data . txt / / Split data into training 60% 
and test 40% . val splits = data . randomSplit 
Array 0.6 0.4 seed = 11L val training = splits 
0 . cache val test = splits 1 / / 
Run training algorithm to build the model val numIterations = 
100 val model = SVMWithSGD . train training numIterations / 
/ Clear the default threshold . model . clearThreshold / 
/ Compute raw scores on the test set . val 
scoreAndLabels = test . map { point = println feature 
= + point . features val score = model . 
predict point . features score point . label } scoreAndLabels 
. foreach println _ / / Get evaluation metrics . 
val metrics = new B i n a r y 
C l a s s i f i c a 
t i o n M e t r i c 
s scoreAndLabels println metrics = + metrics val auROC = 
metrics . areaUnderROC println Area under ROC = + auROC 
/ / Save and load model model . save sc 
myModelPath val sameModel = SVMModel . load sc myModelPath sc 
. stop } } 数据 0 128 51 129 159 
130 253 131 159 132 50 155 48 156 238 
157 252 158 252 159 252 160 237 182 54 
183 227 184 253 185 252 186 239 187 233 
188 252 189 57 190 6 208 10 209 60 
210 224 1 159 124 160 253 161 255 162 
63 186 96 187 244 188 251 189 253 190 
62 214 127 215 251 216 251 217 253 218 
62 . . . 协同 过滤   Collaborative FilteringSpark 中 
协同 过滤 算法 主要 由 交替 最小二乘 法来/nr 实现   
alternating least squares ALS 参数 numBlocks block 块 的 数量 
用来 控制 并行度 rank 特征向量 的 大小 iterations 迭 代数量 
lambda 正规化 参数 alpha 用来 在 隐式 ALS 中 计算 
置信度 的 常量 方法 ALS . train 模型 的 评估 
均方 误差 例子 import org . apache . spark . 
{ SparkContext SparkConf } import org . apache . spark 
. mllib . recommendation . ALS import org . apache 
. spark . mllib . recommendation . M a t 
r i x F a c t o r i 
z a t i o n M o d e 
l import org . apache . spark . mllib . 
recommendation . Rating / * * * Created by Edward 
on 2016 / 9/22 . * / object CollaborativeALS { 
def main args Array String { val conf SparkConf = 
new SparkConf . setAppName CollaborativeALS . setMaster local val sc 
SparkContext = new SparkContext conf / / Load and parse 
the data val data = sc . textFile data / 
mllib / als / test . data val ratings = 
data . map _ . split match { case Array 
user item rate = Rating user . toInt item . 
toInt rate . toDouble } / / Build the recommendation 
model using ALS val rank = 10 val numIterations = 
10 val model = ALS . train ratings rank numIterations 
0.01 / / Evaluate the model on rating data val 
usersProducts = ratings . map { case Rating user product 
rate = user product } val predictions = model . 
predict usersProducts . map { case Rating user product rate 
= user product rate } val ratesAndPreds = ratings . 
map { case Rating user product rate = user product 
rate } . join predictions val MSE = ratesAndPreds . 
map { case user product r1 r2 = val err 
= r1 r2 err * err } . mean / 
/ 均方 误差 println Mean Squared Error = + MSE 
/ / Save and load model model . save sc 
target / tmp / m y C o l l 
a b o r a t i v e F 
i l t e r val sameModel = M a 
t r i x F a c t o r 
i z a t i o n M o d 
e l . load sc target / tmp / m 
y C o l l a b o r a 
t i v e F i l t e r 
} } 持续 更 新中 . . . 