看完 一节 机器学习 实战 算是 踏入 ML 的 大门 了吧 
这里 就 详细 讲 一下 一个 demo 使用 kNN 算法 
实现 手写 字体 的 简单 识别 kNN 先 简单 介绍 
一下 kNN 就是 所谓 的 K 近邻 算法 作用 原理 
存在 一个 样本数据 集合 每个 样本数据 都 存在 标签 输入 
没有 标签 的 新 数据 后 将 新 数据 的 
每个 特征 与 样 本集 数据 的 对应 特征 进行 
比较 然后 算法 提取 样本 集中 最 相似 的 分类 
标签 一般说来 我们 只 选择 样本 数据集 中前 k 个 
最 相似 的 数据 最后 选择 这 k 个 相似 
数据 中 出现 次数 最多 的 分类 作为 新 数据 
的 分类 通俗 的 说 举例说明 有 一群 明确 国籍 
的 人 样本 集合 比如 1000个 中国 人 韩国人 日本人 
美国人 埃及人 现在 有 一个 不知 国籍 的 人 想 
要 通过 比较 特征 来 猜测 他 的 国籍 当然 
特征 具有 可 比较性 和 有效性 通过 比较 特征 得出 
特征 与 该人 最 相近 的 样本 集中 的 9 
个人 k 其中 1个 是 韩国人 2个 是 日本人 6个 
是 中国 人 那么 这 个人 是 中国人 的 可能性 
就 很大 这 就是 kNN 的 基本 思想 手写体 识别 
数据 准备 kNN 输入 需要 特征 矩阵 一般 是 固定 
大小 的 二 值 图像 这里 我们 使用 书上 提供 
的 数据集 这个 数据集 使用 32X32 文本文件 存储 数值 图像 
例如 下图 的 9 这里 每个 文本文件 存储 一个 手写体 
数据 并且 文件名 写成 number _ num . txt 这样 
的 形式 例如 9 _ 1 . txt 方便 后期 
提取 标签 我们 将 样本数据 放在 trainingDigits 文件夹 中 测试 
样例 存储 在 testDigits 文件夹 中 我们 在 处理 时将/nr 
每个 手写体 数据 32x32 转换成 1X1024 维 的 向量 另外 
kNN 涉及 到 相似 度 计算 这里 我们 使用 的 
是 欧氏距离 由于 手写体 数据 向量 是 规则 的 二 
值 数据 因此 不 需要 进行 归一化 手写体 识别 算法 
运行 流程 一 读取 手写体 txt 文件 转化 为 1X1024 
向量 我们 创建 一个 kNN . py 添加 模块 img2vector1 
# 识别 手写 字体 模块 图像 转 向量 32x32 to 
1x1024 2 def img2vector filename 3 returnVect = zeros 1 
1024 4 fr = open filename 5 for i in 
range 32 6 lineStr = fr . readline 7 for 
j in range 32 8 returnVect 0 32 * i 
+ j = int lineStr j 9 return returnVect/w 我们/r 
的/uj 样本/n 数据/n 和/c 测试/vn 数据/n 都/d 需要/v 用到/v 该/r 
函数/n 二 比较 测试数据 和 样本 数据集 的 距离 返回 
k 近邻 中最 相似 的 标签 在 kNN . py 
中 添加 classify0 模块 附上 代码 注释 1 # 2 
# 分类 模块 3 # @ params 4 # inX 
输入 向量 手写体 识别 的 测试 向量 5 # dataSet 
训练 集 样本 手写体 识别 的 训练 集 向量 6 
# labels 训练 集 对应 的 标签 向量 7 # 
k 最近 邻居 数目 本 实验 为 3 8 # 
9 def classifiy0 inX dataSet labels k 10 dataSetSize = 
dataSet . shape 0 # 手写体 样 本集 容量 11 
# 以下 三行 距离 计算 12 diffMat = tile inX 
dataSetSize 1 dataSet 13 sqDiffMat = diffMat * * 2 
14 sqDistances = sqDiffMat . sum axis = 1 15 
distances = sqDistances * * 0.5 # 欧氏距离 开平方 16 
s o r t e d D i s t 
I n d i c i e s = distances 
. argsort # 距离 排序 的 索引 排序 17 classCount 
= { } 18 # 以下 两行 选择 距离 最小 
的 k 个 点 19 for i in range k 
20 voteIlabel = labels s o r t e d 
D i s t I n d i c i 
e s i 21 classCount voteIlabel = classCount . get 
voteIlabel 0 + 1 22 sortedClassCount = sorted classCount . 
items 23 # 排序 24 key = operator . itemgetter 
1 reverse = True 25 return sortedClassCount 0 0 注意 
这里 使用 了 numpy 的 接口 在 kNN . py 
的 开头 要 加上 from numpy import * 三 比较 
标签 与 测试 结果 计算 正确率 同样 在 kNN . 
py 中 添加 h a n d w r i 
t i n g C l a s s T 
e s t 模块 综合 以上 的 两个 模块 获得 
识别 正确率 1 # 手写识别 的 测试代码 2 def h 
a n d w r i t i n g 
C l a s s T e s t 3 
hwLabels = 4 trainingFileList = listdir path = trainingDigits # 
获取 目录 内容 5 m = len trainingFileList 6 trainingMat 
= zeros m 1024 7 for i in range m 
8 # 一下 三行 从 文件名 解析 分类 数字 9 
fileNameStr = trainingFileList i 10 fileStr = fileNameStr . split 
. 0 11 classNumStr = int fileStr . split _ 
0 12 13 hwLabels . append classNumStr 14 trainingMat i 
= img2vector trainingDigits / % s % fileNameStr 15 testFileList 
= listdir path = testDigits 16 17 errorCount = 0.0 
# 错误 个数 计数器 18 mTest = len testFileList 19 
20 # 从 测试 数据 中 提取 数据 21 for 
i in range mTest 22 fileNameStr = testFileList i 23 
fileStr = fileNameStr . split . 0 24 25 classNumStr 
= int fileStr . split _ 0 26 vectorUnderTest = 
img2vector testDigits / % s % fileNameStr 27 classifierResult = 
classify0 vectorUnderTest trainingMat hwLabels 3 28 29 print the classifier 
came back with % d the real answer is % 
d % classifierResult classNumStr 30 if classifierResult = classNumStr 31 
errorCount + = 1.0 32 # 输出 结果 33 print 
\ nthe total number of errors is % d % 
errorCount 34 print \ nthe total error rate is % 
f % errorCount / float mTest 注意 这里 使用 到了 
os 模块 listdir 在 kNN 开头 加入 from numpy import 
listdir 测试 结果 如下 错误率 为 1.16% 可以 看到 识别 
效果 挺不错 后记 通过 实验 我们 可以 看到 使用 kNN 
要将 训练样本 一次性 加 载入 内存 如果 训练 集 的 
规模 很大 势必 对 机器 有 很大 的 要求 另外 
kNN 不 需要 训练 算法 对 异常值 不 敏感 在 
后期 使用 的 时候 要 慎重 选择 吧 