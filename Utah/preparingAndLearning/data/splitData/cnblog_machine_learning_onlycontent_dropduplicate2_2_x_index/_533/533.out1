截止 目前 已经 知道 了 常用 的 机器学习 算法 是 
怎么 回 事儿 学习 的 步骤 是 怎么 进行 的 
但在 机器 学习 的 应用 背景 是 多种多样 的 做 
实际 工程 必须 学会 如何 根据 具体 的 问题 评估 
一个 学习 模型 的 好坏 如何 合理 地 选择 模型 
提取 特征 如何 进行 参数 调 优 这些 也是 我 
以前 做 模式识别 时 欠缺 的 环节 所以 在 遇到 
识别 率 很低 的 情况 时 往往 很 困惑 不 
知道 该 如何 改进 到底 是 应该 改进 模型 改变 
特征 还是 应该 增加 训练 样本 数量 到底 是 应该 
优化 迭代 算法 还是 应该 改变 目标函数 通过学习 Learning Theory 
可以 得到 一些 指导性 的 结论 首先 是 bias variance 
trade off 问题 假设 训练 模型 集合 H 中有 k 
个 备选 模型 k 表示 了 模型 的 复杂度 训练 
集 中有 m 个 样本 则 式子 Test Error = 
  Training Error + 2 * log 2k / delta 
* 1/2 m ^ 0.5 在 概率 1 delta 成立 
Training Error 是 所谓 的 bias 表征 了 训练样本 跟 
模型 的 吻合 程度 bias 越大 即 训练 误差 越大 
训练样本 跟 模型 的 吻合 程度 越低 即 出现 欠 
学习 的 情况 2 * log 2k / delta * 
1/2 m ^ 0.5 是 variance k 越大 即 模型 
的 复杂度 越大 m 越小 即 训练样本 数量 越小 variance 
越大 模型 的 推广 能力 越差 即 出现 过 学习 
的 情况 这个 结论 还有 另外 一个 推论 给定 delta 
和 gamma 如果 Test Error =   Training Error + 
2 * gamma 在 概率 1 delta 下 成立 则 
训练样本 数量 m 必须 满足 m = O 1 / 
gamma * log k / delta 这个 推论 表明 为了 
保证 Test Error 不至于 过大 训练样本 的 数量 m 必须 
同 模型 复杂度 log k 成正比 实际 的 模型 复杂度 
一般 不用 k 表示 而是 假设 模型 有d个/nr 参数 则 
每个 样本点 的 维数 为 d 每个 参数 为 double 
型 那么 k = 2 ^ 64d 上面 的 条件 
变为 m = O d / gamma * log 1 
/ delta 即 训练样本 的 数量 m 同 模型 参数 
个数 d 成正比 上面 的 结论 是 针对 有限 维空间 
的 情况 对于 无限 维空间 d 用 H 的 VC 
维 来 代替 可以 得到 类似 的 结论 一般来讲 VC 
维 与 模型 的 参数 个数 d 成正比 但 在 
一些 特殊 情况 下 VC 维 不一定 与 样本 维数 
有关系 比如 支持 向量 机 bias variance trade off 的 
过程 实际上 就是 模型 选择 和 特征 选择 的 过程 
对于 模型 选择 最 实用 的 办法 就是 进行 交叉 
验证 得到 Test Error 最小 的 模型 对于 特征选择 可 
采用 前 向 选择 或 后向 选择 的 方法 选择 
好 的 特征 删除 不好 的 特征 或者 采用 滤波 
的 方法 计算 每个 特征 xi 与 y 的 互 
信息量 取 互 信息量 较大 的 那个 特征 bias variance 
trade off 的 目的 是 寻找 训练 误差 和 推广 
能力 的 平衡 为了 达到 这个 平衡 也 可以 采用 
加入 Regularation 的 办法 用 统计 推断 的 观点 看待 
机器学习 问题 不加 Regularation 对应 频率 学派 的 方法 即将 
参数 theta 看成 一个 未知 的 确定性 变量 学习 的 
过程 就是 求 y 和x的/nr 最大 似 然 对应 的 
theta 加 Regularation 对应 贝叶斯 学派 的 方法 即将 参数 
theta 看成 一个 随机变量 学习 的 过程 就是 已知 theta 
的 先验概率 求 theta 的 最大 后验/nr 概率 加入 Regularation 
后 目标函数 中 加入 了 lamda * | | theta 
| | ^ 2 的 正则 项 对 一个 回归 
问题 加入 正则 项后/nr 拟合 的 结果 会 更加 平滑 
有效 地 减少 了 过拟合 学习 了 这么 多 Learning 
Theory 我们 回到 笔记 开头 提出 的 问题 怎样 优化 
学习 算法 首先 判 别是 high bias 问题 还是 high 
variance 问题 判断 的 方法 有 两个 一 test error 
大 则是 high variance 问题   training error 大 则是 
high bias 问题 二 增加 训练 样本 数量 看 两类 
error 的 变化 趋势 test error 变小 则是 high variance 
问题 增加 训练 样本 数量 减少 特征 数量 可以 解决 
high variance 问题 增加 特征 数量 可以 解决 high bias 
问题 