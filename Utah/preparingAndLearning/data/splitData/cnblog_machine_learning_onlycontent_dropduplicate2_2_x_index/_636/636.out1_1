机器学习 分类 实例 SVM20180423 20180426 学习 笔记 25 去 首届 
数字 中国 会展 参观 了 没 学习 想 偷懒 由于 
是 最后 一天 感觉 展出 的 东西 少了 因为 24号 
闭幕 了 但是 可以 去 体验 区 主要 体验 了 
VR 其他 展出 的 东西 要么 没意思 要么 看不懂 马云 
马化腾 他们 来 的 时候 我 因为 要 开会 没 
去看 失去 了 找 他们 要 签名 的 机会 唉 
一 工作 主要 是 学习 分类器 的 一些 理论 通过实践 
最终 得出 了 结果 虽然 结果 没 那么 完美 到底 
怎么 不 完美 下面 会 提到 1.1 学习理论 因为 对 
这 方面 的 知识 仅限于 本科 阶段 的 人工智能 与 
数据挖掘 课程 中 了解 一些 应付 考试 用 所以 真的 
要 运用 起来 还 真是 麻烦 虽说 不用 理解 每个 
公式 每个 数字 的 含义 但是 对 整个 模型 输入 
什么 输出 什么 做 什么 核心思想 等 还是 需要 理解 
的 知乎 中的 高票 答案 一答 主 简之/nr 把 SVM 
模型 的 各个 部分 进行 了 形象 生动 的 比喻 
再 之后 无聊 的 大人 们 把 这些 球 叫做 
「 data 」 把 棍子 叫做 「 classifier 」 最大 
间隙 trick 叫做 「 optimization 」 拍桌子 叫做 「 kernelling 
」 那张 纸 叫做 「 hyperplane 」 通过 他 的 
描述 SVM 的 运行 机制 可以 有个 大体 的 理解 
高票 答案 二 答 主 靠靠 靠谱 则 进一步 详细 
地 介绍 了 整个 模型 由 苹果 香蕉 的 分类 
问题 引出 SVM 的 原理 以及 其中 各个 参数 的 
介绍 写得 也 很好 知乎 链接 支持 向量 机 SVM 
是 什么 意思 1.2 学习 实例 看了 理论 还是 挺 
懵 的 本次 毕设 是 采用 scikit learn v0 . 
19.1 去 官方 查询 文档 看 如何 设置 参数 调用函数 
输入输出 格式 等 官方 文档 Support Vector Machines 中文 文档 
支持 向量 机 SVM 不用 看 中文 也 能 明白 
意思 但 一些 参数 还是 无法 理解 搜索 到 一篇 
博客 写得 很好 Python 中 的 支持 向量 机 SVM 
的 使用 有 实例 文中 详细 地 写了 各个 参数 
意义 逐步 按照 博主 的 步骤 就能 正确 分类 并 
绘出 图 还 挺 漂亮 但是 我 要做 的 多维 
特征 所以 这种 二 特征 绘图 不 适合 我 老师 
要求 最后 用图表 来 表示 判别 结果 但是 具体 怎么 
表示 还 没想 清楚 1.3 开始 编码 读取 文件 test 
. txt 里面 存储 的 是 一系列 特征 以及 三个 
label 值 在 我 的 非 民主 相关 帖子 处理 
有 test . txt 的 样式 里面 是 200个 特征 
以及 3个 label 值 1 导入 需要 的 包 import 
numpy as np from sklearn . svm import SVC from 
sklearn . cross _ validation import train _ test _ 
split from sklearn . metrics import classification _ report 2 
读取 文件 并 存储 with open test . txt r 
as file ty = 3 # 代表 取 哪 一列 
label 值 1 代表 取 倒 一列 所有 值 result 
= for line in file . readlines result . append 
list map str line . strip . split vec = 
np . array result x = vec 3 # 取 
除掉 最后 三列 以外 的 所有 列 即 所有 特征 
列 y = vec ty # 标签 列 3 划分 
测试 集 及 训练 集 train _ x test _ 
x train _ y test _ y = train _ 
test _ split x y test _ size = 0.2 
4 模型 训练 及 预测 clf = SVC kernel = 
linear C = 0.4 clf . fit train _ x 
train _ y pred _ y = clf . predict 
test _ x print classification _ report test _ y 
pred _ y 其中 Kernel 在 参考 文档 中 有 
介绍 常数 C 是 靠 经验 得出 的 数值 并 
没有 具体 的 公式 不过 有 关于 它 设置 的 
一些 意义 知乎 答 主 顾 凌峰 是 这样 介绍 
C 的 原则上 C 可以 根据 需要 选择 所有 大于 
0 的 数 C 越大 表示 整个 优化 过程 中 
对于 总 误差 的 关注 程度 越高 对于 减小 误差 
的 要求 越高 甚至 不惜 使 间隔 减小 当 C 
趋于 无穷大 时 这个 问题 也 就是 不 允许 出现 
分类 误差 的 样本 存在 那这/nr 就是 一个 hard marginSVM 
问题 当 C 趋于 0时 我们 不再 关注 分类 是否 
正确 只 要求 间隔 越大 越好 那么/r 我们/r 将/d 无法/n 
得到/v 有/v 意义/n 的/uj 解且/nr 算法/n 不/d 会/v 收敛/v 知乎 
链接 关于 SVM 中 对 常数 C 的 理解 5 
训练 结果 分析 关于 函数 classification _ report test _ 
y pred _ y 介绍 以及 precision / recall / 
f1 score 的 具体 含义 详见 两篇 博客 机器学习 笔记 
－ － classification _ report & 精确度 / 召回率 / 
F1 值 准确率 Accuracy 精确 率 Precision 召回率 Recall 和 
F1 Measure 简单 来说 就是 6 测试 文本 分析 任务 
是 输入 一段 文本 用 jieba 找出 关键词 把 关键词 
数量 选 大一些 尽量 覆盖 全文 此处 用 关键词 还是 
用 分词 存疑 然后再 和 关键 词库 比对 得到 该 
文本 的 特征向量 代码 比较简单 和 之前 的 类似 from 
openpyxl import load _ workbook from openpyxl import Workbook import 
jieba . analyse wr = load _ workbook sta . 
xlsx osheet = wr . active orow = osheet . 
max _ row print orow testL = num = 200 
tempc = 0 for i in osheet A if tempc 
num testL . append i . value else break tempc 
= tempc + 1 with open example . txt r 
as f ftxt = f . read print ftxt content 
= ftxt keywords = jieba . analyse . extract _ 
tags content topK = 1000 print keywords L3 = L2 
= flag = False print testL L2 = for g 
in testL flag = False for i in keywords if 
g = = i flag = True break if flag 
L2 . append 1 else L2 . append 0 print 
L2 file = open examout . txt w file . 
write str L2 . strip . strip file . close 
从 example . txt 中的 一段 文字 文本 最终 变成 
examout . txt 中的 特征值 7 文本 特征 测试 f 
= open examout . txt r newl = f . 
read newl = list map str newl . strip . 
split newv = np . array newl new _ test 
_ x = newv print new _ test _ x 
new _ pred _ y = clf . predict new 
_ test _ x . reshape 1 1 print new 
_ pred _ y 输出 结果 要 注意 我们 是 
对 单列 进行 测试 上文 中 ty = 3 y 
= vec ty 表示 的 是 只对 倒数 第三列 也 
就是 第一 个子 话题 民主制度 进行 训练 对 该 文本 
进行 判别 得出 的 是 其 在 民主制度 标 签下 
的 评分 5分 看来 很 相关 我 的 评分 制度 
是 1 5 1 为 不相关 5 为 很 相关 
注意到 函数 clf . predict new _ test _ x 
. reshape 1 1 该 函数 接收 的 必须 是 
一个 二维 数组 而 特征向量 只有 一维 所以 需要 reshape 
1 1 进行 转换 否则 会 报错 一点 说明 这里 
只 进行 了 少部分 文本 的 测试 大量 文本 测试 
还 尚需 时日 二 总结 反思 实现 了 SVM 并 
对其 有了 一定 了解 但是 内部 原理 由于 没有 时间 
看 相关 论文 所以 还是 不是 很懂 毕设 做完 在 
写 论文 的 时候 可以 多 查查 相关 材料 对 
scilearn 的 使用 有了/nr 比较 浅显 地 理解 并可以 熟练地 
读取 文本 及 表格 SVM 和 DecisionTree 表现 尚可 但是 
朴素 贝叶斯 的 分类 效果 就 比较 差 了 三个 
分类 均已 做完 限于 篇幅 只 写了 SVM 剩下 的 
分类 过两天 写 三 接下来 的 任务 怎么 将 结果 
展示 出来 该 展示 那些 内容 采用 哪种 形式 因为 
要做 三种 分类 准确度 的 对比 所以 先 学习 一下 
Python 的 表格 绘制 吧 明天 要给 学长 学姐 展示 
到 目前 为止 所做 的 工作 