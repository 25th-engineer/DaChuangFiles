作者 无影 随想 时间 2016年 3月 出处 https / / 
zhaokv . com / machine _ learning / 2016/03 / 
ml metric . html 声明 版权所有 转载 请 注明 出处 
在 使用 机器学习 算法 的 过程 中 针对 不同 场景 
需要 不同 的 评价 指标 在 这里 对 常用 的 
指标 进行 一个 简单 的 汇总 一 分类 1 . 
精确 率 与 召回率 精确 率 与 召回率 多 用于 
二分 类 问题 精确 率 Precision 指 的 是 模型 
判为 正 的 所有 样本 中 有 多少 是 真正 
的 正 样本 召回率 Recall 指 的 是 所有 正 
样本 有 多少 被 模型 判为 正 样本 即 召回 
设 模型 输出 的 正 样 本集 合为 $ A 
$ 真正 的 正 样 本集 合为 $ B $ 
则有 $ \ text { Precision } A B = 
\ frac { | A \ bigcap B | } 
{ | A | } \ text { Recall } 
A B = \ frac { | A \ bigcap 
B | } { | B | } $ 有时候 
我们 需要 在 精确 率 与 召回率 间 进行 权衡 
一种 选择 是 画出 精确 率 召回率 曲线 Precision Recall 
Curve 曲 线下 的 面积 被 称为 AP 分数 Average 
precision score 另外 一种 选择 是 计算 $ F _ 
{ \ beta } $ 分数 $ F _ { 
\ beta } = 1 + \ beta ^ 2 
\ cdot \ frac { \ text { precision } 
\ cdot \ text { recall } } { \ 
beta ^ 2 \ cdot \ text { precision } 
+ \ text { recall } } $ 当 $ 
\ beta = 1 $ 称为 $ F _ 1 
$ 分数 是 分类 与 信息检索 中最 常用 的 指标 
之一 2 . ROC 设 模型 输出 的 正 样 
本集 合为 $ A $ 真正 的 正 样 本集 
合为 $ B $ 所有 样本 集 合为 $ C 
$ 我们 称 $ \ frac { | A \ 
bigcap B | } { | B | } $ 
为 真正 率 True positive rate $ \ frac { 
| A B | } { | C B | 
} $ 为 假 正 率 False positive rate ROC 
曲线 适用于 二分 类 问题 以 假 正 率 为 
横坐标 真正 率 为 纵坐标 的 曲线图 如 AUC 分数 
是曲 线下 的 面积 Area under curve 越大 意味着 分类器 
效果 越好 3 . 对数 损失 对数 损失 Log loss 
亦 被 称为 逻辑 回归 损失 Logistic regression loss 或 
交叉 熵 损失 Cross entropy loss 对于 二分 类 问题 
设 $ y \ in \ { 0 1 \ 
} $ 且 $ p = { \ rm Pr 
} y = 1 $ 则 对 每个 样本 的 
对数 损失 为 $ L _ { \ rm log 
} y p = \ log { \ rm Pr 
} y | p = y \ log p + 
1 y \ log 1 p $ 可以 很容易 地 
将其 扩展到 多分 类 问题 上 设 $ Y $ 
为 指示 矩阵 即 当 样本 $ i $ 的 
分类 为 $ k $ 时$y/nr _ { i k 
} = 1 $ 设 $ P $ 为 估计 
的 概率 矩阵 即 $ p _ { i k 
} = { \ rm Pr } t _ { 
i k } = 1 $ 则 对 每个 样本 
的 对数 损失 为 $ L _ { \ log 
} Y _ i P _ i = \ log 
{ \ rm Pr } Y _ i | P 
_ i = \ sum \ limits _ { k 
= 1 } ^ { K } y _ { 
i k } \ log p _ { i k 
} $ 4 . 铰链 损失 铰链 损失 Hinge loss 
一般用 来使 边缘 最大化 maximal margin 铰链 损失 最 开始 
出现 在 二分 类 问题 中 假设 正 样本 被 
标记 为 1 负 样本 被 标记 为 1 $ 
y $ 是 真实 值 $ w $ 是 预测 
值 则 铰链 损失 定义 为 $ L _ { 
\ text { Hinge } } w y = \ 
max \ { 1 wy 0 \ } = | 
1 wy | _ + $ 然后 被 扩展到 多分 
类 问题 假设 $ y _ w $ 是 对 
真实 分类 的 预测 值 $ y _ t $ 
是 对 非 真实 分类 预测 中的 最大值 则 铰链 
损失 定义 为 $ L _ { \ text { 
Hinge } } y _ w y _ t = 
\ max \ { 1 + y _ t y 
_ w 0 \ } $ 注意 二 分类 情况 
下 的 定义 并 不是 多 分类 情况 下 定义 
的 特例 5 . 混淆 矩阵 混淆 矩阵 Confusion Matrix 
又 被 称为 错误 矩阵 通过 它 可以 直观 地 
观察 到 算法 的 效果 它 的 每 一列 是 
样本 的 预测 分类 每 一行 是 样本 的 真实 
分类 反过来 也 可以 顾名思义 它 反映 了 分类 结果 
的 混淆 程度 混淆 矩阵 $ i $ 行 $ 
j $ 列 的 原始 是 原本 是 类别 $ 
i $ 却被 分为 类别 $ j $ 的 样本 
个数 计算 完 之后 还 可以 对 之 进行 可视化 
6 . kappa 系数 kappa 系数 Cohen s kappa 用来 
衡量 两种 标注 结果 的 吻合 程度 标注 指 的 
是 把 N 个 样本 标注 为 C 个 互斥 
类别 计算公式 为 $ \ mathcal { K } = 
\ frac { p _ o p _ e } 
{ 1 p _ e } = 1 \ frac 
{ 1 p _ o } { 1 p _ 
e } $ 其中 $ p _ o $ 是 
观察 到 的 符合 比例 $ p _ e $ 
是 由于 随机性 产生 的 符合 比例 当 两种 标注 
结果 完全 相符 时 $ \ mathcal { K } 
= 1 $ 越 不相符 其 值 越小 甚至 是 
负 的 是不是 云 里来 雾里 去 的 现在 举个 
栗子 对于 50个 测试 样本 的 二分 类 问题 预测 
与 真实 分布 情况 如下 表 G R O U 
N D 1 0 P R E D I C 
T 1 2 0 5 0 1 0 1 5 
预测 与 真实 值 相符 共有 20 + 15个 则 
观察到 的 符合 比例 为 $ p _ o = 
20 + 15 / 50 = 0.7 $ 计算 $ 
p _ e $ 比较复杂 PREDICT 预测 为 1 的 
比例 为 0.5 GROUND 中 1 的 比例 为 0.6 
从 完全 随机 的 角度 来看 PREDICT 与 GROUND 均为 
1 的 概率 为 0.5 * 0.6 = 0.3 PREDICT 
与 GROUND 均为 0 的 概率 为 0.5 * 0.4 
= 0.2 则 PREDICT 与 GROUND 由于 随机性 产生 的 
符合 比例 为 0.2 + 0.3 = 0.5 即 $ 
p _ e = 0.5 $ 最后 求得 $ \ 
mathcal { K } = \ frac { p _ 
o p _ e } { 1 p _ e 
} = \ frac { 0.7 0.5 } { 1 
0.5 } = 0.4 $ 7 . 准确率 准确率 Accuracy 
衡量 的 是 分类 正确 的 比例 设 $ \ 
hat { y } _ i $ 是 是 第 
$ i $ 个 样本 预测 类别 $ y _ 
i $ 是 真是 类别 在 $ n _ { 
\ rm sample } $ 个 测试 样 本上 的 
准确率 为 $ { \ rm accuracy } = \ 
frac { 1 } { n _ { \ rm 
sample } } \ sum \ limits _ { i 
= 1 } ^ { n _ { \ rm 
sample } } 1 \ hat { y } _ 
i = y _ i $ 其中 $ 1 x 
$ 是 indicator function 当 预测 结果 与 真实 情况 
完全 相符 时 准确率 为 1 两者 越 不相符 准确率 
越低 虽然 准确率 适用 范围 很广 可 用于 多 分类 
以及 多 标签 等 问题 上 但在 多 标签 问题 
上 很 严格 在 有些 情况 下 区分度 较差 8 
. 海明 距离 海明 距离 Hamming Distance 用于 需要 对 
样本 多个 标签 进行 分类 的 场景 对于 给定 的 
样本 $ i $ $ \ hat { y } 
_ { ij } $ 是 对 第 $ j 
$ 个 标签 的 预测 结果 $ { y } 
_ { ij } $ 是 第 $ j $ 
个 标签 的 真实 结果 $ L $ 是 标签 
数量 则 $ \ hat { y } _ i 
$ 与 $ y _ i $ 间 的 海明 
距离 为 $ D _ { Hamming } \ hat 
{ y } _ i y _ i = \ 
frac { 1 } { L } \ sum \ 
limits _ { j = 1 } ^ L 1 
\ hat { y } _ { ij } \ 
neq y _ { ij } $ 其中 $ 1 
x $ 是 indicator function 当 预测 结果 与 实际 
情况 完全 相符 时 距离 为 0 当 预测 结果 
与 实际 情况 完全 不符 时 距离 为 1 当 
预测 结果 是 实际 情况 的 真子集 或 真 超集 
时 距离 介于 0 到 1 之间 我们 可以 通过 
对 所有 样本 的 预测 情况 求 平均 得到 算法 
在 测试 集上 的 总体 表现 情况 当 标签 数量 
$ L $ 为 1时 它 等于 1 Accuracy 当 
标签 数 $ L 1 $ 时 也有 较好 的 
区分度 不像 准确率 那么 严格 9 .   杰 卡德 
相似系数 杰 卡德 相似系数   Jaccard similarity coefficients 也是 用于 
需要 对 样本 多个 标签 进行 分类 的 场景 对于 
给定 的 样本 $ i $ $ \ hat { 
y } _ i $ 是 预测 结果 $ { 
y } _ i $ 是 真实 结果 $ L 
$ 是 标签 数量 则 第 $ i $ 个 
样本 的 杰 卡德 相似系数 为 $ J \ hat 
{ y } _ i y _ i = \ 
frac { | \ hat { y } _ i 
\ bigcap y _ i | } { | \ 
hat { y _ i } \ bigcup y _ 
i | } $ 它 与 海明 距离 的 不同 
之 处 在于 分母 当 预测 结果 与 实际 情况 
完全 相符 时 系数 为 1 当 预测 结果 与 
实际 情况 完全 不符 时 系数 为 0 当 预测 
结果 是 实际 情况 的 真子集 或 真 超集 时 
距离 介于 0 到 1 之间 我们 可以 通过 对 
所有 样本 的 预测 情况 求 平均 得到 算法 在 
测试 集上 的 总体 表现 情况 当 标签 数量 $ 
L $ 为 1时 它 等于 Accuracy 10 . 多 
标签 排序 在 这 节 我们 介绍 一些 更 精细 
化 的 多 标签 分类 效果 衡量 工具 设 真实 
标签 分类 情况 为 $ y \ in \ { 
0 1 \ } ^ { n _ \ text 
{ samples } \ times n _ \ text { 
labels } } $ 分类器 预测 情况 为 $ \ 
hat { f } \ in \ mathbb { R 
} ^ { n _ \ text { samples } 
\ times n _ \ text { labels } } 
$ 10.1 涵盖 误差 涵盖 误差 Coverage error 计算 的 
是 预测 结果 中 平均 包含 多少 真实 标签 适用于 
二分 类 问题 涵盖 误差 定义 为 $ coverage y 
\ hat { f } = \ frac { 1 
} { n _ \ text { samples } } 
\ sum \ limits _ { i = 1 } 
^ { n _ \ text { samples } } 
\ max \ limits _ { j y _ { 
ij } = 1 } \ text { rank } 
_ { ij } $ 其中 $ \ text { 
rank } _ { ij } = \ left | 
\ left \ { k \ hat { f } 
_ { ik } \ ge \ hat { f 
} _ { ij } \ right \ } \ 
right | $ 可以 看到 它 实际 衡量 的 是 
真实 标签 中 有 多少 排在 预测 结果 的 前面 
10.2 标签 排序 平均 精度 标签 排序 平均 精度 Label 
ranking average precision 简称 LRAP 它 比 涵盖 误差 更 
精细 $ LRAP y \ hat { f } = 
\ frac { 1 } { n _ \ text 
{ samples } } \ sum \ limits _ { 
i = 1 } ^ { n _ \ text 
{ samples } } \ frac { 1 } { 
| y _ i | } \ sum \ limits 
_ { j y _ { ij } = 1 
} \ frac { | \ mathcal { L } 
_ { ij } | } { \ text { 
rank } _ { ij } } $ 其中 $ 
\ mathcal { L } _ { ij } = 
\ left \ { k y _ { ik } 
= 1 \ hat { f } _ { ik 
} \ ge \ hat { f } _ { 
ij } \ right \ } $ $ \ text 
{ rank } _ { ij } = \ left 
| \ left \ { k \ hat { f 
} _ { ik } \ ge \ hat { 
f } _ { ij } \ right \ } 
\ right | $ 10.3 排序 误差 排序 误差 Ranking 
loss 进一步 精细 考虑 排序 情况 $ ranking y \ 
hat { f } = \ frac { 1 } 
{ n _ \ text { samples } } \ 
sum \ limits _ { i = 1 } ^ 
{ n _ \ text { samples } } \ 
frac { 1 } { | y _ i | 
n _ \ text { labels } | y _ 
i | } \ left | \ mathcal { L 
} _ { ij } \ right | $ 其中 
$ \ mathcal { L } _ { ij } 
= \ left \ { k l \ hat { 
f } _ { ik } \ hat { f 
} _ { ij } y _ { ik } 
= 1 y _ { il } = 0 \ 
right \ } $ 二 拟合 拟合 问题 比较 简单 
所 用到 的 衡量 指标 也 相对 直观 假设 $ 
y _ i $ 是 第 $ i $ 个 
样本 的 真实 值 $ \ hat { y } 
_ i $ 是 对 第 $ i $ 个 
样本 的 预测 值 1 . 平均 绝对误差 平均 绝对误差 
MAE Mean Absolute Error 又 被 称为 $ l1 $ 
范数 损失 $ l1 $ norm loss $ { \ 
rm MAE } y \ hat { y } = 
\ frac { 1 } { n _ { \ 
rm samples } } \ sum \ limits _ { 
i = 1 } ^ { n _ { \ 
rm samples } } | y _ i \ hat 
{ y } _ i | $ 2 . 平均 
平方 误差 平均 平方 误差 MSE Mean Squared Error 又 
被 称为 $ l2 $ 范数 损失 $ l2 $ 
norm loss $ { \ rm MSE } y \ 
hat { y } = \ frac { 1 } 
{ n _ { \ rm samples } } \ 
sum \ limits _ { i = 1 } ^ 
{ n _ { \ rm samples } } y 
_ i \ hat { y } _ i ^ 
2 $ 3 . 解释 变异 解释 变异   Explained 
variance 是 根据 误差 的 方差 计算 得到 的 $ 
{ \ rm explained variance } y \ hat { 
y } = 1 \ frac { { \ rm 
Var } \ { y \ hat { y } 
\ } } { { \ rm Var } { 
y } } $ 4 . 决定系数 决定系数 Coefficient of 
determination 又 被 称为 $ R ^ 2 $ 分数 
$ R ^ 2 y \ hat { y } 
= 1 \ frac { \ sum _ { i 
= 1 } ^ { n _ { \ rm 
samples } } y _ i \ hat { y 
} _ i ^ 2 } { \ sum _ 
{ i = 1 } ^ { n _ { 
\ rm samples } } y _ i \ bar 
{ y } ^ 2 } $ 其中 $ \ 
bar { y } = \ frac { 1 } 
{ n _ { \ rm samples } } \ 
sum _ { i = 1 } ^ { n 
_ { \ rm samples } } y _ i 
$ 三 聚 类 1 . 兰德 指数 兰德 指数 
Rand index 需要 给定 实际 类别 信息 $ C $ 
假设 $ K $ 是 聚 类 结果 $ a 
$ 表示 在 $ C $ 与 $ K $ 
中都 是 同类 别的 元素 对数 $ b $ 表示 
在 $ C $ 与 $ K $ 中都 是 
不同 类别 的 元素 对数 则 兰德 指数 为 $ 
{ \ rm RI } = \ frac { a 
+ b } { C _ 2 ^ { n 
_ { \ rm samples } } } $ 其中 
$ C _ 2 ^ { n _ { \ 
rm samples } } $ 数据 集中 可以 组成 的 
总 元素 对数 RI 取值 范围 为 $ 0 1 
$ 值 越大 意味着 聚 类 结果 与 真实 情况 
越 吻合 对于 随机 结果 RI 并 不能 保证 分数 
接近 零 为了实现 在 聚 类 结果 随机 产生 的 
情况 下 指标 应该 接近 零 调整 兰德 系数 Adjusted 
rand index 被 提出 它 具有 更高 的 区分度 $ 
{ \ rm ARI } = \ frac { { 
\ rm RI } E { \ rm RI } 
} { \ max { \ rm RI } E 
{ \ rm RI } } $ 具体 计算 方式 
参见 Adjusted Rand index ARI 取值 范围 为 $ 1 
1 $ 值 越大 意味着 聚 类 结果 与 真实 
情况 越 吻合 从 广义 的 角度 来讲 ARI 衡量 
的 是 两个 数据 分布 的 吻合 程度 2 . 
互信息 互信息 Mutual Information 也是 用来 衡量 两个 数据 分布 
的 吻合 程度 假设 $ U $ 与 $ V 
$ 是 对 $ N $ 个 样本 标签 的 
分配情况 则 两种 分布 的 熵 熵 表示 的 是 
不确定 程度 分别为 $ H U = \ sum \ 
limits _ { i = 1 } ^ { | 
U | } P i \ log P i H 
V = \ sum \ limits _ { j = 
1 } ^ { | V | } P j 
\ log P j $ 其中 $ P i = 
| U _ i | / N P j = 
| V _ j | / N $ $ U 
$ 与 $ V $ 之间 的 互信息 MI 定义 
为 $ { \ rm MI } U V = 
\ sum \ limits _ { i = 1 } 
^ { | U | } \ sum \ limits 
_ { j = 1 } ^ { | V 
| } P i j \ log \ left \ 
frac { P i j } { P i P 
j } \ right $ 其中 $ P i j 
= | U _ i \ bigcap V _ j 
| / N $ 标准化 后的/nr 互信息 Normalized mutual information 
为 $ { \ rm NMI } U V = 
\ frac { { \ rm MI } U V 
} { \ sqrt { H U H V } 
} $ 与 ARI 类似 调整 互信息 Adjusted mutual information 
定义 为 $ { \ rm AMI } = \ 
frac { { \ rm MI } E { \ 
rm MI } } { \ max H U H 
V E { \ rm MI } } $ 利用 
基于 互 信息 的 方法 来 衡量 聚 类 效果 
需要 实际 类别 信息 MI 与 NMI 取值 范围 为 
$ 0 1 $ AMI 取值 范围 为 $ 1 
1 $ 它们 都是 值 越大 意味着 聚 类 结果 
与 真实 情况 越 吻合 3 . 轮廓 系数 轮廓 
系数 Silhouette coefficient 适用 于 实际 类别 信息 未知 的 
情况 对于 单个 样本 设 $ a $ 是 与 
它 同 类别 中 其他 样本 的 平均 距离 $ 
b $ 是 与 它 距离 最近 不同 类别 中 
样本 的 平均 距离 轮廓 系数 为 $ s = 
\ frac { b a } { \ max a 
b } $ 对于 一个 样本 集合 它 的 轮廓 
系数 是 所有 样本 轮廓 系数 的 平均值 轮廓 系数 
取值 范围 是 $ 1 1 $ 同 类别 样本 
越 距离 相近 且 不同 类别 样本 距离 越远 分数 
越高 四 信息检索 信息检索 评价 是 对 信息 检索系统 性能 
主要 满足 用户 信息 需求 的 能力 进行 评估 与 
机器 学习 也 有 较大 的 相关性 感 兴趣 的 
可以 参考 这篇 不错 的 博文 四 总结 上面 介绍 
了 非常 多 的 指标 实际 应用 中 需要 根据 
具体 问题 选择 合适 的 衡量 指标 那么 具体 工作 
中 如何 快速 使用 它们 呢 优秀 的 Python 机器学习 
开源 项目 Scikit learn 实现 了 上述 绝 指标 的 
大多数 使用 起来 非常 方便 