Python 语言 实现 机器 学习 的 K 近邻 算法 写 
在前 面额 最近 开始 学习 机器学习 嘛 网上 找到 一本 
关于 机器 学习 的 书籍 名字 叫做 机器学习 实战 很 
巧 的 是 这 本书 里 的 算法 是 用 
Python 语言 实现 的 刚好 之前 我 学过 一些 Python 
基础知识 所以 这 本书 对于 我 来说 无疑 是 雪中送炭 
啊 接下来 我 还是 给 大家 讲讲 实际 的 东西 
吧 什么 是 K 近邻 算法 简单 的 说 K 
近邻 算法 就是 采用 测量 不同 特征值 之间 的 距离 
方法 来 进行 分类 它 的 工作 原理 是 存在 
一个 样本数据 集合 也 称作 训练样本 集 并且 样本 集中 
每个 数据 都 存在 标签 即 我们 知道 样本 集中 
每一 数据 与 所属 分类 的 对应 关系 输入 没有 
标签 的 新 数据 之后 将 新 数据 的 每个 
特征 与 样本 集中 数据 对应 的 特征 进行 比较 
然后 算法 提取 出 样本 集中 特征 最 相似 数据 
的 分类 标签 一般来说 我们 只 选择 样本 数据集 中前 
k 个 最 相似 的 数据 这 就是 K 近邻 
算法 名称 的 由来 提问 亲 你 造 K 近邻 
算法 是 属于 监督 学习 还是 无 监督 学习 呢 
使用 Python 导入 数据 从K/nr 近邻 算法 的 工作 原理 
中 我们 可以 看出 要想 实施 这个 算法 来 进行 
数据 分类 我们 手头上 得 需要 样本数据 没有 样本数据 怎么 
建立 分类 函数 呢 所以 我们 第一 步 就是 导入 
样本数据 集合 建立 名为 kNN . py 的 模块 写入 
代码 1 from numpy import * 2 import operator 3 
4 def createDataSet 5 group = array 1.0 1.1 1.0 
1.0 0 0 0 0.1 6 labels = A A 
B B 7 return group labels 代码 中 我们 需要 
导入 Python 的 两个 模块 科学计算/n 包/v NumPy/w 和/c 运算符/n 
模块/n NumPy 函数库 是 Python 开发 环境 的 一个 独立 
模块 大多数 Python 版本 里 没有 默认 安装 NumPy 函数库 
因此 这里 我们 需要 单独 安装 这个 模块 下载 戳 
这里 NumPy 有 很多 的 版本 这里 我 选择 的 
是 numpy 1 . 7.0 win32 superpack python2 . 7 
. exe 实现 K 近邻 算法 K 近邻 算法 的 
具体 思想 如下 1 计算 已知 类别 数据 集中 的 
点 与 当前 点 之间 的 距离 2 按照 距离 
递增 次序 排序 3 选取 与 当前 点 距离 最小 
的 k 个 点 4 确定 前 k 个 点 
所在 类别 的 出现 频率 5 返回 前 k 个 
点中 出现 频率 最高 的 类别 作为 当前 点 的 
预测 分类 Python 语言 实现 K 近邻 算法 的 代码 
如下 1 # coding utf 8 2 3 from numpy 
import * 4 import operator 5 import kNN 6 7 
group labels = kNN . createDataSet 8 9 def classify 
inX dataSet labels k 10 dataSetSize = dataSet . shape 
0 11 diffMat = tile inX dataSetSize 1 dataSet 12 
sqDiffMat = diffMat * * 2 13 sqDistances = sqDiffMat 
. sum axis = 1 14 distances = sqDistances * 
* 0.5 15 sortedDistances = distances . argsort 16 classCount 
= { } 17 for i in range k 18 
numOflabel = labels sortedDistances i 19 classCount numOflabel = classCount 
. get numOflabel 0 + 1 20 sortedClassCount = sorted 
classCount . iteritems key = operator . itemgetter 1 reverse 
= True 21 return sortedClassCount 0 0 22 23 my 
= classify 0 0 group labels 3 24 print my 
运算 结果 如下 输出 结果 是 B 说明 我们 新的 
数据 0 0 是 属于 B 类 代码/n 详解/v 相信/v 
有/v 很多/m 朋友/n 们/k 对/p 上面/f 这个/r 代码/n 有/v 很多/m 
不/d 理解/v 的/uj 地方/n 接下来 我 重点 讲解 几个 此 
函数 的 关键 点 以 方便 读者 们 和我/nr 自己 
回顾 一下 这个 算法 代码 classify 函数 的 参数 inX 
用于 分类 的 输入 向量 dataSet 训练样本 集合 labels 标签 
向量 k K 近邻 算法 中的 kshape 是 array 的 
属性 描述 一个 多 维 数组 的 维度 tile inX 
dataSetSize 1 把 inX 二维 数组 化 dataSetSize 表示 生成 
数组 后的/nr 行数 1 表示 列 的 倍数 整个 这 
一行 代码 表示 前 一个二维 数组 矩阵 的 每一个 元素 
减去 后 一个 数组 对应 的 元素 值 这样 就 
实现 了 矩阵 之间 的 减法 简单 方便 得 不让 
你 佩服 不行 axis = 1 参数 等于 1 的 
时候 表示 矩阵 中行 之间 的 数 的 求和 等于 
0 的 时候 表示 列 之 间数 的 求和 argsort 
对 一个 数 组 进行 非 降序 排序 classCount . 
get numOflabel 0 + 1 这 一行 代码 不得 不说 
的确 很 精美 啊 get 该 方法 是 访问 字典 
项的/nr 方法 即 访 问下 标键 为 numOflabel 的 项 
如果 没有 这 一项 那么 初始值 为 0 然后 把 
这 一项 的 值 加 1 所以 Python 中 实现 
这样 的 操作 就 只需要 一行 代码 实在 是 很 
简洁 高效 后话 K 近邻 算法 KNN 原理 以及 代码 
实现 差不多 就 这样 了 接下来 的 任务 就是 更加 
熟悉 它 争取 达到 裸 敲 的 地步 加油 