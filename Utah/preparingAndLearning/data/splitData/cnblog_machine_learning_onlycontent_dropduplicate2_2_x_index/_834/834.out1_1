转载 请 注明 出处 http / / www . cnblogs 
. com / ymingjingr / p / 4271742 . html 
目录 机器学习 基石 笔记 1 在 何时 可以 使用 机器学习 
1 机器学习 基石 笔记 2 在 何时 可以 使用 机器学习 
2 机器学习 基石 笔记 3 在 何时 可以 使用 机器学习 
3 修改版 机器学习 基石 笔记 4 在 何时 可以 使用 
机器学习 4 机器学习 基石 笔记 5 为什么 机器 可以 学习 
1 机器学习 基石 笔记 6 为什么 机器 可以 学习 2 
机器学习 基石 笔记 7 为什么 机器 可以 学习 3 机器学习 
基石 笔记 8 为什么 机器 可以 学习 4 机器学习 基石 
笔记 9 机器 可以 怎样 学习 1 机器学习 基石 笔记 
10 机器 可以 怎样 学习 2 机器学习 基石 笔记 11 
机器 可以 怎样 学习 3 机器学习 基石 笔记 12 机器 
可以 怎样 学习 4 机器学习 基石 笔记 13 机器 可以 
怎样 学 得 更好 1 机器学习 基石 笔记 14 机器 
可以 怎样 学 得 更好 2 机器学习 基石 笔记 15 
机器 可以 怎样 学 得 更好 3 机器学习 基石 笔记 
16 机器 可以 怎样 学 得 更好 4 九 Linear 
Regression 线性 回归 9.1 Linear Regression Problem 线性 回归 问题 
在 第二章 中 提到 的 银行 发放 信用卡 问题 通过 
是否 发放 信用卡 引出 了 二元 分类 问题 本章 再次 
使用 这个 例子 通过 发放 用户 多 大 额度 的 
信用卡 引出 回归 regression 或者说 线性 回归 linear regression 的 
问题 回归 问题 与 二元 分类 问题 最大 的 不同 
在于 输出 空间 二元 分类 的 输出 空间 为 二元 
标记 要么 + 1 要么 1 而 回归 问题 的 
输出 空间 是 整个 实数 空间 即 以 银行 发放 
信用卡 为例 输入 集合 依然 是 用户 的 特征 空间 
如 年龄 收入 等等 可以 使用 与 二元 分类 一致 
的 表示 方式 因为 输出 集合 的 转变 导致 回归 
问题 的 假设 函数 与 二元 分类 中的 有所不同 但 
思想 一致 仍需 考虑 对 每个 输入 样本 的 各个 
分量 进行 加权 求和 因此 最终 目标函数 f 含有 噪音 
使用 y 表示 的 表示 如 公式 9 1 所示 
公式 9 1 而 假设 函数 的 向量 表示 如 
公式 9 2 所示 公式 9 2 从 公式 9 
2 的 表示 方式 可以 看出 与 二元 分类 假设 
函数 的 表示 只差 了 一个 取 正负号 的 函数 
sign 使用 图像 的 方式 更 形象 的 描述 线性 
回归 如 1 所示 1 a 1 维 输入 空间 
的 线性 回归 b 2 维空间 的 线性 回归 1a 
中 表示 输入 空间 为 1 维 的 线性 回归 
表示 其中 圆圈 ○ 表示 输入 样本点 蓝色 直线 表示 
假设 函数 连接 圆圈 与 蓝色 直线 之间 的 红色 
线段 表示 样本 点到 假设 函数 的 距离 称为 剩余误差 
residuals 在 9 1b 中有 类似 表示 而设 计算法 的 
核心 思想 是 使 总体 剩余误差 最小 上一 章中 也 
提到 过 回归 使用 的 错误 衡量 是 平方 误差 
因此 如 公式 9 3 所示 公式 9 3 在 
线性 回归 问题 中 假设 函数 h 与 权值 向量 
存在着 一一对应 的 关系 因此 公式 9 3 通常 表示 
为 权值 向量 的 形式 如 公式 9 4 所示 
公式 9 4 同理 表示 如 公式 9 5 所示 
注意 这 里 使用 的 是 含有 噪音 的 形式 
因此 服从 联合 概率分布 P 公式 9 5 VC 限制 
可以 约束 各种 情况 的 学习 模型 当然 回归 类型 
的 模型 也被 也 受此 约束 想要 学习 到 知识 
只 需要 寻找 足够 小便 可以满足 够 小 的 需求 
9.2 Linear Regression Algorithm 线性 回归 算法 此节 重点 是 
如何 寻找 最小 的 为了 表达 的 简便 将 求和 
公式 转化成 向量 与 矩阵 的 形式 将 公式 9 
4 转换成 公式 9 6 的 形式 为 方便 显示 
将 向量 w 与 向量 x 位置 交换 因为 是 
向量 内积 符合 交换律 将 平方 求和 转换成 矩阵 平方 
的 形式 再/d 拆解/v 成/n 矩阵/n X/w 和/c 向量/n w/w 
与/p 向量/n y/w 的/uj 形式/n 公式 9 6 再回到 最初 
的 目标 寻找 一个 最小 的 如 公式 9 7 
所示 公式 9 7 求解 此 问题 需要 了解 左式/nr 
其 一维 d = 1时 示意图 如 2 所示 2 
一维 示意图 可以 看出 该 函数 为 连续 continuous 可微 
differentiable 的 凸 convex 函数 其中 连续 及 可微 的 
概念 学过 高等 数学 的 都 应该 有所 了解 凸函数 
说 的 通俗 点 就如 2 所示 像 一个 山谷 
一样 的 形式 注意 国内 数学 教材 中的 凹 函数 
是 这里 凸函数 的 定义 有点 囧 寻找 的 最佳 
便是 山谷 中 的 最低点 对应 图 中的 黑点 以 
数学 的 形式 表示 即 梯度 gradient 为 0 的 
点 我 理解 的 梯度 大概 意思 是 某一 向量 
其 各个 分量 的 偏 导数 组成 的 向量 梯度 
为 的 表示 方式 如 公式 9 8 所示 公式 
9 8 其中 即 梯度 符号 需要 寻找 的 是 
该 向量 满足 这里 的 下标 表示 线性 linear 的 
意思 紧接着 的 问题 是 如何 求解 时的/nr 继续 对 
公式 9 6 做 转化 如 公式 9 9 所示 
公式 9 9 其 中用 矩阵 A 表示 用 向量 
b 表示 用 标量 c 表示 紧接着 对 求 梯度 
向量 对 向量 求 导数 可能 很多 人 都 没有 
接触 甚至 没有 听说 过 最多 也 就是 了解 向量 
对 某 标量 求导 可 通过 3 在 w 为 
标量 情况下 的 对比 形式 理解 求 梯度 的 步骤 
3 a w 为 标量 时求的/nr 梯度 b w 为 
向量 时求的/nr 梯度 线性代数 的 美妙 之处 就 在于 此 
如此 的 相似 因此 可以 写成 公式 9 10 的 
形式 公式 9 10 令 公式 9 10 求 梯度 
结果 为 0 即使 最小 在 输入 空间 X 与 
输出 向y/nr 都为 已知 的 情况 下 如何 求解 最佳 
的 假设 函数 呢 求解 该 问题 分为 两种 情况 
一是 在 可逆 的 情况 下 求解 该 问题 很 
简单 将 公式 9 10 右边 的 部分 设为 0 
如 公式 9 11 公式 9 11 其中 表示 矩阵 
X 的 伪 逆 pseudo inverse 注意 此处 输入 矩阵 
X 在 很少 的 情况 下 才是 方阵 N = 
d + 1时 而 这种 伪 逆 矩阵 的 形式 
和 方阵 中的 逆 矩阵 具有 很多 相似 的 性质 
因此 才 有此 名称 还 有一点 需要 说明 在 大部分 
的 情况下 是 可逆 的 原因 是 在 进行 机器学习 
时 通常 满足 即 样本 数量 N 远远 大于 样本 
的 维度 d 加 1 因此在 中 存在 足够 的 
自由度 使其 可以满足 可逆 的 条件 另一种 是 不可逆的 情况 
实际上 可以 得到 许多 满足 条件 的 解 只 需要 
通过 其他 的 方式 求 解出 选择 其中 一个 满足 
条件 的 解 总 结下 线性 回归 算法 的 求解 
过程 首先 通过 已知 的 数据 集 构建 输入 矩阵 
X 与 输出 向量 y 如 公式 9 12 所示 
公式 9 12 通过 公式 9 12 直接 求得 伪 
逆 在 通过 公式 9 11 求得 假设 函数 如 
公式 9 13 所示 公式 9 13 9.3 Generalization Issue 
泛化 问题 本 小节 讨论 的 问题 理解 起来 不 
简单 目前 自己 还是 一知半解 如有 表述 不 正确 的 
地方 还 希望 指正 首先 要 回答 一个 问题 上一 
小节 中 使用 到 的 求解 最佳 假设 函数 的 
算法 是否 能 算是 机器学习 如 回答 不是 其 理由 
很 简单 求解 只 一步 就 完成 了 不像 前面 
章节 中 提到 的 学习 方法 需要 很 多步 的 
过程 实际上 这种 求解 方式 在 数学 中 被称作 解析 
解 analytical solution 或者 叫 封闭 解或/nr 闭式 解 closed 
form solution 此种 解是/nr 一些 严格 的 公式 给出 任意 
的 自变量 就 可以 求出 其 因变量 通常 与 数值解 
对应 因此 这种 求解 方式 并不 像 之前 提到 的 
PLA 等 算法 时 一步 一步 迭代 求出 的 的 
最 小解 回答 是 的 理由 更 看重 结果 这种 
直接 求解 方式 是 数学 推导 中的 精确 解 因此 
求出 的 一定 是的 最 小解 符合 求解 条件 而且 
求解 伪 逆 算法 此 方法 被 称为 高斯消 元法 
又见 高斯 查了/nr 一下 一 共有 110项 以 他 名字 
命名 的 成果 整个 机器学习 笔记 中 你 还会 不断 
的 听到 以 他 命名 的 成果 并非 如 公式 
展示 中 显示 的 那样 一步 就 可以 得出 最终 
结果 而是 需要 几次 的 循环 迭代 观察 了 矩阵 
求 伪 逆 的 程序 好像 是 三层 循环 也就 
印证 了 NG 在 他 机器学习 课程 中 提到 的 
矩阵 求 逆 的 复杂度 为 只是 被 程序 封装 
的 看不出 迭代 的 过程 而已 而 判断 是否 发生 
机器学习 过程 最 主要 标准 是 学习 到 的 是否 
够好 其实 通过 改进 VC 限制 也 可以 证明 在 
线性 回归 问题 中 VC 起到 了 很好 的 约束 
作用 即 找到 了 好 的 就 可以 保证 还 
不错 这里 不再 证明 因为 是 件 非常 繁琐 的 
过程 此处 只 需要 记住 VC 限制 不 只在 二元 
分类 问题 中 起作用 在 线性 回归 问题 中 也 
发挥 着 作用 但是 本节 使用 一种 比 VC 限制 
更容易 证明 的 保证 来 说明 解析 解也/nr 可以 得到 
一个 好 的 以下 给出 证明 为什么 解析 解 求出 
的 的 结果 是 好 的 而 有关 的 证明 
与 之 类似 首先 观察 的 平均 用 符号 表示 
可 写成 公式 9 14 所示 公式 9 14 其中 
表示 期望 不断 的 从 整体 样本空间 中 抽取 样本 
集 算 其 平均值 表示 关于 表示 数据 中 的 
噪音 N 为 每次 抽样 的 样本 数量 d + 
1 为 权值 向量 w 的 维度 从上 一节 中 
得知 可以 将 写成 公式 9 15 注意 与 使 
向量 形式 公式 9 15 其中 I 是 的 单位 
矩阵 可以 使用 的 H 矩阵 hat matrix 表示 此处 
通过 几何图形 来 更 具体 的 了解 H 矩阵 的 
物理 意义 如 4 所示 4 有关 H 矩阵 的 
几何图形 其中 紫色 向量 表示 实际 输出 向量 y 粉色 
区域 表示 输入 矩阵 X 乘以 不同 权值 向量 w 
所 构成 的 空间 从 这个 定义 得知 解析 解 
求得 最优 权值 向量 所 表示 的 输出 向量 也 
落在 该 空间 中 其中 为 N 维 向量 不难想象 
正是 实际 输出 向量 y 在 该 空间 上 的 
投影 而 绿色 虚线 表示 实际 输出 与 最优 假设 
输出 之间 的 差距 写作 从 上述 情况 可知 因此 
得知 H 矩阵 是 一个 投影 过程 向量 是 向量 
y 通过 矩阵 H 所做 的 投影 可以 将 矩阵 
H 理解为 一系列 旋转 放缩 的 动作 有 的 矩阵 
同样 也 是 一种 线性 变化 是 向量 y 通过 
的 线性 变化 得到 的 向量 在 4中 再 加入 
一点 元素 构成 5 5 加入 理想 的 目标 输出 
f x 如果 实际 输出 矩阵 y 由 理想 的 
目标 输出 f x 加上 噪音 部分 共同 构成 如图 
中 红色 和 黑色 虚线 部分 则 其中 的 形式 
也 可以 通过 噪音 按照 的 变换 方式 构成 因此 
得到 公式 9 16 公式 9 16 其中 是 通过 
的 迹 trace 得出 的 在 求解 之前 可以想象 因为 
经过 两次 转换 所 得到 的 还是 第一次 时的/nr 误差 
向量 trace I H 的 求解 过程 如 公式 9 
17 这里 为 什么 使 用到 迹 我 至今 都不/nr 
知道 望 大神 指教 根据 迹 的 性质 根据 迹 
的 性质 公式 9 17 最终 介绍 下 该 I 
H 这种 转换 的 物理 意义 原来/d 有/v 一个/m 有N个/nr 
自由度/d 的/uj 向量/n y/w 投影 到 一个 有d+/nr 1 维 
的 空间 x 代表 一列 的 自由度 即 单一 输入 
样本 的 参数 而 余数 剩余 的 自由度 最大 只有 
N d + 1 种 最终 可以 写出 的 结果 
同理 也 可以 写出 的 噪音 表示 如 公式 9 
18 和 公式 9 19 所示 公式 9 18 公式 
9 19 这个 证明 更为 复杂 我 也 没有 找到 
相关 资料 就不 证明了 在此 只 介绍 一下 在 哲学 
意义 上 两者 之间 存在 这个 差异 的 原因 因为 
前者 做了 优化 所以 有 机会 比 「 理想 值 
」 多 fit 数据 中的 噪音 一点点 所以 会比 「 
理想 值 」 好 一点 但 的 部份 则要 付出代价 
想象 在 测试 的 时候 拿到 了 与 训练 数据 
「 完全 不同 」 的 噪音 所以 可能 反而 多 
远离 理想 值 一些 从 上面 两个 公式 可以 得到 
一个 学习 鸿沟 图 如 6 所示 6 机器 学习 
的 学习 鸿沟 其中 在 N 趋于 无穷大 时 与 
两者 都会 趋 近于 noise level 的 值 即 泛化 
错误 之间 的 差距 至此 可以 表明 在 线性 回归 
中 可以 寻找 到 很好 的 因此 线性 回归 可以 
学习 第一 次 吐糟 这 一节 的 内容 我 整整 
写了 一天 是 开始 写 笔记 至今 第一 次 一个 
小节 写了 一天 时间 普通 情况 边玩 边写 一天 也 
可以 写 2 到 3 小节 主要 是 这 节 
内容 确实 很 抽象 而且 很多 证明 都 没有 给出 
给出 的 证明 也 没有 解释 清楚 可能 是 我 
太笨 了 唉 其中 迹 的 证明 就是 我 根据 
提示 自己 整理 的 如 有错误 请 指正 如果 你 
了解 这 部分 为什么 莫名其妙 的 使用 了 迹 的 
概念 也请 指点 下 我 9.4 Linear Regression for Binary 
Classification 使用 线性 回归 做 二元 分类 首先 对比 二元 
线性 分类 与 线性 回归 之间 的 差异 分别 在 
三个 部分 进行 对比 输出 空间 假设 函数 和 错误 
衡量 函数 如 7 所示 7 二元 线性 分类 与 
线性 回归 的 对比 从 求解 问题 的 难度 考虑 
二元 分类 的 求解 是 一个 NP 难 问题 只能 
使用 近似 求解 的 方式 而 线性 回归 通过 求 
解析 解 求解 方便 程序 编写 也 简单 因此 考虑 
能否 通过 求解 线性 回归 的 方式 求 二元 分类 
问题 因为 二元 分类 的 输出 空间 { 1 + 
1 } 属于 线性 回归 的 输出 空间 即 其中 
数据集 的 标记 大于 零 的 表示 + 1 小于 
零 的 表示 1 通过 线性 回归 求得 的 解析 
解 直接 得出 最优 假设 但是 这种 推理 只 符合 
直觉 而 如何 使用 数学知识 去 说明 这种 方式 的 
合理性 呢 观察 两种 错误 衡量 方式 和 分别 表示 
为 公式 9 20 和 公式 9 21 公式 9 
20 公式 9 21 观察 两 公式 的 共同 特点 
都 含有 这一 向量 内积 的 形式 如果 将 作为 
横轴 将 err 结果 作为 纵轴 可以 画出 8 其中 
8a 为 y = + 1时 两 err 值 的 
图像 表示 而 8b 为 y = 1时 两 err 
值 的 图像 表示 两幅 图中 红色 的 线 表示 
蓝色 的 先 表示 8 a y = + 1时 
两 err 值 的 表示 b y = 1时 两 
err 值 的 表示 从 图中 得出 公式 9 22 
的 结论 公式 9 22 回忆 下 第七章 中 证明 
的 二元 分类 下 的 上限 结合 公式 9 22 
的 结论 得 公式 9 23 公式 9 23 因此 
二元 分类 问题 得到 了 一个 更 宽松 的 上界 
但是 也 是 一种 更 有效率 的 求解 方式 在 
实际 运用 中 一般/a 都将/nr 通过/p 线性/n 回归/v 求得/v 的/uj 
解析/vn 解/v 作为/v PLA/w 或者/c pocket/w 的/uj 初始值/l 达到 快速 
求解 的 目的 