机器学习 是 时下 非常 流行 的 话题 而 Tensorflow 是 
机器 学习 中 最 有名 的 工具包 TensorflowSharp 是 Tensorflow 
的 C # 语言 表述 本文 会对 TensorflowSharp 的 使用 
进行 一个 简单 的 介绍 本文 会 先 介绍 Tensorflow 
的 一些 基本 概念 然后 实现 一些 基本 操作 例如 
数字 相 加等 运算 然后 实现 求 两个 点 x1 
y1 和 x2 y2 的 距离 最后 通过 这些 前置 
基础 和 一些 C # 代码 实现 使用 KNN 方法 
识别 MNIST 手写 数字 集合 前半部 分 阅读 本文 绝对 
不 需要 任何 机器学习 基础 因为 我 现在 也 才 
刚刚 入门 行文 不准确 之处 难免 敬请 见谅 本文 的 
后半 部分 还 在 整理 之中 1 . 什么 是 
机器 学习 用 最最 简单 的话 来说 机器学习 就是 不断 
改进 一个 模型 的 过程 使之 可以 更好 的 描述 
一组 数据 的 内在 规律 假设 我们 拿到 若干人 的 
年龄 a1 a2 a3 和 他们 的 工资 b1 b2 
b3 此时 我们 就 可以 将 这些 点 画在 一个二维 
直角 坐标系 中 包括 a1 b1 a2 b2 等等 这些 
就 称为 输入 或 训练 数据 我们 可以 用 数学 
的 最小二乘 法 拟合 一条 直线 这样 就 可以 得到 
最好 的 可以 描述 这些 数据 的 规律 y = 
ax + b 了 当然 因为 我们 有 很多 个 
点 所以 它们 可能 不 在 一条 直线 上 因此 
任何 的 直线 都 不会 过 它们 所 有的 点 
即 一定会 有 误差 但 对于 电脑 来说 它 可以 
使用 一种 截然不同 的 方式 来 得到 y = ax 
+ b 中 a b 的 值 首先 它/r 从/p 
一个/m 随便/d 指定/v 的/uj a/w 和b/nr 出发/v 例如 a = 
100 b = 1 然后 它 算出 y = 100 
a1 + 1 的 值 和 b1 的 区别 y 
= 100 a2 + 1 和 b2 的 区别 等等 
它 发现 误差 非常大 此时 它 就会 调整 a 和b的/nr 
值 通过 某种 算法 使得 下一次 的 误差 会 变小 
如果 下次 的 误差 反而 变得 更大 了 那就 说明 
要么 是 初始值 a b 给 的 不好 要么 是 
y = ax + b 可能 不是 一个 好 的 
模型 可能 一个 二次方程 y = a ^ 2 + 
bx + c 更好 等等 经过 N 轮 调整 这 
称为 模型 的 训练 误差 的 总和 可能 已经 到 
了 一个 稳定 的 较小 的 值 误差 小时 a 
和b的/nr 调整 相对 当然 也会 较小 此时 的 a 和b/nr 
就会 十分 接近 我们 使用 最 小二 乘法 做 出来 
的 值 这时 就 可以 认为 模型 训练 完成 了 
当然 这 只是 机器学习 最 简单 的 一个 例子 使用 
的 模型 也 只是 线性 的 直线 方程 如果 使用 
更加 复杂 的 模型 机器学习 可以 做出 十分 强大 的 
事情 2 . 环境 初始化 我 使用 VS2017 创建 一个 
新的 控制台 应用 然后 使用 下面 的 命令 安装 TensorflowSharp 
nuget install T e n s o r F l 
o w h a r p T e n s 
o r f l o w h a r p 
的 源码 地址 https / / github . com / 
migueldeicaza / TensorFlowSharp 如果 在 运行 时 发现 问题 找 
不到 libtensorflow . dll 则 需要 访问 http / / 
ci . tensorflow . org / view / Nightly / 
job / nightly libtensorflow windows / l a s t 
u c c e s s f u l B 
u i l d / artifact / lib _ package 
/ libtensorflow cpu windows x86 _ 64 . zip 下载 
这个 压缩包 然后 在 下载 的 压缩包 中的 \ lib 
中找到 tensorflow . dll 将 它 改名 为 libtensorflow . 
dll 并在 你 的 工程 中 引用 它 这样一来 环境 
初始化 就 完成 了 3 . TensorflowSharp 中的 概念 TensorflowSharp 
/ Tensorflow 中 最重要 的 几个 概念 图 Graph 它 
包含 了 一个 计算 任务 中 的 所有 变量 和 
计算 方式 可以 将 它 和C#/nr 中的 表达式 树 进行 
类比 例如 一个 1 + 2 可以 被 看作 为 
两个 常量 表达式 以 一个 二元运算 表达式 连接起来 在 Tensorflow 
的 世界 中 则 可以 看成 是 两个 tensor 和 
一个 op operation 的 缩写 即 操作 简单 来说 做一个 
机器 学习 的 任务 就是 计算 一张 图 在 计算 
图 之前 当然 要把 图 建立 好 例如 计算 1 
+ 2 * 3 再开 根号 是 一个 包括 了 
3个 tensor 和 3个 Op 的 图 不过 Tensorflow 的 
图 和 常规 的 表达式 还 有所 不同 Tensorflow 中的 
节点 变量 是 可以 被 递归 的 更新 的 我们 
所说 的 训练 也 就是 不停 的 计算 一个 图 
获得 图 的 计算 结果 再 根据 结果 的 值 
调整 节点 变量 的 值 然后 根据 新的 变量 的 
值 再 重新 计算 图 如此 重复 直到 结果 令人满意 
小于 某个 阈值 或 跑到 了 一个 无穷大 / 小 
这说明 图 的 变量 初始值 设置 的 有问题 或者 结果 
基本 不变 了 为止 会话 Session 为了 获得 图 的 
计算 结果 图 必须 在 会话 中被 启动 图 是 
会话 类型 的 一个 成员 会话 类型 还 包括 一个 
runner 负责 执行 这张 图 会话 的 主要 任务 是 
在 图 运算 时 分配 CPU 或 GPU 张量 tensor 
Tensorflow 中 所有 的 输入输出 变量 都是 张量 而 不是 
基本 的 int double 这样 的 类型 即使 是 一个 
整数 1 也 必须 被 包装 成 一个 0 维 
的 长度 为 1 的 张量 1 一个 张量 和 
一个 矩阵 差不多 可以 被 看成 是 一个 多维 的 
数组 从最/nr 基本/n 的/uj 一维/m 到/v N/w 维/v 都/d 可以/c 
张量 拥有 阶 rank 形状 shape 和 数据类型 其中 形状 
可以 被 理解 为 长度 例如 一个 形状 为 2 
的 张量 就是 一个 长度 为 2 的 一维 数组 
而 阶 可以 被 理解 为 维数 阶 数学 实例 
Python 例子 0 纯 量 只有 大小 s = 4831 
向量 大小 和 方向 v = 1.1 2.2 3.3 2 
矩阵 数据表 m = 1 2 3 4 5 6 
7 8 9 33 阶 张量 数据 立体 t = 
2 4 6 8 10 12 14 16 18 Tensorflow 
中的 运算 op 有 很多 很多 种 最 简单 的 
当然 就是 加减乘除 它们 的 输入 和 输出 都是 tensor 
Runner 在 建立 图 之后 必须 使用 会话 中的 Runner 
来 运行图 才能 得到 结果 在 运行图 时 需要 为 
所有 的 变量 和 占位符 赋值 否则 就会 报错 4 
. TensorflowSharp 中的 几类 主要 变量 Const 常量 这很好 理解 
它们 在 定义 时就/nr 必须 被 赋值 而且 值 永远 
无法 被 改变 Placeholder 占位符 这 是 一个 在 定义 
时 不需要 赋值 但在 使用 之前 必须 赋值 feed 的 
变量 通常 用作 训练 数据 Variable 变量 它/r 和/c 占位符/i 
的/uj 不同/a 是/v 它/r 在/p 定义/n 时/n 需要/v 赋值/n 而且 
它 的 数值 是 可以 在 图 的 计算 过程 
中 随时 改变 的 因此 占位符 通常用 作图 的 输入 
即 训练 数据 而 变量 用作 图中 可以 被 训练 
或 学习 的 那些 tensor 例如 y = ax + 
b 中的 a 和b/nr 5 . 基本 运算 下面 的 
代码 演示 了 常量 的 使用 / / 基础 常量 
运算 演示 了 常量 的 使用 static void BasicOperation { 
using var s = new TFSession { var g = 
s . Graph / / 建立 两个 TFOutput 都是 常数 
var v1 = g . Const 1.5 var v2 = 
g . Const 0.5 / / 建立 一个 相加 的 
运算 var add = g . Add v1 v2 / 
/ 获得 runner var runner = s . GetRunner / 
/ 相加 var result = runner . Run add / 
/ 获得 result 的 值 2 Console . WriteLine $ 
相加 的 结果 { result . GetValue } } } 
使用 占位符 / / 基础 占位符 运算 static void B 
a s i c P l a c e h 
o l d e r O p e r a 
t i o n { using var s = new 
TFSession { var g = s . Graph / / 
占位符 一种 不 需要 初始化 在 运算 时 再提供 值 
的 对象 / / 1 * 2 的 占位符 var 
v1 = g . Placeholder TFDataType . Double new TFShape 
2 var v2 = g . Placeholder TFDataType . Double 
new TFShape 2 / / 建立 一个 相乘 的 运算 
var add = g . Mul v1 v2 / / 
获得 runner var runner = s . GetRunner / / 
相加 / / 在 这里 给 占位符 提供 值 var 
data1 = new double { 0.3 0.5 } var data2 
= new double { 0.4 0.8 } var result = 
runner . Fetch add . AddInput v1 new TFTensor data1 
. AddInput v2 new TFTensor data2 . Run var dataResult 
= double result 0 . GetValue / / 获得 result 
的 值 Console . WriteLine $ 相乘 的 结果 { 
dataResult 0 } { dataResult 1 } } } 在 
上面 的 代码 中 我们 使用 了 fetch 方法 来 
获得 数据 Fetch 方法 用来 帮助 取回 操作 的 结果 
上面 的 例子 中 操作 就是 add 我们 看到 整个 
图 的 计算 是 一个 类似 管道 的 流程 在 
fetch 之后 为 占位符 输入 数据 最后 进行 运算 使用 
常量 表示 矩阵 / / 基础 矩阵 运算 static void 
B a s i c M a t r i 
x O p e r a t i o n 
{ using var s = new TFSession { var g 
= s . Graph / / 1x2 矩阵 var matrix1 
= g . Const new double { { 1 2 
} } / / 2x1 矩阵 var matrix2 = g 
. Const new double { { 3 } { 4 
} } var product = g . MatMul matrix1 matrix2 
var result = s . GetRunner . Run product Console 
. WriteLine 矩阵 相乘 的 值 + double result . 
GetValue 0 0 } } 6 . 求 两个 点 
的 距离 L1 L2 求 两点 距离 实际上 就是 若干 
操作 的 结合 而已 我们 知道 x1 x2 y1 y2 
的 距离 为 Sqrt x1 x2 ^ 2 + y1 
y2 ^ 2 因此 我们 通过 张量 的 运算 获得 
x1 x2 y1 y2 通过 Sub x1 x2 ^ 2 
y1 y2 ^ 2 通过 Pow 然后 把这两 个数 加起来 
这 需要 ReduceSum 运算符 最后 开 根 就 可以 了 
我们 把 整个 运算 赋 给 变量 distance 然后 fetch 
distance / / 求 两个 点 的 L2 距离 static 
void DistanceL2 TFSession s TFOutput v1 TFOutput v2 { var 
graph = s . Graph / / 定义 求 距离 
的 运算 / / 这里 要 特别 注意 如果 第一 
个 系数 为 double 第二个 也 需要 是 double 所以 
传入 2d 而不是 2 var pow = graph . Pow 
graph . Sub v1 v2 graph . Const 2d / 
/ ReduceSum 运算 将 输入 的 一串 数字 相加 并 
得出 一个 值 而 不是 保留 输入 参数 的 size 
var distance = graph . Sqrt graph . ReduceSum pow 
/ / 获得 runner var runner = s . GetRunner 
/ / 求 距离 / / 在 这里 给 占位符 
提供 值 var data1 = new double { 6 4 
} var data2 = new double { 9 8 } 
var result = runner . Fetch distance . AddInput v1 
new TFTensor data1 . AddInput v2 new TFTensor data2 . 
Run Console . WriteLine $ 点 v1 和 v2 的 
距离 为 { result 0 . GetValue } } 最后 
我们 根据 目前 所学 实现 KNN 识别 MNIST 7 . 
实现 KNN 识别 MNIST 1 什么 是 KNNK 最 近邻 
k Nearest Neighbor KNN 分类 算法 是 一个 理论 上 
比较 成熟 的 方法 也是 最 简单 的 机器学习 算法 
之一 该 方法 的 思路 是 如果 一个 样本 在 
特征 空间 中的 k 个 最 相似 即 特征 空间 
中最 邻近 的 样本 中 的 大多数 属于 某 一个 
类别 则 认为 该 样本 也 属于 这个 类别 图中 
绿色 圆 要被 决定 赋予 哪个 类 是 红色 三角形 
还是 蓝色 四方形 如果 K = 3 由于 红色 三角形 
所占 比例 为 2/3 绿色 圆 将被 赋予 红色 三角形 
那个 类 如果 K = 5 由于 蓝色 四方形 比例 
为 3/5 因此 绿色 圆 被 赋予 蓝色 四方形 类 
在 进行 计算 时 KNN 就 表现 为 首先 获得 
所有 的 数据 然后 对 一个 输入 的 点 找到 
离 它 最近 的 K 个 点 通过 L1 或 
L2 距离 然后 对这 K 个 点 所 代表 的 
值 找出 最多 的 那个 类 那么 这个 输入 的 
数据 就 被认为 属于 那个 类 对 MNIST 数据 的 
KNN 识别 在 读入 若干 个 输入 数据 和 代表 
的 数字 之后 逐个 读入 测试数据 对 每个 测试数据 找到 
离 他 最近 的 K 个 输入 数据 和 代表 
的 数字 找出 最多 的 代表 数字 A 此时 测试数据 
就被 认 为 代表 数字 A 因此 使用 KNN 识别 
MNIST 数据 就 可以 化 为求 两个 点 群 的 
距离 的 问题 MNIST 数据集 MNIST 是 一个 非常 有名 
的 手写 数字 识别 的 数据集 它 包含 了 6万 
张 手写 数字 图片 例如 当然 对于 我们 人类 而言 
识别 上面 四幅 图 是 什么 数字 是 十分 容易 
的 理由 很 简单 就是 看着 像 比如 第一张 图 
看着 就像 5 但 如果 是 让 计算机 来 识别 
它 可 无法 理解 什么 叫 看着 像 就 显得 
非常 困难 实际上 解决 这个 问题 有 很多 种 方法 
KNN 是 其中 最 简单 的 一种 除了 KNN 之外 
还 可以 使用 各种 类型 的 神经 网络 我们 可以 
将 每个 图片 看成 一个 点 的 集合 实际上 在 
MNIST 输入 中 图片 被 表示 为 28 乘 28 
的 一个 矩阵 例如 当 我们 成功 读取 了 一张 
图 之后 将 它 打印 出来 会 发现 结果 是 
这样 的 做 了 一些 处理 其中 数字 均为 byte 
类型 0 255 数字 越大 代表 灰度 越深 当然 0 
就 代表 白色 了 因此 你 可以 想象 上面 的 
那张 图 就是 一个 手写 的 2 如果把 上图 的 
000 换成 3个 空格 可以 看 的 更 清楚 对于 
每 张 这样 的 图 MNIST 提供 了 它 的 
正确 答案 即 它 应该 是 代表 哪个 数字 被 
称为 label 上图 的 label 显然 就是 2 了 因此 
每张 输入 的 小 图片 都是/nr 一个 28 乘 28 
的 矩阵 含有 784个 数字 那么 我们 当然 也 可以 
计算 任意 两个 小 图片 的 距离 它 就是 784个 
点 和 另外 784个 点 的 距离 之和 因此 如果 
两张 图 的 距离 很小 那么 它们 就 看着 像 
在 这里 我们 可以 有 很多 定义 距离 的 方式 
简单 起见 我们 就 将 两点 的 距离 定义 为 
L1 距离 即 直接 相减 之后 取 绝对值 例如 如果 
两个 图片 完全相同 784个/mq 数字/n 位置/v 和值都/nr 一样/r 那么 它们 
的 距离 为 0 如果 它们 仅有 一个 数字 不同 
一个 是 6 一个 是 8 那么 它们 的 距离 
就是 2 那么 在 简单 了解 了 什么 是 KNN 
之后 我们 的 任务 就 很 清楚 了 获得 数据 
把 数据 处理 为 一种 标准 形式 拿出 数据 中 
的 一部分 例如 5000张 图片 作为 KNN 的 训练 数据 
然后 再从 数据 中 的 另一 部分 拿 一张 图片 
A 对这 张 图片 A 求 它 和 5000张 训练 
图片 的 距离 并 找出 一张 训练 图片 B 它 
是 所有 训练 图片 中 和A/nr 距离 最小 的 那张 
这 意味着 K = 1 此时 就 认为 A 所 
代表 的 数字 等同于 B 所 代表 的 数字 b 
如果 A 的 label 真的 是 b 那么 就 增加 
一次 获胜 次数 通过 多次 拿 图片 我们 就 可以 
获得 一个 准确率 获胜 的 次数 / 拿 图片 的 
总次数 最后 程序 的 输出 如下 在下 一 篇 文章 
中 会 详细 分析 如何 实现 整个 流程 