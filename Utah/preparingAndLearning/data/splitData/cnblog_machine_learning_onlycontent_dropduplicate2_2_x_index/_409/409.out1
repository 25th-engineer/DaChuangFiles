唠嗑 唠嗑 依旧 是 每一次 随便 讲 两句 生活 小事 
表示 最近 有点 懒 可能 是 快要 考试 的 原因 
外加 这 两天 都有 笔试 和 各种 面试 让 心情 
变得 没 那么 安静 的 敲 代码 没 那么 安静 
的 学习 算法 搞得/i 第一次/m 和/c 技术/n 总监/n 聊天/nz 的/uj 
时候/n 都/d 不太/i 懂/v 装饰/n 器/n 这个/r 东东/ns 甚至 不 
知道 函 数式 编程 是 啥 昨天 跟 另外 一个 
经理 聊天 的 时候 也是 没能 把 自己 学习 的 
算法 很好 的 表达 出来 真是 饱暖 思 * * 
啊 额 好像 用词不当 反正 就是 人 的 脑袋 除了 
想着 吃肉 还要 多 运动 运动 幸好 的 是 每天 
晚上 的 瑜伽 能够 让 自己 足够 沉下 心来 冷静 
冷静 回想 起 当初 的 各种 面试 现在 的 自己 
毫无疑问 能够 很好 的 表达 那些问题 但是 很多 时候 贵在 
反应速度 所以 自己 虽然 反应 不 迟钝 但是 回答 的 
不 完美 也 是 平时 没有 反复 巩固 知识 的 
结果 不 扯了 写 笔记 咯 接着 上一 篇文章 python 
机器学习 入门 正文 在 前面 的 入门 文章 中 主要 
介绍 了 机器 学习 任务 重 的 两个 算法 监督 
学习 和非/nr 监督 学习 其中 在 监督 学习 中 最重要 
的 两个 东西 分别 是 回归 和 分类 预测 这里 
我们 主要 讲 回归 预测 上 一节 中 估计 很多 
人 看到 一大堆 文字描述 就很 头疼 表示 这 一节 会 
尽量 以 例子 讲解 其中 例子 的 实现 也是 python 
编程 求得 结果 哦 下 一篇 的 文章 将 会 
具体 的 实现 一个 数据 的 爬 取 分析 以及 
训练 最终 预测 流程 1 回归 的 来源 回归 这一 
词 的 是 达尔文 的 表兄弟 发明 的 天才 都 
一家 去了 话说 这个 表 兄弟 一 开始 是 利用 
豌豆 种子 双亲 来 预测 下一代 的 尺寸 后来 就 
发现 有 一些 规律 可循 因此 就 观察 到 人类 
的 遗传 上面 发现 如果 双亲 的 身高 比 平均 
高度 高 的话 子女 的 身高 也 倾向 于 较高 
的 高度 但 不会 超过 双亲 话说 这 句话 在 
我 身边 完美 体现 害 我 苦恼 为啥 是 家里 
最矮 的 这种 现象 即 孩子 的 高度 向着 平均 
身高 回退 回归 虽然 说 数值 预测 与 回退 现象 
关系 不是 很大 但是 人家 是 达尔文 的 表兄弟 所以 
就 引用 了 人家 的 指定 学术 用 名 啦 
~ 上 一节 我们 讲到 的 房价 月 预测 问题 
实际上 就是 输入 变量 房价 x 并 映射 输出 到 
一个 连续 的 预期 结果 函数 f x 中 具体来说 
假设 我们 有 这么 一群 数据 组合 x i y 
i 其中 i = 1 . . . m 也 
就是 一 共有 m 个 数据 组合 样本 现在 借助 
机器学习 实战 这本书 给出 的 数据 ex0 . zip 文件 
来 实现 该 数据集 的 回归 预测 一 首先 在 
附件 中 下载 并 打开 数据文件 ex0 . txt 观察到 
数据 中 的 第一 列 都是 1 那么 很明显 我们 
可以 将 后面 的 两列 作为 x y 值 虽然 
目前 并不 知道 这些 数据 在 实际 应用 中 的 
名称 所有 的 数据 列 与 列 之间 的 间隔 
都是 tab 符号 分割 每一个 样本数据 各占 一行 这 方便 
我们 后期 的 数据 读取 好 的 分析 数据 最 
方便 的 方式 就是 可视化 数据 那么 画 个 图 
看看 数据 的 趋势 如何 1.1 准备 数据 使用 Python 
从 文本文件 中 导入 数据 创建 名为 reg . py 
文件 本节 所有 的 代码 都 保存 在 该 文件 
中 在 画图 之前 我们 需要 将 准备 一下 步骤 
包括 读取数据 将 数据 解析 保存 到 矩阵 中 代码 
如下 1 # coding = utf 8 2 _ _ 
author _ _ = wing1995 3 4 5 from numpy 
import * 6 7 8 9 def file2matrix filename 10 
f = open filename 11 contents = f . readlines 
12 length = len contents # 得到 文件 内容 的 
行数 13 Mat = zeros length 3 # 创建 一个 
空 矩阵 用于 存储 文件 内容 14 index = 0 
15 for line in contents 16 line = line . 
strip # 去除 每 一行 的 换行符 17 data = 
line . split \ t 18 Mat index = data 
# 将 每 一列 数据 按照 行 索引 存放 到 
空 矩阵 19 index + = 1 20 return mat 
Mat 好 的 现在 你 有了 矩阵 可以 通过 任何 
方式 索引 矩阵 例如 索引 第二列 数据 1 data _ 
file = C \ Users \ wing1995 \ Desktop \ 
m a c h i n e l e a 
r n i n g i n a c t 
i o n \ Ch08 \ ex0 . txt 2 
dataMat = file2matrix data _ file 3 print dataMat 1 
ps 关于 数据 中 的 第一 列 数据 为啥 全是 
1 后 面会 讲到 它 属于 默认 的 特征值 x0 
1.2 分析 数据 使用 Matplotlib 创建 散点图 主要 绘图 用到 
了 以下 函数 绘制 用 基本 函数 plt . scatter 
plt . plot plt . bar 自定义 轴 和 标题 
函数 plt . xlabel plt . ylabel plt . title 
基本 图形 显示 清除 函数 plt . show plt . 
clf 具体 函数 的 画法 可以 通过 help 命令 查看 
基础知识 这里 就 不再 赘述 直接 在 reg . py 
文件 中 添加 画图 函数 1 def my _ scatter 
dataMat 2 x = dataMat 1 3 y = dataMat 
2 4 plt . xlabel x 5 plt . ylabel 
y 6 plt . scatter x y 7 plt . 
show 效果图 如下 可以 很 明显 的 看得出来 图片 呈现 
上升 的 趋势 而且 如果 想用 一条线 来 拟 合该 
趋势 的话 应该 是 一条 直线 因此 我们 给出 拟合 
曲线 的 假设 函数 所谓 的 拟合 就是 尝试 建立 
并 调用函数 h x 让 输入 数据 x 映 射到 
输出 结果 y 以上 样本 有点 大 举个 小 例子 
现在 随机 猜测 假设 函数 的 两个 参数 theta0 = 
2 和 theta1 = 2 此时 假设 函数 h x 
= 2 + 2 * x 得到 的 映射 结果 
如下 这 样子 是 无法 了解 我们 的 假设 函数 
是否 能 很好 的 预测 y 值 因此 有了 成本 
函数 这个 概念 成本 函数 J theta 我们 可以 通过 
成本 函数 来 衡量 假设 函数 的 精确度 这里 的 
精度 指 的 是 预测 值 h x 与 真实 
值 y 之间 的 差值 由于 样本量 往往 是 大于 
一个 的 因此 需要 将 样本 中 的 输入 值 
x 依次 代入 到 假设 函数 中 得到 的 函数值 
与 实际 值 y 作比较 求得 样本 的 预测误差 的 
平均值 具体 公式 如下 作为 学数学 的 人 看 这个 
就 无比 熟悉 工科 的 童鞋 可能 看 公式 不太 
习惯 通俗 来讲 大家 应该 都 知道 平均值 的 定义 
那么 以上 J theta0 theta1 实际上 就是 1/2 * M 
这里 的 M 就是 误差 平方 的 均值 其中 m 
是 指 m 个 样本 例如 上面 表格 中 样本数据 
的 m = 4 这个 成本 函数 的 另外 一个 
名字 或许 更为 大家 所知 平方 误差函数 或者 均方 误差 
这里 的 均值 减半 也是 梯度 下降 算法 的 简易 
实现 因为 对 平方 求导 得到 的 2 会 和 
这里 的 1/2 抵消 还有 一个 问题 是 为啥 当初 
设计 误差 的 人 不 直接 讲 误差 正负 抵消 
而 要做 平方 也是 我 一直 没 弄清 的 问题 
上次 研究 图像 处理 的 混合 互补 模型 ROF 中 
也有 这么 一个 误差 平方和 的 表示 导师 问 我 
为什么 我 没 回答出来 只 觉得 是 固定 的 定义 
而已 希望 知道 的 朋友 解释一下 有了/nr 这个 成本 函数 
我们 就 可以 根据 上面 的 表格 得出 假设 函数 
的 拟合 精 度了 那么 问题 来了 前面 的 假设 
函数 中 theta 值 也 是 我们 假设 的 对于 
大 样本数据 我们 主观 的 给定 theta 的 值 很多 
时候 拟合 的 精度 都 不够 高 如何 求解 这个 
最优 theta 得到 拟合 效果 最好 的 假设 函数 梯度 
下降 算法 现在 我们 有了/nr 假设 函数 以及 衡量 它 
的 精度 的 方式 成本 函数 现在 需要 一个 方法 
来 改善 我们 的 假设 函数 该 方法 即 梯度 
下 降法 1.3 用 python 画 个 图 让 你们 
更好 的 理解 这个 代价 函数 J theta 1 . 
3.1 编程 实现 计算 代价 函数 1 def computeCost X 
y m theta 2 pre = X * theta # 
预测值 3 s = 0 4 for i in range 
m 5 s + = pre i y i * 
* 2 6 J = 1 / 2 * m 
* s # 代价 函数 7 return J 8 9 
10 X = dataMat 0 2 11 y = dataMat 
2 12 m = len y # 样本 数量 13 
theta = zeros 2 1 # 初始化 theta 14 iterations 
= 1500 # 迭代 次数 15 16 J = computeCost 
X y m theta 上面 的 代码 已经 很好 的 
实现 代价 函数 的 算法 由于 我们 的 初始化 theta 
值 为 0 因此 J 的 初始值 也是 0 接下来 
需要 运用 梯度 下降 算法 计算 theta0 和 theta1 因此 
先 上一个 coursera 上面 布置 的 作业 里面 我 用 
matlab 画 的 图 数据 不 一样 后面 贴 python 
代码 实现 该 类型图 的 画法 上图 是 theta0 和 
theta1 在整个 迭代 过程 中 收敛 到 最佳 假设 函数 
的 情况 J0 J3 这个 过程 就是 初始值 theta0 = 
theta1 = 0 到 最优 值 J3 的 多次 迭代 
的 结果 上图 的 红叉叉 就是 J theta 的 一个 
全局 最优 解的/nr 对应 的 最优 theta 的 值 此时 
成本 最小 最能 预测 结果 讲 此时 的 theta 代入 
到 假设 函数 得到 的 假设 函数 正是 我们 需要 
的 回归 函数 拟合度 最高 从 J0 走向 J1 的 
这个 过程 就是 成本 函数 J theta0 theta1 分别 对 
theta0 和 theta1 求 偏 导 例 如从 J0 走向 
J1 的 斜率 就是 theta0 和 theta1 的 偏 导 
就好 比人 走下坡路 斜率 就是 选择 下坡 的 方向 角度 
而 theta0 和 theta1 就是 两个 同时 下坡 的 小人 
迈开 的 步伐 的 大小 就是 学习 速度 alpha 因此 
两个 小 人 能否 走到 坡底 是由 它们 的 初始 
位置 初始 位置 一半 被 初始 化为 0 和 下坡 
的 方向 偏 导 以及 下坡 的 步伐 学习 速度 
alpha 所 决定 总的来说 梯度 下降 的 公式 为 重复 
步骤 直至 收敛 哎呀 看官 可能 看 累了 接下来 都有 
考试 就 先写 这么多 后面 给出 梯度 下降 算法 的 
具体 实现 代码 ~ 