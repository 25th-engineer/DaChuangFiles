Python 数据 预处理 机器学习 人工智能/n 通用/v 技术/n 白宁超/nr  /i 2018年 
12月 24日 17 28 26 摘要 大 数据 技术 与 
我们 日常 生活 越来越 紧密 要做 大 数据 首 要 
解决 数据 问题 原始数据 存在 大量 不 完整 不一致 有 
异常 的 数据 严重 影响 到 数据 建模 的 执行 
效率 甚至 可能 导致 模型 结果 的 偏差 因此 要 
数据 预 处 数据 预处理 主要 是 将 原始数据 经过 
文本 抽取 数据清理 数据 集成 数据处理 数据 变换 数据 降 
维 等 处理 后 不仅 提高 了 数据 质量 而且 
更好 的 提升 算法 模型 性能 数据 预处理 在 数据挖掘 
自然语言 处理 机器学习 深度 学习 算法 中 起着 重要 的 
作用 本文 原创 转载 必须 注明 出处 . 1 什么 
是 数据 预处理 数据 预处理 简而言之 就是 将 原始数据 装进 
一个 预处理 的 黑匣子 之后 产生出 高 质量 数据 用来 
适应 相关 技术 或者 算法 模型 为了 大家 更 明确 
的 了解 数据 预处理 我们 举 个 新闻 分类 的 
例子 将 原始 的 数据 直接 进行 分类 模型 训练 
分类器/n 准确率/n 和/c 召回率/i 都/d 比较/d 低/a 因为 我们 原始数据 
存在 很多 干扰 项 比如 的 是 等 这些 所谓 
停用词 特征 对 分类 起 的 作用 不大 很难 达到 
工程 应用 我们 将 原始数据 放假 预处理 黑匣子 后 会 
自动 过滤掉 干扰 数据 并且 还 会 按照 规约 的 
方法 体现 每个 词 特征 的 重要性 然后 将 词 
特征 压缩 变换 在 数值 型 矩阵 中 再通过 分类器 
就会 取得 不错 的 效果 可以 进行 工程 应用 总结 
数据 预处理 前 的 数据 存在 不 完整 偏态 噪声 
特征 比重 特征 维度 缺失 值 错误 值 等 问题 
数据 预处理 后的/nr 数据 存在 完整 正 态 干净 特征 
比重 合适 特征 维度 合理 无 缺失 值 等 优点 
数据 预处理 方法 数据清理 通过 填写 缺失 的 值 光滑 
噪声 数据 识别 或 删除 离群 点 并 解决 不一致性 
来 清理 数据 主要 目标 格式 标准化 异常 数据 清除 
错误 纠正 重复 数据 的 清除 数据 集成 将 数据 
由 多个 数据源 合并 成 一个 一致 的 数据 存储 
如 数据仓库 数据 变换 通过 平滑 聚集 数据 概 化 
规范化 等 方式 将 数据 转换成 适用于 的 形式 如 
把 数据 压缩 到 0.0 1.0 区间 数据 归约 往往 
数据 量 非常 大 在 少量 数据 上 进行 挖掘 
分析 需要 很长 的 时间 数据 归约 技术 可以 用来 
得到 数据集 的 归约 表示 它 小得多 但仍然 接近 于 
保持 原 数据 的 完整性 并 结果 与 归约 前 
结果 相同 或 几乎 相同 可以 通过 如 聚集 删除 
冗余 特征 或 聚 类 来 降低 数据 的 规模 
2 为什么 做 这门 课程 在 初期 学习 阶段 大家 
精力 着重于 算法 模型 和调/nr 参上 实际 情况 是 有时候 
在 算法 改进 上 花费 很多 功夫 却 不如 在 
数据 质量 上 的 些许 提高 来 的 明显 另外 
习惯于 数据 语料 的 拿来主义 之后 当 面对 新的 任务 
时候 却 不 知道 如何 下手 有的 同学 在 处理 
英语 时候 游刃有余 面对 中文 数据 预处理 却 不知所措 基于 
以上 几 个 问题 结 合作者 工程 经验 整理 出了 
数据 预处理 学习 资料 本 教程 主要 面对 文本 信息处理 
在 图片 语音 等 数据 语料 处理 上 是 有所 
区别 的 3 本 课程 能学 到 什么 文本 批量 
抽取 涉及 技术 点 包括 pywin32 插件 安装 使用 文档 
文本 提取 PDF 文本 提取 文本 抽取 器 的 封装 
方法 参数 的 使用 遍历 文件夹 编码 问题 批量 抽取 
文本 信息 数据 清洗 包括 yield 生成器 高效 读取 文件 
正则表达式 的 使用 清洗 网页 数据 清洗 字符串 中文 的 
繁简 互相 转换 缺失 值 的 处理 噪声 数据 异常 
数据 清洗 批量 清洗 30万 条 新闻 数据 数据处理 包括 
结巴 分词 精讲 HanLP 精讲 停用词 的 处理 NLTK 的 
安装 使用 高频词 和 低频词 的 处理 词性 的 选择 
特征 数据 的 提取 批量 预处理 30万 条 新闻 数据 
数据 向 量化 包括 词 袋 模型 词集 模型 词 
向量 的 转化 缺失 值 和 数据 均衡 语料库 技术 
TFIDF 特征词 比重 主 成分 分析 主题 模型 等 批量 
进行 30 万条 数据 向 量化 可视化 技术 包括 条形图 
柱形图 散点图 饼图 热 力图 等 还有 matplotlib seabom Axes3D 
综合 使用 进行 三维 可视化 XGBoost 竞赛 神器 包括 监督 
学习 文本 分类 XGBoost 原理 XGBoost 算法 实现 XGBoost 调 
参 算法 性能 评估 30 万条 文档 生成 词典 30 
万条 文档 转化 TFIDF 30 万条 文档 转 化生成 LSI 
训练 分类器 模型 抽样 改进 模型 算法 特征 维度 改进 
模型 算法 XGBoost 实现 30万 条 新闻 数据 文本 分类 
综上所述 数据 预处理 整体 包括 数据抽取 数据 清洗 数据处理 数据 
向 量化 可视化 分析 模型 构建 在 整个 过程 中 
我们 每个 章节 相关性 很强 首先 对 整个 章节 最终 
实现 效果 进行 演示 然后 拆分 知识点 分别 讲解 最后 
将 所有 知识点 整合 起来 做 小节 的 实战 每个 
小节 实战 数据 为 下 一个 章节 做 铺垫 最后 
一个 综合 实战 分类 案例 串联 所有 知识点 4 开发 
环境 说明 开发 语言 Python3 . 5.3 系统 环境 window10 
操作系统 编程 环境 Sublime 软件 环境 Anaconda4 . 4.0 插件 
版本 均 支持 最新 版本 sublime 激活 打开 Help Enter 
LICENSE BEGIN LICENSE sgbteam Single User License EA7E 1153259 8891CBB9 
F1513E4F 1A3405C1 A865D53F 115F202E 7B91AB2D 0D2A40ED 352B269B 76E84F0B CD69BFC7 59F2DFEF 
E267328F 215652A3 E88F9D8F 4C38E3BA 5B2DAAE4 969624E7 DC9CD4D5 717FB40C 1B9738CF 20B3C4F1 
E917B5B3 87C38D9C ACCE7DD8 5F7EF854 86B9743C FADC04AA FB0DA5C0 F913BE58 42FEA319 F954EFDD 
AE881E0B END LICENSE 解决 Package Control 报错 Package Control . 
sublime settings 修改 方法 Preferences Package Settings Package Control Settings 
User   添加 channels http / / cst . stu 
. 126 . net / u / json / cms 
/ channel _ v3 . json / / https / 
/ packagecontrol . io / channel _ v3 . json 
/ / https / / web . archive . org 
/ web / 20160103232808 / https / / packagecontrol . 
io / channel _ v3 . json / / https 
/ / gist . g i t h u b 
u s e r c o n t e n 
t . com / nick1m / 6 6 0 e 
d 0 4 6 a 0 9 6 d a 
e 0 b 0 a b / raw / e 
6 e 9 e 2 3 a 0 b b 
4 8 b 4 4 5 3 7 f 6 
1 0 2 5 f b c 3 5 9 
f 8 d 5 8 6 e b 4 / 
channel _ v3 . json 5 项目 演示 5.1 原始数据 
5.2 数据 预览 5.3 数据 清洗 5.4 生成 词典 5.5 
生成 特征向量 5.6 生成 LSI5 . 7 XGBoost 新闻 数据 
文本 分类 6 目录 列表 ☆ 理论 介绍 ★ 实战 
演练 第 1 章 课程 介绍 1 1 为什么 做 
这门 课 ☆ 1 2 课程 整体 介绍 与 导学 
☆ ☆ 1 3 学习 建议 ☆ ☆ 1 4 
课程 开发环境 介绍 ☆ 1 5 文本 分类 项目 演示 
☆ 1 6 源码 获取 说明 ☆ ☆ ☆ 1 
7 总结 与 扩展 ☆ 第 2 章 Python 数据 
预处理 之 抽取 文本 信息 2.1 数据类型 与 采集 方法 
☆ ☆ ☆ 2.2 一堆 杂乱无章 的 数据 ☆ 2.3 
文本 抽取 问题 3 种方法 对比 ☆ 2.4 Pywin32 实现 
格式 转换 ☆ ☆ 2.3 Word 转换 TXT 算法 ★ 
2.6 PDF 转换 TXT 算法 ★ 2.7 文本 抽取 工具 
★ ★ 2.8 文本 批量 编码 ★ 2.9 遍历 读取 
文件 ★ ★ ★ 2.10 实战 案例 1 遍历 文件批量 
抽取 新闻 文本 内容 ★ ★ ★ 2.11 总结 与 
扩展 ☆ ☆ 第 3 章 Python 数据 预处理 之 
清洗 文本 信息 3.1 准备 30万 条 新闻 数据 ☆ 
3.2 yield 生成器 ★ 3.3 高效 读取 文件 ★ ★ 
3.4 数据 缺失 值 ★ ★ 3.5 脏数据 与 噪声 
数据 ★ ★ 3.6 正则 清洗 数据 ★ ★ 3.7 
清洗 HTML 数据 ★ ★ 3.8 简繁 字体 转换 ★ 
★ 3.9 实战 案例 2 30万 条 新闻 文本 数据 
清洗 ★ ★ ★ 3.10 总结 与 扩展 ☆ ☆ 
第 4 章 Python 数据 预处理 之 文本处理 4.1 常见 
分词 工具 ☆ 4.2 jieba 分词 推荐 ★ ★ ★ 
4.3 HanLP 分词 扩展 ★ ★ 4.4 自定义 去 停 
词 ★ ★ 4.5 词频 统计 ★ ★ 4.6 自定义 
去 高低 词频 ★ ★ 4.7 自定义 规则 提取 特征词 
★ ★ 4.8 实战 案例 3 6万 条 新闻 文本处理 
★ ★ ★ 4.9 总结 与 扩展 ☆ ☆ 第 
5 章 Python 数据 预处理 之 文本 特征向量 化 5.1 
解析 数据文件 ★ ★ 5.2 词集 模型 ★ ★ 5.3 
词 袋 模型 ★ ★ 5.4 特征词 转 文本 向量 
★ ★ ★ 5.5 不均衡 数据 归一化 处理 ★ ★ 
5.6 处理 数据 缺失 值 ★ ★ 5.7 实战 案例 
4 新闻 文本 特征向量 化 ★ ★ ★ 5.8 总结 
与 扩展 ☆ ☆ 第 6 章 Python 数据 预处理 
之 gensim 文本 向 量化 6.1 gensim 介绍 ☆ ☆ 
6.2 gensim 构建 语料 词典 ★ 6.3 gensim 统计 词频 
特征 ★ ★ 6.4 gensim 计算 IF IDF ★ ★ 
6.5 潜在 语义 索引 ★ ★ ★ ★ 6.6 生成 
主题 模型 ★ ★ ★ ★ 6.7 生成 随机 映射 
★ ★ ★ ★ 6.8 分层 狄利克雷 过程 ★ ★ 
★ ★ 6.9 实战 案例 6 gensim 实现 新闻 文本 
特征向量 化 ★ ★ ★ ★ 6.10 总结 与 扩展 
☆ ☆ ☆ 第 7 章 Python 数据 预处理 之 
特征 降 维 7.1 什么 是 降 维 ☆ ☆ 
7.2 PCA 概述 ☆ ☆ ☆ 7.3 PCA 应用 场景 
☆ ☆ 7.4 PCA 算法 原理 ★ ★ ★ 7.5 
PCA 算法 实现 ★ ★ ★ 7.6 高维 数据 向低纬/nr 
数据 映射 ★ ★ 7.7 前 N 个 主 成分 
特征 ★ ★ 7.8 实战 案例 5 PCA 技术 实现 
新闻 文本 特征 降 维 ★ ★ ★ ★ 7.9 
总结 与 扩展 ☆ ☆ 第 8 章 数据 可视化 
分析 8.1 matplotlib 介绍 ☆ 8.2 matplotlib 绘制 折线图 ★ 
★ 8.3 matplotlib 绘制 散点图 ★ ★ 8.4 matplotlib 绘制 
直方图 ★ ★ 8.5 matplotlib 绘制 气温 图表 ★ ★ 
8.6 matplotlib 绘制 三维图 ★ ★ ★ 8.7 总结 与 
扩展 ☆ 第 9 章 XGBoost 实现 30万 条 新闻 
数据 文本 分类 9.1 有 监督 学习 ☆ ☆ ☆ 
9.2 文本 分类 方法 ☆ ☆ ☆ 9.3 XGBoost 原理 
★ ★ ★ ★ 9.4 XGBoost 算法 实现 ★ ★ 
★ ★ 9.5 准确率 与 召回率 ☆ 9.6 F 度 
量值 ☆ 9.7 30 万条 文档 生成 词典 ★ ★ 
★ 9.8 30 万条 文档 转化 TFIDF ★ ★ ★ 
9.9 30 万条 文档 转 化生成 LSI ★ ★ ★ 
★ 9.10 训练 分类器 模型 ★ ★ ★ ★ 9.11 
测试 分类器 模型 ★ ★ 9.12 抽样 改进 模型 算法 
★ ★ 9.13 特征 维度 改进 模型 算法 ★ ★ 
9.14 训练 集 和 测试 集 比率 改进 模型 算法 
★ ★ 9.15 综合 实战 XGBoost 实现 30万 条 新闻 
数据 文本 分类 ★ ★ ★ ★ ★ 9.11 总结 
与 扩展 ★ ★ 7 源码 获取 源码 请进 机器 
学习 和 自然 语言 QQ 群 436303759 文件 下载 