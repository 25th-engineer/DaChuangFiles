引言
本系列文章是本人对Andrew NG的机器学习课程的一些笔记，如有错误，请读者以课程为准。
在现实生活中，我们每天都可能在不知不觉中使用了各种各样的机器学习算法。
例如，当你每一次使用 Google 时，它之所以可以运行良好，其中一个重要原因便是由 Google 实现的一种学习算法可以“学会”如何对网页进行排名。每当你使用 Facebook 或者 Apple 的照片处理应用时，它们都能自动识别出你朋友的照片，这也是机器学习的一种。每当你阅读电子邮件时，你的垃圾邮件过滤器将帮助你免受大量垃圾邮件的困扰，这也是通过一种学习算法实现的。
我们有这样一个梦想，就是有朝一日，可以创造出像人类一样聪明的机器。很多人工智能专家认为实现这一目标最好的途径便是通过学习算法来模拟人类大脑的学习方式。
机器学习发源于人工智能领域，我们希望能够创造出具有智慧的机器。我们可以通过编程来让机器完成一些基础的工作，例如如何找到从 A 到 B 的最短路径。但在大多数情况下，我们并不知道如何显式地编写人工智能程序来做一些更有趣的任务，例如网页搜索、标记照片和拦截垃圾邮件等。人们意识到唯一能够达成这些目标的方法就是让机器自己学会如何去做。
现今，Machine Learning 已经发展成为计算机领域的一项新能力，并且与工业界和基础科学界有着紧密的联系。在硅谷，机器学习引导着大量的课，如自主机器人、计算生物学等。机器学习的实例还有很多，例如数据挖掘。
机器学习之所以变得如此流行，原因之一便是网络和自动化算法的爆炸性增长。这意味着我们掌握了比以往多得多的数据集。举例来说，当今有数不胜数的硅谷企业，在收集有关网络点击的数据 (Clickstream Data)，并试图在这些数据上运用机器学习的算法来更好的理解和服务用户，这在硅谷已经成为了一项巨大的产业。
随着电子自动化的发展，我们拥有了电子医疗记录，如果我们能够将这些记录转变为医学知识，那么，我们就能对各种疾病了解的更深入。同时，计算生物学也在电子自动化的辅助下快速发展，生物学家收集了大量有关基因序列以及DNA序列的数据，通过对其应用机器学习的算法可以帮助我们更深入地理解人类基因组及其人类基因组对我们人类的意义。
几乎工程界的所有领域都在使用机器学习算法来分析日益增长的海量数据集。有些机器应用我们并不能够通过手工编程来实现。比如说，想要写出一个能让直升机自主飞行的程序几乎是不可能的任务。唯一可行的解决方案就是让一台计算机能够自主地学会如何让直升机飞行。
再比如手写识别，如今将大量的邮件按地址分类寄送到全球各地的代价大大降低，其中重要的理由之一便是每当你写下这样一封信时，一个机器学习的算法已经学会如何读懂你的笔迹并自动地将你的信件发往它的目的地。
你也许曾经接触过自然语言处理和计算机视觉。事实上，这些领域都是试图通过 AI 来理解人类的语言和图像，如今大多数的自然语言处理和计算机视觉都是对机器学习的一种应用。
机器学习算法也在 self-customizing program 中有着广泛的应用。每当你使用亚马逊 Netflix 或 iTunes Genius 的服务时，都会收到它们为你量身推荐的电影或产品，这就是通过学习算法来实现的。很显然，这些应用都有着上千万的用户，而针对这些海量的用户，编写千万个不同的程序显然是不可能的，唯一有效的解决方案就是开发出能够进行自我学习，定制出符合你喜好的并据此进行推荐的软件。
最后，机器学习算法已经被应用于探究人类的学习方式，并试图理解人类的大脑。
What is machine learning
What is machine learning? 不同人对机器学习有不同的定义。下面是 亚瑟·塞穆尔 (Arthur Samuel) 给出的机器学习的定义：
Arthur Samuel (1959).
Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.
亚瑟·塞穆尔将机器学习定义为：在没有明确为计算机编写（完成某项具体任务的）程序的情况下，让计算机拥有 “学习” 能力的一个研究领域。
Samuel 出名是因为在50年代 ，他编程实现了一个玩西洋跳棋的程序。这个跳棋程序的神奇之处在于，他让程序跟程序自身下了成千上万盘棋，跳棋程序通过观察分析什么样的棋局更容易致胜，什么样的棋局更容易输，逐渐学会了什么是好的棋局，什么是坏的棋局。最终，跳棋程序的下棋水平超过了 Samuel 。
这是一个相当了不起的成果，虽然 Samuel 自己并不是一个很好的棋手，但因为计算机（跳棋程序）可以跟自身对弈成千上万次，通过这样的训练，计算机得到了很多的下棋经验，最终使得计算机最终成为了比 Samuel 更好的棋手。
以上是一个不太正式并且有点老的定义，下面是一个更新的定义，来自 Carnegie Mellon University 的 Tom Mitchell 提出：
Tom Mitchell (1998).
Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.
如果一个计算机程序在任务 T 上的性能度量 P ，通过经验 E 而提高，那么我们称这个计算机程序通过经验 E 来学习。
具体到下跳棋的例子里面，训练经验 E 指的是让计算机程序与 Samuel 对弈成千上万次的经验；任务 T 指的的是下跳棋这个任务，性能标准 P
指的是跳棋程序在下一场面对新对手的比赛中获胜的概率。
学习算法分好几个类型，主要分成两大类，分别是监督学习 (Supervised Learning) 和无监督学习 (Unsupervised Learning)，在后面的博文中我将介绍这些术语的具体含义。不过归根到底，Supervised Learning 就是我们要明确告诉计算机如何做某件事情，而 Unsupervised Learning 则意味着我们要让程序自己进行学习。
在以后的博文中，我们也会讨论一些其他术语，比如强化学习 (Reinforcement Learning) 和推荐系统 (Recommender Systems)，这些其他类型的机器学习算法，我们在以后都会讨论，但两个最常用的学习算法实际上就是就是 Supervised Learning 和 Unsupervised Learning 。
接下来，我们来讨论什么是 Supervised Learning ，什么是 Unsupervised Learning ，并且会讨论在什么情况下使用这两种算法。
Supervised Learning
我们用一个例子开头，介绍什么是监督学习，正式的定义会在后面介绍。
假设你现在想要预测房价，并且拥有一些关于房价的数据，如下：
其中横轴表示房子的面积（单位是平方英尺），纵轴表示房价（单位是千美元），假如你有一套750平方英尺大小的房子想要卖掉，那么基于以上数据，你如何推测房子大概值多少钱。
对于这个问题，我们可以应用机器学习算法，在这组数据中画一条直线或者说是拟合一条直线，根据这条线我们可以推测出这套房子可能卖$150, 000。当然这不是唯一的算法，比如一个二次函数可能更适合已有的数据，我们使用这个二次函数的曲线来进行预测可能效果会更好。
以上就是一个 Supervised Learning 的例子，可以看出 Supervised Learning 指的就是我们给学习算法一个数据集，这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价，然后运用学习算法，计算出更多的正确答案，比如你的那个新房子的价格，用术语来讲，这叫做回归问题。
我们试着推测出一个连续值的结果，即房子的价格。一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，因此又把它看成一个连续的数值，回归这个词的意思指的就是，我们在试着推测出这一系列连续值属性。
回归问题：我们所预测的结果是连续的值。
我们再来讨论另外一个监督学习的例子，假使你希望通过查看病例来预测一个乳腺癌是否是良性的，这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出 1 和 0 来分别表示是恶性肿瘤或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性记为1，不是恶性（或者说是良性）则记为0。
假设现在我们有一个朋友很不幸检查出乳腺肿瘤，假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个分类问题。
分类指的是我们试着推测出离散的输出值: 0 或 1 、良性或恶性。而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出0、1、2、3。其中 0 代表良性，1 表示第一类乳腺癌，2 表示第二类癌症，3 表示第三类。但是，实际上这也是分类问题，因为这几个离散的输出分别对应良性、第一类、第二类或者第三类癌症。
在分类问题中我们可以用另一种方式来绘制这些数据点。我们可以用不同的符号来表示这些数据，既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我们可以这么画，用不同的符号来表示良性和恶性肿瘤，或者说是负样本和正样本。现在我们不全部画X，而是改成良性的肿瘤用O表示，恶性的继续用X表示。我们所做的只是把上面的数据一一映射下来，映射到一根直线上，并且用不同的符号 O 和 X 来表示良性和恶性样本。
注意，在这个例子中，我们只用了肿瘤的尺寸这一种特征来预测肿瘤的恶性与否，在其它一些机器学习问题中可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄，那现在数据集看起来可能是如下这个样子：
也就是说，你现有的数据集是不同病人的年龄和她们身上肿瘤的尺寸大小以及这些肿瘤的良性与否。我们以横坐标为肿瘤的尺寸，以纵坐标为病人的年龄，以 O 代表良性肿瘤，以 X 代表恶性肿瘤。我们的学习算法要做的就是确定出这样一条直线，把恶性肿瘤和良性肿瘤分开。如果根据你学习算法得出的结论是你朋友的肿瘤落在良性这一边，那么现实中就更可能是良性的而不是恶性。
在这个例子中，我们有两种特征，患者年龄和肿瘤大小，而在在其他机器学习问题中，我们通常有更多的特征。就以之前的乳腺癌为例来说，还可以采用这些特征：肿块密度、肿瘤细胞尺寸的一致性和形状的一致性等等。
我们之后的博文会介绍一种学习算法，这种学习算法不仅能处理2种、3种或者5种特征，甚至即使有无限多种特征，它也都可以处理。如果你想用无限多种特征，以便让你的算法可以利用大量的特征或者说是线索来做推测，那么你如何来处理这无限多个特征，甚至怎么来存储这些特征都存在着很大的问题，比如说你电脑的内存肯定就不够用。之后我们会介绍这个算法，叫作SVN（支持向量机），里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。
小结
本章我们介绍了 Supervised Learning ，它的基本思想是我们数据集中的每个样本都有相应的“正确答案”，再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。
我们还介绍了回归问题，即通过回归来推测出一个连续的输出。之后我们介绍了分类问题，其目标是推测出一组离散的结果。
现在来个小测验，假设你经营着一家公司，你想开发学习算法来处理以下两个问题。
第一个问题是，你有一大批相同的货物，你想预测接下来的三个月能卖出多少件。第二个问题是，你有许多客户，这时你想写一个软件来检验每一个用户的账户，而对于每一个账户，你要判断它们是否曾经被盗过。这两个问题，它们是属于分类问题，还是回归问题?
显然，问题一是一个回归问题，因为如果有数千件货物，我们会把它看成一个实数，看成一个连续的值，因此卖出的物品数同样也是一个连续的值。问题二是一个分类问题，我们可以把预测的值用 0 来表示账户未被盗，用 1 表示账户曾经被盗过，就像乳腺癌的例子 0 代表良性，1 代表恶性，所以我们根据账号是否被盗过而把它们定为 0 或 1 ，然后用算法推测一个账号是 0 还是 1 ，因为只有少数的离散值，所以我们把它归为分类问题。
以上就是 Supervised Learning 的内容，下面我们来看 Unsupervised Learning 。
Unsupervised Learning
我们现在来讨论 Unsupervised Learning ，之前我们已经讲过了 Supervised Learning 。回想一下之前的数据集，每个样本都已经被标明为
正样本或者负样本，即良性或恶性肿瘤。因此，对于 Supervised Learning 中的每一个样本，我们已经被清楚地告知了，什么是所谓的正确答案，即它们是良性还是恶性。
在 Unsupervised Learning 中，我们所用的数据会和 Supervised Learning 里的看起来有些不一样。在 Unsupervised Learning 中，没有属性或标签这一概念，也就是说所有的数据都是一样的，没有区别。
所以在 Unsupervised Learning 中，我们只有一个数据集，没人告诉我们该怎么做，我们也不知道每个数据点究竟是什么意思。相反，它只告诉我们，现在有一个数据集，你能在其中找到某种结构吗？
对于给定的数据集，Unsupervised Learning Algorithm可能判定该数据集包含两个不同的聚类。无监督学习算法会把这些数据分成两个不同的聚类，这就是所谓的聚类算法。
聚类算法实例
实际上 Unsupervised Learning 被用在许多地方。我们来举一个聚类算法的例子，是关于Google 新闻的例子。
谷歌新闻每天都在干什么呢？他们每天会去收集成千上万的网络上的新闻，然后将他们分组，组成一个个新闻专题。谷歌新闻所做的就是去搜索成千上万条新闻，然后自动的将他们聚合在一起，有关同一主题的新闻被显示在一起。
其实，聚类算法和无监督学习算法也可以被用于许多其他的问题。这里，我们举个它在基因组学中的应用，下面是一个关于基因芯片的例子：
基本的思想是，给定一组不同的个体，对于每个个体，检测它们是否拥有某个特定的基因。也就是说，你要去分析有多少基因显现出来了。因此，这些颜色：红、绿、灰等等，它们展示了这些不同的个体是否拥有一个特定基因的不同程度。
然后你所能做的就是运行一个聚类算法，把不同的个体归入不同的类或者说归为不同类型的人，这就是无监督学习。我们没有提前告知这个算法哪些是第一类的人、哪些是第二类的人、哪些是第三类的人等等。相反我们只是告诉算法，这儿有一堆数据，我不知道这个数据是什么东西，我不知道里面都有些什么类型，叫什么名字，我甚至不知道都有哪些类型。但是，请问你可以自动的找到这些数据中的类型吗？然后自动的按得到的类型把这些个体分类，虽然事先我并不知道哪些类型，因为对于这些数据样本来说，我们没有给算法一个正确答案，所以，这就是无监督学习。
无监督学习或聚类算法在其他领域也有着大量的应用，它被用来组织大型的计算机集群。一些朋友在管理大型数据中心（大型计算机集群），并试图找出哪些机器趋向于协同工作，如果你把这些机器放在一起，你就可以让你的数据中心更高效地工作。
还有应用可以用于社交网络的分析。所以，如果可以得知你用 email 联系最多的是哪些朋友，或者知道你的 Facebook 好友，或者你 Google+ 里的朋友，知道了这些之后信息后，我们可以自动识别哪些是很要好的朋友组，哪些仅仅是互相认识的朋友组。
还有在市场分割中的应用，许多公司拥有庞大的客户信息数据库，那么给你一个客户数据集，你能否自动找出不同的市场分割，并自动将你的客户分到不同的细分市场中，从而有助于你在不同的细分市场中进行更有效的销售，这也是无监督学习。我们现在有这些客户数据，但我们预先并不知道有哪些细分市场，而且对于我们数据集的某个客户，我们也不能预先知道谁属于细分市场一，谁又属于细分市场二等等。但我们必须让这个算法自己去从数据中发现这一切。
实际上无监督学习也被用于天文数据分析，通过这些聚类算法，我们发现了许多惊人的、有趣的、以及实用的关于星系是如何诞生的理论，所有这些都是聚类算法的例子。
鸡尾酒宴问题
再一个 Unsupervised Learning Algorithm 的例子是鸡尾酒宴问题。想象一下，一个宴会有一屋子的人，大家都坐在一起，并且在同时说话，因此会有许多声音混杂在一起，因为许多人会在同一时间说话，在这种情况下你很难听清楚你面前的人说的话。
因此，比如有这样一个场景，宴会上只有两个人，两个人同时说话（恩，没错…这是个很小的鸡尾酒宴会），我们准备好了两个麦克风，把它们放在房间里，然后因为这两个麦克风距离这两个人的距离是不同的，每个麦克风都记录下了来自两个人的声音的不同组合。
也许A的声音在第一个麦克风里的声音会响一点，也许B的声音在第二个麦克风里会比较响一些，因为2个麦克风的位置相对于2个说话者的位置是不同的，但每个麦克风都会录到来自两个说话者的重叠部分的声音。
所以，我们能做的就是把这两个录音输入一种无监督学习算法中，称为“鸡尾酒会算法”。让这个算法帮你找出其中蕴含的分类，然后这个算法就可以去识别这些录音，分离出这两个被叠加到一起的音频源。以上所说的正是“鸡尾酒会问题”的简化版本。
鸡尾酒会问题（Cocktail Party Problem），在一个满是人的房间中，人们都在互相对话，我们使用一些麦克风录下房间中的声音，利用非监督学习算法来识别房间中某一个人所说的话。
总结：根据录音，算法找出蕴含分类，之后算法就可以识别其他合成的录音中，哪些是属于这个分类，哪些是属于那个分类。
总结
监督学习（分类，回归）
无监督学习（聚类）