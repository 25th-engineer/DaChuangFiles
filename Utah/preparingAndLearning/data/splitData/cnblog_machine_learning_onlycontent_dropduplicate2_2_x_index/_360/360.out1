准备 环境 anacondanano ~ / . zshrc export PATH = 
$ PATH / anaconda / bin source ~ / . 
zshrc echo $ HOME echo $ PATHipythonconda update conda & 
& conda update ipython ipython notebook ipython qtconsole conda install 
s c i p y P Y T H O 
N P A T H e x p o r 
t SPARK _ HOME = / Users / erichan / 
garden / spark 1 . 5.1 bin hadoop2 . 6 
export PYTHONPATH = $ { SPARK _ HOME } / 
python / $ { SPARK _ HOME } / python 
/ lib / py4j 0.8 . 2.1 src . zip 
运行 环境 cd $ SPARK _ HOME IPYTHON = 1 
IPYTHON _ OPTS = pylab . / bin / pyspark 
数据 1 . 获取 原始数据 PATH = / Users / 
erichan / sourcecode / book / Spark 机器学习 user _ 
data = sc . textFile % s / ml 100k 
/ u . user % PATH user _ fields = 
user _ data . map lambda line line . split 
| movie _ data = sc . textFile % s 
/ ml 100k / u . item % PATH movie 
_ fields = movie _ data . map lambda lines 
lines . split | rating _ data _ raw = 
sc . textFile % s / ml 100k / u 
. data % PATH rating _ data = rating _ 
data _ raw . map lambda line line . split 
\ t num _ movies = movie _ data . 
count print num _ movies1682user _ data . first u 
1 | 24 | M | technician | 85711 movie 
_ data . first u 1 | Toy Story 1995 
| 01 Jan 1995 | | http / / us 
. imdb . com / M / title exact Toy 
% 20Story % 20 1995 | 0 | 0 | 
0 | 1 | 1 | 1 | 0 | 
0 | 0 | 0 | 0 | 0 | 
0 | 0 | 0 | 0 | 0 | 
0 | 0 rating _ data _ raw . first 
u 196 \ t242 \ t3 \ t881250949 2 . 
探索 数据 2.1 . 按 列 统计 num _ users 
= user _ fields . map lambda fields fields 0 
. count num _ genders = user _ fields . 
map lambda fields fields 2 . distinct . count num 
_ occupations = user _ fields . map lambda fields 
fields 3 . distinct . count num _ zipcodes = 
user _ fields . map lambda fields fields 4 . 
distinct . count ratings = rating _ data . map 
lambda fields int fields 2 num _ ratings = ratings 
. count max _ rating = ratings . reduce lambda 
x y max x y min _ rating = ratings 
. reduce lambda x y min x y mean _ 
rating = ratings . reduce lambda x y x + 
y / float num _ ratings median _ rating = 
np . median ratings . collect ratings _ per _ 
user = num _ ratings / num _ users ratings 
_ per _ movie = num _ ratings / num 
_ movies print Users % d genders % d occupations 
% d ZIP codes % d % num _ users 
num _ genders num _ occupations num _ zipcodes Users 
943 genders 2 occupations 21 ZIP codes 795print Min rating 
% d % min _ ratingMin rating 1print Max rating 
% d % max _ ratingMax rating 5print Average rating 
% 2.2 f % mean _ ratingAverage rating 3 . 
53print Median rating % d % median _ ratingMedian rating 
4print Average # of ratings per user % 2.2 f 
% ratings _ per _ userAverage # of ratings per 
user 106 . 00print Average # of ratings per movie 
% 2.2 f % ratings _ per _ movieAverage # 
of ratings per movie 59 . 00ratings . stats count 
100000 mean 3.52986 stdev 1.12566797076 max 5 min 1 2.2 
. 使用 matplotlib 的 hist 函数 绘制 直方图 ages = 
user _ fields . map lambda x int x 1 
. collect hist ages bins = 20 color = lightblue 
normed = True fig = matplotlib . pyplot . gcf 
fig . set _ size _ inches 16 10 count 
_ by _ rating = ratings . countByValue x _ 
axis = np . array count _ by _ rating 
. keys y _ axis = np . array float 
c for c in count _ by _ rating . 
values # we normalize the y axis here to percentages 
y _ axis _ normed = y _ axis / 
y _ axis . sum pos = np . arange 
len x _ axis width = 1.0 ax = plt 
. axes ax . set _ xticks pos + width 
/ 2 ax . set _ xticklabels x _ axis 
plt . bar pos y _ axis _ normed width 
color = lightblue plt . xticks rotation = 30 fig 
= matplotlib . pyplot . gcf fig . set _ 
size _ inches 16 10 count _ by _ occupation 
= user _ fields . map lambda fields fields 3 
1 . reduceByKey lambda x y x + y . 
collect x _ axis1 = np . array c 0 
for c in count _ by _ occupation y _ 
axis1 = np . array c 1 for c in 
count _ by _ occupation x _ axis = x 
_ axis1 np . argsort y _ axis1 y _ 
axis = y _ axis1 np . argsort y _ 
axis1 pos = np . arange len x _ axis 
width = 1.0 ax = plt . axes ax . 
set _ xticks pos + width / 2 ax . 
set _ xticklabels x _ axis plt . bar pos 
y _ axis width color = lightblue plt . xticks 
rotation = 30 fig = matplotlib . pyplot . gcf 
fig . set _ size _ inches 16 10 2.3 
. 使用 countByValue 函数 统计 count _ by _ occupation2 
= user _ fields . map lambda fields fields 3 
. countByValue print Map reduce approach print dict count _ 
by _ occupation2 { u administrator 79 u retired 14 
u lawyer 12 u healthcare 16 u marketing 26 u 
executive 32 u scientist 31 u student 196 u technician 
27 u librarian 51 u programmer 66 u salesman 12 
u homemaker 7 u engineer 67 u none 9 u 
doctor 7 u writer 45 u entertainment 18 u other 
105 u educator 95 u artist 28 } print print 
countByValue approach print dict count _ by _ occupation { 
u administrator 79 u writer 45 u retired 14 u 
lawyer 12 u doctor 7 u marketing 26 u executive 
32 u none 9 u entertainment 18 u healthcare 16 
u scientist 31 u student 196 u educator 95 u 
technician 27 u librarian 51 u programmer 66 u artist 
28 u salesman 12 u other 105 u homemaker 7 
u engineer 67 } 2.4 . 使用 filter 转换 def 
convert _ year x try return int x 4 except 
return 1900 years = movie _ fields . map lambda 
fields fields 2 . map lambda x convert _ year 
x years _ filtered = years . filter lambda x 
x = 1900 movie _ ages = years _ filtered 
. map lambda yr 1998 yr . countByValue values = 
movie _ ages . values bins = movie _ ages 
. keys hist values bins = bins color = lightblue 
normed = True array 0 . 0.07575758 0.09090909 0.09090909 0.18181818 
0.18181818 0.04545455 0.07575758 0.07575758 0.03030303 0 . 0.01515152 0.01515152 0.03030303 
0 . 0.03030303 0 . 0 . 0 . 0 
. 0 . 0 . 0.01515152 0 . 0.01515152 0 
. 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 
. 0 . 0.01515152 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0 . 
0 . 0 . 0 . 0 . 0.01515152 0 
. 0 . 0 . 0 . array 0 1 
2 3 4 5 6 7 8 9 10 11 
12 13 14 15 16 17 18 19 20 21 
22 23 24 25 26 27 28 29 30 31 
32 33 34 35 36 37 38 39 40 41 
42 43 44 45 46 47 48 49 50 51 
52 53 54 55 56 57 58 59 60 61 
62 63 64 65 66 67 68 72 76 fig 
= matplotlib . pyplot . gcf fig . set _ 
size _ inches 16 10 2.5 . 使用 groupByKey 分组 
# to compute the distribution of ratings per user we 
first group the ratings by user id user _ ratings 
_ grouped = rating _ data . map lambda fields 
int fields 0 int fields 2 . groupByKey # then 
for each key user id we find the size of 
the set of ratings which gives us the # ratings 
for that user user _ ratings _ byuser = user 
_ ratings _ grouped . map lambda k v k 
len v user _ ratings _ byuser . take 5 
2 62 4 24 6 211 8 59 10 184 
user _ ratings _ byuser _ local = user _ 
ratings _ byuser . map lambda k v v . 
collect hist user _ ratings _ byuser _ local bins 
= 200 color = lightblue normed = True fig = 
matplotlib . pyplot . gcf fig . set _ size 
_ inches 16 10 3 . 处理 转换 3.1 . 
填充 缺失 years _ pre _ processed = movie _ 
fields . map lambda fields fields 2 . map lambda 
x convert _ year x . filter lambda yr yr 
= 1900 . collect years _ pre _ processed _ 
array = np . array years _ pre _ processed 
# first we compute the mean and median year of 
release without the bad data point mean _ year = 
np . mean years _ pre _ processed _ array 
years _ pre _ processed _ array = 1900 median 
_ year = np . median years _ pre _ 
processed _ array years _ pre _ processed _ array 
= 1900 idx _ bad _ data = np . 
where years _ pre _ processed _ array = = 
1900 0 years _ pre _ processed _ array idx 
_ bad _ data = median _ year print Mean 
year of release % d % mean _ yearMean year 
of release 1989print Median year of release % d % 
median _ yearMedian year of release 1995print Index of 1900 
after assigning median % s % np . where years 
_ pre _ processed _ array = = 1900 0 
Index of 1900 after assigning median 4 . 提取 特征 
4.1 . 类别 特征 norminal 变量 / ordinal 变量 all 
_ occupations = user _ fields . map lambda fields 
fields 3 . distinct . collect all _ occupations . 
sort # create a new dictionary to hold the occupations 
and assign the 1 of k indexes idx = 0 
all _ occupations _ dict = { } for o 
in all _ occupations all _ occupations _ dict o 
= idx idx + = 1 # try a few 
examples to see what 1 of k encoding is assigned 
print Encoding of doctor % d % all _ occupations 
_ dict doctor print Encoding of programmer % d % 
all _ occupations _ dict programmer Encoding of doctor 2Encoding 
of programmer 14numpy 的 zeros 函数 K = len all 
_ occupations _ dict binary _ x = np . 
zeros K k _ programmer = all _ occupations _ 
dict programmer binary _ x k _ programmer = 1 
print Binary feature vector % s % binary _ x 
print Length of binary vector % d % KBinary feature 
vector 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 0 
. 0 . 0 . 0 . 0 . 1 
. 0 . 0 . 0.0 . 0 . Length 
of binary vector 214.2 . 派生 特征 时间戳 转换 为 
类别 特征 def extract _ datetime ts import datetime return 
datetime . datetime . fromtimestamp ts def assign _ tod 
hr times _ of _ day = { morning range 
7 12 lunch range 12 15 afternoon range 15 18 
evening range 18 23 night { 23 24 0 1 
2 3 4 5 6 7 } } for k 
v in times _ of _ day . iteritems if 
hr in v return k timestamps = rating _ data 
. map lambda fields int fields 3 hour _ of 
_ day = timestamps . map lambda ts extract _ 
datetime ts . hour # now apply the time of 
day function to the hour of day RDD time _ 
of _ day = hour _ of _ day . 
map lambda hr assign _ tod hr timestamps . take 
5 881250949 891717742 878887116 880606923 886397596 hour _ of _ 
day . take 5 23 3 15 13 13 time 
_ of _ day . take 5 night night afternoon 
lunch lunch 4.3 . 文本 特征 def extract _ title 
raw import re grps = re . search \ \ 
w + \ raw if grps return raw grps . 
start . strip else return raw raw _ titles = 
movie _ fields . map lambda fields fields 1 for 
raw _ title in raw _ titles . take 5 
print extract _ title raw _ title Toy t o 
r y G o l d e n E y 
e F o u r RoomsGet h o r t 
y C o p y c a t m o 
v i e _ titles = raw _ titles . 
map lambda m extract _ title m # next we 
tokenize the titles into terms . We ll use simple 
whitespace tokenization title _ terms = movie _ titles . 
map lambda t t . split print title _ terms 
. take 5 u Toy u Story u GoldenEye u 
Four u Rooms u Get u Shorty u Copycat flatMapall 
_ terms = title _ terms . flatMap lambda x 
x . distinct . collect # create a new dictionary 
to hold the terms and assign the 1 of k 
indexes idx = 0 all _ terms _ dict = 
{ } for term in all _ terms all _ 
terms _ dict term = idx idx + = 1 
num _ terms = len all _ terms _ dict 
print Total number of terms % d % num _ 
termsTotal number of terms 2645print Index of term Dead % 
d % all _ terms _ dict Dead Index of 
term Dead 147print Index of term Rooms % d % 
all _ terms _ dict Rooms Index of term Rooms 
1 9 6 3 z i p W i t 
h I n d e x a l l _ 
terms _ dict2 = title _ terms . flatMap lambda 
x x . distinct . zipWithIndex . collectAsMap print Index 
of term Dead % d % all _ terms _ 
dict2 Dead print Index of term Rooms % d % 
all _ terms _ dict2 Rooms Index of term Dead 
147Index of term Rooms 1963 创建 稀疏 向量 / 广播 
变量 scipy depends $ PYTHONPATHdef create _ vector terms term 
_ dict from scipy import sparse as sp x = 
sp . csc _ matrix 1 num _ terms for 
t in terms if t in term _ dict idx 
= term _ dict t x 0 idx = 1 
return x all _ terms _ bcast = sc . 
broadcast all _ terms _ dict term _ vectors = 
title _ terms . map lambda terms create _ vector 
terms all _ terms _ bcast . value term _ 
vectors . take 5 1x2645 sparse matrix of type with 
1 stored elements in Compressed Sparse Column format 1x2645 sparse 
matrix of type with 1 stored elements in Compressed Sparse 
Column format 1x2645 sparse matrix of type with 1 stored 
elements in Compressed Sparse Column format 1x2645 sparse matrix of 
type with 1 stored elements in Compressed Sparse Column format 
1x2645 sparse matrix of type with 1 stored elements in 
Compressed Sparse Column format 4.4 . 正则化 特征 np . 
random . seed 42 x = np . random . 
randn 10 norm _ x _ 2 = np . 
linalg . norm x normalized _ x = x / 
norm _ x _ 2 print x \ n % 
s % x print 2 Norm of x % 2.4 
f % norm _ x _ 2 print Normalized x 
\ n % s % normalized _ x print 2 
Norm of normalized _ x % 2.4 f % np 
. linalg . norm normalized _ x x 0.49671415 0.1382643 
0.64768854 1.52302986 0.23415337 0.234136961 . 57921282 0.76743473 0.46947439 0.54256004 2 
Norm of x 2 . 5908Normalized x 0.19172213 0.05336737 0.24999534 
0.58786029 0.09037871 0.090372370 . 60954584 0.29621508 0.1812081 0.20941776 2 Norm 
of normalized _ x 1 . 0000from pyspark . mllib 
. feature import Normalizer normalizer = Normalizer vector = sc 
. parallelize x normalized _ x _ mllib = normalizer 
. transform vector . first . toArray print x \ 
n % s % x print 2 Norm of x 
% 2.4 f % norm _ x _ 2 print 
Normalized x MLlib \ n % s % normalized _ 
x _ mllib print 2 Norm of normalized _ x 
_ mllib % 2.4 f % np . linalg . 
norm normalized _ x _ mllib x 0.49671415 0.1382643 0.64768854 
1.52302986 0.23415337 0.234136961 . 57921282 0.76743473 0.46947439 0.54256004 2 Norm 
of x 2 . 5908Normalized x MLlib 0.19172213 0.05336737 0.24999534 
0.58786029 0.09037871 0.090372370 . 60954584 0.29621508 0 . 1812.20941776 2 
Norm of normalized _ x _ mllib 1.0000 