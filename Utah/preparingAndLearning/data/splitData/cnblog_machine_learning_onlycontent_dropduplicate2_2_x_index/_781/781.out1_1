网上 有 很多 关于 sklearn 的 学习 教程 大部分 都是/nr 
简单 的 讲清楚 某一方面 其实 最好 的 教程 就是 官方 
文档 官方 文档 地址 https / / scikit learn . 
org / stable / 可是 官方 文档 非常 详细 同时/c 
许多人/i 对/p 官方/n 文档/n 的/uj 理解/v 和/c 结构/n 上/f 都/d 
不能/v 很好/i 地/uv 把握/v 我 也 打算 好好 学习 sklearn 
这 可能 是 机器 学习 的 神器 下面 先 简单 
介绍 一下 sklearn 自 2007年 发布 以来 scikit learn 已经 
成为 Python 重要 的 机器学习 库 了 scikit learn 简称 
sklearn 支持 包括 分类 回归 降 维和 聚 类 四大 
机器学习 算法 还 包括 了 特征提取 数据 处理 和 模型 
评估 者 三大 模块 sklearn 是 Scipy 的 扩展 建立在 
Numpy 和 matplolib 库 的 基础 上 利用 这 几大 
模块 的 优势 可以 大大 的 提高 机器学习 的 效率 
sklearn 拥有 着 完善 的 文档 上手 容易 具有 着 
丰富 的 API 在 学术界 颇受欢迎 sklearn 已经 封装 了 
大量 的 机器学习 算法 包括 LIBSVM 和 LIBINEAR 同时 sklearn 
内置 了 大量 数据集 节省 了 获取 和 整理 数据集 
的 时间 一 sklearn 官方 文档 的 内容 和 结构 
1.1 sklearn 官方 文档 的 内容 定义 针对/p 经验/n E/w 
和/c 一系列/m 的/uj 任务/n T/w 和/c 一定/d 表现/v 的/uj 衡量/v 
P/w 如果 随着 经验 E 的 积累 针对 定义 好 
的 任务 T 可以 提高 表现 P 就 说明 机器 
具有 学习 能力 1.2 sklearn 官方 文档 结构 由 图中 
可以 看到 库 的 算法 主要有 四类 分类 回归 聚 
类 降 维 其中 常用 的 回归 线性 决策树 SVM 
KNN 集成 回归 随机 森林 Adaboost GradientBoosting Bagging ExtraTrees 常用 
的 分类 线性 决策树 SVM KNN 朴素 贝叶斯 集成 分类 
随机 森林 Adaboost GradientBoosting Bagging ExtraTrees 常用 聚 类 k 
均值 K means 层次 聚 类 Hierarchical clustering DBSCAN 常用 
降 维 L i n e a r D i 
s c r i m i n a n t 
A n a l y s i s PCA 这个 
流程图 代表 蓝色 圆圈 是 判断 条件 绿色 方框 是 
可以 选择 的 算法 我们 可以 根据 自己 的 数据 
特征 和 任务 目标 去 找 一条 自己 的 操作 
路线 sklearn 中 包含 众多 数据 预处理 和 特征 工程 
相关 的 模块 虽然 刚 接触 sklearn 时 大家 都会 
为 其中 包含 的 各种 算法 的 广度 深度 所 
震惊 但 其实 sklearn 六大板块 中有 两块 都是 关于 数据 
预处理 和 特征 工程 的 两个 板块 互相 交互 为 
建模 之前 的 全部 工程 打下基础 模块 preprocessing 几乎 包含 
数据 预处理 的 所有 内容 模块 Impute 填补 缺失 值 
专用 模块 feature _ selection 包含 特征选择 的 各种 方法 
的 实践 模块 decomposition 包含 降 维 算法 二 sklearn 
的 快速 使用 传统 的 机器 学习 任务 从 开始 
到 建模 的 一般 流程 就是 获取数据 数据 预处理 训练 
模型 模型 评估 预测 分类 本次 我们 将 根据 传统 
机器 学习 的 流程 看看 在 每一步 流程 中都 有 
哪些 常用 的 函数 以及 他们 的 用法 是 怎么样 
的 那么 首先 先看 一个 简单 的 例子 鸢尾花 识别 
是 一个 经典 的 机器学习 分类 问题 它 的 数据 
样本 中 包括 了 4个 特征 变量 1个 类别 变量 
样本 总数 为 150 它 的 目标 是 为了 根据 
花萼 长度 sepal length 花萼 宽度 sepal width 花瓣 长度 
petal length 花瓣 宽度 petal width 这四个 特征 来 识别 
出 鸢尾花 属 于山 鸢尾 iris setosa 变色 鸢尾 iris 
versicolor 和 维吉尼亚 鸢尾 iris virginica 中的 哪一种 # 引入 
数据集 sklearn 包含 众多 数据集 from sklearn import datasets # 
将 数据 分为 测试 集 和 训练 集 from sklearn 
. model _ selection import train _ test _ split 
# 利用 邻 近点 方式 训练 数据 from sklearn . 
neighbors import K N e i g h b o 
r s C l a s s i f i 
e r # 引入 数据 本次 导入 鸢尾花 数据 iris 
数据 包含 4个 特征 变量 iris = datasets . load 
_ iris # 特征 变量 iris _ X = iris 
. data # print iris _ X print 特征 变量 
的 长度 len iris _ X # 目标值 iris _ 
y = iris . target print 鸢尾花 的 目标 值 
iris _ y # 利用 train _ test _ split 
进行 训练 集 和 测试 机 进行 分开 test _ 
size 占 30% X _ train X _ test y 
_ train y _ test = train _ test _ 
split iris _ X iris _ y test _ size 
= 0.3 # 我们 看到 训练 数据 的 特征值 分为 
3类 # print y _ train 1 1 0 2 
0 0 0 2 2 2 1 0 2 0 
2 1 0 1 0 2 0 1 0 0 
2 1 2 0 0 1 0 0 1 0 
0 0 0 2 2 2 1 1 1 2 
0 2 0 1 1 1 1 2 2 1 
2 2 2 0 2 2 2 0 1 0 
1 0 0 1 2 2 2 1 1 1 
2 0 0 1 0 2 1 2 0 1 
2 2 2 1 2 1 0 0 1 0 
0 1 1 1 0 2 1 1 0 2 
2 # 训练 数据 # 引入 训练方法 knn = K 
N e i g h b o r s C 
l a s s i f i e r # 
进行 填充 测试数据 进行 训练 knn . fit X _ 
train y _ train params = knn . get _ 
params print params { algorithm auto leaf _ size 30 
metric minkowski metric _ params None n _ jobs None 
n _ neighbors 5 p 2 weights uniform } score 
= knn . score X _ test y _ test 
print 预测 得分 为 % s % score 预测 得分 
为 0 . 9555555555555556 1 2 1 1 2 2 
1 0 0 0 0 1 2 0 1 0 
2 0 0 0 2 2 0 2 2 2 
2 1 2 2 2 1 2 2 1 2 
0 2 1 2 1 1 0 2 1 1 
2 1 1 2 2 1 0 0 0 0 
1 2 0 1 0 2 0 0 0 1 
2 0 2 2 2 2 1 1 2 2 
1 2 2 1 2 0 2 1 2 1 
1 0 2 1 # 预测 数据 预测 特征值 print 
knn . predict X _ test 0 2 2 2 
2 0 0 0 0 2 2 0 2 0 
2 1 2 0 2 1 0 2 1 0 
1 2 2 0 2 1 0 2 1 1 
2 0 2 1 2 0 2 1 0 1 
2 # 打印 真实 特征值 print y _ test 1 
2 2 2 2 1 1 1 1 2 1 
1 1 1 2 1 1 0 2 1 1 
1 0 2 0 2 0 0 2 0 2 
0 2 0 2 2 0 2 2 0 1 
0 2 0 0 下面 我们 开始 一步步 介绍 1 
获取数据 1.1 导入 sklearn 数据集 sklearn 中 包含 了 大量 
的 优质 的 数据 集 在 我们 学习 机器 学习 
的 过程 中 我们 可以 使用 这些 数据集 实现 出 
不同 的 模型 从而 提高 你 动手 实践 能力 同时 
这个 过程 也 可以 加深 对 理论 知识 的 理解 
和 把握 除了 引入 数据 之外 我们 还 可以 通过 
load _ sample _ images 来 引入 图片 首先 要 
使用 sklearn 中的 数据集 必须 导入 datasets 模块 from sklearn 
import datasets 下面 两个 图中 包含 了 大部分 sklearn 中的 
数据集 调用 方式 也 图中 给出 这里 我们 使用 iris 
的 数据 来 举个 例子 表示 导出 数据集 iris = 
datasets . load _ iris # 导入 数据集 X = 
iris . data # 获得 其 特征向量 y = iris 
. target # 获得 样本 label1 . 1.1 手写 数字 
数据集 手写 数字 数据集 包含 1797个 0 9 的 手写 
数字 数据 每个 数据 由 8 * 8 大小 的 
矩阵 构成 矩阵 中值 的 范围 是 0 16 代表 
颜色 的 深度 使用 sklearn . datasets . load _ 
digits 即可 加载 相关 数据集 from sklearn . datasets import 
load _ digits digits = load _ digits print digits 
. data . shape print digits . target . shape 
print digits . images . shape 1797 64 1797 1797 
8 8 展示 如下 import matplotlib . pyplot as plt 
from sklearn . datasets import load _ digits digits = 
load _ digits plt . matshow digits . images 0 
plt . show 1.2 创建 数据集 我们 除了 可以 使用 
sklearn 自带 的 数据 集 还 可以 自己 去 创建 
训练样本 具体 用 法 可以 参考 https / / scikit 
learn . org / stable / datasets / 下面 我们 
拿 分类 问题 的 样本 生成器 举例子 from sklearn . 
datasets . samples _ generator import make _ classification X 
y = make _ classification n _ samples = 6 
n _ features = 5 n _ informative = 2 
n _ redundant = 2 n _ classes = 2 
n _ clusters _ per _ class = 2 scale 
= 1.0 random _ state = 20 # n _ 
samples 指定 样本数 # n _ features 指定 特征 数 
# n _ classes 指定 几 分类 # random _ 
state 随机 种子 使得 随机 状 可 重 测试 如下 
for x _ y _ in zip X y print 
y _ end = print x _ 0 0.6600737 0.0558978 
0.82286793 1.1003977 0.93493796 1 0.4113583 0.06249216 0.90760075 1.41296696 2.059838 1 
1.52452016 0.01867812 0.20900899 1.34422289 1.61299022 0 1.25725859 0.02347952 0.28764782 1.32091378 
0.88549315 0 3.28323172 0.03899168 0.43251277 2.86249859 1.10457948 1 1.68841011 0.06754955 
1.02805579 0.83132182 0.93286635 1 . 2.1   用 sklearn . 
datasets . make _ blobs 来 生成 数据 scikit 中的 
make _ blobs 方法 常被 用来 生成 聚 类 算法 
的 测试数据 直观 地 说 make _ blobs 会 根据 
用户 指定 的 特征 数量 中心点 数量 范围 等 来 
生成 几类 数据 这些 数据 可 用于 测试 聚 类 
算法 的 效果 sklearn . datasets . make _ blobs 
n _ samples = 100 n _ features = 2 
centers = 3 cluster _ std = 1.0 center _ 
box = 10.0 10.0 shuffle = True random _ state 
= None source 输入 n _ samples 表示 产生 多少 
个 数据 n _ features 表示 数据 是 几维 centers 
表示 数 据点 中心 可以 输入 int 数字 代表 有 
多少 个 中心 也 可以 输入 几个 坐标 fixed center 
locations cluster _ std 表示 分布 的 标准差 返回值 X 
n _ samples n _ features 形状 的 数组 代表 
产生 的 样本 y n _ samples 形状 的 数组 
代表 每个 点 的 标签 类别 例子 生成 三类 数据 
用于 聚 类 100个 样本 每个 样本 2个 特征 from 
sklearn . datasets import make _ blobs from matplotlib import 
pyplot data label = make _ blobs n _ samples 
= 100 n _ features = 2 centers = 5 
# 绘制 样本 显示 pyplot . scatter data 0 data 
1 c = label pyplot . show 结果 为 每个 
类别 设置 不同 的 方差 只 需要 在 上述 代码 
中 加入 cluster _ std 参数 即可 import matplotlib . 
pylab as plt from sklearn . datasets import make _ 
blobs # 每个 样本 有几个 属性 或者 特征 n _ 
features = 2 data target = make _ blobs n 
_ samples = 100 n _ features = 2 centers 
= 3 cluster _ std = 1.0 2.0 3.0 # 
在 2D 图中 绘制 样本 每个 样本 颜色 不同 plt 
. scatter data 0 data 1 c = target plt 
. show 1 . 2.2   用 sklearn . datasets 
. make _ classification 来 生成 数据 通常用于 分类 算法 
sklearn . datasets . make _ classification n _ samples 
= 100 n _ features = 20 n _ informative 
= 2 n _ redundant = 2 n _ repeated 
= 0 n _ classes = 2 n _ clusters 
_ per _ class = 2 weights = None flip 
_ y = 0.01 class _ sep = 1.0 hypercube 
= True shift = 0.0 scale = 1.0 shuffle = 
True random _ state = None 输入 n _ features 
特征 个数 = n _ informative + n _ redundant 
+ n _ repeatedn _ informative 多 信息 特征 的 
个数 n _ redundant 冗余 信息 informative 特征 的 随机 
线性组合 n _ repeated 重复 信息 随机 提取 n _ 
informative 和n_/nr redundant 特征 n _ classes 分类 类别 n 
_ clusters _ per _ class 某 一个 类别 是由 
几个 cluster 构成 的 1 . 2.3   用 sklearn 
. datasets . make _ gaussian 和 make _ hastie 
_ 10 _ 2 来 生成 数据 sklearn . datasets 
. make _ gaussian _ quantiles mean = None cov 
= 1.0 n _ samples = 100 n _ features 
= 2 n _ classes = 3 shuffle = True 
random _ state = None 利用 高斯 分 位点 区分 
不同 数据 sklearn . datasets . make _ hastie _ 
10 _ 2 n _ samples = 12000 random _ 
state = None 利用 Hastie 算法 生成 二 分类 数据 
import matplotlib . pyplot as plt from sklearn . datasets 
import make _ classification from sklearn . datasets import make 
_ blobs from sklearn . datasets import make _ gaussian 
_ quantiles from sklearn . datasets import make _ hastie 
_ 10 _ 2 plt . figure figsize = 8 
8 plt . subplots _ adjust bottom = . 05 
top = . 9 left = . 05 right = 
. 95 plt . subplot 421 plt . title One 
informative feature one cluster per class fontsize = small X1 
Y1 = make _ classification n _ samples = 1000 
n _ features = 2 n _ redundant = 0 
n _ informative = 1 n _ clusters _ per 
_ class = 1 plt . scatter X1 0 X1 
1 marker = o c = Y1 plt . subplot 
422 plt . title Two informative features one cluster per 
class fontsize = small X1 Y1 = make _ classification 
n _ samples = 1000 n _ features = 2 
n _ redundant = 0 n _ informative = 2 
n _ clusters _ per _ class = 1 plt 
. scatter X1 0 X1 1 marker = o c 
= Y1 plt . subplot 423 plt . title Two 
informative features two clusters per class fontsize = small X2 
Y2 = make _ classification n _ samples = 1000 
n _ features = 2 n _ redundant = 0 
n _ informative = 2 plt . scatter X2 0 
X2 1 marker = o c = Y2 plt . 
subplot 424 plt . title Multi class two informative features 
one cluster fontsize = small X1 Y1 = make _ 
classification n _ samples = 1000 n _ features = 
2 n _ redundant = 0 n _ informative = 
2 n _ clusters _ per _ class = 1 
n _ classes = 3 plt . scatter X1 0 
X1 1 marker = o c = Y1 plt . 
subplot 425 plt . title Three blobs fontsize = small 
X1 Y1 = make _ blobs n _ samples = 
1000 n _ features = 2 centers = 3 plt 
. scatter X1 0 X1 1 marker = o c 
= Y1 plt . subplot 426 plt . title Gaussian 
divided into four quantiles fontsize = small X1 Y1 = 
make _ gaussian _ quantiles n _ samples = 1000 
n _ features = 2 n _ classes = 4 
plt . scatter X1 0 X1 1 marker = o 
c = Y1 plt . subplot 427 plt . title 
hastie data fontsize = small X1 Y1 = make _ 
hastie _ 10 _ 2 n _ samples = 1000 
plt . scatter X1 0 X1 1 marker = o 
c = Y1 plt . show 结果 1 . 2.4 
  用 sklearn . datasets . make _ circles 和 
make _ moons 来 生成 数据 生成 环线 数据 sklearn 
. datasets . make _ circles n _ samples = 
100 shuffle = True noise = None random _ state 
= None factor = 0.8 factor 外环 和 内环 的 
尺度 因子 1sklearn . datasets . make _ moons n 
_ samples = 100 shuffle = True noise = None 
random _ state = None 生成 半环 图 from sklearn 
. datasets import make _ circles from sklearn . datasets 
import make _ moons import matplotlib . pyplot as plt 
import numpy as np fig = plt . figure 1 
x1 y1 = make _ circles n _ samples = 
1000 factor = 0.5 noise = 0.1 plt . subplot 
121 plt . title make _ circles function example plt 
. scatter x1 0 x1 1 marker = o c 
= y1 plt . subplot 122 x1 y1 = make 
_ moons n _ samples = 1000 noise = 0.1 
plt . title make _ moons function example plt . 
scatter x1 0 x1 1 marker = o c = 
y1 plt . show 结果 2 数据 预处理 数据 预处理 
阶段 是 机器 学习 中 不可缺少 的 一环 它 会 
使得 数据 更加 有效 的 被 模型 或者 评估器 识别 
下面 我们 来看 一下 sklearn 中 有 哪些 平时 我们 
常用 的 函数 from sklearn import preprocessing 为了 使得 训练 
数据 的 标准化 规则 与 测试 数据 的 标准化 规则 
同步 preprocessing 中 提供 了 很多 的 Scaler t a 
n d a r d c a l e r 
M a x A b s c a l e 
r M i n M a x c a l 
e r R o b u s t c a 
l e r N o r m a l i 
z e r 等 其他 预处理 操作 对应 的 有 
直接 的 函数 使用 scale maxabs _ scale minmax _ 
scale robust _ scale normaizer sklearn . preprocessing . scale 
X 2.1 数据 标准化 标准化 在 机器 学习 中 我们 
可能 要 处理 不同 种类 的 资料 例如 音讯 和 
图片 上 的 像素 值 这些 资料 可能 是 高纬度 
的 资料 标准化 后会 使得 每个 特征 中的 数值 平均 
变为 0 将 每个 特征 的 值 都 减掉 原始 
资料 中 该 特征 的 平均 标准差 变为 1 这个 
方法 被 广泛 的 使用 在 许多 机器学习 算法 中 
例如 支持 向量 机 逻辑 回归 和类/nr 神经网络 StandardScaler 计算 
训练 集 的 平均值 和 标准差 以便 测试数据 及 使用 
相同 的 变换 变换/v 后各维/nr 特征/n 有0/nr 均值/n 单位 方差 
也叫 z score 规范化 零 均值 规范化 计算 方式 是 
将 特征值 减去 均值 除以 标准差 fit 用于 计算 训练 
数据 的 均值 和 方差 后面/f 就/d 会用/n 均值/n 和/c 
方差/n 来/v 转换/v 训练/vn 数据/n fit/w _/i transform/w 不仅/c 计算/v 
训练/vn 数据/n 的/uj 均值/n 和/c 方差/n 还会 基于 计算 出来 
的 均值 和 方差 来 转换 训练 数据 从而 把 
数据 转化成 标准 的 正态分布 transform 很显然 它 只是 进行 
转换 只是 把 训练 数据 转换成 标准 的 正态分布 一般 
会把 train 和 test 集 放在 一起 做 标准化 或者 
在 train 集上 做 标准化 后 用 同样 的 标准 
化器 去 标准化 test 集 此时 可以 使用 scaler data 
= 0 0 0 0 1 1 1 1 # 
1 . 基于 mean 和 std 的 标准化 scaler = 
preprocessing . StandardScaler . fit train _ data scaler . 
transform train _ data scaler . transform test _ data 
一般来说 先 使用 fit scaler = preocessing . StandardScaler . 
fit X 这一步 可以 计算 得到 scaler scaler/w 里面/f 存/v 
的/uj 有/v 计算/v 出来/v 的/uj 均值/n 和/c 方差/n 再使用 transformscaler 
. transform X 这一步 再用 scaler 中的 均值 和 方差 
来 转换 X 使 X 标准化 最后 在 预测 的 
时候 也要 对 数据 做 同样 的 标准 化 处理 
即 也要 用上 面的 scaler 中的 均值 和 方差 来 
对 预测 时候 的 特征 进行 标准化 注意 测试数据/n 和/c 
预测/vn 数据/n 的/uj 标准化/vn 的/uj 方式/n 要/v 和/c 训练/vn 数据/n 
标准化/vn 的/uj 方式/n 一样/r 必须 使用 同一个 scaler 来 进行 
transform2 . 2 最小 最大 规范化 最小 最大 规范化 对 
原始 数据 进行 线性变换 变换 到 0 1 区间 也 
可以 是 其他 固定 最小 最大值 的 区间 # 2 
. 将 每个 特征值 归一化 到 一个 固定 范围 scaler 
= preprocessing . MinMaxScaler feature _ range = 0 1 
. fit train _ data scaler . transform train _ 
data scaler . transform test _ data # feature _ 
range 定义 归一化 范围 注 用 括 起来 2.3 正则化 
normalize 当 你 想要 计算 两个 样本 的 相似 度 
时 必不可少 的 一个 操作 就是 正则化 其 思想 是 
首先 求出 样本 的 p 范数 然后 该 样本 的 
所有 元素 都要 除 以该 范数 这样 最终 使得 每个 
样本 的 范数 都是 1 规范化 Normalization 是 将 不同 
变化 范围 的 值 映 射到 相同 的 固定 范围 
常见 的 是 0 1 也 成为 归一化 如下 例子 
将 每个 样本 变 换成 unit norm X = 1 
. 1 . 2 . . . . 2 . 
0 . 0 . . . . 0 . 1 
. 1 . X _ normalized = preprocessing . normalize 
X norm = l2 X _ normalized array 0.40 . 
. . 0.40 . . . 0.81 . . . 
1 . . . . 0 . . . . 
0 . . . . 0 . . . . 
0.70 . . . 0.70 . . . 我们 可以 
发现 对于 每 一个 样本 都有 0.4 ^ 2 + 
0.4 ^ 2 + 0.81 ^ 2 = 1 这 
就是 L2 norm 变换 后 每个 样本 的 各 维 
特征 的 平方和 为 1 . 类似 的 L1 norm 
则是 变换 后 每个 样本 的 各 维 特征 的 
绝对值 之和 为 1 . 还有 max norm 则是 将 
每个 样本 的 各 维 特征 除 以该 样本 各 
维 特征 的 最大值 在 度量 样本 之间 相似性 时 
如果 使用 的 是 二次型 kernel 则 需要 做 Normalization 
2.4 one hot 编码 one hot 编码 是 一种 对 
离散 特征值 的 编码方式 在 LR 模型 中 常用 到 
用于 给 线性 模型 增加 非线性 能力 data = 0 
0 3 1 1 0 0 2 1 1 0 
2 encoder = preprocessing . OneHotEncoder . fit data enc 
. transform data . toarray 2.5 特征 二 值 化 
Binarization 给定 阈值 将 特征 转换 为 0/1 . binarizer 
= sklearn . preprocessing . Binarizer threshold = 1.1 binarizer 
. transform X 2.6 类别 特征 编码 有时候 特征 时 
类别 型 的 而 一些 算法 的 输入 必须 是 
数值 型 此时 需要 对其 编码 enc = preprocessing . 
OneHotEncoder enc . fit 0 0 3 1 1 0 
0 2 1 1 0 2 enc . transform 0 
1 3 . toarray # array 1 . 0 . 
0 . 1 . 0 . 0 . 0 . 
0 . 1 . 上面 这个 例子 第/m 一维/m 特征/n 
有/v 两种/m 值/n 0/m 和1/nr 用 两位 去 编码 第 
二维 用 三位 第 三维 用 四位 2.7 标签 编码 
Label encoding le = sklearn . preprocessing . LabelEncoder le 
. fit 1 2 2 6 le . transform 1 
1 2 6 # array 0 0 1 2 # 
非 数值 型 转化 为 数值 型 le . fit 
paris paris tokyo amsterdam le . transform tokyo tokyo paris 
# array 2 2 1 3 数据集 拆分 在 得到 
训练 数据集 时 通常/d 我们/r 经常/d 会把/i 训练/vn 数据/n 进一步/d 
拆分/v 成/n 训练/vn 集/q 和/c 验证/v 集/q 这样 有助于 我们 
模型 参数 的 选取 train _ test _ split 是 
交叉 验证 中 常用 的 函数 功能 是从 样本 中 
随机 的 按比例 选取 train data 和 testdata 形式 为 
X _ train X _ test y _ train y 
_ test = cross _ validation . train _ test 
_ split train _ data train _ target test _ 
size = 0.4 random _ state = 0 参数 解释 
train _ data 所要 划分 的 样本 特 征集 train 
_ target 所要 划分 的 样本 结果 test _ size 
样本 占 比 如果 是 整数 的话 就是 样本 的 
数量 random _ state 是 随机数 的 种子 随机数 种子 
其实 就是 该组 随机数 的 编号 在 需要 重复 试验 
的 时候 保证 得 到 一组 一样 的 随机数 比如 
你 每次 都填1/nr 其他 参数 一样 的 情况 下 你 
得到 的 随机 数组 是 一样 的 但 填 0 
或不 填 每次 都会 不 一样 随机数 的 产生 取决于 
种子 随机数 和 种子 之间 的 关系 遵从 以下 两个 
规则 种子 不同 产生 不同 的 随机数 种子 相同 即使 
实例 不同 也 产生 相同 的 随机数 参数 说明 示例 
# 作用 将 数据集 划分为 训练 集 和 测试 集 
# 格式 train _ test _ split * arrays * 
* options from sklearn . mode _ selection import train 
_ test _ split X _ train X _ test 
y _ train y _ test = train _ test 
_ split X y test _ size = 0.3 random 
_ state = 42 参数 arrays 样本 数组 包含 特征向量 
和 标签 test _ size float 获得 多 大 比重 
的 测试 样本 默认 0.25 int 获得 多少 个 测试 
样本 train _ size 同 test _ size random _ 
state int 随机 种子 种子 固定 实验 可 复现 shuffle 
是否 在 分割 之前 对 数据 进行 洗牌 默认 True 
返回 分割 后的/nr 列表 长度 = 2 * len arrays 
train test split 拆分 参数 遇到 的 问题 及其 解决 
方法 导入 模块 from sklearn . cross _ validation import 
cross _ val _ score 则会 报错 代码 如下 from 
sklearn . cross _ validation import cross _ val _ 
score M o d u l e N o t 
F o u n d E r r o r 
No module named sklearn . cross _ validation 解决 方法 
from sklearn . model _ selection import cross _ val 
_ score4 定义 模型 在 这 一步 我们 首先 要 
分析 自己 数据 的 类型 明白 自己 要 用 什么 
模型 来做 然后 我们 就 可以 在 sklearn 中 定义 
模型 了 sklearn 为 所有 模型 提供 了 非常 相似 
的 接口 这样 使得 我们 可以 更加 快速 的 熟悉 
所有 模型 的 用法 在这之前 我们 先 来 看看 模型 
的 常用 属性 和 功能 # 拟合 模型 model . 
fit X _ train y _ train # 模型 预测 
model . predict X _ test # 获得 这个 模型 
的 参数 model . get _ params # 为 模型 
进行 打分 model . score data _ X data _ 
y # 线性 回归 R square 分类 问题 acc4 . 
1 线性 回归 from sklearn . linear _ model import 
LinearRegression # 定义 线性 回归模型 model = LinearRegression fit _ 
intercept = True normalize = False copy _ X = 
True n _ jobs = 1 参数 fit _ intercept 
是否 计算 截距 False 模型 没有 截距 normalize 当 fit 
_ intercept 设置 为 False 时 该 参数 将被 忽略 
如果 为真 则 回归 前 的 回归系数 X 将 通过 
减去 平均值 并 除以 l2 范数 而 归一化 n _ 
jobs 指定 线程数 4.2 逻辑 回归 LRfrom sklearn . linear 
_ model import L o g i s t i 
c R e g r e s s i o 
n # 定义 逻辑 回归模型 model = L o g 
i s t i c R e g r e 
s s i o n penalty = l2 dual = 
False tol = 0.0001 C = 1.0 fit _ intercept 
= True intercept _ scaling = 1 class _ weight 
= None random _ state = None solver = liblinear 
max _ iter = 100 multi _ class = ovr 
verbose = 0 warm _ start = False n _ 
jobs = 1 参数 penalty 使用 指定 正则化 项 默认 
l2 dual n _ samples n _ features 取 False 
默认 C 正则化 强度 的 反 值 越小 正则化 强度 
越大 n _ jobs 指定 线程数 random _ state 随机数 
生成器 fit _ intercept 是否 需要 常量 4.3 朴素 贝叶斯 
算法 NB Naive Bayes from sklearn import naive _ bayes 
model = naive _ bayes . GaussianNB # 高斯 贝叶斯 
model = naive _ bayes . MultinomialNB alpha = 1.0 
fit _ prior = True class _ prior = None 
model = naive _ bayes . BernoulliNB alpha = 1.0 
binarize = 0.0 fit _ prior = True class _ 
prior = None 文本 分类 问题 常用 MultinomialNB 参数 alpha 
平滑 参数 fit _ prior 是否 要 学习 类 的 
先验概率 false 使用 统一 的 先验概率 class _ prior 是否 
指定 类 的 先验概率 若 指定 则 不能 根据 参数 
调整 binarize 二 值 化 的 阈值 若为 None 则 
假设 输入 由 二进制 向量 组成 4.4 决策树 DTfrom sklearn 
import tree model = tree . D e c i 
s i o n T r e e C l 
a s s i f i e r criterion = 
gini max _ depth = None min _ samples _ 
split = 2 min _ samples _ leaf = 1 
min _ weight _ fraction _ leaf = 0.0 max 
_ features = None random _ state = None max 
_ leaf _ nodes = None min _ impurity _ 
decrease = 0.0 min _ impurity _ split = None 
class _ weight = None presort = False 参数 criterion 
特征选择 准则 gini / entropy max _ depth 树 的 
最大 深度 None 尽量 下 分 min _ samples _ 
split 分裂 内部 节点 所 需要 的 最小 样本 树 
min _ samples _ leaf 叶子 节点 所 需要 的 
最小 样本数 max _ features 寻找 最优 分割 点 时的/nr 
最大 特征 数 max _ leaf _ nodes 优先 增长 
到 最大 叶子 节 点数 min _ impurity _ decrease 
如果 这种 分离 导致 杂质 的 减少 大于 或 等于 
这个 值 则 节点 将被 拆分 4.5 支持 向量 机 
SVMfrom sklearn . svm import SVC model = SVC C 
= 1.0 kernel = rbf gamma = auto 参数 C 
误差 项的/nr 惩罚 参数 C gamma 核 相关系数 浮点数 If 
gamma is auto then 1 / n _ features will 
be used instead . 4.6 k 近邻 算法 KNNfrom sklearn 
import neighbors # 定义 kNN 分类 模型 model = neighbors 
. K N e i g h b o r 
s C l a s s i f i e 
r n _ neighbors = 5 n _ jobs = 
1 # 分类 model = neighbors . K N e 
i g h b o r s R e g 
r e s s o r n _ neighbors = 
5 n _ jobs = 1 # 回归 参数 n 
_ neighbors 使用 邻居 的 数目 n _ jobs 并行任务 
数 4.7 多层 感知器 神经网络 from sklearn . neural _ 
network import MLPClassifier # 定义 多层 感知机 分类 算法 model 
= MLPClassifier activation = relu solver = adam alpha = 
0.0001 参数 hidden _ layer _ sizes 元祖 activation 激活 
函数 solver 优化 算法 { lbfgs sgd adam } alpha 
L2 惩罚 正则化 项 参数 5 模型 评估 与 选择 
评价 指标 针对 不同 的 机器 学习 任务 有 不同 
的 指标 同一 任务 也 有 不同 侧重点 的 评价 
指标 以下 方法 sklearn 中 都在 sklearn . metrics 类 
下 务必 记住 那些 指标 适合 分类 那些 适合 回归 
机器学习 常用 的 评估 指标 请 参考 博文 Python 机器学习 
笔记 常用 评估 指标 的 前世 今生 5.1 交叉 验证 
交叉 验证 cross _ val _ score 的 scoring 参数 
分类 accuracy 准确率 f1 f1 _ micro f1 _ macro 
这 两个 用于 多 分类 的 f1 _ score precision 
精确度 recall 召回率 roc _ auc 回归 neg _ mean 
_ squared _ error MSE 均方 误差 r2 聚 类 
adjusted _ rand _ score completeness _ score 等 from 
sklearn . model _ selection import cross _ val _ 
score cross _ val _ score model X y = 
None scoring = None cv = None n _ jobs 
= 1 参数 model 拟合 数据 的 模型 cv k 
fold scoring 打分 参数 accuracy f1 precision recall roc _ 
auc neg _ log _ loss 等等 补充 交叉 验证 
的 学习 1 导入 k 折 交叉 验证 模块 from 
sklearn . model _ selection import cross _ val _ 
score2 交叉 验证 的 思想 把 某种 意义 下 将 
原始数据 dataset 进行 分组 一 部分 作为 训练 集 train 
set 另一 部分 作为 验证 集 validation set or test 
set 首先 用 训练 集 对 分类器 进行 训练 再利用 
验证 集 来 测试 训练 得到 的 模型 model 以此 
来 作为 评价 分类器 的 性能 指标 3 为什么 使用 
交叉 验证法 交叉 验证 用于 评估 模型 的 预测 性能 
尤其 是 训练 好 的 模型 在 新 数据 上 
的 表现 可以 在 一定 程序 熵 减少 过拟合 交叉 
验证 还 可以 从 有限 的 数据 中 获取 尽可能 
多 的 有效 信息 4 主要 有 哪些 方法 1 
留 出法 holdout cross validation 在 机器 学习 任务 中 
拿到 数据 后 我们 首先 会 将 原始 数据集 分为 
三 部分 训练 集 验证 集 和 测试 集 训练 
集 用于 训练 模型 验证 集 用于 模型 的 参数 
选择 配置 测试 集 对于 模型 来说 是 未知 数据 
用于 评估 模型 的 泛化 能力 这个 方法 操作 简单 
只需要 随机 将 原始数据 分为 三组 即可 不过 如果 只 
做 一次 分割 它 对 训练 集 验证 集 和 
测试机 的 样本 比例 还有/v 分割/v 后/f 数据/n 的/uj 分布/v 
是否/v 和/c 原始/v 数据集/i 的/uj 分布/v 相同/d 等/u 因素/n 比较/d 
敏感/a 不同 的 划分 会 得到 不同 的 最优 模型 
而且 分成 三个 集合 后 用于 训练 的 数据 更 
少了 于是 又 了 2 . k 折 交叉 验证 
k fold cross validation . 下面 例子 一 共有 150条 
数据 import numpy as np from sklearn . model _ 
selection import train _ test _ split from sklearn import 
datasets from sklearn import svm iris = datasets . load 
_ iris iris . data . shape iris . target 
. shape 150 4 150 用 train _ test _ 
split 来 随机 划分 数据集 其中 40% 用于 测试 集 
有 60条 数据 60% 为 训练 集 有 90条 数据 
X _ train X _ test y _ train y 
_ test = train _ test _ split . . 
. iris . data iris . target test _ size 
= 0.4 random _ state = 0 X _ train 
. shape y _ train . shape 90 4 90 
X _ test . shape y _ test . shape 
60 4 60 用 train 来 训练 用 test 来 
评价 模型 的 分数 clf = svm . SVC kernel 
= linear C = 1 . fit X _ train 
y _ train clf . score X _ test y 
_ test 0.96 . . . 2 2 . k 
折 交叉 验证 k fold cross validation K 折 交叉 
验证 通过 对 k 个 不同 分组 训练 的 结果 
进行 平均 来 减少 方差 因此 模型 的 性能 对 
数据 的 划分 就不 那么 敏感 第一步 不 重复抽样 将 
原始数据 随机 分为 k 份 第二步 每一次 挑选 其中 1 
份 作为 测试 集 剩余 k 1 份 作为 训练 
集 用于 模型 训练 第三步 重复 第二步 k 次 这样 
每个 子集 都有 一次 机会 作为 测试 集 其余 机会 
作为 训练 集 在 每个 训练 集上 训练 后 得到 
一个 模型 用 这个 模型 在 相应 的 测试 集上 
测试 计算 并 保存 模型 的 评估 指标 第四步 计算 
k 组 测试 结果 的 平均 值 作为 模型 精度 
的 估计 并 作为 当前 k 折 交叉 验证 下 
模型 的 性能 指标 K 一般 取 10 数据 量小 
的 是 k 可以 设 大 一点 这样 训练 集 
占 整体 比例 就 比较 大 不过 同时 训练 的 
模型 个数 也 增多 数据 量大 的 时候 k 可以 
设置 小 一点 当 k = m 的 时候 即 
样本 总数 出现 了 留 一 法 举例 这里 直接 
调 用了 cross _ val _ score 这里 用了 5 
折 交叉 验证 from sklearn . model _ selection import 
cross _ val _ score clf = svm . SVC 
kernel = linear C = 1 scores = cross _ 
val _ score clf iris . data iris . target 
cv = 5 scores array 0.96 . . . 1 
. . . . 0.96 . . . 0.96 . 
. . 1 . 得 到最后 平均 分数 为 0.98 
以及 它 的 95% 置信区间 print Accuracy % 0.2 f 
+ / % 0.2 f % scores . mean scores 
. std * 2 Accuracy 0.98 + / 0.03 我们 
可以 直接 看 一下 K Fold 是 怎么样 划分 数据 
的 X 有 四个 数据 把 它 分成 2 折 
结构 中 最后 一个 集合 是 测试 集 前面 的 
是 训练 集 每一 行为 1 折 import numpy as 
np from sklearn . model _ selection import KFold X 
= a b c d kf = KFold n _ 
splits = 2 for train test in kf . split 
X . . . print % s % s % 
train test 2 3 0 1 0 1 2 3 
同样 的 数据 X 我们 来看 LeaveOneOut 后是/nr 什么 样子 
那 就是 把 它 分成 4 折 结果 中 最后 
一个 集合 是 测试 集 只有 一个 元素 前面 的 
是 训练 集 每一 行为 1 折 from sklearn . 
model _ selection import LeaveOneOut X = 1 2 3 
4 loo = LeaveOneOut for train test in loo . 
split X . . . print % s % s 
% train test 1 2 3 0 0 2 3 
1 0 1 3 2 0 1 2 3 3 
留 一 法 Leave one out cross validation 每次 的 
测试 集 都 只有 一个 样本 要 进行 m 次 
训练 和 预测 这个 方法 用于 训练 的 数据 只比 
整体 数据集 少 一个 样本 因此 最接近 原始 样本 的 
分布 但是 训练 复杂度 增加 了 因为 模型 的 数量 
与 原始数据 样本 数量 相同 一般 在 数据 缺少 时 
使用 此外 多次 k 折 交叉 验证 再 求 均值 
例如 10 次 10 折 交叉 验证 以求 更 精确 
一点 划分 时有 多种 方法 例 如对 非平衡 数据 可以 
用 分层 采样 就是/d 在/p 每/zg 一份/m 子/ng 集中/v 都/d 
保持/v 和/c 原始/v 数据集/i 相同/d 的/uj 类别/n 比例/n 模型 训练 
过程 的 所有 步骤 包括 模型 选择 特征选择 等 都是 
在 单个 折叠 fold 中 独立 执行 的 4 Bootstrapping 
通过 自助 采样法 即在 含有 m 个 样本 的 数据 
集中 每次 随机 挑选 一个 样本 再放 回到 数据 集中 
再 随机 挑选 一个 样本 这样有 放回 地 进行 抽样 
m 次 组成 了 新的 数据集 作为 训练 集 这里会 
有 重复 多次 的 样本 也会/i 有/v 一次/m 都/d 没有/v 
出现/v 的/uj 样本/n 原 数据 集中 大概有 36.8% 的 样本 
不会 出现 在 新 组 数据 集中 优点 是 训练 
集 的 样本 总数 和原/nr 数据集 一样 都是 m 并且 
仍 有约 1/3 的 数据 不被 训练 而 可以 作为 
测试 集 缺点 是 这样 产生 的 训练 集 的 
数据 分布 和原/nr 数据集 的 不 一样 了 会 引入 
估计 偏差 此种 方法 不是 很 常用 除非 数据量 真的 
很少 5.2 检验 曲线 使用 检验 曲线 我们 可以 更加 
方便 的 改变 模型 参数 获取 模型 表现 from sklearn 
. model _ selection import validation _ curve train _ 
score test _ score = validation _ curve model X 
y param _ name param _ range cv = None 
scoring = None n _ jobs = 1 参数 model 
用于 fit 和 predict 的 对象 X y 训练 集 
的 特征 和 标签 param _ name 将被 改变 的 
参数 的 名字 param _ range 参数 的 改变 范围 
cv k fold 返回值 train _ score 训练 集 得分 
array test _ score 验证 集 得分 array 5.3 分类 
模型 accuracy _ score 准确率 得分 是 模型 分类 正确 
的 数据 除以 样本 总数   模型 的 score 方法 
算 的 也是 准确率 accuracy _ score y _ test 
y _ pre # 或者 model . score x _ 
test y _ test 大多 模型 都是 有 score 方法 
的 classification _ report 中的 各项 得分 的 avg / 
total 是 每一 分类 占 总数 的 比例 加权 算 
出来 的 print classification _ report y _ test y 
_ log _ pre precision recall f1 score support 0 
0.87 0.94 0.90 105 1 0.91 0.79 0.85 73 avg 
/ total 0.88 0.88 0.88 178confusion _ matrix 混淆 矩阵 
用来 评估 分类 的 准确性 from sklearn . metrics import 
confusion _ matrix y _ true = 2 0 2 
2 0 1 y _ pred = 0 0 2 
2 0 2 confusion _ matrix y _ true y 
_ pred array 2 0 0 0 0 1 1 
0 2 precision _ score 精确度 recall _ score 召回率 
f1 _ score 后者 由 前 两个 推导 出 的 
这三个 不仅 适合 二 分类 也 适合 多 分类 只 
需要 指出 参数 average = micro / macro / weighted 
macro 计算 二 分类 metrics 的 均值 为 每个 类 
给出 相同 权重 的 分值 当 小 类 很重要 时会 
出问题 因为 该 macro averging 方法 是 对 性能 的 
平均 另一方面 该 方法 假设 所有 分类 都是 一样 重要 
的 因此 macro averaging 方法 会对 小 类 的 性能 
影响 很大 micro 给出 了 每个 样本 类 以及 它 
对 整个 metrics 的 贡献 的 pair sample weight 而非 
对 整个 类 的 metrics 求和 它 会 每个 类 
的 metrics 上 的 权重 及 因子 进行 求和 来 
计算 整个 份额 Micro averaging 方法 在 多 标签 multilabel 
问题 中 设置 包含 多 分类 此时 大类 将被 忽略 
weighted 对于 不 均衡 数量 的 类 来说 计算 二 
分类 metrics 的 平均 通过 在 每个 类 的 score 
上 进行 加权 实现 roc _ curve ROC 曲线 用于 
二 分类 6 保存 模型 最后 我们 可以 将 我们 
训 练好 的 model 保存 到 本地 或者 放到 线上 
供 用户 使用 那么 如何 保存 训 练好 的 model 
呢 主要 有 下面 两种 方式 6.1 保存为 pickle 文件 
import pickle # 保存 模型 with open model . pickle 
wb as f pickle . dump model f # 读取 
模型 with open model . pickle rb as f model 
= pickle . load f model . predict X _ 
test 6.2 sklearn 自带 方法 joblibfrom sklearn . externals import 
joblib # 保存 模型 joblib . dump model model . 
pickle # 载入 模型 model = joblib . load model 
. pickle 7 模型 评分 1 模型 的 score 方法 
最 简单 的 模型 评估 方法 就是 调用 模型 自己 
的 方法 # 预测 y _ predict = knnClf . 
predict x _ test print score on the testdata knnClf 
. score x _ test y _ test 2 sklearn 
的 指标 函数 库 提供 的 一些 计算方法 常用 的 
有 classification _ report 方法 3 sklearn 也 支持 自己 
开发 评价 方法 8 几种 交叉 验证 cross validation 方式 
的 比较 模型 评价 的 目的 通过 模型 评价 我们 
知道 当前 训练 模型 的 好坏 泛化 能力 如何 从而 
知道 是否 可以 应用 在 解决 问题 上 如果 不行 
那 又是 那些 出了 问题 train _ test _ split 
在 分类 问题 中 我们 通常 通过 对 训练 集 
进行 triain _ test _ split 划分 出 train 和 
test 两部分 其中 train 用来 训练 模型 test 用来 评估 
模型 模型 通过 fit 方法 从 train 数据 集中 学习 
然后 调用 score 方法 在 test 集上 进行 评估 打分 
从 分数 上 我们 知道 模型 当前 的 训练 水平 
如何 from sklearn . datasets import load _ breast _ 
cancer from sklearn . model _ selection import train _ 
test _ split from sklearn . linear _ model import 
L o g i s t i c R e 
g r e s s i o n import matplotlib 
. pyplot as plt cancer = load _ breast _ 
cancer X _ train X _ test y _ train 
y _ test = train _ test _ split cancer 
. data cancer . target random _ state = 0 
logreg = L o g i s t i c 
R e g r e s s i o n 
. fit X _ train y _ train print Test 
set score { . 2f } . format logreg . 
score X _ test y _ test 结果 Test set 
score 0.96 然而 这 这 方式 只 进行 了 一次 
划分 数据 结果 具有 偶然性 如果在 某次 划分 中 训练 
集 里 全是 容易 学习 的 数据 测试 集 里 
全是 复杂 的 数据 这样 的 就 会 导致 最终 
的 结果 不尽人意 Standard Cross Validation 针对 上面 通过 train 
_ test _ split 划分 从而 进行 模型 评估 方式 
存在 的 弊端 提出 Cross Validation 交叉 验证 Cross Validation 
进行 多次 train _ test _ split 划分 每次 划 
分时 在 不同 的 数据 集上 进行 训练 测试 评估 
从而 得到 一个 评价 结果 如果 是 5 折 交叉 
验证 意思 就是 在 原始数据 集上 进行 五次 划分 每次 
划分 进行 一次 训练 评估 最后 得到 5次 划分 后的/nr 
评估 结果 一般 在 这几次 评估 结果 上 取平 均 
得到 最后 的 评分 k folf cross validation 其中 K 
一般 取 5 或 10 代码 from sklearn . model 
_ selection import cross _ val _ score from sklearn 
. datasets import load _ breast _ cancer from sklearn 
. model _ selection import train _ test _ split 
from sklearn . linear _ model import L o g 
i s t i c R e g r e 
s s i o n import warnings warnings . filterwarnings 
ignore cancer = load _ breast _ cancer X _ 
train X _ test y _ train y _ test 
= train _ test _ split cancer . data cancer 
. target random _ state = 0 logreg = L 
o g i s t i c R e g 
r e s s i o n # CV 默认 
是 3 折 交叉 验证 可以 修改 cv = 5 
变为 5 折 交叉 验证 scores = cross _ val 
_ score logreg cancer . data cancer . target print 
Cross validation scores { } . format scores print Mean 
cross validation score { 2f } . format scores . 
mean 结果 Cross validation scores 0.93684211 0.96842105 0.94179894 Mean cross 
validation score 0.949021 交叉 验证 的 优点 原始 采用 的 
train _ test _ split 方法 数据 划分 具有 偶然性 
交叉 验证 通过 多次 划分 大大 降低 了 这种 由 
一次 随机 划分 带来 的 偶然性 同时 通过 多次 划分 
多次 训练 模型 也 能 遇到 各种各样 的 数据 从而 
提高 其 泛化 能力 与 原始 的 train _ test 
_ split 相比 对 数据 的 使用 效率 更高 train 
_ test _ split 默认 训练 集 测试 集 比例 
为 3 1 而对 交叉 验证 来说 如果 是 5 
折 交叉 验证 训练 集 比 测试 集为 4 1 
10 折 交叉 验证 训练 集 比 测试 集为 9 
1 . 数据 量 越大 模型 准确率 越高 交叉 验证 
的 缺点 这种 简答 的 交叉 验证 方式 从 上面 
的 图片 可以 看 出来 每次 划 分时 对 数据 
进行 均分 设想 一下 会 不会 存在 一种 情况 数据集 
有 5类 抽取 出来 的 也 正好 是 按照 类别 
划分 的 5类 也 就是说 第 一折 全是 0类 第二折 
全是 1类 等等 这样 的 结果 就 会 导致 模型 
训练 时 没有 学习 到 测试 集中 数据 的 特点 
从而 导致 模型 得分 很低 甚至 为 0 为 避免 
这种 情况 又 出现 了 其他 的 各种 交叉 验证 
方式 Stratifid k fold cross validation 分层 交叉 验证 Stratified 
k fold cross validation 首先 它 属于 交叉 验证 类型 
分层 的 意思 是 说 在 每一 折中 都 保持 
着 原始 数据 中 各个 类别 的 比例 关系 比如说 
原始数据 有 3类 比例 为 1 2 1 采用 3 
折 分层 交叉 验证 那么 划分 的 3 折中 每一 
折中 的 数据 类别 保持着 1 2 1 的 比例 
这样 的 验证 结果 更加 可信 通常 情况下 可以 设置 
cv 参数 来 控制 几 折 但是 我们 希望 对其 
划 分等 加以控制 所以 出现 了 KFold KFold 控制 划分 
折 可以 控制 划分 折 的 数目 是否 打乱 顺序 
等 可以 赋值 给 cv 用来 控制 划分 代码 from 
sklearn . datasets import load _ iris from sklearn . 
model _ selection import StratifiedKFold cross _ val _ score 
from sklearn . linear _ model import L o g 
i s t i c R e g r e 
s s i o n import warnings warnings . filterwarnings 
ignore iris _ data = load _ iris logreg = 
L o g i s t i c R e 
g r e s s i o n strKFold = 
StratifiedKFold n _ splits = 3 shuffle = False random 
_ state = 0 scores = cross _ val _ 
score logreg iris _ data . data iris _ data 
. target cv = strKFold print straitified cross validation scores 
{ } . format scores print Mean score of straitified 
cross validation { . 2f } . format scores . 
mean 结果 straitified cross validation scores 0.96078431 0.92156863 0.95833333 Mean 
score of straitified cross validation 0 . 95Leave one out 
Cross validation 留/v 一/m 法留一/nr 法/l Leave/w one out Cross 
validation 是 一种 特殊 的 交叉 验证 方式 顾名思义 如果 
样本容量 为 n 则 k = n 进行 n 折 
交叉 验证 每次 留下 一个 样本 进行 验证 主要 针对 
小 样本数据 代码 from sklearn . datasets import load _ 
iris from sklearn . model _ selection import LeaveOneOut cross 
_ val _ score from sklearn . linear _ model 
import L o g i s t i c R 
e g r e s s i o n import 
warnings warnings . filterwarnings ignore iris = load _ iris 
logreg = L o g i s t i c 
R e g r e s s i o n 
loout = LeaveOneOut scores = cross _ val _ score 
logreg iris . data iris . target cv = loout 
print leave one out cross validation scores { } . 
format scores print Mean score of leave one out cross 
validation { . 2f } . format scores . mean 
结果 leave one out cross validation scores 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 0 
. 1 . 1 . 1 . 0 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 0 . 0 . 0 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 0 . 1 . 1 
. 1 . 0 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . 1 . 1 
. 1 . 1 . 1 . Mean score of 
leave one out cross validation 0 . 95Shuffle split cross 
validation 控制 更加 灵活 可以 控制 划分 迭代 次数 每次 
划分 测试 集 和 训练 集 的 比例 也就 说 
可以 存在 机 不再 训练 集 也 不再 测试 集 
的 情况 代码 from sklearn . datasets import load _ 
iris from sklearn . model _ selection import ShuffleSplit cross 
_ val _ score from sklearn . linear _ model 
import L o g i s t i c R 
e g r e s s i o n import 
warnings warnings . filterwarnings ignore iris = load _ iris 
# 迭代 八次 shufsp1 = ShuffleSplit train _ size = 
0.5 test _ size = 0.4 n _ splits = 
8 logreg = L o g i s t i 
c R e g r e s s i o 
n scores = cross _ val _ score logreg iris 
. data iris . target cv = shufsp1 print shuffle 
split cross validation scores \ n { } . format 
scores print Mean score of shuffle split cross validation { 
. 2f } . format scores . mean 结果 shuffle 
split cross validation scores 0.95 1 . 0.86666667 0.95 0.88333333 
0.88333333 0.85 0.9 Mean score of shuffle split cross validation 
0.91 参考文献 http / / www . cnblogs . com 
/ lianyingteng / p / 7811126 . htmlhttps / / 
www . cnblogs . com / magle / p / 
5638409 . htmlhttps / / blog . csdn . net 
/ u014248127 / article / details / 78885180https / / 
www . cnblogs . com / ysugyl / p / 
8707887 . html 