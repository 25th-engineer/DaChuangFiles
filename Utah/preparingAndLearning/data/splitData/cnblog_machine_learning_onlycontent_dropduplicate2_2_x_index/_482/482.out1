常见 的 机器学习 模型 感知机 线性 回归 逻辑 回归 支持 
向量 机 决策树 随机 森林 GBDT XGBoost 贝叶斯 KNN K 
means 等 常见 的 机器 学习理论 过拟合 问题 交叉 验证 
问题 模型 选择 问题 模型 融合 问题 等 K 近邻 
算法 采用 测量 不同 特征值 之间 的 距离 的 方法 
进行 分类 优点 1 . 简单 好用 容易 理解 精度高 
理论 成熟 既 可以 用来 做 分类 也 可以 用来 
做 回归 2 . 可 用于 数值 型 数据 和 
离散 型 数据 3 . 训练 时间 复杂度 为 O 
n 无 数据 输入 假定 4 . 对 异常值 不 
敏感 缺点 1 . 计算 复杂性 高 空间 复杂性 高 
2 . 样本 不 平衡 问题 即 有些 类别 的 
样本 数量 很多 而 其它 样本 的 数量 很少 3 
. 一般 数值 很大 的 时候 不 用 这个 计算 
量 太大 但是 单个/nr 样本 又不能 太少 否则 容易 发生 
误 分 4 . 最大 的 缺点 是 无法 给出 
数据 的 内在 含义 朴素 贝叶斯 优点 1 . 生成式 
模型 通过 计算 概率 来 进行 分类 可以 用来 处理 
多分 类 问题 2 . 对 小 规模 的 数据 
表现 很好 适合 多 分类 任务 适合 增量 式 训练 
算法 也 比较 简单 缺点 1 . 对 输入 数据 
的 表达 形式 很 敏感 2 . 由于 朴素 贝叶斯 
的 朴素 特点 所以 会 带来 一些 准确率 上 的 
损失 需要 一个 比较 容易 解释 而且 不同 维度 之间 
相关性 较小 的 模型 的 时候 3 . 需要 计算 
先验概率 分类 决策 存在 错误率 决策树 优点 1 . 概念 
简单 计算 复杂度 不高 可解释 性强 输出 结果 易于 理解 
2 . 数据 的 准备 工作 简单 能够 同时 处理 
数据 型 和 常规 型 属性 其他 的 技术 往往 
要求 数据 属性 的 单一 3 . 对 中间 值得 
确实 不 敏感 比较 适合 处理 有 缺失 属性值 的 
样本 能够 处理 不 相关 的 特征 4 . 应用 
范围 广 可以 对 很多 属性 的 数据 集 构造 
决策树 可扩展 性强 决策树 可以 用于 不 熟悉 的 数据 
集合 并从 中 提取 出 一些 列 规则 这 一点 
强于 KNN 缺点 1 . 容易 出现 过拟合 2 . 
对于 那些 各 类别 样本 数量 不 一致 的 数据 
在 决策树 当中 信息 增益 的 结果 偏向 于 那些 
具有 更多 数值 的 特征 3 . 信息 缺 失时 
处理 起来 比较 困难 忽略 数据 集中 属性 之间 的 
相关性 4 . 同时 它 也是 相对 容易 被 攻击 
的 分类器 这里 的 攻击 是 指 人为 的 改变 
一些 特征 使得 分类器 判断 错误 随机 森林 严格来说 随机 
森林 其实 算是 一种 集成 算法 它 首先 随机 选取 
不同 的 特征 feature 和 训练样本 training sample 生成 大量 
的 决策树 然后 综合 这些 决策树 的 结果 来 进行 
最终 的 分类 随机 森林 在 现实 分析 中 被 
大量 使用 它 相对于 决策树 在 准确性 上有 了 很大 
的 提升 同时 一定 程度 上 改善 了 决策树 容易 
被 攻击 的 特点 适用 情景 数据 维度 相对 低 
几十 维 同时 对 准确性 有 较高 要求 时 因为 
不 需要 很多 参数 调整 就 可以 达到 不错 的 
效果 基本上 不 知道 用 什么 方法 的 时候 都 
可以 先 试一下 随机 森林 Svm 优点 1 . 可 
用于 线性 / 非线性 分类 也 可以 用于 回归 泛化 
错误率 低 计算 开销 不大 结果 容易 解释 2 . 
可以 解决 小 样本 情况下 的 机器 学习 问题 可以 
解决 高维 问题 可以 避免 神经 网络结构 选择 和 局部 
极小 点 问题 3 . SVM 是 最好 的 现成 
的 分类器 现成 是 指 不加 修改 可 直接 使用 
并且 能够 得到 较低 的 错误率 SVM 可以 对 训练 
集 之外 的 数据 点 做 很好 的 分类 决策 
4 . SVM 尽量 保持 与 样本 间 距离 的 
性质 导致 它 抗 攻击 的 能力 更强 缺点 对 
参数 调节 和和 函数 的 选择 敏感 原始 分类器 不加 
修改 仅 适用 于 处理 二分 类 问题 Logistic 回归 
根据 现有 数据 对 分类 边界线 建立 回归 公式 依次 
进行 分类 优点 实现 简单 易于 理解 和 实现 计算 
代价 不高 速度 很快 存储资源 低 缺点 容易 欠 拟合 
分类 精度 可能 不高 EM 期望 最大化 算法 上帝 算法 
只要 有 一些 训练 数据 再 定义 一个 最大化 函数 
采用 EM 算法 利用计算机 经过 若干 次 迭代 就 可以 
得到 所需 的 模型 EM 算法 是 自 收敛 的 
分类 算法 既 不 需要 事先 设定 类别 也 不需要 
数据 见 的 两两 比较 合并 等 操作 缺点 是 
当 所要 优化 的 函数 不是 凸函数 时 EM 算法 
容易 给出 局部 最佳解 而 不是 最优 解 判别分析 Discriminant 
analysis LDA 的 核心 思想 是 把 高维 的 样本 
投射 project 到 低维 上 如果 要 分成 两类 就 
投射 到 一维 要 分 三类 就 投射 到 二维 
平面 上 这样 的 投射 当然 有 很多 种 不同 
的 方式 LDA 投射 的 标准 就是 让 同类 的 
样本 尽量 靠近 而不 同类 的 尽量 分开 对于 未来 
要 预测 的 样本 用 同样 的 方式 投射 之后 
就 可以 轻易 地 分辨 类 别了 使用 情景 判别分析 
适用 于 高维 数据 需要 降 维 的 情况 自带 
降 维 功能 使得 我们 能 方便 地 观察 样本分布 
它 的 正确性 有 数学 公式 可以 证明 所以 同样 
是 很 经得住 推敲 的 方式 但是 它 的 分类 
准确率 往往 不是 很高 所以 不是 统计 系 的 人 
就把 它 作为 降 维 工具 用吧 同时 注意 它 
是 假定 样本 成 正态分布 的 所以 那种 同心 圆形 
的 数据 就 不要 尝试 了 更多 分析 见 https 
/ / www . zhihu . com / question / 
26726794 下边 这个 转 自 http / / www . 
ppvke . com / Blog / archives / 44028 机器 
学习 常见 算法 机器学习 领域 涉及 到 很多 的 算法 
和 模型 这里 遴选 一些 常见 的 算法 正则化 算法 
Regularization Algorithms 集成 算法 Ensemble Algorithms 决策树 算法 Decision Tree 
Algorithm 回归 Regression 人工神经网络 Artificial Neural Network 深度 学习 Deep 
Learning 支持 向量 机 Support Vector Machine 降 维 算法 
Dimensionality Reduction Algorithms 聚 类 算法 Clustering Algorithms 基于 实例 
的 算法 Instance based Algorithms 贝叶斯 算法 Bayesian Algorithms 关联 
规则学习 算法 Association Rule Learning Algorithms 图 模型 Graphical Models 
# # # 正则化 算法 Regularization Algorithms 正则化 算法 是 
另一种 方法 通常 是 回归 方法 的 拓展 这种 方法 
会 基于 模型 复杂性 对其 进行 惩罚 它 喜欢 相对 
简单 能够 更好 的 泛化 的 模型 正则化 中 我们 
将 保留 所有 的 特征 变量 但是 会 减小 特征 
变量 的 数量级 参数 数值 的 大小 θ j 这个 
方法 非常 有效 当 我们 有 很多 特征 变量 时 
其中 每 一个 变量 都 能对 预测 产生 一点 影响 
算法 实例 岭回归 Ridge Regression 最小 绝对 收缩 与 选择 
算子 LASSO GLASSO 弹性 网络 Elastic Net 最 小角 回归 
Least Angle Regression 详解 链接 机器学习 之 正则化 算法 集成 
算法 Ensemble algorithms 集成 方法 是 由 多个 较弱 的 
模型 集成 模型 组 其中 的 模型 可以 单独 进行 
训练 并且 它们 的 预测 能以 某种 方式 结合 起来 
去 做出 一个 总体 预测 这类 算法 又称 元 算法 
meta algorithm 最/d 常见/a 的/uj 集成/v 思想/n 有/v 两种/m bagging/w 
和/c boosting/w boosting 基于 错误 提升 分类器 性能 通过 集中 
关注 被 已有 分类器 分类 错误 的 样本 构建 新 
分类器 并 集成 bagging 基于 数据 随机 重 抽样 的 
分类器 构建 方法 算法 实例 B o o s t 
i n g B o o t s t r 
a p p e d Aggregation Bagging AdaBoost 层叠 泛化 
Stacked Generalization blending 梯度 推进机 Gradient Boosting Machines GBM 梯度 
提升 回归 树 Gradient Boosted Regression Trees GBRT 随机 森林 
Random Forest 总结 当先 最 先进 的 预测 几乎 都 
使用 了 算法 集成 它 比 使用 单个 模型 预测 
出来 的 结果 要 精确 的 多 但是 该 算法 
需要 大量 的 维护 工作 详细 讲解 机器学习 算法 之 
集成 算法 # # # 决策树 算法 Decision Tree Algorithm 
决策树 学习 使用 一个 决策树 作为 一个 预测模型 它 将对 
一个 item 表征 在 分支 上 观察 所得 映 射成 
关于 该 item 的 目标值 的 结论 表征 在 叶子 
中 决策树 通过 把 实例 从艮/nr 节点 排列 到 某个 
叶子 结点 来 分类 实例 叶子 结点 即为 实例 所属 
的 分类 树上 的 每一个 结点 指定 了 对 实例 
的 某个 属性 的 测试 并且 该 结点 的 每一个 
后继 分支 对应 于该/nr 属性 的 一个 可能 值 分类 
实例 的 方法 是 从这 棵树 的 根 节点 开始 
测试 这个 结点 的 属性 然后 按照 给定 实例 的 
属性值 对应 的 树枝 向下 移动 然后 这个 过程 在 
以 新 结点 的 根 的 子树 上 重复 算法 
实例 分类 和 回归 树 Classification and Regression Tree CART 
Iterative Dichotomiser 3 ID3 C 4.5 和 C 5.0 一种 
强大 方法 的 两个 不同 版本 详解 机器学习 算法 之 
决策树 算法 回归 Regression 算法 回归 是 用于 估计 两种 
变量 之间 关系 的 统计 过程 当 用于 分析 因变量 
和 一个 多个 自变量 之间 的 关系 时 该/r 算法/n 
能/v 提供/v 很多/m 建模/n 和/c 分析/vn 多个/m 变量/vn 的/uj 技巧/n 
具体 一点 说 回归分析 可以 帮助 我们 理解 当 任意 
一个 自变量 变化 另一个 自变量 不变 时 因变量 变化 的 
典型 值 最 常见 的 是 回归分析 能在 给定 自变量 
的 条件 下 估计 出 因变量 的 条件 期望 算法 
实例 普通 最小二乘 回归 Ordinary Least Squares Regression OLSR 线性 
回归 Linear Regression 逻辑 回归 Logistic Regression 逐步回归 Stepwise Regression 
多元 自适应 回归 样条 Multivariate Adaptive Regression Splines MARS 本地 
散 点 平滑 估计 Locally Estimated Scatterplot Smoothing LOESS 回归 
算法 详解 机器学习 算法 之 回归 算法 人工神经网络 人工神经网络 是 
受 生物 神经网络 启发 而 构建 的 算法 模型 它 
是 一种 模式匹配 常被 用于 回归 和 分类 问题 但 
拥有 庞大 的 子域 由 数百 种 算法 和 各类 
问题 的 变体 组成 人工神经网络 ANN 提供 了 一种 普遍 
而且 实际 的 方法 从 样例 中 学习 值 为 
实数 离散 值 或 向量 函数 人工神经网络 由 一系列 简单 
的 单元 相互连接 构成 其中 每个 单元 有 一定 数量 
的 实值 输入 并 产生 单一 的 实值 输出 算法 
实例 感知器 反向 传播 Hopfield 网络 径向 基 函数 网络 
Radial Basis Function Network RBFN 详细 链接 机器学习 算法 之 
人工神经网络 深度 学习 Deep Learning 深度 学习 是 人工 神经 
网络 的 最新 分支 它 受益 于 当代 硬件 的 
快速 发展 众多 研究 者 目前 的 方向 主要 集中 
于 构建 更大 更 复杂 的 神经 网络 目前 有 
许多 方法 正在 聚焦 半 监督 学习 问题 其中 用于 
训练 的 大 数据集 只 包含 很少 的 标记 算法 
实例 深 玻耳兹曼 机 Deep Boltzmann Machine DBM Deep Belief 
Networks DBN 卷积 神经网络 CNN Stacked Auto Encoders 深度 学习 
详解 机器学习 算法 之 深度 学习 支持 向量 机 Support 
Vector Machines 支持 向量 机 是 一种 监督 式 学习 
Supervised Learning 的 方法 主要 用 在 统计 分类 Classification 
问题 和 回归分析 Regression 问题 上 支持 向量 机 属于 
一般化 线性 分类器 也 可以 被 认为 是 提 克洛夫 
规范化 Tikhonov Regularization 方法 的 一个 特例 这 族 分类器 
的 特点 是 他们 能够 同时 最小化 经验 误差 与 
最大化 几何 边缘 区 因此 支持 向量 机 也 被 
称为 最大 边缘 区 分类器 现在 多 简称为 SVM 给定 
一组 训练 事例 其中 每个 事例 都 属于 两个 类别 
中 的 一个 支持 向量 机 SVM 训练 算法 可以 
在 被 输入 新的 事例 后 将其 分类 到 两个 
类别 中 的 一个 使 自身 成为 非 概率 二进制 
线性 分类器 SVM 模型 将 训练 事例 表示 为 空间 
中的 点 它们 被 映射 到 一幅 图中 由 一条 
明确 的 尽可能 宽 的 间隔 分开 以 区分 两个 
类别 算法 详解 机器学习 算法 之 支持 向量 机降 维 
算法 Dimensionality Reduction Algorithms 所谓 的 降 维 就是指 采用 
某种 映射方法 将 原 高维空间 中 的 数据 点映 射到 
低 维度 的 空间 中 降 维 的 本质 是 
学习 一个 映射函数 f x y 其中 x 是 原始 
数 据点 的 表达 目前 最多 使用 向量 表达形式 y 
是 数据 点 映射 后的/nr 低维 向量 表达 通常 y 
的 维度 小于 x 的 维度 当然 提高 维度 也 
是 可以 的 f 可能 是 显 式 的 或 
隐式 的 线性 的 或非 线性 的 这一 算法 可 
用于 可视化 高维 数据 或 简化 接下来 可 用于 监督 
学习 中 的 数据 许多 这样 的 方法 可 针对 
分类 和 回归 的 使用 进行 调整 算法 实例 主 
成分 分析 Principal Component Analysis PCA 主 成分 回归 Principal 
Component Regression PCR 偏 最小二乘 回归 Partial Least Squares Regression 
PLSR Sammon 映射 Sammon Mapping 多维 尺度 变换 Multidimensional Scaling 
MDS 投影 寻踪 Projection Pursuit 线性 判别分析 Linear Discriminant Analysis 
LDA 混合 判别分析 Mixture Discriminant Analysis MDA 二次 判别分析 Quadratic 
Discriminant Analysis QDA 灵活 判别分析 Flexible Discriminant Analysis FDA 详解 
链接 降 维 算法 聚 类 算法 Clustering Algorithms 聚 
类 算法 是 指 对 一组 目标 进行 分类 属于 
同 一组 亦即 一个 类 cluster 的 目标 被 划分 
在 一组 中 与 其他 组 目标 相比 同 一组 
目标 更加 彼此 相似 优点 是 让 数据 变得 有 
意义 缺点 是 结果 难以 解读 针对 不同 的 数据 
组 结果 可能 无用 算法 实例 K 均值 k Means 
k Medians 算法 Expectation Maximi 封层 ation EM 最大 期望 
算法 EM 分层 集群 Hierarchical Clstering 聚 类 算法 详解 
机器学习 算法 之 聚 类 算法 贝叶斯 算法 Bayesian Algorithms 
贝叶 斯定理 英语 Bayes theorem 是 概率论 中 的 一个 
定理 它 跟 随机变量 的 条件概率 以及 边缘 概率分布 有关 
在 有些 关于 概率 的 解说 中 贝叶 斯定理 贝叶斯 
更新 能够 告知 我们 如何 利用 新 证据 修改 已有 
的 看法 贝叶斯 方法 是 指明 确应 用了 贝叶 斯定理 
来 解决 如 分类 和 回归 等 问题 的 方法 
算法 实例 朴素 贝叶斯 Naive Bayes 高斯 朴素 贝叶斯 Gaussian 
Naive Bayes 多项式 朴素 贝叶斯 Multinomial Naive Bayes 平均 一致 
依赖 估计 器 Averaged One Dependence Estimators AODE 贝叶斯 信念 
网络 Bayesian Belief Network BBN 贝叶斯 网络 Bayesian Network BN 
贝叶斯 算法 链接 贝叶斯 算法 详解 关联 规则学习 算法 Association 
Rule Learning Algorithms 关联 规则学习 方法 能够 提取 出 对 
数据 中的 变量 之间 的 关系 的 最佳 解释 比如说 
一家 超市 的 销售 数据 中 存在 规则 { 洋葱 
土豆 } = { 汉堡 } 那/r 说明/v 当/t 一位/m 
客户/n 同时/c 购买/v 了/ul 洋葱/n 和/c 土豆/n 的/uj 时候/n 他 
很 有可能 还会 购买 汉堡 肉 有点 类似于 联想 算法 
算法 实例 Apriori 算法 Apriori algorithm Eclat 算法 Eclat algorithm 
FP growth 关联 规则学习 算法 关联 规则学习 算法 图 模型 
Graphical Models 图 模型 GraphicalModels 在 概率论 与 图论 之间 
建立 起了 联姻 关系 它 提供 了 一种 自然 工具 
来 处理 应用 数学 与 工程 中 的 两类 问题 
不确定性 Uncertainty 和 复杂性 Complexity 问 题 特别是在 机器学习 算法 
的 分析 与 设计 中 扮演 着 重要 角色 图 
模型 的 基本 理念 是 模块化 的 思想 复杂 系统 
是 通过 组合 简单 系统 建构 的 概率论 提供 了 
一种 粘合剂 使 系统 的 各个 部分 组合 在 一起 
确保 系统 作为 整体 的 持续 一致性 提供 了 多种 
数据接口 模型 方法 图 模型 或 概率 图 模型 PGM 
/ probabilistic graphical model 是 一种 概率模型 一个 图 graph 
可以 通过 其 表示 随机变量 之间 的 条件 依赖 结构 
conditional dependence structure 算法 实例 贝叶斯 网络 Bayesian network 马尔可夫 
随机 域 Markov random field 链 图 Chain Graphs 祖先 
图 Ancestral graph 图 模型 详解 机器学习 算法 之 图 
模型 