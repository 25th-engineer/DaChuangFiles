在 机器学习 李航 统计 学习 方法 学习 笔记 之 感知机 
1 中 我们 已经 知道 感知机 的 建模 和其/nr 几何 
意义 相关 推导 也 做了 明确 的 推导 有了 数学 
建模 我们 要 对模型 进行 计算 感知机 学习 的 目的 
是 求 的 是 一个 能将 正 实 例和 负 
实例 完全 分开 的 分离 超平面 也 就是 去求 感知机 
模型 中 的 参数 w 和b./nr 学习策略 也就是 求解 途径 
就是 定义 个 经验 损失 函数 并将 损失 函数 极小 
化 我们 这儿 采用 的 学习 策略 是 求 所有 
误 分类 点到 超平面 的 总 距离 假设 超平面 s 
的 误 分类 点集合 为 M 那么 所有 误 分类 
点到 超平面 的 总 距离 为 显然 损失 函数 L 
w b 是非 负 的 如果 没有 误 分类 点 
那么 损失 函数 的 值 就是 0 因为 损失 函数 
的 定义 就是 求 误 分类 点到 平面 的 距离 
误 分类 点 都 没有 那么 损失 函数 的 值 
肯定 是 0 . 感知机 学习 算法 是 误 分类 
驱动 采用 随机 梯度 下 降法 首先 任意 选取 一个 
超平面 w b 然后 极小 化 目标函数 相关 定义 在 
作者 的 书中 都有 给出 不在 啰嗦 了 感知机 学习 
算法 的 原始 形式 对 例子 2.1 做 详细 推导 
作者 其实 已经 给 出了 推导 对于 很多 基础 知识 
扎实 的 人 来说 已经 足够 了 但 对于 一些 
大学 期间 高数/nr 忘了 差不多 的 我们 来说 理 通 
作者 思路 也 要 仔细 手写 推导 一下 解   
构建 最 优化 问题 按照 算法 2.1 求解 w b 
学习 η = 1 取 初值 w0 = 0 0 
T 这里 w0 是 初始 的 法向量 如果 是 三维空间 
应该 是 0 0 0 T 这儿 二维 平面 就够 
用了 w0 = 0 0 T 所以 w0 = 0 
0 T   b0 = 0 . 对 x1 = 
3 3 T 因为 是 正 分类 点 所以 y1 
= 1 带入 分离 超平面 公式 y1 w0 • x1 
+ b0 = 1 0 0 T   • 3 
3 T + 0       公式 1.0 其中 
T 代表 矩阵 的 转置 也 就是 把 0 0 
竖 过来 同时 这儿 的 0 0 T 和 3 
3 T 也是 向量 的 表示 中间 的 圆点 代表 
求 两个 向量 的 内积 我们 看 一下 向量 内积 
的 定义 在 线性代数 中有 对此 的 明确 定义 所以 
0 0 T 和 3 3 T   的 内积 
就为 0 * 3 + 0 * 3 = 0 
. 所以 公式 1.0 的 值 为 0 . 因为 
要 把 所有 的 正 实 例和 负 实例 分开 
这儿 该 正 实例 在 分离 超平面 上 显然 不 
符合 要求 所以 我们 要 更新 w b . w1 
= w0 + y1x1   这儿 更新 w 法向量 的 
意义 是 移动 分离 超平面 的 方向 对于 二 维空间 
就是 更改 直线 的 斜率 更新 b 就是 移动 斜线 
的 截距 我们 首先 把 这儿 几个 实例 点 表示出来 
x1y1 = 3 3 T 1         
x2y2 = 4 3 T 1       x3y3 
= 1 1 T 1   求得 w1 = 0 
0 T + 3 3 T = 3 3 T 
      b1 = b0 + y1 = 1 
所以 线性 模型 为 因为 我们 使用 函数 间隔 来 
衡量 是否 被 正确 分类 的 也 就是 在 线性 
模型 前面 加上 参数 yi 因为 正确 分类 时候 yi 
= 1 误 分类 的 时候 yi = 1 所以 
可以 两者 的 乘积 只要 大于 0 就 可以 表示 
正确 分类 了 不 需要 更新 函数参数 小于 等于 0 
就 表示 要 更新 参数 新的 线性 模型 对于 点 
x1y1 = 3 3 T 1         
x2y2 = 4 3 T 1   显然 都 大于 
0 也 就是 可以 被 正确 分类 对于     
x3y3 = 1 1 T 1   带入 后 函数 
间隔 小于 0 代表 函数 未被 正确 分类 所以 需要 
更新 函数 w2 = w1 + y1x1 对于 感知机 求解 
的 一般 形式 很 简单 仔细 看书 了解 几个 数学 
概念 就 很容易 明白 不在 赘述 感知机 学习 算法 的 
收敛性 大体 浏览 了 下 感觉 不是 很 重要 也 
不是 很难 理解 可能 是 我 没 自己 手动 推导 
一下 的 原因 想 研究 的 可以 直接 看 作者 
的 推导 感知机 学习 算法 的 对偶 形式 下面 是 
作者 书中 给出 的 例子 但是 没有 具体 的 推导 
过程 我们 推导 如下 从 原始 形式 中 我们 可以 
知道 w 的 更新过程 第一 次 更新 是 x1y1 = 
3 3 T 1     点 不能 是 函数 
模型 大于 零 所以     w1 = w0 + 
x1y1 第二次 更新 是 x3y3 = 1 1 T 1 
  点 不能 使其 大于 零 所以     w2 
= w1 + x3y3 第三 次 更新 是 x3y3 = 
1 1 T 1   点 不能 使其 大于 零 
所以     w3 = w2 + x3y3 第四次 更新 
是 x3y3 = 1 1 T 1   点 不能 
使其 大于 零 所以     w4 = w3 + 
x3y3 第五次 更新 是 x1y1 = 3 3 T 1 
  点 不能 使其 大于 零 所以     w5 
= w4 + x1y1 第六次 更新 是 x3y3 = 1 
1 T 1   点 不能 使其 大于 零 所以 
    w6 = w5 + x3y3 第七次 更新 是 
x3y3 = 1 1 T 1   点 不能 使其 
大于 零 所以     w7 = w6 + x3y3 
然后 我们 得到 从 上面 可以 总结 出 w7 = 
w6 + x3y3w7 = w5 + x3y3   + x3y3w7 
= w4 + x1y1 + x3y3   + x3y3w7 = 
w3 + x3y3 + x1y1 + x3y3   + x3y3w7 
= w2 + x3y3 + x3y3 + x1y1 + x3y3 
  + x3y3w7 = w1 + x3y3   + x3y3 
+ x3y3 + x1y1 + x3y3   + x3y3w7 = 
w0 + x1y1   + x3y3   + x3y3 + 
x3y3 + x1y1 + x3y3   + x3y3 所以 我们 
可以 得出 最终 w7 的 值 为 两次 x1y1   
+ 五次 x3y3 也就 等于在 对偶 形式 中的 同理 也 
可以 得出 b 例 2.2 中的 误 分 条件 我们 
还 可以 写成 如下 形式 从 上面 的 公式 中 
对比 作者 给出 的 求解 迭代 过程 我们 应该 可以 
很容易 理解 对偶 形式 的 感知机 算法 推导 后 发现 
只是 换 了 一个 简便 的 计算 形式 至此 关于 
统计 学习 方法 中的 感知机 篇章 结束 可 参考 机器学习 
李航 统计 学习 方法 学习 笔记 之 感知机 1 本文 
地址 http / / www . cnblogs . com / 
santian / p / 4351756 . html 博客地址 http / 
/ www . cnblogs . com / santian / 转载 
请 以 超链接 形式 标明 文章 原始 出处 