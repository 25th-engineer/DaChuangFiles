各位 工程师 累 了吗 推荐 一篇 可以 让 你 技术 
能力 达到 出神入化 的 网站 宅男 门诊 https / / 
zhainanmenzhen . com / 1 使用 机器学习 来 解决问题 我们 
用 数学 语言 来 描述 它 然后 建立 一个 模型 
例如 回归模型 或者 分类 模型 等 来 描述 这个 问题 
2 通过 最小化 误差 最大 似 然 最大 后验/nr 概率 
等等 建立 模型 的 代价 函数 转化 为 最优化 问题 
找到 最 优化 问题 的 解 也 就是 能 拟合 
我们 的 数据 的 最好 的 模型 参数 3 求解 
这个 代价 函数 找到 最优 解 求 最优 解 方法 
1 如果 优化 函数 存在 解析 解 例如 我们 求 
最值 一般 是 对 优化 函数 求导 找到 导数 为 
0 的 点 如果 代价 函数 能 简单 求导 并且 
求导 后为 0 的 式子 存在 解析 解 那么 我们 
就 可以 直接 得到 最优 的 参数 2 如果 式子 
很难 求导 例如 函数 里面 存在 隐含 的 变量 或者 
变量 相互 间 存在 耦合 互相 依赖 的 情况 或者/c 
求导/v 后/f 式子/n 得不到/v 解/v 释解/v 或者 未知 参数 的 
个数 大于 方程组 的 个数 等 这时候 使用 迭代 算法 
来 一步 一步 找到 最优 解 特别 的 若 优化 
函数 是 凸函数 那么 就 存在 全局 最优 解 如果 
函数 是非 凸 的 那么 就会 有 很多 局部 最优 
的 解 因此 凸 优化 重要性 不言而喻 人们 总 希望 
在 万千 事物 中 找到 最优 的 那个 他 1 
. 什么 是 机器 学习 计算机 自动 从 数据 中 
发现 规律 并 应用 于 解决 新 问题 给 定 
数据 X1 Y1 X2 Y2 Xn Yn 机器 自动 学习 
X 和Y/nr 之间 的 关系 从而 对 新的 Xi 能够 
预测 Yi 如 由 身高 预测 性别 身高 预测 体重 
机器学习 是 一门 人工智能 的 科学 该 领域 的 主要 
研究 对象 是 人工智能 特别 是 如何 在 经验 学习 
中 改善 具体 算法 的 性能 2 . 基于 规则 
3 . 基于 模型 机器学习 4 . 实例 房价 预测 
5 . 基本概念 我们 先 明确 机器学习 中 一些 概念 
和 常用 的 符号 房屋 销售 记录表 训练 集 training 
set 或者 训练 数据 training data 一般 称为 x 房屋 
销售 价钱 输出 数据 一般 称为 y 拟合 的 函数 
模型 假设 一般 写做 y = h x 训练 数据 
的 条数 training set 一条 训练 数据 是 由 一对 
输入 和 输出 数据 组成 的 输入 数据 的 维度 
特征 的 个数 features 房屋 的 售价 数据表 中的 列 
6 . 机器学习 过程 基本 概念 7 . 机器学习 主要问题 
分类 LR SVM NB KNN 决策树 LR logistic regression SVM 
NB naive bayes KNN k nearest neighbor 决策树 聚 类 
k 均值 k means 层次 GMM 高斯 混合模型 回归 线性 
回归 逻辑 回归 关联 规则 Apriori FPgrowth8 . 监督 与非 
监督 学习 监督 学习 给定 数据 X1 Y1 X2 Y2 
Xn Yn 对 新的 Xi 预测 其 Yi 分类 回归 
非 监督 学习 给定 数据 X1 X2 Xn 求 Yi 
= f Xi P Xi Yi 聚 类 降 维 
9 . 机器学习 三要素 模型 规律 策略 模型 好不好 10 
. 经验 风险 11 . 结构 风险 12 . 算法 
13 . 正则化 正则化 regularization 在 线性代数 理论 中 不适 
定 问题 通常 是由 一组 线性 代数方程 定义 的 而且 
这组 方程组 通常 来源于 有着 很大 的 条件 数 的 
不适 定 反 问题 14 . 交叉 验证 1 . 
简单 交叉 验证 简单 交叉 验证 的 方法 是 这样 
的 随机 从 最初 的 样本 中 选择 部分 形成 
验证 数据 而 剩下 的 当作 训练 数据 一般来说 少于 
三分之一 的 数据 被 选作 验证 数据 2 . K 
折 交叉 验证 10 折 交叉 验证 是 把 样本数据 
分成 10份 轮流 将 其中 9份 做 训练 数据 将 
剩下 的 1份 当 测试数据 10次 结果 的 均值 作为 
对 算法 精度 的 估计 通常 情况下 为了 提高 精度 
还 需要 做 多次 10 折 交叉 验证 更进一步 还有 
K 折 交叉 验证 10 折 交叉 验证 是 它 
的 特殊 情况 K 折 交叉 验证 就是 把 样本 
分为 K 份 其中 K 1份 用来 做 训练 建立 
模型 留 剩下 的 一份 来 验证 交叉 验证 重复 
K 次 每个 子样本 验证 一次 3 . 留 一 
验证 留 一 验证 只 使用 样本数据 中的 一项 当作 
验证 数据 而 剩下 的 全 作为 训练 数据 一直 
重复 直到 所有 的 样本 都作 验证 数据 一次 可以 
看出 留 一 验证 实际上 就是 K 折 交叉 验证 
只不过 这里 的 K 有点 特殊 K 为 样本数据 个数 
15 . 泛化 能力 预测 能力 泛化 能力 指 由 
学习 方法 得到 的 模型 对 未知 数据 的 预测 
能力 概括地说 所谓 泛化 能力 generalization ability 是 指 机器学习 
算法 对 新鲜 样本 的 适应 能力 学习 的 目的 
是 学到 隐含 在 数据 对 背后 的 规律 对 
具有 同一 规律 的 学习 集 以外 的 数据 经过 
训练 的 算法 也能 给出 合适 的 输出 该 能力 
称为 泛化 能力 16 . 模型 评估 与 模型 选择 
当 损失 函 数给 定时 基于 损失 函数 的 模型 
的 训练 误差 和 模型 的 测试 误差 就 自然 
成为 学习 方法 评估 的 标准 通常 测试 误差 越小 
的 方法 具有 更好 的 预测 能力 泛化 能力强 17 
. 过拟合 与 模型 选择 18 . 总结 