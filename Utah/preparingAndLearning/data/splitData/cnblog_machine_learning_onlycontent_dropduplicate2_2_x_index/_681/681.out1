模型 评估 与 选择 经验 误差 与 过拟合 错误率 = 
\ \ frac { 分类 错误 的 样本 } { 
总 样本数 } \ 精度 = 1 错误率 学习 器 
的 实际 预测 输出 与 样本 的 真实 输出 之间 
的 差异 被称为 误差 学习 器 在 训练 集上 的 
误差 为 训练 误差 在 新 样 本上 的 误差 
为 泛化 误差 我们 的 目标 是 让 学习 器 
的 泛化 误差 最小 而 实际上 因为 新 样本 的 
不确定 我们 只能 尽可能 地 让 学习 器 的 训练 
误差 最小 过拟合 是 指 学习 器 在 通过 训练 
集 样本 进行 训练 时 学习 能力 过于 强大 把 
那些 只 属于 训练 集 的 但 并非 是 一般化 
的 特征 也 都学 到了 相对于 过拟合 的 概念 就是 
欠 拟合 在 现实 生活 中 对于 某一 问题 我们 
有 多种 可供 选择 的 算法 而 每个 算法 又因 
不同 的 参数 配置 产生 出 不同 的 模型 那么 
如何 选择 模型 呢 其 标准 自然 是 选择 泛化 
误差 最小 的 但 我们 却 无法 直接 得到 泛化 
误差 同时 训练 误差 也 因为 存在 过拟合 问题 从 
而不 适合 作为 标准 于是 我们 采取 了 一种 评估 
方法 即 选用 部分 样本 作为 训练 集 训练 学习 
器 接下来 将 训 练好 的 该 学习 器 放在 
另一 部分 的 样本 测试 集 中 进行 测试 由此 
得到 测试 误差 我们 将 测试 误差 作为 泛化 误差 
的 近似 从而 对 学习 器 的 好坏 进行 评估 
如何 将 手头 上 的 数据 分为 训练 集 和 
测试 集 进行 测试 就要 采用 以下 的 方法 评估 
方法 留 出法 将 数据集 D 划 分成 两个 互斥 
的 部分 比如 有 1000个 样本 的 数据集 选用 其中 
的 700个 作为 训练 集 剩下 的 300个 用作 测试 
集 划分 数据集 时要/nr 注意 保持 数据分布 的 一致性 即 
保证 训练 集 和 测试 集 是 无 差异 的 
之后 计算 测试 误差 比如 使用 上述 的 700个 样本 
的 数据集 D 训练 模型 将 得到 的 模型 在 
300个 样本 的 测试 集中 进行 测试 发现 其 将 
测试 集中 的 90个 样本 分类 错了 就 可以 得到 
错误率 为 \ \ frac { 90 } { 300 
} \ = 30% 那么 精度 = 1 错误率 = 
70% 然后 将 划分 过程 随机 重复 多次 比如 进行 
100次 的 划分 每次 都 得到 一个 错误率 最后 留 
出法 就是 对这 100个 错误率 进行 平均 看 所 使用 
的 模型 的 平均 错误率 有 多高 一般 情况 下 
会将 总 样本 中的 \ \ frac2 { 3 } 
\ ~ \ \ frac4 { 5 } \ 的 
样本 用作 训练 集 余下 的 \ \ frac1 { 
3 } \ ~ \ \ frac1 { 5 } 
\ 作为 测试 集 交叉 验证法 留 出法 是 划分为 
2个 部分 而 交叉 法则 是 将 数据 D 集 
划分为 k 个 部分 k 2 所以 这 一 方法 
又 被称为 k 折 交叉 验证 比如 一般 会 设置 
k = 10 即 划分为 10个 部分 之后 就用 9个 
k 1个 当做 训练 集 剩下 的 1个 做 测试 
集 将 这 10份 中 每个 都 作为 测试 集 
1次 其余 的 另 9个 作为 训练 集 就会 得到 
10次 结果 另外 再把 原 数据集 按照 不同 的 划分 
方式 再 划分 几次 比如 5次 这样 就 会 得到 
50个 训练 结果 5次 × 10 折 交叉 验证 的 
一个 极端 的 办法 就是 将 数据集 D 共 包含 
m 个 样本 划分为 m 个 部分 即 k = 
m 这 被 称为 留 一 法 每个 子集 中 
只有 一个 样本 这样 训练 集 k 1 ≈ 总 
数据集 m 这样 训 练出 的 效果 也就 跟 使用 
总 数据集 几乎 是 一个 效果 但是 当 数据 集中 
样本 过大 时 这样 的 计算 量 就过 大了 如有 
1 百万个 数据 样本 就需要 训练 1 百万个 模型 自助 
法前/nr 两个 方法 由于 保留 了 部分 样本 用于 测试 
因此 实际 评估 的 模型 所 使用 的 训练 集 
比 总 数据集 小 另外 尽管 留 一 法受/nr 训练样本 
规模 变化 小 但是 计算 复杂度 高 所以 为了 减少 
训练样本 规模 不同 造成 的 影响 同时 高效 地 进行 
试验 估计 就 采用 自助 法 bootstrapping 对于 包含 m 
个 样本 的 数据集 D 使用 自助 采样法 对其 采样 
产生 新的 数据集 D 即 每次 随机 从D中/nr 挑选 一个 
样本 放入 D 中 然后 将该 样本 再 放回 D 
中 再次 从D中/nr 随机 挑选 出 一个 样本 刚才 被 
挑选 出 的 样本 仍 有可能 再次 被选 到 放入 
D 中 不断 重复 这 一 过程 m 次 这样 
新 生成 的 数据 集 D 中 也就 有了 和D/nr 
一样 的 样本 个数 因为 是 重复 采样 所以 仍然会 
有一些 样本 一次 都 没有 被 选入 D 中 这一 
始终 不被 采样 到 的 概率 是 \ 1 − 
\ frac { 1 } m m \ 其 极 
限为 \ \ frac { 1 } e \ ≈ 
37% 这样 始终 不被 采样 的 这 37% 的 数据 
就 可以 用于 测试 集 自助 法在/nr 数据集 较小 难以 
划分 训练 / 测试 集 时很/nr 有用 但是 自助 法 
产生 的 数据 集 改变 了 初始 数据集 的 分布 
这会 引入 估计 偏差 因此 在 数据 量 足 够时 
更多 会 采用 留 出法 和 交叉 验证法 调 参与 
最 终模型 大多数 学习 算法 都有 参数 需要 设定 在 
选择 完 算法 后 对于 算法 的 参数 进行 调节 
就是 调 参 我们 可以 对 一个 算法 中所 需要 
的 每种 参数 配置 都训/nr 练出 模型 然后 挑选出 最好 
的 模型 中 所 使用 的 参数 然而 现实 中 
试 遍 所有 参 数 几乎 是 不 可能 的 
于是 我们 就 会对 每个 参数 选定 一个 范围 和 
变化 步长 进行 计算 比如 在 0 0.2 的 范围内 
以 0.05 为 步长 测试 0 0.05 0.10 0.15 0.20 
这 五个 参数 然后 从这 5 个数 中 选择 最 
合适 的 当 算法 和 参数 已经 选定 好 之后 
这时 需要 再 用 所有 的 数据 m 即用 整个 
数据集 D 来 再度 训练 模型 性能 度量 衡量 模型 
能力 的 泛化 能力 的 评价 标准 就是 性能 度量 
在 对比 不同 的 模型 能力 的 时候 使用 不同 
的 性能 度量 往往 会 导致 不同 的 评判 结果 
我们 使用 均方 误差 来 对 学习 器 的 性能 
进行 度量 即 学习 器 f 对 每个 样本 \ 
x _ i \ 计算 得到 的 数值 \ f 
x _ i \ 与 真实 数值 \ y _ 
i \ 进行 比较 得到 预测值 与 真实 值 的 
误差 然后 对 每个 样本 计算 得到 的 误差 进行 
求和 最后 再 求出 均值 均方 误差 = \ \ 
frac { 1 } m \ sum _ { i 
= 1 } ^ { m } f x _ 
i y _ i ^ 2 \ 错误率 与 精度 
结合 本章 开头 提到 的 错误率 与 精度 对于 数据集 
D 分类 错误率 = \ \ frac { 1 } 
m \ sum _ { i = 1 } ^ 
{ m } Ⅱ f x _ i \ not 
= y _ i \ Ⅱ 在 这里 表示 指示 
函数 即 它 后面 的 函数 取值 或者 为 0 
或者 为 1 精度 = 1 分类 错误率 = 分类 
错误率 = \ \ frac { 1 } m \ 
sum _ { i = 1 } ^ { m 
} Ⅱ f x _ i = y _ i 
\ 查准率 查全率 与 F1 错误率 与 精度 虽然 常用 
但是 并 不能 满足 所有 任务 需求 有时 我们 希望 
知道 的 是 被 当作 好 西瓜 挑 出来 的 
西瓜 中 确实 是 好 西瓜 的 比例 或者 真正 
的 好 瓜 中 有 多少 是 被 伯乐 挑 
出来 了 此时 就 会 出现 四 种 情况 真正 
例 TP 好 的 西瓜 并且 模型 也 认为 是 
好 的 西瓜 假 正 例 FP 坏 的 西瓜 
但是 模型 认为 是 好 的 西瓜 假 反例 FN 
好 的 西瓜 但是 模型 认为 是 坏 的 西瓜 
真 反例 TN 坏 的 西瓜 并且 模型 也 认为 
是 坏 的 西瓜 于是 有 查准率 Precision = \ 
\ frac { 真正 例 TP } { 真正 例 
TP + 假 正 例 FP } \ 即 被 
当作 好 西瓜 挑 出来 的 西瓜 中 确实 是 
好 西瓜 的 比例 查全率 Recall = \ \ frac 
{ 真正 例 TP } { 真正 例 TP + 
假 反例 FN } \ 即 真正 的 好 瓜 
中 有 多少 是 被 伯乐 挑 出来 了 查准率 
与 查全率 是 对 矛盾 的 度量 因为 比如 查准率 
高 就 意味着 模型 越 保守 只会 选择 那些 非常 
有 把握 的 瓜 这样 漏掉 的 好 瓜 也会 
增多 如果 我们 有 多个 模型 则 可以 分别 计算 
每个 模型 的 查准率 和 查全率 来 比较 模型 的 
好坏 比如 我们 有 一个 模型 A 来 预测 西瓜 
的 好坏 对于 每个 样本 100个 输入 它 输出 一个 
计算结果 模型 的 预测 值 100个 即 每个 瓜 的 
得分 我们 将 这 100 的 得分 从大到/nr 小 排序 
分数 越大 的 瓜 就 表示 模型 预测 这个 瓜 
更好 这时 我们 来 设定 阈值 比如 好 瓜 的 
得分 标准 是 60分 80分 还是 90分 等等 每 设定 
一个 阈值 相当于 将 上图 中间 的 区分 左右 两边 
颜色 的 竖线 从 最左 一直 移 到最后 就 可以 
计算 出 一次 该 阈值 下 模型 A 的 好坏 
瓜 预测 情况 的 查准率 和 查全率 如 下图 中的 
左图 所示 横轴 是 查全率 纵轴 是 查准率 绿色 曲线 
是 模型 A 的 数值 变化 蓝线 是 模型 B 
判断 这 两个 模型 的 好坏 只要 看 哪一个 曲线 
在 外面 就 可以 了 因为 在 外面 的 曲线 
上 任选 一点 得到 一对 查准率 和 查全率 里面 曲线 
上 具有 相同 查准率 or 查全率 的 那一点 它 相应 
的 查全率 or 查准率 肯定 要 小于 外面 曲 线上 
的 我们 在 该图 上 如果 画上 函数 y = 
x 的 直线 那么 该 直线 与 模型 A 绿色 
和B/nr 蓝色 的 曲线 的 交点 就是 在 该 曲 
线上 查全率 = 查准率 的 点 平衡点 Break Even Point 
显然 可以 发现 绿色 曲线 的 平衡点 的 数值 肯定 
要 小于 蓝色 曲线 的 该点 上 绿色 曲线 的 
查准率 和 查全率 都要 高于 蓝色 曲线 于是 就 可以 
判断 蓝色 曲线 模型 B 要 优于 绿色 曲线 模型 
A 除了 比较 平衡点 之外 更常用 的 是 被称为 F1 
度量 的 办法 来 比较 不同 的 模型 的 优劣 
\ F1 = \ frac { 2 × 查准率 × 
查全率 } { 查准率 + 查全率 } = \ frac 
{ 2 × 真正 例 } { 总 样本数 + 
真正 例 真 反例 } \ 实际上 F1 的 含义 
如下 \ \ frac1 { F1 } = \ frac1 
{ 2 } \ frac1 { 查准率 } + \ 
frac1 { 查全率 } \ 本质 上 还是 平衡点 只是 
这 一 公式 比 算术平均 \ \ frac { 查准率 
+ 查全率 } 2 \ 或者 几何平均 \ \ sqrt 
{ 查准率 × 查全率 } \ 更 重视 最小值 不同 
应用 中 对于 查准率 和 查全率 的 重视 程度 不同 
比如 在 商品 推荐 系统 中 为了 尽可能 不 打扰 
用户 推荐 顾客 更 感兴趣 的 东西 查准率 更 重要 
而 在逃犯 信息检索 系统 中 希望 少 漏掉 逃犯 此时 
查全率 更重要 于是 引进 一个 参数 \ \ beta \ 
得到 F1 度量 的 一般 形式 \ F _ \ 
beta \ 当 \ \ beta \ 1时 查全率 有 
更大 影响 而 \ \ beta \ 1时 查准率 有 
更大 影响 \ F _ \ beta = \ frac 
{ 1 + \ beta ^ 2 × 查准率 × 
查全率 } { \ beta ^ 2 × 查准率 + 
查全率 } \ ROC 与 AUC 很多 学习 器 是 
为 测试 样本 产生 一个 相应 的 预测 值 然后 
设定 一个 阈值 截 断点 来 与 生成 的 预测 
值 进行 比较 如果 大于 阈值 则是 正 例 小于 
就是 反例 例如 可将 预测值 的 范围 设置 在 0.0 
1.0 之内 然后 设定 0.5 为 阈值 大于 0.5 的 
就 当是 正 例 在 不同 任务 中 可以 根据 
需求 来 选择 截 断点 的 值 我们 将 预测 
的 值 从大到/nr 小排 列出来 如果 我们 重视 查准率 就 
可以 把 截 断点 的 值 设得 高 一些 只 
选择 排名 靠前 的 那些 预测值 认为 满足 这 一截 
断点 值 的 瓜 的 评分 才 代表 是 好 
瓜 如果 重视 查全率 就 可以 把 截 断点 的 
值 设置 得 低 一些 假设 西瓜 基本上 是 长得 
越大 越 成熟 也 越甜/nr 那么 如果 我们 以 个头 
作为 西瓜 的 好坏 标准 的话 截 断点 选择 的 
数值 越大 那么 比 截 断点 值 还要 个头 大 
的 瓜 肯定 大 都是 好 瓜 查准率 高 为了 
让 个头 虽然 不是 很大 但也 仍然 很甜 的 瓜 
也 被选 进来 的话 查全率 高 我们 就 需要 把 
截 断点 的 值 选择 的 相对 低 一点 这样 
我们 对于 某 一个 模型 预测 出来 的 值 可以 
试 遍 所有 的 阈值 然后 在 每个 阈值 下 
计算 出 如下 两个 指标 这 跟 上一 接 所述 
的 查准 查全率 曲线 非常 接近 只是/c 计算/v 时的/nr 分母/n 
和/c 分子/n 略有不同/l 真正 例 率 = \ \ frac 
{ 真正 例 } { 真正 例 + 假 反例 
} \ = \ \ frac { 被 模型 正确 
预测出 的 正 例数 } { 实际 情况下 的 所有 
正 例数 } \ = 查全率 真正 的 好 瓜 
中 有 多少 是 被 伯乐 挑 出来 了 假 
正 例 率 = \ \ frac { 假 正 
例 } { 假 正 例 + 真 反例 } 
\ = \ \ frac { 实际 情况 下 是 
反例 的 被 模型 误 以为 是 正 例 的 
个数 } { 实际 情况下 的 所有 反 例数 } 
\ = 坏 瓜 中间 被 当作 好 瓜 挑 
出来 的 比例 我们 肯定 是 希望 得到 一个 真正 
例 率 高 同时 假 正 例 率 低 的 
模型 为了 更 直观 地 看到 不同 模型 的 这 
两个 指标 的 的 差别 我们 将 每对 假 正 
例 率 真正 例 率 值 的 当作 一个 坐标 
x y 画出来 即 以 真正 例 率 为 纵轴 
坐标 假 正 例 率 为 横轴 坐标 绘制 这样 
就 会 形成 一个 曲线 我们 把 这条 曲线 称之为 
ROC Receiver Operating Characteristic 曲线 ROC 曲线 本身 也 是 
二战 时候 用于 检测 敌机 的 雷达 分析 技术 后来 
多 用于 生物 心理学 制药 等 领域 是 比如 判断 
几种 不同 的 药物 的 好坏 的 评估 办法 之一 
参看 上图 的 右边 的 两条 曲线 很明显 蓝色 曲线 
代表 的 模型 较好 因为 和 绿色 的 相比 当 
他们 假 正 例 率 相同 的 情况 下 蓝色 
曲线 的 真正 例 率 都是 要高 的 为了 在 
量 上 对 这两个 模型 进行 比较 我们 使用 AUC 
Area Under ROC curve 计算 面积 即用 积分 计算出 每条 
ROC 曲线 下方 区域 和横/nr 纵轴 形成 的 类似 扇形 
区域 的 面积 然后 面积 越大 的 就 表示 该 
模型 越好 代价 敏感 错误率 与 代价 曲线 把 坏 
瓜 错划 分成 好 瓜 或者 好 瓜 错划 分成 
坏 瓜 虽然 都是/nr 错误 划分 但是 其 造成 的 
后果 会 不同 好 瓜 当成 坏 瓜 只是 扔掉 
了 一只 瓜 但是 坏 的 当成 好 的 吃了 
可能会 吃 坏肚子 上医院 成本 更高 我们 将 不同 类型 
错误 所 造成 的 不同 损失 的 情况 称为 非 
均等 代价 unequal cost 对于 这种 代价 记为 \ cost 
_ { ij } \ 即 表示 将 第 i 
类 样本 预测 为 第 j 类 样本 的 代价 
以 二 分类 任务 为例 第 0类 和第/nr 1类 则会 
有 两种 情况 分别 是 \ cost _ { 01 
} \ 和\/nr cost _ { 10 } \ 假设 
0类 表示 坏 瓜 1类 表 示好 瓜 那么 显然 
\ cost _ { 01 } \ cost _ { 
10 } \ 在 非 均等 代价 的 情况 下 
我们 不仅 希望 错误率 低 还 希望 总体 代价 也 
很低 即 \ cost _ { 01 } \ 与 
\ cost _ { 10 } \ 的 和的/nr 均值 
很低 这里 我们 采用 一个 指标 代价 敏感 cost sensitive 
= \ \ frac1 { m } \ sum _ 
{ x _ { i } \ in { D 
^ + } } Ⅱ f x _ i \ 
not = y _ i × cost _ { 01 
} + \ sum _ { x _ { i 
} \ in { D ^ } } Ⅱ f 
x _ i \ not = y _ i × 
cost _ { 10 } \ 其中 \ D ^ 
+ D ^ \ 分别 表示 数据集 D 中正 例 
子集 和 反例 子集 比较 检验 虽然有 了 性能 度量 
方法 但是 我们 却 并 不能 直接 通过 比较 不同 
模型 的 性能 度 量值 的 大小 来 决定 模型 
的 好坏 因为 1 实验 评估 得到 的 是 测试 
集上 的 性能 这与 我们 希望 比较 的 泛化 性能 
未必 一致 2 测试 集上 的 性能 与 测试 集 
本身 的 选择 有关 不同 大小 的 测试 集 得到 
的 结果 会 不同 而且 相同 大小 的 测试 集中 
如果 测试 样例 不同 结果 也 可能 会 不同 3 
很多 机器学习 算法 本身 有 随机性 即便 在 同一 测试 
集上 使用 相同 的 参数设置 运行 每次 运行 得到 的 
记过 也会 不同 所以 我们 使用 统计假设 检验 对 学习 
器 的 性能 进行 比较 假设检验 假设 是 指 对 
学习 器 泛化 错误率 分布 的 猜想 我们 需要 根据 
测试 错误率 来 推断出 与其 接近 的 泛化 错误率 我们 
希望 知道 的 是 泛化 错误率 \ \ epsilon \ 
= 学习 器 在 一个 样本 上 犯错 的 概率 
测试 错误率 为 \ \ widehat { \ epsilon } 
\ = 我们 从 测试 样本 中 实际 得到 的 
犯错 概率 P \ \ widehat { \ epsilon } 
\ epsilon \ \ = \ \ \ begin { 
pmatrix } m \ \ \ widehat { \ epsilon 
} × m \ end { pmatrix } \ epsilon 
^ { \ widehat { \ epsilon } × m 
} 1 \ epsilon ^ { m { \ widehat 
{ \ epsilon } × m } } \ 这 
正是 一个 二项式 分布 即 表示 在 m 次 事件 
中 碰巧 发生 \ \ widehat { \ epsilon } 
× m \ 次 情况 的 概率 假设 我们 有 
一个 模型 来 预测 一张 图片 是 男 是 女 
模型 用 的 是 根据 头发 长短 来 判断 的 
办法 一般 情况 下 模型 都是/nr 预测 准确 的 短 
发为 男 长 发为 女 但是 总体 而言 有 3% 
泛化 错误率 的 概率 会 预测 错 因为 有时 男生 
也会 是 长发 因为 我们 每次 测试 的 样本 有限 
可能 碰巧在 测试 的 样本 集 中间 混入 了 比较 
多 的 长头发 的 男生 于是 模型 就 很容易 预测 
错 出现 了 更高 的 例如 5% 的 错误 概率 
测试 错误率 上述 公式 即表示 样本 错误率 应该 为 3% 
概率 时 但 因为 样本 选择 的 问题 以致 于 
我们 观测 到了 错误率 为 5% 的 情况 的 概率 
假设 我们 有 10个 样本 并 假定 泛化 错误率 为 
0.3 那么 观测 到 3个 样本 被 错误 分类 的 
可能性 会 很大 而 错误 分类 出 4 5 6个 
甚至 更多 的 概率 会 比较 小 此时 我们 的 
假设检验 即为 检验 泛化 错误率 是否 不 大于 0.3 这一 
判断 于是 对 错误 分类 出 4个 5个 . . 
. 10 个 等 7种 情况 的 概率 进行 求和 
\ \ alpha = \ sum _ { i = 
4 } ^ { 10 } P _ i \ 
一般 情况下 会 选择 0.05 或 0.1 作为 显著 度 
标准 看 超出 3个 分类 错误 的 情况 的 概率值 
和\/nr \ alpha \ 是否 大于 0.05 或 0.1 如果 
大于 则 拒绝 假设 认为 返回 错误率 大于 0.3 小于 
的话 则 接受 假设 在对 单个 学习 器 的 泛化 
性能 的 假设 进行 检验 时 很多 时候 我们 并非 
只 进行 一次 留 出法 估计 而是 重复 多次 留 
出法 或是 交叉 验证法 进行 多次 训练 或 测试 这样 
我们 就 会 得到 多 个 测试 错误率 首先 假设 
我们 认为 泛化 错误率 是 一个 值 即 \ \ 
epsilon \ 然后 实际上 我们 重复 计算 得到 了 k 
个 测试 错误率 \ \ widehat { \ epsilon } 
_ 1 \ widehat { \ epsilon } _ 2 
. . . \ widehat { \ epsilon } _ 
k \ 我们 对 这 k 个 测试 错误率 求出 
平均值 \ \ mu \ 和 方差 \ \ sigma 
^ 2 \ 考虑到 这 k 个 测试 错误率 可以 
看作 是 泛化 错误率 \ \ epsilon \ 的 独立 
采样 于是 变量 \ \ tau _ t = \ 
frac { \ sqrt { k } \ mu \ 
epsilon } { \ sigma } \ 就 服从 自由度 
为 k 1 的 t 分布 然后 我们 使用 t 
test 来 检验 我们 假定 的 泛化 错误率 \ \ 
epsilon \ 和 得到 的 平均 测试 错误率 \ \ 
mu \ 是否 相同 即 \ \ epsilon \ \ 
= \ \ \ mu \ 是否 成立 在 \ 
1 \ alpha \ 概率 内观 测到 的 最大 错误率 
即 临界值 比如 0.3 如果 平均 错误率 与 我们 认为 
的 泛化 错误率 之差 \ | \ mu \ epsilon 
| \ 在 临界值 范围内 则 不能 拒绝 \ \ 
mu = \ epsilon \ 的 假设 此时 认为 \ 
\ epsilon \ 等于 平均值 \ \ mu \ 否则 
可拒绝 该 假设 因为 概率 极低 的 事件 频繁 发生 
了 认为 泛化 错误率 明显 不 应该 是 我们 设定 
的 \ \ epsilon \ 比如 0.3 这个 值 交叉 
验证 t 检验 两个 模型 的 比较 使用 交叉 法时/nr 
以上 是 对 单个 学习 器 泛化 性能 的 假设 
进行 检验 但 更多 情况 下 我们 需要 对 不同 
的 学习 器 性能 进行 比较 交叉 验证 t 检验 
即是 比较 方法 之一 对于 两 个 学习 器 A 
和B/nr 如果 他们 的 性能 相同 则 他们 的 测试 
错误率 应该 相同 即 \ \ epsilon _ i ^ 
A = \ epsilon _ i ^ B \ 我们 
可以 使用 成对 t 检验 paired t tests 进行 检验 
对 k 折 交叉 验证 产生 的 k 对 测试 
错误率 求差 \ \ Delta _ i = \ epsilon 
_ i ^ A \ epsilon _ i ^ B 
\ 然后 看 该 差 是否 显著 不 等于 零 
然而 通常 情况下 由于 样本 有限 使用 交叉 验证 等 
实验 估计 方法 时 不同 轮次 的 训练 集会 有 
一定 程度 的 重叠 这 导致 测试 错误率 实际上 并不 
独立 产生 过高估计 假设 成立 的 概率 为了 缓解 这 
一 问题 可采用 5 × 2 交叉 验证 即 做 
5次 2 折 交叉 验证 在 每次 2 折 交叉 
验证 之前 随机 将 数据 打乱 是的 5次 交叉 验证 
中 的 数据 划分 不 重复 这里 的 一个 技巧 
是 用于 t 检验 的 平均值 \ \ mu \ 
并 不是 5 × 2次 计算 的 数值 的 平均值 
而是/c 只/d 使用/v 第/m 1/m 折/v 交叉/n 验证/v 时/n 模型/n 
A/w 和/c 模型/n B/w 的/uj 差值/n 来做/i 平均/a 即 \ 
\ mu = 0.5 \ Delta _ 1 ^ 1 
+ \ Delta _ 1 ^ 2 \ 由此 缓解 
测试 错误率 的 非 独立性 但是 方差 计算 时 使用 
了 每次 2 折 实验 的 结果 然后 用 自由度 
为 5 的 t 分布 进行 统计 检验 McNemar 检验 
两个 模型 的 比较 使用 留 一 法时/nr McNemar 检验 
是 指 这样 一种 检验 比如 全班 20 个人 的 
考试 中 第一 次 考试 结果 为 7人 及格 13人 
不及格 第二次 考试 结果 为 14人 及格 6人 不及格 那么 
第二次 考试 结果 是否 比 第一 次 好呢 如果 采用 
Fisher 检验 的话 这 两次 考试 是 无 区别 的 
但是 如果 我们 仔细 看 数据 会 发现 如下 结果 
两次/m 考试/vn 都/d 及格/ad 和/c 都不/i 及格/ad 的/uj 分别/d 是/v 
6/m 人和/i 5人/mq 除了 他们 之外 第一次 不 及格 但是 
第二次 及格 的 8人 成绩 变好 第一 次 及格 但是 
第二次 不 及格 的 1人 成绩 变坏 由此 可以 发现 
实际上 第二 次 考试 结果 是 比 第一 次 要好 
的 McNemar 检验 就是 忽略 掉 那些 两次 考试 没有 
变化 的 人 而 专注 有 变化 的 人 8人 
变好 1人 变坏 之间 是否 是 有 差异 的 这一 
检验 的 本质 相当于 二项式 检验 是 实际 计算 中 
采用 卡方检验 等同于 判断 9次 掷 硬币 后 出现 了 
8次 正面 1次 反面 的 情况 是否 是 正常 的 
于是 对于 在 二分 类 问题 下 使用 留 出法 
的 两个 模型 A 和B/nr 进行 比较 检验 时 就是 
忽略 那些 在 两个 模型 下 都 同时 判断 为 
正确 或 错误 的 那些 样本 比较 在 A 模型 
中 判断 为 正确 但是 B 模型 判断 为 错误 
的 样本 \ e _ { 01 } \ 和**/nr 
B 模型 中 判断 为 正确 但是 A 模型 判断 
为 错误 的 样本 \ e _ { 10 } 
\ $ * 的 数量 是否 相等 此时 统计量 服从 
自由度 为 1 k = 1 的 卡方 分布 所以 
进行 卡方检验 即可 Friedman 检验 和 Nemenyi 检验 多个 模型 
的 比较 对于 多 个 模型 本来 可以 采用 方差分析 
进行 比较 检验 但是 因为 不能 保证 样本 能 满足 
正态分布 所以 采用 Friedman 检验 具体 比如 有A/nr B C 
三个 模型 以及 多个 数据集 D1 D2 D3 D4 这里 
对于 每个 数据集 对 A B C 这三个 模型 的 
好坏 进行 排名 第 1 2 3名 然后 比较 三个 
模型 在 所有 数据集 下 的 排名 的 平均值 比如 
算法 A 在 四个 数据集 下排 名都 是 第一 那么 
其 均值 也是 第一 要 检验 的 假设 就是 这三个 
模型 的 排名 均值 是否 是 相同 的 进一步 如果 
检验 结果 发现 这三个 算法 的 性能 相同 的 假设 
不成立 那么 就 意味着 这 三者 的 性能 显著 不同 
于是 采取 后续 检验 post hoc test 来 进一步 区分 
各 算法 偏差 与 方差 对于 学习 算法 除了 通过 
实验 估计 其 泛化 性能 外 人们 往往 还 希望 
了解 它 为什么 具有 这样 的 性能 我们 可以 把 
泛化 误差 分解为 如下 的 公式 情况 \ 泛化 误差 
= bisa ^ 2 x + var x + \ 
epsilon ^ 2 \ 其中 的 bias 表示 偏差 即 
我们 期望 学习 算法 所 计算出 的 输出 与 真实 
结果 的 偏离 程度 代表 的 是 算法 本身 的 
拟合 能力 var 表示 方差 即使 所 使用 的 训练 
集 大小 都是/nr 相同 的 但 如果 训练 集 不同 
或者说 变动 也 会 导致 学习 性能 发生变化 代表 的 
是 数据 扰动 带来 的 影响 \ \ epsilon \ 
表示 噪声 表达 了 当前 任务 下 任何 学习 算法 
所能 达到 的 期望 泛化 误差 的 下限 代表 的 
是 学习 问题 本身 的 难度 偏差 与 方差 是 
相互 冲突 的 当 训练 不足 学习 器 的 拟合 
能力 还 不强 时 训练 数据 的 扰动 不足以 让 
学习 器 产生 显著 变化 此时 偏差 主导 了 泛化 
错误率 随着 训练 加深 学习 器 的 拟合 能力 增强 
方差 将 主导 泛化 误差 等到 充分 训练 之后 学习 
器 的 拟合 能力 已经 非常 强 训练 数据 的 
任何 轻微 扰动 都会 导致 学习 器 发生 显著 变化 
若 训练 数据 自身 的 非 全局性 的 特性 被 
学习 器 学到 了 的话 就 会 出现 过拟合 