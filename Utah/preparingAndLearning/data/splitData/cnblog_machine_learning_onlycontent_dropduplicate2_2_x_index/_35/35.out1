1 . 人工智能 的 核心 机器学习 深度 学习 神经网络 2 
. 深度 学习 的 工作 流程 a 训练样本 b 特征 
抽取 c 学习 函数 d 预测 3 . 人工智能 的 
运用 范围 自然语言 处理 计算机 视觉 等 4 . 深度 
学习 的 框架 a caffe 不 需要 写 代码 1 
. 数据处理 2 . 定义 网络 3 . 指定 参数 
4 . 训练 模型 b tensorflow google 开发 的 需要 
写 代码 python 5 . python 在 数据 科学 方面 
需要 用到 的 库 a Numpy 科学计算 库 b Pandas 
数据 分析 处理 库 c Matplotlib 数据 可视化 库 d 
Scikit learn 机器学习 库 6 . 深度 学习 路线图   
      人工智能 深度 学习 神经 网络 基础 篇 
Python 编程 微积分 基础 线性代数 基础 以及 统计学 基础 数学 
基础 线性代数 微积分 概率论 统计学 python 数据分析 进阶篇 机器学习 监督 
学习 非 监督 学习 增强 学习 和 深度 学习 各种 
算法 高级 篇 项目 出师 篇 应用 很广 发展方向 也 
很广 7 . 机器学习 的 一般 框架 训练 集 = 
提取 特征向量 = 结合 一定 的 算法 分类器 比如 决策 
数 KNN = 得到 结果 8.9 . 周志华   机器学习 
笔记 1 . 没有 免费 的 午餐 定理 在 机器 
学习 中 存在 一个 普适 定理 没有 免费 的 午餐 
No Free Lunch Theorem NFL 定理 NFL 定理 的 具体 
描述 为 1 对 所有 可能 的 的 目标 函数 
求 平均 得到 的 所有 学习 算法 的 非 训练 
集 误差 的 期望值 相同 2 对 任意 固定 的 
训练 集 对 所有 的 目标 函数 求 平均 得到 
的 所有 学习 算法 的 非 训练 集 误差 的 
期望值 也 相同 3 对 所有 的 先验 知识 求 
平均 得到 的 所有 学习 算法 的 的 非 训练 
集 误差 的 期望值 也 相同 4 对 任意 固定 
的 训练 集 对 所有 的 先验 知识 求 平均 
得到 的 所有 学习 算法 的 的 非 训练 集 
误差 的 期望值 也 相同 NFL 定理 表明 没有 一个 
学习 算法 可以 在 任何 领域 总是 产生 最 准确 
的 学习 器 不管 采用 何种 学习 算法 至少 存在 
一个 目标函数 能够 使得 随机 猜测 算法 是 更好 的 
算法 平常 所说 的 一个 学习 算法 比 另一个 算法 
更 优越 效果 更好 只是 针对 特定 的 问题 特定 
的 先验 信息 数据 的 分布 训练样本 的 数目 代价 
或 奖励 函 数等 NFL 定理 可以 进一步 的 引出 
一个 普适 的 守恒 率 对 每一个 可行 的 学习 
算法 来说 它们 的 性能 对 所有 可能 的 目标 
函数 的 求和 结果 确切 地 为零 即 我们 要 
想在 某些 问题 上 得到 正 的 性能 的 提高 
必须 在 一些 问题 上 付出 等量 的 负 的 
性能 的 代价 比如 时间 复杂度 和 空间 复杂度 实际上 
NFL 定理 并 不是 局限 在 机器学习 领域 在 我们 
所处 的 现在 这个 已知 的 宇宙 中 NFL 定理 
也 总是 成立 的 就像 能量守恒 2 . 奥卡姆 剃刀 
定律 别称 奥康 的 剃刀 简单 性 原则 内容 如 
无必要 勿 增 实体 切勿 浪费 较多 东西 去做 用 
较少 的 东西 同样 可以 做好 的 事情 如今 奥卡姆 
剃刀 常 用于 两种 或 两种 以上 假说 的 取舍 
上 如果 对于 同一 现象 有 两种 或 多种 不同 
的 假说 我们 应该 采取 比较简单 或可 证伪 的 那 
一种 世界 客观存在 即是 建立 在 客观 实践 之上 正所谓 
实践 是 检验 真理 的 唯一 标准 对 奥卡姆 剃刀 
在 机器学习 领域 的 作用 一直 存在 争议 它 并非 
科学研究 中 唯一 可行 的 假设 选择 原则 比如 还有 
多 释 原则 主张 保留 与 经验 观察 一致 的 
所有 假设 这与 集成 学习 方面 的 研究 更加 吻合 
3 . 错误率 分类 错误 的 样本 / 样本 总数 
误差 学习 器 的 实际 预测 输出 与 样本 的 
真实 输出 之间 的 差异 精度 1 错误率 训练 误差 
经验 误差 在 训练 样 本上 的 误差 泛化 误差 
在 新 样 本上 的 误差 过拟合 过 配 把 
训练样本 学习 的 太好了 把 训练样本 自身 的 一些 特点 
当作 所有 潜在 样本 都会 有的 一般 性质 欠 拟合 
欠 配 对 训练 样本 的 一般 性质 尚未 学好 
相同 数据 不同 算法 能 得出 不同 的 学习 器 
模型 经验 不同 数据 相同 算法 能 得出 不同 的 
学习 器 模型 经验 模型 选择 那 我们 该 选择 
哪 一种 学习 算法 使用 哪一种 参数 配置 呢 解决 
方案 是 对 几个 模型 的 泛化 误差 进行 评估 
选择 泛化 误差 最小 的 那个 模型 泛化 误差 难 
获取 训练 误差 又 受 过拟合 影响 所有 评估 方法 
一般 采用 测试 集 的 测试 误差 来 估计 泛化 
误差 的 近似 留 出法 直接 将 数据集 D 划分 
成 俩个 互斥 的 集合 一个 是 训练 集 一个 
是 测试 集 T 比率 大约 2/3 ~ 4/5 之间 
然后 重复 做个 n 次 取 这 n 次 的 
一个 平均值 交叉 验证法 k 折 交叉 验证 将 数据集 
D 划分为 k 个 大小 相似 的 互斥 子集 然后 
用 k 1个 子集 做 训练 集 余下 的 那个 
子集 做 测试 集 最后 得到 k 个 测试 结果 
去 平均值 k 一般 有 10 5 20 当 k 
= 样本 个数 时 叫 留 一 法 自助 法 
