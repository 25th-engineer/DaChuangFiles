本文 主要 参考 中科院 自动化 研究所 复杂 系统 与 智能科学 
实验室 王珏 研究员 关于 机器 学习 的 讨论 讨论 机器 
学习 的 描述 理论 基础 发展 历史 以及 研究 现状 
0 引言 20 世纪 90 年代初 当时 的 美国 副 
总统 提出 了 一个 重要 的 计划 国家 信息 基本 
设施 计划 N a t i o n a l 
I n f o r m a t i o 
n Infrastructure NII 这个 计划 的 技术 含义 包含 了 
四 个 方面 的 内容 1 不分 时间 与 地域 
可以 方便 地 获得 信息 2 不分 时间 与 地域 
可以 有效 地 利用 信息 3 不分 时间 与 地域 
可以 有效 地 利用 软 硬件资源 4 保证 信息 安全 
本文 主要 讨论 解决 信息 有效 利用 问题 其 本质 
是 如何 根据 用户 的 特定 需求 从 海量 数据 
中 建立 模型 或 发现 有用 的 知识 对 计算机 
科学 来说 这 就是 机器学习 计算机科学 特别 是 人工智能 的 
研究 者 一般 公认 Simon 对 学习 的 论述 如果 
一个 系统 能够 通过 执行 某 个 过程 改进 它 
的 性能 这 就是 学习 这 是 一个 相当 广泛 
的 说明 其 要点 是 系统 它 涵盖 了 计算 
系统 控制 系统 以及 人 系统 等 对 这些 不同 
系统 的 学习 显然 属于 不同 的 科学 领域 即使 
计算 系统 由于 目标 不同 也 分为 了 从 有限 
观察 概括 特定 问题 世界 模型 的 机器学习 发现 观测 
数据 中 暗含 的 各种 关系 的 数据 分析 以及 
从 观测 数据挖掘 有用 知识 的 数据挖掘 等 不同 分支 
由于 这些 分支 发展 的 各种 方法 的 共同 目标 
都是 从 大量 无序 的 信息 到 简洁 有序 的 
知识 因此 它们 都 可以 理解 为 Simon 意义 下 
的 过程 也就 都是 学习 1 机器学习 描述 本文 将 
讨论 限制 在 从 有限 观察 概括 特定 问题 世界 
模型 的 机器学习 与 从 有限 观察 发现 观测 数据 
中 暗含 的 各种 关系 的 数据 分析 的 方法 
上 并 统称 其为 机器学习 我们 描述 机器学习 如下 令 
W 是 给定 世界 的 有限 或 无限 的 所有 
观测 对象 的 集合 由于 我们 观察 能力 的 限制 
我们 只能 获得 这个 世界 的 一个 有限 的 子集 
Q W 称为 样 本集 机器学习 就是 根据 这个 样 
本集 推算 这个 世界 的 模型 使 它 对 这个 
世界 尽可能 地 为真 这个 描述 隐含 了 三个 需要 
解决 的 问题 1 一致 假设 世界 W 与 样 
本集 Q 有 相同 的 性质 例如 如果 学习 过程 
基于 统计 原理 独立 同 分布 i . i . 
d 就是 一类 一致 条件 2 划分 将 样 本集 
放到 n 维空间 寻找 一个 定义 在 这个 空间 上 
的 决策 分 界面 等价关系 使得 问题 决定 的 不同 
对象 分在 不 相交 的 区域 3 泛化 泛化 能力 
是 这个 模型 对 世界 为真 程度 的 指标 从 
有限 样本 集合 计算 一个 模型 使得 这个 指标 最大 
最小 这些 问题 对 观测 数据 提出 了 相当 严厉 
的 条件 首先 需要 人们 根据 一致 假设 采集 数据 
由此 构成 机器学习 算法 需要 的 样本 集 其次 需要 
寻找 一个 空间 表示 这个 问题 最后 模型 的 泛化 
指标 需要 满足 一致 假设 并 能够 指导 算法 设计 
这些 条件 限制 了 机器 学习 的 应用 范围 2 
机器 学习 的 发展 历史 2.1 机器学习 与 人工智能 机器 
学习 是 人工智能 研究 的 核心 内容 它 的 应用 
已 遍及 人工智能 的 各个 分支 如 专家系统 自动 推理 
自然语言 理解 模式识别 计算机 视觉 智能 机器人 等 领域 人工智能 
涉及 到 诸如 意识 consciousness 自我 self 心灵 mind 包括 
无 意识 的 精神 unconscious _ mind 等等 问题 人 
唯一 了解 的 智能 是 人 本身 的 智能 这是 
普遍 认同 的 观点 但是 我们 对 我们 自身 智能 
的 理解 都 非常 有限 对 构 成人 的 智能 
的 必要 元素 也 了解 有限 所以 就 很难 定义 
什么 是 人工 制造 的 智能 了 因此 人工智能 的 
研究 往往 涉及 对人 的 智能 本身 的 研究 其它 
关于 动物 或 其它 人造 系统 的 智能 也 普遍 
被 认为 是 人工智能 相关 的 研究 课题 下图 展示 
了 人工智能 的 发展 路线 机器学习 是 人工智能 研究 发展 
到 一定 阶段 的 必然 产物 从 20 世纪 50 
年代 到 70 年代 初 人工智能 研究 处于 推理 期 
人们 认为 只要 给 机器 赋予 逻辑推理 能力 机器 就能 
具有 智能 这一 阶段 的 代表 性 工作 主要 有 
A . Newell 和 H . Simon 的 逻辑 理论家 
程序 以及 此后 的 通用 问题 求解 程序 等 这些 
工作 在 当时 取得 了 令人振奋 的 成果 例如 逻辑 
理论家 程序 在 1952 年/m 证明/n 了/ul 著名/a 数学家/n 罗素/nr 
和/c 怀特海/ns 的/uj 名著/n 数学原理 中的 38 条 定理 在 
1963年 证明 了 全部 的 52 条 定理 而且 定理 
2.85 甚至 比 罗素 和 怀特海 证明 得 更 巧妙 
A . Newell 和 H . Simon 因此 获得 了 
1975 年 图灵奖 然而 随着 研究 向前 发展 人们 逐渐 
认识 到 仅 具有 逻辑推理 能力 是 远远 实现 不了 
人工智能 的 E . A . Feigenbaum 等人 认为 要使 
机器 具有 智能 就必须 设法 使 机器 拥有 知识 在 
他们 的 倡导 下 20 世纪 70 年代 中期 开始 
人工智能 进入 了 知识 期 在 这 一时期 大量 专家 
系统 问世 在 很多 领域 做出 了 巨大 贡献 E 
. A . Feigenbaum 作为 知识工程 之父 在 1994 年 
获得 了 图灵奖 但是 专家 系统 面临 知识工程 瓶颈 简单 
地 说 就是 由人 来 把 知识 总结 出来 再 
教给 计算机 是 相当 困难 的 于是 一些 学者 想到 
如果 机器 自己 能够 学习 知识 该 多好 实际上 图灵 
在 1950年 提出 图灵测试 的 文章 中 就 已经 提到 
了 机器 学习 的 可能 而 20 世纪 50 年代 
其实 已经 开始 有 机器学习 相关 的 研究 工作 主要 
集中 在 基于 神经 网络 的 连接 主义 学习 方面 
代表性 工作 主要 有 F . Rosenblatt 的 感知机 B 
. Widrow 的 Adaline 等 在 20 世纪 6 70 
年代 多种 学习 技术 得到 了 初步 发展 例 如以 
决策 理论 为 基础 的 统计 学习 技术 以及 强化 
学习 技术 等 代表性 工作 主要 有 A . L 
. Samuel 的 跳棋 程序 以及 N . J . 
Nilson 的 学习 机器 等 20 多年 后 红极一时 的 
统计 学习 理论 的 一些 重要 结果 也是 在 这个 
时期 取得 的 在 这 一时期 基于 逻辑或 图 结构 
表示 的 符号 学习 技术 也 开始 出现 代表性 工作 
有 P . Winston 的 结构 学习 系统 R . 
. Michalski 等人 的 基于 逻辑 的 归纳 学习 系统 
E . B . Hunt 等人 的 概念学习 系统 等 
1980 年 夏天 在 美国 卡内基 梅隆 大学 举行 了 
第一届 机器学习 研讨会 同年 策略 分析 与 信息 系统 连出 
三期 机器学习 专辑 1983年 Tioga 出版社 出版 了 R . 
. Michalski J . G . Carbonell 和T./nr M . 
Mitchell 主编 的 机器学习 一种 人工智能 途径 书中 汇集 了 
20 位 学者 撰写 的 16 篇文章 对 当时 的 
机器 学习 研究 工作 进行 了 总结 产生 了 很大 
反响 1986 年 Machine Learning 创刊 1989 年 Artificial Intelligence 
出版 了 机器学习 专辑 刊发 了 一些 当时 比较 活跃 
的 研究 工作 其 内容 后来/nr 出现 在 J . 
G . Carbonell 主编 MIT 出版社 1990 年 出版 的 
机器学习 风范 与 方法 一 书中 总的来看 20 世纪 80 
年代 是 机器学习 成为 一个 独立 的 学科 领域 并 
开始 快速 发展 各种 机器 学习 技术 百花齐放 的 时期 
R . . Michalski 等 人中 把 机器 学习 研究 
划分 成 从 例子 中 学习 在 问题 求解 和 
规划 中 学习 通过 观察 和 发现 学习 从 指令 
中 学习 等 范畴 而 E . A . Feigenbaum 
在 著名 的 人工智能 手册 中 则 把 机器 学习 
技术 划分 为 四大 类 即 机械学习 示教 学习 类比 
学习 归纳 学习 2.2 机器 学习 的 理论 基础 机器 
学习 的 科学 基础 之一 是 神经科学 然而 对 机器学习 
进展 产生 重要 影响 的 是 以下 三个 发现 分别 
是 1 James 关于 神经元 是 相互 连接 的 发现 
2 McCulloch 与 Pitts 关于 神经元 工作 方式 是 兴奋 
和 抑制 的 发现 3 Hebb 的 学习 律 神经元 
相互连接 强度 的 变化 其中 McCulloch 与 Pitts 的 发现 
对 近代 信息科学 产生 了 巨大 的 影响 对 机器学习 
这项 成果 给 出了 近代 机器 学习 的 基本 模型 
加上 指导 改变 连接 神经元 之间 权值 的 Hebb 学习律 
成为 目前 大多数 流行 的 机器学习 算法 的 基础 1954年 
Barlow 与 Hebb 在 研究 视觉 感知 学习 时 分别 
提出 了 不同 假设 Barlow 倡导 单 细胞学说 假设 从 
初级阶段 而来 的 输入 集中 到 具有 专一性 响应 特点 
的 单细胞 并 使用 这个 神经 单细胞 来 表象 视觉 
客体 这个 考虑 暗示 神经细胞 可能 具有 较 复杂 的 
结构 而 Hebb 主张 视觉 客体 是由 相互 关联 的 
神经细胞 集合体 来 表象 并称 其为 ensemble 在 神经 科学 
的 研究 中 尽管 这 两个 假设 均有 生物学 证据 
的 支持 但是 这个 争论 至今 没有 生物学 的 定论 
这个 生物学 的 现实 为 我们 计算机 科学家 留下 了 
想象 的 空间 由于 在 机器 学习 中 一直 存在 
着 两种 相互 补充 的 不同 研究 路线 这 两个 
假设 对 机器 学习 研究 有 重要 的 启示 作用 
在 机器学习 划分 的 研究 中 基于 这 两个 假设 
可以 清晰 地 将 机器学习 发展 历程 总结 为 以 
感知机 BP 与 SVM 等 为 一类 以 样条 理论 
k 近邻 Madalin e 符号 机器学习 集群 机器学习 与 流形 
机器学习 等 为 另一 类 在 McCulloch 与 Pitts 模型 
的 基础 上 1957 年 Rosenblatt 首先 提出 了 感知机 
算法 这 是 第一 个 具有 重要 学术 意义 的 
机器学习 算法 这个 思想 发展 的 坎坷 历程 正是 机器学习 
研究 发展 历史 的 真实 写照 感知机 算法 主要 贡献 
是 首先 借用 最 简单 的 McCulloch 与 Pitts 模型 
作为 神经细胞 模型 然后 根据 Hebb 集群 的 考虑 将 
多个 这样 的 神经细胞 模型 根据 特定 规则 集群 起来 
形成 神经网络 并 将其 转变为 下述 机器学习 问题 计算 一个 
超平面 将在 空间 上 不同 类别 标号 的 点 划分 
到 不同 区域 在 优化 理论 的 基础 上 Rosenblatt 
说明 如果 一个 样本 集合 是 线性 可分 则 这个 
算法 一定 可以 以 任何 精度 收敛 由此 导致 的 
问题 是 对 线性 不可分 问题 如何 处理 1969年 Minsky 
与 Paper 出版 了 对 机器 学习 研究 具有 深远 
影响 的 著作 Perceptron 感知机 目前 人们 一般 的 认识 
是 由于 这 本 著作 中 提出 了 XOR 问题 
从而 扼杀 了 感知机 的 研究 方向 然而 在 这本 
著作 中 对 机器 学习 研究 提出 的 基本 思想 
至今 还是 正确 的 其 思想 的 核心 是 两条 
1 算法 能力 只能 解决 线性 问题 的 算法 是 
不够 的 需要 能够 解决 非线性 问题 的 算法 2 
计算 复杂性 只能 解决 玩具 世界 问题 的 算法 是 
没有 意义 的 需要 能够 解决 实际 世界 问题 的 
算法 在 1986 年 Rumelhart 等人 的 BP 算法 解决 
了 XOR 问题 沉寂 近 二 十年 的 感知机 研究 
方向 重新 获得 认可 人们 自此 重新 开始 关注 这个 
研究 方向 这是 Rumelhart 等人 的 重要 贡献 在 20 
世纪 60 年代 的 另一个 重要 研究 成果 来自 Widrow 
1960 年 Widrow 推出 了 Madaline 模型 在 算 法上 
对 线性 不可分 问题 其 本质 是 放弃 划分 样 
本集 的 决策 分 界面 连续 且 光滑 的 条件 
代之 分段 的 平面 从 近代 的 观点 来看 这项 
研究 与 感知机 的 神经科学 假设 的 主要 区别 是 
它 是 确认 Barlow 假设 中 神经细胞 具有 较 复杂 
结构 的 思想 由此 将 线性 模型 例如 感知机 考虑 
为 神经细胞 模型 而 不是 简单 的 McCulloch 与 Pitts 
模型 然后 再 基于 Hebb 神经元 集合体 假设 将 这些 
局部 模型 集群 为对 问题 世界 的 表征 由此 解决 
线性 不可分 问题 但是 这项 研究 远不如 感知机 著名 其 
原因 是 其一 尽管 Madaline 可以 解决 线性 不可分 问题 
但是 其 解答 可能 是 平凡 的 其二 Widrow 没有 
给出 其 理论 基础 事实上 其 理论 基础 远比 感知机 
复杂 直到 1990 年 Schapire 根据 Valiant 的 概率 近似 
正确 PAC 理论 证明了 弱 可 学习 定理 之后 才 
真正 引起 人们 的 重视 进一步 比较 机器学习 中 两个 
不同 路线 的 神经科学 启示 是 有趣 的 对 机器学习 
来说 它们 最 显著 的 差别 是 对 神经细胞 模型 
的 假设 例如 感知机 是以 最 简单 的 McCulloch 与 
Pitts 模型 作为 神经细胞 模型 而 Madaline 是以 问题 世界 
的 局部 模型 作为 神经细胞 模型 两种 方法 都 需要 
根据 Hebb 思想 集群 因此 对 机器 学习 研究 两个 
神经 科学 的 启示 是 互补 的 但是 两者 还 
有区别 前者 强调 模型 的 整体性 这与 Barlow 表征 客体 
的 单一 细胞 论 一致 因此 我们 称 其为 Barlow 
路线 而 后者 则 强调 对 世界 的 表征 需要 
多个 神经细胞 集群 这与 Hebb 表征 客体 的 多细胞 论 
一致 我们 称 其为 Hebb 路线 鉴于 整体 模型 与 
局部 模型 之间 在 计算 上有 本质 差别 尽管 根据 
Barlow 与 Hebb 假设 区分 机器 学习 的 方法 在 
这 一节 的 最后 将 1989 年/m Carbonell/w 对/p 机器/n 
学习/v 以/p 后/f 十年/m 的/uj 展望/v 与/p 十年后/i Diet/w terich 
的 展望 作 一个 对比 可能 是 有趣 的 我们 
希望 以此 说明 机器学习 研究 由于 面临 问题 的 改变 
所 发生 的 变迁 表 1 3 统计 机器学习 统计 
机器学习 是 近几年 被 广泛 应用 的 机器 学习 方法 
事实上 这是 一类 相当 广泛 的 方法 更为 广义地说 这是 
一类 方法学 当 我们 获得 一组 对 问题 世界 的 
观测 数据 如果 我们 不能 或者 没有 必要 对 其 
建立 严格 物理模型 我们 可以 使 用 数学 的 方法 
从这 组 数据 推算 问题 世界 的 数学 模型 这类 
模型 一般 没有 对 问题 世界 的 物理 解释 但是 
在 输入输出 之间 的 关系 上 反映 了 问题 世界 
的 实际 这 就是 黑箱 原理 一般来说 黑箱 原理 是 
基于 统计 方法 的 假设 问题 世界 满足 一种 统计 
分布 统计 机器学习 本质 上 就是 黑箱 原理 的 延续 
与 感知机 时代不同 由于 这类 机器学习 科学 基础 是 感知机 
的 延续 因此 神经科学 基础 不 是 近代 统计 机器学习 
关注 的 主要 问题 数学 方法 成为 研究 的 焦点 
3.1 统计 机器学习 概述 统计 机器学习 方法 的 基本 假设 
是 同类 数据 具有 一定 的 统计 规律性 其 目标 
是 从 假设 空间 也即 模型 空间 从 输入 空间 
到 输出 空间 的 映射函数 空间 中 寻找 一个 最优 
的 模型 通过 对 统计 机器学习 目标 的 描述 我们 
可以 发现 统计 机器学习 方法 主要 研究 三 个 问题 
1 模型 假设 这个 问题 解决 的 是 如何 将 
样本 从 输入 空间 转化 到 输出 空间 的 它 
往往 是 一个 后验/nr 概率 或者 是 一个 映射函数 2 
模型 选择 模型 所在 空间 也 就是 假设 空间 往往 
包含 无穷 多个 满足 假设 的 可选 模型 如何 从 
假设 空间 中 选择 一个 最优 模型 应该 采用 怎样 
的 选择 标准 这 就是 模型 选择 应该 解决 的 
问题 一般 采用 损失 函数 来 制定 模型 选择 策略 
将 模型 选择 转化 为 一个 最 优化 问题 来 
求解 常用 的 损失 函数 包括 0 1 损失 平方 
误差 损失 绝对 损失 对数 损失 等等 通常 我们 也 
会在 损失 函数 中 加上 正则化 项 从而 降低 模型 
的 复杂性 提高 模型 的 泛化 能力 拒绝 Overfitting 3 
学习 算法 学习 算法 是 用来 解决 最 优化 问题 
的 方法 在 给定 损失 函数 后 如何 快速 找到 
损失 函数 约定 条件下 的 最优 解 就是 学习 算法 
需要 解决 的 问题 常用 的 学习 算法 包括 梯度 
下降 拟 牛顿 法 等等 统计 机器学习 方法 的 三个 
问题 都是/nr 非常 值得 研究 的 对于 模型 假设 这个 
问题 如果 模型 都 选择 错误 无论 后面 如何 选择 
模型 也都 难以 反映 数据集 的 正确 分布 因此 首先 
需要 选择 对模型 做出 正确 假设 如何 选择 模型 的 
假设 空间 是 一个 学问 除掉 交叉 验证 的 方法 
之外 还有 不少 其他 方法 模型 选择 的 关键 在于 
如何 设计 损失 函数 而/c 损失/n 函数/n 通常/d 包括/v 损失/n 
项和/nr 正则化/i 项/n 不同 的 模型 选择 策略 通常 选出 
的 模型 也 非常 不同 从而 导致 模型 的 预测 
效果 也 大大 不同 学习 算法 比较 定式 不同 的 
学习 算法 不仅 学习 的 效率 不同 而且 学习 出来 
的 效果 也 不一样 3.2 统计 机器 学习 的 理论 
基础 机器学习 早期 研究 的 特点 是以 划分 为 主要 
研究 课题 这个 考虑 一直 延续 到 Vapnik 在 20 
世纪 70 年代 发展 的 关于 有限 样本 统计理论 并于 
20 世纪 80 年代 末 流传 到 西方 之后 在 
泛化 能力 意义 下 指导 算法 设计 才 成为 人们 
关注 的 主要 问题 这是 本文 需要 进一步 讨论 的 
问题 尽管 以 Open 问题 驱动 的 BP 算法 研究 
大大 推动 了 感知机 研究 方向 的 发展 然而 近十年 
计算机 科学 与 技术 的 快速 发展 使得 人们 获得 
数据 的 能力 大大 提高 BP 这类 算法 已 不能 
完全 适应 这种 需求 同时 Minsky 的 算法 设计 原则 
愈显 重要 然而 沿着 Barlow 路线 的 机器 学习 研究 
并 没有 终止 自 1992年 开始 Vapnik 将 有限 样本 
统计理论 介绍 给 全世界 并 出版 了 统计 机器学习 理论 
的 著作 尽管 这 部 著作 更多 地 是从 科学 
哲学 上 讨论 了 机器 学习 的 诸多 问题 但是 
其 暗示 的 算法 设计 思想 对 以后 机器学习 算法 
研究 产生 了 重要 的 影响 Vapnik 的 研究 主要 
涉及 机器学习 中 两个 相互 关联 的 问题 泛化 问题 
与 表示 问题 前者 包含 两 个 方面 的 内容 
其一 有限 样本 集合 的 统计理论 其二 概率 近似 正确 
的 泛化 描述 而 后者 则 主要 集中 在 核 
函数 由此 将 算法 设计 建立在 线性 优化 理论 之上 
Valiant 的 概率 近似 正确 学习 的 考虑 在 机器 
学习 的 发展 中 扮演 了 一个 重要 的 角色 
1984 年 Valiant 提出 了 机器 学习 的 一个 重要 
考虑 他 建议 评价 机器学习 算法 应该 以 概率 近似 
正确 PAC 为基础 而 不是 以 传统 模式识别 理论 中 
以 概率 为 1 成立 为 基础 由此 他 引入 
了 类似 在 数学分析 中的 ε δ 语言 来 描述 
PAC 这个 考虑 对 近代 机器学习 研究 产生 了 重要 
的 影响 首先 统计 机器学习 理论 中 泛化 不等式 的 
推导 均以 这个 假设 为 基础 其次 基于 这个 考虑 
的 弱 可 学习 理论 为 研究 基于 Hebb 路线 
的 学习 算法 设计 奠定 了 理论 基础 并 产生 
被 广泛 应用 的 集群 机器学习 理念 ensemble 3.3 统计 
机器 学习 的 研究 现状 3.3 . 1SVM 与 Deep 
Learning 的 竞争 当前 统计 学习 领域 最 热门 方法 
主要 有 deep learning 和 SVM supportvector machine 它们 是 
统计 学习 的 代表 方法 可以/c 认为/v 神经/n 网络/n 与/p 
支持/v 向量/n 机/n 都/d 源自/v 于/p 感知机/n Perceptron 感知机 是由 
Rosenblatt 发明 的 线性 分类 模型 1958年 感知机 对 线性 
分类 有效 但 现实 中 的 分类 问题 通常 是 
非线性 的 神经 网络 与 支持 向量 机 包含 核 
方法 都是 非线性 分类 模型 1986年 Rummelhart 与 McClelland 发明 
了 神经 网络 的 学习 算法 Back Propagation 后来 Vapnik 
等人 于 1992年 提出 了 支持 向量 机 神经 网络 
是 多层 通常 是 三层 的 非线性 模型 支持 向量 
机 利用 核 技巧 把 非线性 问题 转换成 线 性问题 
神经 网络 与 支持 向量 机 一直 处于 竞争 关系 
SVM 应用 核 函数 的 展开 定理 无需 知道 非 
线性映射 的 显 式 表达式 由 于是 在 高维 特征 
空间 中 建立 线性 学习机 所以 与 线性 模型 相比 
不但 几乎 不 增加 计算 的 复杂性 而且 在 某种 
程度 上 避免 了 维数 灾难 而 早先 的 神经 
网络 算法 比较 容易 过 训练 大量 的 经验 参数 
需要 设置 训练 速度 比较 慢 在 层次 比较 少 
小于 等于 3 的 情况 下 效果 并不 比 其它 
方法 更优 神经网络 研究领域 领军者 Hinton 在 2006年 提出 了 
神经 网络 Deep Learning 算法 使 神经 网络 的 能力 
大大 提高 向 支持 向量 机 发出 挑战 Deep Learning 
假设 神经 网络 是 多层 的 首先 用 R e 
s t r i c t e d B o 
l t z m a n n Machine 非 监督 
学习 学习 网络 的 结构 然后 再 通过 Back Propagation 
监督 学习 学习 网络 的 权值 3 . 3.2 支持 
向量 机 SVMSVM 方法 是 通过 一个 非 线性映射 p 
把 样本空间 映射 到 一个 高维 乃至 无穷 维 的 
特征 空间 中 Hilber 空间 使得 在 原来 的 样本 
空间 中 非线性 可分 的 问题 转化 为 在 特征 
空间 中 的 线性 可分 的 问题 升 维 就是 
把 样本 向 高维空间 做 映射 一般 情况 下 这会 
增加 计算 的 复杂性 甚至 会 引起 维数 灾难 因而 
人们 很少 问津 但是 作为 分类 回归 等 问题 来说 
很 可能 在 低维 样本空间 无法 线性 处理 的 样本 
集 在 高维 特征 空间 中 却 可以 通过 一个 
线性 超平面 实现 线性 划分 或 回归 一般 的 升 
维 都会 带来 计算 的 复杂化 SVM 方法 巧妙 地 
解决 了 这个 难题 应用 核 函数 的 展开 定理 
就 不 需要 知道 非 线性映射 的 显 式 表达式 
由 于是 在 高维 特征 空间 中 建立 线性 学习机 
所以 与 线性 模型 相比 不但 几乎 不 增加 计算 
的 复杂性 而且 在 某种 程度 上 避免 了 维数 
灾难 ． 这 一切 要 归功于 核 函数 的 展开 
和 计算 理论 ． 选择 不同 的 核 函数 可以 
生成 不同 的 SVM 常用 的 核 函数 有 以下 
4种 ⑴ 性 核 函数 K x y = x 
y ⑵ 多项式 核 函数 K x y = x 
y + 1 d ⑵ 向基/nr 函数 K x y 
= exp | x y | ^ 2 / d 
^ 2 ⑶ 层 神经网络 核 函数 K x y 
= tanh a x y + b ． 3.3 . 
2.1 SVM 有 如下 主要 几个 特点 1 非 线性映射 
是 SVM 方法 的 理论 基础 SVM 利用 内积 核 
函数 代替 向 高维空间 的 非线性 映射 2 对 特征 
空间 划分 的 最优 超平面 是 SVM 的 目标 最大化 
分类 边际 的 思想 是 SVM 方法 的 核心 3 
支持 向量 是 SVM 的 训练 结果 在 SVM 分类 
决策 中 起 决定 作用 的 是 支持 向量 4 
SVM 是 一种 有 坚实 理论 基础 的 新颖 的 
小样 本 学习 方法 它 基本上 不 涉及 概率 测度 
及 大数 定律 等 因此 不同 于 现有 的 统计 
方法 从 本质 上看 它 避开 了 从 归纳到 演绎 
的 传统 过程 实现 了 高效 的 从 训练样本 到 
预报 样本 的 转导 推理 大大 简化 了 通常 的 
分类 和 回归 等 问题 5 SVM 的 最终 决策函数 
只由 少数 的 支持 向量 所 确定 计算 的 复杂性 
取决于 支持 向量 的 数目 而 不是 样本空间 的 维数 
这在 某种 意义 上 避免 了 维数 灾难 6 少数 
支持 向量 决定 了 最终 结果 这 不但 可以 帮助 
我们 抓住 关键 样本 剔除 大量 冗余 样本 而且 注定 
了 该 方法 不但 算法 简单 而且 具有 较好 的 
鲁棒 性 这种 鲁棒 性 主要 体现 在 ① 增 
删 非 支持 向量 样本 对 模型 没有 影响 ② 
支持 向量 样 本集 具有 一定 的 鲁棒性 ③ 有些 
成功 的 应用 中 SVM 方法 对 核 的 选取 
不 敏感 3.3 . 2.2 SVM 的 两个 不足 1 
SVM 算法 对 大规模 训练样本 难以 实施 由 于 SVM 
是 借助 二次 规划 来 求解 支持 向量 而 求解 
二次 规划 将 涉及 m 阶 矩阵 的 计算 m 
为 样本 的 个数 当/t m/w 数目/n 很大/a 时该/nr 矩阵/n 
的/uj 存储/l 和/c 计算/v 将/d 耗费/v 大量/n 的/uj 机器/n 内存/n 
和 运算 时间 针对 以上 问题 的 主要 改进 有有 
J . Platt 的 SMO 算法 T . Joachims 的 
SVM C . J . C . Burges 等 的 
PCGC 张 学工 的 CSVM 以及 O . L . 
Mangasarian 等 的 SOR 算法 2 用 SVM 解决 多 
分类 问题 存在 困难 经典 的 支持 向量 机 算法 
只给 出了 二类 分类 的 算法 而在 数据挖掘 的 实际 
应用 中 一般 要 解决 多类 的 分类 问题 可以 
通过 多个 二类 支持 向量 机 的 组合 来 解决 
主要 有 一对 多 组合 模式 一对一 组合 模式 和 
SVM 决策树 再 就是 通过 构造 多个 分类器 的 组合 
来 解决 主要 原理 是 克服 SVM 固有 的 缺点 
结合 其他 算法 的 优势 解决 多 类 问题 的 
分类 精度 如 与 粗 集 理论 结合 形成 一种 
优势 互补 的 多类 问题 的 组合 分类器 3 . 
3.2 D e e p L e a r n 
i n g D e e p L e a 
r n i n g 本身 算是 MachineLearning 的 一个 
分支 简单 可以 理解 为 Neural Network 的 发展 大约 
二 三十年前 Neural Network 曾经 是 ML 领域 特别 火热 
的 一个 方向 但是 后来 确 慢慢 淡出 了 原因 
包括 以下 几个 方面 1 比较 容易 过 训练 参数 
比较 难 确定 2 训练 速度 比较 慢 在 层次 
比较 少 小于 等于 3 的 情况 下 效果 并不 
比 其它 方法 更优 所以 中间 有 大约 20 多年 
的 时间 神经 网络 被 关注 很少 这段 时间 基本上 
由 SVM 和 Boosting 算法 主导 但是 Hinton 坚持 下来 
并 最终 和 Bengio Yann . lecun 等 提成 了 
一个 实际 可行 的 Deep Learning 框架 3.3 . 3.1 
Deep Learning 与 传统 的 神经 网络 异同 Deep Learning 
与 传统 的 神经 网络 的 相同 在于 Deep Learning 
采用 了 神经 网络 相似 的 分层 结构 系统 由 
包括 输入 层 隐 层 多层 输出 层 组成 的 
多层 网络 只有 相邻 层 节点 之间 有 连接 同 
一层 以及 跨 层 节点 之间 相互 无连接 每 一层 
可以 看作 是 一个 Logistic Regression 模型 这种 分层 结构 
是 比较 接近 人类 大脑 的 结构 的 而 为了 
克服 神经网络 训练 中 的 问题 DL 采用 了 与 
神经 网络 很 不同 的 训练 机制 传统 神经 网络 
中 采用 的 是 Back Propagation 的 方式 进行 简单 
来讲 就是 采用 迭代 的 算法 来 训练 整个 网络 
随机 设定 初值 计算 当前 网络 的 输出 然后 根据 
当前 输出 和 label 之间 的 差 去 改变 前面 
各层 的 参数 直到 收敛 整体 是 一个 梯度 下 
降法 而 DeepLearning 整体 上 是 一个 Layer Wise 的 
训练 机制 这样 做 的 原因 是 因为 如果 采用 
Back Propagation 的 机制 对于 一个 Deep Network 7层 以上 
残差 传播 到 最 前面 的 层 已经 变得 太小 
出现 所谓 的 Gradient Diffusion 3.3 . 3.2 Deep Learning 
训练 过程 1 采用 无 标定 数据 有 标定 数据 
也可 分层 训练 各层 参数 这一步 可以 看作 是 一个 
无 监督 训练 过程 是 和 传统 神经网络 区别 最大 
的 部分 这个 过程 可以 看作 是 feature learning 过程 
具体 的 先用 无 标定 数据 训练 第一层 训练 时 
可以 采用 auto encoder 来 学习 第 一层 的 参数 
这 一层 可以 看作 是 得到 一个 使得 输出 和 
输入 差别 最小 的 三层 神经 网络 的 隐 层 
由于 模型 capacity 的 限制 以及 稀疏 性 约束 使得 
得到 的 模型 能够 学习 到 数据 本身 的 结构 
从而 得到 比 输入 更 具有 表示 能力 的 特征 
在 学习 得到 第 n 1层 后 将 n 1层 
的 输出 作为 第 n 层 的 输入 训练 第 
n 层 由此 分别 得到 各层 的 参数 这 里面 
需要 重点 理解 auto encoder 以及 sparse 的 机制 的 
原理 和 作用 可以 参考 这 篇 文章 2 基于 
第一步 得到 的 各层 参数 进一步 fine tune 整个 多层 
模型 的 参数 这 一步 是 一个 有 监督 训练 
过程 第一步 类似 神经 网络 的 随机 初始化 初值 过程 
由于 DL 的 第一 步 不是 随机 初始化 而是 通过 
学习 输入 数据 的 结构 得到 的 因而 这个 初值 
更 接近 全局 最优 从而 能够 取得 更好 的 效果 
所以 deep learning 效果 好 很大 程度 上 归功于 第一步 
的 feature learning 过程 总之 deep learning 能够 得到 更好 
地 表示 数据 的 feature 同时 由于 模型 的 层次 
参 数很多 capacity 足够 因此 模型 有 能力 表示 大 
规模 数据 所以 对于 图像 语音 这种 特征 不明显 需要 
手工 设计 且 很多 没有 直观 物理 含义 的 问题 
能够 在 大规模 训练 数据 上 取得 更好 的 效果 
此外 从/p 模式识别/n 特征/n 和/c 分类器/n 的/uj 角/n 度 deep 
learning 框架 将 feature 和 分类器 结合 到 一个 框架 
中 用 数据 去 学习 feature 在 使用 中 减少 
了 手工 设计 feature 的 巨大 工作量 这 是 目前 
工业界 工程师 付出 努力 最多 的 方面 因此 不仅仅 效果 
可以 更好 而且 使用 起来 也 有 很多 方便 之处 
4 集群 机器学习 4.1 弱 可 学习 定理 1990 年 
Schapire 证明 了 一个 有趣 的 定理 如果 一个 概念 
是 弱 可 学习 的 充要条件 是 它 是 强可/nr 
学习 的 这个 定理 的 证明 是 构造性 的 证明 
过程 暗示 了 弱 分类器 的 思想 所谓 弱 分类器 
就是 比 随机 猜想 稍好 的 分类器 这 意味着 如果 
我们 可以 设计 这样 一组 弱 分类器 并将 它们 集群 
起来 就 可以 成为 一个 强 分类器 这 就是 集群 
机器学习 由于 弱 分类器 包含 比 随机 猜想 稍好 的 
条件 从而 避免了 对 Madaline 平凡 解的/nr 批评 另外 由于 
Schapire 定理 的 证明 基于 PAC 的 弱 可 学习 
理论 因此 这种方法 又 具有 泛化 理论 的 支持 这样 
自 Widrow 提出 Madaline 近 30 年 之后 人们 终于 
获得 了 基于 Hebb 路线 下 的 机器学习 算法 设计 
的 理论 基础 这个 学习 理念 立即 获得 人们 的 
广泛 关注 其 原因 不言自明 弱 分类器 的 设计 总比 
强 分类器 设计 容易 特别 是 对 线性 不可分 问题 
更是如此 由此 Madaline 与 感知机 一样 成为 机器学习 最 重要 
的 经典 4.2 经典 算法 Boosting 是 一种 用来 提高 
学习 算法 准确度 的 方法 这种方法 通过 构造 一个 预测 
函数 系列 然后 以 一定 的 方式 将 它们 组合 
成 一个 预测 函数 达到 把 一 弱 学习 算法 
提升 为 强 学习 算法 的 目的 1989 年 Schapire 
提出 了 第一 个 可 证明 的 多项式 时间 Boosting 
算法 对 这个 问题 作出 了 肯定 的 回答 一年 
后 Freund 设计 了 一个 高效 得多 的 通过 重 
取样 或 过滤 运作 的 Boosting by Majority 算法 这个 
算法 尽管 在 某种 意义 上 是 优化 的 但却 
有 一些 实践 上 的 缺陷 1995 年 Freund 和 
Schapire 介绍 了 通过 调整 权重 而 运作 的 AdaBoost 
算法 解决 了 早期 Boosting 算法 很多 实践 上 的 
困难 AdaBoost 是 Boosting 家族 中 的 基础 算法 Boosting 
家族 中 的 大部分 扩展 算法 都由 它 得来 对 
AdaBoost 的 分析 结论 也 适用 于 其它 的 Boosting 
下面 简要 地 介绍 一下 它 的 思想 AdaBoost 算法 
的 主要 思想 是 给定 一 弱 学习 算法 和 
训练 集 x1 y1 xn yn 这里 xi 为 一 
向量 yi 对于 分类 问题 为 一类 别 标志 对于 
回归 问题 为 一 数值 初始 化时 对 每一个 训练 
例 赋 相等 的 权重 1 / n 然后 用 
该 学习 算法 对 训练 集 训练 t 轮 每次 
训练 后 对 训练 失败 的 训练 例 赋以 较大 
的 权重 也 就是 让 学习 算法 在 后续 的 
学习 中 集中 对 比较 难 的 训练 例 进行 
学习 从而 得到 一个 预测 函数 序列 h1 ht 其中 
hj 也 有 一定 的 权重 预测 效果 好 的 
预测 函数 权重 较大 反之 较小 最终 的 预测 函数 
H 对分 类 问题 采用 有 权重 的 投票 方式 
对 回归 问题 采用 加权 平均 的 方法 对 新 
示例 进行 判别 Boosting 算法 是 一种 基于 其他 机器学习 
算法 之上 的 用来 提高 算法 精度 和 性能 的 
方法 当 用于 回归分析 时 不 需要 构造 一个 拟合 
精度高 预测 能力 好 的 回归 算法 只要 一个 效果 
只比 随机 猜测 略好 的 粗糙 算法 即可 称之 为 
基础 算法 通过/p 不断/d 地/uv 调用/vn 这个/r 基础/n 算法/n 就/d 
可以/c 获得/v 一个/m 拟合/v 和/c 预测误差/i 都/d 相当/d 好/a 的/uj 
组合/v 回归模型/i Boosting 算法 可以 应用 于 任何 的 基础 
回归 算法 无论是 线性 回归 神经网络 还是 SVM 方法 都 
可以 有效 地 提高 精度 因此 Boosting 可以 被 视为 
一种 通用 的 增强 基础 算法 性能 的 回归分析 算法 
Bagging Bootstrap Aggregating 又 被 称为 自举 聚合 是 Breiman 
提出 的 与 Boosting 相似 的 技术 11 Bagging 技术 
的 主要 思想 是 给定 一 弱 学习 算法 和一/nr 
训练 集 x 1 y1 xn yn 让 该 学习 
算法 训练 多轮 每 轮 的 训练 集 由 从 
初始 的 训练 集中 随机 取出 的 n 个 训练 
例 组成 初始 训练 例 在某 轮 训练 集中 可以 
出现 多次 或 根本 不 出现 训练 之后 可 得到 
一个 预测 函数 序列 h1 ht 最终 的 预测 函数 
H 对分 类 问题 采用 投票 方式 对 回归 问题 
采用 简单 平均 Bagging 与 Boosting 的 区别 在于 Bagging 
的 训练 集 的 选择 是 随机 的 各 轮 
训练 集 之间 相互 独立 而 Boosting 的 训练 集 
的 选择 不是 独立 的 各 轮 训练 集 的 
选择 与 前面 各 轮 的 学习 结果 有关 Bagging 
的 各个 预测 函数 没有 权重 可以 并行 生成 而 
Boosting 是 有 权重 的 只能 依次 顺序 生成 Boosting 
往往 从 一些 弱 的 学习 器 开始 组合 形成 
一个 集 成 学习 器 从而 给 出 一个 好 
的 学习 结果 而 Bagging 学习 效果 的 好坏 往往 
取决于 集成 学习 器 中 每个 学习 器 的 相关性 
和 各个 学习 器 的 学习 效果 对于 神经网络 这类 
极为 耗时 的 学习 方法 Bagging 可 通过 并行 训练 
节省 大量 时间 开销 5 符号 机器学习 自 1969 年 
Minsky 出版 Perceptron 感知机 一 书 以后 感知机 的 研究 
方向 被 终止 到 1986 年 Rumelhart 等 发表 BP 
算法 近 20 年间 机器学习 研究者 在 做 什么 事情 
呢 这段 时间 正是 基于 符号 处理 的 人工智能 的 
黄金 时期 由于 专家 系统 研究 的 推动 符号 机器学习 
得到 发展 事实上 这类 研究 方法 除了 建立在 符号 的 
基础 上 之外 从 学习 的 机理 来看 如果 将 
学习 结果 考虑 为 规则 每个 规 则将 是 一个 
分类器 尽管 这些 分类器 中 有些 不 一定 满足 弱 
分类器 的 条件 但是 它 应该 是 Hebb 路线 的 
延续 符号 机器 学习 的 最大 优点 是 归纳 的 
解答 与 归纳 的 过程 是 可 解释 的 换句话说 
数据 集合 中的 每个 观测 样本 或 对象 对 用户 
都是/nr 透明 的 它 在 解答 以及 计算 过程 中 
所 扮演 的 角色 用户 都是/nr 可以 显现 了解 的 
然而 它 的 缺陷 同样 突出 就是 泛化 能力 由于 
学习 结果 是 符号 表述 因此 只可 能取 真 与 
假 这样 大大 减 低了 对 具有 一定 噪音 数据 
的 分析 能力 需要 其他 技术 来 补充 其一 观测 
世界 的 数据 到 符号 域 的 映射 其二 不确定 
推理 机制 但是 这 两种 方法 与 符号 机器学习 方法 
本身 并 没有 必然 的 关系 近几年 由于 数据挖掘 的 
提出 符号 机器学习 原理 有了/nr 新的 用途 这 就是 符号 
数据分析 在 数据 挖掘 中 称为 数据 描述 以便 与 
数据 预测 类型 的 任务 相 区别 从 任务 来说 
这类 任务 与 机器 学习 是 一致 的 与 机器 
学习 的 目标 不同 数据 分析 不 是以 所有 用户 
具有 相同 需求 为 假设 相反 强调 不同 用户 具有 
不同 的 需求 另外 数据分析 强调 分析 结果 是 为 
用户 提供 可 阅读 的 参考 文本 决策 将 依赖 
人 的 洞察 如何 根据 用户 的 特定 需求 将 
观测 数据 集合 变换 为 简洁 的 可为 用户 理解 
的 表示 成为 关键 这是 符号 机器 学习 的 另一个 
可以 考虑 的 应用 领域 由于 符号 机器学习 在 泛化 
能力 上 的 欠缺 这 也是 它 在与 基于 统计 
的 机器 学习 方法 竞争 中 避免 遭到 淘汰 的 
出路 6 增强 机器学习 方法 增强 机器学习 reinfo rcementlearning 的 
本质 是 对 变化 的 环境 的 适应 应该说 这 
是 一种 古老 的 机器学习 思想 . 在 1948年 Wiener 
的 著作 控制论 中 就 讨论 了 这个 问题 而在 
以后 的 控制 理论 的 研究 中 这 发展 成为 
重要 的 研究 课题 自 适应控制 由于 控制 理论 研究 
这个 问题 的 焦点 在于 控制 品质 且 其 使用 
的 数学 工具 是 微分方程 因此 对 非线性 问题 使用 
计算机 进行 数值 求解 存在着 本质性 的 困难 这是 这类 
机器学习 长期 未 得到 计算机 科学家 注意 的 原因 直到 
20 世纪 70 年代 Holland 在 讨论 进化 计算 时 
需要 考虑 控制 物种 群体 的 染色体 数量 以便 淘汰 
对 变化 环境 不 适应 的 个体 为此 提出 使用 
桶 队 算法 解决 这个 问题 桶 队 算法 在 
Holland 提出 的 分类器 系统 中 扮演 着 对 变换 
环境 适应 的 角色 以后 在 20 世纪 90 年代初 
Sutton 提出 将 这类 机器学习 建立在 Markov 过程 上 并称 
其 为 增强 机器学习 方法 这个 方法 是 根据 环境 
变化 对 系统 的 刺激 并 作为 系统 输入 然后 
利用 基于 统计 的 方法 优化 转移 概率 并使 系统 
适应 新的 环境 一般地说 增强 机器学习 应该 属于 无 教师 
学习 但是 如果 考虑 环境 就是 教师 这类 机器学习 也 
可以 认为 是 一类 特殊 有 教师 的 机器学习 与 
一般 有 教师 机器 学习 的 区别 在于 教师 是 
环境 且 是 变化 的 环境 这 意味着 不像 传统 
意义 下 的 有 教师 学习 教师 教授 的 知识 
不 是 事先 给定 的 而是 采用 更 灵活 方法 
在 问题 求解 的 过程 中 获得 的 7 总结 
本文 从 机器 学习 的 起源 发展 依据 历史 上 
的 重要 事件 角度 讨论 了 机器 学习 发展 脉络 
通过 对 神经细胞 模型 假设 的 差别 将 机器学习 领域 
划分为 两 大 支系 强调 模型 的 整体 性 基于 
Barlow 表征 客体 的 单一 细胞 论 的 Barlow 路线 
强调 对 世界 的 表征 需要 多个 神经细胞 集群 基于 
Hebb 表征 客体 的 多细胞 论 的 Hebb 路线 这一 
划分 可以 清晰 地 将 机器学习 发展 历程 总结 为 
以 感知机 BP 与 SVM 等 为 一类 的 Barlow 
路线 以 样条 理论 k 紧邻 Madaline 符号 机器学习 集群 
机器学习 与 流行 机器学习 等 为 一类 的 Hebb 路线 
其中 又 重点 关注 了 目前 发展 良好 的 统计 
机器学习 与 集群 学习 讨论 了 SVM 与 神经 网络 
的 关系 与 优缺点 以及 将 弱 学习 算法 提升 
为 强 学习 算法 的 Boosting 算法 本文 提倡 研究 
者 需要 重视 这样 一个 问题 我们 探讨 机器学习 在 
理念 理论 与 技术 上 发展 的 各种 方法 所 
遵循 的 假设 是否 能够 适应 当前 任务 的 需要 
如果 问题 是 否定 的 那么 我们 是 修补 这些 
已 被 普遍 认可 的 理念 理论 与 方法 打补丁 
以 适应 当前 的 需要 还是 从 根本 上 清理 
原有 假设 提出 新的 假设 从而 发展 新的 理念 理论 
和 方法 这 是 一个 需要 仔细 分析 已 有 
理论 与 方法 并 权衡 各种 利弊 才能 决定 的 
事情 综上所述 讨论 机器学习 发展 脉络 以/p 从/p 这个/r 脉络/n 
发现/v 有趣/a 的/uj 经验/n 和/c 教训/vn 对 回答 这个 问题 
是 重要 的 这 必须 考虑 机器学习 发展 的 科学 
依据 历史 上 的 重要 事件 以及 理论 研究 中 
的 重要 结论 这 就是 我们 本文 的 讨论 集中 
在 动机 和 理论 的 原因 