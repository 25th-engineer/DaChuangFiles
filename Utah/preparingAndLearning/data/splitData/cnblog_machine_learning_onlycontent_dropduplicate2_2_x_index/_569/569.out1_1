最近 一直 在 看 机器学习 相关 的 算法 今天 我们 
学习 一种 基于 概率论 的 分类 算法 朴素 贝叶斯 本文 
在对 朴素 贝叶斯 进行 简单 介绍 之后 通过 Python 编程 
加以 实现 一   朴素 贝叶斯 概述 1 前言 贝叶斯 
又是 一个 响当当 的 名字 刚 开始 接触 的 是 
贝叶 斯定理 贝叶斯 分类器 是 一类 分类 算法 的 总称 
是 两种 最为 广泛 的 分类 模型 之一 另一种 就是 
上篇 中的 决策树 了 贝叶斯 分类 均以 贝叶 斯定理 为基础 
朴素 贝叶斯 是 贝叶斯 分类 中 最简单 的 一种 是 
基于 贝叶 斯定理 与 特征 条件 独立 假设 的 分类 
方法 之前 所 学习 的 基于 分类 的 K means 
和 决策树 都是 给出 了 分类 的 明确 答案 但是 
分类 势必 是 会 产生 错误 结果 结合 概率论 的 
相关 知识 我们 在 分类 时 可以 给出 类别 估计值 
进而 将 赋予 数据 最优 类别 猜测 就 分类 而言 
有时 使用 概率 要比 那些 硬 规则 有效 的 多 
贝叶斯 准则 和 贝叶 斯定理 就是 利用 已知 值 来 
估计 未知 概率 的 方法 据此 我们 可以 使用 概率论 
进行 分类 首先 从 一个 最 简单 的 概率 分类器 
开始 进而 给出 一些 假 设来 学习 朴素 贝叶斯 分类器 
之所以 称之为 朴素 是 因为 在 整个 过程 当中 我们 
都 使用 的 是 最 原始 最 简单 的 假设 
贝叶斯 算法 的 基础 是 概率 问题 分类 的 原理 
是 通过 某 对象 的 先验概率 利用 贝叶斯 公式 计算 
出 它 的 后验/nr 概率 对象 属于 某一 类 的 
概率 选取 具有 最大 后验/nr 概率 的 类 作为 该 
对象 所属 的 类 就像 那个 特别 有名 的 例子 
在 大街 上 碰到 一个 黑人 要让 你 猜测 他 
是 哪个 洲 的 你 肯定 首先 会 说 非洲 
为什么 呢 因为 黑 人中 非洲 最多 在 这里 我们 
就 选取 了 出现 概率 最大 的 类别 2 . 
贝叶 斯定理 贝叶 斯定理 对 大家 而言 应该 都 不会 
太 陌生 今天 再 温习 一下 首先 说 一下 与 
贝叶 斯定理 密不可分 的 条件概率 P A | B = 
P AB / P B 其中 P A | B 
表示 的 B 发生 的 情况 下 A 发生 的 
概率 这 就是 条件概率 为什么 要 提出 贝叶 斯定理 呢 
因为 现实 生活 中 的 很多 问题 都是 很容易 求出 
P A | B 但 P B | A 却 
很难 求出 而 P B | A 却 相对 更 
有用 由此 贝叶 斯定理 产生 定义 为 3 . 朴素 
贝叶斯 分类器 分类 的 原理 是 通过 某 对象 的 
先验概率 利用 贝叶斯 公式 计算 出 它 的 后验/nr 概率 
对象 属于 某一 类 的 概率 选取 具有 最大 后验/nr 
概率 的 类 作为 该 对象 所属 的 类 把 
Ａ 和Ｂ/nr 看作 是 随机变量 那么 P B | A 
就是 Ｂ 的 后验/nr 概率 P B 是 B 的 
先验概率 对于 朴素 贝叶斯 分类器 要 做出 两个 假设 1 
特征 之间 相互 独立 即 一个 特征 的 出现 于 
其它 相邻 的 特征 并 无关系 2 每个 特征 同等 
重要 二   使用 朴素 贝叶斯 进行 文档 分类 机器学习 
的 一个 重要 应用 就是 文档 的 分类 整个 文档 
看成 是 实例 而 文档 中 的 元素 相应 的 
构成 特征 我们 可以 观察 文档 中 出现 的 词 
并把 每个 词 的 出现 与否 相应 的 作为 特征 
进而 构造 分类器 对 文档 进行 分类 在 这里 我们 
一个 留言 社区 为例 为了 过滤 掉 那些 内容 不当 
的 侮辱性 言论 对此 我们 可以 建立 两个 类别 侮辱性 
和非/nr 侮辱性 分别 用 0 和1来/nr 表示 下面 用 python 
编程 实现 1   文本 中 获取 特征 # coding 
utf 8 from numpy import * import sys sys . 
path . append E \ . . . . # 
# 从 文本 中 构建 向量 def loadDataSet postingList = 
my dog has flea problems help please maybe not take 
him to dog park stupid my dalmation is so cute 
I love him stop posting stupid worthless garbage mr licks 
ate my steak how to stop him quit buying worthless 
dog food stupid classVec = 0 1 0 1 0 
1 # # 分别 表示 标签 return postingList classVec # 
# 返回 输入 数据 和 标签 向量 def createVocabList dataSet 
vocabSet = set for document in dataSet vocabSet = vocabSet 
| set document return list vocabSet # # 输出 不 
重复 的 元素 def setOfWords2Vec vocabList inputSet # # # 
判断 了 一个 词 是否 出现 在 一个 文档 当中 
returnVec = 0 * len vocabList for word in inputSet 
if word in vocabList returnVec vocabList . index word = 
1 else print the word % s is not in 
my Vocabulary % word return returnVec # # # 输入 
中的 元素 在 词汇表 时 词汇表 相应 位置 为 1 
否 则为 0 # 测试 dataSet classes = loadDataSet print 
dataSet vocabList = createVocabList dataSet print vocabList setWordsVec = setOfWords2Vec 
vocabList dataSet 0 print setWordsVec 1.2   得到 每个 特征 
的 条件概率 # # 得到 每个 特征 的 条件 概率 
def trainNB0 trainMatrix trainCategory # # # 输入 的 文档 
信息 和 标签 numTrainDocs = len trainMatrix numWords = len 
trainMatrix 0 pAbusive = sum trainCategory / float numTrainDocs p0Num 
= ones numWords p1Num = ones numWords p0Denom = 2.0 
p1Denom = 2.0 for i in range numTrainDocs if trainCategory 
i = = 1 p1Num + = trainMatrix i p1Denom 
+ = sum trainMatrix i else p0Num + = trainMatrix 
i p0Denom + = sum trainMatrix i p1Vect = log 
p1Num / p1Denom p0Vect = log p0Num / p0Denom return 
p0Vect p1Vect pAbusive # 测试 dataSet classes = loadDataSet vocabList 
= createVocabList dataSet trainMat = for item in dataSet trainMat 
. append setOfWords2Vec vocabList item p0v p1v pAb = trainNB0 
trainMat classes print p0v print p1v print pAb 3   
分类 # 分类 def classifyNB vec2Classify p0Vec p1Vec pClass1 p1 
= sum vec2Classify * p1Vec + log pClass1 p0 = 
sum vec2Classify * p0Vec + log 1.0 pClass1 if p1 
p0 return 1 else return 0 # 词 袋 模型 
返回 所有 词汇 出现 的 次数 def bagOfWords2VecMN vocabList inputSet 
returnVec = 0 * len vocabList for word in inputSet 
if word in vocabList returnVec vocabList . index word + 
= 1 return returnVec def testingNB listOPosts listClasses = loadDataSet 
myVocabList = createVocabList listOPosts trainMat = for postinDoc in listOPosts 
trainMat . append setOfWords2Vec myVocabList postinDoc p0V p1V pAb = 
trainNB0 array trainMat array listClasses testEntry = love my dalmation 
thisDoc = array setOfWords2Vec myVocabList testEntry print testEntry classified as 
classifyNB thisDoc p0V p1V pAb testEntry = stupid garbage thisDoc 
= array setOfWords2Vec myVocabList testEntry print testEntry classified as classifyNB 
thisDoc p0V p1V pAb # 测试 testingNB 分类 算法 这么多 
要说 贝叶斯 分类器 跟 其它 分类 算法 的 区别 首先 
要 说 贝叶斯 的 分类 准确率 相对 较高 而 对于 
了解 学习 过程 还是 决策树 更适合 