本 系列 文章 为 机器学习 实战 学习 笔记 内容 整理 
自 书本 网络 以及 自己 的 理解 如 有错误 欢迎 
指正 源码 在 Python3 . 5 上 测试 均 通过 
代码 及 数据   https / / github . com 
/ Wellat / MLaction 1 算法 概述 1.1 算法 特点 
简单 地 说 k 近邻 算法 采用 测量 不同 特征值 
之间 的 距离 方法 进行 分类 优点 精度高 对 异常值 
不 敏感 无 数据 输入 假定 缺点 计算 复杂度 高 
空间 复杂度 高适 用 数据 范围 数值 型 和 标称 
型 1.2 工作 原理 存在 一个 训练样本 集 并且 每个 
样本 都 存在 标签 有 监督 学习 输入 没有 标签 
的 新 样本数据 后 将 新 数据 的 每个 特征 
与 样本 集中 数据 对应 的 特征 进行 比较 然后 
算法 提取 出 与 样本 集中 特征 最 相似 的 
数据 最 近邻 的 分类 标签 一般来说 我们 只 选择 
样本 数据集 中前 k 个 最 相似 的 数据 这 
就是 k 近邻 算法 中 k 的 出处 而且 k 
通常 不 大于 20 最后 选择 k 个 最 相似 
数据 中 出现 次数 最多 的 分类 作为 新 数据 
的 分类 1.3 实例 解释 以 电影 分类 为 例子 
使用 k 近邻 算法 分类 爱情片 和 动作片 有人 曾经 
统计 过 很多 电影 的 打斗 镜头 和 接吻 镜头 
下图 显示 了 6部 电影 的 打斗 和 接吻 镜 
头数   假如 有 一部 未 看过 的 电影 如何 
确定 它 是 爱情片 还是 动作片 呢 ① 首先 需要 
统计 这个 未知 电影 存在 多少 个 打斗 镜头 和 
接吻 镜头 下 图中 问号 位置 是 该 未知 电影 
出现 的 镜头 数 ② 之后 计算 未知 电影 与 
样本 集中 其他 电影 的 距离 相似 度 具体 算法 
先 忽略 结果 如下 表 所示 ③ 将 相似 度 
列表 排序 选出 前 k 个 最 相似 的 样本 
此处 我们 假设 k = 3 将上 表中 的 相似 
度 进行 排序 后前3/nr 分别 是 He s Not Really 
into Dudes Beautiful Woman California Man ④ 统计 最 相似 
样本 的 分类 此处 很容易 知道 这 3个 样本 均为 
爱情片 ⑤ 将 分类 最多 的 类别 作为 未知 电影 
的 分类 那么 我们 就 得出 结论 未知 电影 属于 
爱情片 2 代码 实现 2.1 k 近邻 简单 分类 的 
应用 2 . 1.1 算法 一般 流程 2 . 1.2 
Python 实现 代码 及 注释 1 # coding = UTF8 
2 from numpy import * 3 import operator 4 5 
def createDataSet 6 7 函数 作用 构建 一组 训练 数据 
训练样本 共 4个 样本 8 同时 给 出了 这 4个 
样本 的 标签 及 labels 9 10 group = array 
11 1.0 1.1 12 1.0 1.0 13 0 . 0 
. 14 0 . 0.1 15 16 labels = A 
A B B 17 return group labels 18 19 def 
classify0 inX dataset labels k 20 21 inX 是 输入 
的 测试 样本 是 一个 x y 样式 的 22 
dataset 是 训练 样 本集 23 labels 是 训练样本 标签 
24 k 是 top k 最 相近 的 25 26 
# shape 返回 矩阵 的 行数 列数 27 # 那么 
shape 0 获取 数据集 的 行数 28 # 行数 就是 
样本 的 数量 29 dataSetSize = dataset . shape 0 
30 31 32 下面 的 求 距离 过程 就是 按照 
欧氏距离 的 公式 计算 的 33 即 根号 x ^ 
2 + y ^ 2 34 35 # tile 属于 
numpy 模块 下边 的 函数 36 # tile A reps 
返回 一个 shape = reps 的 矩阵 矩阵 的 每个 
元素 是 A 37 # 比如 A = 0 1 
2 那么 tile A 2 = 0 1 2 0 
1 2 38 # tile A 2 2 = 0 
1 2 0 1 2 39 # 0 1 2 
0 1 2 40 # tile A 2 1 2 
= 0 1 2 0 1 2 41 # 0 
1 2 0 1 2 42 # 上边 那个 结果 
的 分开 理解 就是 43 # 最 外层 是 2个 
元素 即 最外边 的 中 包含 2个 元素 类似于 C 
D 而 此处 的 C = D 因为 是 复制 
出来 的 44 # 然后 C 包含 1个 元素 即 
C = E 同理 D = E 45 # 最后 
E 包含 2个 元素 即 E = F G 此处 
F = G 因为 是 复制 出来 的 46 # 
F 就是 A 了 基础 元素 47 # 综合 起来 
就是 2 1 2 = C C = E E 
= F F F F = A A A A 
48 # 这个 地方 就是 为了 把 输入 的 测试 
样本 扩展 为 和 dataset 的 shape 一样 然后 就 
可以 直接 做 矩阵 减法 了 49 # 比如 dataset 
有 4个 样本 就是 4 * 2 的 矩阵 输入 
测试 样本 肯定 是 一个 了 就是 1 * 2 
为了 计算 输入 样本 与 训练 样本 的 距离 50 
# 那么 需要 对 这个 数据 进行 作 差 这 
是 一次 比较 因为 训练样本 有n个/nr 那么 就 要 进行 
n 次 比较 51 # 为了 方便 计算 把 输入 
样本 复制 n 次 然后 直接 与 训练样本 作 矩阵 
差 运算 就 可以 一次性 比较 了 n 个 样本 
52 # 比如 inX = 0 1 dataset 就用 函数 
返回 的 结果 那么 53 # tile inX 4 1 
= 0.0 1.0 54 # 0.0 1.0 55 # 0.0 
1.0 56 # 0.0 1.0 57 # 作 差 之后 
58 # diffMat = 1.0 0.1 59 # 1.0 0.0 
60 # 0.0 1.0 61 # 0.0 0.9 62 diffMat 
= tile inX dataSetSize 1 dataset 63 64 # diffMat 
就是 输入 样本 与 每个 训练样本 的 差值 然后 对其 
每个 x 和y的/nr 差值 进行 平方 运算 65 # diffMat 
是 一个 矩阵 矩阵 * * 2 表示 对 矩阵 
中的 每个 元素 进行 * * 2 操作 即 平方 
66 # sqDiffMat = 1.0 0.01 67 # 1.0 0.0 
68 # 0.0 1.0 69 # 0.0 0.81 70 sqDiffMat 
= diffMat * * 2 71 72 # axis = 
1 表示 按照 横轴 sum 表示 累加 即 按照 行 
进行 累加 73 # sqDistance = 1.01 74 # 1.0 
75 # 1.0 76 # 0.81 77 sqDistance = sqDiffMat 
. sum axis = 1 78 79 # 对 平方和 
进行 开 根号 80 distance = sqDistance * * 0.5 
81 82 # 按照 升序 进行 快速排序 返回 的 是 
原 数组 的 下标 83 # 比如 x = 30 
10 20 40 84 # 升序 排序 后 应该 是 
10 20 30 40 他们 的 原 下标 是 1 
2 0 3 85 # 那么 numpy . argsort x 
= 1 2 0 3 86 s o r t 
e d D i s t I n d i 
c i e s = distance . argsort 87 88 
# 存放 最终 的 分类 结果 及 相应 的 结果 
投票数 89 classCount = { } 90 91 # 投票 
过程 就是 统计 前 k 个 最近 的 样本 所属 
类别 包含 的 样本 个数 92 for i in range 
k 93 # index = s o r t e 
d D i s t I n d i c 
i e s i 是 第 i 个 最 相近 
的 样本 下标 94 # voteIlabel = labels index 是 
样本 index 对应 的 分类 结果 A or B 95 
voteIlabel = labels s o r t e d D 
i s t I n d i c i e 
s i 96 # classCount . get voteIlabel 0 返回 
voteIlabel 的 值 如果 不 存在 则 返回 0 97 
# 然后 将 票数 增 1 98 classCount voteIlabel = 
classCount . get voteIlabel 0 + 1 99 100 # 
把 分类 结果 进行 排序 然后 返回 得票数 最多 的 
分类 结果 101 sortedClassCount = sorted classCount . items key 
= operator . itemgetter 1 reverse = True 102 return 
sortedClassCount 0 0 103 104 if _ _ name _ 
_ = = _ _ main _ _ 105 # 
导入 数据 106 dataset labels = createDataSet 107 inX = 
0.1 0.1 108 # 简单 分类 109 className = classify0 
inX dataset labels 3 110 print the class of test 
sample is % s % className 2.2 在 约会 网站 
上 使用 k 近邻 算法 2 . 2.1 算法 一般 
流程 2 . 2.2 Python 实现 代码 datingTestSet . txt 
文件 中有 1000行 的 约会 数据 样本 主要 包括 以下 
3种 特征 每年 获得 的 飞行 常客 里程数 玩 视频 
游戏 所 耗时间 百分比 每周 消费 的 冰淇淋 公升 数 
将 上述 特征 数据 输人 到 分类器 之前 必须 将 
待处理 数据 的 格式 改变 为 分类器 可以 接受 的 
格式 在 kNN . py 中 创建 名为   file2matrix 
  的 函数 以此 来 处理 输人 格式 问题 该 
函数 的 输 人为 文件名 字符串 输出 为 训练样本 矩阵 
和类/nr 标签 向量 autoNorm 为 数值 归一化 函数 将 任意 
取值 范围 的 特征值 转化 为 0 到 1区 间内 
的 值 最后 datingClassTest 函数 是 测试代码 将 下面 的 
代码 增加 到 kNN . py   中 1 def 
file2matrix filename 2 3 从文件 中 读入 训练 数据 并 
存储 为 矩阵 4 5 fr = open filename 6 
arrayOlines = fr . readlines 7 numberOfLines = len arrayOlines 
# 获取 n = 样本 的 行数 8 returnMat = 
zeros numberOfLines 3 # 创建 一个 2 维 矩阵 用于 
存放 训练 样本数据 一 共有 n 行 每 一行 存放 
3个 数据 9 classLabelVector = # 创建 一个 1 维 
数组 用于 存放 训练样本 标签 10 index = 0 11 
for line in arrayOlines 12 # 把 回车 符号 给 
去掉 13 line = line . strip 14 # 把 
每 一行 数据 用 \ t 分割 15 listFromLine = 
line . split \ t 16 # 把 分割 好 
的 数据 放 至 数据集 其中 index 是 该 样本数据 
的 下标 就是 放到 第 几行 17 returnMat index = 
listFromLine 0 3 18 # 把 该 样本 对应 的 
标签 放 至 标签集 顺序 与 样 本集 对应 19 
classLabelVector . append int listFromLine 1 20 index + = 
1 21 return returnMat classLabelVector 22 23 def autoNorm dataSet 
24 25 训练 数据 归一化 26 27 # 获取 数据 
集中 每 一列 的 最小 数值 28 # 以 createDataSet 
中 的 数据 为例 group . min 0 = 0 
0 29 minVals = dataSet . min 0 30 # 
获取 数据 集中 每 一列 的 最大 数值 31 # 
group . max 0 = 1 1.1 32 maxVals = 
dataSet . max 0 33 # 最大值 与 最小 的 
差值 34 ranges = maxVals minVals 35 # 创建 一个 
与 dataSet 同 shape 的 全0/nr 矩阵 用于 存放 归一化 
后的/nr 数据 36 normDataSet = zeros shape dataSet 37 m 
= dataSet . shape 0 38 # 把 最小值 扩充 
为 与 dataSet 同 shape 然 后作 差 具体 tile 
请 翻看 第三节 代码 中的 tile 39 normDataSet = dataSet 
tile minVals m 1 40 # 把 最大 最小 差值 
扩充 为 dataSet 同 shape 然 后作 商 是 指 
对应 元素 进行 除法 运算 而 不是 矩阵 除法 41 
# 矩阵 除法 在 numpy 中 要用 linalg . solve 
A B 42 normDataSet = normDataSet / tile ranges m 
1 43 return normDataSet ranges minVals 44 45 def datingClassTest 
46 # 将 数据 集中 10% 的 数据 留作 测试 
用 其余 的 90% 用于 训练 47 hoRatio = 0.10 
48 datingDataMat datingLabels = file2matrix datingTestSet2 . txt # load 
data setfrom file 49 normMat ranges minVals = autoNorm datingDataMat 
50 m = normMat . shape 0 51 numTestVecs = 
int m * hoRatio 52 errorCount = 0.0 53 for 
i in range numTestVecs 54 classifierResult = classify0 normMat i 
normMat numTestVecs m datingLabels numTestVecs m 3 55 print the 
classifier came back with % d the real answer is 
% d result is % s % classifierResult datingLabels i 
classifierResult = = datingLabels i 56 if classifierResult = datingLabels 
i errorCount + = 1.0 57 print the total error 
rate is % f % errorCount / float numTestVecs 58 
print errorCount 2.3 手写 识别系统 实例 2 . 3.1 实例 
数据 为 了 简单 起见 这里 构造 的 系统 只能 
识别 数字 0 到 9 需要 识别 的 数字 已经 
使用 图形 处理软件 处理/v 成/n 具有/v 相同/d 的/uj 色彩/n 和/c 
大小/b  /i 宽 髙 是 32 像素 x   32 
像素 的 黑白 图像 尽管 采用 文本格式 存储 图像 不能 
有效地 利用 内存空间 但是 为了 方便 理解 我们 还是 将 
图像 转换 为 文本格式 trainingDigits 是 2000个 训练样本 testDigits 是 
900个 测试 样本 2 . 3.2 算法 的 流程 2 
. 3.3 Python 实现 代码 将 下面 的 代码 增加到 
  kNN . py   中 img2vector 为 图片 转换成 
向量 的 方法 h a n d w r i 
t i n g C l a s s T 
e s t 为 测试 方法 1 from os import 
listdir 2 def img2vector filename 3 4 将 图片 数据 
转换 为 01 矩阵 5 每张 图片 是 32 * 
32 像素 也 就是 一共 1024个 字节 6 因此 转换 
的 时候 每行 表示 一个 样本 每个 样本 含 1024个 
字节 7 8 # 每个 样本数据 是 1024 = 32 
* 32个 字节 9 returnVect = zeros 1 1024 10 
fr = open filename 11 # 循环 读取 32行 32列 
12 for i in range 32 13 lineStr = fr 
. readline 14 for j in range 32 15 returnVect 
0 32 * i + j = int lineStr j 
16 return returnVect 17 18 def h a n d 
w r i t i n g C l a 
s s T e s t 19 hwLabels = 20 
# 加载 训练 数据 21 trainingFileList = listdir trainingDigits 22 
m = len trainingFileList 23 trainingMat = zeros m 1024 
24 for i in range m 25 # 从 文件名 
中 解析 出 当前 图像 的 标签 也 就是 数字 
是 几 26 # 文件名 格式 为 0 _ 3 
. txt 表示 图片 数字 是 0 27 fileNameStr = 
trainingFileList i 28 fileStr = fileNameStr . split . 0 
# take off . txt 29 classNumStr = int fileStr 
. split _ 0 30 hwLabels . append classNumStr 31 
trainingMat i = img2vector trainingDigits / % s % fileNameStr 
32 # 加载 测试数据 33 testFileList = listdir testDigits # 
iterate through the test set 34 errorCount = 0.0 35 
mTest = len testFileList 36 for i in range mTest 
37 fileNameStr = testFileList i 38 fileStr = fileNameStr . 
split . 0 # take off . txt 39 classNumStr 
= int fileStr . split _ 0 40 vectorUnderTest = 
img2vector testDigits / % s % fileNameStr 41 classifierResult = 
classify0 vectorUnderTest trainingMat hwLabels 3 42 print the classifier came 
back with % d the real answer is % d 
The predict result is % s % classifierResult classNumStr classifierResult 
= = classNumStr 43 if classifierResult = classNumStr errorCount + 
= 1.0 44 print \ nthe total number of errors 
is % d / % d % errorCount mTest 45 
print \ nthe total error rate is % f % 
errorCount / float mTest k 近邻 算法 识别 手写 数字 
数据集 错误率 为 1 . 2% 改变 变量 k 的 
值 修改 函数 h a n d w r i 
t i n g C l a s s T 
e s t   随机 选取 训练样本 改变 训练样本 的 
数目 都会 对 k 近邻 算法 的 错误率 产生影响 感 
兴趣 的话 可以 改变 这些 变量值 观察 错误率 的 变化 
k 近邻 算法 是 分类 数据 最 简单 最 有效 
的 算法 它 必须 保存 全部 数据集 如果 训练 数据集 
很大 必须 使用 大量 的 存储空间 此外 由于 必须 对 
数据 集中 的 每个 数据 计算 距离 值 实际 使用 
时 可能 非常 耗时 其 另一个 缺陷 是 它 无法 
给 出 任何 数据 的 基础 结构 信息 因此/c 我们/r 
也/d 无法/n 知晓/v 平均/a 实例/n 样本/n 和/c 典型/n 实例/n 样本/n 
具/v 有/v 什么/r 特征/n 3 应用 scikit learn 库 实现 
k 近邻 算法 1 2 scikit learn 库 对 knn 
的 支持 3 数据集 是 iris 虹膜 数据集 4 5 
6 from sklearn . datasets import load _ iris 7 
from sklearn import neighbors 8 import sklearn 9 10 # 
查看 iris 数据集 11 iris = load _ iris 12 
print iris 13 14 15 K N e i g 
h b o r s C l a s s 
i f i e r n _ neighbors = 5 
weights = uniform 16 algorithm = auto leaf _ size 
= 30 17 p = 2 metric = minkowski 18 
metric _ params = None n _ jobs = 1 
* * kwargs 19 n _ neighbors 默认值 为 5 
表示 查询 k 个 最 近邻 的 数目 20 algorithm 
{ auto ball _ tree kd _ tree brute } 
指定 用于 计算 最 近邻 的 算法 auto 表示 试图 
采用 最 适合 的 算法 计算 最 近邻 21 leaf 
_ size 传递 给 ball _ tree 或 kd _ 
tree 的 叶子 大小 22 metric 用于 树 的 距离 
度量 默认 minkowski 与 P = 2 即 欧氏 度量 
23 n _ jobs 并行 工作 的 数量 如果 设为 
1 则 作业 的 数量 被 设置 为 CPU 内核 
的 数量 24 查看 官方 api http / / scikit 
learn . org / dev / modules / generated / 
sklearn . neighbors . K N e i g h 
b o r s C l a s s i 
f i e r . html # sklearn . neighbors 
. K N e i g h b o r 
s C l a s s i f i e 
r 25 26 knn = neighbors . K N e 
i g h b o r s C l a 
s s i f i e r 27 # 训练 
数据集 28 knn . fit iris . data iris . 
target 29 # 训练 准确率 30 score = knn . 
score iris . data iris . target 31 32 # 
预测 33 predict = knn . predict 0.1 0.2 0.3 
0.4 34 # 预测 返回 概率 数组 35 predict2 = 
knn . predict _ proba 0.1 0.2 0.3 0.4 36 
37 print predict 38 print iris . target _ names 
predict 代码 解释 参考 原 贴 http / / blog 
. csdn . net / niuwei22007 / article / details 
/ 49703719 