【重磅】微软开源自动机器学习工具 - NNI
在机器学习建模时，除了准备数据，最耗时耗力的就是尝试各种超参组合，找到模型最佳效果的过程了。即使是对于有经验的算法工程师和数据科学家，有时候也很难把握其中的规律，只能多次尝试，找到较好的超参组合。而对于初学者来说，要花更多的时间和精力。
自动机器学习这两年成为了热门领域，着力解决超参调试过程的挑战，通过超参选择算法和强大的算力来加速超参搜索的过程。
NNI (Neural Network Intelligence) 是微软开源的自动机器学习工具。与当前的各种自动机器学习服务或工具相比，有非常独特的价值。本文先介绍一下 NNI 的特点，然后在后续的安装、使用章节详细介绍如何上手。
支持私有部署。云服务中的自动机器学习直接提供了自动机器学习的服务，不仅包含了自动机器学习的功能，也包含了算力。如果团队或个人已经有了很强的算力资源，就需要支持私有部署的自动学习工具了。
NNI 支持私有部署。整个部署也很简单，使用 pip 即可完成安装。
分布式调度。NNI 可以在单机上完成试验，也支持以下两种分布式调度方案：
GPU 远程服务器。通过 SSH 控制多台 GPU 服务器协同完成试验，并能够计划每个试验所需要的 GPU 的数量。
OpenPAI。通过 OpenPAI，NNI 的试验可以在独立的 Docker 中运行，支持多样的实验环境。在计算资源规划上，不仅能指定 GPU 资源，还能制定 CPU，内存资源。
超参搜索的直接支持。当前，大部分自动机器学习服务与工具都是在某个任务上使用，比如图片分类。这样的好处是，普通用户只要有标记数据，就能训练出一个高质量的平台，不需要任何模型训练方面的知识。但这需要对每个训练任务进行定制，将模型训练的复杂性包装起来。
与大部分现有的自动机器学习服务与工具不同，NNI 需要用户提供训练代码，并指定超参的搜索范围。这样的好处在于，NNI 几乎是通用的工具，任何训练任务都可以使用 NNI 来进行超参搜索。但另一方面，NNI 的通用性，也带来了一定的使用门槛。使用 NNI 需要有基本的模型训练的经验。
兼容已有代码。NNI 使用时，可以通过注释的方法来进行无侵入式的改动。不会影响代码原先的用途。通过注释方式支持 NNI 后，代码还可以单独运行。
易于扩展。NNI 的设计上有很强的可扩展性。通过下面这些扩展性，能将系统与算法相隔离，把系统复杂性都包装起来。
Tuner 接口，可以轻松实现新的超参调试算法。研究人员可以使用 NNI 来试验新的超参搜索方法，比如在强化学习时，在 Tuner 中支持 off-policy 来探索比较好的超参组合，在 Trial 里进行 on-policy 的实际验证。也可以使用 Tuner 和训练代码相配合，支持复杂的超参搜索方法。如，实现 ENAS ，将 Tuner 作为 Control，在多个 Trial 中并行试验。
Accessor 接口，可以加速参数搜索，将表现不好的超参组合提前结束。
NNI 还提供了可扩展的集群接口，可以定制对接的计算集群。方便连接已经部署的计算集群。
可视化界面。在启动一次超参搜索试验后，就可以通过可视化界面来查看试验进展，并帮助超参结果，洞察更多信息。
首页，可以看到当前试验的进展情况，搜索参数和效果最好的一些超参组合。
优化进度页面可以看到按时序排列的精度或损失值（此图为精度）。可以看到，时间越靠后（右侧），精度高的越多。这说明选择的超参探索算法随着时间能找到一些好的超参空间继续探索。
通过超参的分布图来直观地看到哪些超参值会明显比较好，或者看出它们之间的关联。通过下面的颜色图就能直观地看到红色（即精度较高的超参组合）线条所表达的丰富信息。如：
卷积核大一些会表现较好。
全连接层大了不一定太好。也许是所需要的训练时间增加了，训练速度太慢造成的。
而学习率小一些（小于0.03），表现基本都不错。
ReLU 比 tanh 等其它激活函数也好不少。
...
通过试验状态页面，能看到每个试验的时间长度以及具体的超参组合。
通过控制页面还可以实时的增加试验的超参组合，或者调整超参的范围。
最后，再贴一次地址：https://github.com/microsoft/nni
使用方法和更多详情，可参考 GitHub 的官网，有问题或 bug 可以直接提 Issue。