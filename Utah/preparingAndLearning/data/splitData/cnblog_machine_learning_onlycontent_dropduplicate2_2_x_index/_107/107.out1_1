Random Forest 是 加州 大学 伯克利 分校 的 Breiman Leo 
和 Adele Cutler 于 2001年 发表 的 论文 中 提到 
的 新的 机器学习 算法 可以 用来 做 分类 聚 类 
回归 和 生存 分析 这里 只 简单 介绍 该 算法 
在 分类上 的 应用 Random Forest 随机 森林 算法 是 
通过 训练 多个 决策树 生成 模型 然后 综合利用 多个 决策树 
进行 分类 随机 森林 算法 只 需要 两个 参数 构建 
的 决策 树 的 个数 t 在 决策树 的 每个 
节点 进行 分裂 时 需要 考虑 的 输入 特征 的 
个数 m 1 . 单棵/nr 决策树 的 构建 1 令 
N 为 训练 样例 的 个数 则/d 单棵/nr 决策树/n 的/uj 
输入/v 样例/i 的/uj 个数/n 为/p N/w 个/q 从/p 训练/vn 集/q 
中有/i 放回/v 的/uj 随机/d 抽取/v N/w 个/q 训练/vn 样例/i 2 
令 训练 样例 的 输入 特征 的 个数 为 M 
切 m 远远 小于 M 则 我们 在 每颗 决策树 
的 每个 节点 上 进行 分裂 时 从M个/nr 输入 特征 
里 随机 选择 m 个 输入 特征 然后 从这 m 
个 输入 特征 里 选择 一个 最好 的 进行 分裂 
m 在 构建 决策树 的 过程 中 不会 改变 3 
每 棵树 都 一直 这样 分裂 下去 直到 该 节点 
的 所有 训练 样例 都 属于 同 一类 不 需要 
剪枝 2 . 随机 森林 的 分类 结果 按照 1 
生成 t 个 决策树 之后 对于 每个 新 的 测试 
样例 综合 多个 决策树 的 分类 结果 来 作为 随机 
森林 的 分类 结果 1 目标 特征 为 数字 类型 
取 t 个 决策树 的 平均值 作为 分类 结果 2 
目标 特征 为 类别 类型 少数 服从 多数 取 单 
棵树 分类 结果 最多 的 那个 类别 作为 整个 随机 
森林 的 分类 结果 3 . 分类 效果 的 评价 
在 随机 森林 中 无需 交叉 验证 来 评价 其 
分类 的 准确性 随机 森林 自带 OOB out of bag 
错误 估计 OOB 在/p 构造/v 单棵/nr 决策树/n 时/n 我们/r 只是/c 
随机/d 有/v 放回/v 的/uj 抽取/v 了/ul N/w 个/q 样例/i 所以 
可以 用 没有 抽 取到 的 样例 来 测试 这棵 
决策树 的 分类 准确性 这些 样例 大概 占 总 样例 
数目 的 三分之一 作者 这么 说 的 我 还 不 
知道 理论上 是 如何 出来 的 但是 可以 自己 做 
试验 验证 所以 对于 每个 样例 j 都有 大约 三分之一 
的 决策树 记为 SetT j 在 构造 时 没用到 该 
样例 我们 就 用 这些 决策树 来 对 这个 样例 
进行 分类 我们 对于 所有 的 训练 样例 j 用 
SetT j 中的 树 组成 的 森林 对其 分类 然后 
看 其 分类 结果 和 实际 的 类别 是否 相等 
不相等 的 样例 所占 的 比例 就是 OOB 错误 估计 
OOB 错误 估计 被 证明 是 无偏 的 参考文献 1 
Mahout Wiki Random Forest 2 Leo Breiman 2001年 的 paper 
3 Breiman 自己 对 Random Forest 的 介绍 