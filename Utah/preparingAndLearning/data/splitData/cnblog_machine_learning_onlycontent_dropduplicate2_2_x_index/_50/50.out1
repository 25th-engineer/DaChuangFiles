1 什么 是 决策树 Decision Tree 决策树 是 一个 类似于 
流程图 的 树结构 其中 每 一个 树节点 表示 一个 属性 
上 的 测试 每 一个 分支 代表 一个 属性 的 
输出 每一个 树叶 节点 代 表 一个 类 或者 类 
的 分布 树 的 最 顶层 是 树 的 根 
节点 举 一个 例子 小明 同学 想 根据 天气 情况 
是否 享受 游泳运动 这里 包含 了 6个 属性 一条 样例 
即为 一个 实例 待 学习 的 概念 为 是否 享受 
运动 学习 目标函数 f X Y 根据 上面 的 表中 
实例 我们 可以 试着 用 一个 树 结构 的 流程图 
来 表示 小明 根据 那 6个 属性 决定 是否 享受 
运动 从 上面 这个 树状 图中 我们 可以 看到 总共 
的 实例 有 14个 出去 运动 的 实例 有 9个 
不 运动 的 实例 有 5个 从 树顶 往下看 首先 
看到 菱形 的 选项 意思 是 天气 如何 然后 分 
出了 三个 分支 晴天 阴天 雨天 实例 中 是 天气 
属性 为 晴天 并 决定 要 去 运动 的 有 
2个 不去 运动 的 有 3个 天气 属性 为 阴天 
并 决定 去 运动 的 有 4个 不 运动 的 
有 0个 天气 属性 为 雨天 并 决定 去 运动 
的 有 3个 不 运动 的 有 2个 从 图中 
我们 可以 看到 当 标记 中的 正 例 或者 反例 
为 0个 时 树 就不 继续 往下 扩展 了 比如 
天气 属性 为 阴天 的 时候 不去 运动 的 实例 
为 0个 假如 正 例 或者 反例 都 不为 0时 
那么 就 要根据 属性 继续 往下 扩展 树 决策树 是 
机器 学习 中 分类 方法 中 的 一个 重要 算法 
2 如何 构造 一个 决策树 算法 1 信息熵 信息 是 
一种 抽象 的 概念 那么 如何 对 信息 进行 一个 
量化 的 操作 呢 1948年 香农 提出 了 信息熵 的 
概念 一条 信息 的 信息量 大 小和 它 的 不确定性 
有 直接 的 关系 要 搞清楚 一件 非常 不 确定 
的 事情 或者 说 我们 对 一件 事情 一无所知 就 
需要 了解 大量 的 信息 信息量 的 度量 就 等于 
不确定性 的 多少 举个 例子 NBA 总决赛 的 夺冠 球队 
假设 你 对 NBA 球队 一无所知 你 需要 猜 多少次 
假设 每个 球队 的 夺冠 几率 都是 一样 的 这里 
我们 可以 给 进入 季后赛 的 NBA 球队 进行 编号 
NBA 季后赛 会 选出 16支 球队 然后 使用 二分法 进行 
猜测 猜测 冠军 队伍 在 1 8号 球队 之间 是 
的话 在 进行 二分 不是 的话 就在 9 16号 球队 
之间 这样 我们 要 猜测 的 次数 最多 是 4次 
2 ^ 4 = 16 嘛 信息熵 使用 比特 bit 
来 衡量 信息 的 多少 计算 公式 如下 P1 * 
log2 P1 + P2 * log2 P2 + . . 
. P16 * log2 P16 计算 NBA 季后赛 总冠军 的 
夺冠 球队 的 信息 熵值 含义 是 每一个 球队 的 
夺冠 概率 乘以 以 2 为 底 这个 队 夺冠 
的 对数 P1 P2 . . . PN 表示 哪 
一支 球队 的 夺冠 概率 假设 每 一个 球队 夺冠 
的 概率 都 相等 的话 那么 这里 算出 的 信息 
熵值 就是 4 当然 这种 情况 是 不太可能 存在 的 
因为 每 一个 球队 的 实力 不 一样 嘛 变量 
的 不 确定 越大 熵 的 值 也就 越大 2 
决策树 归纳 算法 ID3 这个 算法 是 1970 1980年 由 
J . Ross . Quinlan 发明 的 在 决策树 算法 
中 比较 重要 的 一点 是 我们 如何 确定 哪个 
属性 应该 先 选择 出来 哪个 属性 应该 后 选择 
出来 当做 树 的 节点 这里 就 涉及 到 了 
一个 新的 概念 叫做 信息 获取 量 公式 如下 Gain 
A = Info D Info _ A D A 属性 
的 信息 获取 量 的 值 就 等于 不按 任何 
属性 进行 分类 的 时候 的 信息量 加上 有按A/nr 这个 
属性 进行 分类 的 时候 的 信息量 注意 这里 信息量 
的 符号 是 负号 所以 说 加上 以 是否 购买 
电脑 的 案例 为 例子 给 出了 14个 实例 如下 
图 所示 不按 任何 属性 进行 分类 的 情况 下 
计算 信息 获取 量 Info D 以 年龄 属性 进行 
分类 的 情况 下 计算 信息 获取 量 所以 Gain 
age = 0.940 0.694 = 0.246 bits 同理 我们 可以 
算出 Gain income = 0.029 Gain student = 0.151 Gain 
credit _ rating = 0.048 比较 大 小 年龄 的 
信息 获取 量 是 最大 的 所以 选择 年龄 作为 
第一 个 根 节点 再次 同理 后面 的 节点 选择 
也 是 按照 这样 的 计算 方法 来 决定 以 
哪个 属性 作为 节点 3 结束 条件 当 我们 使用 
递归 的 方法 来 创建 决策树 时 什么 时候 停止 
节点 的 创建 很 关键 综上 停止 节点 创建 的 
条件 有 以下 几点 a 给定 节点 的 所有 样本 
属性 都 属于 同 一种 标记 的 时候 比如 2 
中的 例子 以 年龄 为 属性 创建 的 节点 下 
有 三个 分支               
              senior youth middle 
_ age 其中 middle _ age 的 所有 实例 的 
标记 都是 yes 也 就是说 中年人 都会 买 电脑 这种 
情况 下 这个 节点 就 可以 设置 成 树叶 节 
点了 b 当 没有 剩余 属性 用来 进一步 划分 样本 
时 就 停止 节点 的 创建 采用 多数 表决 c 
分枝 3 其它 算法 C 4.5 CART 算法 这几个 算法 
都是 贪心 算法 自上而下 只是 选择 属性 的 度量 方法 
不同 4 树 剪 枝叶 避免 overfitting 当 树 的 
深度 太大 时 设计 的 算法 在 训练 集上 的 
表现 会 比较 好 但是 在 测试 集上 的 表现 
却 会很 一般 这时 我们 就要 对 树 进行 一定 
的 裁剪 1 先 剪枝 当 分到 一定 程度 就不 
向下 增长 树 了 2 后 剪枝 把 树 完全 
建好 后 根据 类 的 纯度 来 进行 树 的 
裁剪 5 . 决策树 的 优点 直观 便于 理解 小规模 
数据集 有效 6 . 决策树 的 缺点 处理 连续变量 不好 
类别 较 多时 错误 增加 的 比较 快 可 规模性 
一般 