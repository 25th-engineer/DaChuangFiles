版权 声明 本文 由 LeftNotEasy 所有 发布 于 http / 
/ leftnoteasy . cnblogs . com 如果 转载 请 注明 
出处 在 未经 作者 同意 下 将 本文 用于 商业 
用途 将 追究 其 法律 责任 前言 上次 写过 一篇 
关于 贝叶斯 概率论 的 数学 最近 时间 比较 紧 coding 
的 任务 比较 重 不过 还是 抽空 看 了 一些 
机器 学习 的 书 和 视频 其中 很 推荐 两个 
一个 是 stanford 的 machine learning 公开课 在 verycd 可 
下载 可惜 没有 翻译 不过 还是 可以 看 另外 一个 
是 prml pattern recognition and machine learning Bishop 的 一部 
反响 不错 的 书 而且是 2008年 的 算是 比较 新的 
一 本书 了 前 几天 还 准备 写 一个 分布式计算 
的 系列 只 写了 个 开头 又 换到 写 这个 
系列 了 以后 看 哪边 的 心得 更多 就 写 
哪 一个 系列 吧 最近 干的/nr 事情 比较 杂 有跟/nr 
机器学习 相关 的 有跟/nr 数学 相关 的 也有 跟 分布式 
相关 的 这个 系列 主要 想 能够 用 数学 去 
描述 机器学习 想要 学好 机器学习 首先 得 去 理解 其中 
的 数学 意义 不 一定 要 到 能够 轻松 自如 
的 推导 中间 的 公式 不过 至少 得 认识 这些 
式子 吧 不然 看 一些 相关 的 论文 可就 看不 
懂了 这个 系列 主要 将会 着重于 去 机器学习 的 数学 
描述 这个 部分 将会 覆盖 但 不一定 局限于 回归 聚 
类 分类 等 算法 回归 与 梯度 下降 回归 在 
数学 上 来说 是 给定 一个点 集 能够 用 一条 
曲线 去 拟合 之 如果 这个 曲线 是 一条 直线 
那就 被 称为 线性 回归 如果 曲线 是 一条 二次曲线 
就 被 称为 二次 回归 回归 还有 很多 的 变种 
如 locally weighted 回归 logistic 回归 等等 这个 将在 后面 
去 讲 用 一个 很 简单 的 例子 来 说明 
回归 这个 例子 来自 很多 的 地方 也 在 很多 
的 open source 的 软件 中 看到 比如说 weka 大概 
就是 做一个 房屋 价值 的 评估 系统 一个 房屋 的 
价值 来自 很多 地方 比如说 面积 房间 的 数量 几室 
几 厅 地段 朝向 等等 这些 影响 房屋 价值 的 
变量 被称为 特征 feature feature 在 机器 学习 中 是 
一个 很 重要 的 概念 有 很多 的 论文 专门 
探讨 这个 东西 在 此处 为了 简单 假设 我们 的 
房屋 就是 一个 变量 影响 的 就是 房屋 的 面积 
假设 有 一个 房屋 销售 的 数据 如下 面积 m 
^ 2   销售 价钱 万元 123       
                250150   
                    
32087                   
        160102           
            220       
                    
  这个 表 类似于 帝都 5 环 左右 的 房屋 
价钱 我们 可以 做出 一个 图 x 轴 是 房屋 
的 面积 y 轴 是 房屋 的 售价 如下 如果 
来 了 一个 新的 面积 假设在 销售 价钱 的 记录 
中 没有 的 我们 怎么办 呢 我们 可以 用 一条 
曲线 去 尽量 准 的 拟合 这些 数据 然后 如果 
有 新的 输入 过来 我们 可以 在 将 曲线 上 
这个 点 对应 的 值 返回 如果 用 一条 直线 
去 拟合 可能 是 下面 的 样子 绿色 的 点 
就是 我们 想要 预测 的 点 首先 给 出 一些 
概念 和 常用 的 符号 在 不同 的 机器学习 书籍 
中 可能 有 一定 的 差别 房屋 销售 记录表 训练 
集 training set 或者 训练 数据 training data 是 我们 
流程 中 的 输入 数据 一般 称为 x 房屋 销售 
价钱 输出 数据 一般 称为 y 拟合 的 函数 或者 
称为 假设 或者 模型 一般 写做 y = h x 
训练 数据 的 条目 数 # training set 一条 训练 
数据 是 由 一对 输入 数据 和 输出 数据 组成 
的 输入 数据 的 维度 特征 的 个数 # features 
n 下面 是 一个 典型 的 机器 学习 的 过程 
首先 给 出 一个 输入 数据 我们 的 算法 会 
通过 一 系列 的 过程 得到 一个 估计 的 函数 
这个 函数 有 能力 对 没有 见过 的 新 数据 
给 出 一个 新的 估计 也 被 称为 构建 一个 
模型 就 如同 上面 的 线性 回归 函数 我们 用 
X1 X2 . . Xn 去 描述 feature 里面 的 
分量 比如 x1 = 房间 的 面积 x2 = 房间 
的 朝向 等等 我们 可以 做出 一个 估计 函数 θ 
在这儿 称为 参数 在 这儿 的 意思 是 调整 feature 
中 每个 分量 的 影响力 就是 到底 是 房屋 的 
面积 更 重要 还是 房屋 的 地段 更重要 为了 如果 
我们 令 X0 = 1 就 可以 用 向量 的 
方式 来 表示 了 我们 程序 也 需要 一个 机制 
去 评估 我们 θ 是否 比较好 所以 说 需要 对 
我们 做出 的 h 函数 进行 评估 一般 这个 函数 
称为 损失 函数 loss function 或者 错误 函数 error function 
描述 h 函数 不好 的 程度 在下面 我们 称 这个 
函数 为 J 函数 在这儿 我们 可以 做出 下面 的 
一个 错误 函数 这个 错误 估计 函数 是 去 对 
x i 的 估计值 与 真实 值 y i 差 
的 平方 和 作为 错误 估计 函数 前面 乘上 的 
1/2 是 为了 在 求导 的 时候 这个 系数 就 
不见 了 如何 调整 θ 以 使得 J θ 取得 
最小值 有 很多 方法 其中 有 最小二乘 法 min square 
是 一种 完全 是 数学 描述 的 方法 在 stanford 
机器学习 开放 课 最后 的 部分 会 推导 最小二乘 法的/nr 
公式 的 来源 这个/r 来/v 很多/m 的/uj 机器/n 学习/v 和/c 
数学/n 书上/s 都/d 可以/c 找到/v 这里 就 不提 最小二乘 法 
而 谈谈 梯度 下 降法 梯度 下 降法 是 按 
下面 的 流程 进行 的 1 首先 对 θ 赋值 
这个 值 可以 是 随机 的 也 可以 让 θ 
是 一个 全零的/nr 向量 2 改变 θ 的 值 使得 
J θ 按 梯度 下降 的 方向 进行 减少 为了 
更 清楚 给出 下面 的 图 这 是 一个 表示 
参数 θ 与 误差函数 J θ 的 关系 图 红色 
的 部分 是 表示 J θ 有着 比 较高 的 
取值 我们 需要 的 是 能够 让 J θ 的 
值 尽量 的 低 也 就是 深蓝色 的 部分 θ 
0 θ 1 表示 θ 向量 的 两个 维度 在 
上面 提到 梯度 下 降法 的 第一步 是 给 θ 
给 一个 初值 假设 随机 给 的 初值 是 在 
图上 的 十字 点 然后 我们 将 θ 按照 梯度 
下降 的 方向 进行 调整 就会 使得 J θ 往 
更低 的 方向 进行 变化 如图所示 算法 的 结束 将 
是 在 θ 下降 到 无法 继续 下降 为止 当然 
可能 梯度 下降 的 最终 点 并非 是 全局 最 
小点 可能 是 一个 局部 最 小点 可能 是 下面 
的 情况 上面 这张 图 就是 描述 的 一个 局部 
最 小点 这 是 我们 重新 选择 了 一个 初 
始点 得到 的 看来 我们 这个 算法 将会 在 很大 
的 程度 上 被 初 始点 的 选择 影响 而 
陷入 局部 最 小点 下面 我 将用 一个 例子 描述 
一下 梯度 减少 的 过程 对于 我们 的 函数 J 
θ 求 偏 导 J 求导 的 过程 如果 不 
明白 可以 温习 一下 微积分 下面 是 更新 的 过程 
也 就是 θ i 会 向着 梯度 最小 的 方向 
进行 减少 θ i 表示 更新 之前 的 值 后面 
的 部分 表示 按 梯度方向 减少 的 量 α 表示 
步长 也 就是 每次 按照 梯度 减少 的 方向 变化 
多少 一个 很 重要 的 地方 值得 注意 的 是 
梯度 是 有 方向 的 对于 一个 向量 θ 每 
一维 分量 θ i 都 可以 求出 一个 梯度 的 
方向 我们 就 可以 找到 一个 整体 的 方向 在 
变化 的 时候 我们 就 朝着 下降 最多 的 方向 
进行 变化 就 可以 达到 一个 最 小点 不管 它 
是 局部 的 还是 全局 的 用 更 简单 的 
数学 语言 进行 描述 步骤 2 是 这样 的 倒三角形 
表示 梯度 按 这种 方式 来 表示 θ i 就 
不见 了 看看 用好 向量 和 矩阵 真的 会 大大 
的 简化 数学 的 描述 啊 总结 与 预告 本 
文中 的 内容 主要 取自 stanford 的 课程 第二集 希望 
我 把 意思 表达 清楚 了 本 系列 的 下 
一篇 文章 也 将会 取自 stanford 课程 的 第三 集 
下一次 将会 深入 的 讲讲 回归 logistic 回归 和 Newton 
法 不过 本 系列 并不 希望 做成 stanford 课程 的 
笔记 版 再往 后面 就 不一定 完全 与 stanford 课程 
保持一致 了 