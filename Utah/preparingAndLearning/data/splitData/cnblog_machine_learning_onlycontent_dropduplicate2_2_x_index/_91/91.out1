Keras 是 一个 用于 深度 学习 的 Python 库 它 
包含 高效 的 数值 库 Theano 和 TensorFlow 本文 的 
目的 是 学习 如何 从 csv 中 加载 数据 并 
使其 可供 Keras 使用 如何 用 神经网络 建立 多类 分类 
的 数据 进行 建模 如何 使用 scikit learn 评估 Keras 
神经网络 模型 前言 对 两 分类 和多/nr 分类 的 概念 
描述 前言 是 整理 别人 博客 的 笔记 https / 
/ blog . csdn . net / qq _ 22238533 
/ article / details / 77774223 1 在 LR 逻辑 
回归 中 如何 进行 多 分类 一般 情况 下 我们 
所 认识 的 lr 模型 是 一个 二 分类 的 
模型 但是 能否 用 lr 进行 多 分类 任务 呢 
答案 当然 是 可以 的 不过 我们 需要 注意 的 
是 我们 有 许多 种 思想 利用 lr 来 进行 
分类 2 训练 多个 二 分类器 的 思想 既然 天然 
的 lr 是 用来 做 二 分类 那么 我们 很 
自然 地 想到 把 多 分类 划分 为 多个 二 
分类 的 任务 具体 有 以下 三种 策略 2.1 一对一 
假如 某 个 分类 中有 N 个 类别 我们 将 
这 N 个 类别 进行 两两 配对 两两 配对 后 
转化 为 二分 类 问题 那么 我们 可以 得到 个 
二 分类器 简单 解释一下 相当于 在 N 个 类别 里面 
抽 2个 之后 在 测试 阶段 我们 把 新 样本 
交给 这个 二 分类器 于是 我们 可以 得到 个 分类 
结果 把 预测 的 最多 的 类别 作为 预测 的 
结果 下面 我 给 一个 具体 的 例子 来 理解 
一下 上图 的 意思 其实 很 明显 首先 把 类别 
两两 组合 6种 组合 组合 完 之后 其中 一个 类别 
作为 正 类 另一个 作为 负 类 这个 正负 只是 
相对而言 目的 是 转化 为 二 分类 然后 对 每个 
二 分类器 进行 训练 可以 得到 6个 二 分类器 然后 
把 测试 样本 在 6个 二 分类器 上面 进行 预测 
从 结果 上 可以 看到 类别 1 被 预测 的 
最多 故 测 试样 本属于 类别 1 2.2 一对 其余 
OvR 一对 其余 其实 更加 好 理解 每次 将 一个 
类别 作为 正 类 其余 类别 作为 负 类 此时 
共有 N 个 分类器 在 测试 的 时候 若 仅有 
一个 分类器 预测 为 正 类 则 对应 的 类别 
标记 为 最终 的 分类 结果 例如 下面 这个 例子 
大概 解释一下 就是 有当 有 4个 类别 的 时候 每次 
把 其中 一个 类别 作为 正 类别 其余 作为 负 
类别 共有 4种 组合 对于 这 4中 组合 进行 分类器 
的 训练 我们 可以 得到 4个 分类器 对于 测试 样本 
放进 4个 分类器 进行 预测 仅有 一个 分类器 预测 为 
正 类 于是 取 这个 分类器 的 结果 作为 预测 
结果 分类器 2 预测 的 结果 是 类别 2 于是 
这 个 样本 便 属于 类别 2 其实 有人 会 
有疑问 那么 预测 为 负 类 的 分类器 就 不用 
管 了吗 是的 因为 预测 为 负 类 的 时候 
有 多种 可能 无法 确定 只有 预测 为 正 类 
的 时候 才能 唯一 确定 属于 哪 一类 比如 对于 
分类器 3 分类 结果 是 负 类 但是 负 类有 
类别 1 类别 2 类别 4 三种 到底 属于 哪 
一种 2.3 多对 多 MvM 所谓 多对 多 其实 就是 
把 多个 类别 作为 正 类 多个 类别 作为 负 
类 本文 不 介绍 这个 方法 详细 可以 参考 周志华 
西瓜 书 P64 P65 3 对于 上面 的 方法 其实 
都是/nr 训练 多个 二 分类器 那么 有 没有 更加 直接 
的 方法 对 LR 来 进行 多 分类 呢 我们 
知道 对于 二 分类 的 LR 时 正 类 和负类/nr 
的 概率 分别 如下 对于 多 分类 其实 我 只 
需要 做 简单 的 修改 就 可以 了 假设 某 
分类 任务 有K个/nr 类别 那么 对于 每 一个 类别 的 
概率 有 对于 第 K 类 来说 对于 其余 类 
而言 一 问题 描述 在 本文 学习 中 我们 将 
使用 鸢尾花 数据集 的 标准 机器学习 问题 这个 数据集 经过 
深入研究 是 在 神经 网络 上 练习 的 一个 很好 
的 问题 因为 所有 4个 输入 变量 都是 数字 的 
并且 具有 相同 的 厘米 级别 每个 实例 描述 观察到 
的 花 测量 的 属性 输出 变量 是 特定 的 
鸢尾 种类 这 是 一个 多 类别 的 分类 问题 
意味着 有 两个 以上 的 类 需要 预测 实际上 有三种 
花种 这是 用 神经网络 练习 的 一个 重要 问题 类型 
因为 三个 类 值 需要 专门 的 处理 鸢尾花 数据集 
是 一个 充分 研究 的 问题 我们 可以 期望 实现 
模型 精度 为 在 95％ 至 97％ 的 范围内 这 
为 开发 我们 的 模型 提供 了 一个 很好 的 
目标 您 可以 从 UCI 机器学习 库 下载 鸢尾花 数据集 
并将 其 放在 当前工作 目录 中 文件 名为     
iris . csv 5.1 3.5 1.4 0.2 Iris setosa 4.9 
3.0 1.4 0.2 Iris setosa 4.7 3.2 1.3 0.2 Iris 
setosa 4.6 3.1 1.5 0.2 Iris setosa 5.0 3.6 1.4 
0.2 Iris setosa 5.4 3.9 1.7 0.4 Iris setosa 4.6 
3.4 1.4 0.3 Iris setosa 5.0 3.4 1.5 0.2 Iris 
setosa 4.4 2.9 1.4 0.2 Iris setosa 4.9 3.1 1.5 
0.1 Iris setosa 5.4 3.7 1.5 0.2 Iris setosa 4.8 
3.4 1.6 0.2 Iris setosa 4.8 3.0 1.4 0.1 Iris 
setosa 4.3 3.0 1.1 0.1 Iris setosa 5.8 4.0 1.2 
0.2 Iris setosa 5.7 4.4 1.5 0.4 Iris setosa 5.4 
3.9 1.3 0.4 Iris setosa 5.1 3.5 1.4 0.3 Iris 
setosa 5.7 3.8 1.7 0.3 Iris setosa 5.1 3.8 1.5 
0.3 Iris setosa 5.4 3.4 1.7 0.2 Iris setosa 5.1 
3.7 1.5 0.4 Iris setosa 4.6 3.6 1.0 0.2 Iris 
setosa 5.1 3.3 1.7 0.5 Iris setosa 4.8 3.4 1.9 
0.2 Iris setosa 5.0 3.0 1.6 0.2 Iris setosa 5.0 
3.4 1.6 0.4 Iris setosa 5.2 3.5 1.5 0.2 Iris 
setosa 5.2 3.4 1.4 0.2 Iris setosa 4.7 3.2 1.6 
0.2 Iris setosa 4.8 3.1 1.6 0.2 Iris setosa 5.4 
3.4 1.5 0.4 Iris setosa 5.2 4.1 1.5 0.1 Iris 
setosa 5.5 4.2 1.4 0.2 Iris setosa 4.9 3.1 1.5 
0.1 Iris setosa 5.0 3.2 1.2 0.2 Iris setosa 5.5 
3.5 1.3 0.2 Iris setosa 4.9 3.1 1.5 0.1 Iris 
setosa 4.4 3.0 1.3 0.2 Iris setosa 5.1 3.4 1.5 
0.2 Iris setosa 5.0 3.5 1.3 0.3 Iris setosa 4.5 
2.3 1.3 0.3 Iris setosa 4.4 3.2 1.3 0.2 Iris 
setosa 5.0 3.5 1.6 0.6 Iris setosa 5.1 3.8 1.9 
0.4 Iris setosa 4.8 3.0 1.4 0.3 Iris setosa 5.1 
3.8 1.6 0.2 Iris setosa 4.6 3.2 1.4 0.2 Iris 
setosa 5.3 3.7 1.5 0.2 Iris setosa 5.0 3.3 1.4 
0.2 Iris setosa 7.0 3.2 4.7 1.4 Iris versicolor 6.4 
3.2 4.5 1.5 Iris versicolor 6.9 3.1 4.9 1.5 Iris 
versicolor 5.5 2.3 4.0 1.3 Iris versicolor 6.5 2.8 4.6 
1.5 Iris versicolor 5.7 2.8 4.5 1.3 Iris versicolor 6.3 
3.3 4.7 1.6 Iris versicolor 4.9 2.4 3.3 1.0 Iris 
versicolor 6.6 2.9 4.6 1.3 Iris versicolor 5.2 2.7 3.9 
1.4 Iris versicolor 5.0 2.0 3.5 1.0 Iris versicolor 5.9 
3.0 4.2 1.5 Iris versicolor 6.0 2.2 4.0 1.0 Iris 
versicolor 6.1 2.9 4.7 1.4 Iris versicolor 5.6 2.9 3.6 
1.3 Iris versicolor 6.7 3.1 4.4 1.4 Iris versicolor 5.6 
3.0 4.5 1.5 Iris versicolor 5.8 2.7 4.1 1.0 Iris 
versicolor 6.2 2.2 4.5 1.5 Iris versicolor 5.6 2.5 3.9 
1.1 Iris versicolor 5.9 3.2 4.8 1.8 Iris versicolor 6.1 
2.8 4.0 1.3 Iris versicolor 6.3 2.5 4.9 1.5 Iris 
versicolor 6.1 2.8 4.7 1.2 Iris versicolor 6.4 2.9 4.3 
1.3 Iris versicolor 6.6 3.0 4.4 1.4 Iris versicolor 6.8 
2.8 4.8 1.4 Iris versicolor 6.7 3.0 5.0 1.7 Iris 
versicolor 6.0 2.9 4.5 1.5 Iris versicolor 5.7 2.6 3.5 
1.0 Iris versicolor 5.5 2.4 3.8 1.1 Iris versicolor 5.5 
2.4 3.7 1.0 Iris versicolor 5.8 2.7 3.9 1.2 Iris 
versicolor 6.0 2.7 5.1 1.6 Iris versicolor 5.4 3.0 4.5 
1.5 Iris versicolor 6.0 3.4 4.5 1.6 Iris versicolor 6.7 
3.1 4.7 1.5 Iris versicolor 6.3 2.3 4.4 1.3 Iris 
versicolor 5.6 3.0 4.1 1.3 Iris versicolor 5.5 2.5 4.0 
1.3 Iris versicolor 5.5 2.6 4.4 1.2 Iris versicolor 6.1 
3.0 4.6 1.4 Iris versicolor 5.8 2.6 4.0 1.2 Iris 
versicolor 5.0 2.3 3.3 1.0 Iris versicolor 5.6 2.7 4.2 
1.3 Iris versicolor 5.7 3.0 4.2 1.2 Iris versicolor 5.7 
2.9 4.2 1.3 Iris versicolor 6.2 2.9 4.3 1.3 Iris 
versicolor 5.1 2.5 3.0 1.1 Iris versicolor 5.7 2.8 4.1 
1.3 Iris versicolor 6.3 3.3 6.0 2.5 Iris virginica 5.8 
2.7 5.1 1.9 Iris virginica 7.1 3.0 5.9 2.1 Iris 
virginica 6.3 2.9 5.6 1.8 Iris virginica 6.5 3.0 5.8 
2.2 Iris virginica 7.6 3.0 6.6 2.1 Iris virginica 4.9 
2.5 4.5 1.7 Iris virginica 7.3 2.9 6.3 1.8 Iris 
virginica 6.7 2.5 5.8 1.8 Iris virginica 7.2 3.6 6.1 
2.5 Iris virginica 6.5 3.2 5.1 2.0 Iris virginica 6.4 
2.7 5.3 1.9 Iris virginica 6.8 3.0 5.5 2.1 Iris 
virginica 5.7 2.5 5.0 2.0 Iris virginica 5.8 2.8 5.1 
2.4 Iris virginica 6.4 3.2 5.3 2.3 Iris virginica 6.5 
3.0 5.5 1.8 Iris virginica 7.7 3.8 6.7 2.2 Iris 
virginica 7.7 2.6 6.9 2.3 Iris virginica 6.0 2.2 5.0 
1.5 Iris virginica 6.9 3.2 5.7 2.3 Iris virginica 5.6 
2.8 4.9 2.0 Iris virginica 7.7 2.8 6.7 2.0 Iris 
virginica 6.3 2.7 4.9 1.8 Iris virginica 6.7 3.3 5.7 
2.1 Iris virginica 7.2 3.2 6.0 1.8 Iris virginica 6.2 
2.8 4.8 1.8 Iris virginica 6.1 3.0 4.9 1.8 Iris 
virginica 6.4 2.8 5.6 2.1 Iris virginica 7.2 3.0 5.8 
1.6 Iris virginica 7.4 2.8 6.1 1.9 Iris virginica 7.9 
3.8 6.4 2.0 Iris virginica 6.4 2.8 5.6 2.2 Iris 
virginica 6.3 2.8 5.1 1.5 Iris virginica 6.1 2.6 5.6 
1.4 Iris virginica 7.7 3.0 6.1 2.3 Iris virginica 6.3 
3.4 5.6 2.4 Iris virginica 6.4 3.1 5.5 1.8 Iris 
virginica 6.0 3.0 4.8 1.8 Iris virginica 6.9 3.1 5.4 
2.1 Iris virginica 6.7 3.1 5.6 2.4 Iris virginica 6.9 
3.1 5.1 2.3 Iris virginica 5.8 2.7 5.1 1.9 Iris 
virginica 6.8 3.2 5.9 2.3 Iris virginica 6.7 3.3 5.7 
2.5 Iris virginica 6.7 3.0 5.2 2.3 Iris virginica 6.3 
2.5 5.0 1.9 Iris virginica 6.5 3.0 5.2 2.0 Iris 
virginica 6.2 3.4 5.4 2.3 Iris virginica 5.9 3.0 5.1 
1.8 Iris virginica 二 导入/v 类/q 和/c 函数/n 我们/r 从/p 
导入/v 本文/r 需要/v 的/uj 所有/b 类/q 和/c 函数/n 开始/v 其中 
包括 需要 Keras 的 功能 还 包括 来自 pandas 的 
数据 加载 以及 来自 scikit learn 的 数据 准备 和 
模型 评估 import numpy import pandas from keras . models 
import Sequential from keras . layers import Dense from keras 
. wrappers . scikit _ learn import KerasClassifier from keras 
. utils import np _ utils from sklearn . model 
_ selection import cross _ val _ score from sklearn 
. model _ selection import KFold from sklearn . preprocessing 
import LabelEncoder from sklearn . pipeline import Pipeline 三 初始化 
随机数 生成器 下面 我们 将 随机数 生成器 初始 化为 常 
量值 7 这 对于 确保 我们 可以 再次 精确 地 
实现 从该/nr 模型 获得 的 结果 非常 重要 它 确保 
可以 再现 训练 神经网络 模型 的 随机 过程 # fix 
random seed for reproducibility seed = 7 numpy . random 
. seed seed 四 记载 数据集 可以 直接 加载 数据集 
因为 输出 变量 包含 字符串 所以 最 容易 使用 pandas 
加载 数据 然后 我们 可以 将 属性 列 拆 分为 
输入 变量 X 和 输出 变量 Y # load dataset 
dataframe = pandas . read _ csv iris . csv 
header = None dataset = dataframe . values X = 
dataset 0 4 . astype float Y = dataset 4 
五 编码 输出 变量 输出 变量 包含 三 个 不同 
的 字符串 值 当 使用 神经 网络 对 多类 分类 
问题 进行 建模 时 优良 作法 是 将 包含 每个 
类 值 的 值 的 向量 的 输出 属性 重新 
整形 为 一个 矩阵 每个 类 值 都 有一个 布尔值 
以及 给定 实例 是否 具有 该 值 是否 有类值/nr 这 
称为 one hot encoding   或者 从 分类 变量 创建 
虚拟 变量 例如 在 这个 问题 中 三个 类 值 
是 Iris setosa Iris versicolor 和 Iris virginica 如果 我们 
有 观察 结果 多类 分类 问题 本质 上 可以 分解 
为 多个 二 分类 问题 而 解决 二 分类 问题 
的 方法 有 很多 这里 我们 利用 Keras 机器学习 框架 
中的 ANN artificial neural network 来 解决 多 分类 问题 
这里 我们 采用 的 例子 是 著名 的 UCI Machine 
Learning Repository 中的 鸢尾花 数据集 iris flower dataset 多类 分类 
问题 与 二类 分类 问题 类似 需要 将 类别 变量 
categorical function 的 输出 标签 转化 为 数值 变量 这个 
问题 在 二 分类 的 时候 直接 转 换为 0 
1 输出 层 采用 sigmoid 函数 或 1 1 输出 
层 采用 tanh 函数 类似 的 在 多分 类 问题 
中 我们 将 转化 为 虚拟 变量 dummy variable 即用 
one hot encoding 方法 将 输出 标签 的 向量 vector 
转化 为 只在 出现 对应 标签 的 那一 列为 1 
其余 为 0 的 布尔 矩阵 以 我们 所用 的 
鸢尾花 数据 为例 sample label 1 Iris setosa 2 Iris 
versicolor 3 Iris virginica 用 one hot encoding 转化 后 
如下 sample Iris setosa Iris versicolor Iris virginica 1 1 
0 0 2 0 1 0 3 0 0 1 
注意 这 里 不要 将 label 直接 转化 成 数值 
变量 如 1 2 3 这样的话 与其说 是 预测 问题 
更 像是 回归 预测 的 问题 后者 的 难度 比 
前者 大 当 类别 比 较多 的 时候 输出 值 
的 跨度 就会 比较 大 此时 输出 层 的 激活 
函数 就 只能 用 linear 我们 可以 通过 首先 使用 
scikit learn 类 LabelEncoder 将 字符串 一致地 编码 为整 数来 
完成 此 操作 然后 使用 Keras 函数 to _ categorical 
将 整数 向量 转换 为 一个 热 编码 # encode 
class values as integers encoder = LabelEncoder encoder . fit 
Y encoded _ Y = encoder . transform Y # 
convert integers to dummy variables i . e . one 
hot encoded dummy _ y = np _ utils . 
to _ categorical encoded _ Y 六 定义 神经网络 模型 
Keras 库 提供 了 包装 类 允许 您 在 scikit 
learn 中 使用 Keras 开发 的 神经 网络 模型 Keras 
中 有一个 KerasClassifier 类 可 用作 scikit learn 中的 Estimator 
它 是 库 中 基本 类型 的 模型 KerasClassifier 将 
函数 的 名称 作为 参数 该 函数 必须 返回 构建 
的 神经 网络 模型 为 训练 做好 准备 下面 是 
一个 函数 它 将为 鸢尾花 分类 问题 创建 一个 基线 
神经网络 它 创建 了 一个 简单 的 完全 连接 的 
网络 其中 一个 隐藏 层 包含 8个 神经元 隐藏 层 
使用 整流器 激活 功能 这 是 一种 很好 的 做法 
因为 我们 对 鸢尾花 数据集 使用 了 单热/nr 编码 所以 
输出 层 必须 创建 3个 输出 值 每个 类 一个 
具有 最大值 的 输出 值 将被 视为 模型 预测 的 
类 这个 简单 的 单层 神经 网络 的 网络拓扑 可以 
概括 为 4 inputs 8 hidden nodes 3 outputs 请注意 
我们 在 输出 层 使用   softmax   激活 功能 
这 是 为了 确保 输出 值 在 0 和1的/nr 范围内 
并且 可以 用作 预测 概率 最后 网络 使用 具有 对数 
损失 函数 的 高效 Adam 梯度 下降 优化 算法 在 
Keras 中 称为   categorical _ crossentropy   # define 
baseline model def baseline _ model # create model model 
= Sequential model . add Dense 8 input _ dim 
= 4 activation = relu model . add Dense 3 
activation = softmax # Compile model model . compile loss 
= categorical _ crossentropy optimizer = adam metrics = accuracy 
return model 我们 现在 可以 创建 我们 的 KerasClassifier 用于 
scikit learn 我们 还 可以 在 构造 KerasClassifier 类 中 
传递 参数 该类 将 传递 给 内部 用于 训练 神经 
网络 的 fit 函数 在 这里 我们 将 时期 数量 
传递 为 200 批量 大小 为 5 以便 在 训练 
模型 时 使用 通过 将 verbose 设置 为 0 在 
训练 时 也会 关闭 调试 estimator = KerasClassifier build _ 
fn = baseline _ model epochs = 200 batch _ 
size = 5 verbose = 0 七 使用 k fold 
交叉 验证 评估 模型 Keras 是 基于 Theano 或 Tensorflow 
底层 开发 的 简单 模块化 的 神经 网络 框架 因此 
用 Keras 搭建 网络结构 会比 Tensorflow 更加 简单 这里 我们 
将 使用 Keras 提供 的 KerasClassifier 类 这个 类 可以 
在 scikit learn 包中/nr 作为 Estimator 使用 故/n 利用/n 这个/r 
类/q 我们/r 就/d 可以/c 方便/a 的/uj 调用/vn sklearn/w 包中的/nr 一些/m 
函数/n 进行/v 数据/n 预处理/vn 和/c 结果/n 评估/vn 此为 sklearn 包中/nr 
模型 model 的 基本 类型 对于 网络结构 我们 采用 3层 
全向 连接 的 输入 层 有 4个 节点 隐含 层 
有 10个 节点 输出 层 有 3个 节点 的 网络 
其中 隐含 层 的 激活 函数 为 relu rectifier 输出 
层 的 激活 函数 为 softmax 损失 函 数则 相应 
的 选择 categorical _ crossentropy 此 函数 来着 theano 或 
tensorflow 具体 可以 参见 这里 二 分类 的话 一般 选择 
activation = sigmoid loss = binary _ crossentropy PS 对于 
多类 分类 网络结构 而言 增加 中间 隐含 层 能够 提升 
训练 精度 但是 所需 的 计算 时间 和 空间 会 
增大 因此 需要 测试 选择 一个 合适 的 数目 这里 
我们 设为 10 此外 每 一层 的 舍弃 率 dropout 
也 需要 相应 调整 太高 容易 欠 拟合 太低 容易 
过拟合 这里 我们 设为 0.2 我们 现在 可以 在 训练 
数据 上 评估 神经网络 模型 scikit learn 具有 使用 一套 
技术 评估 模型 的 出色 能力 评估 机器学习 模型 的 
黄金 标准 是 k 倍 交叉 验证 首先 我们 可以 
定义 模型 评估 程序 在 这里 我们 将 折叠 数 
设置 为 10 一个 很好 的 默认值 并在 分区 之前 
对 数据 进行 洗牌 kfold = KFold n _ splits 
= 10 shuffle = True random _ state = seed 
现在 我们 可以 使用 10倍 交叉 验证 程序 kfold 在 
我们 的 数据 集 X 和 dummy _ y 上 
评估 我们 的 模型 估计 器 评估 模型 仅 需要 
大约 10 秒钟 并 返回 一个 对象 该 对象 描述 
了 对 数据集 的 每个 分割 的 10个 构建 模型 
的 评估 results = cross _ val _ score estimator 
X dummy _ y cv = kfold print Baseline % 
. 2f % % % . 2f % % % 
results . mean * 100 results . std * 100 
结果 总结 为 数据 集上 模型 精度 的 均值 和 
标准差 这是 对看 不见 的 数据 的 模型 性能 的 
合理 估计 对于 这个 问题 它 也 属于 已知 的 
最佳 结果 范围 Accuracy 97.33% 4.42% 八 代码 实现 import 
numpy as np import pandas as pd from keras . 
models import Sequential from keras . layers import Dense Dropout 
from keras . wrappers . scikit _ learn import KerasClassifier 
from keras . utils import np _ utils from sklearn 
. model _ selection import train _ test _ split 
KFold cross _ val _ score from sklearn . preprocessing 
import LabelEncoder # load dataset dataframe = pd . read 
_ csv iris . csv header = None dataset = 
dataframe . values X = dataset 0 4 . astype 
float Y = dataset 4 # encode class values as 
integers encoder = LabelEncoder encoded _ Y = encoder . 
fit _ transform Y # convert integers to dummy variables 
one hot encoding dummy _ y = np _ utils 
. to _ categorical encoded _ Y # define model 
structure def baseline _ model model = Sequential model . 
add Dense output _ dim = 10 input _ dim 
= 4 activation = relu model . add Dropout 0.2 
model . add Dense output _ dim = 3 input 
_ dim = 10 activation = softmax # Compile model 
model . compile loss = categorical _ crossentropy optimizer = 
adam metrics = accuracy return model estimator = KerasClassifier build 
_ fn = baseline _ model nb _ epoch = 
40 batch _ size = 256 # splitting data into 
training set and test set . If random _ state 
is set to an integer the split datasets are fixed 
. X _ train X _ test Y _ train 
Y _ test = train _ test _ split X 
dummy _ y test _ size = 0.3 random _ 
state = 0 estimator . fit X _ train Y 
_ train # make predictions pred = estimator . predict 
X _ test # inverse numeric variables to initial categorical 
labels init _ lables = encoder . inverse _ transform 
pred # k fold cross validate seed = 42 np 
. random . seed seed kfold = KFold n _ 
splits = 10 shuffle = True random _ state = 
seed results = cross _ val _ score estimator X 
dummy _ y cv = kfold 九 总 结在 这篇文章 
中 我们 学习 了 如何 使用 Keras Python 库 开发 
和 评估 神经 网络 以 进行 深度 学习 学习 了 
以下 知识 如何 加载 数据 并 使其 可 用于 Keras 
如何 使用 一个 热 编码 准备 多类 分类 数据 进行 
建模 如何 使用 keras 神经网络 模型 与 scikit learn 如何 
使用 Keras 定义 神经 网络 进行 多类 分类 如何 使用 
带有 k fold 交叉 验证 的 scikit learn 来 评估 
Keras 神经网络 模型 十 参考 http / / m a 
c h i n e l e a r n 
i n g m a s t e r y 
. com / multi class classification tutorial keras deep learning 
library / http / / datascience . stackexchange . com 
/ questions / 10048 / what is the best keras 
model for multi label c l a s s i 
f i c a t i o n h t 
t p / / stackoverflow . com / questions / 
28064634 / random state pseudo random numberin scikit learnhttp / 
/ scikit learn . org / stable / modules / 
classes . html 