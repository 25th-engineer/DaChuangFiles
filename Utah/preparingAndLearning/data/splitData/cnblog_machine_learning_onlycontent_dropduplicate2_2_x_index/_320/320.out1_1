从 去年 开始 陆陆续续 学习 了 大半年 的 机器学习 现在 
是 时候 做 个 总结 了 在 以往 的 编程 
经验 里面 我们/r 需要/v 对/p 于/p 输入/v 有/v 一个/m 精确/a 
的/uj 可 控制 的 可以 说明 的 输出 例如 将 
1 + 1 作为 输入 其 结果 就是 一个 精确 
的 输出 2 并且 不论 怎么 调整 参数 都 希望 
结果 是 2 并且 能够 很 清楚 的 说明 为什么 
结果 是 2 不是 3 这样 的 理念 在 传统 
的 IT 界 非常 重要 所有 的 东西 就像 时钟 
一般 精确 一切 都是/nr 黑白 分明 的 由于 这种 严格 
的 输入输出 衍生 出 很多 对于 程序 的 自动 测试工具 
你 的 程序 无论 怎么 运行 都 应该 在 相同 
输入 情况 下 得到 相同 的 准确 的 精确 的 
输出 但是 如果 你 进入 机器 学习 的 世界 则 
一切 都是/nr 基于 一个 准确率 换句话说 你 的 模型 允 
许是 不 完美 的 1 + 1 结果 可以 是 
2.01 也 可以 是 1.98 有时候 如果 你 的 模型 
要 追求 完美 则 可能 出现 过 拟合 的 可能性 
也 就是说 由于 你 的 模型 太 过于 完美 使得 
模型 可以 很好 的 匹配 训练 用 数据 反而 失去 
了 通用性 在 数据 发生 变化 的 时候 发生 错误 
举个 例子 来说 吧 如果 一个 男孩子 说 喜欢 某个 
女孩子 这个 女孩子 身高 178 籍贯 是 辽宁 抚顺 专业 
是 计算机 如果 机器学习 发生 过拟合 的 时候 它 就会 
输出 这样 一个 模型 如果 身高 = 178 籍贯 = 
抚顺 专业 = 计算机 则 喜欢 这个 模型 如果 用来 
匹配 一个 个例 则 这个 模型 是 完美 的 但是 
如果 这个 女孩子 身高 是 179 呢 这个 模型 会 
告诉 你 这个 男孩子 不 喜欢 她 其实 对于 男 
孩子 来说 178 和 179 其实 没有 什么 很大 的 
区别 但是 由于 计算机 想 精确 给出 男孩子 喜欢 女孩子 
的 模型 所以 计算机 做出 了 过拟合 的 模型 当然 
一般来说 计算机 的 模型 应该 是 有 弹性 的 身高 
在 175 185 之间 籍贯 是 东北 专业 是 IT 
相关 的 这样 的话 模型 虽然会 把 一些 男 孩子 
不 喜欢 的 女孩子 也 错误 的 标识 出来 但是 
大 部分 的 样本 还是 可以 比较 好 的 预测 
出来 的 机器学习 追求 的 不是 100% 的 正确 而是 
一个 可以 容忍 的 正确 率 当然 在 某些 时候 
还 需要 一些 风险 策略 的 例如 在 人工智能 判断 
一个 用户 是否 能够 发给 信用卡 的 时候 并 不是 
说 这个人 51% 的 可能性 是 一个 讲 信用 的 
人 就 发卡 而 是 这个 人 95% 是 讲 
信用 的 人 的 时候 才 发卡 的 机器 给出 
的 只是 一个 估计值 最后 还是 要 人工 控制 风险 
的 机器学习 很多 人 认为 是 一个 高 科技 的 
IT 技能 其实 一个 好 的 机器学习 模型 领域 里 
的 业务 知识 还是 很 需要 的 而且 现在 很多 
工具 可以 帮助 大家 建立 程序 完全 不 需要 什么 
编程 的 技能 只 需要 给 机器 喂 数据 调节 
参数 就 可以 获得 结果 了 给 机器 喂 什么 
数据 那些 数据 的 特征 值 是 有用 的 那些 
特征值 没有 价值 这个 就是 领域专家 思考 的 问题 了 
男孩子 喜欢 女孩子 这时候 颜值/nr 身材 脾气 可能 是 比较 
关键 的 特征 值 喜欢 可口可乐 还是 百事可乐 则 变得 
基本 没有 什么 价值 如果 你 的 数据 里面 都是 
女孩子 喜欢 那个 牌子 的 可乐 这样 的 数据 训练 
出来 的 模型 没有 任何 意义 当然 如果 你 有 
很多 特征值 还是 有 一些 自动化 的 计算 帮 你 
挑选 用 那些 特征值 的 主 成因 分析 在 机器 
学习 中 有 一些 复杂 的 概念 往往 都 是由 
一个 简单 的 概念 扩展 开来 的 卷积 神经网络 为首 
的 一些 神经 网络 的 概念 都 是从 感知机 这个 
小家伙 来 的 感知机 的 输出 是由 输入 和 权重 
决定 的 在 监督 学习 中 输入 和 输出 是 
已知 的 然后 机器学习 通过 不停 的 调整 权重 使得 
感知机 的 输出 模型 和 实际 的 输出 样本 尽量 
一致 这个 过程 中 学习 结果 就是 这些 权重 权重 
知道 了 模型 就 定下 来了 一个 最 简单 的 
感知机 的 应用 就是 线性 单元 零基础 入门 深度 学习 
1 感知器 零基础 入门 深度 学习 2 线性 单 元和 
梯度 下降 单个 感知机 是 弱小 的 但是 如果 感知机 
有 成千上万 个 然后 一层 一层 一层 叠加 起来 呢 
这些 小家伙 就 变成 强大 的 神经 网络 了 贝叶斯 
马尔科夫 同志 则 共享 了 很多 关于 概率 的 机器学习 
贝叶斯 最大 贡献 如下 在 你家 隔壁 住着 老王 B 
的 前提 下 你 的 孩子 长得 像 隔壁 老王 
A 的 概率 等于 你 的 孩子 长得 像 隔壁 
老王 A 的 前提 下 你家 隔壁 住着 老王 B 
乘以 你 的 孩子 长得 像 隔壁 老王 A 的 
概率 和 隔壁 是否 住着 老王 无关 除以 你家 隔壁 
住着 老王 B 的 概率 当然 这个 正统 说法 要 
牵涉到 先验概率 后验/nr 概率 从最/nr 简单 的 伯努利 分布 到 
关于 分布 的 分布 的 变态 级别 的 狄利克雷 分布 
很多 机器学习 都在 追求 模型 最 符合 抽样 的 分布 
概率 换句话说 就是 希望 从 概率 学 上看 我们 做 
出来 的 模型 和 我们 看到 的 样本 之间 看上去 
是 最 相似 最大 似 然 例如 我们 要 做 
一个 模型 表示 抛 一枚 硬币 有 多大 概率 正面 
向上 如果 我们 的 样本 告诉 我们 10次 里面 有 
7次 正面 向上 则 我们 说 这 枚 硬币 70% 
会 出现 正面 向上 这个 模型 的 结论 和 样本 
之间 从 概率 学 上看 是 最 有可能 的 我们 
做 的 模型 就是 追求 和 实际 样本 的 结果 
在 概率 学 上看 是 最 有可能 发生 的 情况 
最快 梯度 下降 则 几乎 出现 在 所有 的 迭代 
算法 中 为什么 梯度 下降 特别 重要 因为 大 部分 
的 算法 都是/nr 尽可能 将 损失 函数 降低 怎么 才能 
将 损失 函数 降低 就是 不停 调整 参数 权重 权重 
调整 的 方向 和 梯度 下降 的 方向 是 一致 
的 当然 最快 梯度 下降 有 可能 不会 收敛 到 
全局 最低点 能否 收敛 到 全局 最低点 和 初始 位置 
有关 机器 学习 和 自然 语言 处理 也 是 密不可分 
的 在 很多 自然语言 处理 中 将 大量 使用 机器 
学习 的 概念 马尔可夫 链 和 条件 随 机场 狄利克雷 
分布 这些 都是/nr 自然 语言 处理 的 基础理论 关注 公众 
号 TensorFlow 教室 深度 学习 机器学习 自然语言 处理 