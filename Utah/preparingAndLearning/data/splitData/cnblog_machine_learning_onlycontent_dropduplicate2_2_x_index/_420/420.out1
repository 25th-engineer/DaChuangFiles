在 使用 机器学习 算法 过程 中 针对 不同 的 问题 
需要 不用 的 模型 评估 标准 这里 统一 汇总 主要 
以 两大类 分类 与 回归 分别 阐述 一 分类 问题 
1 混淆 矩阵 混淆 矩阵 是 监督 学习 中 的 
一种 可视化 工具 主要 用于 比较 分类 结果 和 实例 
的 真实 信息 矩阵 中的 每 一行 代表 实例 的 
预测 类别 每 一列 代表 实例 的 真实 类别 真正 
True Positive TP 被 模型 预测 为 正 的 正 
样本 假 正 False Positive FP 被 模型 预测 为 
正 的 负 样本 假 负 False Negative FN 被 
模型 预测 为 负 的 正 样本 真 负 True 
Negative TN 被 模型 预测 为 负 的 负 样本 
真正 率 True Positive Rate TPR TPR = TP / 
TP + FN 即被 预测 为 正 的 正 样本数 
/ 正 样本 实际 数 假 正 率 False Positive 
Rate FPR FPR = FP / FP + TN 即被 
预测 为 正 的 负 样本数 / 负 样本 实际 
数 假 负 率 False Negative Rate FNR FNR = 
FN / TP + FN 即被 预测 为 负 的 
正 样本数 / 正 样本 实际 数 真 负 率 
True Negative Rate TNR TNR = TN / TN + 
FP 即被 预测 为 负 的 负 样本数 / 负 
样本 实际 数 / 22 准确率 Accuracy 准确率 是 最 
常用 的 分类 性能指标 Accuracy = TP + TN / 
TP + FN + FP + TN 即 正确 预测 
的 正反 例数 / 总数 3 精确 率 Precision 精确 
率 容易 和 准确率 被 混为一谈 其实 精确 率 只是 
针对 预测 正确 的 正 样本 而 不是 所有 预测 
正确 的 样本 表现 为 预测 出 是 正 的 
里面 有 多少 真 正是 正 的 可 理解 为 
查准率 Precision = TP / TP + FP 即 正确 
预测 的 正 例数 / 预测 正 例 总数 4 
召回率 Recall 召回率 表现 出 在 实际 正 样本 中 
分类器 能 预测 出 多少 与 真正 率 相等 可 
理解 为 查全率 Recall = TP / TP + FN 
即 正确 预测 的 正 例数 / 实际 正 例 
总数 5 F1 scoreF 值 是 精确 率 和 召回率 
的 调和 值 更 接近 于 两个 数 较小 的 
那个 所以 精确 率 和 召回率 接近 时 F 值 
最大 很多 推荐 系统 的 评测 指标 就是 用 F 
值 的 2 / F1 = 1 / Precision + 
1 / Recall6 ROC 曲线 逻辑 回归 里面 对于 正负 
例 的 界定 通常会 设 一个 阈值 大于 阈值 的 
为 正 类 小于 阈值 为 负 类 如果 我们 
减小 这个 阀值 更多 的 样本 会 被 识别 为 
正 类 提高 正 类 的 识别 率 但 同时 
也 会 使得 更多 的 负 类 被 错误 识别 
为 正 类 为了 直观 表示 这 一 现象 引入 
ROC 根据 分类 结果 计算 得到 ROC 空间 中 相应 
的 点 连接 这些 点 就 形成 ROC curve 横坐标 
为 False Positive Rate FPR 假 正 率 纵坐标 为 
True Positive Rate TPR 真正 率 一般 情况 下 这个 
曲线 都 应该 处于 0 0 和 1 1 连线 
的 上方 如图 ROC 曲线 中的 四个 点 和 一条线 
点 0 1 即 FPR = 0 TPR = 1 
意味着 FN ＝ 0 且 FP ＝ 0 将 所有 
的 样本 都 正确 分类 点 1 0 即 FPR 
= 1 TPR = 0 最差 分类器 避开 了 所有 
正确 答案 点 0 0 即 FPR = TPR = 
0 FP ＝ TP ＝ 0 分类器 把 每个 实例 
都 预测 为 负 类 点 1 1 分类器 把 
每个 实例 都 预测 为 正 类 总之 ROC 曲线 
越 接近 左上角 该 分类器 的 性能 越好 而且 一般来说 
如果 ROC 是 光滑 的 那么 基本 可以 判断 没有 
太大 的 overfitting7 AUCAUC Area Under Curve 被 定义 为 
ROC 曲 线下 的 面积 ROC 的 积分 通常 大于 
0.5 小于 1 随机 挑选 一个 正 样本 以及 一个 
负 样本 分类器 判定 正 样本 的 值 高于 负 
样本 的 概率 就是 AUC 值 AUC 值 面积 越大 
的 分类器 性能 越好 如图 8 PR 曲线 PR 曲线 
的 横坐标 是 精确 率 P 纵坐标 是 召回率 R 
评价 标准 和 ROC 一样 先看 平滑 不 平滑 蓝线 
明显 好些 一般来说 在 同一 测试 集 上面 的 比下 
面的 好 绿线 比 红线 好 当 P 和R的/nr 值 
接近 时 F1 值 最大 此时 画 连接 0 0 
和 1 1 的 线 线 和 PRC 重合 的 
地方 的 F1 是 这条 线 最大 的 F1 光滑 
的 情况 下 此时 的 F1 对于 PRC 就好像 AUC 
对于 ROC 一样 一个 数字 比 一条线 更 方便 调 
型 有时候 模型 没有 单纯 的 谁比谁 好 比如 图二 
的 蓝线 和青线/nr 所以 选择 模型 还是 要 结合 具体 
的 使用 场景 下面 是 两个 场景 1 地震 的 
预测 对于 地震 的 预测 我们 希望 的 是 RECALL 
非常 高 也 就是说 每次 地震 我们 都 希望 预测 
出来 这个 时候 我们 可以 牺牲 PRECISION 情愿 发出 1000次 
警报 把 10次 地震 都 预测 正确 了 也 不要 
预测 100次 对了 8次 漏了 两次 2 嫌疑人 定罪 基于 
不 错怪 一个 好人 的 原则 对于 嫌疑人 的 定罪 
我们 希望 是 非常 准确 的 即时 有时候 放过 了 
一些 罪犯 recall 低 但也 是 值得 的 对于 分类器 
来说 本质上 是 给 一个 概率 此时 我们 再 选择 
一个 CUTOFF 点 阀值 高于 这个 点 的 判 正 
低于 的 判 负 那么 这个 点 的 选择 就 
需要 结合 你 的 具体 场景 去 选择 反过来 场景 
会 决定 训练 模型 时的/nr 标准 比如 第一 个 场景 
中 我们 就 只看 RECALL = 99.9999% 地震 全中 时的/nr 
PRECISION 其他 指标 就 变得 没有 了 意义 当 正负 
样本 数量 差距 不大 的 情况 下 ROC 和 PR 
的 趋势 是 差不多 的 但是 在 正负 样本分布 极不 
均衡 的 情况 下 PRC 比 ROC 更能 真实 的 
反映 出 实际 情况 因为 此时 ROC 曲线 看起来 似乎 
很好 但是 却在 PR 上 效果 一般 二 回归 问题 
拟合 回归 问题 比较 简单 所 用到 的 衡量 指标 
也 相对 直观 假设 yiyi 是 第 ii 个 样本 
的 真实 值 y ̂   iy ^ i 是 
对 第 ii 个 样本 的 预测 值 1 . 
平均 绝对误差 MAE 平均 绝对误差 MAE Mean Absolute Error 又 
被 称为 l1 范数 损失 l1 norm loss 2 . 
平均 平方 误差 MSE 平均 平方 误差 MSE Mean Squared 
Error 又 被 称为 l2 范数 损失 l2 norm loss 
3 均方根 误差 RMSE RMSE 虽然 广为 使用 但是 其 
存在 一些 缺点 因为 它 是 使用 平均误差 而 平均值 
对 异常 点 outliers 较 敏感 如果 回归 器 对 
某个 点 的 回归 值 很不 理性 那么 它 的 
误差 则 较大 从而 会对 RMSE 的 值 有 较大 
影响 即 平均值 是非 鲁棒 的 4 解释 变异 解释 
变异   Explained variance 是 根据 误差 的 方差 计算 
得到 的 5 决定系数 决定系数 Coefficient of determination 又 被 
称为 R2 分数 三 聚 类 1 . 兰德 指数 
兰德 指数 Rand index 需要 给定 实际 类别 信息 C 
假设 K 是 聚 类 结果 a 表示 在 C 
与 K 中都 是 同类 别的 元素 对数 b 表示 
在 C 与 K 中都 是 不同 类别 的 元素 
对数 则 兰德 指数 为 其中 数据 集中 可以 组成 
的 总 元素 对数 RI 取值 范围 为 0 1 
值 越大 意味着 聚 类 结果 与 真实 情况 越 
吻合 对于 随机 结果 RI 并 不能 保证 分数 接近 
零 为了实现 在 聚 类 结果 随机 产生 的 情况 
下 指标 应该 接近 零 调整 兰德 系数 Adjusted rand 
index 被 提出 它 具有 更高 的 区分度 具体 计算 
方式 参见 Adjusted Rand index ARI 取值 范围 为 − 
1 1 值 越大 意味着 聚 类 结果 与 真实 
情况 越 吻合 从 广义 的 角度 来讲 ARI 衡量 
的 是 两个 数据 分布 的 吻合 程度 2 . 
互信息 互信息 Mutual Information 也是 用来 衡量 两个 数据 分布 
的 吻合 程度 假设 UU 与 VV 是 对 NN 
个 样本 标签 的 分配情况 则 两种 分布 的 熵 
熵 表示 的 是 不确定 程度 分别为 利用 基于 互 
信息 的 方法 来 衡量 聚 类 效果 需要 实际 
类别 信息 MI 与 NMI 取值 范围 为 0 1 
AMI 取值 范围 为 − 1 1 它们 都是 值 
越大 意味着 聚 类 结果 与 真实 情况 越 吻合 
3 . 轮廓 系数 轮廓 系数 Silhouette coefficient 适用 于 
实际 类别 信息 未知 的 情况 对于 单个 样本 设 
aa 是 与 它 同 类别 中 其他 样本 的 
平均 距离 bb 是 与 它 距离 最近 不同 类别 
中 样本 的 平均 距离 轮廓 系数 为 对于 一个 
样本 集合 它 的 轮廓 系数 是 所有 样本 轮廓 
系数 的 平均值 轮廓 系数 取值 范围 是 − 1 
1 − 1 1 同 类别 样本 越 距离 相近 
且 不同 类别 样本 距离 越远 分数 越高 四 信息检索 
信息检索 评价 是 对 信息 检索系统 性能 主要 满足 用户 
信息 需求 的 能力 进行 评估 与 机器 学习 也 
有 较大 的 相关性 感 兴趣 的 可以 参考 这篇 
不错 的 博文 五 总结 上面 介绍 了 非常 多 
的 指标 实际 应用 中 需要 根据 具体 问题 选择 
合适 的 衡量 指标 那么 具体 工作 中 如何 快速 
使用 它们 呢 优秀 的 Python 机器学习 开源 项目 Scikit 
learn 实现 了 上述 绝 指标 的 大多数 使用 起来 
非常 方便 