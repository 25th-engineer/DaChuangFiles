6 . 学习 模型 的 评估 与 选择 Content6 . 
学习 模型 的 评估 与 选择 6.1 如何 调试 学习 
算法 6.2 评估 假设 函数 Evaluating a hypothesis 6.3 模型 
选择 与 训练 / 验证 / 测试 集 Model selection 
and training / validation / test sets 6.4 偏差 与 
方差 6 . 4.1 Diagnosing bias vs . variance . 
6 . 4.2 正则化 与 偏差 / 方差 Regularization and 
bias / variance 6.5 学习曲线 Learning Curves 6.6 调试 学习 
算法 我们 已经 学习 了 许多 有用 的 学习 模型 
线性 回归 Logistic 回归 神经网络 但是 当 要 解决 一个 
实际 问题 时 以下 问题 是 我们 要 考虑 的 
如何 知道 我们 所 设计 的 模型 是 有用 的 
或者 较好 的 当 模型 应用 的 不 理想 时 
我们 应该 从 哪些 方面 进行 改进 如何 针对 具体 
问题 选择 学习 模型 下面 将 针对 上述 问题 提出 
建议 6.1 如何 调试 学习 算法 现在 假设 我们 已经 
实现 了 如下 的 一个 正则化 的 线性 回归模型 用于 
预测 房价 根据 已 有的 训练 集 我们 已经 将 
该 模型 训练 完毕 但是 当 我们 需要 在 新的 
数据 集上 进行 房价 的 预测 时 发现/v 预测/vn 的/uj 
结果/n 和/c 实际/n 有/v 很大/a 的/uj 误差/n 下面 我们 应该 
做 什么 我们 可以 从 下面 的 一些 角度 考虑 
获取 更多 的 数据 量 有时 数据 量大 并 没有 
帮助 通常 数据 量 越大 学习 模型 训练 得 越好 
但是 即使 这样 也 应该 做 一些 初步 实验 见 
6.5节 学习曲线 来 确保 数据 量 越大 训练 越好 如果 
一 开始 就 用 大量 的 数据 来 训练 模型 
将会 耗费 大量 的 时间 收集 数据 训练 模型 减少 
特征 量 细心 的 从 已有 的 特征 量 中 
选出 一个 子集 可以 手工 选择 也 可以 用 一些 
降 维   dimensionality   reduction 技术 增加 额外 的 
特征 量 有 时并 不起作用 仔细 考虑 数据集 是否 遗漏 
了 一些 重要 的 特征 量 可能 花费 较多 的 
时间 添加 的 特征 量 可能 只是 训练 集 的 
特征 不适合 全体 数据集 可能会 过拟合 添加 多项式 的 特征 
量减少 正则化 参数 增加 正则化 参数 可以 发现 我们 似乎 
有 很多 种 方法 来 改善 学习 模型 但是 有些 
方法 可能 要 花费 很多 时间 或许 还 不起作用 有些 
方法 可能 是 矛盾 的 所以 需要 一种 方式 来 
给 我们 指明 方向 到底 应该 采用 哪种 或 哪些 
方式 来 优化 模型 我们 将 这种 方式 称为 机器学习 
诊断 Machine Learning Diagnostics 机器学习 诊断 是 一种 测试法 能够 
深入 了解 某种 算法 到底 是否 有用 这 通常 也 
能够 告诉 我们 要想 改进 一种 算法 的 效果 什么样 
的 尝试 才是 有 意义 的 从而 节省 时间 减少 
不 必要 的 尝试 6.2 评估 假设 函数 Evaluating a 
hypothesis 当 我们 确定 学习 算法 的 参数 的 时候 
我们 考虑 的 是 选择 使 训练 误差 最小化 的 
参数 但 我们 已经 知道 见 3.1 underfitting and overfitting 
  仅仅 是 因为 这个 假设 具有 很小 的 训练 
误差 并 不能 说明 它 就 一定 是 一个 好 
的 假设 函数 可能 该 假设 函数 会 过拟合 泛化 
能力 弱 该 如何 判断 一个 假设 函数 是 过拟合 
的 呢 对于 简单 的 例子 可以 对 假设 函数 
h x 进行 画图 然后 观察 图形 趋势 但是 特征 
量 较多 时 大于 2 画图 就 很难 实现 因此 
我们 需要 另一种 方法 来 评估 我们 的 假设 函数 
如下 给出 了 一种 评估 假设 函数 的 标准 方法 
假设 我们 有 这样 一组 数据 组 如 1 我们 
要 做 的 是 将 这些 数据 分成 两部分   
训练 集 和 测试 集 一种 典型 的 分割 方法 
是 按照 7 3 的 比例 将 70% 的 数据 
作为 训练 集 30% 的 数据 作为 测试 集 这里 
默认 原有 数据集 是 无序 的 随机 的 所以 我们 
选择 前 70% 作为 训练 集 后 30% 作为 测试 
集 但 如果 原 数据集 是 有序 的 我们 应该 
随机 选择 出 7 3 的 数据 集 分别 作为 
训练 集 和 测试 集 1 大小 为 10 的 
数据集 及其 划分 因此 典型 的 训练 和 测试 方案 
如下 用 70% 划分 得到 的 训练 集 来 训练 
模型 即 最小化 J θ 计算 训练 后的/nr 模型 在 
测试 集上 的 误差 test set error 其中 Jtest θ 
  为 测试 集上 的 平均 平方 误差 average square 
error mtest 为 测试 集 的 大小 如果 我们 使用 
线性 回归 test set error 则为 另一种 定义 Logistics 回归 
的 误差 是 误 分类 率 m i s c 
l a s s i f i c a t 
i o n error 或称 0/1 错 分率 0/1 m 
i s c l a s s i f i 
c a t i o n . 定义 error functionTest 
error i s 6.3 模型 选择 与 训练 / 验证 
/ 测试 集 Model selection and training / validation / 
test sets 如何 选择 正则化 参数 的 大小 和 多项式 
的 次数 是 常常 面临 的 问题 称之为 模型 选择 
问题 我们 已经 多次 接触 到 过拟合 现象 在 过拟合 
的 情况 中 参数 非常 拟合 训练 集 那么 模型 
对于 相同 数据 组 预测 集 的 预测误差 不 能够 
用 来 推广 到 一般 情况 的 即是 不能 作为 
实际 的 泛化 误差 也 就是 不能 说明 你 的 
假设 对于 新 样本 的 效果 下面 我们 来 考虑 
模型 选择 问题 假如 要 选择 能 最好 地 拟合 
数据 的 多项式 次数 具体 地 我们 在 次数 为 
1 到 10 之间 应该 如何 做出 选择 d 表示 
应该 选择 的 多项式 次数 所以 似乎 除了 要 确定 
的 参数 θ 之外 我们 同样 需要 用 数据集 来 
确定 这个 多项式 的 次数 d d = 1 linear 
d = 2 quadratic . . . d = 10 
那么 我们 可以 这样 做 选择 第一 个 模型 d 
= 1 然后 求 训练 误差 的 最小值 得到 一个 
参数 向量 θ 1 选择 第二 个 模型 d = 
2 二次函数 模型 进行 同样 的 过程 得到 另一个 参数 
向量 θ 2 以此类推 最后 得到 θ 10 接下来 对 
所有 这些 模型 求出 测试 集 误差 Jtest θ 1 
Jtest θ 2 . . . Jtest θ 10 接下来 
为了 确定 选择 哪 一个 模型 最好 即 哪一个 对应 
的 测试 集 误差 最小 对于 这个 例子 我们 假设 
最终 选择 了 五次 多项式 模型 确定 模型 后 现在 
我们 想 知道 这个 模型 能 不能 很好 地 推广 
到 新 样本 我们 可以 观察 这个 五次 多项式 假设 
模型 对 测试 集 的 拟合 情况 但 这里 有 
一个 问题 是 这样 做 仍然 不能 公平 地 说明 
我 的 假设 推广 到 一般 时的/nr 效果 其 原因 
在于 我们 刚才 是 使用 的 测试 集 和 假设 
拟合 来 得到 的 多项式 次数 d 这个 参数 这 
也 就是说 我们 选择 了 一个 能够 最好 地 拟合 
测试 集 的 参数 d 的 值 因此 我们 的 
参数 向量 θ 5 在 拟合 测试 集 时的/nr 结果 
很可能 导致 一个 比 实际 泛化 误差 更 完美 的 
预测 结果 换言之 我们 是 找 了 一个 最能 拟合 
测试 集 的 参数 d 因此 我 再用 测试 集 
来 评价 我们 的 模型 就 显得 不 公平 了 
为了 解决 这 一 问题 在 模型 选择 中 如果 
我们 想 要 评价 某个 假设 我们 通常 采用 以下 
的 方法 给定 某个 数据集 和/c 刚才/t 将/d 数据/n 分为/v 
训练/vn 和/c 测试/vn 集/q 不同/a 的/uj 是/v 我们 要 将其 
分为 三段 训练 集   Training set   60% m 
values 交叉 检验 集   Cross validation   CV set 
  20% mcv 测试 集   Test set   20% 
  mtest 我们 随之 也 可以 定义 训练 误差 交叉 
验证 误差 和 测试 误差 如下 因此 我们 按 如下 
方式 选择 模型 1 . Minimize cost function for each 
of the models as before2 . Test these hypothesis on 
the   cross   validation set to generate the   
cross   validation error3 . Pick the hypothesis with the 
lowest cross validation error . e . g . pick 
  θ 54 . Finally Estimate generalization error of model 
using the test set 值得 注意 的 是 在 如今 
的 机器学习 应用 中 也 有 很多 人 是 用 
测试 集 来 选择 模型 然后 又 同样 的 测试 
集 来 评价 模型 的 表现 报告 测试 误差 看起来 
好像 还 能 得到 比较 不错 的 泛化 误差 如果 
有 很多 很多 测试 集 的话 这 也许 还 能 
行得通 否则 得到 的 测试 误差 很大 程度 要 比 
实际 的 泛化 误差 好 因此 最佳 做法 还是 把 
数据 分成 训练 集 验证 集 测试 集 6.4 偏差 
与 方差 6 . 4.1 Diagnosing bias vs . variance 
如 2 当 运行 一个 学习 算法 时 如果 这个 
算法 的 表现 不 理想 那么 多半 是 出现 两种 
情况 要么 是 偏差 比较 大 欠 拟合 要么 是 
方差 比较 大 过拟合 能 判断 出现 的 情况 是 
这 两种 情况 中的 哪 一种 非常 重要 因为 它 
是 一个 很 有效 的 指示器 告诉 我们 可以 改进 
算法 的 最 有效 的 方法 和 途径 2 不同 
模型 的 拟合 情况 现在 我们 已经 掌握 了 训练 
集 验证 集 和 测试 集 的 概念 我们/r 就/d 
能/v 更好/d 地/uv 理解/v 偏差/n 和/c 方差/n 的/uj 问题/n 具体来说 
我们 沿用 之前 所 使用 的 训练 集 误差 和 
验证 集 误差 的 定义 也 就是 平方 误差 画出 
3 . 3 多项式 次数 与 误差 的 关系 d 
等于 1 是 用 线性函数 来 进行 拟合 而在 最 
右边 的 这个 图 表示 更高 次数 的 多项式 的 
拟合 情况 随着 我们 增大 多项式 的 次数 我们 将 
对 训练 集 拟合 得 越来越 好 所以 如果 d 
等于 1时 对应 着 一个 比 较大 的 训练 误差 
而 如果 我们 的 多项式 次数 很高 时 我们 的 
训练 误差 就会 很小 甚至 可能 等于 0 因为 可能 
非常 拟合 训练 集 所以 当 我们 增大 多项式 次数 
时 我们 不难 发现 训练 误差 明显 下降 接下来 我们 
再看 交叉 验证 误差 如果 d 等于 1 意味着 用 
一个 很 简单 的 函数 来 拟合 数据 此时 我们 
不能 很好 地 拟合 训练 集 欠 拟合 我们 会 
得到 一个 较大 的 交叉 验证 误差 而 如果 我们 
用 一个 中等 大小 的 多项式 次 数来 拟 合时 
如 d 等于 2 那么 我们 会 得到 一个 更小 
的 交叉 验证 误差 因为 我们 找 了 一个 能够 
更好 拟合 数据 的 次数 但是 如果 次数 d 太大 
比如说 d 的 值 取 为 4 那么 我们 又 
过拟合 了 我们 又 会 得到 一个 较大 的 交叉 
验证 误差 具体来说 假设 我们 得出 了 一个 学习 算法 
而 这个 算法 并 没有 表现 地 如 期望 那么 
好 我们/r 应该/v 判断/v 此时/c 的/uj 学习/v 算法/n 是/v 正/d 
处于/v 高/a 偏差/n 的/uj 问题/n 还是/c 高/a 方差/n 的/uj 问题/n 
当 训练 误差 和 交叉 验证 误差 相近 且 都比 
较大 时 即 对应 3 曲线 中的 左端 对应 的 
就是 高 偏差 的 问题 相反地 当 训练 误差 较 
小而 交叉 验证 误差 远大于 训练 误差 时 即 对应 
3 曲线 右端 对应 的 是 高 方差 的 问题 
6 . 4.2 正则化 与 偏差 / 方差 Regularization and 
bias / variance 我们 知道 算法 正则化 可以 有效地 防止 
过拟合 但/c 正则化/i 跟/p 算法/n 的/uj 偏差/n 和/c 方差/n 又/d 
有/v 什么/r 关系/n 呢/y 对于 如下 正则化 的 线性 回归模型 
我们 分析 以下 三 种 情形 第 一种 情形 是 
正则化 参数 λ 取 一个 比 较大 的 值 如 
等于 10000 此时 所有 这些 参数 θ 将被 大大 惩罚 
其 结果 是 这些 参数 的 值 将 近似 等于 
0 并且 假设 模型 h x 的 值 将 等于 
或者 近似 等于 因此 我们 最终 得到 的 假设 函数 
应该 近似 是 一条 平滑 的 直线 如 4 1 
因此 这个 假设 处于 高 偏差 对 数据集 欠 拟合 
underfit 与之 对应 的 另一 种 情况 是 λ 值 
很小 比如 λ = 0 这种 情况 下 如果 我们 
要 拟合 一个 高阶 多项式 通常/d 会/v 处于/v 高/a 方差/n 
和/c 过拟合/i overfitting 的 情况 如 4 3 因为 λ 
的 值 等于 0 相当于 没有 正则化 项 因此 会对 
假设 过拟合 如 4 2 只有 λ 取 不大不小 的 
值 时 才会 得到 一组 对 数据 刚好 拟合 的 
参数值 θ 4 不同 λ 取值 的 拟合 情况 现在 
我们 可以 按照 如下 方式 选择 出 一个 最 合适 
的 正则化 参数 λ 确定 λ 可能 的 取值 向量 
通常 为 0 0.01 0.02 0.04 0.08 10.24 每一个 λ 
的 可能 取值 对应 一个 模型 对 每 一个 模型 
进行 训练 使 代价 函数 最小 得到 对应 的 参数 
θ 对于 每个 训练 后的/nr 模型 计算出 其 在 交叉 
检验 集上 的 误差 取 使 最小 的 模型 作为 
我们 的 模型 并将 其 应用于 测试 集 得到 测试 
误差 并 以此 估计 泛化 误差 其中 与 多项式 次数 
与 误差 类似 我们 可以 画出 λ 与 误差 的 
函数关系 如 5 所示 5 λ 与 误差 的 关系 
6.5 学习曲线 Learning Curves 有时 我们 需要 检查 学习 算法 
运行 是否 一切正常 或者 希望 改进 算法 的 表现 或 
效果 那么 学习曲线 Learning Curves 就是 一种 很好 的 工具 
并且 我们 可以 使用 学习曲线 来 判断 某 一个 学习 
算法 是否 处于 偏差 方差 问题 或 是 二者 皆有 
下面 我们 就 来 介绍 学习曲线 学习曲线 和 5 类似 
它们 的 区别 在于 学习曲线 是以 训练 集 的 大小 
m 为 横坐标 纵坐标 仍然 是 训练 集 误差 Jtrain 
和 交叉 检验 误差 Jcv 一般 情况下 的 学习 曲线 
如 7 所示 对于 训练 集 误差 而言 m 越小 
越 容易 拟合 误差 越小 换言之 Jtrain 随 m 的 
增大 而 增大 对于 交叉 检验 误差 而言 m 越小 
模型 的 泛化 能力 越弱/nr 故 误差 越大 换言之 Jcv 
随 m 的 增大 而 减小 当 m 大 到 
一定 程度 时 训练/vn 集/q 误差/n 和/c 交叉/n 检验/vn 误差/n 
较/zg 接近/v 且/zg 都/d 比较/d 小/a 7 一般 情况下 的 
学习 曲线 当 学习 算法 是 高 偏差 时 如 
8 所示 此时 对于 训练 集 误差 而言 当 m 
很 小时 误差 很小 但 由于 它 不能 很好 的 
拟合 训练 集 随后 就 会 增长 较快 达到 一个 
较 稳定 的 值 对于 交叉 检验 误差 而言 当 
m 很 小时 算法 的 泛化 能力 非常 弱 误差 
很大 随着 m 的 增加 泛化 能力 稍有 提升 误差 
会 有所 减小 但 由于 学习 算法 本身 对 训练 
集 误差 较大 故 交叉 检验 误差 不会 下降 太多 
最后 稳定 在 一个 较高 的 值 在 m 不 
太大 时 训练 集 误差 就和 交叉 检验 误差 接近 
但 都 比较 大 所以 在 高 偏差 的 情况 
下 增大 训练 集 往往 不起作用 8 高/a 偏差/n 时的/nr 
学习曲线/n 当/t 学习/v 算法/n 是/v 高/a 方差/n 时/n 如 9 
所示 此时 对于 训练 集 误差 而言 当 m 很 
小时 误差 很小 并且 由于 算法 能 很好 的 拟合 
训练 集 过拟合 随着 m 的 增加 误差 只有 少量 
增加 增加 很慢 对于 交叉 检验 误差 而言 当 m 
很 小时 算法 的 泛化 能力 非常 弱 误差 很大 
随着 m 的 增加 泛化 能力 稍有 提升 误差 会 
有所 减小 但 由于 学习 算法 过拟合 泛化 能力 有限 
故 交叉 检验 误差 不会 下降 太多 最后 稳定 在 
一个 较高 的 值 在 m 较大 时 训练/vn 集/q 
误差/n 和/c 交叉/n 检验/vn 误差/n 也/d 有/v 一定/d 的/uj 差距/n 
此时 训练 集 误差 较小 而 交叉 检验 集 误差 
较大 所以 在 高 方差 的 情况 下 增大 训练 
集 通常 是 有效 的 减少 过拟合 9 高/a 方差/n 
时的/nr 学习曲线/n 6.6/mx 调试 学习 算法 经过 了 上面 的 
分析 现在 我们 对 调试 学习 算法 的 策略 进行 
总结 Get more training examples   helps to fix high 
varianceNot good if you have high biasSmaller set of features 
  fixes high variance overfitting Not good if you have 
high biasTry adding additional features   fixes high bias because 
hypothesis is too simple make hypothesis more specific Add polynomial 
terms   fixes high bias p r o b l 
e m D e c r e a s i 
n g   λ   fixes high biasIncreases   λ 
  fixes high variance 对于 神经网络 而言 我们 需要 针对 
不同 的 问题 设计 不同 的 网络 结构 通常 从 
下面 两种 角度 考虑 选择 一个 较小 的 网络 较少 
的 隐藏 层 如 1层 和 较少 的 隐藏 单元 
适用于 变量 特征 量 较少 的 情况 可能 欠 拟合 
但 计算 代价 较小 选择 一个 较大 的 网络 更多 
的 隐藏 层 需要 我们 决定 具体 是 多少 层 
较好 适用于 变量 较多 的 情况 可能会 过拟合 需要 使用 
正则化 来 削弱 过拟合 计算 代价 更大 通常 而言 选择 
一层 隐藏 层 或许 是 比较 好 的 选择 当然 
在 应用 神经网路 时 也应 将 已有 数据集 划分 为 
训练 集 交叉 检验 集 和 测试 集 