机器学习 中 的 基本 数学知识 注 本文 的 代码 是 
使用 Python 3 写 的 机器学习 中 的 基本 数学知识 
线性代数 linear algebra 第一 公式 矩阵 的 操作 换位 transpose 
矩阵 乘法 矩阵 的 各种 乘积 内积 外积 元素 积 
element wise product / point wise product / Hadamard product 
加 低等 数学 几何 范数 norm 拉格朗日/i 乘子/n 法和/nr KKT/w 
条件/n 微分/n differential 表示 形式 法则 常见 导数 公式 统计学 
/ 概率论 信息论 香农 熵 Shannon Entropy 博弈论/n 不/d 知道/v 
放/v 到哪儿/i 机器学习/i 激活/a 函数/n 损失/n 函数/n 附录/v 希腊字母/nz 的/uj 
含义/n 和/c 发音/n 数学/n 符号/n 的/uj 含义/n 和/c 发音/n 参照/v 
线性代数/l linear algebra 第一 公式 \ f x = xw 
^ T + b \ 这是 在 机器 学习 中 
最 常见 的 公式 我 把 这个 称为 机器 学习 
的 第一 公式 实际上 就是 线性 分类 函数 linear classifier 
训练 分类器 的 目标 就是 求出 \ w b \ 
其中 \ x \ 是 一个 一 行矩阵 \ x 
_ 1 x _ 2 . . . x _ 
n \ \ w \ 是 一个 一 行矩阵 \ 
w _ 1 w _ 2 . . . w 
_ n \ \ x \ 和 \ w \ 
的 维度 相同 \ b \ 是 一个 数 \ 
xw ^ T = \ sum _ { i = 
1 } ^ n x _ iw _ i \ 
称为 点积 dot product 有时 我们 也 会 见到 这个 
公式 表示 为 类似 下面 的 样子 它们 的 基本 
含义 都是 一样 的 \ f x = w x 
+ b \ \ f x = w ^ T 
x + b \ \ f x = \ vec 
{ w } \ cdot \ vec { x } 
+ b \ 注 这里 \ w \ 表示 为 
一个 一维 数组 或者 向量 矢量 vector \ x _ 
1 x _ 2 . . . x _ n 
\ 注 一维 数组 在 数学 上 可以 理解 为 
向量 表示 多维空间 上 的 一个 点 注 由于 在 
线性代数 中 矩阵 乘法 \ ab \ ne ba \ 
所以 对于 表达式 \ w ^ Tx \ 严格地 说 
要把 矢量 向量 看做 一列 的 矩阵 而 不是 一行 
的 矩阵 才 符合 数学上 的 定义 注 表达式 \ 
\ vec { w } \ cdot \ vec { 
x } \ 和\/nr w x \ 是 正确 的 
因为 \ w \ 和\/nr x \ 是 矢量 这个 
符合 矢量 计算 的 定义 矩阵 的 操作 由于 这 
篇 文章 是 从 数学 的 角度 写 的 所以 
我们 先 关注 矩阵 的 操作 换位 transpose 矩阵 的 
换位 操作 将 矩阵 中的 数 按照 对角线 交换 数学公式 
\ w ^ T \ 代码 示例 # Matrix Transpose 
m = numpy . mat 1 2 3 4 print 
Matrix . Transpose print m . T Output Matrix . 
Transpose 1 3 2 4 矩阵 乘法 矩阵 相乘 的 
含义 如果 一 斤 苹果 10元 5斤 苹果 多少 元 
答案 是 \ 10 * 5 = 50 \ 如果 
一 斤 苹果 10元 一斤 梨 20元 5斤 苹果 2斤 
梨 一共 多少 元 答案 是 \ \ begin { 
bmatrix } 10 & 20 \ end { bmatrix } 
\ begin { bmatrix } 5 \ \ 2 \ 
end { bmatrix } = 10 \ times 5 + 
20 \ times 2 = 90 \ 我们 可以 看出 
矩阵 相乘 的 约束 乘数 1 的 列数 要和 乘数 
2 的 行数 相等 矩阵 乘法 不满足 交换律 \ m1 
\ cdot m2 \ ne m2 \ cdot m1 \ 
我们 再 看看 交换 乘数 后 计算 的 结果 \ 
\ begin { bmatrix } 10 \ \ 20 \ 
end { bmatrix } \ begin { bmatrix } 5 
& 2 \ end { bmatrix } \ \ = 
\ begin { bmatrix } 10 \ times 5 & 
10 \ times 2 \ \ 20 \ times 5 
& 20 \ times 2 \ end { bmatrix } 
\ \ = \ begin { bmatrix } 50 & 
20 \ \ 100 & 40 \ end { bmatrix 
} \ 比如 数 \ 20 \ 的 含义 是 
2斤 苹果 多少钱 举例说明 它们 的 不同 之处 \ m1 
= \ begin { bmatrix } 1 & 2 \ 
end { bmatrix } \ \ m2 = \ begin 
{ bmatrix } 10 \ \ 20 \ end { 
bmatrix } \ \ m1 \ cdot m2 \ 的 
计算 方法 是 \ m1 \ cdot m2 = \ 
begin { array } { | c | c | 
} \ text { } & \ begin { bmatrix 
} 10 \ \ 20 \ end { bmatrix } 
\ \ \ hline \ begin { bmatrix } 1 
& 2 \ end { bmatrix } & 1 * 
10 + 2 * 20 \ end { array } 
= \ begin { bmatrix } 50 \ end { 
bmatrix } \ \ m2 \ cdot m1 \ 的 
计算 方法 是 \ m2 \ cdot m1 = \ 
begin { array } { | c | c | 
c | } \ text { } & 1 & 
2 \ \ \ hline 10 & 10 * 1 
& 10 * 2 \ \ 20 & 20 * 
1 & 20 * 2 \ \ \ end { 
array } = \ begin { bmatrix } 10 & 
20 \ \ 20 & 40 \ end { bmatrix 
} \ 计算公式 矩阵 相乘 是 用 矩阵 1 的 
每 一行 和 矩阵 2 的 每 一列 的 点积 
得到 一个 矩阵 \ l * m \ 的 矩阵 
乘以 \ m * n \ 的 矩阵 形成 一个 
\ l * n \ 的 矩阵 \ \ begin 
{ array } \ \ x \ cdot y & 
= \ begin { bmatrix } x _ { 1 
} & \ cdots & x _ { n } 
\ \ \ end { bmatrix } \ begin { 
bmatrix } y _ { 1 } \ \ \ 
cdots \ \ y _ { n } \ end 
{ bmatrix } \ \ & = \ begin { 
bmatrix } \ sum _ { i = 1 } 
^ n x _ { i } y _ { 
i } \ end { bmatrix } \ end { 
array } \ \ \ begin { array } \ 
\ x \ cdot y & = \ begin { 
bmatrix } x _ { 1 } \ \ \ 
cdots \ \ x _ { m } \ end 
{ bmatrix } \ begin { bmatrix } y _ 
{ 1 } & \ cdots & y _ { 
n } \ \ \ end { bmatrix } \ 
\ & = \ begin { bmatrix } x _ 
{ 1 } y _ { 1 } & \ 
cdots & x _ { 1 } y _ { 
n } \ \ \ cdots & \ cdots & 
\ cdots \ \ x _ { m } y 
_ { 1 } & \ cdots & x _ 
{ m } y _ { n } \ end 
{ bmatrix } \ end { array } \ \ 
\ begin { array } \ \ x \ cdot 
y & = \ begin { bmatrix } x _ 
{ 11 } & \ cdots & x _ { 
1n } \ \ x _ { 21 } & 
\ cdots & x _ { 2n } \ \ 
\ cdots & \ cdots & \ cdots \ \ 
x _ { m1 } & \ cdots & x 
_ { mn } \ end { bmatrix } \ 
begin { bmatrix } y _ { 11 } & 
\ cdots & y _ { 1q } \ \ 
y _ { 21 } & \ cdots & y 
_ { 2q } \ \ \ cdots & \ 
cdots & \ cdots \ \ y _ { n1 
} & \ cdots & y _ { nq } 
\ end { bmatrix } \ \ & = \ 
begin { bmatrix } \ sum _ { i = 
1 } ^ n x _ { 1i } y 
_ { i1 } & \ cdots & \ sum 
_ { i = 1 } ^ n x _ 
{ 1i } y _ { iq } \ \ 
\ cdots & \ cdots & \ cdots \ \ 
\ sum _ { i = 1 } ^ n 
x _ { mi } y _ { i1 } 
& \ cdots & \ sum _ { i = 
1 } ^ n x _ { mi } y 
_ { iq } \ end { bmatrix } \ 
end { array } \ 代码 演示 # Matrix Multiplication 
print Matrix Multiplication a = numpy . mat 1 2 
b = numpy . mat 10 20 print a * 
b print a . T * b . T a 
= numpy . mat 1 2 3 4 b = 
numpy . mat 10 20 30 40 print a * 
b Output 50 10 20 20 40 70 100 150 
220 矩阵 的 各种 乘积 操作 数学 符号 PythonDemo 点积 
dot product $ a b $ a . dot b 
numpy . dot a b $ $ \ begin { 
array } \ \ AB & = 1 2 \ 
begin { pmatrix } 10 \ \ 20 \ end 
{ pmatrix } \ \ & = 1 * 10 
+ 2 * 20 \ \ & = 50 \ 
end { array } $ $ 内积 inner product $ 
a \ cdot b $ $ \ langle a b 
\ rangle $ numpy . inner a b $ $ 
a \ cdot b = a b ^ T $ 
$ 外积 outer product $ a \ otimes b $ 
numpy . outer a b $ $ \ begin { 
array } \ \ A \ otimes B & = 
\ begin { pmatrix } 1 \ \ 2 \ 
end { pmatrix } \ begin { pmatrix } 10 
& 20 \ end { pmatrix } \ \ & 
= \ begin { pmatrix } 1 * 10 & 
1 * 20 \ \ 2 * 10 & 2 
* 20 \ end { pmatrix } \ \ & 
= \ begin { pmatrix } 10 & 20 \ 
\ 20 & 40 \ end { pmatrix } \ 
end { array } $ $ 元素 积 element wise 
product point wise product Hadamard product $ a \ circ 
b $ $ a \ odot b $ numpy . 
multiply a b $ $ \ begin { array } 
\ \ A \ odot B & = \ begin 
{ pmatrix } 1 & 2 \ \ 3 & 
4 \ end { pmatrix } \ begin { pmatrix 
} 10 & 20 \ end { pmatrix } \ 
\ & = \ begin { pmatrix } 1 * 
10 & 2 * 20 \ \ 3 * 10 
& 4 * 20 \ end { pmatrix } \ 
\ & = \ begin { pmatrix } 10 & 
40 \ \ 30 & 80 \ end { pmatrix 
} \ end { array } $ $ 注 Python 
中 矩阵 数据 可以 表示 为 matrix 和 ndarray 两种 
类型 这 两种 类型 的 操作 非常 接近 但是 有 
细微 的 不同 ndarray * operation element wise product . 
matrix * operation dot product . numpy . multiply for 
ndarray element wise product . same . numpy . multiply 
for matrix element wise product . same . numpy . 
dot for ndarray inner product . 1 d array . 
numpy . dot for matrix dot product . shape determined 
by values . numpy . inner for ndarray inner product 
. 1 d array . numpy . inner for matrix 
inner product . shape determined by values . numpy . 
outer for ndarray outer product . same . numpy . 
outer for matrix outer product . same . 内积 英文 
inner product scalar product 矢量 的 降 维 运算 变成 
一个 数 矩阵 的 内积 是 每行 每 列 的 
内积 的 矩阵 \ x y = \ langle x 
y \ rangle = \ textstyle \ sum _ { 
i = 1 } ^ n x _ iy _ 
i \ x = numpy . array 1 2 y 
= numpy . array 10 20 print Array inner print 
numpy . inner x y Output Array inner 50 x 
= numpy . mat 1 2 3 4 y = 
numpy . mat 10 20 print Matrix inner print numpy 
. inner x y Output Matrix inner 50 110 外积 
矢量 的 升 维 运算 \ m \ 维 矢量 
和\/nr n \ 维 矢量 的 外积 是 \ m 
* n \ 为 矩阵 矩阵 的 并 集 运算 
\ a1 * a2 \ 维 矢量 和\/nr b1 * 
b2 \ 维 矩阵 的 外积 是 \ a1 * 
a2 * b1 * b2 \ 为 矩阵 \ \ 
begin { array } \ \ x \ otimes y 
& = \ begin { bmatrix } x _ 1 
& \ cdots & x _ { 1n } \ 
\ x _ 2 & \ cdots & x _ 
{ 2n } \ \ \ cdots & \ cdots 
& \ cdots \ \ x _ m & \ 
cdots & x _ { mn } \ end { 
bmatrix } \ begin { bmatrix } y _ 1 
& \ cdots & y _ { 1q } \ 
\ y _ 2 & \ cdots & y _ 
{ 2q } \ \ \ cdots & \ cdots 
& \ cdots \ \ y _ p & \ 
cdots & x _ { pq } \ end { 
bmatrix } \ \ & = \ begin { bmatrix 
} x _ 1y _ 1 & \ cdots & 
x _ 1y _ { 1q } & x _ 
1y _ { 2 } & \ cdots & x 
_ 1y _ { pq } \ \ \ cdots 
& \ cdots & \ cdots & \ cdots & 
\ cdots & \ cdots \ \ x _ { 
1n } y _ 1 & \ cdots & x 
_ { 1n } y _ { 1q } & 
x _ { 1n } y _ { 2 } 
& \ cdots & x _ { 1n } y 
_ { pq } \ \ x _ 2y _ 
1 & \ cdots & x _ 2y _ { 
1q } & x _ 2y _ { 2 } 
& \ cdots & x _ 2y _ { pq 
} \ \ \ cdots & \ cdots & \ 
cdots & \ cdots & \ cdots & \ cdots 
\ \ x _ { mn } y _ 1 
& \ cdots & x _ { mn } y 
_ { 1q } & x _ { mn } 
y _ { 2 } & \ cdots & x 
_ { mn } y _ { pq } \ 
end { bmatrix } \ end { array } \ 
x = numpy . array 1 3 y = numpy 
. array 10 20 print Array outer print numpy . 
outer x y Output Array outer 10 20 30 60 
x = numpy . mat 1 2 3 4 y 
= numpy . mat 10 20 print Matrix outer print 
numpy . outer x y Output Matrix outer 10 20 
20 40 30 60 40 80 注 有 没有 发现 
matrix outer 是 vector outer 的 并 集 元素 积 
element wise product / point wise product / Hadamard product 
计算公式 \ \ begin { array } \ \ x 
\ cdot y & = \ begin { bmatrix } 
x _ { 1 } & \ cdots & x 
_ { n } \ \ \ end { bmatrix 
} \ begin { bmatrix } y _ { 1 
} & \ cdots & y _ { n } 
\ end { bmatrix } \ \ & = \ 
begin { bmatrix } x _ { 1 } y 
_ { 1 } & \ cdots x _ ny 
_ n \ end { bmatrix } \ end { 
array } \ \ \ begin { array } \ 
\ x \ cdot y & = \ begin { 
bmatrix } x _ { 1 } & \ cdots 
& x _ { n } \ \ \ end 
{ bmatrix } \ begin { bmatrix } y _ 
{ 1 } \ \ \ cdots \ \ y 
_ { m } \ \ \ end { bmatrix 
} \ \ & = \ begin { bmatrix } 
x _ { 1 } y _ { 1 } 
& \ cdots & x _ { n } y 
_ { 1 } \ \ \ cdots & \ 
cdots & \ cdots \ \ x _ { 1 
} y _ { m } & \ cdots & 
x _ { n } y _ { m } 
\ end { bmatrix } \ end { array } 
\ \ \ begin { array } \ \ x 
\ cdot y & = \ begin { bmatrix } 
x _ { 11 } & \ cdots & x 
_ { 1n } \ \ \ cdots & \ 
cdots & \ cdots \ \ x _ { m1 
} & \ cdots & x _ { mn } 
\ end { bmatrix } \ begin { bmatrix } 
y _ { 11 } & \ cdots & y 
_ { 1n } \ \ \ cdots & \ 
cdots & \ cdots \ \ y _ { m1 
} & \ cdots & x _ { n } 
\ end { bmatrix } \ \ & = \ 
begin { bmatrix } x _ { 11 } y 
_ { 11 } & \ cdots & x _ 
{ 1n } y _ { 1n } \ \ 
\ cdots & \ cdots & \ cdots \ \ 
x _ { m1 } y _ { m1 } 
& \ cdots & x _ { mn } y 
_ { nn } \ end { bmatrix } \ 
end { array } \ x = numpy . array 
1 3 y = numpy . array 10 20 print 
Array element wise product print x * y Output Array 
element wise product 10 60 加 x = numpy . 
mat 1 2 3 4 y = numpy . mat 
10 20 30 40 print Matrix Add print x + 
y Output Matrix Add 11 22 33 44 低等 数学 
求 总和 公式 这个 大家 应该 都 知道 \ \ 
sum _ { i = 1 } ^ N x 
_ i = x _ 1 + x _ 2 
+ \ cdots + x _ n \ 求 总 
积 公式 \ \ prod _ { i = 1 
} ^ N x _ i = x _ 1 
\ times x _ 2 \ times \ cdots \ 
times x _ n \ 对数 对数 的 含义 求数 
的 长度 将 乘法 转变 成 加法 解决 下溢 出问题 
由于 太多 很小 的 数 相乘 造成 的 问题 数学 
表达 \ log x = \ log _ { 10 
} x \ \ \ log _ { 2 } 
x \ \ ln x \ 由于 不同 底 的 
对数 的 结果 是 等比 关系 所以 有时 底数 是 
谁 是 无所谓 的 等比 \ a \ 等比 于\/nr 
b \ 可 用于 算法 复杂度 计算 \ a ~ 
b \ \ a \ propto b \ 下 取整 
floor 和上/nr 取整 ceil \ \ text { floor } 
\ left \ lfloor x \ right \ rfloor \ 
\ \ text { ceil } \ left \ lceil 
x \ right \ rceil \ 几何 范数 norm L1 
范数 \ \ lVert w \ rVert _ 1 \ 
L1 范数 也 就是 各 项目 绝对值 的 和 \ 
\ lVert w \ rVert _ 1 = \ textstyle 
\ sum _ { i = 1 } ^ n 
| w _ i | \ L2 范数 \ \ 
lVert w \ rVert \ text { or } \ 
lVert w \ rVert _ 2 \ L2 范数 也 
就是 各 项目 平方和 的 平方根 \ \ lVert w 
\ rVert = \ sqrt { \ textstyle \ sum 
_ { i = 1 } ^ n w _ 
i ^ 2 } \ 拉格朗日/i 乘子/n 法和/nr KKT/w 条件/n 
如果/c 方程式/n \/i f x = wx + b \ 
有 不等式 约束条件 拉格朗日/i 乘子/n 法和/nr KKT/w 条件/n 提供/v 了/ul 
一种/m 方法/n 可以 计算 \ w b \ \ \ 
mathcal { L } w b \ alpha \ 关于/p 
拉格朗日/i 乘子/n 法和/nr KKT/w 条件/n 请看 深入 理解 拉格朗日 乘子 
法 Lagrange Multiplier 和 KKT 条件 微分 differential 表示 形式 
\ { f x } \ \ \ text { 
or partial differential in Leibniz notation } \ \ { 
\ partial f x \ over \ partial x } 
\ \ { dy \ over dx } \ \ 
\ text { or } \ \ { \ nabla 
f x \ over \ nabla x } \ text 
{ the gradient of f at x } \ 含义 
\ { df x \ over dx } = \ 
lim _ { h \ to 0 } \ frac 
{ f x + h f x } { h 
} \ \ where \ \ { d \ over 
dx } \ text { is an operation of f 
x } \ 数学 含义 是 在 \ x \ 
点上 \ f x \ 的 变化 除以 \ x 
\ 的 变化 数学 上 可以 认为 是 斜率 机器学习 
中指 的 是 梯度 计算 梯度 后 乘以 一个 比值 
步长 可以 得到 矫 正值 用于 反向 传播 矫正 权值 
partial differential 偏微分 表示 函数 在 某个 维 度上 的 
微分 这时 可将 其它 维度 看做 常量 法则 法则 微分 
偏微分 和 法则 sum rule $ f + g = 
f + g $ $ $ \ frac { \ 
partial u + v } { \ partial x } 
= \ frac { \ partial u } { \ 
partial x } + \ frac { \ partial v 
} { \ partial x } $ $ 积 法则 
product rule $ f \ cdot g = f \ 
cdot g + f \ cdot g $ $ $ 
{ \ partial u \ cdot v \ over \ 
partial x } = u \ cdot { \ partial 
v \ over \ partial x } + v \ 
cdot { \ partial u \ over \ partial x 
} $ $ 链式法则 chain rule of differentiation $ f 
g x = f g x g x $ $ 
$ { \ partial z \ over \ partial x 
} = { \ partial z \ over \ partial 
y } \ cdot { \ partial y \ over 
\ partial x } $ $ 常见 导数 公式 f 
x f x $ ax $ $ a $ $ 
x ^ n $ $ nx ^ { n 1 
} $ $ x + c $ $ 1 $ 
$ e ^ x $ $ e ^ x $ 
$ ln x $ $ \ frac { 1 } 
{ x } $ 统计学 / 概率论 贝叶斯 公式 Bayes 
formula \ p A | B = \ frac { 
p B | A p A } { p B 
} \ \ where \ \ p A \ text 
{ the probability of observing event A . } \ 
\ p B \ text { the probability of observing 
event B . } \ \ p A | B 
\ text { the probability of observing event A given 
that B is true . } \ \ p B 
| A \ text { the probability of observing event 
B given that A is true . } \ 比如 
在 判断 垃圾 邮件 的 算法 中 P A 所有 
邮件 中 垃圾 邮件 的 概率 P B 出现 某 
个 单词 的 概率 P B | A 垃圾 邮件 
中 出现 某 个 单词 的 概率 P A | 
B 出现 某 个 单词 的 邮件 是 垃圾 邮件 
的 概率 信息论 香农 熵 Shannon Entropy 熵 的 定义 
在 信息论 中 熵 是 接收 的 每条 消息 中 
包含 的 信息 的 平均 量 又 被 称为 信息熵 
信源 熵 平均 自 信息量 熵 定义 为 信息 的 
期望值 熵 实际 是 对 随机变量 的 比特 量 和顺 
次 发生 概率 相乘 再 总和 的 数学期望 熵 的 
单位 通常 为 比特 bit 或者 sh annon 基于 2 
但 也用 nat 基于 自然对数 Hart 基于 10 计量 取决于 
定义 用到 对数 的 底 熵 的 单位 不 重要 
因为 是 求 对数 所以 是 等比 的 不 理解 
这 句话 也 无所谓 熵值 是 一个 = 0 的 
值 如果 为 0 则 表明 结果 可以 准确 预测 
从 下面 的 公式 可以 看出 其 概率 为 1 
. 熵 的 特征 发生 概率 越小 的 信息 熵值 
越大 常识 的 熵 为 0 从 计算 损失 的 
角度 来说 熵值 越大 说明 损失 越大 期望值 在 概率论 
和 统计学 中 一个 离散性 随机变量 的 期望值 或 数学期望 
或 均值 亦 简称 期望 物理学 中 称为 期待值 是 
试验 中 每次 可能 结果 的 概率 乘以 其 结果 
的 总和 比如 掷骰子 其 点数 的 期望值 是 3.5 
\ E x = 1 * 1 / 6 + 
1 * 2 / 6 + 1 * 3 / 
6 + 1 * 4 / 6 + 1 * 
5 / 6 + 1 * 6 / 6 = 
3.5 \ 通俗 的 理解 信息熵 是 各个 值 的 
概率 * 值 的 长度 的 总和 数据集 的 信息 
熵 的 计算 公式 \ \ begin { alignat } 
{ 2 } H X & = E I X 
\ \ & = E lnP X \ \ & 
= \ sum \ limits _ { i = 1 
} ^ n P x _ i I x _ 
i \ \ & = \ sum \ limits _ 
{ i = 1 } ^ n P x _ 
i \ log P x _ i \ end { 
alignat } \ \ where \ \ \ qquad H 
X 数据 集合 X 的 信息 熵值 \ \ \ 
qquad E 求 期望值 \ \ \ qquad I 求 
信息 值 惊奇 值 \ \ \ qquad X 数据 
集合 X \ \ \ qquad x _ i 数据 
集合 X 的 标签 的 一个 枚举 值 \ \ 
\ qquad I x _ i x _ i 的 
资讯 量 information self . I x _ i = 
log P x _ i \ \ \ qquad P 
x _ i \ text { 发生 x _ i 
的 概率 x 的 机率 质量 函数 probability mass function 
} P x _ i = count x _ i 
/ len X . \ 熵 的 作用 计算 损失 
Loss function 用于 调整 梯度 递减 的 步长 本次 熵 
损失 比 上次 熵 损失 大 说明 步长 太大 了 
用于 决策树 熵 越大 说明 特征 feature 的 划分 数据 
能力 越强 博弈论 倾向 关系 preference relation 描述 了 玩家 
的 倾向 \ x \ succeq y \ 意味着 x 
至少 和y/nr 一样 好 不 知道 放 到哪儿 求 最大化 
参数 数学 表示 \ \ underset { c } { 
argmax } P c \ 解释 可以 用于 返回 一个 
可能性 对 大 的 分类 返回 当 P c 为 
最大值 时c的/nr 值 例如 \ c \ in \ { 
1 2 \ } \ \ P 1 = 0.9 
\ \ P 2 = 0.1 \ \ \ therefore 
\ \ \ underset { c } { argmax } 
P c = 1 \ 返回 最大值 数学 表示 \ 
\ underset { a \ in \ mathcal { A 
} } { max } P a \ 解释 在 
所有 \ a \ in \ mathcal { A } 
\ 的 计算 中 返回 最大值 \ P a \ 
约束条件 Subject to 数学 表示 \ y = 2x + 
1 \ text { s . t . } x 
0 \ 解释 当 约束条件 \ x 0 \ 成立 
时 有\/nr y = 2x + 1 \ 定 义上 
相等 数学 表示 \ A \ doteq B \ 解释 
A 的 定义 为 B 2 补数 2 s complement 
一种/m 使用/v 2/m 进制/v 表示/v 有符/nr 号数/n 的/uj 方法/n 第一位 
为 符号 位 如果 是 0 则 记 做 0 
如果 为 1 则 记 做 \ 2 ^ { 
n 1 } \ text { n is the size 
of the number } \ 例如 0010 为 2 1010 
为 6 机器学习 激活 函数 请看 我 的 另外 一个 
博文 神经 网络 学习 笔记 激活 函数 的 作用 定义 
和 微分 证明 损失 函数 请看 我 的 另外 一个 
博文 神经 网络 学习 笔记 损失/n 函数/n 的/uj 定义/n 和/c 
微分/n 证明/n 附录/v 希腊字母/nz 的/uj 含义/n 和/c 发音/n 大写/n 小写/n 
English/w 发音/n 中文/nz 含义/n 1/m Α/i α/i alphaa/w lf 阿尔法 
2 Β β betabet 贝塔 3 Γ γ gammaga m 
伽马 4 Δ δ deltadelt 德尔塔 δ delta value 偏 
差值 5 Ε ε epsilonep silon/w 伊普/nr 西龙/ns 6/m Ζ/i 
ζ/i zetazat/w 截塔/i 7/m Η/i η/i etaeit/w 艾塔/nr 8/m Θ/i 
θ/i thet/w θ/i it/w 西塔/nr 9/m Ι/i ι/i iotaiot/w 约塔/i 
10/m Κ/i κ/i kappakap/w 卡帕/nr 11/m ∧/i λ/i lambdalambd/w 兰布达/nr 
12/m Μ/i μ/i mumju/w 缪/nr 13/m Ν/i ν/i nunju/w 纽/ns 
14/m Ξ/i ξ/i xiksi/w 克西/ns ξ/i slack variable 松弛 变量 
15 Ο ο omicronomik ron 奥密克戎 16 ∏ π pipai 
派 π 圆周率 17 Ρ ρ rhorou 肉 18 ∑ 
σ sigma sigma 西格马 19 Τ τ tautau 套 20 
Υ υ upsilonjup silon 宇普西龙 21 Φ φ phifai 佛 
爱 22 Χ χ chiphai 凯 23 Ψ ψ psipsai 
普西 24 Ω ω omegao miga 欧米伽 松弛 变量 slack 
variable 在 SVM 中 为了 处理 异常 点 跑到 另一个 
分类 中的 点 设定 的 容忍 值 数学 符号 的 
含义 和 发音 大写 小写 English 发音 中文 含义 1 
\ \ partial \ partial 偏 分 偏 分 1 
\ \ infty \ infinity 无穷 无穷 参照 Bayes theorem 
希腊 字母表 配 读音 cs231n . github . io 矩阵 
乘法 的 本质 是 什么 如 有希望 介绍 的 数学 
概念 请 写到 评论 中 我 有空 会 加上 