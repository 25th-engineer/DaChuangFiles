之前 通过 各种 博客 视频 学习 CNN 总是 对 参数 
啊 原理 啊 什么 的 懵懵懂懂 这次 上课 终于 弄 
明白 了 O ∩ _ ∩ O ~ 上世纪 科学家 
们 发现 了 几个 视觉神经 特点 视神经 具有 局部 感受 
野 一整张 图 的 识别 由 多个 局部 识别 点 
构成 不同 神经元 对 不同 形状 有 识别 能力 且 
视神经 具有 叠加 能力 高层 复杂 的 图案 可以 由 
低层 简单 线条 组成 之后 人们 发现 经过 conclusional 的 
操作 可以 很好 反映 视神经 处理 计算 的 过程 典型 
的 是 1998年 LeCun 发明 的 LeNet 5 可以 极大 
地 提升 识别 效果 本文 主要 就 convolutional layer pooling 
layer 和 整体 CNN 结构 展开 一 Convolutional Layer 卷积 
层 1 原理 和 参数 可以 模拟 局部 感受 野 
的 性质 同上 一层 不是 全 连接 而是 一 小块 
区域 连接 这 一小块 就是 局部 感受 野 receptive field 
并且 通过 构造 特定 的 卷积 神经元 可以 模拟 不同 
神经元 对 不同 形状 刺激 不同 反应 的 性质 如下 
图 所示 一个 神经元 处理 一层 会 形成 一个 feature 
map 多层 叠加 层数 逐渐 加深 感受 野 kernel 或 
filter 的 尺寸 可以 看做 fh * fw 由于 感受 
野 本身 具有 尺寸 feature map 会 不断 缩小 为了 
处理 方便 使得 每层 大小 不变 于是 我们 每层 加值 
为 0 的 边 zero padding 保证 经过 处理 以后 
的 feature map 同前 一层 尺寸 一样 多层 之间 的 
卷积 运算 操作 相当于 和 原来 像素 对应 位置 做 
乘法 如 下左图 所示 加了/i 边后/nr 可以/c 保证/v 上下/f 层/q 
大小/b 一致/d 右图 表示 每层 之间 convolve 的 操作 如果 
不 加 zero padding 但 上图 所示 只是 简单 例子 
一般 扫描 的 是 三维 图像 RGB 就 不是 一个 
矩阵 而是 一个 立方体 我们 用 一个三维 块 去 扫描 
它 原理 同 上图 相同 有时 扫描 时 不是 顺序 
去 扫 而是 跳跃 着 扫描 每次 移动 2 3个 
像素 值 stride 但 并非 完全 分离 不会 造成 信息 
丢失 这样 形成 的 feature map 相较 于 原始 图片 
缩小 实现 信息 聚集 的 效果 就像 如下 灰度 图 
2d 中 所示 左边 只 提取 竖线 vertical filter 右边 
只 提取 横线 horizontal filter 可 看出 横梁 部分 变亮 
大量 不同 的 这样 的 filter 比如 可以 识别 边角 
折线 的 filter 的 叠加 可 形成 多张 feature maps 
下图 是 一个 3d 的 RGB 效果 每个 kernel filter 
可以 扫描 出 一张 feature map 多个 filter 可以 叠 
加出 很厚 的 feature maps 前 一层 filter 做 卷积 
可以 形成 后 一层 的 一个 像素点 如 下图 可以 
代表 i 行 j 列 k 深度 的 一个 输出 
像素 值 k 代表 第 k 个 filter w 代表 
filter 中的 值 x 代表 输入 b 是 偏 值 
2 TensorFlow 实现 以下 是 使用 TensorFlow 实现 的 代码 
主要 使用 conv2d 这个 函数 import numpy as np from 
sklearn . datasets import load _ sample _ images # 
Load sample images dataset = np . array load _ 
sample _ images . images dtype = np . float32 
# 一共 4 维 channel 表示 通 道数 RGB 是 
3 batch _ size height width channels = dataset . 
shape # Create 2 filters # 一般 感受 野 大小 
7 * 7 5 * 5 3 * 3 设置 
2个 kernel 输出 2层 feature map filters _ test = 
np . zeros shape = 7 7 channels 2 dtype 
= np . float32 # 第一 个 0 filter 的 
设定 7 * 7 矩阵 中 3 是 中间 filters 
_ test 3 0 = 1 # vertical line # 
第二个 1 filter 的 设定 filters _ test 3 1 
= 1 # horizontal line # a graph with input 
X plus a convolutional layer applying the 2 filters X 
= tf . placeholder tf . float32 shape = None 
height width channels # 虽然 输入 是 一个 四维 图像 
但是/c 由于/c batch/w _/i size/w 和/c channel/w 都/d 已经/d 固定/a 
所以 使用 conv2d # strides 设定 第一/m 个/q 和/c 第四/m 
个/q 都是/i 1/m 表示/v 不/d 可以/c 跳过/i batch/w _/i size/w 
和/c channel/w # 那/r 两个/m 2/m 表示/v 横/v 纵向/v 都/d 
缩减/v 2/m 相当于 整张 图片 缩减 为 原来 四分之一 做了 
75% 的 缩减 convolution = tf . nn . conv2d 
X filters strides = 1 2 2 1 padding = 
SAME with tf . Session as sess output = sess 
. run convolution feed _ dict = { X dataset 
} 下面 是 padding 的 值 SAME 和 VALID 的 
区别 filter 的 宽度 为 6 stride 为 5 SAME 
确保 所有 图像 信息 都被 convolve 添加 zero padding 而 
VALID 只 添加 包含在内 的 像素点 3 所耗/n 内存/n 计算/v 
相比/v 于/p 传统/n 的/uj 全/a 连接/v 层/q 卷积 层 只是 
部分 连接 节省 了 很多 内存 比如 一个 具有 5 
* 5 大小 filter 的 卷积 层 输出 200张 150 
* 100 大小 的 feature maps stride 取 1 即 
不 跳跃 padding 为 SAME 输入 是 150 * 100 
大小 的 RGB 图像 channel = 3 总共 的 参数 
个数 是 200 * 5 * 5 * 3 + 
1 = 15200 其中 + 1 是 bias 如果 输出 
采用 32 bits float 表示 np . float32 那么 每张 
图片 会 占据 200 * 150 * 100 * 32 
= 9600000bits 11 . 4MB 如果 一个 training batch 包含 
100张 图片 mini batch = 100 那么 这 一层 卷积 
层 就会 占据 1GB 的 RAM 可以 看出 训练 卷积 
神经 网络 是 非常 消耗 内存 的 但是 使用 时 
只用到 最后 一层 的 输出 即可 二 Pooling Layer 池化层/nr 
1 原理/n 和/c 参数/n 当/t 图片大小/n 很大/a 时/n 内存/n 消耗/n 
巨大/a 而 Pooling Layer 所 起 的 作用 是 浓缩 
效果 缓解 内存 压力 即 选取 一定 大 小区域 将该 
区域 用 一个 代表 元素 表示 具体 的 Pooling 有 
两种 取 平均值 mean 和取/nr 最大值 max 如下 图 所示 
是 一个 取 最大值 的 pooling layer kernel 大小 为 
2 * 2 stride 大小 取决于 kernel 大小 这里 是 
2 即 刚好 使得 所有 kernel 都不 重叠 的 值 
因而 实现 高效 的 信息 压缩 将 原始 图像 横纵 
压缩 一半 如右 图 所示 特征 基本 都 完全 保留 
了 下来 pooling 这个 操作 不 影响 channel 数 在 
feature map 上 也 一般 不做 操作 即 z 轴 
一般 不变 只 改变 横纵 大小 2 TensorFlow 实现 # 
Create a graph with input X plus a max pooling 
layer X = tf . placeholder tf . float32 shape 
= None height width channels # 选用 取 最大值 的 
max _ pool 方法 # 如果 是 取 平均值 这里 
是 mean _ pool # ksize 就是 kernel 大小 feature 
map 和 channel 都是 1 横向 纵向 是 2 max 
_ pool = tf . nn . max _ pool 
X ksize = 1 2 2 1 strides = 1 
2 2 1 padding = VALID with tf . Session 
as sess output = sess . run max _ pool 
feed _ dict = { X dataset } 三 整体 
CNN 框架 典型 CNN architecture 有名 的 CNN 架构 LeNet 
MISIT 上 1998 输入 32 * 32 在 28 * 
28 图像 上 加了 zero padding 第一层 kernel 用了 6个 
神经元 kernel 大小 5 * 5 stride 取 1 输出 
就是 28 * 28 第二层 做了 average pooling 2 * 
2 的 kernel stride 是 2 输出 就 变为 原来 
的 一半 不 改变 feature map 数目 第三层 放了 16个 
神经元 其他 同理 第五层 用了 120个 神经元 5 * 5 
的 kernel 对 5 * 5 的 输入 做 卷积 
没法 再 滑动 输出 为 1 * 1 F6 用 
120个 1 * 1 的 输出 全 连接 84个 神经元 
Out 全 连接 10个 神经元 对应 手写体 识别 输出 的 
10个 数字 激活 函数 前面 都用 的 tanh 是 传统 
CNN 中 常用 的 输出 层 用了 RBF 比较 特殊 
是 一个 计算 距离 的 方式 去 判断 和 目标 
输出 间 距离 做 lost AlexNet 2012 最早 应用于 竞赛 
中 近 10% 的 提高 了 准确度 输入 224 * 
224 的 彩色图像 C1 是个 很大 的 11 * 11 
的 filter stride = 4 最后 连做/nr 3层 convolution 最后 
输出 1000个 类 的 分类 结果 激活 函数 使用 ReLU 
这在 现今 很 流行 输出 层 用 的 softmaxAlexNet 使用 
了 一个 小 技巧 是 Local Response Normalization LRN 局部 
响应 归一化 这种 操作 可以 在 传统 输出 上加 一个 
bias 考虑到 近邻 的 一些 输出 影响 即 一个 输出 
旁边 有很 牛掰 的 输出 的话 它 的 输出 就会 
怂 了 收到 抑制 可以 看到 含 β 的 整个 
项 都在 分母 上 但 后来 发现 这个 技术 对 
分类器 的 提升 也 不是 很 明显 有的 就 没有 
用 GoogleLeNet 2014 大量 应用 Inception module 一个 输入 进来 
直接 分 四步 进行 处理 这 四步 处理 完 后 
深度 直接 进行 叠加 在 不同 的 尺度 上 对 
图片 进行 操作 大量 运用 1 * 1 的 convolution 
可以 灵活 控制 输出 维度 可以 降低 参数 数量 如右 
图 所示 输入 是 192 使用 了 9层 inception module 
如果 直接 用 3 * 3 5 * 5 参数 
可以 算 一下 之后 inception 参数 数目 是 非常 大 
的 深度 上 可以 调节 可以 指定 任意 数目 的 
feature map 通过 增加 深度 把 维度 减 下来 inception 
模块 6个 参数 刚好 对应 这 6个 convolution 上面 4个 
参数 对应 上面 4个 convolution 加入 max pool 不会 改变 
feature map 数目 如 480 = 128 + 192 + 
96 + 64 将 正确率 升高 到 95 96% 超过 
人类 分辨率 因为 image net 中 但是 狗 的 种类 
就 有 很多 人类 无法 完全 一一 分辨出 ReSNet 残差 
网络 2015 不再 直接 学习 一个 目标函数 输入 直接 跳过 
中间层 直 接连到 输 出上 要 学习 的 是 残差 
f x 输入 跳过 中间层 直接 加到 输 出上 好处 
是 深度 模型 路径 依赖 的 限制 即 gradient 向前 
传导 时要/nr 经过 所 有层 如果 中间 有层 死掉 了 
前面 的 层 就 无法 得到 训练 残差 网络 不断 
跳跃 即使 中间 有的 层 已经 死掉 信息 仍旧 能够 
有效 流动 使得 训练 信号 有效 往回 传导 