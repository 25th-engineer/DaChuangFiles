机器学习 数据挖掘 人工智能 统计模型 这么 多 概念 有何 差异 在 
各种各样 的 数据 科学 论坛 上 这样 一个 问题 经常 
被 问到 机器 学习 和 统计 模型 的 差别 是 
什么 这 确实 是 一个 难以 回答 的 问题 考虑到 
机器学习 和 统计模型 解决 问题 的 相似性 两者 的 区别 
似乎 仅仅 在于 数据量 和 模型 建立者 的 不同 这里/r 
有/v 一张/m 覆盖/v 机器学习/i 和/c 统计/v 模型/n 的/uj 数据/n 科学/n 
维恩/nr 图/n 在 这篇文章 中 我 将尽 最大 的 努力 
来 展示 机器学习 和 统计 模型 的 区别 同时 也 
欢迎 业界 有 经验 的 朋友 对 本文 进行 补充 
在 我 开始 之前 让 我们 先 明确 使用 这些 
工具 背后 的 目标 无论 采用 哪种 工具 去 分析 
问题 最终 的 目标 都 是从 数据 获得 知识 两种 
方法 都 旨在 通过 分析 数据 的 产生 机制 挖掘 
背后 隐藏 的 信息 两种 方法 的 分析 目标 是 
相同 的 现在 让 我们 详细 的 探究 一下 其 
定义 及 差异 定义 机器学习 一种 不 依赖 于 规则 
设计 的 数据 学习 算法 统计模型 以 数学 方程 形式 
表现 变量 之间 关系 的 程式 化 表达 对于 喜欢 
从 实际 应用 中 了解 概念 的 人 上述 表达 
也许 并不 明确 让 我们 看 一个 商务 的 案例 
商业 案例 让 我们 用 麦肯锡 发布 的 一个 有趣 
案例 来 区分 两个 算法 案例 分析 理解 电信公司 一段 
时间 内 客户 的 流失 水平 可获得 数据 两个 驱动 
A & B 麦肯锡 接下来 的 展示 足够 让 人 
兴奋 盯住 下图 来 理解 一下 统计模型 和 机器学习 算法 
的 差别 从上 图中 你 观察到 了 什么 统计模型 在 
分类 问题 中 得到 一个 简单 的 分类 线 一条 
非线性 的 边界线 区分 了 高风险 人群 和低/nr 风险 人群 
但当 我们 看到 通过 机器学习 产生 的 颜色 时 我们 
发现 统计模型 似乎 没有 办法 和 机器学习 算法 进行 比较 
机器 学习 的 方法 获得 了 任何 边界 都 无法 
详细 表征 的 信息 这 就是 机器学习 可以为 你 做 
的 机器学习 还被 应用在 YouTube 和 Google 的 引擎 推荐 
上 机器学习 通过 瞬间 分析 大量 的 观测 样本 给出 
近乎 完美 的 推荐 建议 即使 只 采用 一个 16 
G 内存 的 笔记本 我 每天 处理 数 十万行 的 
数千 个 参数 的 模型 也 不会 超过 30 分钟 
然而 一个 统计模型 需要 在 一台 超级计算机 跑 一百万年 来来 
观察 数千个 参数 机器 学习 和 统计 模型 的 差异 
在给 出了 两种 模型 在 输出 上 的 差异 后 
让 我们 更 深入 的 了解 两种 范式 的 差异 
虽然 它们 所做 的 工作 类似 1 所属 的 学派 
2 产生 时间 3 基于 的 假设 4 处理 数据 
的 类型 5 操作 和 对象 的 术语 6 使用 
的 技术 7 预测/vn 效果/n 和/c 人力/n 投入/v 以/p 上/f 
提到/v 的/uj 方面/n 都/d 能从/i 每种/r 程度/n 上/f 区分/n 机器学习/i 
和/c 统计模型/i 但 并 不能 给出 机器学习 和 统计 模型 
的 明确 界限 分属 不同 的 学派 机器学习 计算机科学 和 
人工智能 的 一个 分支 通过 数据 学习 构建 分析 系统 
不依赖 明确 的 构建 规则 统计模型 数学 的 分支 用以 
发现 变量 之间 相关 关系 从而 预测 输出 诞生 年代 
不同 统计模型 的 历史 已经 有 几个 世纪 之久 但是 
机器学习 却是 最近 才 发展 起来 的 二十世纪 90 年代 
稳定 的 数字化 和 廉价 的 计算 使得 数据 科学家 
停止 建立 完整 的 模型 而 使用 计算机 进行 模型 
建立 这 催生 了 机器 学习 的 发展 随着 数据 
规模 和 复杂 程度 的 不断 提升 机器学习 不断 展现 
出 巨大 的 发展 潜力 假设 程度 差异 统计模型 基于 
一 系列 的 假设 例如 线性 回归模型 假设 1 自变量 
和 因变量 线性相关 2 同 方差 3 波动 均值 为 
0 4 观测 样本 相互 独立 5 波动 服从 正态分布 
Logistics 回归 同样 拥有 很多 的 假设 即使 是 非线性 
回归 也 要 遵守 一个 连续 的 分割 边界 的 
假设 然而 机器学习 却从 这些 假设 中 脱身 出来 机器学习 
最大 的 好处 在于 没有 连续性 分割 边界 的 限制 
同样 我们 也 并不 需要 假设 自变量 或因 变量 的 
分布 数据 区别 机器学习 应用 广泛 在线 学习 工具 可 
飞速 处理 数据 这些 机器学习 工具 可 学习 数以亿计 的 
观测 样本 预测 和 学习 同步进行 一些/m 算/v 法如/i 随机/d 
森林/n 和/c 梯度/n 助推/vn 在/p 处理/v 大/a 数据/n 时/n 速度/n 
很快/d 机器学习 处理 数据 的 广度 和 深度 很大 但 
统计模型 一般 应用 在 较小 的 数据 量 和 较窄 
的 数据 属性 上 命名 公约 下面 一些 命名 几乎 
指 相同 的 东西 公式 虽然 统计模型 和 机器 学习 
的 最终 目标 是 相似 的 但 其 公式化 的 
结构 却 非常 不同 在 统计 模型 中 我们 试图 
估计 f 函数 通过 因变量 Y = f 自变量 扰动 
函数 机器学习 放弃 采用 函数 f 的 形式 简化 为 
输出 Y 输入 X 它 试图 找到 n 维 变量 
X 的 袋子 在 袋子 间 Y 的 取值 明显 
不同 预测 效果 和 人力 投入 自然 在 事情 发生 
前 并不 给出 任何 假设 一个 预测模型 中 越少 的 
假设 越高 的 预测 效率 机器学习 命名 的 内在 含义 
为 减少 人力 投入 机器学习 通过 反复 迭代 学习 发现 
隐藏 在 数据 中 的 科学 由于 机器学习 作用 在 
真实 的 数据 上 并不 依赖于 假设 预测 效果 是 
非常 好 的 统计模型 是 数学 的 加强 依赖于 参数估计 
它 要求 模型 的 建立者 提前 知道 或 了解 变量 
之间 的 关系 结束语 虽然 机器学习 和 统计模型 看 起来 
为 预测 模型 的 不同 分支 但 它们 近乎 相同 
通过 数十年 的 发展 两种 模型 的 差异性 越来越 小 
模型 之间 相互 渗透 相互 学习 使得 未来 两种 模型 
的 界限 更加 模糊 http / / www . cda 
. cn / view / 19060 . html 