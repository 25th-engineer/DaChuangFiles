Spark 机器学习 库 现 支持 两种 接口 的 API RDD 
based 和 DataFrame based Spark 官方 网站 上 说 RDD 
based APIs 在 2.0 后 进入 维护 模式 主要 的 
机器学习 API 是 spark ml 包 中的 DataFrame based API 
并 将在 3.0 后 完全 移除 RDD based API 在 
学习 了 两周 Spark MLlib 后 准备 转向 DataFrame based 
接口 由于 现有 的 文档 资料 均 是 RDD based 
接口 于是 便去 看了 看 Spark MLlib 的 源码 DataFrame 
based API 包含 在 org . apache . spark . 
ml 包中/nr 其中 主要 的 类 结构 如下 咱 先看 
一个 线性 回归 的 例子 examples / ml / L 
i n e a r R e g r e 
s s i o n E x a m p 
l e . scala 其 首先 定义 了 一个 LinearRegression 
的 对象 val lir = new LinearRegression . setFeaturesCol features 
. setLabelCol label . setRegParam params . regParam . s 
e t E l a s t i c N 
e t P a r a m params . elasticNetParam 
. setMaxIter params . maxIter . setTol params . tol 
然后 调用 fit 方法 训练 数据 得到 一个 训 练好 
的 模型 lirModel 它 是 一个 L i n e 
a r R e g r e s s i 
o n M o d e l 类 的 对象 
val lirModel = lir . fit training 现在 我们 大概 
可以 理清 MLlib 机器 学习 的 流程 和 很多 单机 
机器学习 库 一样 先 定义 一个 模型 并 设置 好 
参数 然后 训练 数据 最后 返回 一个 训练 好了 的 
模型 我们 现在 在 源码 中去 查看 LinearRegression 和Li/nr n 
e a r R e g r e s s 
i o n M o d e l 其 类 
的 依赖 关系 如下 LinearRegression 是 一个 Predictor L i 
n e a r R e g r e s 
s i o n M o d e l 是 
一个 Model 那么 Predictor 是 学习 算法 Model 是 训练 
得到 的 模型 除此之外 还有 一类 继承 自 Params 的 
类 这 是 一个 表示 参数 的 类 Predictor 和 
Model 共享 一套 参数 现在 用 Spark MLlib 来 完成 
第一 个 机器学习 例子 数据 是 我 之前 放在 txt 
文件 里 的 回归 数据 一共 550 多万条 共 13列 
第一列 是 Label 后面 是 Features 分别 演示 两种 接口 
先 用旧 的 接口 1 . 读取 原始数据 scala import 
org . apache . spark . mllib . linalg . 
_ import org . apache . spark . mllib . 
linalg . _ scala import org . apache . spark 
. mllib . regression . _ import org . apache 
. spark . mllib . regression . _ scala val 
raw _ data = sc . textFile data / my 
/ y _ x . txt raw _ data org 
. apache . spark . rdd . RDD String = 
data / my / y _ x . txt MapPartitionsRDD 
1 at textFile at console 302 . 转换 格式 RDD 
based 接口 以 LabeledPoint 为 输入 数据 的 格式 scala 
val data = raw _ data . map { line 
= | val arr = line . split . map 
_ . toDouble | val label = arr . head 
| val features = Vectors . dense arr . tail 
| LabeledPoint label features | } data org . apache 
. spark . rdd . RDD org . apache . 
spark . mllib . regression . LabeledPoint = MapPartitionsRDD 2 
at map at console 323 . 划分 train test 数据集 
scala val splits = data . randomSplit Array 0.8 0.2 
splits Array org . apache . spark . rdd . 
RDD org . apache . spark . mllib . regression 
. LabeledPoint = Array MapPartitionsRDD 3 at randomSplit at console 
34 MapPartitionsRDD 4 at randomSplit at console 34 scala val 
train _ set = splits 0 . cache train _ 
set org . apache . spark . rdd . RDD 
org . apache . spark . mllib . regression . 
LabeledPoint = MapPartitionsRDD 3 at randomSplit at console 34 scala 
val test _ set = splits 1 . cache test 
_ set org . apache . spark . rdd . 
RDD org . apache . spark . mllib . regression 
. LabeledPoint = MapPartitionsRDD 4 at randomSplit at console 344 
. 使用 L i n e a r R e 
g r e s s i o n W i 
t h G D . train 训练 模型 scala val 
lr = L i n e a r R e 
g r e s s i o n W i 
t h G D . train train _ set 100 
0.0001 warning there was one deprecation warning re run with 
deprecation for details 16 / 08/26 09 20 44 WARN 
Executor 1 block locks were not released by TID = 
0 rdd _ 3 _ 0 lr org . apache 
. spark . mllib . regression . L i n 
e a r R e g r e s s 
i o n M o d e l = org 
. apache . spark . mllib . regression . L 
i n e a r R e g r e 
s s i o n M o d e l 
intercept = 0.0 numFeatures = 125 . 模型 评估 scala 
val pred _ labels = test _ set . map 
lp = lp . label lr . predict lp . 
features pred _ labels org . apache . spark . 
rdd . RDD Double Double = MapPartitionsRDD 17 at map 
at console 42 scala val mse = pred _ labels 
. map { case p v = math . pow 
p v 2 } . mean mse Double = 0 
. 0 5 1 0 4 1 5 0 7 
3 5 9 1 0 0 7 4 再用 新的 
接口 1 . 读取 原始数据 scala import org . apache 
. spark . ml . linalg . _ import org 
. apache . spark . ml . linalg . _ 
scala import org . apache . spark . ml . 
regression . _ import org . apache . spark . 
ml . regression . _ scala import org . apache 
. spark . sql . _ import org . apache 
. spark . sql . _ scala val raw _ 
data = spark . read . text data / my 
/ y _ x . txt raw _ data org 
. apache . spark . sql . DataFrame = value 
string 2 . 转换 数据 scala val data = raw 
_ data . rdd . map { case Row line 
String = | val arr = line . split . 
map _ . toDouble | val label = arr . 
head | val features = Vectors . dense arr . 
tail | label features | } data org . apache 
. spark . rdd . RDD Double org . apache 
. spark . ml . linalg . Vector = MapPartitionsRDD 
4 at map at console 343 . 划分 数据集 scala 
val splits = data . randomSplit Array 0.8 0.2 splits 
Array org . apache . spark . rdd . RDD 
Double org . apache . spark . ml . linalg 
. Vector = Array MapPartitionsRDD 5 at randomSplit at console 
36 MapPartitionsRDD 6 at randomSplit at console 36 scala val 
train _ set = splits 0 . toDS . cache 
train _ set org . apache . spark . sql 
. Dataset Double org . apache . spark . ml 
. linalg . Vector = _ 1 double _ 2 
vector scala val test _ set = splits 1 . 
toDS . cache test _ set org . apache . 
spark . sql . Dataset Double org . apache . 
spark . ml . linalg . Vector = _ 1 
double _ 2 vector 4 . 创建 LinearRegression 对象 并 
设置 模型 参数 这里 设置 类 LabelCol 和 FeaturesCol 列 
默认 为 label 和 features 而 我们 的 数据 是 
_ 1 和 _ 2 scala val lir = new 
LinearRegression lir org . apache . spark . ml . 
regression . LinearRegression = linReg _ c4e70a01bcd3 scala lir . 
setFeaturesCol _ 2 res0 org . apache . spark . 
ml . regression . LinearRegression = linReg _ c4e70a01bcd3 scala 
lir . setLabelCol _ 1 res1 org . apache . 
spark . ml . regression . LinearRegression = linReg _ 
c4e70a01bcd35 . 训练 模型 val model = lir . fit 
train _ set 16 / 08/26 09 45 16 WARN 
Executor 1 block locks were not released by TID = 
0 rdd _ 9 _ 0 16 / 08/26 09 
45 16 WARN W e i g h t e 
d L e a s t q u a r 
e s regParam is zero which might cause numerical instability 
and overfitting . model org . apache . spark . 
ml . regression . L i n e a r 
R e g r e s s i o n 
M o d e l = linReg _ c4e70a01bcd36 . 
模型 评估 scala val res = model . transform test 
_ set res org . apache . spark . sql 
. DataFrame = _ 1 double _ 2 vector . 
. . 1 more field scala import org . apache 
. spark . ml . evaluation . _ import org 
. apache . spark . ml . evaluation . _ 
scala val eva = new R e g r e 
s s i o n E v a l u 
a t o r eva org . apache . spark 
. ml . evaluation . R e g r e 
s s i o n E v a l u 
a t o r = regEval _ 8fc6cce63aa9 scala eva 
. setLabelCol _ 1 res6 eva . type = regEval 
_ 8fc6cce63aa9 scala eva . setMetricName mse res7 eva . 
type = regEval _ 8fc6cce63aa9 scala eva . evaluate res 
res8 Double = 0 . 0 2 7 9 3 
3 6 5 3 5 3 3 0 8 8 
6 6 6 