上手 机器学习 从 搞懂 这 十大 经典 算法 开始 翻译 
| AI 科技 大本营 rgznai100 参与 | 林椿眄/nr 编辑 | 
波波 Donna 在 机器学习 领域 没有 免费 的 午餐 是 
一个 不变 的 定理 简而言之 没有 一种 算法 是 完美 
的 可以 作为 任何 问题 的 最佳 解决方案 认清 这 
一点 对于 解决 监督 学习 问题 如 预测 建模 问题 
尤其 重要 我们 不能 总 说 神经 网络 就是 比 
决策树 好 反之亦然 影响 算法 性能 的 因素 有 很多 
比如 数据集 的 大小 和 结构 因此 对于 自己 的 
问题 要 尝试 多种 不同 的 算法 并 使用 测试 
数据集 来 评估 各个 算法 的 性能 以 选出 效果 
最优 的 那一个 当然 前面 所 尝试 的 算法 必须 
要 适合 自己 的 问题 这也 正是 你 要 选对 
正确 的 机器 学习 任务 的 地方 比如 需要 打 
扫房子 的 时候 你 会 使用 真空 吸尘器 扫帚 或 
拖把 但 绝不 应该 用 铲子 在 屋内 挖坑 ▌ 
重要 的 原则 话虽如此 但 所有 用于 预测 建模 的 
有 监督 机器学习 算法 却 有一个 共同 的 原则 机器学习 
算法 的 本质 是 找到 一个 目标函数 f 使其 成为 
输入 变量 X 到 输出 变量 Y 之间 的 最佳 
映射 Y = f X 这是 最 常见 的 学习 
任务 给定 任意 新的 输入 变量 X 我们 就 能 
预测 出 输出 变量 Y 的 值 因为 我们 不 
知道 目标函数 f 的 形式 或 样子 所以 才要 机器 
去 把 它 找出来 不然的话 我们 就 可以 直接 用 
目标函数 来 进行 预测 了 而非 还要 用 机器学习 算法 
来 学习 数据 了 最 常见 的 机器 学习类型 就是 
找到 最佳 映射 Y = f X 并 以此 来 
预测 新 X 所 对应 的 Y 值 这一 过程 
被 称为 预测 建模 或 预测 分析 目标 是 尽可能 
到 出 最为 准确 的 预测 对于 渴望 理解 机器学习 
基本 概念 的 各位 新手 我们 特地 整理 出 数据 
科学家 最 常用 的 十大 机器学习 算法 便于 大家 快速 
上手 ▌   1 线性 回归 线性 回归 可能 是 
统计学 和 机器 学习 中 最为 知名 最 易于 理解 
的 一个 算法 预测 建模 主要 关注 的 是 如何 
最小化 模型 的 误差 或 是 如何 在 一个 可 
解释性 代价 的 基础 上 做出 最 为 准确 的 
预测 我们 将 借用 重用 和 窃取 包括 统计学 在内 
的 多个 不同 领域 的 算法 并将 其 用于 这些 
目的 线性 回归 所 表示 的 是 描述 一条 直线 
的 方程 通过 输入 变量 的 特定 权重 系数 B 
来 找出 输入 变量 x 和 输出 变量 y 之间 
最 适合 的 映射 关系 线性 回归 例如 y = 
B0 + B1 * x 给定 输入 x 我们 可以 
预测 出 y 的 值 线性 回归 学习 算法 的 
目标 是 找到 系数 B0 和 B1 的 值 找出 
数据 的 线性 回归模型 有 多种 不同 的 技巧 例如/v 
将/d 线性代数/l 解/v 用于/v 普通/nz 最/d 小二/nr 乘法/n 和/c 梯度/n 
下降/v 优化/vn 问题/n 线性 回归 业已 存在 200 多年 并已 
被 广泛 研究 过 使用 该 算法 的 一些 窍门 
是 尽可能 地 去除 非常 相似 的 相关 变量 以及 
数据 中 的 噪声 这 是 一个 快速 简单 而又 
好用 的 算法 ▌   2 逻辑 回归 逻辑 回归 
是 机器学习 借自 统计 领域 的 另一 项 技术 用于 
解决 二元 分类 问题 有 两个 类 值 的 问题 
逻辑 回归 就像 线性 回归 因为 它 的 目标 是 
找出 每个 输入 变量 的 加权 系 数值 与 线性 
回归 不同 的 是 逻辑 回归 预测 输出 值 的 
函数 是非 线性 的 也 被 称为 逻辑 函数 逻辑 
回归 的 函数 图像 看起来 是 一个 大 的 形 
并将 任何 值 转换 至 0 到 1 的 区间 
这种 形式 非常 有用 因为 我们 可以 用 一个 规则 
把 逻辑 函数 的 值 转化成 0 和1/nr 例如 如果 
函数值 小于 0.5 则 输出 1 从而 预测 类别 逻辑 
回归 基于 模型 学习 的 方式 逻辑 回归 的 输出 
值 也 可以 用来 预测 给定 数据 实例 属于 类别 
0 和 类别 1 的 概率 当 你 的 预测 
需要 更多 依据 时 这 一点 会 非常 有用 跟 
线性 回归 一样 当 你 剔除 与 输出 变量 无关 
或 与之 除 非常 相似 相关 的 属性 后 逻辑 
回归 的 效果 会 更好 对于 二元 分类 问题 它 
是 一个 易于 上手 快速 而又 有效 的 模型 ▌ 
  3 线性 判别分析 一般来说 逻辑 回归 仅限于 二元 分类 
问题 但 如果 分类 类别 超过 两个 线性 判别分析 就 
成为 你 首选 的 线性 分类 算法 线性 判别分析 的 
表达式 非常简单 它 由 数据 的 统计 属性 组成 并 
计算 每个 类别 的 属性值 对于 单个 输入 变量 它 
包括 每个 类别 的 平均值 所有 类别 的 方差 线性 
判别分析 线性 判别分析 通过 计算 每个 类别 的 差别 值 
并对 拥有 最大值 的 类别 进行 预测 该 方法 假定 
数据 服从 高斯分布 钟形 曲线 因此 预测 前 从 数据 
中 移除 异常值 会 是 一个 很好 的 习惯 对于 
分类 预测 问题 来说 它 是 一个 简单 而又 强大 
的 方法 ▌   4 分类 和 回归 树 决策树 
是 用于 预测 建模 的 一种 重要 机器学习 算法 决策树 
模型 的 表现 形式 为 二叉树 也 就是 来自 算法 
和 数据 结构 方面 的 二叉树 没有 什么 特别 树上 
每个 节点 代表 一个 输入 变量 x 与 一个 基于 
该 变量 的 分离点 假定 这个 变量 是 数字 决策 
树叶 节点 包含 了 用于 预测 的 输出 变量 y 
预测 是 通过 遍历 树 的 分离 点 开始 直到 
抵达 每 一个 叶 节点 并 输出 该 叶 节点 
的 分类 值 决策树 算法 学习 起来 很快 预测 速度 
也 很快 决策树/n 对于/p 各种各样/l 的/uj 问题/n 都能/nr 做出/v 准确/a 
的/uj 预测/vn 并且 无需 对 数据 做 任何 特殊 的 
预处理 ▌   5 朴素 贝叶斯 朴素 贝叶斯 是 一种 
简单 而又 强大 的 预测 建模 算法 该 模型 由 
两种 概率 组成 它们 都 能从 训练 数据 中 直接 
计算出来 1 每个 类别 的 概率 2 对于 给定 的 
x 值 每个 类别 的 条件 概率 一旦 计算出来 概率模型 
就 可以 用于 使用 贝叶 斯定理 对 新的 数据 进行 
预测 当 你 的 数据 是 实值 时 通常会 假定 
一个 高斯分布 钟形 曲线 这样 你 就 很容易 计算 出 
这些 数据 的 概率 朴素 贝叶斯 朴素 贝叶斯 假定 每个 
输入 变量 都是 独立 所以 被 称为 朴素 的 这 
是 一个 强 假设 对 真实 数据 而言 有点 不切实际 
但该 方法 在 大 范围 的 复杂 问题 上 非常 
有效 ▌   6 K 最 近邻 算法 K 最 
近邻 算法 是 一种 非常 简单 和 有效 它 的 
模型 所 表示 是 整个 训练 数据集 看上去 很 简单 
对吧 对于 给定 的 训练 数据 通过 搜索 整个 数据 
集中 K 个 最 相似 的 实例 邻居 汇总 这 
K 个 实例 的 输出 变量 可以 预测 新的 数据 
点 对于 回归 问题 它 可能 是 输出 变量 的 
平均值 对于 分类 问题 它 可能 是 模式 或 最 
常见 的 类别 值 使用 K 最 近邻 算法 的 
诀窍 是 在于 如何 确定 数据 实例 之间 的 相似性 
最 简单 的 方法 如果 你 的 属性 在 欧几里德 
距离 上 尺度 相同 例如 均以 英寸 为 单位 那么 
基于 每个 输入 变量 之间 的 差异 你 就 可以 
直接 计算 其 数值 来 确定 相似性 K 最 近邻 
算法 可能 需要 大量 的 内存 或 存储空间 来 储存 
所有 数据 但 只有 在 预测 时 才会 执行 计算 
或 学习 你 也 可以 随时 更新 和 管理 你 
的 训练 实例 以 保持 预测 的 准确性 距离 或 
紧密度 的 概念 在 非常 高的/nr 维度 大量 的 输入 
变量 中 可能 会 失效 因为 输入 变量 的 数量 
对于 算法 性能 有着 很大 的 负面 影响 这 就是 
维度 灾难 这就 要求 你 只 使用 那些 与 预测 
输出 变量 最 相关 的 输入 变量 ▌   7 
学习 向量量化 K 最 近邻 算法 的 一个 缺点 是 
你 需要 使用 整个 训练 数据集 而 作为 人工神经网络 学习 
向量量化 算法 简称 LVQ 允许 你 选择 训练 实例 的 
数量 并能 准确 地 学习 这些 实例 所 应有 的 
特征 学习 向量量化 学习 向量量化 算法 所 表示 的 是 
码本 向量 的 集合 这些 向量 在 初始化 的 时候 
随机 选择 出来 并在 学习 算法 的 多次 迭代 中 
优化 成 最能 概括 训练 数据集 的 集合 在 学习 
完成 后 码本 向量 可以 像 K 最 近邻 算法 
一样 进行 预测 通过 计算 每个 码本 向量 和新/nr 数据 
实例 之间 的 距离 来 找到 最 相似 的 邻居 
最佳 匹配 码本 向量 然后 返回 最佳 匹配 单元 的 
类别 值 或 在 回归 情况下 的 实际 值 作为 
预测 如果 能 重新 调整 数据 使其 处于 相同 的 
区间 如 0 到 1 之间 则 可以 获得 最佳 
的 预测 结果 如果 K 最 近邻 算法 在 你 
的 数据 集上 已经 给 出了 很好 的 预测 结果 
那么 可以 尝试 用 学习 向量量化 算法 来 减少 整个 
训练 数据集 的 内存 存储 需求 ▌   8 支持 
向量 机 支持 向量 机 可能 是 最 受欢迎 讨论 
最为 广泛 的 机器学习 算法 之一 超平面 是 输入 变量 
空间 内 的 一条 分割线 在 支持 向量 机中 超平面 
可以 通过 类别 0类 或 1类 最佳 分割 输入 变量 
空间 在 二维 空间 内 超平面 可被 视为 一条线 我们 
假设 所有 的 输入 点 都 可以 被 该线 完全 
分开 支持 向量 机 的 目标 是 找到 一个 分离系数 
让 一个 超平面 能够 对 不同 类别 的 数据 进行 
最佳 分割 支持 向量 机 超平面 与 最近 的 数据 
点 之间 的 距离 被 称为 边距 在 分离 两个 
类 上 具有 最大 边距 的 超平面 被 称为 最佳 
超平面 超平面 的 确定 只跟 这些 点 及 分类器 的 
构造 有关 这些 点 被 称为 支持 向量 它们 支持 
并 定义 超平面 在 实践 中 可以 使用 优化 算法 
来 找到 能够 最大化 边距 的 系数 支持 向量 机 
可能 是 最为 强大 的 开箱 即用 分类器 之一 值得 
你 尝试 ▌   9 bagging 算法 和 随机 森林 
随机 森林 是 最 流行 最 强大 的 机器学习 算法 
之一 它 是 一种 被 称为 Bootstrap Aggregation 或 Bagging 
的 机器学习 集成 算法 Bootstrap 是 一种 从 数据 样本 
中 估算 数量 的 强大 统计 方法 换句话说 你 需要 
抽取 大量 的 数据 样本 计算 平均值 然后再 计算 所有 
均值 的 平均 以便 更好 地 估计 整体 样本 的 
真实 平均值 bagging 算法 也 使用 相同 的 方式 但 
用于 估计 整个 统计模型 的 最 常见 方法 是 决策树 
训练 数据 中 的 多个 样本 将被 取样 然后 对 
每个 数据 样本 建模 对 新 数据 进行 预 测时 
每个 模型 都会 进行 预测 并对 每个 预测 结果 进行 
平均 以 更好 地 估计 真实 的 输出 值 随机 
森林 随机 森林 是 对 bagging 算法 的 一种 调整 
它 不是 选择 最佳 分割 点来 创建 决策树 而是 通过 
引入 随机性 来 得到 次优 分割 点 因此 针对 每 
个 数据 样本 所 创建 的 模型 会 与 其他 
方式 有所 不同 但 仍能 以其 独特 和 不同 的 
方式 准确 预测 结合 所有 模型 的 预测 可以 更好 
地 估计 潜在 的 真实 输出 如果 用 方差 较高 
的 算法 如 决策树 能够 获得 较好 的 结果 那么 
通过 bagging 算法 通常 可以 获得 更好 的 结果 ▌ 
  10 Boosting/w 和/c AdaBoost/w 算法/n Boosting/w 是/v 一项/m 从/p 
多个/m 弱/a 分类器/n 中/f 构/v 建强/nr 分类器/n 的/uj 集成/v 预测/vn 
技术/n 它 从 训练 数据 中 构建 模型 然后 通过 
修正 前 一个 模型 的 错误 创造 出 第二 个 
模型 以此类推 模型 不断 叠加 直至 能够 完美 预测 训练 
数据集 或 达到 可 添加 的 模型 的 数量 上限 
在 针对 二元 分类 所 开发 的 boosting 算法 中 
AdaBoost 是 第一 个 成功 的 它 是 理解 boosting 
算法 的 最佳 起点 现代 boosting 方法 基于 AdaBoost 而 
构建 最 典型 的 例子 是 随机 梯度 加速器 通常 
AdaBoost 算法 与 决策树 一起 工作 第一 个 决策树 创建 
后 决策树 在 每个 训练 实例 上 的 性能 都被 
用来 衡量 下一个 决策树 针对 该 实例 所应 分配 的 
关注 程度 难以 预测 的 训练 数据 被 赋予 更大 
的 权重 而 容易 预测 的 数据 则 被 赋予 
更小 的 权重 模型 依次 被 创建 每次 更新 训练 
实例 的 权重 都会 影响 到 序列 中 下一个 决策树 
学习 性能 所有 决策树 完成后 即可 对 新 输入 的 
数据 进行 预测 而 每个 决策树 的 性能 将由 它 
在 训练 数据 上 的 准确度 所 决定 由于 模型 
注意力 都 集中于 纠正 上一个 算法 的 错误 所以 必须 
确保 数据 是 干净 无 异常 的 ▌   最后 
的 建议 初学者 常常 会被 眼花缭乱 的 机器学习 算法 所 
困扰 提出 我 该 使用 哪种 算法 这样 的 问题 
此 问题 的 答案 取决于 许多 因素 包括 1 数据 
的 大小 质量 和 性质 2 可用 的 计算 时间 
3 任务 的 紧迫性 4 你 想要 用 数据 来 
做什么 即使 是 一位 经验 丰富 的 数据 科学家 在 
尝试 不同 的 算法 之前 也 无法 回答 哪种 算法 
的 性能 会 是 最好 的 机器 学习 的 算法 
还有 很多 但 以上 这些 是 最 受欢迎 的 算法 
如果 你 刚 入门 机器学习 这将 是 一个 很好 的 
学习 起点 作者 | James Le 原文 链接 | https 
/ / t o w a r d s d 
a t a s c i e n c e 
. com / a tour of the top 10 algorithms 
for machine learning newbies dde4edffae11 