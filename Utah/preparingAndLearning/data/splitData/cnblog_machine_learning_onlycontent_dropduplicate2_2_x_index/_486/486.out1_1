应用 机器 学习 的 建议 1 . 评估 学习 算法 
在 实际 中 应用 学习 算法 时 如何 评估 一个 
学习 算法 的 好坏 进一步 地 如果 学习 的 算法 
的 效果 不太好 如何 改进 学习 算法 例如 对于 一个 
简单 的 线性 拟合 模型 改进 算法 效果 的 策略 
包括 采用 更多 的 训练 实例 训练 模型 采用 更小 
的 特征 集合 增加 额外 的 特征 尝试 高次 项 
拟合 $ x _ 1 ^ 2 $ $ x 
_ 2 ^ 2 $ $ x _ 3 ^ 
3 $ $ \ ldots $ 增加/v 惩罚/vn 项/n 系数/n 
$/i \/i lambda/w $/i 减小/v 惩罚/vn 项/n 系数/n $/i \/i 
lambda/w $/i 机器学习/i 算法/n 诊断/v ML diagnostic 负责 发现 学习 
算法 中 存在 的 问题 通过 恰当 的 策略 提高 
它 的 性能 尽管 该 过程 会 需要 一定 的 
时间 实现 然而 这样 的 代价 是 物超所值 的 评估 
假设 Evaluating a hypothesis 如果 使用 全部 的 数据 集 
训练 模型 该 模型 可能 在 训练 集上 表现 良好 
然而 泛化 到 新的 实例 上 效果 显著 下降 即 
出现 过拟合 问题 如 所示 需要 对 假设 进行 验证 
一种 合理 的 方式 是 将 数据集 分为 训练 集 
training set 和 测试 集 test set 两部分   首先 
使用 训练 集 训练 模型 获得 参数 $ \ theta 
$ 然后 在 测试 集上 计算 $ J _ { 
\ text { test } } \ theta $ . 
对于 线性 回归 问题 $ $ J _ { \ 
text { test } } \ theta = \ frac 
{ 1 } { 2m _ { \ text { 
test } } } \ left \ sum \ limits 
_ { i = 1 } ^ { m _ 
{ \ text { test } } } h _ 
{ \ theta } x ^ { i } y 
^ { i } \ right $ $ 对于 0 
1分 类 问题 $ $ J _ { \ text 
{ test } } \ theta = \ frac { 
1 } { m _ { \ text { test 
} } } \ sum \ limits _ { i 
= 1 } ^ { m _ { \ text 
{ test } } } err h _ { \ 
theta } x ^ { i } y ^ { 
i } $ $ 其中 $ $ err h _ 
{ \ theta } x ^ { i } y 
^ { i } = \ left \ {   
\ begin { aligned }   1 & \ quad 
If \ quad h _ { \ theta } x 
\ geq 0.5 \ quad and \ quad y = 
0 \ \   1 & \ quad   If 
\ quad h _ { \ theta } x 0.5 
\ quad and \ quad y = 1 \ \ 
  0 & \ quad otherwise   \ end { 
aligned }   \ right . $ $ 模型 选择 
model select & 训练 / 验证 / 测试 training / 
validation / test 集 对于 线性 回归模型 根据 特征选择 的 
复杂 程度 可以 用 多个 模型 可供 选择 例如 可以考虑 
线性 二次 项 三次 项 四次 项 等等 如何 从 
这些 模型 中 选择 一个 合理 的 模型 呢 按照 
之前 的 训练 / 测试 集 划分 我们 可以 使用 
训练 集 分别 得到 各 个 模型 参数 然后 在 
测试 集上 比较 模型 的 误差 选择 误差 最小 的 
模型 然而 紧接着 的 一个 问题 是 在 选定 了 
该 模型 后 我们 如何 测试 模型 的 效果 呢 
因为 该 模型 本来 就是 选择 在 测试 集上 误差 
最小 的 所以 在 测试 集上 进行 验证 显然 不能 
得到 有效 的 结论 为此 可以 将 模型 划分 三 
部分 训练 集 training set / 交叉 验证 集 cross 
validation set cv / 测试 集 test set 在 训练 
集上 学习 模型 参数 在 验证 集上 选择 最佳 模型 
最后 在 测试 集上 评估 最佳 模型 的 效果 2 
. Bias and Variance 学习 算法 中 常见 的 两类 
问题是 欠 拟合 问题 和 过拟合 问题 如 所示 欠 
拟合 的 原因 主要 是 因为 模型 过于 简单 因此/c 
模型/n 在/p 训练/vn 和/c 验证/v 集中/v 的/uj 误差/n 都/d 很大/a 
且/zg $/i J/w _/i {/i cv/w }/i \ theta \ 
approx J _ { train } \ theta $ 相反 
过拟合 问题 是 模型 过于 复杂 模型 在 训练 集中 
误差 很小 接近于 0 然而 在 验证 集中 误差 非常大 
即 $ J _ { cv } \ theta \ 
gg J _ { train } \ theta $ 给 
出了 这 两种 情况 的 表示 .   $ J 
_ { train } \ theta $ 和$J/nr _ { 
cv } \ theta $ 随 模型 复杂度 的 变化 
2.1 regularization 和 bias / variance 对于 含有 regularization 的 
模型 参数 $ \ lambda $ 的 不当 选择 也 
会 导致 模型 出现 欠 拟合 和 过拟合 以 线性 
回归 为例 如果 $ \ lambda $ 选择 过大 那么 
模型 会 出现 欠 拟合 反之 如果 $ \ lambda 
$ 过小 则 容易 出现 过 拟合 通过 将 数据集 
划分 为 训练 集 / 验证 集 / 测试 集 
然后 $ \ lambda $ 取 一 系列 值 0 
0.01 0.02 0.04 0.08 . . . 对于 每一个 $ 
\ lambda $ 取值 用 训练 集 训练 参数 $ 
\ theta $ 对于 得到 的 每一个 模型 在 验证 
集 选择 使得 错误 最小 的 参数 $ \ lambda 
$ 作为 模型 参数 即 $ J _ { cv 
} \ theta $ 最小 更 直观 的 方式 可以 
做出 $ J _ { train } \ theta $ 
和$J/nr _ { cv } \ theta $ 随 $ 
\ lambda $ 的 变化 曲线 如 所示 选择 最优 
的 $ \ lambda $ 2.2 学习曲线 学习曲线 是 $ 
J _ { train } \ theta $ 和$J/nr _ 
{ cv } \ theta $ 随 训练 集 尺寸 
的 变化 曲线 可以 用于 识别 欠 拟合 和 过拟合 
问题 对于 欠 拟合 由于 模型 过于 简单 因而 训练 
错误 $ J _ { train } \ theta $ 
和 验证 错误 $ J _ { cv } \ 
theta $ 均 较大 如左 所示 增加 训练 实例 并不能 
改善 这种 情况 而 对于 过拟合 问题 在 训练 错误 
非常 小 $ J _ { train } \ theta 
\ approx 0 $ 而 验证 错误 $ J _ 
{ cv } \ theta $ 很大 两者 之间 有 
一个 非常 大 的 鸿沟 gap 如右 所示 在 这种 
情况 下 下 增加 训练 实例 很 有可能 改善 算法 
性能 2.3 总   结 采取 恰当 的 措施 解决 
欠 拟合 和 过拟合 问题 采取 的 措施 及 其 
解决 的 问题 如表 1 所示 表 1 . 采取 
的 措施 与 其 解决 的 欠 拟合 和 过拟合 
问题 机器学习 系统设计 3.1 构建 垃圾邮件 分类器 spam classfier 采用 
监督 式 学习 构建 一个 单词表 对于 每 一封 邮件 
判断 邮件 中 是否 出现 单词表 中的 单词 如果 出现 
对应 位置 标记 为 1 反之 标记 为 0 这样 
将 一封 邮件 映射 为 一个 高维 的 0 1 
向量 然后 对于 垃圾邮件 标记 为 1 反之 标记 为 
0 从而 转化 为 一个 常规 的 分类 问题 错误 
分析 从 一个 简单 的 算法 开始 plot 学习曲线 分析 
算法 存在 的 问题 并 采用 对应 的 措施 增加 
更多 数据 增加 更多 特征 等等 人工 检查 算法 在 
验证 集中 出现 错误 分类 的 情况 进行 必要 的 
统计 分析 哪 类 邮件 容易 被 错误 划分 哪些 
特征 应该 会 改善 算法 拼写错误 邮件 占 多少 标点 
误用 邮件 占 多少 等等 3.2 处理 偏斜 数据 skewed 
data 例子 对于 癌症 / 非 癌症 的 分类 问题 
假设 y = 1 表示 癌症 y = 0 表示 
非 癌症 因为 癌症 的 人数 必然 是 少数 不妨 
假设 为 1% 那么 一个 非常 naive 的 算法 可以 
在 任何 情况下 直接 返回 0 这样 表面上 该 算法 
的 正确 率 高达 99% 因为 本来 99% 的 人都 
是非 癌症 然而 实际上 容易 看出 对于 癌症 患者 该 
算法 一个 也 没有 检测 出来 如 癌症 类 这样 
相较 于 其他 类 本身 的 比例 与 其他 类 
数量 差距 巨大 的 类 称为 偏斜 类 skewed class 
为了 更好 的 衡量 算法 在 偏斜 数据 集上 的 
效果 仅仅 使用 准确率 是 不够 因此 提出 了 如下 
的 指标 来 衡量 分类 的 效果 Precision / Recall 
根据 example 的 实际 值 和 算法 对其 预测 的 
值 可以 将其 归为 以下 四类 之一 如表 2 所示 
其中 偏斜 类 标记 为 1 True positive 算法 预测值 
为 1 实际 值 也为 1 算法 预测 正确 False 
positive 算法 预测值 为 1 实际 值 为 0 算法 
预测 错误 False negative 算法 预测值 为 0 实际 值 
为 1 算法 预测 错误 True negative 算法 预测值 为 
0 实际 值 为 0 算法 预测 正确 表 2 
. example 分类 定义 precision 和 recall 如下 所示 其中 
precision 表示 算法 预测 的 癌症 患者 中 真正 的 
癌症 患者 占 多 大比 列 而 recall 表示 在 
所有 的 癌症 患者 中 算法 识别 出来 了 多 
大比例 $ $ \ text { Precision } = \ 
frac { \ text { # True positive } } 
{ \ text { # Predict positive } } = 
\ frac { \ text { # True positive } 
} { \ text { # True positive } + 
\ text { # False positive } } $ $ 
$ $ \ text { Recall } = \ frac 
{ \ text { # True positive } } { 
\ text { # Actual positive } } = \ 
frac { \ text { # True positive } } 
{ \ text { # True positive } + \ 
text { # False negative } } $ $ 在 
logistic 回 归中 对于 $ h _ { \ theta 
} x \ leq 0.5 $ 预测 y = 1 
如果 提高 阈值 0.5 比如 0.7 那么 预测 的 precision 
提高 然而 与此同时 recall 会 降低 反之 如果 降低 阈值 
0.5 例如 0.3 那么 recall 会 增大 precision 会 减小 
为了 在 两者 之间 取得 平衡 同时 考虑 precision 和 
recall 定义 F1 score 为 $ $ F _ 1 
= \ frac { 2 \ times \ text { 
Precision } \ times \ text { Recall } } 
{ \ text { Precision } + \ text { 
Recall } } $ $ 3.3 使用 大 数据集 large 
data set 大 数据 基本 原理 选择 足够 多 的 
特征 来 预测 y 值 从而 避免 欠 拟合 一个 
有用 的 测试 是 问 该 领域 内 的 专家 
是否 能够 用 这些 特征 认为 地 预测 y 的 
值 然后 使用 多 参数 的 学习 算法 线性 回归 
/ logistic 回归 / 神经网络 等在 大 数据 集上 进行 
训练 从而 避免 过拟合 当 数据 足够 多时 模型 不太可能 
出现 过拟合 参考文献 1 Andrew Ng Coursera 公开课 第六周 2 
Wikipedia   Bias – variance tradeoff .   https / 
/ en . wikipedia . org / wiki / Bias 
% E 2% 80% 93variance _ tradeoff 3   Statistics 
Bias variance trade off between overfitting and underfitting .   
http / / gerardnico . com / wiki / data 
_ mining / bias _ trade off 3   Welcome 
to the Machine Learning .   http / / www 
. ociweb . com / resources / publications / sett 
/ february 2015 welcome to the machine learning / 