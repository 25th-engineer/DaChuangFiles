本 系列 文章 为 机器学习 实战 学习 笔记 内容 整理 
自 书本 网络 以及 自己 的 理解 如 有错误 欢迎 
指正 源码 在 Python3 . 5 上 测试 均 通过 
代码 及 数据   https / / github . com 
/ Wellat / MLaction 1 算法 概述 1.1 朴素 贝叶斯 
朴素 贝叶斯 是 使用 概率论 来 分类 的 算法 其中 
朴素 各 特征 条件 独立 贝叶斯 根据 贝叶 斯定理 根据 
贝叶 斯定理 对 一个 分 类 问题 给定 样本 特征 
x 样 本属于 类别 y 的 概率 是 1 在 
这里 x 是 一个 特征向量 设 x 维度 为 M 
因为 朴素 的 假设 即 特征 条件 独立 根据 全 
概率 公式 展开 上式 可以 表达 为 这里 只要 分别 
估计 出 特征   Χ i   在 每 一类 
的 条件 概率 就 可以 了 类别 y 的 先验概率 
可以 通过 训练 集 算出 同样 通过 训练 集上 的 
统计 可以 得出 对应 每 一类 上 的 条件 独立 
的 特征 对应 的 条件概率 向量 1.2 算法 特点 优点 
在 数据 较少 的 情况 下 仍然 有效 可以 处理 
多 类别 问题 缺点 对于 输入 数据 的 准备 方式 
较为 敏感 适用 数据类型 标称 型 数据 2 使用 Python 
进行 文本 分类 要从 文本 中 获取 特征 需要 先 
拆分 文本 可以 把 词条 想象 为 单词 也 可以 
使用 非 单词 词条 如 URL IP 地址 或者 任意 
其他 字符串 然后 将 每一个 文本 片段 表示 为 一个 
词条 向量 其 中值 为 1 表示 词条 出现 在 
文档 中 0 表示 词条 未 出现 2.1 准备 数据 
从 文本 中 构建 词 向量 1 from numpy import 
* 2 3 def loadDataSet 4 5 postingList 进行 词条 
切分 后的/nr 文档 集合 6 classVec 类别 标签 7 8 
postingList = my dog has flea problems help please 9 
maybe not take him to dog park stupid 10 my 
dalmation is so cute I love him 11 stop posting 
stupid worthless garbage 12 mr licks ate my steak how 
to stop him 13 quit buying worthless dog food stupid 
14 classVec = 0 1 0 1 0 1 # 
1 代表 侮辱性 文字 0 代表 正常 言论 15 return 
postingList classVec 16 17 def createVocabList dataSet 18 vocabSet = 
set # 使用 set 创建 不 重复 词表 库 19 
for document in dataSet 20 vocabSet = vocabSet | set 
document # 创建 两个 集合 的 并 集 21 return 
list vocabSet 22 23 def setOfWords2Vec vocabList inputSet 24 returnVec 
= 0 * len vocabList # 创建 一个 所 包含 
元素 都为 0 的 向量 25 # 遍历 文档 中 
的 所有 单词 如果 出现 了 词汇表 中的 单词 则将 
输出 的 文档 向量 中的 对应 值 设为 1 26 
for word in inputSet 27 if word in vocabList 28 
returnVec vocabList . index word = 1 29 else print 
the word % s is not in my Vocabulary % 
word 30 return returnVec 31 32 我们 将 每个 词 
的 出现 与否 作为 一个 特征 这 可以 被 描述 
为 词集 模型 set of words model 33 如果 一个 
词 在 文档 中 出现 不止 一次 这 可能 意味着 
包含 该词 是否 出现 在 文档 中 所 不能 表达 
的 某种 信息 34 这种 方法 被 称为 词 袋 
模型 bag of words model 35 在 词 袋中 每个 
单词 可以 出现 多次 而在 词 集中 每个 词 只能 
出现 一次 36 为 适应 词 袋 模型 需要 对 
函数 setOfWords2Vec 稍加 修改 修改后 的 函数 称为 bagOfWords2VecMN 37 
38 def bagOfWords2VecMN vocabList inputSet 39 returnVec = 0 * 
len vocabList 40 for word in inputSet 41 if word 
in vocabList 42 returnVec vocabList . index word + = 
1 43 return returnVec2 . 2 训练 算法 从词向/nr 量计算/l 
概率/n 计算/v 每个/r 类别/n 的/uj 条件/n 概率/n 伪代码 1 def 
trainNB0 trainMatrix trainCategory 2 3 朴素 贝叶斯 分类器 训练 函数 
此处 仅 处理 两类 分类 问题 4 trainMatrix 文档 矩阵 
5 trainCategory 每篇 文档 类别 标签 6 7 numTrainDocs = 
len trainMatrix 8 numWords = len trainMatrix 0 9 pAbusive 
= sum trainCategory / float numTrainDocs 10 # 初始化 所有 
词 出现 数 为 1 并将 分母 初始 化为 2 
避免 某一个 概率值 为 0 11 p0Num = ones numWords 
p1Num = ones numWords # 12 p0Denom = 2.0 p1Denom 
= 2.0 # 13 for i in range numTrainDocs 14 
if trainCategory i = = 1 15 p1Num + = 
trainMatrix i 16 p1Denom + = sum trainMatrix i 17 
else 18 p0Num + = trainMatrix i 19 p0Denom + 
= sum trainMatrix i 20 # 将 结果 取 自然对数 
避免 下 溢出 即 太多 很小 的 数 相乘 造成 
的 影响 21 p1Vect = log p1Num / p1Denom # 
change to log 22 p0Vect = log p0Num / p0Denom 
# change to log 23 return p0Vect p1Vect pAbusive2 . 
3 测试 算法 分类 函数 1 def classifyNB vec2Classify p0Vec 
p1Vec pClass1 2 3 分类 函数 4 vec2Classify 要 分类 
的 向量 5 p0Vec p1Vec pClass1 分别 对应 trainNB0 计算 
得到 的 3个 概率 6 7 p1 = sum vec2Classify 
* p1Vec + log pClass1 8 p0 = sum vec2Classify 
* p0Vec + log 1.0 pClass1 9 if p1 p0 
10 return 1 11 else 12 return 0 测试 1 
def testingNB 2 listOPosts listClasses = loadDataSet 3 myVocabList = 
createVocabList listOPosts 4 trainMat = 5 for postinDoc in listOPosts 
6 trainMat . append setOfWords2Vec myVocabList postinDoc 7 # 训练 
模型 注意 此处 使用 array 8 p0V p1V pAb = 
trainNB0 array trainMat array listClasses 9 testEntry = love my 
dalmation 10 thisDoc = array setOfWords2Vec myVocabList testEntry 11 print 
testEntry classified as classifyNB thisDoc p0V p1V pAb 12 testEntry 
= stupid garbage 13 thisDoc = array setOfWords2Vec myVocabList testEntry 
14 print testEntry classified as classifyNB thisDoc p0V p1V pAb 
3 实例 使用 朴素 贝叶斯 过滤 垃圾邮件 一般 流程 3.1 
切分 文本 将 长 字符串 切 分成 词表 包括 将 
大写 字符 转换成 小写 并 过滤 字符 长度 小于 3 
的 字符 1 def textParse bigString # 2 3 文本 
切分 4 输入 文本 字符串 输出 词表 5 6 import 
re 7 listOfTokens = re . split r \ W 
* bigString 8 return tok . lower for tok in 
listOfTokens if len tok 2 93.2 使用 朴素 贝叶斯 进行 
垃圾邮件 分类 1 def spamTest 2 3 垃圾邮件 测试函数 4 
5 docList = classList = fullText = 6 for i 
in range 1 26 7 # 读取 垃圾邮件 8 wordList 
= textParse open email / spam / % d . 
txt % i r encoding = utf 8 . read 
9 docList . append wordList 10 fullText . extend wordList 
11 # 设置 垃圾 邮件 类 标签 为 1 12 
classList . append 1 13 wordList = textParse open email 
/ ham / % d . txt % i r 
encoding = utf 8 . read 14 docList . append 
wordList 15 fullText . extend wordList 16 classList . append 
0 17 vocabList = createVocabList docList # 生成 次 表 
库 18 trainingSet = list range 50 19 testSet = 
# 20 # 随机 选 10组 做 测试 集 21 
for i in range 10 22 randIndex = int random 
. uniform 0 len trainingSet 23 testSet . append trainingSet 
randIndex 24 del trainingSet randIndex 25 trainMat = trainClasses = 
26 for docIndex in trainingSet # 生成 训练 矩阵 及 
标签 27 trainMat . append bagOfWords2VecMN vocabList docList docIndex 28 
trainClasses . append classList docIndex 29 p0V p1V pSpam = 
trainNB0 array trainMat array trainClasses 30 errorCount = 0 31 
# 测试 并 计算 错误率 32 for docIndex in testSet 
33 wordVector = bagOfWords2VecMN vocabList docList docIndex 34 if classifyNB 
array wordVector p0V p1V pSpam = classList docIndex 35 errorCount 
+ = 1 36 print classification error docList docIndex 37 
print the error rate is float errorCount / len testSet 
38 # return vocabList fullText4 实例 使用 朴素 贝叶斯 分类器 
从 个人 广告 中 获取 区域 倾向 一般 流程 在 
这个 中 我们 将 分别 从 美国 的 两个 城市 
中 选取 一些 人 通过 分析 这些 人 发布 的 
征婚 广告 信息 来 比较 这 两个 城市 的 人们 
在 广告 用词 上 是否 不同 4.1 实现 代码 1 
2 函数 localWords 与 程序清单 中的 spamTest 函数 几乎 相同 
区别 在于 这里 访问 的 是 3 RSS 源 而不是 
文件 然后 调用函数 calcMostFreq 来 获得 排序 最高 的 30个 
单词 并 随后 将 它们 移除 4 5 def localWords 
feed1 feed0 6 import feedparser 7 docList = classList = 
fullText = 8 minLen = min len feed1 entries len 
feed0 entries 9 for i in range minLen 10 wordList 
= textParse feed1 entries i summary 11 docList . append 
wordList 12 fullText . extend wordList 13 classList . append 
1 # NY is class 1 14 wordList = textParse 
feed0 entries i summary 15 docList . append wordList 16 
fullText . extend wordList 17 classList . append 0 18 
vocabList = createVocabList docList # create vocabulary 19 top30Words = 
calcMostFreq vocabList fullText # remove top 30 words 20 for 
pairW in top30Words 21 if pairW 0 in vocabList vocabList 
. remove pairW 0 22 trainingSet = list range 2 
* minLen testSet = # create test set 23 for 
i in range 10 24 randIndex = int random . 
uniform 0 len trainingSet 25 testSet . append trainingSet randIndex 
26 del trainingSet randIndex 27 trainMat = trainClasses = 28 
for docIndex in trainingSet # train the classifier get probs 
trainNB0 29 trainMat . append bagOfWords2VecMN vocabList docList docIndex 30 
trainClasses . append classList docIndex 31 p0V p1V pSpam = 
trainNB0 array trainMat array trainClasses 32 errorCount = 0 33 
for docIndex in testSet # classify the remaining items 34 
wordVector = bagOfWords2VecMN vocabList docList docIndex 35 if classifyNB array 
wordVector p0V p1V pSpam = classList docIndex 36 errorCount + 
= 1 37 print the error rate is float errorCount 
/ len testSet 38 return vocabList p0V p1V 39 40 
def calcMostFreq vocabList fullText 41 42 返回 前 30个 高频词 
43 44 import operator 45 freqDict = { } 46 
for token in vocabList 47 freqDict token = fullText . 
count token 48 sortedFreq = sorted freqDict . items key 
= operator . itemgetter 1 reverse = True 49 return 
sortedFreq 30 50 51 if _ _ name _ _ 
= = _ _ main _ _ 52 # 导入 
RSS 数据源 53 import operator 54 ny = feedparser . 
parse http / / newyork . craigslist . org / 
stp / index . rss 55 sf = feedparser . 
parse http / / sfbay . craigslist . org / 
stp / index . rss 56 localWords ny sf 