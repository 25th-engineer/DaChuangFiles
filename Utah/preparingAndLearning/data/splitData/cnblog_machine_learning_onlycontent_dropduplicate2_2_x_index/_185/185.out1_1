一 引言 最近 写 了 许多 关于 机器 学习 的 
学习 笔记 里面 经常 涉及 概率论 的 知识 这里 对 
所有 概率论 知识 做 一个 总结 和 复习 方便 自己 
查阅 与 广大 博友 共享 所谓 磨刀不误砍柴工 希望 博友 们 
在 这篇 博文 的 帮助 下 阅读 机器 学习 的 
相关 文献 时 能够 更加 得心应手 这里 只 对 本人 
觉得 经常 用到 的 概率论 知识点 做 一次 小结 主要 
是 基本 概念 因为 机器 学习 中 涉及 概率论 的 
地方 往往 知道 基本 概念 就 不难 理解 后 面会 
不 定期 更新 希望 博友 们 多 留言 补充 二 
古典 概率论 中的 几个 重要 的 公式 $ P \ 
bar { A } = 1 P A $ $ 
P A B = P A P AB $ $ 
P A + B = P A + P B 
P AB $ $ P A + B + C 
= P A + P B + P C P 
AB P AC P BC + P ABC $ 对于 
$ n $ 个 事件   $ A _ { 
1 } A _ { 2 } A _ { 
3 } \ ldots A _ { n } $ 
两两 互斥 则   $ P \ cup _ { 
i = 1 } ^ { n } A _ 
{ i } = \ sum _ { i = 
1 } ^ { n } P A _ { 
i } $ 二 贝叶斯 Bayes 公式 通 常把 事件 
A   的 概率 P A 叫做 实验 前 的 
假设 概率 即 先验概率 prior   probability 如果 有 另一个 
事件 B 与 事件 A 有 某种 关系 即 事件 
A 和 B 不是 互相 独立 的 那么 当 事件 
B 确实 发生 之后 则 应当 重新 估计 事件 A 
  的 概率 即 P A   | B 这 
叫做 条件概率 或者 试验 后的/nr 假设 概率 即 后验/nr 概率 
posterior   probability . 公式 一 再 引入 全 概率 
公式 设 事件 A 当前 仅 当 互不 相容 的 
事件 即 任意 两个 事件 不 可能 同时 发生 的 
i = 1 2 . . . n 中的 任意 
一个 事件 发生 时才/nr 可能 发生 已知 事件     
的 概率     及 事件 A 在     
已 发生 的 条件 下 的 条件概率 则 事件 A 
发生 的 概率 为 这 就是 全 概率 公式 . 
根据 概率 乘法 定理 我们 可以 得到 于是 再 根据 
上面 介绍 的 全 概率 公式 则 可得到 传说中 的 
贝叶斯 公式 这些 公式 定理 几乎 贯穿 整个 机器学习 很 
基本 也 很 重要 三 常用 的 离散 随 见 
变量 分布 0 1 分布 设 随机变量 X 只能 取得 
两个 数值 0 与 1 而 概率函数 是   通常 
把 这种 分布 叫做 0 1 分布 或者 两 点 
分布 是 分布 参数 . 二项分布 binomial distribution 设 随机变量 
X 可能 的 的 值 是 0 1 2 . 
. . n 而 概率函数 是 其中 这种 分布 叫做 
二项分布 含 有 两个 参数   和 /nr 通常 把 这种 
分布 记作 如果 随 见 变量 X 服从 二项分布 记作 
3 .   泊松 Possion 分布 设 随机变量 X 的 
可能 值 是 一切 非 负整数 而 概率函数 是 其中 
λ 0 为 常数 这种 分布 叫做 泊松分布 泊松分布 就 
含有 一个 参数 λ 记作 P λ 如果 随机变量 X 
服从 泊松分布 则 记作 X ~ P λ 四 随机变量 
的 分布 函数 设 x 是 任何 实数 考虑 随机变量 
X 取得 的 值 不大于     x 的 概率 
即 事件 X   ≤       x   
的 概率 记作 F x = P X ≤ x 
这个 函数 叫做 随机变量 X 的 概率分布 函数 或者 分布 
函数 注意 区别于 上面 讲到 的 概率函数 . 如果 已知 
随机变量 X 的 分布 函数 F X 则 随 见 
变量 X 落在 半 开区间 x1 x2 内 的 概率 
P x1 X ≤ x2 = F x2 F x1 
五 连续 随机变量 的 概率密度 连续 随机变量 的 概率密度 就是 
分布 函数 的 导函数 六 随机变量 的 数学期望 如果 随机变量 
X 只能 取得 有限 个 值 而 取得 有限 个 
值得 概率 分别 是 则 数学期望 如果 连续 随机变量 X 
的 概率 密度 为 则 连续 随机变量 的 数学期望 一个 
常数 的 的 数学期望 等于 这个 常数 本身 定理 两个 
独立 随机变量 的 乘积 的 数学期望 等于 它们 数学期望 的 
乘积 证明 如下 对于 离散 随机变量 X 与 Y 独立 
对于 连续 随机变量   X   与 Y 独立 七 
方差 与 标准差 随机变量 X 的 方差 记作 D X 
定义 为 下面 证明 一个 很 有用 的 公式 会 
用到 性质 一个 常数 的 的 数学期望 等于 这个 常数 
本身 简而言之 随机变量 的 方差 等于 变量 平方 的 期望 
减去 期望 的 平方 . 标准差 就是 方差 的 算术 
平方根 常数 的 方差 为 0 . 八 协方差 与 
相关 系数 随机变量 X 与 随机变量 Y 的 协方差 记作 
进一步 推导 可得 因为 两个 独立 随机变量 乘积 的 期望 
等于 两个 随机变量 各自 期望 的 乘积 于是 当 两个 
随机变量 独立 使 很容易 得到 它们 的 协方差 为 0 
. 两个 随机变量 X 与 Y 的 相关 系数 为 
两个 随机变量 的 相关 系数 的 绝对值 不大于 1 . 
当且仅当 随机变量 Y 与 X   之间 存在 线性关系 时 
相关 系数 的 绝对值 等于 1 并且 九 正态分布 正态分布 
又叫 高斯分布 设 连续 随机变量 X 的 概率密度 其中   
μ 及   σ 0 都是 常数 这种 分布 就是 
正态分布 . 正态分布 含有 两个 参数   μ 及   
σ 0 其中 μ 等于 正态分布 的 数学期望 而   
σ 等于 正态分布 的 标准差 通常 把 这种 分布 记作 
随机变量 X 服从 正态分布 则 记为 定理 设 随机变量 X 
服从 正态分布 则 X 的 线性函数 Y = a + 
bX b ≠ 0 也 服从 正态分布 且 有先 总结 
这么多 以后 遇到 重要 的 概率论 知识点 会 继续 补充 
