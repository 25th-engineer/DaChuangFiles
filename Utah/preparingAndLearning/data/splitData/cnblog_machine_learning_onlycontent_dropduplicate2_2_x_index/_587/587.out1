本人 看过 的 关联 规则 博文 很少 有 清晰 的 
把关 联 规则 的 算法 说 很 明白 的 希望 
读者 读完 本文 可以 有 新的 收获 本文 是 在 
默认 读者 有 相关 机器学习 算法 基础 的 总结 和 
提升 对 关联 规则 代码 实现 的 理解 并 介绍 
相关 案例 语言 python 一 引言 关联 规则 起初 是 
在 购物篮 分析 中 发现 的 沃尔玛 超市 在 美国 
某 地区 啤酒 和 尿布 放在 一起 卖 这种 关联 
规则 有利于 市场 营销 决策 的 制定 关联 规则 是非 
监督 学习 的 一种 二   两个 重要 的 概念 
我们 认定 满足 支持度 和 置信度 的 规则 是 有趣 
的 支持度 P A 及 项集A/nr 出现 的 概率 频数 
置信度 P B / A 条件概率 P B / A 
= P AB / P A 所以 支持度 可以 用来 
计算 置信度 代码 是 学习 算法 最好 的 途径 三 
Apriori 算法 网上 很多 文章 介绍 Apriori 算法 都是 云里雾里 
下面 梳理 一下 脉络 核心 是 apriori 原理 如果 某个 
项集是/nr 频繁 的 那么 它 是 所有 子集 也是 频繁 
的 apriori 原理 的 精妙 在于 他 的 逆否命题 若 
子集 不是 频繁 的 则 所有 包含 它 的 项集/nr 
都是 不 频繁 的 这样 剪掉 不 频繁 项集时/nr 就/d 
可以/c 同时/c 剪掉/v 很多/m 包含/v 这个/r 项集的/nr 不/d 频繁/a 的/uj 
项/n 集了/i 若 蛮力 查找 大 频 项集/nr 时间 复杂度 
是 指数 型 例如 4个 项集/nr 它 的 所有 组合 
的 复杂度 是 15 同理 可以 剪掉 后件 不满足 置信度 
规则 时 同时 剪掉 后件 包含 这个 规则 后件 的 
规则 形象 的 说 看 下图 eg 项集{/nr 0 1 
2 3 } 计算 所有 的 组合 情况 如下 图 
好像 一个 格 时间 复杂度 是 指数 型 的 按照/p 
项集元/nr 素数/n 由小到大/l 计算/v 每个/r 组合/v 的/uj 支持/v 度/zg { 
2 3 } 黑色 圈 不满足 最小 支持度 由 apriori 
定理 则 所有 以 它 为 子集 的 项集均/nr 不满足 
最小 支持度 需要 剪掉 下面 继续 考虑 置信度 规则 { 
012 } { 3 } 不满足 最小 置信度 由 apriori 
定理 所有 后件 包含 这条 规则 后件 的 规则 需要 
剪掉 即 二 后件 规则 { 01 } { 23 
} { 02 } { 1 3 } { 12 
} { 03 } 和三/nr 后件 规则 { 0 } 
{ 123 } { 1 } { 023 } { 
2 } { 013 } 读/v 到/v 这里/r 有/v 关联/ns 
规则/n 基础/n 的/uj 人/n 应该/v 会/v 有/v 感悟/v 通过 下面 
代码 介绍 可以 细致 的 明白 apriori 算法 的 机制 
四 apriori 实现 1 加载 demo 数据集 可以 改成 真实 
数据集 读 文件 from numpy import * def loadDataSet return 
1 3 4 2 3 5 1 2 3 5 
2 5 2 生成 一 频繁 项集/nr 作为 起始 点 
即 长度 为 1 的 频繁 集 图中 的 第一 
层 使用 frozenset 结构 是 因为 set 不 可以 作为 
dict 的 关键字 def createC1 dataSet # create one item 
C1 = for transaction in dataSet for item in transaction 
if not item in C1 C1 . append item C1 
. sort # print C1 return map frozenset C1 # 
use frozen set so we # can use it as 
a key in a dict3 计算 Ck 支持度 并 剪掉 
不满足 最小 指出 的 项集/nr def scanD D Ck minSupport 
# create one or more big frequence item ssCnt = 
{ } for tid in D for can in Ck 
if can . issubset tid if not ssCnt . has 
_ key can ssCnt can = 1 else ssCnt can 
+ = 1 numItems = float len D retList = 
supportData = { } for key in ssCnt support = 
ssCnt key / numItems if support = minSupport retList . 
insert 0 key supportData key = support return retList supportData4 
由/p m/w 频繁/a 项集/nr 生成/v m/w +/i 1/m 频繁/a 项集/nr 
举例 Ck 为 1 频繁 项集{/nr 01 } { 12 
} { 02 } 生成 { 012 } 有个 技巧 
只 合并 前 m 2项 一样 的 项集/nr 这样 不会 
重复 操作 如 这个 例子 { 01 } 和{/nr 12 
} 不 合并 { 12 } { 02 } 也不 
合并 只有 { 01 } { 02 } 合并 生成 
最后 的 { 012 } 否则 前 几个 合并 都是 
重复 的 值得 注意 的 是 0 3项 集 要 
排好 序 否则 前 k 2个 没有 比较 的 必要 
def aprioriGen Lk k # creates Ck retList = lenLk 
= len Lk # print Lk for i in range 
lenLk for j in range i + 1 lenLk L1 
= list Lk i k 2 L2 = list Lk 
j k 2 L1 . sort L2 . sort # 
print L1 L2 if L1 = = L2 # if 
first k 2 elements are equal retList . append Lk 
i | Lk j # set union # print retList 
return retList5 生/vn 成打/i 频/n 项集的/nr 算法/n 思路 生成 1 
频 项集/nr 根据 最小 支持度 过滤 依次/d 由/p m/w 频/n 
项集/nr 生成/v m/w +/i 1/m 频/n 项集/nr 直到/v m/w +/i 
1/m 频/n 项/n 集为/v 空/n 停止/v 迭代/v def apriori dataSet 
minSupport = 0.5 C1 = createC1 dataSet D = map 
set dataSet L1 supportData = scanD D C1 minSupport # 
create one big frequence item L1 # print L1 L 
= L1 k = 2 # print L while len 
L k 2 0 # print L k 2 L 
k 2 # print L Ck = aprioriGen L k 
2 k Lk supK = scanD D Ck minSupport # 
scan DB to get Lk supportData . update supK L 
. append Lk k + = 1 return L supportData 
以上 都是 大 频 项集的/nr 生成 算法 下面 继续 有趣 
的 关联 规则 的 发现 算法 6 计算 后件 为 
H 的 规则 的 置信度 代码 可以 看出 只是 一个 
条件概率 公式 而已 根据 最小 置信度 筛选 出 有趣 的 
规则 def calcConf freqSet H supportData brl minConf = 0.7 
prunedH = # create new list to return for conseq 
in H conf = supportData freqSet / supportData freqSet conseq 
# calc confidence if conf = minConf brl . append 
freqSet conseq conseq conf prunedH . append conseq return prunedH7 
由/p 后/f 件数/n 为/p m/w 的/uj 规则/n 集/q 生成/v 后件/n 
为/p 后/f 件数/n 为/p m/w +/i 1/m 的/uj 规则/n 集/q 
并 计算 置信度 递归 到 没有 可以 合并 的 规则 
集 停止 直观 的 过程 可以 查看 上图 的 格 
eq { 23 } { 01 } 和{/nr 12 } 
{ 03 } 合并 为 { 2 } { 013 
} 因为 标 红处前/nr k 2 相同 为了 避免 重复 
的 合并 操作 同 上面 打 大 频 项集/nr 合并 
def rulesFromConseq freqSet H supportData brl minConf = 0.7 if 
len freqSet m + 1 # try further merging Hmp1 
= aprioriGen H m + 1 # create Hm + 
1 new candidates Hmp1 = calcConf freqSet Hmp1 supportData brl 
minConf if len Hmp1 1 # need at least two 
sets to merge rulesFromConseq freqSet Hmp1 supportData brl minConf 8 
产生 关联 规则 的 最后 算法 思路 由于 规则 的 
前后 件 均 不能 为 空 所以 只有 二 频繁 
项集/nr 才能 产生 关联 规则 1 首先 由 二 频繁 
项集/nr 生成 规则 集 遍历 所有 的 二 频繁 项集/nr 
每个 元素 轮流 作为 后件 根据 最小 置信度 过滤 规则 
集 eg 二 频繁 项集{/nr 12 } 则 计算 规则 
{ 1 } { 2 } 和{2/nr } { 1 
} 的 置信度 2 依次 迭代 在 三大 频 项集/nr 
生成 规则 集 每个 元素 轮流 作为 后件 需要 考虑 
规则 的 合并 eg   三大 频 项集{/nr 123 } 
则 { 12 } { 3 } { 13 } 
{ 2 } { 23 } { 1 } 此外 
考虑 合并 { 1 } { 23 } { 2 
} { 13 } { 3 } { 12 } 
还要 继续 合并 根据 后件 前 k 2个 同 的 
合并 本例 前 k 2个 同 的 个数 为 0 
所以 停止 复杂 的 情况 看 步骤 7 def generateRules 
L supportData minConf = 0.7 # supportData is a dict 
coming from scanD bigRuleList = for i in range 1 
len L # only get the sets with two or 
more items for freqSet in L i H1 = frozenset 
item for item in freqSet if i 1 rulesFromConseq freqSet 
H1 supportData bigRuleList minConf else calcConf freqSet H1 supportData bigRuleList 
minConf return bigRuleList 五 应用 关联 规则 可以 应用 到 
哪些 问题 呢 购物篮 分析 搜索引擎 的 查询 词 国会 
投票 毒蘑菇 的 相似 特征提取 等 六 毒蘑菇 的 相似 
特征提取 毒蘑菇 部分 数据集 如下 1 3 9 13 23 
25 34 36 38 40 52 54 59 63 67 
76 85 86 90 93 98 107 113 2 3 
9 14 23 26 34 36 39 40 52 55 
59 63 67 76 85 86 90 93 99 108 
114 2 4 9 15 23 27 34 36 39 
41 52 55 59 63 67 76 85 86 90 
93 99 108 115 1 3 10 15 23 25 
34 36 38 41 52 54 59 63 67 76 
85 86 90 93 98 107 113 2 3 9 
16 24 28 34 37 39 40 53 54 59 
63 67 76 85 86 90 94 99 109 114 
2 3 10 14 23 26 34 36 39 41 
52 55 59 63 67 76 85 86 90 93 
98 108 114 2 4 9 15 23 26 34 
36 39 42 52 55 59 63 67 76 85 
86 90 93 98 108 115 2 4 10 15 
23 27 34 36 39 41 52 55 59 63 
67 76 85 86 90 93 99 107 115 1 
3 10 15 23 25 34 36 38 43 52 
54 59 63 67 76 85 86 90 93 98 
110 114 2 4 9 14 23 26 34 36 
39 42 52 55 59 63 67 76 85 86 
90 93 98 107 115 2 3 10 14 23 
27 34 36 39 42 52 55 59 63 67 
76 85 86 90 93 99 108 114 2 3 
10 14 23 26 34 36 39 41 52 55 
59 63 67 76 85 86 90 93 98 107 
115 每 一行 代表 一个 蘑菇 的 特征 第一列 是 
决策 类 1 代表 有毒 2 代表 五毒 加载 数据集 
dataset = line . split for line in open mashroom 
. dat readline 查找 大 频率 项集/nr L supp = 
apriori dataset 0.3 apriori 函数 在 算法 部分 已经 实现 
直接 调用 即可 有时候 我们 只 需要 查找 大 频 
项集/nr 并不需要 关联 规则 具体 问题 具体 分析 即可 七 
总结 整体 算法 就有 两个 核心 1 计算 满足 最小 
支持度 的 大 频率 项集/nr 2 挖掘 满足 最小 置信度 
的 有趣 规则 暴力 遍历 每种 组 合 的 方式 
指数级 利用 了 apriori 定理 剪掉 了 不 满足 要求 
的 小项 集 和小/nr 后件 规则 的 同时 剪掉/v 包含/v 
他们/r 的/uj 大/a 频度/n 项集和/nr 大/a 后件/n 规则/n 还有 一点 
主意 的 是 按 照 图 中格 的 形式 一层 
一层 有 小到 大 迭代 