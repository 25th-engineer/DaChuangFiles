人工智能 早已 不是 一个 新名词 它 的 发展 历史 已经 
有 几十 年 从 80 年代 早期 开始 当时/t 计算机科学/n 
家/q 设计/vn 出/v 可以/c 学习/v 和/c 模仿/v 人类/n 行为/v 的/uj 
算法/n 在 学习 方面 最 重要 的 算法 是 神经 
网络 但 由于 模型 过于 强大 没有 足够 的 数据 
支持 导致 不是 很 成功 然而 在 一些 更 具体 
的 任务 中 使用 数据 来 适应 函数 的 想法 
获得 了 巨大 的 成功 这也 构成 了 机器 学习 
的 基础 人工智能 早已 不是 一个 新名词 它 的 发展 
历史 已经 有 几十 年 从 80 年代 早期 开始 
当时/t 计算机科学/n 家/q 设计/vn 出/v 可以/c 学习/v 和/c 模仿/v 人类/n 
行为/v 的/uj 算法/n 在 学习 方面 最 重要 的 算法 
是 神经 网络 但 由于 模型 过于 强大 没有 足够 
的 数据 支持 导致 不是 很 成功 然而 在 一些 
更 具体 的 任务 中 使用 数据 来 适应 函数 
的 想法 获得 了 巨大 的 成功 这也 构成 了 
机器 学习 的 基础 在 模仿 方面 人工智能 在 图像 
识别 语音 识别 和 自然 语言 处理 方面 有着 广泛 
的 应用 专家 们 花费 了 大量 时间 去 创建 
边缘 计算 彩色 型材 N gram 语言 模型 语法树 等 
不料 所获 成绩 平平 传统 的 机器学习 机器学习 ML 技术 
在 预测 中 发挥 了 重要 作用 机器学习 已经 经历 
了 多代 有一套 完备 的 模型 结构 如 线性 回归 
Logistic 回归 决策树 支持 向量 机 贝叶斯 模型 正则化 模型 
集成 模型 神经网络 每一个 预测模型 都 基于 一定 的 算法 
结构 参数 可 进行 调整 训练 预测模型 涉及 以下 步骤 
1 . 选择 模型 结构 例如 逻辑 回归 随机 森林 
等 2 . 用 训练 数据 输入 和 输出 对模型 
进行 反馈 3 . 学习 算法 将 输出 最优 模型 
即 具有 特定 参数 的 模型 使 训练 误差 最小化 
每个/r 模型/n 都有/nr 自己/r 的/uj 特点/n 在 某些 任务 中 
表现 很好 在 其他 方面 也 却 不尽人意 但 一般来说 
我们 可以 把 它们 分为 低功耗 简单 模型 和 大功率 
复杂 模型 在 不同 的 模型 之间 进行 选择 是 
一个 非常 棘手 的 问题 传统上 使用 低功耗 / 简单 
模型 比 使用 高 功率 / 复杂 模型 要好 原因 
如下 在 我们 拥有 大量 的 处理 能力 之前 训练 
高功率 模型 需要 花费 很长 时间 直到 我们 有 一个 
庞大 的 数据 量 培养 高 功率 模型 会 导致 
过拟合 问题 由于 高 功率 模型 具有 丰富 的 参数 
可以 适应 多种 数据 的 形状 我们 可能 最终 会 
训练 出 一个 与 当前 训练 数据 非常 相关 的 
模型 而 不是 对 未来 数据 进行 预测 然而 选择 
低功耗 模型 存在 着 所谓 的 欠 拟合 问题 即 
模型 结构 过于 简单 无法 在 较 复杂 的 情况 
下 适应 训练 数据 假设 下面 的 数据 有 一个 
二次 关系 y = 5 * X 的 平方 没有 
方法 可以 拟合 一个 线性 回归 y = A B 
B B 无论 我们 选择 什么样 的 A 和B/nr 为了 
减轻 不 适合 的 问题 数据 科学家 通常会 应用 他们 
的 领域 知识 来 产生 输入 特性 它 与 输 
出有 更 直接 的 关系 例如 返回 到 二次 关系 
y = 5 * X 的 平方 然后 通过 选取 
a = 5 和b=/nr 0 拟合 线性 回归 机器 学习 
的 一个 主要 障碍 是 这个 特征 工程 步骤 它 
要求 领域 专家 在 进入 培训 过程 之前 识别 重要 
的 信号 特征 工程 步骤 非常 手工 需要 大量 的 
领域 专门知识 因此 成为 当今 大多数 机器学习 任务 的 主要 
瓶颈 换句话说 如果 我们 没有 足够 的 处理 能力 和 
足够 的 数据 那么 我们 必须 使用 低功耗 / 简单 
的 模型 这/r 需要/v 我们/r 花/v 大量/n 的/uj 时间/n 和/c 
精力/n 来/v 创建/v 适当/a 的/uj 输入/v 特性/n 这是 大多数 数据 
科学家 花 时间 做 的 事情 神经 网络 的 回归 
在 2000 年代 早期 随着 大 容量 数据 时代 大量 
的 细粒度 事件 数据 的 收集 随着 云计算 和 大规模 
并行处理 基础 设施 的 进步 机器 处理 能力 得到 了 
极大 的 提高 我们 不再 局限于 低功耗 / 简单 的 
模型 例如 当今 最 流行 的 两种 主流 机器学习 模型 
是 随机 森林 和 梯度 增强 树 然而 尽管 它们 
都 非常 强大 并 提供 非线性 模型 拟合 训练 数据 
数据 科学家 仍然 需要 仔细 地 创建 功能 以 达到 
良好 的 性能 与此同时 计算机 科学家 重新 使用 了 许多 
层 的 神经 网络 来 完成 这些 人类 模拟 任务 
这 给 新 出生 的 DNN 深度 神经网络 在 图像 
分类 和 语音 识别 的 任务 提供 了 一个 重大 
的 突破 DNN 的 主要 区别 是 你 可以 发出 
原 信号 例如 RGB 像素 值 直接 到 DNN 没有 
创造 任何 特定 于域的/nr 输入 特征 通过 多 层次 的 
神经 元 这 就是 为什么 它 被 称为 深 的 
神经 网络 能够 自动 生成 相应 的 功能 通过 各层 
最后 提供 了 一个 很好 的 预测 这 大大 节省 
了 特征 工程 的 努力 也是 数据 科学家 遇到 的 
一个 主要 瓶颈 DNN 也 演变成 许多 不同 的 网络 
结构 所以 我们 美国有线电视新闻网 卷积 神经网络 RNN 神经网络 LSTM 长短期 
记忆 GAN 生成 对抗 网络 迁移 学习 注意 模型 整个 
光谱 被称为 深度 学习 这是 当今 全 机器学习 界 关注 
的 焦点 强化 学习 另一个 关键 的 部分 是 如何 
模仿 一个人 或 动物 学习 想象 一下 感知 / 行为 
/ 奖赏 周期 的 非常 自然 的 动物 行为 一个人 
或 动物 首先 会 通过 感知 他 或 她 处于 
什么 状态 来 理解 环境 基于 这 一点 他 或 
她 会 选择 一个 动作 把 他 或 她 带到 
另一个 状态 然后 他 或 她 会 得到 一个 奖励 
如此 循环 重复 这种 学习 方法 称为 强化 学习 与/p 
传统/n 的/uj 有/v 监督/vn 机器/n 学习/v 的/uj 曲线拟合/n 方法/n 有/v 
很大/a 的/uj 不同/a 特别 是 强化 学习 的 发生 非常 
迅速 因为 每 一个 新 的 反馈 如 执行 一个 
动作 和 获得 一个 奖励 立即 被 发送 来 影响 
随后 的 决定 强化 学习 已经 获得 了 巨大 的 
成功 在 自动 驾驶 汽车 以及 AlphaGO 下棋 机器人 强化 
学习 也 提供 了 一个 平滑 的 预测 和 优化 
集成 因为/c 它/r 保持/v 一个/m 信念/n 的/uj 当前/t 状态/n 和/c 
可能/v 的/uj 转移/v 概率/n 时/n 采取/v 不同/a 的/uj 行动/vn 然后 
作出 决定 哪些 行动 会 带来 最好 的 结果 深度 
学习 + 强化 学习 = 人工智能 与 经典 机器学习 技术 
相比 深度 学习 提供 了 一个 更 强大 的 预测模型 
通常 能 产生 良好 的 预测 与 经典 的 优化 
模型 相比 强化 学习 提供 了 更快 的 学习 机制 
并且 更 适应 环境 的 变化 