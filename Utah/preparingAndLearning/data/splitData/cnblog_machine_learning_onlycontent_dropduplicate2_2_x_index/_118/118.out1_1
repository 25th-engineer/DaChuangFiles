本文 链接 http / / www . cnblogs . com 
/ breezedeus / p / 3496819 . html 转载 请 
注明 出处 从 等式 约束 的 最小化 问题 说起 上面 
问题 的 拉格朗日 表达式 为 也 就是 前 面的 最小化 
问题 可以 写 为 \ \ min \ limits _ 
{ x } \ max \ limits _ { y 
} L x y \ 它 对应 的 对偶 问题 
为 \ \ max \ limits _ { y } 
  \ min \ limits _ { x } L 
x y \ 下面 是 用来 求解 此 对偶 问题 
的 对偶 上升 迭代 方法 这个 方法 在 满足 一些 
比较 强的/nr 假设 下 可以 证明 收敛 为了 弱化 对偶 
上升 方法 的 强 假设性 一些 研究者 在 上世纪 60 
年代 提出 使用 扩展 拉格朗日 表达式 augmented Lagrangian 代替 原来 
的 拉格朗日 表达式 其中 \ \ rho 0 \ 对应 
上面 的 对偶 上升 方法 得到 下面 的 乘子 法 
method of multipliers 注意 乘子 法里把/nr 第二个 式子 里 的 
\ \ alpha ^ k \ 改成 了 扩展 拉格朗日 
表达式 中 引入 的 \ \ rho \ 这 不是 
一个 随意 行为 而是 有 理论 依据 的 利用 \ 
L x y \ 可以 导出 上面 最小化 问题 对应 
的 原始 和 对偶 可行性 条件 分别为 \ \ frac 
{ \ partial L } { \ partial y } 
= 0 \ \ \ frac { \ partial L 
} { \ partial x } = 0 \ 既然 
\ x ^ { k + 1 } \ 最小化 
\ L _ { \ rho } x y ^ 
{ k } \ 有 上面 最后 一个 等式 就是 
利用 了 \ y ^ { k + 1 } 
= y ^ { k } + \ rho A 
x ^ { k + 1 } b \ 从 
上面 可知 这种 \ y ^ { k + 1 
} \ 的 取法 使得 \ x ^ { k 
+ 1 } y ^ { k + 1 } 
\ 满足 对偶 可行 条件 \ \ frac { \ 
partial L } { \ partial x } = 0 
\ 而 原始 可行 条件 在 迭代 过程 中 逐渐 
成立 乘子/n 法/l 弱化/n 了/ul 对偶/n 上升/v 法的/nr 收敛/v 条件/n 
但 由于 在 x minimization/w 步/n 引入/v 了/ul 二次/m 项而/nr 
导致/v 无法/n 把/p x/w 分开/v 进行/v 求解/v 详见 1 而 
接下来 要讲 的 Alternating Direction Method of Multipliers ADMM 就是/d 
期望/v 结合/v 乘子/n 法的弱/nr 条件/n 的/uj 收敛/v 性/n 以及/c 对偶/n 
上升/v 法的/nr 可分解/l 求/v 解性/n ADMM 求解 以下 形式 的 
最小化 问题 其 对应 的 扩展 拉格朗日 表达式 为 ADMM 
包括 以下 迭代 步骤 ADMM/w 其实/d 和/c 乘子/n 法/l 很像/i 
只是 乘子 法里把/nr \ x \ 和\/nr z \ 放 
一块 求解 而 ADMM 是 分开 求解 类似 迭代 一步 
的 Gauss Seidel 方法 其中 3.4 中的 推导 类似于 乘子 
法 只是 使用 了 \ z ^ { k + 
1 } \ 最小化 \ L _ { \ rho 
} x ^ { k + 1 } z y 
^ k \ 其 中用 到了 \ z \ 对应 
的 对偶 可行性 式子 \ \ frac { \ partial 
L } { \ partial z } = \ nabla 
g z + B ^ Ty = 0 \ 定义新 
变量 \ u = \ frac { 1 } { 
\ rho } y \ 那么 3.2 3.4 中的 迭代 
可以 变 为 以下 形式 在 真正 求解 时 通常 
会 使用 所谓 的 over relaxation 方法 也 即在 \ 
z \ 和\/nr u \ 中 使用 下 面的 表达式 
代替 其中 的 \ Ax ^ { k + 1 
} \ \ \ alpha ^ k A x ^ 
{ k + 1 } 1 \ alpha ^ k 
B z ^ k c \ 其中 \ \ alpha 
^ k \ 为 relaxation 因子 有 实验 表明 \ 
\ alpha ^ k \ in 1.5 1.8 \ 可以 
改进 收敛性 2 下面 让 我们 看看 ADMM 怎么 被 
用来 求解 大型 的 机器学习 模型 所谓 的 大型 要不就 
是 样本 数 太多 或者 样本 的 维数 太高 下面 
我们 只 考虑 第 一种 情况 关于 第二 种 情况 
感兴趣 的 读者 可以 参 见 最后 的 参考 文献 
1 2 样本数 太多 无法 一次 全部 导入 内存 常见 
的 处理 方式 是 使用 分布式系统 把 样本 分块 使得 
每块 样 本能 导入到 一台 机器 的 内存 中 当然 
我们 要 的 是 一个 最 终模型 它 的 训练 
过程 利用 了 所有 的 样本数据 常见 的 机器学习 模型 
如下 \ \ text { minimize } _ { x 
} \ sum _ { j = 1 } ^ 
{ J } f _ j x + g x 
\ 其中 \ x \ 为 模型 参数 \ f 
_ j x \ 对应 第 \ j \ 个 
样本 的 损失 函数 而 \ g x \ 为 
惩罚 系数 如 \ g x = | | x 
| | _ 1 \ 假设 把 \ J \ 
个 样本 分成 \ N \ 份 每份 可以 导入 
内存 此时 我们 把 上面 的 问题 重写 为 下面 
的 形式 除了 把 目标函数 分成 \ N \ 块 
还 额外 加了 \ N \ 个 等式 约束 使得 
利用 每块 样本 计算 出来 的 模型 参数 \ x 
_ i \ 都 相等 那么 ADMM 中的 求解 步骤 
3.2 3.4 变为 例如 求解 L1 惩罚 的 LR 模型 
其 迭代 步骤 如下 \ u = \ frac { 
1 } { \ rho } y \ \ g 
z = \ lambda | | z | | _ 
1 \ 其中 \ \ bar { x } \ 
doteq \ frac1N \ sum _ { i } ^ 
N x _ i \ \ \ bar { y 
} \ 的 定义 类似 在 分布式 情况下 为了 计算 
方便 通常 会把 \ u \ 的 更新 步骤 挪 
在 最前面 这样 \ u \ 和\/nr x \ 的 
更新 可以 放在 一块 ADMM 的 框架 确实 很 牛逼 
把 一个 大 问题 分成 可 分布式 同时 求解 的 
多个 小问题 理论上 ADMM 的 框架 可以 解决 大 部分 
实际 中 的 大尺度 问题 我 自己 全部 实现 了 
一遍 这个 框架 主要 用于 求解 LR 问题 下面 说说 
我 碰到 的 一些 问题 1 . 收敛 不够 快 
往往 需要 迭代 几十步 整体 速度 主要 依赖 于\/nr x 
_ i \ 更新 时所/nr 使用 的 优化 方法 个人 
建议 使用 liblinear 里 算法 但是 不能 直接 拿来 就用 
需要 做 一些 调整 2 . 停止 准则 和\/nr \ 
rho \ 的 选取 停止 准则 主要 考量 的 是 
\ x _ i \ 和\/nr z \ 之间 的 
差异 和 它们 本身 的 变动 情况 但 这些 值 
又 受 \ \ rho \ 的 取值 的 影响 
它们 之间 如何 权衡 并 无定法 个人 建议 使用 模型 
在 测试 集上 的 效果 来 确定 是否 停止 迭代 
3 . 不适合 MapReduce 框架 实现 需要 保证 对 数据 
的 分割 自始至终 都 一致 用 MPI 实现 的话 相对于 
其他 算法 又 未必 有 什么 优势 如 L BFGS 
OwLQN 等 4 . relaxation 步骤 要 谨慎 \ \ 
alpha \ 的 取值 依赖 于 具体 的 问题 很多 
时候 的确 可以 加快 收敛 速度 但对 有些 问题 甚至 
可能 带来 不 收敛 的 后果 用 的 时候 不论是 
用 x z u 的 更新 步骤 还是 用 u 
x z 的 更新 步骤 在/p u/w 步/n 使用/v 的/uj 
x/w _/i hat/w 要/v 和在/i z/w 步/n 使用/v 的/uj 相同/d 
使用 旧 的 z 而 不是 使用 z 步刚/nr 更新 
的 z 重算 5 . warm start 和子/nr 问题 求解 
逐渐 精确 的 策略 可以 降低 \ x _ i 
\ 更新 时的/nr 耗时 但也 使得 算法 更加 复杂 需要 
设定 的 参数 也 增加 了 References 1 . Boyd 
. Alternating Direction Method of Multipliers Slides . 2 . 
Boyd et al . Distributed Optimization and Statistical Learning via 
the Alternating Direction Method of Multipliers 2010 . 