机器学习 六 K means 聚 类 算法 想想 常见 的 
分类 算法 有 决策树 Logistic 回归 SVM 贝叶斯 等 分类 
作为 一种 监督 学习 方法 要求 必须 事先 明确 知道 
各个 类别 的 信息 并且 断言 所 有待 分 类项 
都 有一个 类别 与之 对应 但是 很多 时候 上述 条件 
得不到 满足 尤其 是 在 处理 海量 数据 的 时候 
如果 通过 预处理 使得 数据 满足 分类 算法 的 要求 
则 代价 非常大 想想 如果 给 你 50个 G 这么 
大 的 文本 里面 已经 分 好词 这时 需要 将 
其 按照 给定 的 几十 个 关键字 进行 划分 归类 
监督 学习 的 方法 确实 有点 困难 而且 也 不划算 
前期 工作 做 得 太多 了 这时候 可以 考虑 使用 
聚 类 算法 我们 只 需要 知道 这 几十 个 
关键字 是 什么 就 可以 了 聚 类 属于 无 
监督 学习 相比 于 分类 聚 类 不依赖 预定义 的 
类 和类/nr 标号 的 训练 实例 本文 首先 介绍 聚 
类 的 基础 距离 与 相 异度 然后 介绍 一种 
常见 的 聚 类 算法 K means 聚 类 在 
正式 讨论 聚 类 前 我们 要 先 弄 清楚 
一个 问题 如何 定 量计算 两个 可比较 元素 间 的 
相 异度 前面 的 这些 知识 弄 懂了 加上 K 
means 的 定义 基本上 就 可以 大概 理解 K means 
的 算法 了 不算 一个 特别 难 的 算法 用 
通俗 的 话说 相异 度 就是 两个 东西 差 别有 
多大 例如/v 人类/n 与/p 章鱼/nr 的/uj 相/v 异度/i 明显/a 大于/d 
人类/n 与/p 黑猩猩/n 的/uj 相/v 异度/i 这是 能 我们 直观 
感受到 的 但是 计算机 没有 这种 直观 感受 能力 我们 
必须 对 相 异度 在 数学 上 进行 定量 定义 
设 X = { x1 x2 x3 xn } Y 
= { y1 y2 y3 yn }   其中 X 
Y 是 两个 元素 项 各自 具有 n 个 可 
度量 特征 属性 那么/r X/w 和Y的/nr 相/v 异度/i 定义/n 为/p 
d = X Y = f X Y R 其中 
R 为 实 数域 也 就是说 相 异度 是 两个 
元素 对 实 数域 的 一个 映射 所 映射 的 
实数 定量 表示 两个 元素 的 相 异度 下面 介绍 
不同 类型 变量 相 异度 计算方法 标量 标量 也就是 无 
方向 意义 的 数字 也叫 标度 变量 现在 先 考虑 
元素 的 所有 特征 属性 都是 标量 的 情况 例如 
计算 X = { 2 1 102 } 和Y=/nr { 
1 3 2 } 的 相 异度 一种 很 自然 
的 想法 是 用 两者 的 欧几里得 距离 来 作为 
相 异度 欧几里得 距离 的 定义 如下 其 意义 就是 
两个 元素 在 欧氏 空间 中 的 集合 距离 因为 
其 直观 易懂 且 可解释 性强 被 广泛 用于 标识 
两个 标量 元素 的 相 异度 将 上面 两个 示例 
数据 代入 公式 可得 两者 的 欧氏距离 为 除 欧氏距离 
外 常/d 用作/v 度量/n 标量/n 相/v 异度/i 的/uj 还有/v 曼哈顿/ns 
距离/n 和/c 闵可夫/nr 斯基/nr 距离/n 两者 定义 如下 曼哈顿 距离 
闵可夫 斯基 距离 欧氏距离/i 和/c 曼哈顿/ns 距离/n 可以/c 看做/v 是/v 
闵可夫/nr 斯基/nr 距离/n 在/p p/w =/i 2/m 和p=/nr 1/m 下/f 
的/uj 特例/n 0 1 规格化 下面 要说 一下 标量 的 
规格 化 问题 上面/f 这样/r 计算/v 相/v 异度/i 的/uj 方式/n 
有/v 一点/m 问题/n 就是 取值 范围 大 的 属性 对 
距离 的 影响 高于 取值 范围 小 的 属性 例如 
上述 例子 中 第三 个 属性 的 取值 跨度 远大于 
前 两个 这样 不利于 真实 反映 真实 的 相 异度 
为了 解决 这个 问题 一般 要对 属性值 进行 规格化 所谓 
规格化 就是 将 各个 属性值 按比例 映 射到 相同 的 
取值 区间 这样 是 为了 平衡 各个 属性 对 距离 
的 影响 通常 将 各个 属性 均 映 射到 0 
1 区间 映射 公式 为 其中 max ai 和 min 
ai 表示/v 所有/b 元素/n 项中第/nr i/w 个/q 属性/n 的/uj 最大值/l 
和/c 最小值/l 例如 将 示例 中的 元素 规格化 到 0 
1 区间 后 就 变成 了 X = { 1 
0 1 } Y = { 0 1 0 } 
重新 计算 欧氏距离 约为 1.732 二元 变量 所谓 二元 变量 
是 只能 取 0 和1/nr 两种 值 变量 有点 类似 
布尔值 通常 用来 标识 是 或 不是 这种 二 值 
属性 对于 二元 变量 上 一节 提到 的 距离 不能 
很好 标识 其 相 异度 我们 需要 一种 更 适合 
的 标识 一种 常用 的 方法 是 用 元素 相同 
序位 同 值 属性 的 比例 来 标识 其 相 
异度 设有 X = { 1 0 0 0 1 
0 1 1 } Y = { 0 0 0 
1 1 1 1 1 } 可以 看到 两个 元素 
第 2 3 5 7 和 8个 属性 取值 相同 
而 第 1 4 和 6个 取值 不同 那么 相 
异度 可以 标识 为 3/8 = 0.375 一般 的 对于 
二元 变量 相 异度 可用 取值 不同 的 同位 属性 
数 / 单个 元素 的 属性 位数 标识 上面/f 所说/c 
的/uj 相/v 异度/i 应该/v 叫做/v 对称/v 二元/m 相/v 异度/i 现实 
中 还有 一种 情况 就是 我们 只 关心 两者都 取 
1 的 情况 而 认为 两者 都取0/nr 的 属性 并不 
意味着 两者 更 相似 例如 在 根据 病情 对 病人 
聚 类 时 如果 两个人 都 患有 肺癌 我们 认为 
两 个人 增强 了 相似 度 但 如果 两个人 都没 
患 肺癌 并不 觉得 这 加强 了 两人 的 相似性 
在 这种 情况 下 改用 取值 不同 的 同位 属性 
数 / 单个 元素 的 属性 位数 同 取 0 
的 位数 来 标 识相 异度 这 叫做 非对称 二元 
相 异度 如果 用 1 减去 非对称 二元 相 异度 
则 得到 非 对称 二元 相似 度 也叫 Jaccard 系数 
是 一个 非常 重要 的 概念 分类 变量 分类 变量 
是 二元 变量 的 推广 类似于 程序 中的 枚举 变量 
但 各个 值 没有 数字 或 序数 意义 如 颜色 
民族 等等 对于 分类 变量 用 取值 不同 的 同位 
属性 数 / 单个 元素 的 全部 属性 数 来 
标识 其 相 异度 序数 变量 序数 变量 是 具有 
序数 意义 的 分类 变量 通常 可以 按照 一 定顺序 
意义 排列 如 冠军 亚军 和 季军 对于 序数 变量 
一般 为 每个 值 分配 一个 数 叫做 这个 值 
的 秩 然后 以 秩 代替 原值 当做 标量 属性 
计算 相 异度 向量 对于 向量 由于/c 它/r 不仅/c 有/v 
大小/b 而且/c 有/v 方向/n 所以 闵可夫 斯基 距离 不是 度量 
其 相 异度 的 好办法 一种 流行 的 做法 是 
用 两个 向量 的 余弦 度量 这个 应该 大家 都 
知道 吧 其 度量 公式 为 其中 | | X 
| | 表示 X 的 欧几里得 范数 要 注意 余弦 
度量 度量 的 不是 两者 的 相 异度 而是 相似 
度 什么 是 聚 类 所谓 聚 类 问题 就是 
给 定 一个 元素 集合 D 其中 每个 元素 具有 
n 个 可 观察 属性 使用 某种 算法 将 D 
划分 成k个/nr 子集 要求 每个 子集 内部 的 元素 之间 
相 异度 尽可能 低 而 不同 子集 的 元素 相 
异度 尽可能 高 其中 每个 子集 叫 做一个 簇 与 
分类 不同 分类 是 示例 式 学习 要求 分类 前 
明确 各 个 类别 并 断言 每个 元素 映射 到 
一个 类别 而 聚 类 是 观察 式 学习 在 
聚 类 前 可以 不 知道 类别 甚至不 给定 类别 
数量 是 无 监督 学习 的 一种 目前 聚 类 
广泛 应用于 统计学 生物学 数据库 技术 和 市场 营销 等 
领域 相应 的 算法 也 非常 的 多 本文 仅 
介绍 一种 最 简单 的 聚 类 算法 k 均值 
k means 算法 k 均值 算法 的 计算 过程 非常 
直观 1 从D中/nr 随机 取 k 个 元素 作为 k 
个 簇 的 各自 的 中心 2 分别 计算 剩下 
的 元素 到 k 个 簇 中心 的 相 异度 
将 这些 元素 分别 划归 到 相 异度 最低 的 
簇 3 根据 聚 类 结果 重新 计算 k 个 
簇 各自 的 中心 计算 方法 是 取 簇 中 
所有 元素 各自 维度 的 算术 平均数 4 将 D 
中 全部 元素 按照 新的 中心 重新 聚 类 5 
重复 第 4步 直到 聚 类 结果 不再 变化 6 
将 结果 输出 时间 复杂度 O T * n * 
k * m 空间 复杂度 O n * m n 
元素 个数 k 第一步 中 选取 的 元素 个数 m 
每个 元素 的 特征 项 个数 T 第 5步 中 
迭代 的 次数 参考 T2 噬菌体 很多 理解 都是 借鉴 
这位 大牛 的 还在 阅读 学习 TA 的 其他 博文 
K means 聚 类 百度 百科 总结 接下来 的 目标 
就是 Logistic 回归 SVM 之前 看过 很多 遍 有关 这 
两个 算法 的 博客 但是 理解 还是 不够 深入 继续 
学习 希望 有所 收获 