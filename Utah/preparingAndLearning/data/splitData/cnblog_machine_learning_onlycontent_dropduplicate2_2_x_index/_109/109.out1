SVD 奇异 值 分解 SVD 是 一种 可靠 的 正交矩阵 
分 解法 可以 把 A 矩阵 分解成 U ∑ VT 
三个 矩阵 相乘 的 形式 Svd A = U * 
∑ * VT A 不 必是 方阵 U VT 必定 
是 正交 阵 是 对角 阵 以 奇异 值 为 
对角线 其他 全为 0 用途 信息检索 LSA 隐性 语义 索引 
LSA 隐性 语义分析 分解 后的/nr 奇异 值 代表 了 文章 
的 主题 或者 概念 信息检索 的 时候 同义词 或者说 同一 
主题 下 的 词 会 映射 为 同一 主题 这样 
就 可以 提高 搜索 效率 数据压缩 通过 奇异 值 分解 
选择 能量/nr 较大 的 前 N 个 奇异 值 来 
代替 所有 的 数据 信息 这样 可以 降低 噪声 节省 
空间 推荐 系统 主要 是 降噪 矩阵 变换 至 低 
维空间 方便 计算 目前 没有 意识 到 它 对 推荐 
精确度 的 提升 有 什么 具体 作用 原理 矩阵 分解 
矩阵 变换 数据 降 维 基于 协同 过滤 的 推荐 
系统 相关 知识 相似 度 计算 A a1 a2 a3 
B b1 b2 b3 1 . 欧氏距离 相似 度 点到点 
的 距离 在 多维空间 的 推广 | | A B 
| | 表示 A B 的 2 范数 2 . 
皮尔逊 相关系数 3 . 余玄/nr 相似 度 SVD 的 矩阵 
空间 变换 1 . 奇异 值 分解 2 . 奇异 
值 选择 数据 矩阵 重构 协同 过滤 算法 就是 在 
重构 后的/nr 矩阵 空间 上 做 相似 度 计算 下面 
就 机器学习 实战 来看 一下 具 体矩阵 分解 和 奇异 
值 选择 的 操作 后面 会附 上 具体 的 代码 
大家 一看 就 懂 很多 东西 都被 Python 封装 好了 
直接 调用 原始数据 data1 每 一列 代表 一种 商品 每 
一行 代表 一个 用户 数据 是 用户 对 商品 的 
评价 Data M * N 7 * 5 奇异 值 
分解 U M * M 7 * 7 ∑ M 
* N 对角 矩阵 前 N * N 是 对角 
矩阵 对角线 时 奇异 值 后M/nr N 是 0 7 
* 5VT N * N 5 * 5 奇异 值 
选择 ∑ = e1 e2 e3 . . . em 
从 上图 分解 后的∑/nr 可以 看出 前 2个 奇异 值 
之和 远大于 后面 的 奇异 值 所以 说 前 两个 
奇异 值 中 代表 的 信息 足以 描述 整个 数据 
我们 可以 计算 前 x 个 奇异 值得 平方和 占 
所有 奇异 值 的 平方和 的 比例 如果 大于 90% 
我们 就 选 这 x 个 奇异 值 重构 矩阵 
剩余 的 数据 代表 的 可能 是 噪声 无用 数据 
我们 通过 矩阵 重构 来看 一下 理论 是否 正确 矩阵 
重构 U M * X 7 * 2 ∑ X 
* X 2 * 2 以前 X 个 奇异 值 
构建 对角 矩阵 VT x * n 2 * 5A 
重构/n 后的U/nr */i ∑/i */i VT/w 可以/c 发现/v 原始数据/n 中/f 
非零/i 的/uj 部分/n 都/d 完整/a 的/uj 保存/v 了/ul 下来/t 说明 
选择 的 奇异 值 几乎 完整 地 保存 了 所有 
有用/nr 信息 其他 部分 都是 近似 为零 的 小数 将 
他们 损失 精度 强/a 转成/v 整形/b 后/f 就是/d 0强/mq 转/v 
之后/f 如/v 下图/v 原始数据 Data 可以 看到 相比较 于 原始数据 
出现 了 部分 损失 这/r 是/v 由于/c 强/a 转/v 后将/nr 
损失/n 信息/n 放大/v 所致/c 在 浮点数 情况 下 这些 微小 
的 损失 被 忽略 掉了 个人 理解 基于 以下 数据 
data2 做 商品 推荐 行 用户 列 商品 由于 上 
一个 数据集 维数 较低 已经 用于 展示 了 这个 步骤 
中的 操作 下面 就 直接 放 代码 实现 步骤 1 
. 进 行矩阵 奇异 值 分解 2 . 矩阵 进行 
低 维空间 的 映射   降 维 后的/nr 数据 A 
3 . 在 低维 空间 做 相似 度 计算 并 
进行 估计 评分 贴 代码 没有 代码 说 个 卵 
呀 最后 会 放上 源码 python 才 开始 用 可能 
风格 有点 怪异 代码 是 机器学习 实战 的 内容 注释 
也 很多 不 做多 说 了 Exp 用户 A 评价 
了 1 2 3 4 5 这 5个 商品 中的 
1 2 3 用户 B 评价 了 1 2 3 
4 5 这 5个 商品 中的 1 3 4 现在 
要给 A 做 推荐 4 5号 商品 未 评价 过 
的 才 需要 推荐 首先 我们 遍历 A 评价 过得 
商品 的 每 一列 在 矩阵 中 代表 其他 用户 
对 这个 商品 的 评价 然后 和 指定 的 4号 
商品 所在 的 列 做 相似 度 计算 在 这里 
就是 1 2 3 列 分别 于 第四 列 做 
相似 度 计算 给出 一个 评分 然后 1 2 3列 
再与 第 5列 做 相似 度 评分 最终 我们 比较 
4 5 的 估计 评 分值 谁 大 我们 就 
说 喜欢 1 2 3号 商品 的 用户 可能 也 
喜欢 4号 就 以上 的 说明 并 没有 用到 SVD 
我们 再取 数据 的 列 的 时候 并 不是 从原/nr 
矩阵 中 去取 而是/c 从/p 利用/n SVD/w 降/v 维/v 后的/nr 
矩阵/n 中/f 去取/v 这是 唯 一用到 SVD 的 部分 根据 
评分 推荐 遍历 所有 未 评分 的 商品 进行 评分 
然后 排序 取 TOPN 这里 选 三个 输出 的 结果 
就是 给 这个 用户 推荐 的 商品 基于 SVD 实现 
的 数据压缩 SVD 数据压缩 说白 了 就是 奇异 值 分解 
后 A 可以 近似 的 用 U * ∑ * 
VT 表示 A 原始 的 A 需要 M * N 
个 存储空间 我们 现在 只 需要 存储 U ∑ VT 
三个 矩阵 在 使用 的 时候 做 乘积 就 可以 
得到 A 而且 U ∑ VT 需要 的 空间 M 
* X + X * X + X * N 
远 小于 M * N 这就 实现 了 数据压缩 从M*/nr 
N 压缩 到了 M * X + X * X 
+ X * NExp 对 一个 图像 数据 进行 压缩 
32 * 32 的 图像 数据 总 空间 需要 32 
* 32 = 1024 压缩 前 压缩 后 还原 可以/c 
发现/v 有/v 微小/b 的/uj 差异/n 压缩/v 后的/nr 三个/m 矩阵/n sigma 
2 VT 2 * 32 U 32 * 2 总 
空间 = 130 相比 1024 极大 缩小 了 占有 空间 
源代码 p y 2.7 可直接 运行 1 # * coding 
utf 8 * 2 # Filename svd . py 3 
# Author Ljcx 4 5 6 from numpy import * 
7 8 9 class Svd object 10 11 def loadExData 
self 12 data = 0 0 0 2 2 13 
0 0 0 3 3 14 0 0 0 1 
1 15 1 1 1 0 0 16 2 2 
2 0 0 17 5 5 5 0 0 18 
1 1 1 0 0 19 return data 20 21 
def loadExData2 self 22 23 列 表示 商品 行 表示 
用户 的 评分 24 25 return 0 0 0 0 
0 4 0 0 0 0 5 26 0 0 
0 3 0 4 0 0 0 0 3 27 
0 0 0 0 4 0 0 1 0 4 
0 28 3 3 4 0 0 0 0 2 
2 0 0 29 5 4 5 0 0 0 
0 5 5 0 0 30 0 0 0 0 
5 0 1 0 0 5 0 31 4 3 
4 0 0 0 0 5 5 0 1 32 
0 0 0 4 0 4 0 0 0 0 
4 33 0 0 0 2 0 2 5 0 
0 1 2 34 0 0 0 0 5 0 
0 0 0 4 0 35 1 0 0 0 
0 0 0 1 2 0 0 36 37 # 
相似 度 计算 inA inB 为 列 向量 还是 行向量 
基于 我们 需要 计算 相似 的 维度 38 def ecludSim 
self inA inB 39 norm 求 范数 40 范数 表示 
数值 平方 开方 inA inB 的 范数 = inA 和 
inB 的 欧氏距离 41 42 return 1.0 / 1.0 + 
linalg . norm inA inB 43 44 def pearsSim self 
inA inB 45 corrcoef 求 皮尔逊 相关系数 1 1 46 
皮尔逊 相关系数 0.5 + 0.5 * corrcoef 规范化 到 0 
1 47 48 if len inA 3 49 return 1.0 
50 return 0.5 + 0.5 * corrcoef inA inB rowvar 
= 0 0 1 51 52 def cosSim self inA 
inB 53 54 余玄/nr 相似 度 即 两个 向量 的 
余玄/nr 夹角 值 1 1 55 56 num = float 
inA . T * inB 57 denom = linalg . 
norm inA * linalg . norm inB 58 return 0.5 
+ 0.5 * num / denom 59 60 # 奇异 
值 分解 = = 矩阵 重构 可 用于 图像压缩 61 
def svdMt self data 62 63 奇异 值 分解 矩阵 
data = U * Sigma * VT 用 分解 后的/nr 
矩阵 可以 近似 地 表示 原 矩阵 64 节省 空间 
65 Sigma 是个 奇异 值 方阵 66 67 U Sigma 
VT = linalg . svd data 68 前 两个 奇异 
值 已经 几乎 包含 了 所有 的 信息 远 大于 
后 三个 数据 所以 忽略 掉 后 三个 69 数据 
70 启发式 搜索 选择 奇异 之 平方和 大于 总平方和 90% 
为 标准 71 72 num = 0 # 需要 保存 
的 奇异 值 个数 73 for i in range len 
Sigma 74 if linalg . norm Sigma i + 1 
/ linalg . norm Sigma 0.9 75 num = i 
+ 1 76 break 77 # 构建 对角 矩阵 78 
sig3 = mat eye num * Sigma num 79 选取 
前 num 个 奇异 值 重构 数据集 80 81 newData 
= U num * mat sig3 * VT num 82 
print newData 83 print newData . astype int 84 return 
U Sigma VT num newData 85 86 87 基于 相似 
度 的 推荐 引擎 88 只 需要 对 用户 所购 
商品 和 其他 商品 做 相似 度 计算 选取 TOPn 
个 作为 推荐 89 基于 SVD 的 推荐 引擎 90 
先 进行 奇异 值 分解 选取 前 n 个 奇异 
值 能量 之和 大于 90% 奇异 之 平方和 大于 总平方和 
91 90% 为 标准 作为 需要 降 维 的 维数 
原 数据 往 低 维空间 投影 Data . T * 
U n * Sigma 4 92 寻找 指定 一个 商品 
的 所有 评分 x 和每/nr 一个 商品 的 所有 评 
分做 相似 度 计算 相似 度 求和 93 94 95 
# 相似 度 推荐 96 def standEst self 97 pass 
98 99 def svdEst self dataMat xformedItems user simMeas item 
100 计算 相似 度 并 计算 评分 101 # dataMat 
原始数据 102 # user 用户 编号 103 # simMeas 相似 
度 计算方法 104 # item 商品编号 105 # xformedItems 降 
维 后的/nr 数据 106 107 n = shape dataMat 1 
# 获取 列 多少 个 商品 108 simTotal = 0.0 
109 ratSimTotal = 0.0 110 # 计算 指定 用户 评价 
过 的 商品 与 其他 所有 用户 的 评价 过 
的 商品 做 相似 度 计算 来 估计 111 # 
指定 的 未 评价 商品 item 的 评分 112 for 
j in range n 113 userRating = dataMat user j 
114 if userRating = = 0 or j = = 
item 115 continue 116 similarity = simMeas xformedItems item . 
T xformedItems j . T 117 print the % d 
and % d similarity is % f % item j 
similarity 118 simTotal + = similarity # 相似 度 求和 
119 ratSimTotal + = similarity * userRating # 相似 度 
乘以 评 分在 求和 120 if simTotal = = 0 
121 return 0 122 else 123 return ratSimTotal / simTotal 
# 根据 相似 度 对 一个 指定 商品 给 一个 
评分 124 125 def recommend self dataMat user N = 
3 simMeas = cosSim estMethod = svdEst 126 127 # 
根据 SVD 空间 评分 推荐 寻找 所有 该 用户 未 
评分 的 商品 对 每个 商品 进行 评分 估计 128 
129 unratedItems = nonzero dataMat user . A = = 
0 1 # findunrated items 130 if len unratedItems = 
= 0 131 return you rated everything 132 U Sigma 
VT num newData = self . svdMt dataMat 133 sig 
= mat eye num * Sigma num # 构建 对角 
矩阵 134 xformedItems = dataMat . T * U num 
* sig . I # 数据 投影 降 维 135 
print xform 136 print xformedItems 137 itemScores = 138 for 
item in unratedItems 139 estimatedScore = estMethod 140 dataMat xformedItems 
user simMeas item # 评分 141 itemScores . append item 
estimatedScore 142 return sorted itemScores key = lambda jj jj 
1 reverse = True N 143 144 def loadImageData self 
145 146 加载 图像 数据 147 148 fp = open 
image . txt r 149 imageData = 150 for line 
in fp . readlines 151 lineData = 152 for i 
in range len line 1 153 lineData . append int 
line i 154 imageData . append lineData 155 return mat 
imageData 156 157 def imageCompress self 158 svd 图像压缩 = 
= 分解 矩阵 之后 选择 几个 重要 的 奇异 值 
对 U Sigma VT 进行 切割 159 切割 后的/nr 矩阵 
的 乘积 仍 可以 表示 原 矩阵 我们 只需 存储 
这三个 矩阵 就 可以 在 使用 的 时候 160 还原 
原 矩阵 了 161 162 data = self . loadImageData 
163 self . printMat data 0.8 # 压缩 前 数据 
164 print 165 U Sigma VT num newData = self 
. svdMt data 166 self . printMat newData 0.8 # 
压缩 后 还原 的 数据 167 print Sigma 168 print 
num + str num 169 print 前 % d 个 
奇异 值 的 平方 和 达到 了 所有 奇异 值 
平方和 的 0.9 以上 则 2个 奇异 值 重构 矩阵 
可表示 原 矩阵 % num 170 U = U num 
171 Sigma = Sigma num 172 VT = VT num 
173 print U + str shape U 174 print U 
175 print Sigma + str shape Sigma 176 print Sigma 
177 print VT + str shape VT 178 print VT 
179 print 压缩 前 存储空间 str shape data 0 * 
shape data 1 180 print 压缩 后 存储空间 str shape 
U 0 * shape U 1 181 + shape Sigma 
0 * shape Sigma 0 182 + shape VT 0 
* shape VT 1 183 184 def printMat self inMat 
thresh = 0.8 185 for i in range 32 186 
for k in range 32 187 if float inMat i 
k thresh 188 print 1 189 else 190 print 0 
191 print 192 193 194 if _ _ name _ 
_ = = _ _ main _ _ 195 sd 
= Svd 196 data = sd . loadExData2 197 sd 
. recommend mat data 2 3 sd . cosSim sd 
. svdEst 198 sd . imageCompress View Code 