机器学习 算法 原理 实现 与 实践 机器 学习 的 三要素 
1 模型 在 监督 学习 中 模型 就是 所 要 
学习 的 条件 概率分布 或 决策函数 模型 的 假设 空间 
包含 所有 可能 的 条件 概率分布 或 决策函数 例如 假设 
决策函数 是 输入 变量 的 线性函数 那么 模型 的 假设 
空间 就是 这些 线性函数 构成 的 函数 的 集合 假设 
空间 用 $ \ mathcal { F } $ 表示 
假设 空间 可以 定义 为 决策 函数 的 集合 $ 
$ \ mathcal { F } = \ { f 
| Y = f X \ } $ $ 其中 
$/i X/w $/i 和$Y/nr $/i 是/v 定义/n 在/p 输入/v 空间/n 
$/i \/i mathcal/w {/i X/w }/i $/i 和/c 输出/v 空间/n 
$/i \/i mathcal/w {/i Y/w }/i $/i 上/f 的/uj 变量/vn 
这时 $ \ mathcal { F } $ 通常 是 
由 一个 参数 向量 决定 的 函数 族 $ $ 
\ mathcal { F } = \ { f | 
Y = f _ { \ theta } X \ 
theta \ in \ mathbf { R } ^ n 
\ } $ $ 参数 向量 $ \ theta $ 
取值 于$n/nr $ 维 欧氏 空间 $ \ mathbf { 
R } ^ n $ 称为 参数 空间 parameter space 
假设 空间 也 可以 定义 为 条件 概率 的 集合 
$ $ \ mathcal { F } = \ { 
P | P Y | X \ } $ $ 
其中 $/i X/w $/i 和$Y/nr $/i 是/v 定义/n 在/p 输入/v 
空间/n $/i \/i mathcal/w {/i X/w }/i $/i 和/c 输出/v 
空间/n $/i \/i mathcal/w {/i Y/w }/i $/i 上/f 的/uj 
变量/vn 这时 $ \ mathcal { F } $ 通常 
是 由 一个 参数 向量 决定 的 条件 概率分布 族 
$ $ \ mathcal { F } = \ { 
P | P _ { \ theta } Y | 
X \ theta \ in \ mathbf { R } 
^ n \ } $ $ 称 由 决策函数 表示 
的 模型 为非 概率模型 由 条件概率 表示 的 模型 为 
概率模型 2 策略 有了 模型 的 假设 空间 机器学习 接着 
要 考虑 的 是 按照 什么样 的 准则 学习 或 
选择 最优 的 模型 首先 引入 损失 函数 与 风险 
函数 的 概念 损失 函数 度量 模型 一次 预测 的 
好坏 风险 函数 度量 平均 意义 下 模型 预测 的 
好坏 2.1 损失 函数 与 风险 函数 对于 给定 的 
输入 $ X $ 和 假设 空间 $ \ mathcal 
{ F } $ 中 选择 的 决策函数 模型 $ 
f $ 由 $ f X $ 给出 相应 的 
输入 $ Y $ 这个 输出 的 预 没 值 
$ f X $ 与 真实 值 $ Y $ 
可能 一致 也 可能 不 一致 用 一个 损失 函数 
或 代价 函 数来 度量 预测 的 错误 程度 损失 
函数 是 $ f x $ 和$Y/nr $ 的 非 
负 实值函数 记作 $ L Y f X $ 几种 
常用 的 损失 函数 1 0 1 损失 函数 0 
1 loss function $ $ L Y f X = 
\ begin { cases } 1 & Y \ neq 
f X \ \ 0 & Y = f X 
\ end { cases } $ $ 2 平方 损失 
函数 quadratic loss function $ $ L Y f X 
= Y – f X ^ 2 $ $ 3 
绝对 损失 函数 absolute loss function $ $ L Y 
f X = | Y f X | $ $ 
4 对数 损失 函数 logarithmic loss function 或 对数 似 
然 损失 函数 $ $ L Y P Y | 
X = – logP Y | X $ $ 损失 
函数值 越小 模型 就 越好 由于 模型 的 输入 输出 
$ X Y $ 是 随机变量 遵循 联合 分布 $ 
P X Y $ 所以 损失 函数 的 期望 是 
$ $ R _ { exp } f = E 
_ P L Y f X = \ int _ 
{ \ mathcal { X } \ times \ mathcal 
{ Y } } L y f x P x 
y dxdy $ $ 这是 理论上 模型 $ f X 
$ 关于 联合 分布 $ P X Y $ 的 
平均 意义 下 的 损失 称为 风险 函数 risk function 
或 期望 损失 expected loss 学习 的 目标 就是 选择 
期望 风险 最小 的 模型 由于 联合 分布 $ P 
X Y $ 是 所有 样本 所 遵循 的 统计 
规律 它 是 未知 的 所以 $ R _ { 
exp } f $ 不能 直接 计算 实际上 如果 知道 
了 联合 分布 那么 可以 直接 计算出 $ P Y 
| X = \ int _ { \ mathcal { 
X } } P x y dx $ 也就 不 
需要 学习 了 所以 用 上面 那种 方式 定义 风险 
函数 是 不行 的 那样的话 监督 学习 变成 了 一个 
病态 问题 对于 给定 的 训练 数据集 $ $ T 
= { x _ 1 y _ 1 x _ 
2 y _ 2 \ dots x _ N y 
_ N } $ $ 模型 $ f X $ 
关于 训练 数据集 的 平均 损失 称为 经验 风险 empirical 
risk 或 经验 损失 empirical loss 记作 $ R _ 
{ emp } $ $ $ R _ { emp 
} f = \ frac { 1 } { N 
} \ sum _ { i = 1 } ^ 
NL y _ i f x _ i $ $ 
期望 风险 $ R _ { exp } f $ 
是 模型 关于 联合 分布 的 期望 损失 经验 风险 
$ R _ { emp } f $ 是 模型 
关于 训练样本 集 的 平均 损失 根据 大数 定律 当 
样本容量 $ N $ 趋于 无穷 时 经验 风险 $ 
R _ { emp } f $ 趋向于 期望 风险 
$ R _ { exp } f $ 所以 一个 
很 自然 的 想法 是 用 经验 风险估计 期望 风险 
但是 由于 现实 中 训练样本 数目 很 有限 所以 用 
经验 风险估计 期望 风险 常常 不 理想 要对 经验 风险 
进行 一定 的 矫正 这就 关系 到 监督 学习 的 
两个 基本 策略 经验 风险 最小化 和 结构 风险 最小化 
2.2 经验 风险 最小化 与 结构 风险 最小化 在 假设 
空间 损失 函数 以及 训练 数据集 确定 的 情况 下 
经验 风险 函 数式 就 可以 确定 经验 风险 最小化 
的 策略 认为 经验 风险 最小 的 模型 就 是 
最优 的 模型 根据 这 一 策略 按照 经验 风险 
最小化 求 最佳 模型 就是 求解 最优化 问题 $ $ 
\ min _ { f \ in \ mathcal { 
F } } \ frac { 1 } { N 
} \ sum _ { i = 1 } ^ 
NL y _ i f x _ i $ $ 
其中 $ \ mathcal { F } $ 是 假设 
空间 当 样本容量 足够 大 时 经验/n 风险/n 最小化/l 能/v 
保证/v 有/v 很好/i 的/uj 学习/v 效果/n 在 现实 中 广泛 
采用 比如 极大 似 然 估计 就 是 经验 风险 
最小化 的 一个 例子 当 模型 是 条件 概率分布 损失 
函数 是 对数 损失 函数 时 经验 风险 最小化 就 
等价 于 极大 似 然 估计 但是 当 样本容量 很 
小时 经验 风险 最小化 学习 效果 就 未必 很好 会 
产生 过拟合 over fitting 现象 结构 风险 最小化 structural risk 
minimization SRM 是 为了 防止 过拟合 而提 出来 的 策略 
结构 风险 最小化 等价 于 正则化 结构 风险 在 经验 
风险 上加 上 表示 模型 复杂度 的 正则化 项或罚/nr 项 
在 假设 空间 损失 函数 以及 训练 样 本集 确定 
的 情况 下 结构 风险 的 定义 是 $ $ 
R _ { srm } f = \ frac { 
1 } { N } \ sum _ { i 
= 1 } ^ NL y _ i f x 
_ i + \ lambda J f $ $ 其中 
$ J f $ 为 模型 的 复杂度 是 定义 
在 假设 空间 $ \ mathcal { F } $ 
上 的 泛 函 模型 $ f $ 越 复杂 
复杂度 $ J f $ 就 越大 反之 模型 $ 
f $ 越 简单 复杂度 $ J f $ 就 
越小 也 就是说 复杂度 表示 了 对 复杂 模型 的 
惩罚 $ \ lambda \ ge 0 $ 是 系数 
用以 权衡 经验 风险 和 模型 的 复杂度 结构 风险 
小 需要 经验 风险 与 模型 复杂度 同时 小 结构 
风险 小 的 模型 往往 对 训练 数据 以及 未知 
的 测试数据 都有 较好 的 预测 比如 贝叶斯 估计 中 
的 最大 后验/nr 概率 估计 maximum posterior probability estimation MAP 
就是 结构 风险 最小化 的 例子 当 模型 是 条件 
概率分布 损失 函数 就是 对数 损失 函数 模型 复杂度 由 
模型 的 先验概率 表示 时 结构/n 风险/n 最小化/l 就/d 等价/n 
于/p 最大/a 后验/nr 概率/n 估计/v 结构 风险 最小化 的 策略 
认为 结构 风险 最小 的 模型 是 最优 的 模型 
所 以求 最优化 模型 时 就是 求解 最优化 问题 $ 
$ \ min _ { f \ in \ mathcal 
{ F } } \ frac { 1 } { 
N } L y _ i f x _ i 
+ \ lambda J f $ $ 这样 监督 学习 
问题 就 变成 了 经验 风险 或 结构 风险 函数 
的 最优 化 问题 这时 经验 或 结构 风险 函数 
是 最 优化 的 目标 函数 3 算法 从 上面 
可以 看出 在 确定 寻找 最优 模型 的 策略 后 
机器学习 的 问题 归结为 最 优化 的 问题 机器学习 讨论 
的 算法 问题 就 成为 了 求解 最优化 模型 解的/nr 
算法 而且 往往 最 优化 模型 没有 的 解析 解 
需要用 数值 计算 的 方法 求解 我们 要 确保 找到 
全局 最优 解 以及 使 求解 的 过程 非常 高效 
