原创 文章 同步 首 发自 作者 个人 博客 转载 请 
务必 在 文章 开头 显眼 处 注明 出处 摘要 本文 
详述 了 如何 通过 数据 预览 探索 式 数据分析 缺失 
数据 填补 删除 关联 特征 以及 派生 新 特征 等 
方法 在 Kaggle 的 Titanic 幸存 预测 这 一分 类 
问题 竞赛 中 获得 前 2% 排名 的 具体 方法 
竞赛 内容 介绍 Titanic 幸存 预测 是 Kaggle 上 参赛 
人数 最多 的 竞赛 之一 它 要求 参赛 选手 通过 
训练 数据集 分析 出 什么 类型 的 人 更 可能 
幸存 并 预测 出 测试数据 集中 的 所有 乘客 是否 
生还 该 项目 是 一个 二元 分类 问题 如何 取得 
排名 前 2% 的 成绩 加载 数据 在 加载 数据 
之前 先 通过 如下 代码 加载 之后 会 用到 的 
所有 R 库 library readr # File read / write 
library ggplot2 # Data visualization library ggthemes # Data visualization 
library scales # Data visualization library plyr library stringr # 
String manipulation library InformationValue # IV / WOE calculation library 
MLmetrics # Mache learning metrics . e . g . 
Recall Precision Accuracy AUC library rpart # Decision tree utils 
library randomForest # Random Forest library dplyr # Data manipulation 
library e1071 # SVM library Amelia # Missing value utils 
library party # Conditional inference trees library gbm # AdaBoost 
library class # KNN library scales 通过/p 如下/t 代码/n 将/d 
训练/vn 数据/n 和/c 测试数据/n 分别/d 加载/v 到/v 名为/v train/w 和/c 
test/w 的/uj data/w ./i frame/w 中/f train/w read _ csv 
train . csv test read _ csv test . csv 
由于 之后 需要 对 训练 数据 和 测试 数据 做 
相同 的 转换 为 避免 重复 操作 和 出现 不一 
至 的 情况 更 为了 避免 可能 碰到 的 Categorical 
类型 新 level 的 问题 这里 建议 将 训练 数据 
和 测试数据 合并 统一 操作 data bind _ rows train 
test train . row 1 nrow train test . row 
1 + nrow train nrow train + nrow test 数据 
预览 先 观察 数据 str data # # Classes tbl 
_ df tbl and data . frame 1309 obs . 
of 12 variables # # $ PassengerId int 1 2 
3 4 5 6 7 8 9 10 . . 
. # # $ Survived int 0 1 1 1 
0 0 0 0 1 1 . . . # 
# $ Pclass int 3 1 3 1 3 3 
1 3 3 2 . . . # # $ 
Name chr Braund Mr . Owen Harris Cumings Mrs . 
John Bradley Florence Briggs Thayer Heikkinen Miss . Laina Futrelle 
Mrs . Jacques Heath Lily May Peel . . . 
# # $ Sex chr male female female female . 
. . # # $ Age num 22 38 26 
35 35 NA 54 2 27 14 . . . 
# # $ SibSp int 1 1 0 1 0 
0 0 3 0 1 . . . # # 
$ Parch int 0 0 0 0 0 0 0 
1 2 0 . . . # # $ Ticket 
chr A / 5 21171 PC 17599 STON / O2 
. 3101282 113803 . . . # # $ Fare 
num 7.25 71.28 7.92 53.1 8.05 . . . # 
# $ Cabin chr NA C85 NA C123 . . 
. # # $ Embarked chr S C S S 
. . . 从上 可见 数据集 包含 12个 变量 1309条 
数据 其中 891条 为 训练 数据 418条 为 测试数据 PassengerId 
整型 变量 标识 乘客 的 ID 递增 变量 对 预测 
无帮助 Survived 整型 变量 标识 该 乘客 是否 幸存 0 
表示 遇难 1 表示 幸存 将其 转换 为 factor 变量 
比较 方便 处理 Pclass 整型 变量 标识 乘客 的 社会 
经济 状态 1 代表 Upper 2 代表 Middle 3 代表 
LowerName 字符 型 变量 除 包含 姓 和名/nr 以外 还 
包含 Mr . Mrs . Dr . 这样 的 具有 
西方 文化 特点 的 信息 Sex 字符 型 变量 标识 
乘客 性别 适合 转换 为 factor 类型 变量 Age 整型 
变量 标识 乘客 年龄 有 缺失 值 SibSp 整型 变量 
代表 兄弟姐妹 及 配偶 的 个数 其中 Sib 代表 Sibling 
也即 兄弟姐妹 Sp 代表 Spouse 也即 配偶 Parch 整型 变量 
代表 父母 或 子女 的 个数 其中 Par 代表 Parent 
也即 父母 Ch 代表 Child 也即 子女 Ticket 字符 型 
变量 代表 乘客 的 船票 号 Fare 数值 型 代表 
乘客 的 船票 价 Cabin 字符 型 代表 乘客 所在 
的 舱位 有 缺失 值 Embarked 字符 型 代表 乘客 
登船 口岸 适合 转换 为 factor 型 变量 探索 式 
数据分析 乘客 社会等级 越高 幸存 率 越高 对于 第一个 变量 
Pclass 先 将其 转换 为 factor 类型 变量 data $ 
Survived factor data $ Survived 可 通过 如下 方式 统计 
出 每个 Pclass 幸存 和 遇难 人数 如下 ggplot data 
= data 1 nrow train mapping = aes x = 
Pclass y = . . count . . fill = 
Survived + geom _ bar stat = count position = 
dodge + xlab Pclass + ylab Count + ggtitle How 
Pclass impact survivor + scale _ fill _ manual values 
= c # FF0000 # 00FF00 + geom _ text 
stat = count aes label = . . count . 
. position = position _ dodge width = 1 vjust 
= 0.5 + theme plot . title = element _ 
text hjust = 0.5 legend . position = bottom 从 
上图 可见 Pclass = 1 的 乘客 大 部分 幸存 
Pclass = 2 的 乘客 接近 一半 幸存 而 Pclass 
= 3 的 乘客 只有 不到 25% 幸存 为了 更为 
定量 的 计算 Pclass 的 预测 价值 可以 算出 Pclass 
的 WOE 和 IV 如下 从 结果 可以 看出 Pclass 
的 IV 为 0.5 且 Highly Predictive 由此 可以 暂时 
将 Pclass 作为 预测模型 的 特征 变量 之一 WOETable X 
= factor data $ Pclass 1 nrow train Y = 
data $ Survived 1 nrow train # # CAT GOODS 
BADS TOTAL PCT _ G PCT _ B WOE IV 
# # 1 1 136 80 216 0.3976608 0.1457195 1.0039160 
0.25292792 # # 2 2 87 97 184 0.2543860 0.1766849 
0.3644848 0.02832087 # # 3 3 119 372 491 0.3479532 
0.6775956 0.6664827 0 . 21970095IV X = factor data $ 
Pclass 1 nrow train Y = data $ Survived 1 
nrow train # # 1 0.5009497 # # attr howgood 
# # 1 Highly Predictive 不同 Title 的 乘客 幸存 
率 不同 乘客 姓名 重复 度 太低 不适合 直接 使用 
而 姓名 中 包含 Mr . Mrs . Dr . 
等 具有 文化 特征 的 信息 可 将之 抽 取出来 
本文 使用 如下 方式 从 姓名 中 抽取 乘客 的 
Titledata $ Title sapply data $ Name FUN = function 
x { strsplit x split = . 1 2 } 
data $ Title sub data $ Title data $ Title 
data $ Title % in % c Mme Mlle Mlle 
data $ Title data $ Title % in % c 
Capt Don Major Sir Sir data $ Title data $ 
Title % in % c Dona Lady the Countess Jonkheer 
Lady data $ Title factor data $ Title 抽取 完 
乘客 的 Title 后 统计 出 不同 Title 的 乘客 
的 幸存 与 遇难 人数 ggplot data = data 1 
nrow train mapping = aes x = Title y = 
. . count . . fill = Survived + geom 
_ bar stat = count position = stack + xlab 
Title + ylab Count + ggtitle How Title impact survivor 
+ scale _ fill _ discrete name = Survived breaks 
= c 0 1 labels = c Perish Survived + 
geom _ text stat = count aes label = . 
. count . . position = position _ stack vjust 
= 0.5 + theme plot . title = element _ 
text hjust = 0.5 legend . position = bottom 从 
上图 可 看出 Title 为 Mr 的 乘客 幸存 比例 
非常 小 而 Title 为 Mrs 和 Miss 的 乘客 
幸存 比例 非常 大 这里 使用 WOE 和 IV 来 
定 量计算 Title 这一 变量 对于 最终 的 预测 是否 
有用 从 计算结果 可见 IV 为 1.520702 且 Highly Predictive 
因此 可 暂 将 Title 作为 预测模型 中 的 一个 
特征 变量 WOETable X = data $ Title 1 nrow 
train Y = data $ Survived 1 nrow train # 
# CAT GOODS BADS TOTAL PCT _ G PCT _ 
B WOE IV # # 1 Col 1 1 2 
0.002873563 0.001808318 0.46315552 4.933741 e 04 # # 2 Dr 
3 4 7 0.008620690 0.007233273 0.17547345 2.434548 e 04 # 
# 3 Lady 2 1 3 0.005747126 0.001808318 1.15630270 4.554455 
e 03 # # 4 Master 23 17 40 0.066091954 
0.030741410 0.76543639 2.705859 e 02 # # 5 Miss 127 
55 182 0.364942529 0.099457505 1.30000942 3.451330 e 01 # # 
6 Mlle 3 3 3 0.008620690 0.005424955 0.46315552 1.480122 e 
03 # # 7 Mr 81 436 517 0.232758621 0.788426763 
1.22003757 6.779360 e 01 # # 8 Mrs 99 26 
125 0.284482759 0.047016275 1.80017883 4.274821 e 01 # # 9 
Ms 1 1 1 0.002873563 0.001808318 0.46315552 4.933741 e 04 
# # 10 Rev 6 6 6 0.017241379 0.010849910 0.46315552 
2.960244 e 03 # # 11 Sir 2 3 5 
0.005747126 0.005424955 0.05769041 1.858622 e 05IV X = data $ 
Title 1 nrow train Y = data $ Survived 1 
nrow train # # 1 1.487853 # # attr howgood 
# # 1 Highly Predictive 女性 幸存 率 远 高于 
男性 对于 Sex 变量 由 Titanic 号 沉没 的 背景 
可知 逃 生时 遵循 妇女 与 小孩 先走 的 规则 
由此 猜想 Sex 变量 应该 对 预测 乘客 幸存 有帮助 
如下 数据验证 了 这一 猜想 大部分 女性 233 / 233 
+ 81 = 74.20% 得以 幸存 而 男性 中 只有 
很 小部分 109 / 109 + 468 = 22.85% 幸存 
data $ Sex as . factor data $ Sex ggplot 
data = data 1 nrow train mapping = aes x 
= Sex y = . . count . . fill 
= Survived + geom _ bar stat = count position 
= dodge + xlab Sex + ylab Count + ggtitle 
How Sex impact survivo + geom _ text stat = 
count aes label = . . count . . position 
= position _ dodge width = 1 vjust = 0.5 
+ theme plot . title = element _ text hjust 
= 0.5 legend . position = bottom 通过 计算 WOE 
和 IV 可知 Sex 的 IV 为 1.34 且 Highly 
Predictive 可 暂 将 Sex 作 为特征 变量 WOETable X 
= data $ Sex 1 nrow train Y = data 
$ Survived 1 nrow train # # CAT GOODS BADS 
TOTAL PCT _ G PCT _ B WOE IV # 
# 1 female 233 81 314 0.6812865 0.147541 1.5298770 0.8165651 
# # 2 male 109 468 577 0.3187135 0.852459 0.9838327 
0 . 5251163IV X = data $ Sex 1 nrow 
train Y = data $ Survived 1 nrow train # 
# 1 1.341681 # # attr howgood # # 1 
Highly Predictive 未成年人 幸存 率 高于 成年人 结合 背景 按照 
妇女 与 小孩 先走 的 规则 未成年人 应该 有 更大 
可能 幸存 如下 图 所示 Age 18 的 乘客 中 
幸存 人数 确实 高于 遇难 人数 同时 青壮年 乘客 中 
遇难 人数 远 高于 幸存 人数 ggplot data = data 
is . na data $ Age & row data Age 
= 891 aes x = Age color = Survived + 
geom _ line aes label = . . count . 
. stat = bin binwidth = 5 + labs title 
= How Age impact survivor x = Age y = 
Count fill = Survived # # Warning Ignoring unknown aesthetics 
label 配偶 及 兄弟 姐妹 数 适中 的 乘客 更易 
幸存 对于 SibSp 变量 分别 统计 出 幸存 与 遇难 
人数 ggplot data = data 1 nrow train mapping = 
aes x = SibSp y = . . count . 
. fill = Survived + geom _ bar stat = 
count position = dodge + labs title = How SibSp 
impact survivor x = Sibsp y = Count fill = 
Survived + geom _ text stat = count aes label 
= . . count . . position = position _ 
dodge width = 1 vjust = 0.5 + theme plot 
. title = element _ text hjust = 0.5 legend 
. position = bottom 从 上图 可见 SibSp 为 0 
的 乘客 幸存 率 低于 1/3 SibSp 为 1 或 
2 的 乘客 幸存 率 高于 50% SibSp 大于 等于 
3 的 乘客 幸存 率 非常 低 可 通过 计算 
WOE 与 IV 定 量计算 SibSp 对 预测 的 贡献 
IV 为 0.1448994 且 Highly Predictive WOETable X = as 
. factor data $ SibSp 1 nrow train Y = 
data $ Survived 1 nrow train # # CAT GOODS 
BADS TOTAL PCT _ G PCT _ B WOE IV 
# # 1 0 210 398 608 0.593220339 0.724954463 0.2005429 
0.026418349 # # 2 1 112 97 209 0.316384181 0.176684882 
0.5825894 0.081387334 # # 3 2 13 15 28 0.036723164 
0.027322404 0.2957007 0.002779811 # # 4 3 4 12 16 
0.011299435 0.021857923 0.6598108 0.006966604 # # 5 4 3 15 
18 0.008474576 0.027322404 1.1706364 0.022063953 # # 6 5 5 
5 5 0.014124294 0.009107468 0.4388015 0.002201391 # # 7 8 
7 7 7 0.019774011 0.012750455 0.4388015 0 . 003081947IV X 
= as . factor data $ SibSp 1 nrow train 
Y = data $ Survived 1 nrow train # # 
1 0.1448994 # # attr howgood # # 1 Highly 
Predictive 父母 与 子女 数 为 1 到 3 的 
乘客 更 可能 幸存 对于 Parch 变量 分别 统计 出 
幸存 与 遇难 人数 ggplot data = data 1 nrow 
train mapping = aes x = Parch y = . 
. count . . fill = Survived + geom _ 
bar stat = count position = dodge + labs title 
= How Parch impact survivor x = Parch y = 
Count fill = Survived + geom _ text stat = 
count aes label = . . count . . position 
= position _ dodge width = 1 vjust = 0.5 
+ theme plot . title = element _ text hjust 
= 0.5 legend . position = bottom 从 上图 可见 
Parch 为 0 的 乘客 幸存 率 低于 1/3 Parch 
为 1 到 3 的 乘客 幸存 率 高于 50% 
Parch 大于 等于 4 的 乘客 幸存 率 非常 低 
可 通过 计算 WOE 与 IV 定 量计算 Parch 对 
预测 的 贡献 IV 为 0.1166611 且 Highly Predictive WOETable 
X = as . factor data $ Parch 1 nrow 
train Y = data $ Survived 1 nrow train # 
# CAT GOODS BADS TOTAL PCT _ G PCT _ 
B WOE IV # # 1 0 233 445 678 
0.671469741 0.810564663 0.1882622 0.026186312 # # 2 1 65 53 
118 0.187319885 0.096539162 0.6628690 0.060175728 # # 3 2 40 
40 80 0.115273775 0.072859745 0.4587737 0.019458440 # # 4 3 
3 2 5 0.008645533 0.003642987 0.8642388 0.004323394 # # 5 
4 4 4 4 0.011527378 0.007285974 0.4587737 0.001945844 # # 
6 5 1 4 5 0.002881844 0.007285974 0.9275207 0.004084922 # 
# 7 6 1 1 1 0.002881844 0.001821494 0.4587737 0 
. 000486461IV X = as . factor data $ Parch 
1 nrow train Y = data $ Survived 1 nrow 
train # # 1 0.1166611 # # attr howgood # 
# 1 Highly Predictive FamilySize 为 2 到 4 的 
乘客 幸存 可能性 较高 SibSp 与 Parch 都 说明 当 
乘客 无亲 人时 幸存 率 较低 乘客 有 少数 亲 
人时 幸存 率 高于 50% 而 当 亲人 数 过高 
时 幸存 率 反而 降低 在 这里 可以 考虑 将 
SibSp 与 Parch 相加 生成 新的 变量 FamilySize data $ 
FamilySize data $ SibSp + data $ Parch + 1 
ggplot data = data 1 nrow train mapping = aes 
x = FamilySize y = . . count . . 
fill = Survived + geom _ bar stat = count 
position = dodge + xlab FamilySize + ylab Count + 
ggtitle How FamilySize impact survivor + geom _ text stat 
= count aes label = . . count . . 
position = position _ dodge width = 1 vjust = 
0.5 + theme plot . title = element _ text 
hjust = 0.5 legend . position = bottom 计算 FamilySize 
的 WOE 和 IV 可知 IV 为 0.3497672 且 Highly 
Predictive 由 SibSp 与 Parch 派生 出来 的 新 变量 
FamilySize 的 IV 高于 SibSp 与 Parch 的 IV 因此 
可将 这个 派生 变量 FamilySize 作 为特征 变量 WOETable X 
= as . factor data $ FamilySize 1 nrow train 
Y = data $ Survived 1 nrow train # # 
CAT GOODS BADS TOTAL PCT _ G PCT _ B 
WOE IV # # 1 1 163 374 537 0.459154930 
0.68123862 0.3945249 0.0876175539 # # 2 2 89 72 161 
0.250704225 0.13114754 0.6479509 0.0774668616 # # 3 3 59 43 
102 0.166197183 0.07832423 0.7523180 0.0661084057 # # 4 4 21 
8 29 0.059154930 0.01457195 1.4010615 0.0624634998 # # 5 5 
3 12 15 0.008450704 0.02185792 0.9503137 0.0127410643 # # 6 
6 3 19 22 0.008450704 0.03460838 1.4098460 0.0368782940 # # 
7 7 4 8 12 0.011267606 0.01457195 0.2571665 0.0008497665 # 
# 8 8 6 6 6 0.016901408 0.01092896 0.4359807 0.0026038712 
# # 9 11 7 7 7 0.019718310 0.01275046 0.4359807 
0 . 0030378497IV X = as . factor data $ 
FamilySize 1 nrow train Y = data $ Survived 1 
nrow train # # 1 0.3497672 # # attr howgood 
# # 1 Highly Predictive 共 票号 乘客 幸存 率 
高 对于 Ticket 变量 重复 度 非常 低 无法 直接 
利用 先 统计 出 每张 票 对应 的 乘客 数 
ticket . count aggregate data $ Ticket by = list 
data $ Ticket function x sum is . na x 
这里 有个 猜想 票号 相同 的 乘客 是 一家人 很 
可能 同时 幸存 或者 同时 遇难 现将 所有 乘客 按照 
Ticket 分为 两组 一组 是 使用 单独 票号 另一组 是 
与 他人 共享 票号 并 统计 出 各组 的 幸存 
与 遇难 人数 data $ TicketCount apply data 1 function 
x ticket . count which ticket . count 1 = 
= x Ticket 2 data $ TicketCount factor sapply data 
$ TicketCount function x ifelse x 1 Share Unique ggplot 
data = data 1 nrow train mapping = aes x 
= TicketCount y = . . count . . fill 
= Survived + geom _ bar stat = count position 
= dodge + xlab TicketCount + ylab Count + ggtitle 
How TicketCount impact survivor + geom _ text stat = 
count aes label = . . count . . position 
= position _ dodge width = 1 vjust = 0.5 
+ theme plot . title = element _ text hjust 
= 0.5 legend . position = bottom 由 上图 可见 
未 与 他人 同 票号 的 乘客 只有 130 / 
130 + 351 = 27% 幸存 而与 他人 同 票号 
的 乘客 有 212 / 212 + 198 = 51.7% 
幸存 计算 TicketCount 的 WOE 与 IV 如下 其 IV 
为 0.2751882 且 Highly Predictive WOETable X = data $ 
TicketCount 1 nrow train Y = data $ Survived 1 
nrow train # # CAT GOODS BADS TOTAL PCT _ 
G PCT _ B WOE IV # # 1 Share 
212 198 410 0.619883 0.3606557 0.5416069 0.1403993 # # 2 
Unique 130 351 481 0.380117 0.6393443 0.5199641 0 . 1347889IV 
X = data $ TicketCount 1 nrow train Y = 
data $ Survived 1 nrow train # # 1 0.2751882 
# # attr howgood # # 1 Highly Predictive 支出 
船票 费 越高 幸存 率 越高 对于 Fare 变量 由 
下图 可知 Fare 越大 幸存 率 越高 ggplot data = 
data is . na data $ Fare & row data 
Fare = 891 aes x = Fare color = Survived 
+ geom _ line aes label = . . count 
. . stat = bin binwidth = 10 + labs 
title = How Fare impact survivor x = Fare y 
= Count fill = Survived 不同 仓位 的 乘客 幸存 
率 不同 对于 Cabin 变量 其 值 以 字母 开始 
后面 伴以 数字 这里 有 一个 猜想 字母 代表 某个 
区域 数据 代表 该 区域 的 序号 类似于 火车票 即 
有车 箱号 又有 座位号 因此 这里 可 尝试 将 Cabin 
的 首字母 提取 出来 并 分别 统计 出 不同 首字母 
仓位 对应 的 乘客 的 幸存 率 ggplot data 1 
nrow train mapping = aes x = as . factor 
sapply data $ Cabin 1 nrow train function x str 
_ sub x start = 1 end = 1 y 
= . . count . . fill = Survived + 
geom _ bar stat = count position = dodge + 
xlab Cabin + ylab Count + ggtitle How Cabin impact 
survivor + geom _ text stat = count aes label 
= . . count . . position = position _ 
dodge width = 1 vjust = 0.5 + theme plot 
. title = element _ text hjust = 0.5 legend 
. position = bottom 由 上图 可见 仓位 号 首字母 
为 B C D E F 的 乘客 幸存 率 
均 高于 50% 而 其它 仓位 的 乘客 幸存 率 
均 远 低于 50% 仓位 变量 的 WOE 及 IV 
计算 如下 由此可见 Cabin 的 IV 为 0.1866526 且 Highly 
Predictive data $ Cabin sapply data $ Cabin function x 
str _ sub x start = 1 end = 1 
WOETable X = as . factor data $ Cabin 1 
nrow train Y = data $ Survived 1 nrow train 
# # CAT GOODS BADS TOTAL PCT _ G PCT 
_ B WOE IV # # 1 A 7 8 
15 0.05109489 0.11764706 0.8340046 0.055504815 # # 2 B 35 
12 47 0.25547445 0.17647059 0.3699682 0.029228917 # # 3 C 
35 24 59 0.25547445 0.35294118 0.3231790 0.031499197 # # 4 
D 25 8 33 0.18248175 0.11764706 0.4389611 0.028459906 # # 
5 E 24 8 32 0.17518248 0.11764706 0.3981391 0.022907100 # 
# 6 F 8 5 13 0.05839416 0.07352941 0.2304696 0.003488215 
# # 7 G 2 2 4 0.01459854 0.02941176 0.7004732 
0.010376267 # # 8 T 1 1 1 0.00729927 0.01470588 
0.7004732 0 . 005188134IV X = as . factor data 
$ Cabin 1 nrow train Y = data $ Survived 
1 nrow train # # 1 0.1866526 # # attr 
howgood # # 1 Highly Predictive Embarked 为 的 乘客 
幸存 率 较低 Embarked 变量 代表 登船 码头 现 通过 
统计 不同 码头 登船 的 乘客 幸存 率 来 判断 
Embarked 是否 可 用于 预测 乘客 幸存 情况 ggplot data 
1 nrow train mapping = aes x = Embarked y 
= . . count . . fill = Survived + 
geom _ bar stat = count position = dodge + 
xlab Embarked + ylab Count + ggtitle How Embarked impact 
survivor + geom _ text stat = count aes label 
= . . count . . position = position _ 
dodge width = 1 vjust = 0.5 + theme plot 
. title = element _ text hjust = 0.5 legend 
. position = bottom 从 上图 可见 Embarked 为 的 
乘客 幸存 率 仅为 217 / 217 + 427 = 
33.7% 而 Embarked 为 C 或为 NA 的 乘客 幸存 
率 均 高于 50% 初步判断 Embarked 可 用于 预测 乘客 
是否 幸存 Embarked 的 WOE 和 IV 计算 如下 WOETable 
X = as . factor data $ Embarked 1 nrow 
train Y = data $ Survived 1 nrow train # 
# CAT GOODS BADS TOTAL PCT _ G PCT _ 
B WOE IV # # 1 C 93 75 168 
0.27352941 0.1366120 0.6942642 9.505684 e 02 # # 2 Q 
30 47 77 0.08823529 0.0856102 0.0302026 7.928467 e 05 # 
# 3 S 217 427 644 0.63823529 0.7777778 0.1977338 2.759227 
e 02IV X = as . factor data $ Embarked 
1 nrow train Y = data $ Survived 1 nrow 
train # # 1 0.1227284 # # attr howgood # 
# 1 Highly Predictive 从 上述 计算 结果 可见 IV 
为 0.1227284 且 Highly Predictive 填补 缺失 值 列出 所有 
缺失 数据 attach data missing list Pclass = nrow data 
is . na Pclass missing $ Name nrow data is 
. na Name missing $ Sex nrow data is . 
na Sex missing $ Age nrow data is . na 
Age missing $ SibSp nrow data is . na SibSp 
missing $ Parch nrow data is . na Parch missing 
$ Ticket nrow data is . na Ticket missing $ 
Fare nrow data is . na Fare missing $ Cabin 
nrow data is . na Cabin missing $ Embarked nrow 
data is . na Embarked for name in names missing 
{ if missing name 1 0 { print paste name 
miss missing name 1 values sep = } } detach 
data # # 1 Age miss 263 values # # 
1 Fare miss 1 values # # 1 Cabin miss 
1014 values # # 1 Embarked miss 2 values 预测 
乘客 年龄 缺失 年龄 信息 的 乘客 数 为 263 
缺失 量 比较 大 不适合 使用 中位数 或者 平均值 填补 
一般 通过 使用 其它 变量 预测 或者 直接 将 缺失 
值 设置 为 默认值 的 方法 填补 这里 通过 其它 
变量 来 预测 缺失 的 年龄 信息 age . model 
rpart Age ~ Pclass + Sex + SibSp + Parch 
+ Fare + Embarked + Title + FamilySize data = 
data is . na data $ Age method = anova 
data $ Age is . na data $ Age predict 
age . model data is . na data $ Age 
中位数 填补 缺失 的 Embarked 值 从 如下 数据 可见 
缺失 Embarked 信息 的 乘客 的 Pclass 均为 1 且 
Fare 均为 80 data is . na data $ Embarked 
c PassengerId Pclass Fare Embarked # # # A tibble 
2 × 4 # # PassengerId Pclass Fare Embarked # 
# int int dbl chr # # 1 62 1 
80 NA # # 2 830 1 80 NA 由 
下图 所见 Embarked 为 C 且 Pclass 为 1 的 
乘客 的 Fare 中位数 为 80 ggplot data is . 
na data $ Embarked aes x = Embarked y = 
Fare fill = factor Pclass + geom _ boxplot + 
geom _ hline aes yintercept = 80 color = red 
linetype = dashed lwd = 2 + scale _ y 
_ continuous labels = dollar _ format + theme _ 
few 因此 可以 将 缺失 的 Embarked 值 设置 为 
C data $ Embarked is . na data $ Embarked 
C data $ Embarked as . factor data $ Embarked 
中位数 填补 一个 缺失 的 Fare 值 由于 缺失 Fare 
值 的 记录 非常 少 一般 可 直接 使用 平均值 
或者 中位数 填补 该 缺失 值 这里 使用 乘客 的 
Fare 中位数 填补 缺失 值 data $ Fare is . 
na data $ Fare median data $ Fare na . 
rm = TRUE 将 缺失 的 Cabin 设置 为 默认值 
缺失 Cabin 信息 的 记录 数 较多 不适合 使用 中位数 
或者 平均值 填补 一般 通过 使用 其它 变量 预测 或者 
直接 将 缺失 值 设置 为 默认值 的 方法 填补 
由于 Cabin 信息 不 太 容易 从 其它 变量 预测 
并且 在上 一节 中 将 NA 单独 对待 时 其 
IV 已经 比较 高 因此 这里 直接 将 缺失 的 
Cabin 设置 为 一个 默认值 data $ Cabin as . 
factor sapply data $ Cabin function x ifelse is . 
na x X str _ sub x start = 1 
end = 1 训练 模型 set . seed 415 model 
cforest Survived ~ Pclass + Title + Sex + Age 
+ SibSp + Parch + FamilySize + TicketCount + Fare 
+ Cabin + Embarked data = data train . row 
controls = cforest _ unbiased ntree = 2000 mtry = 
3 交叉 验证 一般 情况下 应该 将 训练 数据 分为 
两部分 一 部分 用于 训练 另一 部分 用于 验证 或者 
使用 k fold 交叉 验证 本文 将 所有 训练 数据 
都 用于 训练 然后 随机 选取 30% 数据集 用于 验证 
cv . summarize function data . true data . predict 
{ print paste Recall Recall data . true data . 
predict print paste Precision Precision data . true data . 
predict print paste Accuracy Accuracy data . predict data . 
true print paste AUC AUC data . predict data . 
true } set . seed 415 cv . test . 
sample sample 1 nrow train as . integer 0.3 * 
nrow train replace = TRUE cv . test data cv 
. test . sample cv . prediction predict model cv 
. test OOB = TRUE type = response cv . 
summarize cv . test $ Survived cv . prediction # 
# 1 Recall 0 . 947976878612717 # # 1 Precision 
0 . 841025641025641 # # 1 Accuracy 0 . 850187265917603 
# # 1 AUC 0 . 809094822285082 预测 predict . 
result predict model data 1 + nrow train nrow data 
OOB = TRUE type = response output data . frame 
PassengerId = test $ PassengerId Survived = predict . result 
write . csv output file = cit1 . csv row 
. names = FALSE 该 模型 预测 结果 在 Kaggle 
的 得分 为 0.80383 排 第 992名 前 992/6292 = 
15.8% 调 优 去掉 关联 特征 由于 FamilySize 结合 了 
SibSp 与 Parch 的 信息 因此 可以 尝试 将 SibSp 
与 Parch 从 特征 变量 中 移除 set . seed 
415 model cforest Survived ~ Pclass + Title + Sex 
+ Age + FamilySize + TicketCount + Fare + Cabin 
+ Embarked data = data train . row controls = 
cforest _ unbiased ntree = 2000 mtry = 3 predict 
. result predict model data test . row OOB = 
TRUE type = response submit data . frame PassengerId = 
test $ PassengerId Survived = predict . result write . 
csv submit file = cit2 . csv row . names 
= FALSE 该 模型 预测 结果 在 Kaggle 的 得分 
仍 为 0.80383 去掉 IV 较低 的 Cabin 由于 Cabin 
的 IV 值 相对 较低 因此 可以 考虑 将其 从 
模型 中 移除 set . seed 415 model cforest Survived 
~ Pclass + Title + Sex + Age + FamilySize 
+ TicketCount + Fare + Embarked data = data train 
. row controls = cforest _ unbiased ntree = 2000 
mtry = 3 predict . result predict model data test 
. row OOB = TRUE type = response submit data 
. frame PassengerId = test $ PassengerId Survived = predict 
. result write . csv submit file = cit3 . 
csv row . names = FALSE 该 模型 预测 结果 
在 Kaggle 的 得分 仍 为 0.80383 增加 派生 特征 
对于 Name 变量 上文 从中 派生 出了 Title 变量 由于 
以下 原因 可推测 乘客 的 姓氏 可能 具有 一定 的 
预测 作用 部分 西方 国家 中 人名 的 重复 度 
较高 而 姓氏 重复 度 较低 姓氏 具有 一定 辨识度 
部分 国家 的 姓氏 具有 一定 的 身份 识别 作用 
姓氏 相同 的 乘客 可能 是 一家人 这 一点 也 
基于 西方 国家 姓氏 重复 度 较低 这一 特点 而 
一家人 同时 幸存 或 遇难 的 可能性 较高 考虑到 只 
出现 一次 的 姓氏 不 可能 同时 出现 在 训练 
集 和 测试 集中 不具 辨识度 和 预测 作用 因此 
将 只 出现 一次 的 姓氏 均 命名为 Small data 
$ Surname sapply data $ Name FUN = function x 
{ strsplit x split = . 1 1 } data 
$ FamilyID paste as . character data $ FamilySize data 
$ Surname sep = data $ FamilyID data $ FamilySize 
= 2 Small # Delete erroneous family IDs famIDs data 
. frame table data $ FamilyID famIDs famIDs famIDs $ 
Freq = 2 data $ FamilyID data $ FamilyID % 
in % famIDs $ Var1 Small # Convert to a 
factor data $ FamilyID factor data $ FamilyID set . 
seed 415 model cforest as . factor Survived ~ Pclass 
+ Sex + Age + Fare + Embarked + Title 
+ FamilySize + FamilyID + TicketCount data = data train 
. row controls = cforest _ unbiased ntree = 2000 
mtry = 3 predict . result predict model data test 
. row OOB = TRUE type = response submit data 
. frame PassengerId = test $ PassengerId Survived = predict 
. result write . csv submit file = cit4 . 
csv row . names = FALSE 该 模型 预测 结果 
在 Kaggle 的 得分 为 0.82297 排 第 207名 前 
207/6292 = 3.3% 其它 经 试验 将 缺失 的 Embarked 
补充 为 出现 最多 的 而非 C 成绩 有所 提升 
但该 方法 理论依据 不强 并且 该 成绩 只是 Public 排行榜 
成绩 并非 最终 成绩 并 不能 说明 该 方法 一定 
优于 其它 方法 因此 本文 并不 推荐 该 方法 只是 
作为 一种 可能 的 思路 供 大家 参考 学习 data 
$ Embarked c 62 830 = S data $ Embarked 
factor data $ Embarked set . seed 415 model cforest 
as . factor Survived ~ Pclass + Sex + Age 
+ Fare + Embarked + Title + FamilySize + FamilyID 
+ TicketCount data = data train . row controls = 
cforest _ unbiased ntree = 2000 mtry = 3 predict 
. result predict model data test . row OOB = 
TRUE type = response submit data . frame PassengerId = 
test $ PassengerId Survived = predict . result write . 
csv submit file = cit5 . csv row . names 
= FALSE 该 模型 预测 结果 在 Kaggle 的 得分 
仍 为 0.82775 排 第 114名 前 114/6292 = 1.8% 
总结 本文 详述 了 如何 通过 数据 预览 探索 式 
数据分析 缺失 数据 填补 删除 关联 特征 以及 派生 新 
特征 等 方法 在 Kaggle 的 Titanic 幸存 预测 这 
一分 类 问题 竞赛 中 获得 前 2% 排名 的 
具体 方法 下篇 预告 下 一篇 文章 将 侧重 讲解 
使用 机器学习 解决 工程 问题 的 一般 思路 和 方法 
