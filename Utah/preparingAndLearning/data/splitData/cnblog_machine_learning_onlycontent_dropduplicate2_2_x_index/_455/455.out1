声明 机器学习 系列 主要 记录 自己 学习 机器学习 算法 过程 
中 的 一些 参考 和 总结 其中/r 有/v 部分/n 内容/n 
是/v 借鉴/v 参考/v 书籍/n 和/c 参考/v 博客/nr 的/uj 目录 什么 
是 关联 规则 关联 规则 中 的 必须 知道 的 
概念 关联 规则 的 实现 过程 关联 规则 的 核心 
点 如何 生成 频繁 项集/nr Apriori 算法 关联 规则 的 
核心 点 如何 生成 频繁 项集/nr FP Growth 算法 实际 
使用 过程 中 需要 注意 的 地方 关联 规则 总结 
与 课后 作业 参考文献 一 什么 是 关联 规则 所谓 
数据挖掘 就是 以 某种 方式 分析 源 数据 从中/nr 发现 
一些 潜在 的 有用 的 信息 即 数据挖掘 又 可以 
称作 知识发现 而 机器学习 算 法则 是 这种 某种 方式 
关联 规则 作为 十大 经典 机器学习 算法 之一 因此 搞懂 
关联 规则 虽然 目前 使用 的 不多 自然 有着 很 
重要 的 意义 顾名思义 关联 规则 就是 发现 数据 背后 
存在 的 某种 规则 或者 联系 举个 简单 的 例子 
尿布 和 啤酒 太 经典 通过 调研 超市 顾客 购买 
的 东西 可以 发现 30% 的 顾客 会 同时 购买 
床单 和 枕套 而在 购买 床单 的 顾客 中有 80% 
的 人 购买 了 枕套 这就 存在 一种 隐含 的 
关系 床单 → 枕套 也 就是说 购买 床单 的 顾客 
会 有 很大 可能 购买 枕套 因此 商场 可以 将 
床单 和 枕套 放在 同一个 购物 区 方便 顾客 购买 
一般 关联 规则 可以 应用 的 场景 有 优化 货架 
商品 摆放 或者 优化 邮寄 商品 的 目录 交叉 销售 
或者 捆绑 销售 搜索词 推荐 或者 识别 异常 二 概念 
项目 交易 数据库 中 的 一个 字段 对 超市 的 
交易 来 说 一般 是 指 一次 交易 中 的 
一个 物品 如 牛奶 事务 某个 客户 在 一次 交易 
中 发生 的 所有 项目 的 集合 如 ｛ 牛奶 
面包 啤酒 ｝ 项集/nr 包含 若干 个 项目 的 集合 
一次 事务 中的 一般 会 大于 0个 支持度 项集｛/nr X 
Y ｝ 在 总 项 集中 出现 的 概率 见 
下面 的 例子 频繁 项集/nr 某个 项集的/nr 支持 度 大于 
设定 阈值 人为 设定 或者 根据 数据 分布 和 经验 
来 设定 即/v 称/v 这个/r 项/n 集为/v 频繁/a 项集/nr 置信度 
在 先决条件 X 发生 的 条件 下 由 关联 规则 
｛ X Y ｝ 推出 Y 的 概率 见 下面 
的 例子 提升 度 表示 含有 X 的 条件 下 
同时 含有 Y 的 概率 与 无论 含 不含 X 
含有 Y 的 概率 之比 支持度 和 提升 度 示例 
假如 有 一条 规则 牛肉 鸡肉 那么 同时 购买 牛肉 
和 鸡肉 的 顾客 比例 是 3/7 而 购买 牛肉 
的 顾客 当中 也 购买 了 鸡肉 的 顾客 比例 
是 3/4 这 两个 比例 参数 是 很 重要 的 
衡量 指标 它们 在 关联 规则 中 称作 支持度 support 
和 置信度 confidence 对于 规则 牛肉 鸡肉 它 的 支持 
度 为 3/7 表示/v 在/p 所有/b 顾客/nr 当中/s 有/v 3/7/mf 
同时/c 购买/v 牛肉/n 和/c 鸡肉/n 其 反应 了 同时 购买 
牛肉 和 鸡肉 的 顾客 在 所有 顾客 当中 的 
覆盖 范围 它 的 置信度 为 3/4 表示 在 买了 
牛肉 的 顾客 当中 有 3/4 的 人 买了 鸡肉 
其 反应 了 可 预测 的 程度 即 顾客 买 
了 牛肉 的话 有 多大 可能性 买 鸡肉 其实/d 可以/c 
从/p 统计学/nt 和/c 集合/v 的/uj 角度/n 去/v 看/v 这个/r 问题/n 
假如 看作 是 概率 问题 则 可以 把 顾客 买 
了 牛肉 之后 又 多大 可能性 买 鸡肉 看作 是 
条件 概率 事件 而从 集合 的 角度 去看 可以 看 
下面 这幅 图 上面 这副 图 可以 很好 地 描述 
这个 问题 表示 所有 的 顾客 而 A 表示 买了 
牛肉 的 顾客 B 表示 买了 鸡肉 的 顾客 C 
表示 既 买了 牛肉 又 买了 鸡肉 的 顾客 那么 
C . count / . count = 3/7 C . 
count / A . count = 3/4 提升 度 示例 
1000名 顾客 购 买年货 A 组 有 500人 购买 茶叶 
有 450人 购买 咖啡 B 组 有 0人 购买 茶叶 
有 450人 购买 咖啡 购买 茶叶 购买 咖啡 A 组 
500人 500450B 组 500人 0450 茶叶 咖啡 的 支持 度 
＝ 450/1000 = 45% 茶叶 咖啡 的 置信度 ＝ 450/500 
= 90% 茶叶 咖啡 的 提升 度 ＝ 90% ／ 
90% ＝ 1 说明 1 由于 lift 茶叶 X 咖啡 
Y ＝ 1 所以 说明 X 与 Y 相互 独立 
即 是否 有X/nr 对于 Y 的 出现 没有 影响 虽然/c 
支持度/i 和/c 置信度/n 都高/nr 但 它们 之间 没有 必然 的 
关联关系 2 满足/v 最小/a 支持度/i 和/c 最小/a 置信度/n 的/uj 关联关系/i 
叫做/v 强/a 关联关系/i 如果/c lift/w 1 叫做 有效 的 强 
关联关系 如果 lift = 1 叫做 无效 的 强 关联关系 
特别 的 如果 lift X Y ＝ 1 则 称 
X 与 Y 相互 独立 三 实现 过程 从 以上 
的 分析 可以 得知 关联 规则 是 从事 务 集合 
中 挖掘 出 这样 的 关联 规则 ｛ X Y 
｝ 它 的 支持 度 和 置信度 要 大于 最小 
阈值 minSup minConf 当然 这个 最小 阈值 是由 用户 指定 
的 可以 根据 数据 分布 和 经验 同时 他 的 
提升 度 最好 是 大于 1 的 具体 值 根据 
实际 情况 设定 例如 3 5 均可 即是 有效 强 
关联 规则 使用 关联 规则 的 过程 主要 包含 以下 
三 个 步骤 1 数据 筛选 首先 对 数据 进行 
清洗 清洗 掉 那些 公共 的 项目 比如 热门 词 
通 用词 此 步 依据 具体 项目 而定 2 根据 
支持度 support 从/p 事务/n 集合/v 中/f 找出/v 频繁/a 项集/nr 使用 
算法 Apriori 算法 FP Growth 算法 3 根据 置信度 confidence 
从/p 频繁/a 项/n 集中/v 找出/v 强/a 关联/ns 规则/n 置信度 阈值 
需要 根据 实验 或者 经验 而定 4 根据 提升 度 
lift 从强/nr 关联/ns 规则/n 中/f 筛选/v 出/v 有效/a 的/uj 强/a 
关联/ns 规则/n 提升 度 的 设定 需要 经过 多次 试验 
确定 四 如何 生成 频繁 项集－/nr Apriori 算法 ［ 1 
］ 关联 规则 中 比较 关键 的 两个 点 是 
1 三种 阈值 的 设定 2 如何 找出 频繁 项集/nr 
本节 主要 讨论 如何 解决 寻找 频繁 项集的/nr 问题 目前 
主要 有 两种 算法 1 Apriori 算法 2 FP Growth 
算法 下面 分别 介绍 一下 这 两种 算法 1 算法 
原理 它 主要 利用 了 向下 封闭 属性 如果 一个 
项集是/nr 频繁 项目 集 那么 它 的 非空 子集 必定 
是 频繁 项目 集 它 先 生成 1 频繁 项目 
集 再利用 1 频繁 项目 集 生成 2 频繁 项目 
集 然后 根据 2 频繁 项目 集 生成 3 频繁 
项目 集 依次 类推 直至 生成 所有 的 频繁 项目 
集 然后 从 频繁 项目 集中 找 出 符合 条件 
的 关联 规则 2 生成 频繁 项集/nr 过程 它 的 
原理 是 根据 k 频繁 项目 集 生成 k + 
1 频繁 项目 集 因此 首先 要 做 的 是 
找出 1 频繁 项目 集 这个 很容易 得到 只要 循环 
扫描 一次 事务 集合 统计 出 项目 集合 中 每个 
元素 的 支持 度 然后 根据 设定 的 支持 度 
阈值 进行 筛选 即可 得到 1 频繁 项目 集 下面 
证明 一下 为何 可以 通过 k 频繁 项目 集 生成 
k + 1 频繁 项目 集 下面 证明 如何 从K/nr 
频繁/a 项集/nr 生成/v k/w +/i 1/m 频繁/a 项集/nr 假设 某 
个 项目 集 = { s1 s2 . . . 
sn } 是 频繁 项目 集 那么 它 的 n 
1 非空 子集 { s1 s2 . . . sn 
1 } { s1 s2 . . . sn 2 
sn } . . . { s2 s3 . . 
. sn } 必定 都是 频繁 项目 集 通过观察 任何 
一个 含有 n 个 元素 的 集合 A = { 
a1 a2 . . . an } 它 的 n 
1 非空 子集 必行 包含 两项 { a1 a2 . 
. . an 2 an 1 } 和 { a1 
a2 . . . an 2 an } 对比 这 
两个 子集 可以 发现 它们 的 前 n 2 项是/nr 
相同 的 它们 的 并 集 就是 集合 A 对于 
2 频繁 项目 集 它 的 所有 1 非空 子集 
也 必定 是 频繁 项目 集 那么 根据 上面 的 
性质 对于 2 频繁 项目 集中 的 任一个 在 1 
频繁 项目 集中 必定 存在 2个 集合 的 并 集 
与 它 相同 因此 在 所有 的 1 频繁 项目 
集中 找 出 只有 最后 一项 不同 的 集合 将其 
合并 即可 得到 所有 的 包含 2个 元素 的 项目 
集 得到 的 这些 包含 2个 元素 的 项目 集 
不一定 都是/nr 频繁 项目 集 所以 需要 进行 剪枝 剪枝 
的 办法 是 看 它 的 所有 1 非空 子集 
是否 在 1 频繁 项目 集中 如果 存在 1 非空 
子集 不在 1 频繁 项目 集中 则 将该 2 项目 
集 剔除 经过 该 步骤 之后 剩下 的 则 全是 
频繁 项目 集 即 2 频繁 项目 集 依次 类推 
可以 生成 3 频繁 项目 集 直至 生成 所有 的 
频繁 项目 集 3 生成 强 关联 规则 得到 频繁 
项目 集 之后 则 需要 从 频繁 项目 集中 找 
出 符合 条件 的 关联 规则 最 简单 的 办法 
是 遍历 所有 的 频繁 项目 集 然后 从 每个 
项目 集中 依次 取 1 2 . . . k 
个 元素 作为 后件 该 项目 集中 的 其他 元素 
作为 前件 计算 该 规则 的 置信度 进行 筛选 即可 
这样 的 穷举 效率 显然 很低 假如 对于 一个 频繁 
项目 集 f 可以 生成 下面 这样 的 关联 规则 
f β β 那么 这条 规则 的 置信度 = f 
. count / f β . count 下面 证明 如何 
生成 强 关联 规则 即 先 生成 小 后件 的 
再 根据 小 后件 依 次生 成大 后件 因为 假设 
该 规则 是 强 关联 规则 则 f β sub 
β sub 也是 强 关联 规则 根据 这个 置信度 计算公式 
可知 对于 一个 频繁 项目 集 f . count 是 
不变 的 而 假设 该 规则 是 强 关联 规则 
则 f β sub β sub 也是 强 关联 规则 
其中 β sub 是 β 的 子集 因为 f β 
sub . count 肯定 小于 f β . count 即 
给定 一个 频繁 项目 集 f 如果 一条 强 关联 
规则 的 后件 为 β 那么 以 β 的 非 
空子 集为 后件 的 关联 规则 都是 强 关联 规则 
所以 可以 先 生成 所有 的 1 后件 后件 只有 
一项 强 关联 规则 然后再 生成 2 后件 强 关联 
规则 依次 类推 直至 生成 所有 的 强 关联 规则 
4 举例说明 下面 举例说明 Apiori 算法 的 具体 流程 假如 
有 项目 集合 I = { 1 2 3 4 
5 } 有 事务 集 T 1 2 3 1 
2 4 1 3 4 1 2 3 5 1 
3 5 2 4 5 1 2 3 4 设定 
minsup = 3/7 misconf = 5/7 首先 生成 频繁 项目 
集 1 频繁 项目 集 { 1 } { 2 
} { 3 } { 4 } { 5 } 
2 频繁 项目 集 根据 1 频繁 项目 集 生成 
所有 的 包含 2个 元素 的 项目 集 任意 取 
两个 只有 最后 一个 元素 不同 的 1 频繁 项目 
集 求其 并 集 由于 每个 1 频繁 项目 集 
元素 只有 一个 所以 生成 的 项目 集 如下 { 
1 2 } { 1 3 } { 1 4 
} { 1 5 } { 2 3 } { 
2 4 } { 2 5 } { 3 4 
} { 3 5 } { 4 5 } 计算 
它们 的 支持 度 发现 只有 { 1 2 } 
{ 1 3 } { 1 4 } { 2 
3 } { 2 4 } { 2 5 } 
的 支持 度 满足要求 因此 求得 2 频繁 项目 集 
{ 1 2 } { 1 3 } { 1 
4 } { 2 3 } { 2 4 } 
3 频繁 项目 集 因为 { 1 2 } { 
1 3 } { 1 4 } 除了 最后 一个 
元素 以外 都 相同 所 以求 { 1 2 } 
{ 1 3 } 的 并 集 得到 { 1 
2 3 }   { 1 2 } 和{1/nr 4 
} 的 并 集 得到 { 1 2 4 } 
{ 1 3 } 和{1/nr 4 } 的 并 集 
得到 { 1 3 4 } 但是 由于 { 1 
3 4 } 的 子集 { 3 4 } 不在 
2 频繁 项目 集中 所以 需要 把 { 1 3 
4 } 剔除 掉 然后再 来 计算 { 1 2 
3 } 和{1/nr 2 4 } 的 支持 度 发现 
{ 1 2 3 } 的 支持 度 为 3/7 
{ 1 2 4 } 的 支持 度 为 2/7 
所以 需要 把 { 1 2 4 } 剔除 同理 
可以 对 { 2 3 } { 2 4 } 
求 并 集 得到 { 2 3 4 } 但是 
{ 2 3 4 } 的 支持 度 不 满足 
要求 所以 需要 剔除 掉 因此 得到 3 频繁 项目 
集 { 1 2 3 } 到此 频繁 项目 集 
生成 过程 结束 注意 生成 频繁 项目 集 的 时候 
频繁 项目 集中 的 元素 个数 最大值 为 事务 集中 
事务 中 含有 的 最大 元素 个数 即若 事务 集中 
事务 包含 的 最大 元素 个数 为 k 那么 最多 
能 生成 k 频繁 项目 集 这个 原因 很 简单 
因为 事务 集合 中 的 所有 事务 都不/nr 包含 k 
+ 1 个 元素 所以 不 可能 存在 k + 
1 频繁 项目 集 在 生成 过程 中 若 得到 
的 频繁 项目 集 个数 小于 2 生成 过程 也 
可以 结束 了 现在 需要 生成 强 关联 规则 这里 
只 说明 3 频繁 项目 集 生成 关联 规则 的 
过程 对于 集合 { 1 2 3 } 1 后件 
的 关联 规则 1 2 3   置信度 = 3/4 
1 3 2 置信度 = 3/5 置信度 不 满足 要求 
所以 剔除 掉 2 3 1       置信度 
= 3/3 因此 得到 1 后件 的 集合 { 1 
} { 3 } 2 后件 的 关联 规则 根据 
1 － 后件 集合 2 1 3       
置信度 = 3/5 不 满足 要求 所以 对于 3 频繁 
项目 集 生成 的 强 关联 规则 为 1 2 
3 和 2 3 1 至此 Apriori 算法 完成 当然 
实际 项目 中 还 需要 去 验证 生成 的 强 
关联 规则 是否 满足 提升 度 要求 即 是否 是 
有效 强 关联 规则 五 如何 生成 频繁 项集－/nr FP 
Growth 算法 ［ 4 ］ Apriori 算法 是 关联 规则 
的 基本 算法 很多 用于 发现 关联 规则 的 算法 
都是/nr 基于 Apriori 算法 但 Apriori 算法 需要 多次 访问 
数据库 具有 严重 的 性能 问题 FP Growth 算法 只需要 
两次 扫描 数据库 相比 于 Apriori 减少 了 I / 
O 操作 克服 了 Apriori 算法 需要 多次 扫描 数据库 
的 问题 本文 采用 如下 的 样例 数据 A B 
E B D B C A B D A C 
B C A C A B C E A B 
C 1 FP Growth 生成 FP TreeFP Growth 算法 将 
数据库 中 的 频繁 项集/nr 压缩 到 一颗 频繁 模式 
树 中 同时 保持 了 频繁 项集/nr 之间 的 关联关系 
通过 对 该 频繁 模式 树 挖掘 得到 频繁 项集/nr 
其 过程 如下 第一 次 扫描 数据库 产生 频繁 1项 
集 并对 产生 的 频繁 项集/nr 按照 频数 降序 排列 
并 剪枝 支持 数 低于 阀值 的 元素 处理 后 
得到 L 集合 第二 次 扫描 数据库 对 数据库 的 
每个 交易 事务 中的 项 按照 L 集合 中项 出现 
的 顺序 排序 生成 FP Tree . 1 . 1 
FT － Tree . 2   生成 fp tree 的 
步骤 2 从 FP Tree/w 挖掘/v 频繁/a 项集从/nr FP/w Tree 
重 可以 挖掘 出 频繁 项集/nr 其 过程 如下 . 
3  /i 频繁/a 项集/nr 挖掘/v 过程/n 从/p 频繁/a 1项/mq 集/q 
链表/n 中/f 按照/p 逆序/n 开始/v 链表 可以 追溯 到 每个 
具有 相同 项的/nr 节点 从 链表 中找到 项 E 追溯 
出 FP Tree 中有 两个 带 E 的 节点 由 
这 两个 节点 分别 向上 parent 追溯 形成 两条 模式 
E C A B 1 E A B 1 . 
由 这两条 模式 得到 项 E 的 条件 模式 A 
B 2 . 根据 条件 模式 得到 项 E 的 
频繁 项集/nr 不 包含 频繁 1项 集 E A 2 
E B 2 E A B 2 然后 一次 得到 
项 D C A 3 找出 强 关联 规则 同 
第四节 4 找出 有效 的 强 关联 规则 同 第四节 
至此 FP － Growth 算法 生成 频繁 项集/nr 已经 结束 
六 注意 点 1 三个 阈值 点 需要 经过 对此 
实验 或者 经验 才能 找到 合适 的 阈值 2 关联 
规则 与 word2vec 在 哪些 场景 有着 共性 和 不同 
需要 验证 需要 研究 word2vec 实现 原理 后再 下结论 3 
数据集 需要 某些 处理 后 也许 效果 会 有 提升 
同事 的 经验 七 总结 第一 次 摘抄 整理 别人 
的 博客 来 放在 自己 的 博客 算是 一个 小小的 
开始 的 其实 很多 东西 只 有 自己 去 真正 
的 学习 思考 整理 才 有收获 机器学习 算法 与 模型 
是 一个 很 有意思 的 东西 很多 东西 不 去看 
自己 完全 想象 不到 还能 这么 玩 然而 看 了 
就是 看了 跟 用了 还是 有 很大 差别 希望 以后 
能够 在 工作 中 将 自己 看 的 一些 东西 
用上去 多 整理 这样 效果 会 比较 好 虽然 我 
是 一个 从 网络 方向 转 过来 的 出家 人 
但是 这 都 不是 事 我 觉得 看 的 多了 
整理 的 多了 其实 学 起来 还是 有 套路 可以 
遵循 的 八 参考文献 ［ 1 ］ http / / 
www . cnblogs . com / dolphin0520 / archive / 
2012/10 / 29/2733356 . html ［ 2 ］ http / 
/ blog . sina . com . cn / s 
/ blog _ 4d8d6303010009kb . html ［ 3 ］ http 
/ / www . 360doc . com / content / 
15/0611 / 19/25802092 _ 477451393 . shtml ［ 4 ］ 
http / / westerly lzh . github . io / 
cn / 2015/08 / DM002 FP Tree / ［ 5 
］ http / / www . bjt . name / 
2013/09 / association rules ［ 6 ］ http / / 
blog . csdn . net / rav009 / article / 
details / 8985322 ［ 7 ］ http / / blog 
. csdn . net / rav009 / article / details 
/ 8979249 