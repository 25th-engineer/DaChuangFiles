当我们运用训练好了的模型来预测未知数据时候发现有较大误差，那么我们下一步可以做什么呢？
一般来说可以选择以下几种方法：
增加训练集（通常是有效的，但是代价太大）
减少特征的数量
获取更多的特征
增加多项式特征
减小正则化参数lambda
增大正则化参数lambda
但是要选择什么方法来改进我们的算法，我们需要运用一些机器学习诊断法来协助我们判断。
一、评估h(x) ---- Evaluating a Hypothesis
一个好的Hypothesis：有小的训练误差同时没有过拟合
我们的训练是通过最小化训练误差来得到h(x), 但是有小的训练误差并不代表它一定就是一个好的Hypothesis，很可能会发生过拟合导致泛化能力差。
过拟合检验：
把数据集分成训练集（70%）和测试集（30%）
用训练集训练出一个模型之后，我们通过测试集来评估这个模型
对于回归模型：利用测试集计算代价函数J
对于分类模型：利用测试集计算代价函数J，并计算误分类比率err(h(x), y) / mtest
二、模型选择和交叉验证集 ---- Model Selection and Train_Validation_Test set
当我们不确定多项式模型最高该几次或者正则化参数应该取多大的时候，我们可以使用交叉验证集来帮助选择模型。（微调模型的超参数：多项式最高次，正则化参数）
交叉验证(cross validation)：
数据集：训练集（60%），交叉验证集（20%）， 测试集（20%）
模型选择过程(model selection)：
使用训练集训练出多个模型
用这些模型分别对交叉验证集计算交叉验证误差J
选取代价函数最小的模型
用选出的模型对测试集计算推广误差J
很多人仅仅把数据集分成了训练集和交叉验证集，使用交叉验证集选择模型同时测出误差作为预测效果。当数据集很大时也许可以得到比较好的泛化误差，但是一般来说这样并不好。
三、诊断偏差和方差 ---- Diagnosing Bias and Variance
当一个模型表现不是很好时，一般来说是两种情况：偏差比较大（欠拟合），方差比较大（过拟合）。
泛化性能用期望泛化误差表示，而期望泛化误差可以分解为偏差，方差和噪声。
Bias：描述的是预测值与真实值之间的差距。
Variance：描述的是预测值的变化范围，离散程度，也就是离其真实值的距离。
偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；（准确性）
方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；（稳定性）
判断偏差和方差（多项式次数及λ的值）：
我们通过将训练集和交叉验证集的代价函数误差与多项式的次数绘制在同一张图表上来分析
如表所示，当Jcv(Θ)和Jtrain(Θ)都比较大而且近似时，属于高偏差问题。（欠拟合）
当Jtrain(Θ)比较小，而且Jcv(Θ)远大于Jtrain(Θ)时，属于高方差问题。（过拟合）
同样的，我们将训练集和交叉验证集的代价函数误差与λ的值绘制在同一张图表上来分析(在选择模型时，λ的值一般取两倍步长)
注意：这里我们在计算训练集误差、验证集误差和测试集误差时都不考虑正则化项（只包含数据的平方误差）。
可以看出，当λ比较小时，可能出现过拟合问题（高方差），此时训练集误差比较小，验证集误差比较大。
当λ比较大时，对每个参数的惩罚因子都很大，可能出现欠拟合问题（高偏差），此时训练集误差和验证集误差都比较大。
四、学习曲线 ---- Learning Curves
训练集大小的影响：
对于高偏差的情况，增加训练集并没有用
对于高方差的情况，增加训练集也许是有用的；
六、针对高方差和高偏差的情况可以采取的措施
增加训练集：高方差
减少特征的数量：高方差
获取更多的特征：高偏差
增加多项式特征：高偏差
减小正则化参数lambda：高偏差
增大正则化参数lambda：高方差
对于神经网络，越简单的神经网络计算量小但是容易欠拟合。相反的，越复杂的神经网络容易过拟合，但我们可以使用正则化项来克服过拟合，一般来说用复杂的神经网络比简单的神经网络效果好，当然计算量比较大。对于隐藏层数量的选择，一般来说一层是比较合理的选择，但是你想要从一层、两层、三层...里面做最合理的选择，可以用交叉验证集做模型选择。