当 我们 运用 训练 好了 的 模型 来 预测 未知 
数据 时候 发现 有 较大 误差 那么 我们 下 一步 
可以 做 什么 呢 一般来说 可以 选择 以下 几种 方法 
增加 训练 集 通常 是 有效 的 但是 代价 太大 
减少 特征 的 数量 获取 更多 的 特征 增加 多项式 
特征 减小 正则化 参数 lambda 增大 正则化 参数 lambda 但是 
要 选择 什么 方法 来 改进 我们 的 算法 我们 
需要 运用 一些 机器学习 诊断法 来 协助 我们 判断 一 
评估 h x Evaluating a Hypothesis 一个 好 的 Hypothesis 
有小 的 训练 误差 同时 没有 过拟合 我们 的 训练 
是 通过 最小化 训练 误差 来 得到 h x 但是 
有小 的 训练 误差 并不 代表 它 一定 就是 一个 
好 的 Hypothesis 很 可能 会 发生 过 拟合 导致 
泛化 能力差 过拟合 检验 把 数据集 分成 训练 集 70% 
和 测试 集 30% 用 训练 集训 练出 一个 模型 
之后 我们 通过 测试 集 来 评估 这个 模型 对于 
回归模型 利用 测试 集 计算 代价 函数 J 对于 分类 
模型 利用 测试 集 计算 代价 函数 J 并 计算 
误 分类 比率 err h x y / mtest 二 
模型 选择 和 交叉 验证 集 Model Selection and Train 
_ Validation _ Test set 当 我们 不 确定 多项式 
模型 最高 该 几次 或者 正则化 参数 应该 取 多大 
的 时候 我们 可以 使用 交叉 验证 集 来 帮助 
选择 模型 微调 模型 的 超 参数 多项式 最 高次 
正则化 参数 交叉 验证 cross validation 数据集 训练 集 60% 
交叉 验证 集 20% 测试 集 20% 模型 选择 过程 
model selection 使用 训练 集训 练出 多个 模型 用 这些 
模型 分别 对 交叉 验证 集 计算 交叉 验证 误差 
J 选取 代价 函数 最小 的 模型 用 选出 的 
模型 对 测试 集 计算 推广 误差 J 很多 人 
仅仅 把 数据集 分成 了 训练 集 和 交叉 验证 
集 使用 交叉 验证 集 选择 模型 同时 测出 误差 
作为 预测 效果 当 数据集 很大 时 也许 可以 得到 
比较 好 的 泛化 误差 但是 一般来说 这样 并 不好 
三 诊断 偏差 和 方差 Diagnosing Bias and Variance 当 
一个 模型 表现 不是 很好 时 一般 来说 是 两种 
情况 偏差 比较 大 欠 拟合 方差 比较 大 过拟合 
泛 化性 能用 期望 泛化 误差 表示 而 期望 泛化 
误差 可以 分解 为 偏差 方差 和 噪声 Bias 描述 
的 是 预测 值 与 真实 值 之间 的 差距 
Variance 描述 的 是 预测 值 的 变化 范围 离散 
程度 也 就是 离 其 真实 值 的 距离 偏差 
度量 了 学习 算法 的 期望 预测 与 真实 结果 
的 偏离 程度 即 刻画 了 学习 算法 本身 的 
拟合 能力 准确性 方差 度量 了 同样 大小 的 训练 
集 的 变动 所 导致 的 学习 性能 的 变化 
即 刻画 了 数据 扰动 所 造成 的 影响 稳定性 
判断 偏差 和 方差 多项式 次数 及 λ 的 值 
我们/r 通过/p 将/d 训练/vn 集/q 和/c 交叉/n 验证/v 集/q 的/uj 
代价/n 函数/n 误差/n 与/p 多项式/l 的/uj 次数/n 绘制/n 在/p 同一/b 
张/q 图表/n 上/f 来/v 分析/vn 如表/i 所示/v 当 Jcv Θ 
和 Jtrain Θ 都 比较 大 而且 近似 时 属于 
高 偏差 问题 欠 拟合 当 Jtrain Θ 比较 小 
而且 Jcv Θ 远大于 Jtrain Θ 时 属于 高 方差 
问题 过拟合 同样 的 我们/r 将/d 训练/vn 集/q 和/c 交叉/n 
验证/v 集/q 的/uj 代价/n 函数/n 误差/n 与/p λ/i 的/uj 值/n 
绘制/n 在/p 同一/b 张/q 图表/n 上/f 来/v 分析/vn 在 选择 
模型 时 λ 的 值 一般 取 两倍 步长 注意 
这里 我们 在 计算 训练 集 误差 验证/v 集/q 误差/n 
和/c 测试/vn 集/q 误差/n 时都/nr 不考虑/i 正则化/i 项/n 只 包含 
数据 的 平方 误差 可以 看出 当 λ 比较 小时 
可能 出现 过 拟合 问题 高 方差 此时 训练 集 
误差 比较 小 验证 集 误差 比较 大 当 λ 
比 较大 时 对 每个 参数 的 惩罚 因子 都 
很大 可能 出现 欠 拟合 问题 高 偏差 此时/c 训练/vn 
集/q 误差/n 和/c 验证/v 集/q 误差/n 都/d 比较/d 大/a 四 
学习曲线 Learning Curves 训练 集 大小 的 影响 对于 高 
偏差 的 情况 增加 训练 集 并 没有 用 对于 
高 方差 的 情况 增加 训练 集 也许是 有用 的 
六 针对/p 高/a 方差/n 和高/nr 偏差/n 的/uj 情况/n 可以/c 采取/v 
的/uj 措施/n 增加/v 训练/vn 集/q 高 方差 减少 特征 的 
数量 高 方差 获取 更多 的 特征 高 偏差 增加 
多项式 特征 高 偏差 减小 正则化 参数 lambda 高 偏差 
增大 正则化 参数 lambda 高 方差 对于 神经网络 越 简单 
的 神经 网络 计算 量小 但是 容易 欠 拟合 相反 
的 越 复杂 的 神经 网络 容易 过拟合 但 我们 
可以 使用 正则化 项来/nr 克服 过拟合 一般来说 用 复杂 的 
神经 网络 比 简单 的 神经 网络 效果 好 当然 
计算 量 比较 大 对于 隐藏 层 数量 的 选择 
一般来说 一层 是 比较 合理 的 选择 但是 你 想要 
从 一层 两层 三层 . . . 里面 做 最 
合理 的 选择 可以 用 交叉 验证 集 做 模型 
选择 