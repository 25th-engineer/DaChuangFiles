Infer.NET机器学习翻译系列文章将进行连载，感兴趣的朋友请收藏或关注
本博客所有文章分类的总目录：http://www.cnblogs.com/asxinyu/p/4288836.html
微软Infer.NET机器学习组件文章目录：http://www.cnblogs.com/asxinyu/p/4329742.html
关于本文档的说明
本文档基于Infer.NET 2.6对Infer.NET User Guide进行中文翻译，但进行了若干简化和提炼，按照原网站的思路进行，但不局限与其顺序。
欢迎传播分享，必须保持原作者的信息，但禁止将该文档直接用于商业盈利。
本人正在研究基于Infer.NET组件，并计划将其应用于实际的预测之中，该组件功能强大，封装很完善，但也有很多难以理解的地方，同时官方也给出了大量的例子，限于个人精力有限，更新时间较慢，也希望有兴趣的朋友一起来完成该项工作。
Email：asxinyu@qq.com
本文章地址： http://www.cnblogs.com/asxinyu/p/4252769.html
1.基本介绍
Infer.NET是微软剑桥研究院基于.NET平台开发的一款机器推理组件，官方网站：http://research.microsoft.com/en-us/um/cambridge/projects/infernet/default.aspx
该组件的采用的是Microsoft Research License Agreement 授权，Non-Commercial Use Only，除了商业使用，都可以，自己看着办。
本章节的英文原文为，在这里。
1.1 Infer.NET是什么?
Infer.NET是一个概率图模型中(graphical models)用于运行贝叶斯推理机(Bayesian inference)的框架。如果对概率图模型或者贝叶斯推理的意义不了解，你可以参考一下相关资源文件，在Resources and References page页面。Infer.NET为各种应用程序所需要推理提供了先进的消息传递算法和统计程序。Infer.NET 与现有的一些推理软件有下列区别:
1.1.1 丰富的建模语言
支持单变量和多变量变量、也支持连续型和离散型变量。可以使用大量的各种因素进行建模，包括算术运算、线性代数、范围和积极约束、布尔操作符等等。支持不同模型的组合，以及不同类型的组合。【附：Infer.NET的内部使用了The model specification language (MSL) 建模语言，由于该组件不允许用于商业，因此源代码也没有全部开发，无法也无法搞清楚其原理】
1.1.2 多种推理算法
内置了多种推理算法，如Expectation Propagation, Belief Propagation (a special case of EP), Variational Message Passing and Gibbs sampling.这几个专业词汇暂时还不懂意义。
1.1.3 为大规模推理而设计
现有的在大多数推理程序执行过程中的开销，减慢了推理过程。而Infer.NET将推理模型编译为能够独立执行的源代码，不需要额外的开销。它也可以直接集成到您的应用程序。此外,也可以查看，分步执行源代码，或者使用标准的开发工具进行修改。
1.1.4 用户可以进行扩展
概率分布、因素、消息操作和推理算法都可以由用户添加。Infer.NET使用一个插件架构,使其开放性,适应性更强。而内置库支持多种模型和推理操作；但总会有特殊的情况,需要新的因素或者分布类型或者算法，这种情况下,用户可以编写自定义代码，自由与内置功能进行混合，以减少一些额外的工作。
可以看看一个简单使用Infer.NET的例子。这个文档中的示例代码是C#，但Infer.NET支持.NET平台的所有语言。
1.2 安装文件夹
Infer.NET通过Zip压缩包进行发行，解压后，可以看到如下的文件夹目录：
“Bin,Learners,Source(Distributions,Factors,Wrappers),Samples(C#,F#)”
Bin文件夹包含了Infer.NET的dll文件:
1.Infer.Compiler.dll是一个使用Infer.NET API编写的将模型描述转换为推理代码的编译器；
2.Infer.Runtime.dll是一个执行推理代码的程序集
一般开发过程中只需要引用这两个dll,但在某些部署场景你可能只需要Infer.Runtime.dll。
Infer.FSharp.dll是为了标准的F＃语言调用所做的一个封装。【不懂F#，也没有去深究】
Bin文件夹还包括了一些例子的生成文件，以及几个项目的生成文件。
例子文件夹中有2个完整项目的源代码，1个是贝叶斯分类器，1个是推荐系统【比较复杂，还没开始研究】
1.3 一个简单的例子
下面是一个使用Infer.NET计算抛掷2枚硬币，结果都是正面的概率的例子，代码如下：
1 Variable<bool> firstCoin = Variable.Bernoulli(0.5); 2 Variable<bool> secondCoin = Variable.Bernoulli(0.5); 3 Variable<bool> bothHeads = firstCoin & secondCoin; 4 InferenceEngine ie = new InferenceEngine(); 5 Console.WriteLine("Probability both coins are heads: "+ie.Infer(bothHeads));
程序输出为:
1 Probability both coins are heads: Bernoulli(0.25)
上述结果说明2面同时为正面的概率为0.25。上述简单的例子，包括了使用Infer.NET编程的几个关键步骤。
1.定义概率模型：所有Infer.NET程序都需要明确定义的概率模型。上述程序的前3行就是定义3个随机变量。
2.创建推理引擎(推理机)：所有的推理都是使用推理引擎进行的，在使用之前，必须创建和配置推理引擎。如第四行，使用默认的推理算法创建的推理引擎。
3.执行推理查询：给定一个推理引擎，就可以使用Infer()方法来查询变量的边际分布。例子的最后一行中，引擎就去推理2个都是正面的边际分布。你还可以在这里找到更多“运行推理”的细节。
1.4 Infer.NET工作原理
下图是Infer.NET的推理过程：
过程如下：
1.首先用户创建1个 模型定义，并声明一些和模型相关推理查询需求；
2.用户将模型定义和推理查询传递给模型编译器,后者使用指定的推理算法，创建需要执行这些查询模型的源代码。这个源代码可以写入一个文件,如果需要,也可以直接使用。
3.C#编译器编译源代码来创建一个编译过的算法。这可以手动执行，或通过推断方法自动执行。
4.使用一组观测值(数据),推理引擎根据用户指定的设置，执行编译算法,以便产生推理查询要求的边际分布。可以对观测值重复不同的设置，而不需要重新编译算法。
本文章原始地址： http://www.cnblogs.com/asxinyu/p/4252769.html
1.5 Frequently Asked Questions
常见问题，比较简单，暂时没有翻译的必要，地址在这里。
1.6 Resources and References
常见问题，比较简单，暂时没有翻译的必要，地址在这里。
2.资源下载
这里提供Infer.NET 2.6的下载，包括了例子和基础的源码。下载地址：链接：http://pan.baidu.com/s/1o6FmVe6 密码：12wz
如果本文章资源下载不了，或者文章显示有问题，请参考 本文原文地址：http://www.cnblogs.com/asxinyu/p/4252769.html
另外本文的翻译电子版，以及该项目相关的翻译资源，将在最终完成后逐步开放，请关注本博客。
翻译很累，写篇文章也费时间，兄台顺手点个推荐吧。