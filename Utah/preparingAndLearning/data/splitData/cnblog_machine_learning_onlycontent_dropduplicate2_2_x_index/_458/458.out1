声明 本篇 博文 是 学习 机器学习 实战 一 书 的 
方式 路程 系 原创 若 转载 请 标明 来源 1 
贝叶 斯定理 的 引入 概率论 中的 经典 条件概率 公式 公式 
的 理解 为 P X Y = P Y X 
= P X | Y P Y = P Y 
| X P X 即 X 和 Y 同时 发生 
的 概率 与 Y 和 X 同时 发生 的 概率 
一样 2 朴素 贝叶 斯定理 朴素 贝叶斯 的 经典 应用 
是 对 垃圾 邮件 的 过滤 是 对 文本 格式 
的 数据 进行 处理 因此 这里 以此 为 背景 讲解 
朴素 贝叶 斯定理 设 Ｄ 是/v 训练/vn 样本/n 和相/nr 关联/ns 
的/uj 类/q 标号/n 的/uj 集合/v 其中 训练样本 的 属性 集为 
          X { X1 X2 . 
. . Xn   } 共有 n 个 属性 类 
标 号为 C { C1 C2 . . . Cm 
  } 有m/nr 中 类别 朴素 贝叶 斯定理 其中 P 
Ci | X 为 后验/nr 概率 P Ci 为 先验概率 
P X   | Ci 为 条件概率 朴素 贝叶斯 的 
两个 假设 1 属性 之间 相互 独立 2 每个 属性 
同等 重要 通过 假设 1 知 条件概率 P X   
| Ci 可以 简化 为 3 朴素 贝叶斯 算法 朴素 
贝叶斯 算法 的 核心 思想 选择 具有 最高 后验/nr 概率 
作为 确定 类别 的 指标 下面 是以 过滤 有 侮辱性 
的 评论 为例 介绍 朴素 贝叶斯 利用 Python 语言 实现 
的 过程 其 本质 是 利用 词 和 类别 的 
联合 概率 来 预测 给定 文档 属于 某个 类别 4 
使用 Python 对 文本 分类 4.1 建立 文本 数据 文本 
数据 用 一个 个 对象 组成 一个 对象 是 由 
若干 单词 组成 每个 对象 对应 一个 确定 的 类别 
代码 如下 1 # 文本 数据集 2 def loadDataList 3 
postingList = 4 my dog has flea problems help please 
5 maybe not take him to dog park stupid 6 
my dalmation is so cute I love him 7 stop 
posting stupid worthless garbage 8 mr licks ate my steak 
how to stop him 9 quit buying worthless dog food 
stupid 10 classVec = 0 1 0 1 0 1 
11 return postingList classVec4 . 2 对 文本 数据 的 
处理 从 文本 数据 中 提取 出 训练样本 的 属性 
集 这里 是 属性 集 是由 单词 组成 的 词汇 
集 代码 如下 1 # 提取 训练 集 的 所有 
词 2 def createVocabList dataSet 3 vocabSet = set 4 
for document in dataSet 5 vocabSet = vocabSet | set 
document # 两个 集合 的 并 集 6 return list 
vocabSet 这里 利用 集合 的 性质 对 数据集 提取 不同 
的 单词 函数 createVocabList 返回值 是 列表 类型 4.3 对词 
汇集 转化 成数 值类型 因为 单词 的 字符串 类型 无法 
参与 到 数值 的 计算 因此 把 一个 对象 的 
数据 由 词汇 集中 的 哪些 单词 组成 表示 成 
0 该 对象 没有 这个 词 1 该 对象 有 
这个 词 代码 如下 1 # 根据 类别 对词 进行 
划分 数值 型 的 类别 2 def setOfWords2Vec vocabList inputSet 
3 returnVec = 0 * len vocabList 4 for word 
in inputSet 5 if word in vocabList 6 returnVec vocabList 
. index word = 1 7 else 8 print the 
word % s is not in my Vocabulary % word 
9 return returnVec 参数 vocabList 是 词 汇集 inputSet 是 
对象 的 数据 而 返回值 是由 词 汇集 的 转换 
成 0 和 1 组成 的 对象 单词 在 词 
汇集 的 标记 4.4 朴素 贝叶斯 分类器 的 训练 函数 
这里 说明 一下 训练样本 是 postingList 列表 数据 属性 集 
是 词 汇集 类 标号 是 classVec 列表 数据 在 
编写 代码 时 考虑 到 对象 的 单词 在 词汇 
集中 占有率 比较 低 会 造成 词 汇集 转化 时有 
大量 的 0 组成 同时 又 会 造成 条件概率 大量 
为 0 又有 计算 真实 概率值 普遍 偏小 容易 造成 
下 溢出 因此 代码 对 计算 条件概率 时 进行 转换 
但 不 影响 条件概率 的 大小 排序 也 就 不会 
影响 朴素 贝叶斯 的 使用 代码 如下 1 2 求 
贝叶斯 公式 中的 先验概率 pAbusive 条件概率 p0Vect p1Vect 函数 中 
所求 的 概率值 3 是 变形 值 不影响 贝叶斯 的 
核心 思想 选择 具有 最高 概率 的 决策 4 5 
def trainNB0 trainMatrix trainCategory 6 numTrainDocs = len trainMatrix # 
样本 中 对象 的 个数 7 numWords = len trainMatrix 
0 # 样本 中 所有 词 的 集合 个数 8 
pAbusive = sum trainCategory / float numTrainDocs # 对 类别 
只有 两种 的 先验概率 计算 9 # 对 所有 词 
在 不同 的 类别 下 出现 次数 的 初始 化为 
1 为了 防止 计算 条件概率 出现 为 0 10 p0Num 
= ones numWords 11 p1Num = ones numWords 12 # 
对 不同 类别 出现 次数 的 初始 化为 2 词 
的 出现 数 初始 数 为 1 的 情况 下 
增加 分母 值 避免 概率值 大于 1 13 p0Denom = 
2.0 14 p1Denom = 2.0 15 for i in range 
numTrainDocs # 遍历 所有 对象 16 if trainCategory i = 
= 1 # 类别 类型 的 判断 17 p1Num + 
= trainMatrix i # 对 所有 词 在 不同 的 
类别 下 出现 次数 的 计算 18 p1Denom + = 
sum trainMatrix i # 对 不同 类别 出现 次数 的 
计算 19 else 20 p0Num + = trainMatrix i # 
对 所有 词 在 不同 的 类别 下 出现 次数 
的 计算 21 p0Denom + = sum trainMatrix i # 
对 不同 类别 出现 次数 的 计算 22 p1Vect = 
log p1Num / p1Denom # 条件概率 用 对数 的 形式 
计算 是 为避免 概率值 太小 造成 下 溢出 23 p0Vect 
= log p0Num / p0Denom # 条件概率 用 对数 的 
形式 计算 是 为避免 概率值 太小 造成 下 溢出 24 
return p0Vect p1Vect pAbusive4 . 5 朴素/nr 贝叶斯/nr 的/uj 分类/n 
函数/n 根据/p 先验概率/l 和/c 条件概率/i 对/p 不同/a 类别/n 的/uj 后验/nr 
概率/n 进行/v 计算/v 并 选取 后验/nr 概率 最大 的 类别 
作为 朴素 贝叶斯 预测 结果 值 代码 如下 1 # 
计算 后验/nr 概率 并 选择 最高 概率 作为 预测 类别 
2 def classifyNB vec2Classify p0Vec p1Vec pClass1 3 p1 = 
sum vec2Classify * p1Vec + log pClass1 # 对 未知 
对象 的 单词 的 每 一项 的 条件 概率 相加 
对数 相加 为 条件 概率 的 相乘 4 p0 = 
sum vec2Classify * p0Vec + log 1.0 pClass1 # 后面 
加上 的 一项 是 先验概率 5 if p1 p0 6 
return 1 7 else 8 return 04.6 测试 样本 的 
预测 通过 朴素 贝叶斯 算法 给出 两个 未知 类别 的 
对象 预测 其 类别 代码 如下 1 # 对 侮辱性 
语言 的 测试 2 def testingNB 3 listOposts listClasses = 
loadDataList # 训练样本 的 数据 listOposts 为 样本 listClasses 为 
样本 的 类别 4 myVocabList = createVocabList listOposts # 样本 
的 词汇 集 5 trainMat = # 对 样本 的 
所有 对象 相关 的 单词 转化 为 数值 6 for 
postinDoc in listOposts 7 trainMat . append setOfWords2Vec myVocabList postinDoc 
8 p0V p1V pAb = trainNB0 array trainMat array listClasses 
# 样本 的 先验概率 和 条件概率 9 10 testEntry = 
love my dalmation love # 未知 类别 的 对象 11 
thisDoc = array setOfWords2Vec myVocabList testEntry # 对 未知 对象 
的 单词 转化 为 数值 12 print testEntry classified as 
classifyNB thisDoc p0V p1V pAb # 对 未知 对象 的 
预测 其 类别 13 14 testEntry = stupid garbage # 
未知 类别 的 对象 15 thisDoc = array setOfWords2Vec myVocabList 
testEntry # 对 未知 对象 的 单词 转化 为 数值 
16 print testEntry classified as classifyNB thisDoc p0V p1V pAb 
# 对 未知 对象 的 预测 其 类别 其 运行 
结果 图 对象   love my dalmation love 由 直观 
可知 其 类别 是非 侮辱性 词汇 与 预测 结果 0 
代表 正常 语言 相同 对象   stupid garbage 类 别是 
侮辱性 词汇 与 预测 结果 1 代表 侮辱性 语言 相同 
说明 朴素 贝叶斯 算法 对 预测 类别 有效 5 例子 
对 垃圾 邮件 的 识别 这里 给出 朴素 贝叶斯 算法 
最 经典 的 应用 实例 对 垃圾 邮件 的 过滤 
识别 由于 邮件 是 以 文件 的 形式 保存 因此 
我们 要 对 邮件 的 内容 进行 提取 并 处理 
成 符合 算法 可用 的 类型 5.1 邮件 文件 解析 
利用 正则 语 言对 邮件 的 内容 进行 单词 的 
划分 代码 如下 1 # 邮件 文件 解析 2 def 
textParse bigString 3 import re 4 listOfTokens = re . 
split r \ w * bigString # 利用 正则 语 
言对 邮件 文本 进行 解析 5 return tok . lower 
for tok in listOfTokens if len tok 2 # 限定 
单词 的 字母 大于 2 第 5 行 代码 解释 
lower 方法 转换 字符串 中 所有 大写 字符 为 小写 
5.2 垃圾邮件 测试函数 代码 如下 1 # 完整 的 垃圾 
邮件 测试函数 2 def spamTest 3 docList = classList = 
fullText = 4 for i in range 1 26 5 
wordList = textParse open email / spam / % d 
. txt % i . read 6 docList . append 
wordList # 把 解析 后的/nr 邮件 作为 训练样本 7 fullText 
. extend wordList 8 classList . append 1 # 邮件 
所 对应 的 类别 9 wordList = textParse open email 
/ ham / % d . txt % i . 
read 10 docList . append wordList # 把 解析 后的/nr 
邮件 作为 训练样本 11 fullText . extend wordList 12 classList 
. append 0 # 邮件 所 对应 的 类别 13 
vocabList = createVocabList docList # 样本 生成 的 词汇 集 
14 # 随机 产生 十个 测试 样本 和 四十个 训练样本 
15 trainingSet = range 50 testSet = 16 for i 
in range 10 17 randIndex = int random . uniform 
0 len trainingSet 18 testSet . append trainingSet randIndex 19 
del trainingSet randIndex 20 # 对 训练 样本 进行 词 
的 转化 成数 值类型 21 trainMat = 22 trainClasses = 
23 for docIndex in trainingSet 24 trainMat . append setOfWords2Vec 
vocabList docList docIndex 25 trainClasses . append classList docIndex 26 
p0V p1V pSpam = trainNB0 array trainMat array trainClasses # 
训练样本 的 先验概率 及 条件概率 27 errorCount = 0 # 
测试 样本 的 出错 数 初始化 28 for docIndex in 
testSet 29 wordVector = setOfWords2Vec vocabList docList docIndex # 测试 
对象 的 词 的 数值 转化 30 if classifyNB array 
wordVector p0V p1V pSpam = classList docIndex # 预测 的 
类别 与 真实 类别 的 对比 31 errorCount + = 
1 32 print the error rate is float errorCount / 
len testSet # 测试 样本 的 出错率 第 17 行 
代码 解释 uniform 函数 是 在 random 模块 里 将 
随机 生成 下 一个 实数 它 在 x y 范围 
内 x 随机数 的 最小值 包含 该 值 y 随机数 
的 最大 值 不 包含 该 值 返回值 是 一个 
浮点数 运行 结果 图 结果显示 测试 集 的 出错 比例 
是 10% 由于 训练 集 是 随机 组合 的 因此 
每次 运行 的 结果 会 有所不同 在 机器学习 实战 一 
书中 给出 这个 算法 的 错误率 在 6% 左右 说明 
朴素 贝叶斯 算法 在 严苛 的 条件 下 也有 较好 
的 效果 严苛 条件 是 指 我们 对 属性 都是 
独立 的 这在 现实 中 很难 找到 符合 这样 的 
条件 对 垃圾 邮件 的 过滤 也是 不 例外 的 
如 bacon 培根 出现 在 unhealthy 不 健康 的 后面 
与 出现 在 delicious 美味 的 后面 的 概率 是 
不同 的 bacon 培根 常 常与 delicious 美味 的 搭配 
附 完整 代码 # * coding utf 8 * from 
numpy import * # 文本 数据集 def loadDataList postingList = 
my dog has flea problems help please maybe not take 
him to dog park stupid my dalmation is so cute 
I love him stop posting stupid worthless garbage mr licks 
ate my steak how to stop him quit buying worthless 
dog food stupid classVec = 0 1 0 1 0 
1 return postingList classVec # 提取 训练 集中 的 所有 
词 def createVocabList dataSet vocabSet = set for document in 
dataSet vocabSet = vocabSet | set document # 两个 集合 
的 并 集 return list vocabSet # 根据 类别 对词 
进行 划分 数值 型 的 类别 def setOfWords2Vec vocabList inputSet 
returnVec = 0 * len vocabList for word in inputSet 
if word in vocabList returnVec vocabList . index word = 
1 else print the word % s is not in 
my Vocabulary % word return returnVec # 文档 词 袋 
模型 可以 对 重复 的 单词 计数 def bagOfWords2Vec vocabList 
inputSet returnVec = 0 * len vocabList for word in 
inputSet if word in vocabList returnVec vocabList . index word 
+ = 1 return returnVec 求 贝叶斯 公式 中的 先验概率 
pAbusive 条件概率 p0Vect p1Vect 函数 中 所求 的 概率值 是 
变形 值 不影响 贝叶斯 的 核心 思想 选择 具有 最高 
概率 的 决策 def trainNB0 trainMatrix trainCategory numTrainDocs = len 
trainMatrix # 样本 中 对象 的 个数 numWords = len 
trainMatrix 0 # 样本 中 所有 词 的 集合 个数 
pAbusive = sum trainCategory / float numTrainDocs # 对 类别 
只有 两种 的 先验概率 计算 # 对 所有 词 在 
不同 的 类别 下 出现 次数 的 初始 化为 1 
为了 防止 计算 条件概率 出现 为 0 p0Num = ones 
numWords p1Num = ones numWords # 对 不同 类别 出现 
次数 的 初始 化为 2 词 的 出现 数 初始 
数 为 1 的 情况 下 增加 分母 值 避免 
概率值 大于 1 p0Denom = 2.0 p1Denom = 2.0 for 
i in range numTrainDocs # 遍历 所有 对象 if trainCategory 
i = = 1 # 类别 类型 的 判断 p1Num 
+ = trainMatrix i # 对 所有 词 在 不同 
的 类别 下 出现 次数 的 计算 p1Denom + = 
sum trainMatrix i # 对 不同 类别 出现 次数 的 
计算 else p0Num + = trainMatrix i # 对 所有 
词 在 不同 的 类别 下 出现 次数 的 计算 
p0Denom + = sum trainMatrix i # 对 不同 类别 
出现 次数 的 计算 p1Vect = log p1Num / p1Denom 
# 条件概率 用 对数 的 形式 计算 是 为避免 概率值 
太小 造成 下 溢出 p0Vect = log p0Num / p0Denom 
# 条件概率 用 对数 的 形式 计算 是 为避免 概率值 
太小 造成 下 溢出 return p0Vect p1Vect pAbusive # 计算 
后验/nr 概率 并 选择 最高 概率 作为 预测 类别 def 
classifyNB vec2Classify p0Vec p1Vec pClass1 p1 = sum vec2Classify * 
p1Vec + log pClass1 # 对 未知 对象 的 单词 
的 每 一项 的 条件 概率 相加 对数 相加 为 
条件 概率 的 相乘 p0 = sum vec2Classify * p0Vec 
+ log 1.0 pClass1 # 后面 加上 的 一项 是 
先验概率 if p1 p0 return 1 else return 0 # 
对 侮辱性 语言 的 测试 def testingNB listOposts listClasses = 
loadDataList # 训练样本 的 数据 listOposts 为 样本 listClasses 为 
样本 的 类别 myVocabList = createVocabList listOposts # 样本 的 
词汇 集 trainMat = # 对 样本 的 所有 对象 
相关 的 单词 转化 为 数值 for postinDoc in listOposts 
trainMat . append setOfWords2Vec myVocabList postinDoc p0V p1V pAb = 
trainNB0 array trainMat array listClasses # 样本 的 先验概率 和 
条件概率 testEntry = love my dalmation love # 未知 类别 
的 对象 thisDoc = array setOfWords2Vec myVocabList testEntry # 对 
未知 对象 的 单词 转化 为 数值 print testEntry classified 
as classifyNB thisDoc p0V p1V pAb # 对 未知 对象 
的 预测 其 类别 testEntry = stupid garbage # 未知 
类别 的 对象 thisDoc = array setOfWords2Vec myVocabList testEntry # 
对 未知 对象 的 单词 转化 为 数值 print testEntry 
classified as classifyNB thisDoc p0V p1V pAb # 对 未知 
对象 的 预测 其 类别 # 邮件 文件 解析 def 
textParse bigString import re listOfTokens = re . split r 
\ w * bigString # 利用 正则 语 言对 邮件 
文本 进行 解析 return tok . lower for tok in 
listOfTokens if len tok 2 # 限定 单词 的 字母 
大于 2 # 完整 的 垃圾 邮件 测试函数 def spamTest 
docList = classList = fullText = for i in range 
1 26 wordList = textParse open email / spam / 
% d . txt % i . read docList . 
append wordList # 把 解析 后的/nr 邮件 作为 训练样本 fullText 
. extend wordList classList . append 1 # 邮件 所 
对应 的 类别 wordList = textParse open email / ham 
/ % d . txt % i . read docList 
. append wordList # 把 解析 后的/nr 邮件 作为 训练样本 
fullText . extend wordList classList . append 0 # 邮件 
所 对应 的 类别 vocabList = createVocabList docList # 样本 
生成 的 词汇 集 # 随机 产生 十个 测试 样本 
和 四十个 训练样本 trainingSet = range 50 testSet = for 
i in range 10 randIndex = int random . uniform 
0 len trainingSet testSet . append trainingSet randIndex del trainingSet 
randIndex # 对 训练 样本 进行 词 的 转化 成数 
值类型 trainMat = trainClasses = for docIndex in trainingSet trainMat 
. append setOfWords2Vec vocabList docList docIndex trainClasses . append classList 
docIndex p0V p1V pSpam = trainNB0 array trainMat array trainClasses 
# 训练样本 的 先验概率 及 条件概率 errorCount = 0 # 
测试 样本 的 出错 数 初始化 for docIndex in testSet 
wordVector = setOfWords2Vec vocabList docList docIndex # 测试 对象 的 
词 的 数值 转化 if classifyNB array wordVector p0V p1V 
pSpam = classList docIndex # 预测 的 类别 与 真实 
类别 的 对比 errorCount + = 1 print the error 
rate is float errorCount / len testSet # 测试 样本 
的 出错率 if _ _ name _ _ = = 
_ _ main _ _ # testingNB # 对 侮辱性 
评价 的 测试 spamTest # 对 垃圾 邮件 的 测试 
完整 代码 