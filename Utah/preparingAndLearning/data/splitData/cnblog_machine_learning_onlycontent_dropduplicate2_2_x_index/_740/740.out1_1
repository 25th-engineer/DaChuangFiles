目录 + 前言/n SVM/w 机器学习/i 与/p 深度/ns 学习/v 人工智能/n 领域/n 
机器学习/i 与/p 深度/ns 学习/v SVM/w 简介/v SVM/w 原理/n 分析/vn 快速/d 
理解/v SVM/w 原理/n 线性/n 可分/v 和/c 线性/n 不可分/i 函数/n 间隔/n 
和/c 几何/r 间隔/n 超平面/n 分析/vn 与/p 几何/r 间隔/n 详解/v 二次/m 
最优化/v SVM/w 支持 向量 机 原理 详解 与 实践 前言 
去年 由于 工作 项目 的 需要 实际 运用 到了 SVM 
和 ANN 算法 也 就是 支持 向量 机 和 人工神经网络 
算法 主要 是 实现 项目 中 的 实时 采集 图片 
工业 高速 摄像头 采集 的 图像 识别 的 这 一 
部分 功能 虽然 几 经 波折 但是 还好 最终 还 
算 顺利 完成 了 项目 的 任务 忙碌 一年 趁着 
放假 有 时间 好好 整理 并 总结 一下 本文 的 
内容 包括 前面 的 部分 是 对 支持 向量 机 
原理 的 分析 后半 部分 主要 直接 上手 的 一些 
实践 的 内容 本文 的 原理 部分 针对 支持 向量 
机 的 原理 特别 拉格朗日 对偶性 求解 拉 个 拉格朗日 
函数 以及/c 和/c 函数/n 与/p 核/n 技巧/n 再到/i 软/a 间隔/n 
和/c 正则化/i 等/u 重要/a 内容/n 做/v 了/ul 一些/m 讨论/v 实践 
部分 的 目标 则 是 通过 对 实践 时 碰到 
的 问题 调 参 的 过程 的 讲解 可以 对 
前半部 分 讲解 的 SVM 原理 部分 的 内容 有 
一个 更 深入 的 了解 SVM 机器学习 与 深度 学习 
人工智能 领域 在 大 数据 人工智能 的 时代 深度 学习 
可以 说 火 得 一塌糊涂 美国 硅谷 的 大 公司 
都在/nr 布局 着 这个 领域 而 中国 国内 腾讯 百度 
阿里 巴巴 等 等 知名 企业 也都 在 这个 领域 
争先 发力 2017 年初 百度 迎来 陆奇/nr 前 微软 全球 
执行 副总裁 人工智能 领域 世界级 的 权威 要知道 百度 还有 
人工智能 大牛 Andrew Ng – 吴恩 达 所有 迹象 表明 
人工智能 必然 是 继 互联网 之后 的 全球 各 大 
公司 甚至 国家 必争 的 高地 机器学习 与 深度 学习 
由于 深度 学习 在 大 数据 预测 能力 上 的 
卓越 表现 当下 出现 了 深度 学习 是否 会 替代 
传统 机器学习 算法 并 淘汰 他们 的 讨论 但是 另一方面 
大多数 人 仍然 相信 深度 学习 不 会 代替 其他 
的 模型 或者 算法 对于 大多数 的 应用 像 一些 
简单 的 算法 如 逻辑 回归 支持 向量 机 表现 
的 已经 很 不错 了 使用 深度 学习会 让 问题 
复杂化 深度 学习 是 可以 应用 到 大 部分 领域 
的 但是 就像 前面 说 的 深度 学习 并非 所有 
问题 的 最优 方案 如果 你 的 工作 中 有 
用到 机器学习 算法 你 可以 尝试 传统 的 机器学习 算法 
也 可以 达到 很好 的 效果 虽然 现在 已经 有 
一些 工作 去 把 各 领域 的 知识 融入 到 
深度 学习 中的 但这 并 不能 完全 替代 原有 的 
上图 是 一个 关于 机器学习 算法 的 时间 线 来自于 
Eren Golge 就 像在 20 世纪 早期 SVM 一样 深度 
学习 会 成为 主流 但 首先 深度 学习 应当 解决 
其 在 大 数据 需求 及 复杂性 方面 的 问题 
这样 它 才会 成为 人们 的 第一 选择 SVM 简介 
SVM support vector machine 简单 的 说 是 一个 分类器 
并且 是 二类 分类器 Vector 通俗 说 就是 点 或是 
数据 Machine 也 就是 classifier 也 就是 分类器 SVM 作为 
传统 机器 学习 的 一个 非常 重要 的 分类 算法 
它 是 一种 通用 的 前馈 网络 类型 最早 是由 
Vladimir N . Vapnik 和 Alexey Ya . Chervonenkis 在 
1963年 提出 目前 的 版本 soft margin 是 Corinna Cortes 
和 Vapnik 在 1993年 提出 1995年 发表 深度 学习 2012 
出现 之前 SVM 被 认为 是 机器 学习 中 近 
十几 年最/nr 成功 表现 最好 的 算法 SVM 原理 分析 
快速 理解 SVM 原理 很多 讲解 SVM 的 书籍 都 
是从 原理 开始 讲解 如果 没有 相关 知识 的 铺垫 
理解 起来 还是 比较 吃力 的 以下 的 一个 例子 
可以 让 我们 对 SVM 快速 建立 一个 认知 给定 
训练样本 支持 向量 机 建立 一个 超平面 作为 决策 曲面 
使得 正 例和 反例 的 隔离 边界 最大化 决策 曲面 
的 初步 理解 可以 参考 如下 过程 如 下图 想象 
红色 和 蓝色 的 球 为 球 台上 的 桌球 
我们 首先 目的 是 找到 一条 曲线 将 蓝色 和 
红色 的 球 分开 于是 我们 得到 一条 黑色 的 
曲线 图一 . 2 为了 使 黑色 的 曲线 离 
任意 的 蓝球 和 红球 距离 也 就是 我们 后面 
要 提到 的 margin 最大化 我们 需要 找到 一条 最优 
的 曲线 如 下图 图二 . 3 想象 一下 如果 
这些 球 不是 在 球 桌上 而是 被 抛向 了 
空中 我们 仍然 需要 将 红色 球 和 蓝色 球 
分开 这时 就 需要 一个 曲面 而且 我们 需要 这个 
曲面 仍然 满足 跟 所有 任意 红球 和 蓝球 的 
间距 的 最大化 需要 找到 的 这个 曲面 就是 我们 
后面 详细 了解 的 最优 超平面 4 离 这个 曲面 
最近 的 红色 球 和 蓝色 球 就是 Support Vector 
线性 可分 和 线性 不可分 线性 可分 linearly separable 在 
二维 空间 可以 理解 为 可以 用 一条 直线 一个 
函数 把 两 类型 的 样本 隔开 被 隔离 开来 
的 两类 样本 即为 线性 可分 样本 同理 在 高维空间 
可以 理解 为 可以 被 一个 曲面 高维 函数 隔开 
的 两类 样本 线性 不可分 则 可以 理解 为 自变量 
和 因变量 之间 的 关系 不是 线性 的 实际上 线性 
可 不分 的 情况 更多 但是 即使 是 非线性 的 
样本 通常 也 是 通过 高斯 核 函数 将其 映 
射到 高维空间 在 高维空间 非线性 的 问题 转化 为 线性 
可分 的 问题 函数 间隔 和 几何 间隔 函数 间隔 
functional margin 给定 一个 训练样本 有 函数 间隔 代表 了 
特征 是 正 例 或是 反例 的确 信度 几何 间隔 
geometrical margin 向量 点到 超平面 的 距离 其中 后面 详细 
介绍 超平面 分析 与 几何 间隔 详解 前面 已经 对 
SVM 的 原理 有了/nr 一个 大概 的 了解 并且 简单 
介绍 了 函数 间隔 和 几何 间隔 的 概念 为了 
更好 的 理解 线性 可分 模式 下 超平面 以下 将 
进行 深入 的 剖析 推导 过程 我们 假设有 训练样本 集 
期望 的 响应 为 这里 我们 用 类 + 1 
和类/nr 1 来 代表 以 表明 样本 是 线性 可分 
的 决策 曲面 方程 如下 其中 x 输入 向量 也 
就是 样本 集合 中的 向量 w 是 可调 权值 向量 
每个 向量 可调 权值 T 转置 向量 的 转置 b 
偏置 超平面 相对 原点 的 偏移 根据 逻辑 回归 定义 
展开 其实 就是 其中 假设 约定 于是 将 替换成 b 
则有 而 T 是 转置 所以有 这里 假设 模式 线性 
可分 线性 可分 模式 下 最优 超平面 的 示意图 如下 
如上 图 所示 为 分离 边缘 即 超平面 和 最近 
数 据点 的 间隔 如果 一个 平面 能使 最大 则为 
最优 超平面 灰色 的 方形 点 和 原形 点 就是 
我们 所说 的 支持 向量 假设/vn 和/c 向量/n 和/c 偏置/n 
的/uj 最优/d 解/v 则 最优 超平面 的 函数 为 相应 
的 判别函数 是 以下 是 点 x 到 最优 超平面 
的 二维 示意图 由 上图 可知 r 为 点 x 
到 最优 超平面 的 距离 那么 代数 距离 是 如何 
得到 的 呢 通过 将 带入 可以 得到 r 其中 
为 x 在 最优 超平面 的 正轴 投影 因为 在 
平面 上 下面 给 出 一种 更为 简单 且 直观 
的 理解 首先 我们 必须 要 知道 Euclidean norm 范数 
即 欧几里德 范数 以 下用 w 表示 多维 的 向量 
再 参考 点到面 的 距离 公式 也就是 类似 的 扩展到 
多维 的 w 向量 也是 一样 代数 距离 r 类似于 
d 而 类似 于 所以 展开 后 也就是 对比 点 
平面 的 公式 以上 的 r 也就 多维 度空间 向量 
的 到 最优 超平面 的 距离 再看 上图 如果 x 
= 0 即 原点 则有 那么 是 如何 得到 的 
呢 很 简单 如 上面 分析 的 因为 x = 
0 它 在 原点 它 与 任意 可调 权值 向量 
w 相乘 都 等于 0 于是 有 注意 b 为 
偏置 只是 决定 了 决策 曲面 相对 原点 的 偏离 
结合 上 图 我们 可 知道 b 0 则 原 
点在 最优 超平面 的 正面 b 0 则 原 点在 
最优 超平面 的 负面 b = 0 则 原点 就在 
最优 超平面 上 找到 的 这个 最优 超平面 的 参数 
和 于是 在 样本 向量 集中 有 一对 一定 满足 
因为 是 常数 它 只是 决定 了 决策 曲面 相对 
原点 的 偏离 满足 上式 的 点 就是 则为 支持 
向量 这些 点 距离 决策 曲面 也就 时 超平面 最近 
时 最难 区分 的 点 于是/nr 根据 点到 超平面 的 
距离 公式 在/p 超平面/n 的/uj 正面/ad 和/c 负面/n 我们/r 有/v 
任一/r 支持/v 向量/n 满足/v 代数/n 距离/n 如果 让 表示 两个 
分离 边缘 的 最优 值 则 根据 上式 有 所以 
我们 可以 看出 如果 要 使得 最大 则 就 必须 
使得 最小 也 就 可以 总结 为 最大化 两个 类 
之间 的 分离 边缘 等价 于 最小化 权值 向量 w 
的 欧几里得 范数 二次 最优化 回头 看 我们 前面 提到 
的 给定 一个 训练 集 我们 的 需求 就是 尝试 
找到 一个 决策 边界 使得 几何 间隔 最大 回归 到 
问题 的 本质 那 就是 我们 如何 找到 这个 最大 
的 几何 间隔 要 想要 最大化 间隔 margin 正如 上面 
提到 的 最大化 两个 类 之间 的 分离 边缘 等价 
于 最小化 权值 向量 w 的 欧几里得 范数 即 其中 
也 就是 前面 提到 的 函数 间隔 回顾 几何 间隔 
约束条件 就是 让 函数 间隔 等于 几何 间隔 或是 将 
优化 的 问题 转化 为 以下 式子 其中 就是 将 
函数 间隔 和 几何 间隔 联系起来 我们 发现 以上 两个 
式子 都 可以 表示 最大化 间隔 的 优化 问题 但是 
我们 同时 也 发现 无论 上面 哪个 式子 都 是非 
凸 的 并 没有 现成 的 可用 的 软件 来 
解决 这 两种 形式 的 优化 问题 于是/nr 一个 行之有效 
的 优化 问题 的 形式 被 提出 来 注意 它 
是 一个 凸函数 形式 如下 以上 的 优化 问题 包含 
了 一个 凸 二 次优化 对象 并且 线性 可分 概括 
来说 就是 需 找 最优 超平面 的 二次 最优化 这个 
优化 的 问题 可以 用 商业 的 凸 二次 规划 
代码 来 解 凸函数 在 凸 集中 任取 两个 点 
连成 一条 直线 这条 直线 上 的 点 仍然 在 
这个 集合 内部 左边 凸函数 局部 最优 就是 全局 最优 
而 右边 的 非 凸函数 的 局部 最优 就 不是 
全局 最优 了 下面 要 具体 介绍 的 拉格朗日 对偶性 
它 可以 引导 我们 到 优化 问题 的 对偶 形式 
因为 对偶 形式 在 高维空间 有效 的 运用 核 函数 
来 得到 最优 间隔 分类器 的 方法 中 扮演 了 
非常 重要 的 角色 对偶 形式 让 我们 得到 一个 
有效 的 算法 来 解决 上述 的 优化 问题 并且 
相较 通用 的 二次 规划 商业软件 更好 优化 问题 的 
对偶 形式 的 方法 简单 来说 就是 通过 Lagrange Duality 
变换 到 对偶 变量 dual variable 的 优化 问题 之后 
应用 拉格朗日 对偶性 通过 求解 对偶 问题 得到 最优 解 
这 就是 线性 可分 条件下 支持 向量 机 的 对偶 
算法 这样 做 的 优点 在于 一是 原 问题 的 
对偶 问题 往往 更容易 求解 二者 可以 自然 的 引入 
核 函数 进而 推广 到 非线性 分类 问题 