转载 请 注明 出处 http / / www . cnblogs 
. com / ymingjingr / p / 4271742 . html 
目录 机器学习 基石 笔记 1 在 何时 可以 使用 机器学习 
1 机器学习 基石 笔记 2 在 何时 可以 使用 机器学习 
2 机器学习 基石 笔记 3 在 何时 可以 使用 机器学习 
3 修改版 机器学习 基石 笔记 4 在 何时 可以 使用 
机器学习 4 机器学习 基石 笔记 5 为什么 机器 可以 学习 
1 机器学习 基石 笔记 6 为什么 机器 可以 学习 2 
机器学习 基石 笔记 7 为什么 机器 可以 学习 3 机器学习 
基石 笔记 8 为什么 机器 可以 学习 4 机器学习 基石 
笔记 9 机器 可以 怎样 学习 1 机器学习 基石 笔记 
10 机器 可以 怎样 学习 2 机器学习 基石 笔记 11 
机器 可以 怎样 学习 3 机器学习 基石 笔记 12 机器 
可以 怎样 学习 4 机器学习 基石 笔记 13 机器 可以 
怎样 学 得 更好 1 机器学习 基石 笔记 14 机器 
可以 怎样 学 得 更好 2 机器学习 基石 笔记 15 
机器 可以 怎样 学 得 更好 3 机器学习 基石 笔记 
16 机器 可以 怎样 学 得 更好 4 二 Learning 
to Answer Yes / No 二元 分类 解决 上 一章 
提出 的 银行 发行 信用卡 的 问题 2.1 Perceptron Hypothesis 
Set 感知器 的 假设 空间 还是 银行 发 信用卡 的 
例子 银行 可能 掌握 了 用户 的 各种 属性 如 
年龄 年薪 工作 年限 负债 情况 等等 这些 属性 可以 
作为 上面 提到 的 样本 输入 的 向量 属性值 但是 
这样 还是 无法 进行 机器学习 因为 我们 还 需要 另 
一个 输入 即 假设 空间 H 假设 空间 该 如何 
表示 呢 本节 提出 了 一种 表示 方式 这种 学习 
的 模型 称之为 感知器 Perceptron 其实 感知器 的 产生 很早 
算 是 第一 代的/nr 单层 神经网络 这里 就不 多做 介绍 
在 其他 的 读书 笔记 中 进行 说明 这种 假设 
空间 的 思想 就 类似 考试 给 的 成绩 对 
每 一题 给 一个 特定 的 分数 即 权重 说白 
了 就是 给 输入 向量 的 每个 属性 乘以 一个 
加 权值 在 设计 一个 及格线 即 所谓 的 阈值 
或者 叫 门槛 值 threshold 如果 加权 求和 的 分数 
大于 这个 及格线 就叫 及格 了 即 对应 的 输出 
值 为 1 小于 这个 及格线 成为 不 及格 对应 
的 输出 值 为 1 其中 h x ∈ H 
如 公式 2 1 所示 公式 2 1 其中 sign 
括号 中 所 包含 的 内容 大于 0时 取 + 
1 小于 0时 取 1 此时 可以 对 h x 
做 一些 数学上 的 简化 注意 这 仅仅 是 一种 
数学 表示 方式 的 简化 如 公式 2 2 所示 
公式 2 2 如上 所示 将 阈值 的 负数 表示 
为 权值 向量 中的 一项 用 表示 而 对应 权值 
分量 的 输入 分量 则 被 默认 为 1 用 
最终 将 公式 简化 为 两个 向量 内积 的 形式 
其中 T 表示 转置 这里 必须 说明 一个 问题 就是 
不同 h x 对应 着 不同 的 向量 即 可以 
说 假设 空间 H 就是 向量 的 取值 范围 这么 
描述 还是 很 抽象 因此 引入 一种 方式 就是 使用 
图像 或者 可以 说 是 几何 来 更 形象 更 
具体 的 来 说明 以上 函数 这里 说 点 题外话 
由于 二元 函数 和 三元 函数 可以 使用 几何 图像 
来 一一对应 用 几何 的 方式 更 直观 的 表示 
函数 的 意义 方便 大家 理解 这在 以后 的 章节 
中 会 不断 使用 为了 理解 的 方便 将 输入 
向量 的 维度 限制 为 两个 即 h 函数 可以 
表示 成 公式 2 3 公式 2 3 将/d 输入/v 
向量/n 对应/vn 于/p 一个二维/m 平/n 面上/f 的/uj 点/m 如果 向量 
的 维度 更高 对应 于 一个 高维空间 中的 点 输出 
y 在 分类 问题 中 又 称作 标签 label 使用 
○ 表示 + 1 × 表示 1 假设 h 对应 
一条条 的 直线 如果 在 输入 向量 是 高维空间 的话 
则 对应 于 一个 超平面 这里 不止 一条 不同 的 
权值 向量 对应 不同 的 直线 因为 sign 是以 0 
为 分界线 的 函数 所以 可以 设 该 式 恰是 
一条 直线 的 表示 因此 每条 边的/nr 一边 为 正 
的 而 另一边 为 表示 为 负 的 最终 得到 
的 图像 如 1 所示 1 感知器 在 维度 为 
2时 的 几何 表示 因此 这里 将 感知器 作为 一条 
二元 线性 分类器 linear binary classifiers 2.2 Perceptron Learning Algorithm 
PLA 感知器 学习 算法 在 第一 章中 我们 介绍 过 
一个 机器学习 模型 由 两部分 组成 而上 一节 仅仅 介绍 
了 它 其中 的 一部分 即 假设 空间 H 如何 
表示 本节 我们 将 更 详细 的 介绍 感知器 的 
算法 A 即 如何 从 假设 空间 中 找到 一个 
近似 未知 目标函数 f 的 最好 假设 g x 问题 
是 我们 如何 找到 这个 g x 呢 首先 考虑 
g x 和/c 目标函数/i f/w 越/d 接近/v 越好/d 但 问题 
是 我们 不 知道 f 如果 知道 了 就 不 
需要 学习 了 但是 我们 知道 些 什么 呢 知道 
的 是 样本 输入 x 在 f x 作用 下 
得到 的 标记 y 所以 如果 我们 能 使得 g 
x 在 所有 的 样本 输入 中都 能够 得到 跟 
f 函数 作用 过 输入 得到 的 输出 一样 的话 
我们 认为 这时 的 g 是 不错 的 在 后面 
的 章节 还会在 这种 思想 的 基础 上 更 深入 
的 讨论 这 一 问题 但是 问题 又来了 假设 空间 
H 的 函数 h x 有 无数种 表示 即 向量 
w 有 无数种 取值 如在 二元 输 入时 假设 空间 
对于 在 二维 平 面上 的 直线 在 那个 空间 
中 可以 画 出 无数 条 直线 面对 这 无数 
多种 情况 我们 又 该 如何 求解 我们 想到 一个 
简单 的 方式 就是 一步 一步 的 修正 错误 的 
分类 在 二维 平面 中 可以 想象 成 一条 初始 
的 直线 在 经过 不断 的 纠正 它 的 错误 
就是 旋转 平移 之类 的 使得 最终 的 结果 可以 
达到 希望 的 效果 还要 在 重复 上 一节 中 
已经 得到 的 一个 结论 在 感知器 模型 中 每一个 
假设 函数 h 都 对应 一个 权值 向量 因此 我们 
要 做 的 就是 不断 修正 这个 权值 向量 使得 
最接近 目标函数 f 下面 来 详细 介绍 一下 PLA 首先 
我们 在 设置 初始 注意 此处 是 向量 不是 向量 
的 分量 比如 设置 为 0 向量 然后 使用 训练 
样 本来 将 权值 向量 修正 的 更 接近 目标函数 
f 其 修正 步骤 如下 将 权值 向量 的 修正 
次数 表示 为 t t = 0 1 2 在 
何种 情况 下 需要 修正 向量 呢 如 公式 2 
4 所示 公式 2 4 其中 训练样本 为 在 t 
次 时 使用 的 输入 向量 而为 在 t 次 
时的/nr 标记 量 该 公式 2 4 的 意思 就是 
在 t 次 时 选择 的 权值 向量 有 一个 
训练样本 使得 在 经过 即 假设 计算 的 得到 的 
标签 与 f x 得到 的 标签 不一致 在 这种 
情况下 就 需要 对 权值 向量 进行 修改 使 它 
符合 条件 修改 的 公式 如 公式 2 5 所示 
公式 2 5 从 直觉 上 理解 这个 公式 相对 
困难 我们 还是 将 它 化成 一个 几何图形 更 准确 
的 说法 变成 向量 加减 的 形式 去 理解 它 
如 2 所示 2 公式 2 5 的 几何 解 
a b 2a 中 是 在 本身 标记 为 + 
1时 权值 向量 和 输入 向量 的 内积 为 负数 
对 权值 向量 略作 修改 加上 一个 标记 y 和 
输入 向量 的 乘积 得到 一个 新的 权值 向量 可以 
看出 新的 权值 向量 和 输入 向量 的 相乘 之后 
符合 了 标记 的 要求 2b 中 是 在 本身 
标记 为 1时 权值 向量 和 输入 向量 的 内 
积为 正数 对 权值 向量 略作 修改 加上 一个 标记 
y 和 输入 向量 的 乘积 得到 一个 新的 权值 
向量 可以 看出 新的 权值 向量 和 输入 向量 的 
相乘 之后 符合 了 标记 的 要求 而 非常 巧合 
的 是 只需要 乘以 一个 该 训练 样本 的 标记 
就 可以 将 这 两种 情况 合为 一种 情况 如 
公式 2 5 所示 如此这般 的 重复 查找 错误 样本 
和 修改 加 权向量 直到 再也 找 不到 可以 使 
公式 2 4 成立 的 样本 为止 此时 得到 的 
加权 向量 即 为 我们 想要 的 最终 g 描述 
了 上面 内容 之后 你 很 可能 有 一个 疑问 
就 如何查找 错误 样本点 或者 如何 确定 没有 错误 的 
点了 一个 简单 的 方式 就是 将 训练样本 编号 从1到/nr 
n 整个 训练样本 就有 n 个 点 以/p 按/p 从1到/nr 
n/w 的/uj 顺序/n 不断/d 查/v 找错/i 误点/n 如果 没有 错 
就 自动 的 用 下一个 样本点 继续 查找 当/t 从1到/nr 
n/w 这/r n/w 个/q 样本点/i 都/d 没有/v 产生/n 错误/n 时/n 
算法 即 结束 得到 g 将 这种 方式 的 算法 
叫做 Cyclic PLA 这时候 就 又 出来 几个 新的 问题 
第一 这个/r 算法/n 一定/d 会/v 找到/v 一个/m 能使/nr 所有/b 的/uj 
样本/n 都/d 不符合/i 即 都被 分 对了 类 的 情况 
吗 就是 这个 算法 会 不会 停止 第二 个 问题 
这个 算法 找到 的 真的 是 最好 的 g 吗 
看起来 好像 只是 在 训练 样本 中 才 符合 这一 
性质 如果 出现 新的 样本 的话 又 会 如何 呢 
第一 个 问题 下一 小节 将 进行 介绍 而 其他 
问题 会 在 后面 的 章节 中 讨论 2.3 Guarantee 
of PLAPLA 算法 可行 的 保障 PLA 算法 只有 在 
满足 训练样本 是 线性 可分 linear separable 的 情况下 才 
可以 停止 什么 是 线性 可分 呢 简单 的 说 
就是 存在 一条 直线 能将 两类 样本点 完全 分开 如 
3 所示 3 线性 可分 与 线性 不可分 其中 最 
左边 的 为 线性 可分 的 训练样本 而 右边 两个 
图形 为 线性 不 可分 的 两种 情况 这 两种 
情况 会 在 后面 的 章节 一一 解释 我们 需要 
证明 在 线性 可分 的 情况 下 权值 向量 在 
经过 一段 时间 的 修正 会 停止 即 t 次 
修正 会 有一个 上界 首先 我们 考虑 是否 每次 修正 
都 可以 使得 权值 向量 变得 更好 就是 是否 会 
更 接近 未知 的 目标 函数 所 表示 的 向量 
有了/nr 这个 思路 我们 先 假设 目标函数 的 权值 向量 
为 可以 求解 出 两个 向量 相似 度 的 度量 
方式 有 很多 其中 比较 常用 的 一种 方式 就是 
求 两个 向量 的 内积 于是 我们 对 和做/nr 内积 
其中 T 表示 为 停止 时的/nr 次数 直接 使用 这 
两个 向量 做 内积 其 内积 越大 并 不能 代表 
这两个 向量 越 接近 因为 向量 本身 的 变长 也 
可以 导致 这 一 现象 因此 我们 需要 求解 的 
是 这两个 向量 做 归一化 就是 各自 除以 自身 的 
L1 范式 得到 单位向量 之后 的 内积 这时 它 俩 
的 内积 有了 上界 即为 1 如 公式 2 6 
所示 公式 2 6 乍一看 公式 2 6 完全 无从下手 
是 未知 目标 向量 是 终止 时的/nr 向量 也 是 
一个 未知 向量 因此 思路 就是 将 其中 一个 未知量 
消除 消除 的 可能性 不大 因此 选择 消除 在 公式 
中的 不确定性 如 公式 2 7 所示 是 解决 归一化 
之前 两个 向量 内积 的 问题 取 所有 的 样本 
中的 最小 乘积 因为 是 在 线性 可分 情况下 的 
目标 函数 所以 所有 的 必定 大于 等于 0 进行 
迭代 又 因为 初始值 设置 为 0 向量 因此 公式 
2 7 除了 不 容易 确定 之外 的 L1 范式 
也 不容易 得出 如 公式 2 8 是 求解 L1 
范式 的 不等式 其 思想 如 公式 2 7 因为 
只有 在 犯错 的 情况下 才 会 进行 改变 那 
什么 时候 是 犯错 就是 在 公式 2 4 成立 
的 情况 即 该 公式 等价 于 因此 如下 公式 
2 8 通过 公式 2 7 和 公式 2 8 
可以 将 公式 2 6 写成 如 公式 2 9 
如 下式 所示 公式 2 9 将 公式 2 9 
中的 常数 设置 为 C 该 公式 如 公式 2 
10 所示 公式 2 10 可以 看出 权值 向量 和 
目标函数 内积 会 以 的 速度 不断 的 增长 但是 
这种 增长 不 是 没有 限制 的 它 最多 只能 
等于 1 因此 有 以下 结论 如 公式 2 11 
所示 公式 2 11 求解 得到 公式 2 12 的 
结论 公式 2 12 将 公式 2 12 中的 值 
分别 使用 简单 的 数字 符号 代替 如 公式 2 
13 和 公式 2 14 所示 公式 2 13 公式 
2 14 从 公式 2 12中 就 可以 看出 T 
是 有 上界 即在 线性 可分 的 情况 下 PLA 
算法 最终 会 停止 找到 一个 最 接近 目标 函数 
的 假设 函数 g 2.4 Non Separable Data 线性 不 
可分 的 数据 上 一节 的 阐述 PLA 这个 算法 
一定 会 停下来 这一 结论 是 建立 在 存在 一个 
目标函数 可以 将 所有 的 数据 点 都 线性 分开 
这个 假设 的 基础 之上 对于 一堆 复杂 的 数据 
如何 能 确定 它 一定 是 线性 可分 的 比如 
一个 PLA 算法 运行 了 很长 时间 仍然 没有 停止 
此时 存在 两种 可能性 一是 该 数据集 是 线性 可分 
的 但是 还 没有 运行 结束 另一种 压根 就 不 
存在 一条 直线 可以 将 数据集 分开 就是 压根 这个 
算法 就不会 终止 假如 是 后者 又该 如何 处理 首先 
还是 要 解释 下 为什么 会 出现 后者 此种 情况 
出现 的 概率 大 吗 出现 不 可分 的 一种 
可能 是 从未 知 目标函数 中 产生 的 训练样本 存在 
噪音 noise 如 录入 样本 时有 人工 的 错误 等 
情况 导致 数据 本身 不 正确 使得 最终 本 可以 
线性 可分 的 样本 集 变得 线性 不可 分了 如 
4 所示 4 加入 噪音 的 机器学习 流程图 而 噪音 
占 整个 数据集 的 比例 一般 不会 太大 如 5 
所示 这种 情况 下 我们 又 该 如何 计算 出 
最佳 的 假设 g 呢 5 存在 噪音 时 线性 
不 可分 的 情况 其实 5 已经 在 前面 的 
小节 中 出现 过 一种 新的 思路 是 找出 犯错 
最少 的 权值 向量 如 公式 2 15 所示 公式 
2 15 其中 表示 当 满足 条件 时 输出 1 
否 则为 0 但是 这个 公式 在 数学 上 是 
NP 难 问题 我们 无法 直接 求解 于是 我们 需要 
找 出 一种 近似 的 算法 来 求解 这个 问题 
这里 介绍 一个 叫 pocket 的 算法 它 的 本质 
是 一种 贪心 算法 做 一 简单 的 介绍 也是 
随机 的 初始化 一个 权值 向量 随机 的 使用 n 
个 点中 的 一个 点 去 发现 是否 有 错误 
此处 与 cyclic PLA 使用 的 循环 方式 有所 不同 
不是 按 顺序 一个 一个 的 查看 是否 符合 条件 
而是 在 n 个 点中 随机 的 抽取 这种 方式 
可以 增加 其 寻找 最优 解的/nr 速度 和 PLA 一样 
使用 公式 2 5 进行 修正 . 如果有 了 修正 
则 计算 出 刚刚 修 正过 的 权值 向量 和 
上一个 权值 向量 到底 谁 犯 的 错误 比较 少 
将 少 的 保留 重复 第 2步 到 第 4步 
的 动作 假如/c 很长/i 时间/n 都/d 没有/v 新的/i 权值/i 向/p 
量比/i 当前/t 的/uj 权值/i 向量/n 犯错/v 更少/d 则 返回 该 
向量 作为 函数 g 