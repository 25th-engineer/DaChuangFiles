背景 在 公司 内部 我 负责 帮助 研究院 的 小伙伴 
搭建 机器学习 web 服务 研究院 的 小伙伴 提供 一个 机器学习 
本地 接口 我 负责 提供 一个 对外 服务 的 HTTP 
接口 说起 人工智能 和 机器学习 python 是 最 擅长 的 
其 以 开发 速度 快 第三/m 方库/nr 多而/i 广/a 受欢迎/v 
以至于 现在 大多数 机器学习 算法 都是 用 python 编写 但是 
对于 服务化 来说 python 有 致命 的 问题 很难 利用 
机器 多核 由于 一个 python 进程 中 全局 只有 一个 
解释器 故 多线程 是 假 的 多个 线程 只能 使用 
一个 核 要想 充分 利用 多核 就 必须 使用 多进程 
此外 由于 机器学习 是 CPU 密集型 其 对 多核 的 
需求 更为 强烈 故 要想 服务化 必须 多进程 但是 机器学习 
服务 有 一个 典型 特征 服务 初始 化时 有 一个 
非常 大 的 数据模型 要 加载 到 内存 比如 我 
现在 要 服务化 的 这个 模型 加载 到 内存 需要 
整整 8G 的 内存 之后 在 模型 上 的 分类 
预测 都是 只读 没有 写 操作 所以在 多进程 基础 上 
也要 考虑 内存 限制 如果 每个 进程 都 初始化 自己 
的 模型 那么 内存 使用量 将 随着 进程 数 增加 
而 成倍 上涨 如何 使得 多个 进程 共享 一个 内存 
数据模型 也是 需要 解决 的 问题 特别 的 如何 在 
一个 web 服务 上 实现 多进程 共享 大 内存 模型 
是 一个 棘手 的 问题 首先 我们 来 看看 如何 
进行 web 服务化 呢 我 使用 python 中 广泛 利用 
的 web 框架 Flask + gunicorn Flask + gunicorn 我 
这 里面 认为 大伙 都 用过 所以 我 后面 写 
的 就 省略 些 主要 精力 放在 遇到 的 问题 
和 解决 问题 的 过程 实现 方式 1 每个 进程 
分别 初始化 自己 的 模型 为此 我 编写 了 一个 
python 文件 来 对 一个 分类 模型 进行 服务化 文件 
首先 进行 模型 初始化 之后 每次 web 请求 对 请求 
中 的 数据 data 利用 模型 进行 预测 返回 其 
对应 的 标签 # label _ service . py # 
省略 一些 引入 的 包 model = Model # 数据模型 
model . load # 模型 加载 训 练好 的 数据 
到 内存 中 app = Flask _ _ name _ 
_ class Label MethodView def post self data = request 
. data label = model . predict data return label 
app . add _ url _ rule / labelservice / 
view _ func = Label . as _ view label 
methods = POST GET 利用 gunicorn 进行 启动 gunicorn 的 
好处 在于 其 支持 多进程 每个 进程 可以 独立 的 
服务 一个 外部 请求 这样 就 可以 利用 多核 gunicorn 
w8 b 0.0 . 0.0 12711 label _ service app 
其中 w8 意思 是 启动 8个 服务 进程 满心欢喜 的 
启动 但是 随即 我 就 发现 内存 直接 爆 掉 
前面 说过 我 的 模型 加载 到 内存 中 需要 
8个 G 但是 由于 我 启动 了 8个 工作 进程 
每个 进程 都 初始化 一次 模型 这就 要求 我 的 
机器 至少有 64G 内存 这 无法 忍受 可是 如果 我 
就 开 一个 进程 那么 我 的 多核 机器 的 
CPU 就 浪费 了 怎么办 那么 有 没有 什么 方法 
能够 使得 8个 工作 进程 共用 一份 内存 数据模型 呢 
很遗憾 python 中 提供 多进程 之间 共享内存 都是 对于 固定 
的 原生 数据类型 而 我 这 里面 是 一个 用户 
自定义 的 类 此外 模型 中 依赖 的 大量 的 
第三 方 机器学习 包 这些 包 本身 并不 支持 共享内存 
方式 而且 我 也 不 可能 去 修改 它们 的 
源码 怎么办 gunicorn 进程 模型 仔细 看了 gunicorn 的 官方 
文档 其中 就 有对 其 工作 模型 的 描述 gunicorn 
主 进程 负责 fork 子 进程 并 监控 子 进程 
根据 外部 信号 来 决定 是否 增加 或者 减少 子 
进程 的 数量 gunicorn 子 进程 负责 接收 web 请求 
并且 完成 请求 计算 我 突发 奇想 我 可以 利用 
gunicorn 父子 进程 在 fork 时 共享 父进程 内存空间 直接 
使用 模型 只要 没有 对 模型 的 写 操作 就 
不会 触发 copy on write 内存 就 不会 由于 子 
进程 数量 增加 而 成本 增长 原理图 如下 主 进程 
首先 初始化 模型 之后 fork 的 子 进程 直接 就 
拥有 父进程 的 地址 空间 接下来 的 问题 就是 如何 
在 gunicron 的 一个 恰当 的 地方 进行 初始化 并且 
如何 把 模型 传递 给 Flask 实现 方式 2 利用 
gunicorn 配置文件 只在 主 进程 中 初始化 模型 查看 gunicorn 
官方 文档 可以 在 配置文件 配置 主 进程 初始化 所需 
的 数据 gunicorn 保证 配置文件 中 的 数据 只在 主 
进程 中 初始化 一次 之后 可以 利用 gunicorn 中的 HOOK 
函数 pre _ request 把 model 传递 给 flask 处理 
接口 # gunicorn . conf import sys sys . path 
. append . # 必须 把 本地 路径 添加到 path 
中 否则 gunicorn 找不到 当前目录 所 包含 的 类 model 
= Model model . load def pre _ request worker 
req req . headers . append FLASK _ MODEL model 
# 把 模型 通过 request 传递 给 flask pre _ 
request = pre _ request # label _ service . 
py # 省略 一些 引入 的 包 app = Flask 
_ _ name _ _ class Label MethodView def post 
self data = request . data model = request . 
environ HTTP _ FLASK _ MODEL # 从 这里 取出 
模型 注意 多 了 一个 HTTP 前缀 label = model 
. predict data return label app . add _ url 
_ rule / labelservice / view _ func = Label 
. as _ view label methods = POST GET 启动 
服务 gunicorn c gunicorn . conf w8 b 0.0 . 
0.0 12711 label _ service app 使用 c 指定 我们 
的 配置文件 启动 服务 发现 达到 了 我 的 目的 
模型 只 初始化 一次 故 总 内存 消耗 还是 8G 
这 里面 提醒 大家 当 你 用 top 看 内存 
时 发现 每 个子 进程 内存大小 还是 8G 没有 关系 
我们 只要 看 本机 总的 剩余 内存 是 减少 8G 
还是 减少 了 8 * 8 = 64G 到此 满心欢喜 
进行 上线 但是 悲剧 马上 接踵而来 服务 运行 一段 时间 
每个 进程 内存 陡增 1G 如 下图 是 我 指定 
gunicorn 进程 数 为 1 的 时候 实测 发现 如果 
启动 8个 gunicorn 工作 进程 则 内存 在 某一 时刻 
增长 8G 直接 oom 到此 我 的 内心 是 崩溃 
的 不过 根据 经验 我 推测 在 某个 时刻 某些 
东西 触发 了 copy on write 机制 于是 我 让 
研究院 小伙伴 仔细 审查 了 一下 他们 的 模型 代码 
确认 没有 写 操作 那么 就 只 可能 是 gunicorn 
中 有写 操作 接下来 我 用 蹩脚 的 英文 在 
gunicorn 中提 了 一个 issue https / / github . 
com / benoitc / gunicorn / issues / 1892 大神 
立刻 给 我 指出 了 一条 明路 原来 是 python 
的 垃圾 收集器 搞 的 鬼 详见 https / / 
bugs . python . org / issue31558 因为 python 的 
垃圾 收 集会 更改 每个 类 的 PyGC _ Head 
从而 它 触发 了 copy on write 机制 导致 我 
的 服务 内存 成倍增长 那么 有 没有 什么 方法 能够 
禁止 垃圾 收集器 收集 这些 初始化 好 的 需要 大 
内存 的 模型 呢 有 那 就是 使用 gc . 
freeze 详见 https / / docs . python . org 
/ 3.7 / library / gc . html # gc 
. freeze 但是 这个 接口 在 python3 . 7 中 
才 提供 为此 我 不得不 把 我 的 服务 升级 
到 python3 . 7 实现 方式 3 python2 . 7 
升级到 python3 . 7 后 使用 gc . freeze 升级 
python 是 一件 非常 痛苦 的 事情 因为 我们 的 
代码 都是/nr 基于 python2 . 7 编写 许多 语法 在 
python3 . 7 中 不兼容 特别 是 字符串 操作 简直 
恶心 到死 只能 一一 改正 除此之外 还有 pickle 的 不兼容 
等等 具体 修改 过程 不 赘述 最终 我们 的 服务 
代码 如下 # gunicorn . conf import sys import gc 
sys . path . append . # 必须 把 本地 
路径 添加到 path 中 否则 gunicorn 找不到 当前目录 所 包含 
的 类 model = Model model . load gc . 
freeze # 调用 gc . freeze 必须 在 fork 子 
进程 之前 在 gunicorn 的 这个 地方 调用 正好 合适 
freeze 把 截止 到 当前 的 所有 对象 放入 持久化 
区域 不 进行 回收 从而 model 占用 的 内存 不会 
被 copy on write def pre _ request worker req 
req . headers . append FLASK _ MODEL model # 
把 模型 通过 request 传递 给 flask pre _ request 
= pre _ request 上线 之后 观察到 我们 单个 进程 
内存大小 从 8个 G 降低 到 6.5个 G 这个 推测 
和 python3 . 7 本身 的 优化 有关 其次 运行 
一段 时间 后 每 个子 进程 内存 缓慢 上涨 500M 
左右 后 达到 稳定 这 要比 每 个子 进程 突然 
增加 1G 内存 并且 不 知道 是否 只 突增 一次 
要好 的 多 使用 父子 进程 共享 数据 后 需要 
进行 预热 当 使用 gunicorn 多进程 实现 子 进程 与 
父进程 共享 模型 数据 后 发现 了 一个 问题 就是 
每 个子 进程 模型 的 第一 次 请求 计算 耗时 
特别 长 之后 的 计算 就会 非常快 这个 现象 在 
每个 进程 拥有 自己 的 独立 的 数据模型 时是不/nr 存在 
的 不 知道 是否 和 python 的 某些 机制 有关 
有 哪位 小伙伴 了解 可以 留言 给 我 对于 这种 
情况 解决 办法 是 在 服务 启动 后 预热 人为 
尽可能 多发 几个 预热 请求 这样 每 个子 进程 都 
能够 进行 第一 次 计算 请求 处理 完毕 后再 上线 
这样 就 避免 线上 调用 方 长时间 hang 住 得不到 
响应 结语 到此 我 的 服务 化 之路 暂时 告一段落 
这个 问题 整整 困扰 我 一周 虽然 解决 的 不是 
很 完美 但是 对于 我 这个 python 新手 来说 还是 
收获 颇丰 也 希望 我 的 这篇文章 能够 对 小伙伴 
们 产生 一些 帮助 