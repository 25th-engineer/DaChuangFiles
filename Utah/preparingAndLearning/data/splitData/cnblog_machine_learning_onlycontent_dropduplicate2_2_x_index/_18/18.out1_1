1 人工智能 机器学习 深度 学习 的 关系 人工智能 一 词 
最早 是 再 20 世纪 50 年代 提 出来 的 
机器学习 是 通过 算法 使用 大量 数据 进行 训练 训练/vn 
完成/v 后会/nr 产生/n 模型/n 有/v 监督/vn 的/uj 学习/v supervised learning 
无 监督 的 学习 unsupervised learning 增强 式 学习 reinforcement 
learning 已经 应用 领域 推荐 引擎 定向 广告 需求预测 垃圾邮件 
过滤 医学 诊断 自然语言 处理 搜索引擎 证券 分析 视觉 识别 
语音识别 手写识别 等 深度 学习 是 机器 学习 的 分支 
其 仿真 人类 神经 网络 的 工作 方式 常见 深度 
学习 架构 有 多层 感知器 multi layer perceptron 深度 神经网络 
deep neural network DNN 卷积 神经网络 convolutional neural network CNN 
递归 神经网路 recurrent neural network RNN 已经 应用 领域 视觉 
识别 语音识别 自然语言 处理 生物 医学 等 另 GPU Graphics 
Processing Unit 为 图形 处理器 用于 电脑 的 图形 运算 
CPU 与 GPU 的 架构 有 本质 的 不同 CPU 
含有 数颗 核心 为 顺序 处理 进行 优化 而 GPU 
则 拥有 高达 数千 个 小型 且 高效 的 核心 
发挥 强大 并行 计算能力 深度 学习 以 大量 矩形 运算 
模拟 神经元 的 工作 方式 该 工作 方式 特别 适合 
并行计算 GPU 通过 大量 核心 并行计算 在 深度 学习 训练 
中 GPU 比 CPU 要快 10 ~ 75倍 Google 公司 
于 2016年 宣布 人工智能 专用 芯片 TPU Tensor Processing Unit 
张量 处理单元 / 张量 处理 芯片 来 进行 计算 TPU 
是 专为 深度 学习 设计 的 特殊 规格 的 逻辑 
芯片 IC 使得 深度 学习 的 训练 速度 更快 2 
机器学习 介绍 机器 学习 的 训练 数据 构成 数据 特征 
features 数据 标签 label 机器学习 分为 两个 阶段 训练 Training 
预测 Predict3 机器学习 分类 3.1 有/v 监督/vn 的/uj 学习/v 有/v 
监督/vn 的/uj 学习/v 的/uj 数据/n 具备/v 特征/n features/w 预测 目标 
/ 标签 label 两 要素 通过 算法 训练 并 建立 
模型 当 有 新的 数据 时 我们 将 其 进行 
预测 二元 分类 特征 features 的 标签 label 有 两个 
离散 选项 多元 分类 特征 features 的 标签 label 有 
至少 两个 离散 选项 回归分析 特征 features 的 标签 label 
是 连续 的 值 3.2 无 监督 的 学习 该 
方式 无 label 标签 如 cluster 集群 算法 将 数据 
分成 几个 差异 较大 的 群组 而 群组 内 的 
相似 度 最高 3.3 增强 式 学习 增强 式 学习 
原理 借助 定义 动作 actions 状态 states 奖励 rewards 的 
方式 不断 训练 机器 循序渐进 使其 学会 执行 某 项 
任务 的 算法 常见 算法 有 Q Learning TD Temporal 
Difference Sarsa 等 如 训练 机器 玩 超级玛丽 电子游戏 就是 
借助 不断 训练 学会 玩游戏 对应状态 有 动作 左 右 
跳 状态 当前 游戏 界面 奖励 得分 受伤 4 深度 
学习 简介 一个 输入 层 一个 输出 层 N 个 
隐藏 层 所以 称之为 深度 学习 