前言 高斯 过程 回归 GPR 和 贝叶斯 线性 回归 类似 
区别 在于 高斯 过程 回归 中用 核 函数 代替 了 
贝叶斯 线性 回归 中的 基 函数 其实 也是 核 函数 
线性 核 采用 核 函数 可以 定义 高斯 过程 回归 
是 一个 比 贝叶斯 线性 回归 更 通用 的 模型 
应用 非常 广泛 本文 参考 的 资料 为 视频 http 
/ / www . youtube . com / playlist list 
= P L D 0 Z 0 6 A A 
0 D 2 E 8 Z Z B A 中 
相关 的 部分 以及 论文 Gaussian Processes for Regression A 
Quick Introduction . 基础知识 首先 来 看看 Bayesian linear regression 
贝叶斯 线性 回归 模型 其中 的 D 为 已知 的 
有 监督 的 训练样本 Yi 为 样本 标签 由 可知 
yi 可以 表示 为 一个 高斯 过程 和 一个 随机 
变量 的 和 公式 中的 w 是 一个 多 维 
高斯分布 而   是 一个 高斯分布 并且 它 属于 线性 
高斯分布 有上 一篇 博文 机器学习 & 数据挖掘 笔记 _ 10 
高斯 过程 简单 理解 可知 如果 高斯 过程 为 线性 
的 即 它 的 sample 是 在 高维空间 中的 平面 
要求 它 的 核 函数 需 满足 k xi xj 
= xi * xj 的 形式 且 均值 函数 为 
0 下面 是 它 的 证明 过程 既然 已经 得知 
yi 的 中心 是 在 一个 高维空间 的 平面 上 
所以 当 新来 的 数据 后 就 可以 预测 它 
的 均值 也在 该 平面 对应 的 位置 上 这就 
达到 了 回归 的 目的 在 将 BLR 贝叶斯 线性 
回归 扩展到 GPR 高斯 过程 回归 前 来 看看 多维 
高斯分布 的 一些 重要 性质 第一/m 个/q 性质/n 为/p 两个/m 
相互/d 独立/v 的/uj 多维/m 高斯分布/nr A/w 和B的/nr 和也是/nr 一个/m 多维/m 
高斯分布/nr C/w 且/zg C/w 的/uj 均值/n 和/c 方差/n 都为/i A/w 
和B/nr 均值/n 方差/n 的/uj 和/c 第二个 性质 为 两个 多维 
高斯分布 之和 构成 的 分布 C 而言 在 已知 一部分 
观察 值 C1 的 条件 下 另一 部分 观察 值 
C2 的 概率分布 是 一个 多维 高斯分布 且 可以 用 
A 和B中/nr 对应 的 信息 来 表示 这 2个 性质 
的 介绍 如下 接下来 就是 要 怎样 利用 高斯 过程 
进行 回归 运 算了 高斯 过程 回归 的 模型 如下 
其中 的 ya 为 需要 预测 的 值 yb 为 
观察到 的 值 当然 了 xa 和 xb 也是 观察 
值 由 前面 博文 机器学习 & 数据挖掘 笔记 _ 10 
高斯 过程 简单 理解 中 介绍 的 高斯 过程 存在 
性 定理 可知 一旦 我们 确定 了 x 上 的 
u 和k/nr 就 可以 得到 一个 高斯 过程 Zx 此时 
的 样本 值 Yi 可以 写成   即 两个 独立 
的 多维 高斯 变量 之和 而 利用 上面 多维 高斯 
变量 的 性质 可 推导 出 需要 预测 的 ya 
在 yb 条件 下 的 概率 上面/f 的/uj m/w 和D有/nr 
解析/vn 表达式/n 因此 可以 直接 求 里面 的 的 变量 
都是 已知 的 其中 的 m 就是 我们 回归 预测 
的 值 而 D 就是 此时 预测 的 误差 两者 
表达式 和 前面 类似 如下 由 贝叶斯 线性 回归 和 
高斯 过程 回归 的 对比 可知 贝叶斯 线性 回归 是 
高斯 过程 回 归中 的 一个 子集 只是 它 用 
的 是 线性 核 而已 通过 两者 的 公式 就 
可以 看出 它们 之间 的 关系 上面 是 贝叶斯 线性 
回归 下面 是 高斯 过程 回归 简单 例子 假设 现在 
已经 观察 到了 6个 样本点 x 为 样本点 特征 一维 
的 y 为 样本 输出 值 现在 新来 了 一个 
样本点 要求 是 用 高斯 回归 过程 来 预测 新来 
样本点 的 输出 值 这些 样本点 显示 如下 其中 前面 
6个 点 是 已知 输出 值 的 训练样本 其 值 
为 第 7个 点 是 需要 预测 的 样本 红色 
的 垂直 条形 线 表示 观察 输出 值 的 误差 
绿色 的 垂直 条形 线 为 用 高斯 过程 回归 
的 误差 用 GPR 解该/nr 问题 的 流程 大概 如下 
对应 前面 讲 的 一些 基础 知识 1 . 选择 
适当 的 u 均值 函数 和k/nr 核 函数 以及 噪声 
变量 σ 其 中核 函数 的 选择 尤其 重要 因为 
它 体现 了 需 处理 问题 的 先验 知识 应 
根据 不同 的 应用 而 选择 不同 的 核 2 
. 计算出 训练样本 的 核 矩阵 6 * 6 如下 
3 . 计算 需 预测 的 点   与 训练样本 
6个 点 的 核 值 向量 如下 4 . 自己 
和 自己 的 核 值 为     且 此时 
整个 样本 的 多维 高斯分布 表达式 为 5 . 通过 
前面 m 和D的/nr 公式 求得 m = 0.95 D = 
0 . 21.6 . 画出 最终 结果 如下 这个 例子 
来源于 论文 Gaussian Processes for Regression A Quick Introduction 中 
它 的 核 函数 等 参数 选择 和 基础 知识 
部分 的 不同 但 这里 主要 是 对 GPR 的 
应用 有个/nr 简单 的 宏观 上 的 理解 让 大脑 
对 GPR 应用 有个/nr 初步 的 印象 否则/c 有了/nr 那么/r 
多/m 的/uj 公式/n 推导/v 但/c 不会/v 应用/v 又/d 有/v 什么/r 
用/p 呢/y 参考资料 http / / www . youtube . 
com / playlist list = P L D 0 Z 
0 6 A A 0 D 2 E 8 Z 
Z B A G a u s s i a 
n Processes for Regression A Quick Introduction M . Ebden 
August 2008 . 机器学习 & 数据挖掘 笔记 _ 10 高斯 
过程 简单 理解 