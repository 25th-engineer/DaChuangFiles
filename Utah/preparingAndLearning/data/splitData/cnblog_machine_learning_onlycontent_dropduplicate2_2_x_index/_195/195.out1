一 概述 我们 知道 机器 学习 的 特点 就是 以 
计算机 为 工具 和 平台 以 数据 为 研究 对象 
以 学习 方法 为 中心 是 概率论 线性代数 数值 计算 
信息论 最优化 理论 和 计算机 科学 等 多个 领域 的 
交叉 学科 所以 本文 就 先 介绍 一下 机器学习 涉及到 
的 一些 最 常用 的 的 数学 知识 二 线性代数 
2 1 标量 一个 标 量 就是 一个 单独 的 
数 一般 用 小写 的 的 变量 名称 表示 2 
2 向量 一个 向量 就是 一 列数 这些 数 是 
有序 排列 的 用过 次序 中的 索引 我们 可以 确定 
每个 单独 的 数 通常会 赋予 向量 粗体 的 小写 
名称 当 我们 需要 明确 表示 向量 中的 元素 时 
我们 会 将 元素 排列 成 一个 方括号 包围 的 
纵 柱 我们 可以 把 向量 看作 空间 中的 点 
每个 元素 是 不同 的 坐标 轴上 的 坐标 2 
3 矩阵 矩阵 是 二维 数组 其中 的 每 一个 
元素 被 两个 索引 而非 一个 所 确定 我们 通常 
会 赋予 矩阵 粗体 的 大写 变量 名称 比如 A 
如果 一个 实数 矩阵 高度 为 m 宽度 为 n 
那么 我们 说 矩阵 这 东西 在 机器 学习 中 
就 不要 太 重要 了 实际上 如果 我们 现在 有N个/nr 
用户 的 数据 每条 数据 含有 M 个 特征 那 
其实 它 对应 的 就是 一个 N * M 的 
矩阵 呀 再 比如 一张 图 由 16 * 16 
的 像素 点 组成 那这/nr 就是 一个 16 * 16 
的 矩阵 了 现在 才 发现 我们 大一 学 的 
矩阵 原理 原来 这么 的 有用 要是 当时 老师 讲课 
的 时候 先 普及 一下 也 不至于 很多 同学 学 
矩阵 的 时候 觉得 莫名其妙 了 2 4 张量 几何 
代数 中 定义 的 张量 是 基于 向量 和 矩阵 
的 推广 通俗 一点 理解 的话 我们 可以 将 标量 
视 为零 阶 张量 矢量 视为 一 阶 张量 那么 
矩阵 就是 二阶 张量 例如 可以 将 任意 一张 彩色图片 
表示 成 一个 三阶 张量 三个 维度 分别 是 图片 
的 高度 宽度 和 色彩 数据 将 这张 图 用 
张量 表示出来 就是 最 下方 的 那张 表格 其 中表 
的 横轴 表示 图片 的 宽度 值 这里 只 截取 
0 ~ 319 表 的 纵轴 表示 图片 的 高度 
值 这里 只 截取 0 ~ 4 表格 中 每个 
方格 代表 一个 像素点 比如 第一行 第一列 的 表格 数据 
为 1.0 1.0 1.0 代表 的 就是 RGB 三原色 在 
图片 的 这个 位置 的 取值 情况 即 R = 
1.0 G = 1.0 B = 1.0 当然 我们 还 
可以 将 这一 定义 继续 扩展 即 我们 可以 用 
四阶 张量 表示 一个 包含 多 张 图片 的 数据 
集 这四个 维度 分别 是 图片 在 数据 集中 的 
编号 图片 高度 宽度 以及 色彩 数据 张量 在 深度 
学习 中 是 一个 很 重要 的 概念 因为 它 
是 一个 深度 学习 框架 中 的 一个 核心 组件 
后续/v 的/uj 所有/b 运算/vn 和/c 优化/vn 算法/n 几乎/d 都是/nr 基于/p 
张量/nr 进行/v 的/uj 2 5 范数 有时 我们 需要 衡量 
一个 向量 的 大小 在 机器 学习 中 我们 经常 
使用 被 称为 范数 norm 的 函数 衡量 矩阵 大小 
Lp 范数 如下 所以 L1 范数 为 x 向量 各个 
元素 绝对值 之和 L2 范数 为 x 向量 各个 元素 
平方和 的 开方 这里 先 说明 一下 在 机器 学习 
中 L1 范数 和 L2 范数 很 常见 主要 用在 
损失 函数 中 起到 一个 限制 模型 参数 复杂度 的 
作用 至于 为什么 要 限制 模型 的 复杂度 这又 涉及 
到 机器学习 中 常见 的 过拟合 问题 具体 的 概念 
在 后续 文章 中 会有 详细 的 说明 和 推导 
大家 先 记住 这个 东西 很 重要 实际 中 经常 
会 涉及 到 面试 中 也 常 会被 问到 2 
6 特征 分解 许多 数学 对象 可以 通过 将 它们 
分解成 多个 组成部分 特征 分解 是 使用 最广 的 矩阵 
分解 之一 即将 矩阵 分解成 一组 特征向量 和 特征值 方阵 
A 的 特征向量 是 指 与 A 相乘 后 相当于 
对 该向 量 进行 缩放 的 非零 向量 标量 被 
称为 这个 特征向量 对应 的 特征值 使用 特征 分解 去 
分析 矩阵 A 时 得到 特征向量 构成 的 矩阵 V 
和 特征值 构成 的 向量 我们 可以 重新 将 A 
写作 2 7 奇异 值 分解 Singular Value Decomposition SVD 
矩阵 的 特征 分解 是 有 前提 条件 的 那 
就是 只有 对 可对 角化 的 矩阵 才 可以 进行 
特征 分解 但 实际 中 很多 矩阵 往往 不 满足 
这 一 条件 甚至 很多 矩阵 都 不是 方阵 就是说/c 
连/nr 矩阵/n 行/zg 和列的/nr 数目/n 都/d 不相等/i 这时候 怎么办 呢 
人们 将 矩阵 的 特征 分解 进行 推广 得到 了 
一种 叫作 矩阵 的 奇异 值 分解 的 方法 简称 
SVD 通过 奇异 分解 我们 会 得到 一些 类似于 特征 
分解 的 信息 它 的 具体 做法 是 将 一个 
普通 矩阵 分解为 奇异 向量 和 奇异 值 比如 将 
矩阵 A 分解成 三个 矩阵 的 乘积 假设 A 是 
一个 mn 矩阵 那么 U 是 一个 mm 矩阵 D 
是 一个 mn 矩阵 V 是 一个 nn 矩阵 这些 
矩阵 每一个 都 拥有 特殊 的 结构 其中 U 和V/nr 
都是 正交矩阵 D 是 对角 矩阵 注意 D 不 一定 
是 方阵 对角 矩阵 D 对角 线上 的 元素 被 
称为 矩阵 A 的 奇异 值 矩阵 U 的 列 
向量 被 称为 左 奇异 向量 矩阵 V 的 列 
向量 被 称 右 奇异 向量 SVD 最 有用 的 
一个 性质 可能 是 拓展 矩阵 求 逆 到 非 
方 矩阵 上 另外 SVD 可 用于 推荐 系统 中 
2 8 Moore Penrose 伪 逆 对于 非 方 矩阵 
而言 其 逆 矩阵 没有 定义 假设 在下面 问题 中 
我们 想 通过 矩阵 A 的 左逆B/nr 来 求解 线性方程 
等式/n 两边/f 同时/c 左/m 乘/v 左逆B/nr 后/f 得到 是否 存在 
唯一 的 映射 将 A 映 射到 B 取决于 问题 
的 形式 如果 矩阵 A 的 行数 大于 列数 那么 
上述 方程 可能 没 有解 如果 矩阵 A 的 行数 
小于 列数 那么 上述 方程 可能 有 多个 解 Moore 
Penrose 伪 逆 使 我们 能够 解决 这种情况 矩阵 A 
的 伪 逆 定义 为 但是 计算 伪 逆 的 
实际 算法 没有 基于 这个 式子 而是 使用 下面 的 
公式 其中 矩阵 U D 和V/nr 是 矩阵 A 奇异 
值 分解 后 得到 的 矩阵 对角 矩阵 D 的 
伪 逆 D + 是 其 非零 元素 取 倒 
之后 再 转置 得到 的 2 9 几种 常用 的 
距离 上面 大致 说过 在 机器学习 里 我们 的 运算 
一般 都是/nr 基于 向量 的 一条 用户 具有 100个 特征 
那么 他 对应 的 就是 一个 100 维 的 向量 
通过 计算 两个 用户 对应 向量 之间 的 距离 值 
大小 有时候 能 反映 出 这 两个 用户 的 相似 
程度 这在 后面 的 KNN 算法 和K/nr means 算法 中 
很明显 设有 两个 n 维 变量 和 则 一些 常用 
的 距离 公式 定义 如下 1 曼哈顿 距离 曼哈顿 距离 
也 称为 城市 街区 距离 数学 定义 如下 曼哈顿 距离 
的 Python 实现 from numpy import * vector1 = mat 
1 2 3 vector2 = mat 4 5 6 print 
sum abs vector1 vector2 View Code2 欧氏距离 欧氏距离 其实 就是 
L2 范数 数学 定义 如下 欧氏距离 的 Python 实现 from 
numpy import * vector1 = mat 1 2 3 vector2 
= mat 4 5 6 print sqrt vector1 vector2 * 
vector1 vector2 . T View Code3 闵可夫 斯基 距离 从 
严格 意义 上 讲 闵可夫 斯基 距离 不是 一种 距离 
而是 一组 距离 的 定义 实际上 当 p = 1时 
就是 曼哈顿 距离 当 p = 2时 就是 欧式 距离 
4 切比雪夫 距离 切比雪夫 距离 就是 即 无穷 范数 数学 
表达式 如下 切比雪夫 距离 额 Python 实现 如下 from numpy 
import * vector1 = mat 1 2 3 vector2 = 
mat 4 5 6 print sqrt abs vector1 vector2 . 
max View Code5 夹角 余弦 夹角 余弦 的 取值 范围 
为 1 1 可以 用来 衡量 两个 向量 方向 的 
差异 夹角 余弦 越大 表示 两个 向量 的 夹角 越小 
当 两个 向量 的 方向 重 合时 夹角 余弦 取 
最大值 1 当 两个 向量 的 方向 完全 相反 时 
夹角 余弦 取 最小值 1 机器学习 中用 这一 概念 来 
衡量 样本 向量 之间 的 差异 其 数学 表达式 如下 
夹角 余弦 的 Python 实现 from numpy import * vector1 
= mat 1 2 3 vector2 = mat 4 5 
6 print dot vector1 vector2 / linalg . norm vector1 
* linalg . norm vector2 View Code6 汉明 距离 汉明 
距离 定义 的 是 两个 字符串 中 不相同 位数 的 
数目 例如 字符串 1111 与 1001 之间 的 汉明 距离 
为 2 信息 编码 中 一般 应 使得 编码 间 
的 汉明 距离 尽可能 的 小 汉明 距离 的 Python 
实现 from numpy import * matV = mat 1 1 
1 1 1 0 0 1 smstr = nonzero matV 
0 matV 1 print smstrView Code7 杰/nr 卡德/l 相似系数/i 两个/m 
集合/v A/w 和B的/nr 交集/v 元素/n 在/p A/w 和B的/nr 并/c 集中/v 
所占/i 的/uj 比例/n 称为/v 两个/m 集合/v 的/uj 杰/nr 卡德/l 相似系数/i 
用 符号 J A B 表示 数学 表达式 为 杰 
卡德 相似系数 是 衡量 两个 集合 的 相似 度 的 
一种 指标 一般 可以 将其 用在 衡量 样本 的 相似 
度上 8 杰 卡德 距离 与 杰 卡德 相似系数 相反 
的 概念 是 杰 卡德 距离 其 定义 式 为 
杰 卡德 距离 的 Python 实现 from numpy import * 
import scipy . spatial . distance as dist matV = 
mat 1 1 1 1 1 0 0 1 print 
dist . pdist matV jaccard View Code 三 概率 3 
1 为什么 使用 概率 概率论 是 用于 表示 不确定性 陈述 
的 数学 框架 即 它 是 对 事物 不确定性 的 
度量 在 人工智能 领域 我们 主要 以 两种 方式 来 
使用 概率论 首先 概率法 则 告诉 我们 AI 系统 应该 
如何 推理 所以 我们 设计 一些 算法 来 计算 或者 
近似 由 概率论 导出 的 表达式 其次 我们/r 可以/c 用/p 
概率/n 和/c 统计/v 从/p 理论/n 上/f 分析/vn 我们/r 提出/v 的/uj 
AI/w 系统/n 的/uj 行为/v 计算机 科学 的 许多 分支 处理 
的 对象 都是/nr 完全 确定 的 实体 但 机器学习 却 
大量 使用 概率论 实际上 如果 你 了解 机器 学习 的 
工作 原理 你 就会 觉得 这个 很 正常 因为 机器学习 
大部分 时候 处理 的 都是 不确 定量 或 随机量 3 
2 随机变量 随机变量 可以 随机 地 取 不同 值 的 
变量 我们 通常 用 小写 字母 来 表示 随机变量 本身 
而用 带 数字 下 标的 小写字母 来 表示 随机变量 能够 
取到 的 值 例如 和 都是 随机变量 X 可能 的 
取值 对于 向 量值 变量 我们 会 将 随机变量 写成 
X 它 的 一个 值 为 就其 本身 而言 一个 
随机变量 只是 对 可能 的 状态 的 描述 它 必须 
伴随 着 一个 概率分布 来 指定 每个 状态 的 可能性 
随机变量 可以 是 离散 的 或者 连续 的 3 3 
概率分布 给定 某 随机变量 的 取值 范围 概率分布 就是 导致 
该 随机事件 出现 的 可能性 从 机器 学习 的 角度 
来看 概率分布 就是 符合 随机变量 取值 范围 的 某个 对象 
属于 某个 类别 或 服从 某种 趋势 的 可能性 3 
4 条件概率 很多 情况 下 我们 感兴趣 的 是 某个 
事件 在 给定 其它 事件 发生 时 出现 的 概率 
这种 概率 叫 条件概率 我们 将 给定 时 发生 的 
概率 记为 这个 概率 可以 通过 下面 的 公式 来 
计算 3 5 贝叶斯 公式 先 看看 什么 是 先验概率 
和 后验/nr 概率 以 一个 例子 来 说明 假设 某种 
病 在 人群 中 的 发病率 是 0.001 即 1000 
人中 大概 会有 1 个人 得病 则有 P 患病 = 
0.1% 即 在 没有 做 检验 之前 我们 预计 的 
患病率 为 P 患病 = 0.1% 这个 就 叫作 先验概率 
再 假设 现在 有 一种 该病 的 检测 方法 其 
检测 的 准确率 为 95% 即 如果 真的 得了 这种 
病 该 检测法 有 95% 的 概率 会 检测 出 
阳性 但 也有 5% 的 概率 检测 出 阴性 或者 
反过来说 但 如果 没有 得病 采用 该 方法 有 95% 
的 概率 检测 出 阴性 但 也有 5% 的 概率 
检测 为 阳性 用 概率 条件概率 表示 即为 P 显示 
阳性 | 患病 = 95% 现在 我们 想 知道 的 
是 在 做完 检测 显示 为 阳性 后 某人 的 
患病率 P 患病 | 显示 阳性 这个 其实 就 称为 
后验/nr 概率 而 这个 叫 贝叶斯 的 人 其实 就是 
为 我们 提供 了 一种 可以 利用 先验概率 计算 后验/nr 
概率 的 方法 我们 将 其 称为 贝叶斯 公式 这里 
先 了解 条件概率 公式 由 条件概率 可以 得到 乘法 公式 
将 条件概率 公式 和 乘法 公式 结合 可以 得到 再由 
全 概率 公式 代入 可以 得到 贝叶斯 公式 在 这个 
例子 里 就是 贝叶斯 公式 贯穿 了 机器 学习 中 
随机 问题 分析 的 全过程 从 文本 分类 到 概率 
图 模型 其 基本 分类 都是 贝叶斯 公式 期望 方差 
协方差 等 主要 反映 数据 的 统计 特征 机器 学习 
的 一个 很 大 应用 就是 数据挖掘 等 因此 这些 
基本 的 统计 概念 也是 很有必要 掌握 另外 像 后面 
的 EM 算法 中 就 需要 用到 期望 的 相关 
概念 和 性质 3 6 期望 在 概率论 和 统计学 
中 数学期望 是 试验 中 每次 可能 结果 的 概率 
乘以 其 结果 的 总和 它 是 最 基本 的 
数学 特征 之一 反映 随机变量 平均值 的 大小 假设 X 
是 一个 离散 随机变量 其 可能 的 取值 有 各个 
取值 对应 的 概率 取值 为 则 其 数学期望 被 
定义 为 假设 X 是 一个 连续型 随机变量 其 概率密度函数 
为 则 其 数学期望 被 定义 为 3 7 方差 
概率 中 方差 用来 衡量 随机变量 与其 数学期望 之间 的 
偏离 程度 统计 中的 方差 为 样本方差 是 各个 样本数据 
分别 与其 平均数 之差 的 平方和 的 平均数 数学 表达式 
如下 3 8 协方差 在 概率论 和 统计学 中 协方差 
被 用于 衡量 两个 随机变量 X 和Y/nr 之间 的 总体 
误差 数学 定义 式 为 3 9 常见 分布 函数 
1 0 1 分布 0 1 分布 是 单个 二 
值 型 离散 随机变量 的 分布 其 概率分布 函数 为 
2 几何 分布 几何 分布 是 离散 型 概率分布 其 
定义 为 在 n 次 伯努利 试验中 试验 k 次 
才得到 第一 次 成功 的 机率 即 前 k 1次 
皆 失败 第 k 次 成功 的 概率 其 概率分布 
函数 为 性质 3 二项分布 二项分布 即 重复 n 次 
伯努利 试验 各次 试验 之间 都 相互 独立 并且 每次 
试验 中 只有 两种 可能 的 结果 而且 这 两种 
结果 发生 与否 相互 对立 如果 每次 试验 时 事件 
发生 的 概率 为 p 不 发生 的 概率 为 
1 p 则 n 次 重复 独立试验 中 发生 k 
次 的 概率 为 性质 4 高斯分布 高斯分布 又叫 正态分布 
其 曲线 呈 钟型/nr 两头 低 中间 高 左右 对称 
因其 曲线 呈 钟形 如下 图 所示 若 随机变量 X 
服从 一个 数学期望 为 方差 为 的 正态分布 则 我们 
将 其 记为 其 期望值 决定了 正态分布 的 位置 其 
标准差 方差 的 开方 决定了 正态分布 的 幅度 5 指数分布 
指数分布 是 事件 的 时间 间隔 的 概率 它 的 
一个 重要 特征 是 无 记忆性 例如 如果 某一 元件 
的 寿命 的 寿命 为 T 已知 元件 使用 了 
t 小时 它 总共 使用 至少 t + s 小时 
的 条件 概率 与/p 从/p 开始/v 使用/v 时/n 算起/v 它/r 
使用/v 至少/d s/w 小时/n 的/uj 概率/n 相等/v 下面 这些 都 
属于 指数分布 婴儿 出生 的 时间 间隔 网站 访问 的 
时间 间隔 奶粉 销售 的 时间 间隔 指数分布 的 公式 
可以 从 泊松分布 推断 出来 如果 下 一个 婴儿 要 
间隔时间 t 就 等同于 t 之内 没有 任何 婴儿 出生 
即 则 如 接下来 15 分钟 会有 婴儿 出生 的 
概率 为 指数分布 的 图像 如下 6 泊松分布 日常 生活 
中 大量 事件 是 有 固定 频率 的 比如 某 
医院 平均 每 小时 出生 3个 婴儿 某 网站 平均 
每 分钟 有2/nr 次访问 某 超市 平均 每小时 销售 4包 
奶粉 它们 的 特点 就是 我们 可以 预估 这些 事件 
的 总数 但是 没法 知道 具体 的 发生 时间 已知 
平均 每小时 出生 3个 婴儿 请问 下 一个 小时 会出 
生 几个 有 可能 一下子 出生 6个 也 有 可能 
一个 都不 出生 这 是 我们 没法 知道 的 泊松分布 
就是 描述 某段 时间 内 事件 具体 的 发生 概率 
其 概率函数 为 其中 P 表示 概率 N 表示 某种 
函数关系 t 表示 时间 n 表示 数量 1 小时 内 
出生 3个 婴儿 的 概率 就 表示 为 P N 
1 = 3 λ 表示 事件 的 频率 还是 以 
上面 医院 平均 每小时 出生 3个 婴儿 为例 则 那么 
接下来 两 个 小时 一个 婴儿 都不 出生 的 概率 
可以 求得 为 同理 我们 可 以求 接下来 一个 小时 
至少 出生 两个 婴儿 的 概率 注 上面/f 的/uj 指数/n 
分布/v 和/c 泊松分布/i 参考/v 了/ul 阮/nr 一峰/m 大牛/i 的/uj 博客/nr 
泊松分布 和 指数分布 10 分钟 教程 在此 说明 也对 其 
表示 感谢 3 10 Lagrange/w 乘子/n 法/l 对于/p 一般/a 的/uj 
求/v 极值问题/i 我们/r 都/d 知道/v 求导 等于 0 就 可以 
了 但是 如果 我们 不但 要求 极值 还 要求 一个 
满足 一定 约束 条件 的 极值 那么 此时 就 可以 
构造 Lagrange 函数 其实 就是 把 约束 项 添加到 原函数 
上 然后 对 构造 的 新 函数 求导 对于 一个 
要求 极值 的 函数 图上 的 蓝圈 就是 这个 函数 
的 等高 图 就是说 分别 代表 不同 的 数值 每个 
值 代表 一圈 等高 图 我 要 找到 一组 使 
它 的 值 越大 越好 但是 这 点 必须 满足 
约束条件 在 黄 线上 也 就是 说和 相切 或者说 它们 
的 梯度 ▽ 和▽/nr 平行 因此 它们 的 梯度 偏 
导 成 倍数 关系 那我么/nr 就 假设 为 倍 然后 
把 约束条件 加到 原函数 后再 对 它 求导 其实 就 
等于 满足 了 下 图上 的 式子 在 支持 向量 
机 模型 SVM 的 推导 中 一步 很 关键 的 
就是 利用 拉格朗日 对偶性 将 原 问题 转化 为 对偶 
问题 3 11 最大 似 然 估计 最大 似 然也 
称为 最 大概 似 估计 即 在 模型 已定 参数 
θ 未知 的 情况 下 通过 观测 数据 估计 未知 
参数 θ 的 一种 思想 或 方法 其 基本 思想 
是 给定 样本 取值 后 该 样本 最 有可能 来自 
参数 为何 值 的 总体 即 寻找 使得 观测 到 
样本数据 的 可能性 最大 举个 例子 假设 我们 要 统计 
全国 人口 的 身高 首先 假设 这个 身高 服从 服从 
正态分布 但是 该 分布 的 均值 与 方差 未知 由于 
没有 足够 的 人力 和 物力 去 统计 全国 每 
个人 的 身高 但是 可以 通过 采样 所有 的 采样 
要求 都是/nr 独立 同 分布 的 获取 部分 人 的 
身高 然后 通过 最大 似 然 估计 来 获取 上述 
假设 中的 正态分布 的 均值 与 方差 求 极大 似 
然 函数 估计值 的 一般 步骤 1 写出 似 然 
函数 2 对 似 然 函数 取 对数 3 两边 
同时 求 导数 4 令 导数 为 0 解出 似 
然 方程 在 机器 学习 中 也会 经常 见到 极大 
似 然 的 影子 比如 后面 的 逻辑 斯特 回归模型 
LR 其 核心 就是 构造 对数 损失 函数 后 运用 
极大 似 然 估计 四 信息论 信息论 本来 是 通信 
中的 概念 但是 其 核心 思想 熵 在 机器 学习 
中 也 得到 了 广泛 的 应用 比如 决策树 模型 
ID3 C 4.5中 是 利用 信息 增益 来 划分 特征 
而 生成 一颗 决策树 的 而 信息 增益 就是 基于 
这里 所说 的 熵 所以 它 的 重要性 也是 可想而知 
4 1 熵 如果 一个 随机变量 X 的 可能 取值 
为 其 概率分布 为 则 随机变量 X 的 熵 定义 
为 H X 4 2 联合 熵 两个 随机变量 X 
和Y的/nr 联合 分布 可以 形成 联合 熵 定义 为 联合 
自 信息 的 数学期望 它 是 二维 随机变量 XY 的 
不确定性 的 度量 用 H X Y 表示 4 3 
条件 熵 在 随机变量 X 发生 的 前提 下 随机变量 
Y 发生 新 带来 的 熵 定义 为 Y 的 
条件 熵 用 H Y | X 表示 条件 熵 
用来 衡量 在 已知 随机变量 X 的 条件 下 随机变量 
Y 的 不确定性 实际上 熵 联合 熵 和 条件 熵 
之间 存在 以下 关系 推导 过程 如下 其中 第二行 推到 
第三行 的 依据 是 边缘 分布 P x 等于 联合 
分布 P x y 的 和 第三行 推到 第四行 的 
依据 是 把 公因子 logP x 乘 进去 然后 把 
x y 写 在 一起 第四行 推到 第 五行 的 
依据 是 因为 两个 sigma 都有 P x y 故 
提取 公因子 P x y 放到 外边 然后 把 里边 
的 log P x y log P x 写成 log 
P x y / P x 第 五行 推到 第 
六行 的 依据 是 P x y = P x 
* P y | x 故 P x y / 
P x = P y | x 4 4 相对 
熵 相对 熵 又称 互 熵 交叉 熵 KL 散度 
信息 增益 是 描述 两个 概率分布 P 和Q/nr 差异 的 
一种 方法 记为 D P | | Q 在 信息论 
中 D P | | Q 表示 当用 概率分布 Q 
来 拟合 真实 分布 P 时 产生 的 信息 损耗 
其中 P 表示 真实 分布 Q 表示 P 的 拟合 
分布 对于 一个 离散 随机变量 的 两个 概率分布 P 和Q/nr 
来说 它们 的 相对 熵 定义 为 注意 D P 
| | Q ≠ D Q | | P 相对 
熵 又称 KL 散度 Kullback – Leibler divergence KL 散度 
也 是 一个 机器学习 中 常考 的 概念 4 5 
互信息 两个 随机变量 X Y 的 互信息 定义 为 X 
Y 的 联合 分布 和 各自 独立 分布 乘积 的 
相对 熵 称为 互信息 用 I X Y 表示 互信息 
是 信息论 里 一种 有用 的 信息 度量 方式 它 
可以 看成 是 一个 随机变量 中 包含 的 关于 另 
一个 随机 变量 的 信息量 或者说 是 一个 随机变量 由于 
已知 另一个 随机变量 而 减少 的 不肯 定性 互信息 熵 
和 条件 熵 之间 存在 以下 关系 推导 过程 如下 
通过 上面 的 计算 过程 发现有 H Y | X 
= H Y I X Y 又 由 前面 条件 
熵 的 定义 有 H Y | X = H 
X Y H X 于是 有I/nr X Y = H 
X + H Y H X Y 此 结论 被 
多数 文献 作为 互信息 的 定义 4 6 最大熵 模型 
最大熵 原理 是 概率模型 学习 的 一个 准则 它 认为 
学习 概率模型 时 在 所有 可能 的 概率分布 中 熵 
最大 的 模型 是 最好 的 模型 通常用 约束条件 来 
确定 模型 的 集合 所以 最大熵 模型 原理 也 可以 
表述 为 在 满足 约束 条件 的 模型 集合 中 
选取 熵 最大 的 模型 前面 我们 知道 若 随机变量 
X 的 概率分布 是 则 其 熵 定义 如下 熵 
满足 下列 不等式 式 中 | X | 是 X 
的 取值 个数 当且仅当 X 的 分布 是 均匀分布 时 
右边 的 等号 成立 也 就是说 当 X 服从 均匀分布 
时 熵 最大 直观 地 看 最大熵 原理 认为 要 
选择 概率模型 首先 必须 满足 已有 的 事实 即 约束条件 
在 没有 更多 信息 的 情况 下 那些 不 确定 
的 部分 都是 等 可能 的 最大熵 原理 通过 熵 
的 最大化 来 表示 等 可能性 等 可能 不易 操作 
而 熵 则 是 一个 可 优化 的 指标 五 
数值 计算 5 1 上溢 和 下溢 在 数字 计算机 
上 实现 连续 数学 的 基本 困难 是 我们 需要 
通过 有限 数量 的 位 模式 来 表示 无限 多 
的 实数 这 意味着 我们 在 计算机 中 表示 实数 
时 几乎 都会 引入 一些 近似 误差 在 许多 情况 
下 这 仅仅 是 舍入 误差 如果 在 理论上 可行 
的 算法 没有 被 设计 为 最小化 舍入 误差 的 
累积 可能会 在 实践 中 失效 因此 舍入 误差 是 
有 问题 的 特别 是 在 某些 操作 复合 时 
一种 特别 毁灭性 的 舍入 误差 是 下溢 当 接近 
零 的 数 被 四舍五入 为零 时 发生 下溢 许多 
函数 会 在其 参数 为零 而 不是 一个 很小 的 
正数 时 才会 表现 出质 的 不同 例如 我们 通常 
要 避免 被 零 除 另 一个 极 具 破坏力 
的 数值 错误 形式 是 上溢 overflow 当 大量 级 
的 数 被 近 似为 或时 发生 上溢 进一步 的 
运算 通常 将 这些 无 限值 变为 非数字 必须 对 
上溢 和 下溢 进行 数值 稳定 的 一个 例子 是 
softmax 函数 softmax 函数 经常 用于 预测 与 multinoulli 分布相 
关联 的 概率 定义 为 softmax 函数 在 多分 类 
问题 中 非常 常见 这个 函数 的 作用 就是 使得 
在 负无穷 到 0 的 区间 趋向于 0 在 0 
到 正无穷 的 区间 趋向于 1 上面 表达式 其实 是 
多分 类 问题 中 计算 某个 样本 的 类别 标签 
属于 K 个 类别 的 概率 最后 判别 所属 类别 
时 就是 将其 归为 对应 概率 最大 的 那一个 当 
式 中的 都是 很小 的 负数 时 就 会 发生 
下溢 这 意味着 上面 函数 的 分母 会 变成 0 
导致 结果 是 未定 的 同理 当 式 中的 是 
很大 的 正数 时 就 会 发生 上溢 导致 结果 
是 未定 的 5 2 计算 复杂性 与 NP 问题 
1 算法 复杂性 现实 中 大多数 问题 都是 离散 的 
数据集 为了 反映 统计 规律 有时 数据 量 很大 而且 
多数 目标函数 都 不能 简单 地 求得 解析 解 这就 
带来 一个 问题 算法 的 复杂性 算法 理论 被 认为 
是 解决 各类 现实 问题 的 方法论 衡量 算法 有 
两个 重要 的 指标 时间 复杂度 和 空间 复杂度 这是 
对 算法 执行 所 需要 的 两类 资源 时间 和 
空间 的 估算 一般 衡量 问题 是否 可解 的 重要 
指标 是 该 问题 能否 在 多项式 时间内 求解 还是 
只能 在 指数 时间 内 求解 在 各类 算法 理论 
中 通常 使用 多项式 时间 算法 即可 解决 的 问题 
看作 是 易解 问题 需要 指数 时间 算法 解决 的 
问题 看作 是 难解 问题 指数 时间 算法 的 计算 
时间 随着 问题 规模 的 增长 而 呈 指数化 上升 
这类 问题 虽然 有解 但 并 不适 用于 大 规模 
问题 所以 当前 算法 研究 的 一个 重要 任务 就是 
将 指数 时间 算法 变换 为 多项式 时间 算法 2 
确定性 和非/nr 确定性 除了 问题 规模 与 运算 时间 的 
比较 衡量 一个 算法 还 需要 考虑 确定性 和非/nr 确定性 
的 概念 这里 先 介绍 一下 自动机 的 概念 自动机 
实际上 是 指 一种 基于 状态 变化 进行 迭代 的 
算法 在 算法 领域 常把 这类 算法 看作 一个 机器 
比较 知名 的 有 图灵机 玻尔兹曼 机 支持 向量 机 
等 所谓 确定性 是 指 针对 各种 自动机 模型 根据 
当时 的 状态 和 输入 若 自动机 的 状态 转移 
是 唯一 确定 的 则 称 确定性 若在 某一 时刻 
自动机 有 多个 状态 可供 选择 并 尝试 执行 每个 
可选择 的 状态 则 称为 非 确定性 换个 说法 就是 
确定性 是 程序 每次 运行 时 产生 下 一步 的 
结果 是 唯一 的 因此 返回 的 结果 也 是 
唯一 的 非 确定性 是 程序 在 每个 运行时 执行 
的 路径 是 并行 且 随机 的 所有 路径 都 
可能 返回 结果 也 可能 只有 部分 返回 结果 也 
可能 不 返回 结果 但是 只要 有 一个 路径 返回 
结果 那么 算法 就 结束 在 求解 优化 问题 时 
非 确定性 算法 可能 会 陷入 局部 最优 3 NP/w 
问题/n 有了/nr 时间/n 上/f 的/uj 衡量/v 标准/n 和/c 状态/n 转移/v 
的/uj 确定性/n 与非/c 确定性/n 的/uj 概念/n 我们 来 定义 一下 
问题 的 计算 复杂度 P 类 问题 就是 能够 以 
多项式 时间 的 确定性 算法 来 对 问题 进行 判定 
或 求解 实现 它 的 算法 在 每个 运行 状态 
都是/nr 唯一 的 最终 一定 能够 确定 一个 唯一 的 
结果 最优 的 结果 NP 问题 是 指 可以 用 
多项式 时间 的 非 确定性 算法 来 判定 或 求解 
即 这类 问题 求解 的 算法 大多 是非 确定性 的 
但 时间 复杂度 有 可能 是 多项式 级别 的 但是 
NP 问题 还 要 一个 子类 称为 NP 完全问题 它 
是 NP 问题 中 最难 的 问题 其中 任何 一个 
问题 至今 都 没有 找到 多项式 时间 的 算法 机器学习 
中 多数 算法 都是/nr 针对 NP 问题 包括 NP 完全问题 
的 5 3 数值 计算 上面 已经 分析 了 大部分 
实际 情况 中 计算机 其实 都 只能 做 一些 近似 
的 数值 计算 而 不 可能 找到 一个 完全 精确 
的 值 这 其实 有 一门 专门 的 学科 来 
研究 这个 问题 这门 学科 就是 数值分析 有时 也 叫作 
计算方法 运用 数值分析 解决 问题 的 过程 为 实际 问题 
→ 数学模型 → 数值 计算方法 → 程序设计 → 上机 计算 
求出 结果 计算机 在 做 这些 数值 计算 的 过程 
中 经常 会 涉及 到 的 一个 东西 就是 迭代 
运算 即 通过 不停 的 迭代计算 逐渐 逼近 真 实值 
当然 是 要在 误差 收敛 的 情况 下 六 最优化 
本节 介绍 机器学习 中 的 一种 重要 理论 最优化 方法 
6 1 最优化 理论 无论 做 什么事 人们 总 希望 
以 最小 的 代价 取得 最大 的 收益 在 解决 
一些 工程 问题 时 人们 常会 遇到 多种 因素 交织 
在 一起 与 决策 目标 相互 影响 的 情况 这就 
促使 人们 创造 一种 新的 数学 理论 来 应对 这 
一 挑战 也 因此 最早 的 优化 方法 线性规划 诞生 
了 在 李航 博士 的 统计 学习 方法 中 其 
将 机器学习 总结 为 如下 表达式 机器学习 = 模型 + 
策略 + 算法 可以 看得出 算法 在 机器学习 中的 重要性 
实际上 这里 的 算法 指 的 就是 优化 算法 在 
面试 机器 学习 的 岗位 时 优化 算法 也 是 
一个 特别 高频 的 问题 大家 如果 真的 想 学好 
机器学习 那 还是 需要 重视 起来 的 6 2 最优化 
问题 的 数学 描述 最 优化 的 基本 数学模型 如下 
它 有 三个 基本要素 即 设计 变量 x 是 一个 
实 数域 范围内 的 n 维 向量 被 称为 决策变量 
或 问题 的 解 目标函数 f x 为 目标函数 约束条件 
称为 等式 约束 为 不等式 约束 6 3 凸 集 
与 凸 集 分离 定理 1 凸 集 实 数域 
R 上 或 复数 C 上 的 向量空间 中 如果 
集合 中 任 两点 的 连线 上 的 点 都在 
内 则 称 集合 为 凸 集 如下 图 所示 
数学 定义 为 设 集合 若 对于 任意 两点 及 
实数 都有 则 称 集合 D 为 凸 集 2 
超平面 和半/nr 空间 实际上 二维 空间 的 超平面 就是 一条线 
可以 使 曲线 三维空间 的 超平面 就是 一个 面 可以 
是 曲面 其 数学 表达式 如下 超平面 半 空间 3 
凸 集 分离 定理 所谓 两个 凸 集 分离 直观 
地 看 是 指 两个 凸 集合 没有 交叉 和 
重合 的 部分 因此 可以 用 一张 超平面 将 两者 
隔在 两边 如下 图 所示 4 凸函数 凸函数 就是 一个 
定义域 在 某个 向量空间 的 凸 子集 C 上 的 
实值函数 数学 定义 为 对于 函数 f x 如果 其 
定义域 C 是 凸 的 且 对于 ∀ x y 
∈ C 有 则 f x 是 凸函数 注 如果 
一个 函数 是 凸函数 则 其 局部 最 优点 就是 
它 的 全局 最 优点 这个 性质 在 机器学习 算法 
优化 中 有很 重要 的 应用 因为 机器学习 模型 最后 
就是 在 求 某个 函数 的 全局 最 优点 一旦 
证明 该 函数 机器学习 里面 叫 损失 函数 是 凸函数 
那 相当于 我们 只用 求 它 的 局部 最优 点了 
6 4 梯度 下降 算法 1 引入 前面 讲 数值 
计算 的 时候 提到 过 计算机 在 运用 迭代法 做 
数值 计算 比如 求解 某个 方程组 的 解 时 只要 
误差 能够 收敛 计算机/n 最后/f 经过/p 一定/d 次数/n 的/uj 迭代/v 
后是/nr 可以/c 给/p 出/v 一个/m 跟/p 真实/d 解很/nr 接近/v 的/uj 
结果/n 的/uj 这里 进一步 提出 一个 问题 如果 我们 得到 
的 目标 函数 是非 线性 的 情况 下 按照 哪个 
方向 迭代 求解 误差 的 收敛 速度 会 最快 呢 
答案 就是 沿 梯度方向 这就 引入 了 我们 的 梯度 
下 降法 2 梯度 下 降法 在 多元 微分学 中 
梯度 就是 函数 的 导数 方向 梯度 法是/nr 求解 无约束 
多元 函数 极值 最早 的 数值 方法 很多 机器 学习 
的 常用 算法 都 是以 它 作为 算法 框架 进行 
改进 而 导出 更为 复杂 的 优化 方法 在 求解 
目标函数 的 最小值 时 为 求得 目标函数 的 一个 凸函数 
在 最优化 方法 中被 表示 为 根据 导数 的 定义 
函数 的 导函数 就是 目标函数 在上 的 变化 率 在 
多元 的 情况 下 目标函数 在某 点 的 梯度 是 
一个 由 各个 分量 的 偏 导数 构成 的 向量 
负 梯度方向 是 减小 最快 的 方向 如上 图 所示 
当 需 要求 的 最小值 时 机器学习 中的 一般 就是 
损失 函数 而 我们 的 目标 就是 希望 损失 函数 
最小化 我们 就 可以 先 任意 选取 一个 函数 的 
初始 点 三维 情况 就是 让其 沿着 途中 红色 箭头 
负 梯度方向 走 依次 到 . . . 迭代 n 
次 这样 可 最快 达到 极小值 点 梯度 下 降法 
过程 如下 输入 目标函数 梯度 函数 计算精度 输出 的 极小值 
点 1 任取 取 初始值 置 2 计算 3 计算 
梯度 当时 停止 迭代 令 4 否则 令 求 使 
5 置 计算 当 或时 停止 迭代 令 6 否则 
置 转 3 6 5 随机 梯度 下降 算法 上面 
可以 看到 在 梯度 下 降法 的 迭代 中 除了 
梯度 值 本身 的 影响 外 还有 每一次 取 的 
步长 也很 关键 步长 值 取得 越大 收敛 速度 就 
会 越快 但是 带来 的 可能 后果 就是 容易 越过 
函数 的 最优 点 导致 发散 步长 取 太小 算法 
的 收敛 速度 又 会 明显 降低 因此 我们 希望 
找到 一种 比较 好 的 方法 能够 平衡 步长 随机 
梯度 下 降法 并 没有 新的 算法 理论 仅仅 是 
引进 了 随机样本 抽取 方式 并 提供 了 一种 动态 
步长 取值 策略 目的 就是 又要 优化 精度 又要 满足 
收敛 速度 也 就是说 上面 的 批量 梯度 下 降法 
每次 迭代 时 都会 计算 训练 集中 所有 的 数据 
而 随机 梯度 下 降法 每次 迭代 只是 随机 取了 
训练 集中 的 一部分 样本数据 进行 梯度 计算 这样 做 
最大 的 好处 是 可以 避免 有时候 陷入 局部 极小值 
的 情况 因为 批量 梯度 下 降法 每次 都 使用 
全部 数据 一旦 到 了 某个 局部 极小值 点 可能 
就 停止 更新 了 而/c 随机/d 梯度/n 法/l 由于/c 每次/r 
都是/nr 随机/d 取/v 部分/n 数据/n 所以 就算 局部 极小值 点 
在下 一步 也 还是 可以 跳出 两者 的 关系 可以 
这样 理解 随机 梯度 下降 方法 以 损失 很小 的 
一部分 精确度 和 增加 一定 数量 的 迭代 次数 为 
代价 换取 了 总体 的 优化 效率 的 提升 增加 
的 迭代 次数 远远 小于 样本 的 数量 6 6 
牛顿 法1/nr 牛顿/nr 法/l 介绍/v 牛顿/nr 法/l 也是/i 求解/v 无约束/l 
最优化/v 问题/n 常用/b 的/uj 方法/n 最大 的 优点 是 收敛 
速度快 从 本质 上 去看 牛顿 法是/nr 二阶 收敛 梯度 
下降 是 一 阶 收敛 所以 牛顿 法就/nr 更快 通俗 
地 说 比如 你 想找 一条 最短 的 路径 走到 
一个 盆地 的 最底部 梯度 下 降法 每次 只从 你 
当前 所处 位置 选 一个 坡度 最大 的 方向 走 
一步 牛顿 法在/nr 选择 方向 时 不仅 会 考虑 坡度 
是否 够大 还会 考虑 你 走了 一步 之后 坡度 是否 
会 变得 更大 所以 可以 说 牛顿 法比/nr 梯度 下 
降法 看得 更远 一点 能 更快 地 走到 最 底部 
或者 从 几何 上 说 牛顿 法 就是 用 一个 
二次曲面 去 拟合 你 当前 所处 位置 的 局部 曲面 
而 梯度 下 降法 是 用 一个 平面 去 拟合 
当前 的 局部 曲面 通常 情况下 二次曲 面的 拟合 会比 
平面 更好 所以 牛顿 法 选择 的 下降 路径 会 
更 符合 真实 的 最优 下降 路径 2 牛顿 法的/nr 
推导 将 目标函数 在 处 进行 二阶 泰勒 展开 可得 
因为 目标函数 有 极值 的 必要条件 是 在 极值 点 
处 一 阶 导数 为 0 即 所以 对 上面 
的 展开式 两边 同时 求导 注意 才是 变量 是 常量 
都是 常量 并 令 可得 即 于是/nr 可以 构造 如下 
的 迭代 公式 这样 我们 就 可以 利用 该 迭代 
式 依次 产生 的 序列 才 逐渐 逼近 的 极小值 
点了 牛顿 法的/nr 迭代 示意图 如下 上面 讨论 的 是 
2 维 情况 高维 情况 的 牛顿 迭代 公式 是 
式 中 ▽ 是的 梯度 即 H 是 Hessen 矩阵 
即 3 牛顿 法的/nr 过程 1 给定 初值 和 精度 
阈值 并 令 2 计算 和 3 若 则 停止 
迭代 否则 确定 搜索 方向 4 计算 新的 迭 代点 
5 令 转至 2 6 7 阻尼 牛顿 法1/nr 引入 
注意到 牛顿 法的/nr 迭代 公式 中 没有 步长 因子 是 
定 步长 迭代 对于 非 二次型 目标函数 有时候 会 出现 
的 情况 这表明 原始 牛顿 法 不能 保证 函数值 稳定 
的 下降 在 严重 的 情况 下 甚至 会 造成 
序列 发散 而 导致 计算 失败 为 消除 这一 弊病 
人们 又 提出 阻尼 牛顿 法 阻尼 牛顿 法 每次 
迭代 的 方向 仍然 是 但 每次 迭代 会 沿 
此 方向 做 一维 搜索 寻求 最优 的 步长 因子 
即 2 算法 过程 1 给定 初值 和 精度 阈值 
并 令 2 计算 在 处 的 梯度 值 和 
3 若 则 停止 迭代 否则 确定 搜索 方向 4 
利用 得到 步长 并 令 5 令 转至 2 6 
8 拟 牛顿 法1/nr 概述/v 由于/c 牛顿/nr 法/l 每一步/i 都/d 
要求/v 解/v 目标函数/i 的/uj Hessen/w 矩阵/n 的/uj 逆/vg 矩阵/n 计算 
量 比较 大 求 矩阵 的 逆运算 量 比较 大 
因此 提出 一种 改进 方法 即 通过 正定矩阵 近似 代替 
Hessen 矩阵 的 逆 矩阵 简化 这一 计算 过程 改进 
后的/nr 方法 称为 拟 牛顿 法 2 拟 牛顿 法的/nr 
推导 先将 目标函数 在 处 展开 得到 两边 同 时取 
梯度 得 取 上式 中的 得 即 可得 上面 这个 
式子 称为 拟 牛顿 条件 由 它 来 对 Hessen 
矩阵 做 约束 