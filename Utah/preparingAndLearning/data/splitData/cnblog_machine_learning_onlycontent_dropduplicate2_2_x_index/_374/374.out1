前言 特征 是 数据 中 抽取 出来 的 对 结果 
预测 有用 的 信息 可以 是 文本 或者 数据 特征 
工程 是 使用 专业 背景 知识 和 技巧 处理 数据 
使得 特征 能在 机器学习 算法 上 发挥 更好 的 作用 
的 过程 过程 包含 了 特征提取 特征 构建 特征选择 等 
模块 特征 工程 的 目的 是 筛选 出 更好 的 
特征 获取 更好 的 训练 数据 因为 好 的 特征 
具有 更强 的 灵活性 可以 用 简单 的 模型 做 
训练 更 可以 得到 优秀 的 结果 工欲善其事 必先利其器 特征 
工程 可以 理解 为利 其 器 的 过程 互联网 公司 
里 大 部分 复杂 的 模型 都是/nr 极少数 的 数据 
科学家 在做 大多数 工程师 们 做 的 事情 基本 是 
在 数据 仓库 里 搬 砖 不断 地 数据 清洗 
再 一个 是 分析 业务 不断 地 找 特征 例如 
某 广告 部门 的 数据 挖掘 工程师 2周 内 可以 
完成 一次 特征 迭代 一个 月 左右 可以 完成 模型 
的 小 优化 来 提升 auc 1 . 数据采集 / 
清洗 / 采样 数据采集 数据采集 前 需要 明确 采集 哪些 
数据 一般 的 思路 为 哪些 数据 对 最后 的 
结果 预测 有 帮助 数据 我们 能够 采集 到 吗 
线上 实时 计算 的 时候 获取 是否 快捷 举例 1 
我 现在 要 预测 用户 对 商品 的 下单 情况 
或者 我 要给 用户 做 商品 推荐 那我/nr 需要 采集 
什么 信息 呢 店家 店铺 的 评分 店铺 类别 商品 
商品 评分 购买 人数 颜色 材质 领子 形状 用户 历史 
信息 购买 商品 的 最低价 最高价 消费 能力 商品 停留时间 
数据 清洗   数据 清洗 也是 很 重要 的 一步 
机器学习 算法 大多数 时候 就是 一个 加工 机器 至于 最后 
的 产品 如何 取决于 原材料 的 好坏 数据 清洗 就是 
要 去除 脏数据 比如 某些 商品 的 刷 单 数据 
那么 如何 判定 脏数据 呢 1 简单 属性 判定 一个人 
身高 3米 + 的 人 一个 人 一个 月 买了 
10w 的 发卡 2 组合 或 统计 属性 判定 号称 
在 米国 却 ip 一直都 是 大陆 的 新闻 阅读 
用户 你 要 判定 一个 人 是否 会 买 篮球鞋 
样本 中 女性 用户 85% 3 补齐 可 对应 的 
缺省值 不 可信 的 样本 丢掉 缺省值 极多 的 字段 
考虑 不用 数据 采样 采集 清洗 过 数据 以后 正负 
样本 是 不 均衡 的 要 进行 数据 采样 采样/v 
的/uj 方法/n 有/v 随机/d 采样/v 和/c 分层抽样/l 但是 随机 采样 
会有 隐患 因为 可能 某次 随机 采样 得到 的 数据 
很 不均匀 更多 的 是 根据 特征 采用 分层抽样 正负 
样本 不平衡 处理 办法 正 样本 负 样本 且 量 
都 挺大 = downsampling 正 样本 负 样本 量 不大 
= 1 采集 更多 的 数据 2 上 采样 / 
oversampling 比如 图像识别 中的 镜像 和 旋转 3 修改 损失 
函数 / loss function 设置 样本 权重 2 . 特征 
处理 2.1 数值 型 1 .   幅度 调整 / 
归一化 python 中会 有一些 函数 比如 preprocessing . MinMaxScaler 将 
幅度 调整 到 0 1 区间 2 . 统计 值 
包括 max min mean std 等 python 中用 pandas 库 
序列化 数据 后 可以 得到 数据 的 统计 值 3 
. 离散化 把 连续 值 转成 非线性 数据 例如 电商 
会有 各种 连续 的 价格 表 从 0.03 到 100元 
假 如以 一 元钱 的 间距 分割 成 99个 区间 
用 99 维 的 向量 代表 每 一个 价格 所处 
的 区间 1.2 元和 1.6元 的 向量 都是 0 1 
0 0 pd . cut 可以 直接 把 数据 分成 
若干段 4 . 柱状 分布 离散化 后 统计 每个 区间 
的 个数 做 柱状图 2.2 类别 型 类别 型 一般 
是 文本 信息 比如 颜色 是 红色 黄色 还是 蓝色 
我们 存储 数据 的 时候 就 需要 先 处理 数据 
处理 方法 有 1 .   one hot 编码 编码 
后 得到 哑 变量 统计 这个 特征 上 有 多少 
类 就 设置 几维 的 向量 pd . get _ 
dummies 可以 进行 one hot 编码 ２ .   Hash 
编码 成词/nr 向量 ３ .   Histogram 映射 把 每 
一列 的 特征 拿出来 根据 target 内容 做 统计 把 
target 中的 每个 内容 对应 的 百分比 填到 对应 的 
向量 的 位置 优点 是 把 两个 特征 联系起来 上 
表中 我们 来 统计 性别 与 爱好 的 关系 性 
别有 男 女 爱好 有三种 表示 成 向量 散步 足球 
看 电视剧 分别 计算 男性 和 女性 中 每个 爱好 
的 比例 得到 男 1/3 2/3 0 女 0 1/3 
2/3 即 反映 了 两个 特征 的 关系 2.3 时间 
型 时间 型 特征 的 用处 特别 大 既 可以 
看做 连续 值 持续时间 间隔时间 也 可以 看做 离散 值 
星期几 几月份 连续 值 a 持续时间 单页 浏览 时长 b 
间隔时间 上次 购买 / 点击 离 现在 的 时间 离散 
值 a 一天 中 哪个 时间段 hour _ 0 23 
b 一周 中 星期几 week _ monday . . . 
c 一年中 哪个 星期 d 一年中 哪个 季度 e 工作日 
/ 周末 数据挖掘 中经 常会 用 时间 作为 重要 特征 
比如 电商 可以 分析 节假日 和 购物 的 关系 一天 
中 用户 喜好 的 购物 时间等 2.4 文本 型 １ 
.   词 袋 文本 数据 预处理 后 去掉 停用词 
剩下 的 词 组成 的 list 在 词库 中的 映射 
稀疏 向量 Python 中用 CountVectorizer 处理 词 袋 ． ２ 
. 把 词 袋 中的 词 扩充 到 n gram 
n gram 代表 n 个 词 的 组合 比如 我 
喜欢 你 你 喜欢 我 这 两句话 如果 用词 袋 
表示 的话 分词 后 包含 相同 的 三个 词 组成 
一样 的 向量 我 喜欢 你 显然 两句话 不是 同 
一个 意思 用 n gram 可以 解决 这个 问题 如果 
用 2 gram 那么 我 喜欢 你 的 向量 中会 
加上 我 喜欢 和 喜欢 你 你 喜欢 我 的 
向量 中会 加上 你 喜欢 和 喜欢 我 这样 就 
区分 开来 了 ３ . 使用 TF IDF 特征 TF 
IDF 是 一种 统计 方法 用以 评估 一 字词 对于 
一个 文件 集 或 一个 语料库 中的 其中 一份 文件 
的 重要 程度 字词 的 重要性 随着 它 在 文件 
中 出现 的 次数 成正比 增加 但 同时 会 随着 
它 在 语料库 中 出现 的 频率 成反比 下降 TF 
t = 词 t 在当 前文 中 出现 次数 / 
t 在 全部 文档 中 出现 次数 IDF t = 
ln 总 文档 数 / 含 t 的 文档 数 
TF IDF 权重 = TF t * IDF t 自然语言 
处理 中 经常 会 用到 2.5 统计 型 加减 平均 
商品 价格 高于 平均 价格 多少 用户 在 某个 品类 
下消 费 超过 平均 用户 多少 用户 连续 登录 天数 
超过 平均 多少 . . . 分 位线 商品 属于 
售出 商品 价格 的 多少 分 位线 处 次序 型 
排在 第 几位 比例 类 电商 中 好 / 中 
/ 差评 比例 你 已 超过 全国 百分之 的 同学 
2.6 组合 特征 1 . 拼接 型 简单 的 组合 
特征 例如 挖掘 用户 对 某种 类型 的 喜爱 对 
用户 和 类型 做 拼接 正负 权重 代表 喜欢 或 
不喜欢 某种 类型 user _ id & & category 10001 
& & 女裙 10002 & & 男士 牛仔 user _ 
id & & style 10001 & & 蕾丝 10002 & 
& 全棉 2 . 模型 特征 组合 用 GBDT 产出 
特征 组合 路径 组合 特征 和 原始 特征 一起 放进 
LR 训练 3 . 特征选择 特征选择 就是 从 多个 特征 
中 挑选 出 一些 对 结果 预测 最 有用 的 
特征 因为/c 原始/v 的/uj 特征/n 中/f 可能会/i 有/v 冗余/a 和/c 
噪声/n 特征选择/nr 和降维/nr 有/v 什么/r 区别/n 呢/y 前者 只 踢掉 
原本 特征 里 和 结果 预测 关系 不大 的 后者 
做 特征 的 计算 组合 构成 新 特征 3.1 过滤 
型 方法   评估 单个 特征 和 结果 值 之间 
的 相关 程度 排序 留下 Top 相关 的 特征 部分 
评价 方式 Pearson 相关系数 互信息 距离 相关度 缺点 只 评估 
了 单个 特征 对 结果 的 影响 没有 考虑到 特征 
之间 的 关联 作用 可能 把 有用 的 关联 特征 
误 踢掉 因此 工业界 使用 比较 少 python 包 SelectKBest 
指定 过滤 个数 SelectPercentile 指定 过滤 百分比 3.2 包裹 型 
方法 把 特征选择 看做 一个 特征 子集 搜索 问题 筛选 
各种 特征 子集 用 模型 评估 效果 典型 算法 递归 
特征 删除 算法 应用在 逻辑 回归 的 过程 用 全量/nr 
特征 跑 一个 模型 根据 线性 模型 的 系数 体现 
相关性 删掉 5 10% 的 弱 特征 观察 准确率 / 
auc 的 变化 逐步 进行 直至 准确率 / auc 出现 
大 的 下滑 停止 python 包 RFE3 . 3 嵌入 
型 方法 根据 模型 来 分析 特征 的 重要性 最 
常见 的 方式 为 用 正则化 方式 来做 特征选择 举例 
最早 在 电商 用 LR 做 CTR 预估 在 3 
5亿 维 的 系数 特征 上用 L1 正则化 的 LR 
模型 上 一篇 介绍 了 L1 正则化 有 截断 作用 
剩余 2 3 千万 的 feature 意味着 其他 的 feature 
重要 度 不够 python 包 feature _ selection . SelectFromModel 
选出 权重 不为 0 的 特征 注 以上 总结 来自 
于 七月 在线 课程 