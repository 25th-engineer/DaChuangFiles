这是 机器学习 知识 体系 中 的 线性 回归 内容 完整 
的 知识 体系 可以 查看 这里 机器学习 什么 是 机器学习 
业界 有如 下定义 •   ArthurSamuel 1959 . MachineLearning Fieldof 
study that gives computers the ability to learn without being 
explicitly programmed . • TomMitchell 1998 Well posed Learning Problem 
A computer program is said to learn from experience E 
with respect to some task T and some performance measure 
P if its performance on T as measured by P 
improves with experience E . 通常 情况下 人类 进行编程 让 
机器 完成 一项 工作 需要 事先 定义 好 一系列 程序逻辑 
机器 然后 根据 编写 的 代码 来 执行 这种方式 其实 
人类 定义 的 规则 机器 仅仅 是 运算 执行 而已 
机器学习 强调 的 是 without explicitly programmed 通过 机器 根据 
某些 经验 数据 自我 归纳 总 结算法 从而 对 一些 
新的 数据 进行 准确 的 预测 推导 常见 的 应用 
场景 包括 1 . 数据挖掘 2 . 手写识别 自然语言 处理 
NLP 计算机 视觉 3 . 产品 推荐 系统 4 . 
. . . 监督 学习 和无/nr 监督 学习 机器学习 方式 
大体上 分为 两种 类别 监督 学习 和非/nr 监督 学习 监督 
学习 指 的 是 人类 给 机器 一大堆 标示 label 
过 的 数据 通常指 机器 通过 学习 一 系列 数据 
X 代表 输入 数据 特征 Feature Y 代表 输出 数据 
然后 自我 推导 到 X Y 的 公式 用于 未来 
其他 数据 的 预测 判断 使用 监督 学习 根据 输出 
数据 又 分为 回归 问题 Regression 和 分类 问题 Classfication 
回归 问题 通常 输出 是 一个 连续 的 数值 分类 
问题 的 输出 是 几个 特定 的 数值 举例 如下 
a 回归 问题 给定 一张 人脸 照片 估计 出 这个 
人 的 年龄 年龄 输出 是 一个 连续 的 数值 
b 分类 问题 假定 一个 人 患有 肿瘤 判断 是 
为 恶性 还是 良性 恶性 和 良性 的 输出 是 
几个 特定 的 数值 回归 问题 房价 预测 分类 问题 
肿瘤 恶性 / 良性 判 断无 监督 学习 所 学习 
的 数据 没有 属性 或 标签 这一 概念   也就是说 
所有 的 数据 都是/nr 一样 的 没有 区别 通常 给 
的 数据 是 一系列 并不 存在 Y 的 输出 数据 
所以在 无 监督 学习 中 我们 只有 一个 数据集 没人 
告诉 我们 该 怎么做 我们 也 不 知道 每 个数 
据点 究竟 是 什么 意思 相反 它 只 告诉 我们 
现在 有一个 数据集 你 能在 其中 找到 某种 结构 吗 
对于 给定 的 数据集 无 监督 学习 算 法可能 判定 
该 数据集 包含 不同 的 聚 类 并且 能够 归纳 
出 哪些 数据 是 一个 聚 类 模型 表达 在 
建立 数学模型 之前 先 约定 好 一些 表达形式 代表 输入 
数据 features 代表 输出 数据 target 代表 一组 训练 数据 
training example m 代表 训练 数据 的 个数 n 代表 
特征 数量 监督 学习 目标 就是 假定 给 一组 训练 
数据 可以 学习 到 一个 函数 方法 h 可以 使得 
h x y 这个 函数 方法 h 被称为 假设 hypothesis 
整体 流程 如下 代价 函数 对于 线性 回归 而言 函数 
h 的 表达式 如下 我们 通常 指定 如果 使用 线性代数 
来 表达 的话 其中 是 矩阵 的 转置 Transpose 那么 
对于 一 系列 训练 数据 如何 获得 最优 的 成为 
解决 问题 的 核心 直观 上 而言 我们 希望 获取 
一组 值 使得 h x 越 接近 y 越好 于是 
定义 这个 衡量 标准 为 代价 函数 Cost Function 如下 
这个 函数 又 称为 Squared Error Function 我们 看 下 
两个 参数 的 Cost Function 图像 通常 如下 它 是 
一个 弓形 的 图像 这个 弓形 的 最低点 就是 的 
最优 解 梯度 下降 算法 对于 线性 回归 问题 我们 
需要 解决 的 事情 往往 如下 定义出 Cost Function 希望 
能够 找到 一组 能够 最小化 即 梯度 下降 算法 步骤 
如下 1 . 随机 选择 一组 2 . 不断 的 
变化 让 变小 j = 0 1 . . . 
n 是 所有 n + 1个 值 同时 进行 变化 
α 是 代表 学习 速率   是 Cost Function 对 
的 偏 导数 3 . 直到 寻找 到 最小值 偏 
导 求解 如下 因此 最终 的 梯度 下降 算法 表达 
如下 从 Cost Function 的 图上 我们/r 可以/c 看到/v 选择/v 
最优/d 解的/nr 过程/n 寻找/v 到/v 局部/n 最优/d 解1/nr 寻找/v 到/v 
局部/n 最优/d 解2从/nr 上面/f 两个/m 图/n 可以/c 看出/v 寻找 最优 
解的/nr 过程 很想 是 在 下山 沿着 下山 的 路 
下来 并 最终 到达 一个 局部 的 底部 保持 不变 
正规 方程 Normal Equation 梯度 下降 算法 给出 了 一种 
方法 可以 最小化 Cost Function 正规 方程 Normal Equation 是 
另外 一种 方法 它 使用 非常 直接 的 方式 而 
不 需要 进行 迭代 的 算法 在 这个 方法 中 
我们 通过 对 J 取 对应 的 的 偏 导数 
然后 将 偏 导数 设置 为 0 通过 推导 正规 
方程 如下 梯度 下降 算法 和 正规 方程 对比 如下 
梯度 下降 算法 正规 方程 需要 选择 学习 速率 参数 
不 需要 学习 速率 参数 需要 很多 次 迭代 不需要 
迭代 n 如果 很大 依旧 还能 工作 n 如果 很大 
速度 会 非常 慢 因此 两 种方法 能否 工作 取决于 
n 特征 x 的 数量 的 大小 如果 n 很大 
10000 那么 使用 梯度 下降 算法 是 比较 明智 的 
选择 = = = = = = = = = 
= = = = = = = = 华丽 的 
分割线 = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = 广告 时间 
请 关注 我 个人 微信 公众 号 聊聊 技术 管理 
生活 