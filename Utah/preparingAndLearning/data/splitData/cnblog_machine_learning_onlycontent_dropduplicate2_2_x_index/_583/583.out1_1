最近 的 十几 年 机器学习 很是 火热 尤其 是 其中 
的 一个 分支 深度 学习 在 工业界 取得 很好 应用 
吸引 了 很多 眼球 不过 从其 历程 来看 机器 学习 
的 历史 并不 短暂 ~ 从 早期 的 感知机 到 
八十 年代 火热 的 神经 网络 再到 九十 年代 被 
提出 的 经典 算法 集成 学习 和 支持 向量 机 
而 最近 的 十年 算得 上 是 机器 学习 发展 
的 黄金 年代 软 硬件 计算 条件 大幅提高 尤其 是 
现在 数据量 的 爆发 式 增长 让 机器 拥有 充分 
学习 的 资本 另一方面 现在 开源 项目 越来越 多 即便 
一些 算法 的 实现 很复杂 我等 小白 只 需要 调 
几个 接口 也 能 完成 对 数据 的 处理 在 
这个 年代 里 不同 的 人 充斥 着 不同 的 
野心 计算机 科学家 仍 在 探索 人工智能 的 奥义 资本 
媒体 都在 热炒 机器学习 概念 大 数据 AI 俨然 成为 
宠儿 各行 程序员 也在 茶余饭后 有了 谈资 盛名之下 其实难副 机器学习 
人工智能 的 发展 还 处在 浅层 特别 是 深度 学习 
这些 被 媒体 过度 炒作 的 产物 从 计算 智 
能到 感知 智能 再到 认知 智能 前面 的 路 依然 
很远 长 路漫漫 不管怎样 越来越 多 的 人 投入 这个 
行业 确实 对 行业 本身 有 很大 的 发展 特别 
是 可以 看出 国内外 很多 高校 的 专家 学者 已经 
把 研究 阵地 转向 工业 不 仅仅 是 因为 报酬 
丰厚 更 因为 工业界 提供 了 现实 场景 更 丰富 
的 数据 而 这些 数据 让 算法 拥有 很好 的 
施展 空间 还记得 16年 在 亚马逊 买了 一本 南大 周志华 
老师 的 机器学习 到手 之后 真的 超出 了 预期 书 
上面 的 算法 介绍 的 比较 系统 每一 章节 提到 
了 某个 领域 的 经典 算法 后面 给出 的 附录 
也 适合 非 科班 同学 看懂 ~ 更 难得 是 
这是 一本 中文 的 可以 当成 教材 的 书 ~ 
而且 从写的/nr 内容 来看 真的 很 谦虚 严谨 总之 比较 
推荐 入门 的 同学 看 因为 之前 一直 被 广为人知 
的 还是 NG 的 斯坦福 大学 Machine Learning 公开课 讲义 
现在 终于 有本好/nr 的 中文 图书 了 似乎 有些 偏 
题了 初衷 只是 想 写 一个 机器学习 系列 笔记 的 
开篇 算是 对 自己 的 一个 督促 吧 现在 很多 
时候 感觉 脑子 不 动 真的 是 要 上 锈了 
~ 好了 不多 说 了 下面 进入 正题 吧 ~ 
1 . 概念 机器学习 到底 是 什么 Wiki 上有 Tom 
M . Mitchell 这样 一段 定义 A computer program is 
said to learn from experience E with respect to some 
class of tasks T and performance measure P if its 
performance at tasks in T as measured by P improves 
with experience E . 我 经常 这样 总结   设计 
模型 并从 已 观测 的 数据 中 学习 出 模型 
参数 然后 通过 模型 对 未知 进行 分 预测 这样 
说 似乎 还是 有点 抽象 台大 李宏 毅 老师 ppt 
解释 的 非常 形象 这个 图 解释 的 含义 是 
什么 呢 可以 这样 看 机器 学习 的 本质 是 
进行 预测 比如 我们 想 要 判断 一幅 输入 的 
图像 是 猴子 猫 还是 狗 怎样 预测 呢 1 
首先 我们 需要 找到 一个 模型 来 表达 预测 的 
过程 这个 模型 可能 包含 一个 或者 多 个 需要 
设定 的 参数 因此 模型 是 一个 多 个 函数 
组成 的 集合 2 在 模型 确定 了 之后 我们 
需要 从 数学 上 寻找 一个 函数 来 表示 这个 
模型 即从 函数 集合 中 寻找 一个 能够 准确 地 
表达 模型 这 一步 我们 需要 在 已知 的 数据 
上 进行 学习 即 让 函数 能够 在 已知 数据 
上 获得 很 不错 的 预测 效果 3 使用 2 
中 确定 的 函数 对 未知 的 数据 进行 预测 
一个 典型 的 机器学习 系统 包含 输入 和 输出 空间 
分别 对应 输入 和 输出 所有 可能 取值 的 集合 
输入 值 简称 样本 描述 了 样本 不同 特征 或者 
属性 的 取值 它 可以 是 一个 向量 矩阵 张量 
或者 其他 更为 复杂 的 数学 形式 比如 \ x 
= \ left x ^ { 1 } x ^ 
{ 2 } . . . x ^ { n 
} \ right \ 输出 值 一般 是 离散 或者 
连续 的 值 如果 是 离散 的 对应 于 分类 
问题 此时 描述 了 样本 的 类别 标签 如果 是 
连续 的 则 对应 于 回归 问题 描述 了 具体 
的 输出 值 输出 值 通常 可以 用 \ y 
\ 表示 机器学习 系统 的 目标 在于 利用 已知 数据 
信息 设计 合理 的 函数 映射 在 给定 新的 未知 
数据 时 使得 输出 值 比较 符合 我们 的 预期 
\ F = \ left \ { f | Y 
= f _ { \ theta } X \ theta 
\ in R ^ { n } \ right \ 
} \ 大写 的 \ X \ 和\/nr Y \ 
分别 对应 于 某个 输入 或者 输出 的 集合 好 
的 特征 输入 对于 机器学习 模型 的 设计 尤为重要 比如 
很多 电商 需要 预测 用户 可 能 购买 或者 感兴趣 
的 产品 怎样 基于 用户 过去 的 购买 浏览 收藏 
等 行为 构建 行为 特征 把 具体 的 用户 行为 
数学化 如果 我们 需要 对 房价 进行 预测 我们 可能 
会 拥有 已有 房产 的 大小 地理位置 户型 甚至 当前 
房市 总体 行情 等 特征 我们 需要 选择 哪些 特征 
并 处理 成 模型 的 输入 形式 这对 预测 的 
最终 结构 非常 重要 像 这种 特征选择 或者 处理 在 
数据 挖掘 中 做 的 非常 多 我们 有时 叫做 
业务 模型 构建 这 其实 并 不是 机器学习 过度 关注 
的 问题 机器学习 更加 关注 与 模型 和 算法 本身 
我 把 机器 学习 做 的 事情 概括 成 任务 
策略 和 方法 其中 任务 描述 了 机器 学习 的 
最终 目的 而 策略 描述 了 机器 学习 在 处理 
问题 时 使用 的 方案 方 法则 是 机器 学习 
在 处理 实际 问题 中 使用 的 具体 方法 2 
. 任务 机器 学习 的 本质 在于 使用 已知 数据 
的 经验 来 预测 未知 数据 从 模型 的 输出 
来看 我们 处理 实际 问题 的 最终 目的 主要 可以 
分成 两种 一是 分类 classification 即 预测 某个 输入 样本 
对应 的 类别 或者 叫 标签 二 是 回归 regression 
即 预测 输入 样本 对应 的 具体 的 输出 值 
1 通俗 一点 的 来讲 分类 也 就是 我们 通常 
所说 的 识别 比 如上图 中 判断 图像 中 是否 
包含 一只猫 分类 包含 二元 分类 和 多元 分类 即 
模型 可能 输出 的 标签 是 2个 或者 大于 2个 
比如 判断 图像 中 是否 存在 猫 判断 一封 邮件 
是 不是 垃圾 邮件 这里 输 出有 或者 无 是 
典型 的 二元 分类 判断 图像 中 是 猫 还是 
狗 猴子 或者 其他 动物 则是 多元 分类 可以 看出 
分类 模型 中 输出 的 值 是 离散 的 值 
2 回归 是 指 模型 的 输出 可能 是 多个 
连续 的 值 比如 要 预测 明天 天气 的 最高 
温度 这里 的 温度 就 是 一个 存在 于 某个 
范围 区间 的 值 房价 预测 无人驾驶 方向盘 输出 角度 
预测 都 可以 看成 是 回归 任务 3 . 策略 
在 不同 的 场景 下 我们 会 遇到 不同 类型 
的 数据 而 数据 的 不同 也 会 导致 我们 
设计 机器学习 模型 的 策略 不同 通常 情况下 可以 分成 
以下 几种 1 有 监督 学习 supervised learning 即 给定 
的 样本 是 有 标记 的 2 无 监督 学习 
supervised learning 即 给定 的 样本 是 无 标记 的 
3 半 监督 学习 semi supervised learning 一 部分 样本 
是 有 标记 的 另一 部分 是 无 标记 的 
大多数 现实 机器学习 模型 都是 有 监督 学习 因为 已知 
输出 的 数据 训练 效果 对 最后 预测 的 结果 
影响 太大 了 有 监督 学习 强调 人类 教 机器 
进行 学习 比如 小孩子 可能 没有 见过 猴子 现实 的 
或者 图片 但是 父母 会 告诉他 这是 一只 猴子 因此 
孩子 的 大脑皮层 会 对此 做出 记忆 和 处理 认为 
这种 类型 的 东东 是 一只 猴子 并且 在 看到 
其他 动物 的 时候 大脑 会 将其 图像 和 猴子 
的 特征 进行 相似 度 比较 来 判断 是 一只 
猴子 还是 其他 动物 这一 行为 是 典型 的 有 
监督 学习 无 监督 学习 强调 让 机器 自己 去 
学习 比如 聚 类 算法 机器 可以 自己 进行 归类 
而 不 需要 任何 标记 的 数据 考虑 到 现实 
场景 获取 有 标记 的 数据 代价 较高 你 需要 
人工 的 方式 去打 标记 而 网络 社会 中 包含 
大量 没有 标记 的 数据 这些 数据 很好 获取 更为 
重要 的 是 这些 数据 对于 对于 预测 本身 是 
有 很大 帮助 的 比如 近些年 比较 热门 的 一个 
方向 迁移 学习 如果 我们 要 做 人脸识别 由于 人脸 
头像 存在 角度 光照 等 复杂 外界 因素 的 干扰 
那么 是否 可以 借助 这些 大量 的 不同 场景 的 
无 标记 数据 实现 模型 本身 的 迁移 从而 使其 
更 能适应 干扰 提高 识别 的 精度 呢 这 就是 
迁移 学习 的 一个 重要 作用 4 . 方法 方法 
就是 具体 的 模型 设计 用到 的 方法 比如 线性 
方法 或 非线性 方法 线性 方法 比如 早期 的 感知机 
线性 回归 线性 的 子空间 投影 方法 如 经典 的 
降 维 算法 主 成分 分析 等等 非线性 方法 比如 
现在 火热 的 深度 神经网络 支持 向量 机 等等 这些 
在 后面 的 文章 中 会 提到 5 . 经验 
风险 最小化 结构 风险 最小化 和 过拟合 欠 拟合 有了 
模型 和 样本 之后 我们 需要 利用 这些 样本 即 
通过 这些 已经 观测 得到 的 数据 对模型 参数 进行 
训练 这个 过程 也 就是 学习 或者 训练 然后 通过 
学习 的 模型 对 未知 数据 进行 预测 的 过程 
可以 称之为 预测 预测 的 目的 在于 检验 学习 得到 
模型 的 好坏 然而 一个 机器学习 系统 的 好坏 不仅 
和 模型 设计 有关 而且/c 和/c 数据/n 的/uj 特点/n 有/v 
很大/a 关系/n No free lunch 告诉 我们 模型 的 设计 
必然 会 带来 某些 方面 的 代价 或者 损失 因此 
必须 综合 数据 的 特点 算法 模型 开销 等等 各个 
方面 来 设计 比如 在 某些 情况下 样本 规模 大小 
和 数据 的 分布 完全 不 知道 倘若在 设计 模型 
的 时候 过于 追求 精度 致使 模型 对 训练 样本 
的 预测 效果 很好 但是 在 预测 新的 未知 数据 
时 效果 很差 也 就是 我们 常说 的 过拟合 问题 
举 一个 很 直观 的 例子 小明 学习 的 基础 
并 不是 很好 在 学习 了 一个 新 的 知识 
点 之后 做 了 很多 习题 这些 习题 套路 固定 
题型 类似 然后 需要 进行 测试 如果 测验 用 的 
题目 和 题型 与 练习 的 题目 变化 不大 那么 
小明 在 考试 中 很 有可能 取得 很好 的 成绩 
然而 这种 测试 获得 的 成绩 掩盖 了 背后 的 
假象 一旦 出题 老师 换 一个 全新 的 套路 小明 
的 成绩 很 有可能 就 炸 了 可以 看出 过拟合 
意味着 模型 适应 不同 场景 数据 的 能力 我们 有时候 
叫做 泛化 能力 过拟合 问题 是 机器学习 长期 需要 面对 
的 挑战 之一 而 现实 中 有 很多 情况 掩盖 
了 过拟合 带来 的 问题 其中 之一 便是 数据量 比如 
小明 如果 平时 做 的 习题 足够 足够 多 那么 
还是 很 有可能 应付 测验 的 再者 我们 也 不能 
让 一个 模型 为了 过于 适应 复杂 场景 追求 算法 
的 适应 能力 但是 过多 的 损失 了 精度 这 
就是 欠 拟合 下面 的 样本 分布图 样本 分布图 通常 
以 二维 坐标 的 形式 展示 样本 的 分布 情况 
给出 了 一个 示例 来 展示 欠 拟合 和 过拟合 
用 小圈圈 表示 二维 平面 中的 样本 其中 红色 圈圈 
表示 训练样本 绿色 圈圈 表示 真实 样本 然后 我 分别 
用 不同 的 多项式 曲线 去 拟合 这些 样本 可以 
看出 第 一幅 图 中的 简单 直线 并 没有 准确 
的 对 训练 样本 和 真实 样本 进行 拟合 但是 
从 一定 程度 表示 出了 样本 的 大概 趋势 这是 
欠 拟合 第二幅 图 中的 曲线拟合 地 效果 比较 好 
尽管 在 个别 样本 稍有 偏差 但 就 预测 真实 
样本 而言 是 三张 图中 最好 的 这 正是 理想 
情况下 需要 寻找 的 模型 相比较 而言 第三幅 图中 的 
曲线 虽然能 完美 地 反映 出 训练 样本点 的 位置 
不过 存在 很大 的 缺陷 也 就是 曲线 过于 复杂 
在 真实 的 环境 下 会 遭遇 严重 的 过拟合 
问题 比如 横坐标 9 到 10 的 这些 点 与 
预期 值 差别 巨大 在 很多 情况 下 大量 的 
数据 是 不可多得 的 有时候 我们 尝试 从 模型 而不是 
数据 方面 着手 解决 此 问题 因此 怎样 合理 地 
控制 模型 使之 避免 过拟合 呢 首先 在 监督 学习 
中 我们 需要 定义 一定 的 标准 来 保证 学习 
的 精度 的 好坏 显而易见 的 是 我们 可以 使用 
一种 叫做 损失 函数 的 东东 来 衡量 结果 损失 
函数 可以 解释 为 衡量 预测值 和 实际 值 之间 
的 一致性 损失 函数 可以 使用 \ L \ left 
Y f X \ right \ 来 表示 很容易 想到 
的 一种 关于 \ L \ 的 表示 是 使用 
衡量 预测值 和 实际 值 之间 的 偏差 为了 保证 
偏差 总是 大于 0 的 可以 用 \ L \ 
left Y f X \ right = \ left Y 
f x \ right ^ { ^ { 2 } 
} \ 来 表示 还有 的 模型 可能会 使用 偏差 
的 绝对值 之和 0 1 值 或者 其他 的 方式 
定义 损失 函数 实际上 如 偏差 平方和 形式 的 损失 
函数 是 基于 最小二乘 拟合 的 一种 应用 基于 极大 
似 然 估计 可以 得到 在后面 博客 中 写到 线性 
回归 的 时候 提到 ~ 如果 给定 训练 集合 也 
就是 包含 多个 样本 的 数据集 模型 关于 样本 的 
平均 损失 可以 称之为 经验 损失 或者 经验 风险 顾名思义 
也 就是 根据 已 给出 的 数据 经验 式 地 
衡量 模型 的 好坏 比如 对于 训练 集 \ \ 
left \ { x _ { 1 } y _ 
{ 1 } x _ { 2 } y _ 
{ 2 } . . . x _ { m 
} y _ { m } \ right \ } 
\ 对应 的 经验 损失 可以 定义 为 \ R 
_ { emp } f = \ frac { 1 
} { n } \ sum _ { i = 
1 } ^ { n } L y _ i 
f x _ i \ 直观 地 来说 如果 需要 
机器 学习 的 预测 效果 好 要求 经验 损失 最小 
也 就是 我们 常说 的 经验 风险 最小化 Empirical Risk 
Minimization ERM 基于 此 策略 可以考虑 如下 的 经验 风险 
最小化 最优化 模型 \ \ mathrm { min } \ 
frac { 1 } { n } \ sum _ 
{ i = 1 } ^ { n } L 
y _ i f x _ i \ 在 样本数据 
量 很大 的 情况 下 ERM 往往 能 获得 很好 
的 预测 效果 但是 正如 前面 提到 的 一旦 数据 
规模 较小 会 出现 过拟合 的 情况 过拟合 是 很多 
机器学习 问题 都会 面对 的 一大 挑战 很多 方法 用来 
避免出现 过拟合 除了 增 大 数据 量 以外 其中 一个 
常见 的 做法 是 对模型 的 复杂 程度 进行 约束 
也 就是 添加 正则化 项 regularizer 或 惩罚 项 penalty 
直观 上 来说 模型 越 复杂 越 难以 模拟 真实 
场景 翻看 很多 paper 不管 是 大牛 的 也好 灌水 
的 也好 限制/v 模型/n 复杂度/n 作为/v 惩罚/vn 项/n 已经/d 是/v 
一件/m 司空见惯/n 的/uj 事情/n 了/ul ~/i 毕竟/d 惩罚/vn 项/n 很容易/i 
对/p 模型/n 进行/v 解释/v 了/ul 尽管 有时候 随意 添加 惩罚 
项的/nr 效果 并 不怎么 好 . . . 这种 约束 
模型 复杂 程度 的 做法 叫做 结构 风险 最小化 意在 
ERM 的 基础 上 限制 模型 复杂度 \ R _ 
{ srm } f = \ frac { 1 } 
{ n } \ sum _ { i = 1 
} ^ { n } L y _ i f 
x _ i + \ lambda J f \ 上式 
中 \ J f \ 即 模型 复杂度 项 系数 
\ \ lambda \ 为 ERM 和 模型 复杂 惩罚 
之间 的 平衡 因子 ~ 不过 不同 模型 处理 过拟合 
会 使用 不同 的 方法 比如 在 回归 分析 中 
添加 的 \ L _ { 1 } \ \ 
L _ { 2 } \ 惩罚 项 得到 的 
lasso 回归 和 岭回归 在 决策树 中 使用 剪枝 来 
降低 模型 复杂度 在 深度 神经 网络 中 使用 dropout 
等等 6 . 模型 评估 和 验证 在 我们 训练 
得到 一个 模型 之后 我们 需要 一定 的 手段 来 
对模型 进行 评估 大多数 情况 我们 会 预留 出 一 
部分 数据 作为 测试 集 使用 这 一部分 数据 进行 
验证 工作 在 模型 评估 环节 当中 我们 不仅 需要 
模型 有 精确 地 预测 效果 还 需要 很强 的 
健壮性 在 算法 精度 和 性能 上都 有好 的 表现 
通常 的 一个 做法 是 我们 需要 对 样本 集 
合做 交叉 验证 多次 选取 不同 或者 不同 规模 的 
训练 集合 进行 评估 另外 不同 的 场景 我们 需要 
考虑 的 侧重点 可能 不 一样 比如 我们 做 一个 
账号 产品缺陷 检测 系统 我们 会 更 关注 在 真实 
的 缺陷 样本 是否 被 检测 出来 而 不是 真实 
的 无 缺陷 样本 有 没有 被 检测 出来 我们 
在 类似 于 这样 的 二分 类 问题 中 使用 
召回率 错误 接受 率 正 类 准确率 准确率 和F/nr measure 
等 指标 来 衡量 分类 效果 用 FP FN TN 
和 TP 定义 以下 行为 样本 的 个数 FP 真实 
样本 是 负 例 被 错误 地 预测 为 正 
例 FN 真实 样本 是 正 例 被 错误 地 
预测 为 负 例 TN 真实 样本 是 负 例 
被 正确 地 预测 为 负 例 TP 真实 样本 
是 正 例 被 正确 地 预测 为 正 例 
召回率 Recall Rate 其 定义 为 \ \ frac { 
TP } { TP + FN } \ 召回率 是 
一种 重要 的 分类器 性能 衡量 指标 因为 在 实际 
应用 中 需要 重点 考虑 的 是 正 类 的 
数据 其 反映 了 被 正确 判定 的 正 类 
样本 占 总的 正 类 样本 的 比重 即 衡量 
着 正 类 样本 检测 的 全面 程度 错误 接受 
率 False positive rate 其 定义 为 \ \ frac 
{ FP } { FP + TN } \ 其 
反映 了 分类 结果 中 负 类 数据 被 预测 
为 正 类 数据 的 比例 正 类 准确率 Precision 
其 定义 为 \ \ frac { TP } { 
TP + FP } \ 衡量 检测 到 正 类 
样本 的 准确率 准确率 Accuracy 其 定义 为 \ \ 
frac { TP + TN } { TP + FN 
+ FP + TN } \ 其 衡量 着 所有 
正确 分类 的 样本 占 总 样本 的 比例 从 
以上 定义 看出 一个 好 的 的 分类器 预测模型 希望 
能 满足 较高 的 召回率 正 类 检测 准确率 以及 
准确率 较低 的 错误 接受 率 然而 实际 情况 中 
查准率/nr 和/c 召回率/i 之间/f 往往/t 难以/d 同时/c 都/d 达到/v 较高/i 
的/uj 值/n 需要 在 二者 之间 寻求 权衡 因此 需要 
折中 考虑 二者 通常 引入 F measure 值 来 考虑 
衡量 准确率 和 召回率 的 调和 平均数 其 被 定义 
为 \ F = 2 \ ast \ beta \ 
ast recall * pre / recall + \ beta ^ 
{ 2 } \ ast pre \ 现 如今 很多 
模型 的 优劣 可以 通过 比较 有名 的 benchmark 来 
度量 每个 benchmark 的 度量 标准 可能 不 一样 比如 
在 图像 分类 竞赛 中 有些 度量 标准 还 包括 
top5 我们 用 最 匹配 的 5个 样本 来 衡量 
准确率 因此 模型 评估 很大 程度 取决于 业务 场景 和 
设定 的 规则 7 . 总结 机器学习 是 一门 关于 
预测 的 学科 即 设计 模型 利用 已知 的 数据 
预测 未知 的 数据 数据分布/n 和/c 模型/n 本身/r 都对/i 预测/vn 
的/uj 结果/n 有/v 一定/d 的/uj 影响/vn 没有 完美 的 模型 
我们 构建 的 是 适用 于 不同 场景 的 模型 
在 预测 过程 中 我们 会 遇到 过拟合 欠 拟合 
等 挑战 而在 benchmark 上 对模型 评估 和 验证 为 
我们 提供 了 调节 模型 的 指标 暂时 写 到这 
后面 的 文章 准备 从 线性 模型 开始 写 一些 
机器学习 中 经典 或者 重要 的 算法 