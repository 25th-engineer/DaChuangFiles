上一 篇 文章 主要 介绍 了 查询 与 文档 内容 
相似性 的 打分 以及 基于 概率模型 的 BM25 模型 和 
如何 修改 lucene 的 排序 源代码 这 篇 文章 将 
重点 讲述 机器学习 排序 其中 的 重头戏 是 关于 ListNet 
算法 的 英文原版 学术 论文 的 解读 以及 RankLib 源码 
包的/nr 学习 机器学习 排序 从 Pairwise 方法 到 Listwise 方法 
Zhe Cao * Tao Qin * 清华大学 北京 10084 中国 
Tie Yan Liu 微软 亚洲 研究院 海淀区 知春路 49号 10080 
中国北京 Ming Feng Tsai * 国立 台湾 大学 中华 台北 
106Hang Li 微软 亚洲 研究院 海淀区 知春路 49号 10080 中国 
北京翻译 XueQiang   Tong     http / / www 
. cnblogs . com / txq157     txq157 @ 
163 . com 说明 在 翻译 过程 中 我会 尽量 
尊重 原著 力求 做到 简洁 易懂 后面 会 加入 自己 
的 一些 理解 摘要 本文 主要 阐述 对 排序 对象 
构建 机器学习 模型 评分 函数 机器学习 排序 在 文档 检索 
协同/n 过滤/v 以及/c 其他/r 许多/m 领域/n 都有/nr 广泛/a 且/zg 重要/a 
的/uj 应用/v 目前 一种 基于 把 文档 对 作为 排序 
对象 的 机器学习 排序 方法 已经 被 提出 来 在 
学术界 我们 把 它 称为 Pairwise 方法 尽管 Pairwise 有所改进 
然而 它 忽略 了 一个 非常 重要 的 事实 我们 
的 排序 预测 任务 是 基于 所有 的 排序 对象 
这些 对象 的 排列 顺序 要 远远 多于 两个 对象 
的 排列 本文 论述 的 机器学习 排序 方法 是 把 
对象 列表 检索 出 的 全部 文档 作为 排序 对象 
并且 为 这个 方法 提出 了 一种 概率模型 具体来说 我们 
引入 了 两个 概率模型 作为 Listwise 方法 的 损失 函数 
分别/d 是/v 全/a 排列/v 概率模型/n 和/c top/w one 概率模型 我们 
会 使用 神经网络 构建 评分 函数 和 梯度 下降 作为 
损失 函数 的 优化 手段 在 信息检索 中 的 经验 
显示 Listwise 比 Pairwise 表现 得 更加 出色 1 . 
引言 很多 应用 的 核心 事务 都 离不开 排序 比如 
全文检索 协同 过滤 专家 搜索 反 网络 垃圾邮件 情感 分析 
产品 评级 等等 不失 一般性 本文 主要 以 文档 检索 
为例 讨论 机器学习 排序 当 应用于 全文检索 时 机器学习 排序 
按照 如下 方式 工作 假设 现在 有 一些 文档 集合 
在 检索 的 时候 给定 一个 查询 然后 评分 函数 
给 每一个 返回 的 文档 打分 按 降序 排列 每个 
文档 的 得分 代表 了 与 这个 查询 的 相对 
相关 程度 在 机器学习 排序 的 训练 中 往往 先 
提供 多个 查询 其中/r 每个/r 查询/v 都和由/nr 这个/r 查询/v 得到/v 
的/uj 评分/n 文档/n 集合/v 相关联/l 得到 文档 后用 这些 训练 
数据 创 建出 评分 函数 用以 精确 地 预测 文档 
集 的 得分 由于 它 的 重要性 近年来 机器学习 排序 
在 机器 学习 社区 中 引起 了 广泛 的 关注 
在 业内 被 称之为 Pairwise 的 若干 方法 已经 成功 
用于 全文检索 这个 方法 把 一对儿 有 排列 顺序 的 
文档 作为 训练 学习 的 实例 并且 用 分类 算法 
来 处理 特别地 在 训练 中 在 我们 收集 到 
所有 文档 对儿 的 全 排列 之后 对 每个 文档 
对儿 标识 一个 代表 这两个 文档 相关 程度 的 标签 
1 or 1 然后 我们 用 这些 数据 训 练出 
分类 模型 再用 这个 分类 模型 排序 SVM Boosting 还有 
神经网络 这些 分类 模型 的 应用 直接 导致 RankingSVM Herbrich 
et al . 1999 RankBoost Freund et al . 1998 
RankNet Burges et al . 2005 算法 的 产生 使用 
Pairwise 方法 有 很多 优势 首先 在 分类 算法 中 
很多 成型 的 方法 可以 直接 应用于 排序 中 其次 
在 特定 情况 下 可以 非常 容易 地 获取 到 
文档 对儿 Joachims 2002 然而 这个 方法 存在 很多 缺点 
首先 作为 训练 对象 的 文档 对儿 他 所 训练 
出来 的 模型 的 最小化 损失 函数 是 用在 分类 
中 而非 排序 中 其次 文档 对儿 数量 庞大 导致 
计算 复杂度 太高 第三 文档 对儿 属于 独立 同 分布 
iid 的 假设 过于 严格 strong 与 实际 情况 相差 
甚远 最后 不同 的 查询 产生 的 文档 对儿 数量 
变化 太大 换句话说 文档 对儿 的 数量 对 查询 比较 
敏感 由于 这个 差异 将 直接 导致 训练 模型 更加 
偏向 于 拥有 更多 文档 对儿 的 查询 拥有 多 
数量 文档 对儿 的 查询 对 建模 贡献 更大 在 
本文 中 我们 提出 Listwise 的 方法 在 这个 方法 
中 我们 把 文档 集 作为 训练 对象 接下来 的 
主要 问题 是 如何 定义 Listwise 的 损失 函数 我们 
提出 一个 概率模型 用于 listwise 损失 函数 的 参数估计 我们 
会 同时 把 排序 函数 对 文档 的 打分 此时 
参数 是 未知 的 和 人工 对 文档 显示 的 
或者 隐士 的 打分 变 换成 概率分布 这样 我们 就 
可以 把 两者 特指 概率分布 间 的 距离 差异 作为 
损失 函数 我们 定义 了 两个 概率模型 分别 是 组合 
全 排列 概率模型 和 top one 概率 ListNet 算法 是 
这样 一种 算法 它 使用 listwise 的 损失 函数 优化 
损失 函数 前先 构建 神经网络 模型 然后 用 梯度 下降 
估计 参数 事实 表明 ListNet 算法 明显 好于 Ranking SVM 
RankBoost 还有 RankNet 本文 主要 包括 以下 4 部分 ① 
listwise 算法 的 概述 ② 基于 概率模型 的 损失 函数 
的 转换 ③ listwise 算法 的 发展 ④ 关于 这个 
算法 的 实验 验证 2 . Related Work2 . 1 
机器学习 排序 RankNet 算法 在对 损失 函数 进行 参数估计 时 
使用 交叉 熵 作为 参数 搜索 方向 构建 损失 函数 
使用 梯度 下 降法 优化 损失 函数 在 这个 过程 
中 会 构建 线性 神经网络 作为 评分 函数 Pairwise 算法 
被 先后 应用于 信息检索 比如 Joachims 2002 把 RankingSVM 算法 
应用于 全文检索 他 从 用户 的 点击 数据 一般 从 
点击 图中 获取 中 获取 训练 时要/nr 用到 的 文档 
对儿 2.2 排序 中的 概率模型 Luce 定义 了 概率分布 模型 
他 进一步 引入 参 数来 表征 概率分布 并且 发明 了 
估计 参数 的 方法 Plackett 在 投票 结果 系统 上 
应用 了 这个 模型 和 方法 本文 应用 相似 的 
概率分布 模型 然而 本文 提到 的 底层 结构 parameters 和 
基本 用法 文档 分数 转换 为 概率分布 与 Plackett 的 
会 有些 差异 3 . Listwise 方法 这部分 我们 将 
会 以 全文检索 为例 给出 关于 机器学习 排序 的 一般性 
的 描述 并且 在 细节 上 加以 详细 说明 在 
以下 描述 中 我们 使用 上标 表示 查询 的 索引 
使用 下标 表示 文档 的 索引 在 训练 中 通常 
给定 这样 一组 查询 Q = { q 1 q 
2 q m } 每个/r 查询/v 都和/nr 文档/n 集合/v d/w 
i = d i 1 d i 2 d i 
n i 相关联 其中 d i j 表示 第 j 
个 文档 n i 表示 第 i 个 查询 的 
文档 数目 d i 此外 每 一组 文档 d i 
都和/nr 文档/n 的/uj 人工/n 打分/v y/w i = y i 
1 y i 2 y i n i 相关联 y 
i 代表 了 文档 和 查询 的 相关 程度 这个 
分数 是 人为 指定 的 比如 这个 分数 可以 由 
文档 d i j 的 点击率 转化 而来 Joachims 2002 
这种 假设 认为 具有 较高 点击率 的 文档 和 查询 
的 相关性 更强 一个 特征向量 x i j = Ψ 
q i d i j 是由 每个 查询 文档 q 
i d i j 创建 而来 i = 1 2 
m j = 1 2 n i 每个 特征向量 构成 
x i = x i 1 x i 2 x 
i n i 这是 每个 查询 构成 的 特征 矩阵 
对应 分数 集合 y i = y i 1 y 
i 2 y i n i 最后 训练 集 可以 
表示 成T/nr = ｛ x i y i ｝ mi 
= 1 然后 我们 定义 一个 评分 函数 f 对 
每个 特征向量 x i j 输 出 一个 评分 f 
x i j 对于 特征 矩阵 我们 得到 一组 评分 
z i = f x i 1 f x i 
2 f x i n i 学习 的 目标 是 
在整个 数据集 上 取得 总 损失 函数 最小化 ∑ mi 
= 1L y i z i         
    1 L 为 listwise 的 损失 函数 在 
训练 过 中 给定/v 一个/m 查询/v 和相/nr 关联/ns 的/uj 文档/n 
集/q 我们 把 整个 文档 集 的 函数 打分 和 
人工 打分 转换成 概率分布 然后 计算 差值 利用 梯度 下降 
估计 出 打分 函数 的 最优 参数 优化 的 过程 
然后 用 测试 集 提高 泛化 能力 相比之下 Pairwise 方法 
训练 时在 文档 集中 找 出 所有 的 文档 对儿 
排列 如果 前 一个 文档 的 人工 打分 高于 后 
一个 就 标识 为 1 否 则为 1 最后 用 
这些 训练 数据 训练 出 一个 分类 模型 比如 SVM 
比如 有 三个 文档 我们 暂且 命名为 a b c 
全排/nr 列为 ab 1 ba 1 ac 1 ca 1 
cb 1 bc 1 括号 里 为 预测 后的/nr 分类 
我们 可以 从 所有 分类 为 1 的 组合 中 
找出 文档 排列 顺序 acb Pairwise 算法 将 更多 的 
精力 放在 寻找 全 排列 的 文档 对儿 以及 训练 
分类 模型 上 复杂度 非常 高 Listwise 解决 了 这个 
问题 4 . 概率模型 前面 我们 提出 使 用 两个 
概率模型 中的 任意 一个 计算 损失 函数 这 两个 概率模型 
分别 是 组合概率 和 top one 概率 4.1 . Permutation 
Probability 我们 确定 了 排序 对象 集合 1 2 n 
其中 一种 排 列为 { 1 2 n } 我们 
写 为 π 其中 π j 表示 对象 在 排列 
中 的 位置 文档 集合 的 所有 可能 的 排列 
为 Ω n 以后 我们 有时 会 互换 排名 函数 
和 排名 函数 给出 的 分数 列表 我们 假设 在 
使用 排序 函数 的 排序 列表 中 进行 预测 时 
具有 不确定性 换句话说 任何 排列 都是 可能 的 但是 不同 
的 排列 可能 有 不同 的 似 然 函数 估计 
我们 定义 的 组合概率 在 给定 评分 函数 前提下 应该 
在 组合 概率 的 似 然 估计 上 取得 比较 
理想 的 效果 因此 我们 有 如下 定义 定理 1 
假设 π 是 排序 列表 中 其中 一种 排列 Φ 
. 是 一个 递增 并且 恒 大于 零 的 函数 
那么 排列 组合 的 概率 为 于 任意 的 排序 
列表 在前 一个 文档 得分 高于 后面 一个 文档 得分 
的 情况 下 如果 两者 交换 位置 我们 将 会 
得到 一个 更加 低值 的 概率分布 定理 4 更加 简单 
如果 一个 概率分布 是 按照 文档 的 分数 降序 排列 
的 那么 他 具有 最高值 的 概率分布 反之 如果 按照 
升序 排列 的话 概率分布 的 值 是 最低 的 给定 
两个 scores 集合 我们 根据 他们 计算 出 两个 组合 
概率分布 模型 然后 把 这 两个 模型 之间 的 差值 
作为 listwise 的 损失 函数 然而 对于 容量 为 n 
的 文档 集合 来说 组合 情况 是 n 计算起来 比较 
棘手 所有 我们 考虑 使用 top one 概率模型 4.2 Top 
One Probability 一个 对象 的 top one 概率 表示 这个 
对象 在 所有 的 文档 集中 排在 最 前面 的 
概率 需要 注意 的 是 ListNet 和 RankNet 很 相似 
他们 的 主要 区别 在于 前者 把 document list 作为 
训练 和 预测 的 对象 后者 把 document pair 作为 
实例 比较 有趣 的 是 当 有 一组 查询 每个 
查询 得到 的 文档 数目 为 2时 listwise 的 损失 
函数 变得 和 pairwise 几乎 相等 RankNet 的 时间 复杂度 
为 O m . n2max Burges et al . 2005 
m 代表 查询 的 数目 ｎ 代表 每个 查询 对应 
的 最大 文档 数目 ListNet 的 时间 复杂度 为 O 
m . nmax 6 . 实验 我们 将 使用 三个 
数据集 分别 与 RankNet Burges et al . 2005 Ranking 
SVM Herbrich et al . 1999 和 RankBoost Freund et 
al . 1998 进行 精度 对比 这里 的 ListNet 使用 
top one 概率模型 为了 简单 起见 在 本次 实验 中 
我们 使用 线性 神经网络 模型 并且 省略 常量 b 尖括号 
里面 代表 向量 内积 6.1 数据集 我们 使用 3个 数据集 
TREC OHSUMED CSearch TREC 数据集 包括了 1053110个 pages 11164829个 超链接 
这些 数据 是 查询 50次 得到 的 在 构造 特征向量 
时 考虑 了 内容 特征 和 超链接 特征 总共有 20个 
OHSUMED 数据集 包括了 348556个 documents 106个 queries 16140个 文档 对儿 
总共 构建 了 30个 特征 CSearch 大约 包含 了 25000 
queries 每个 query 有 1000 多个 关联 文档 构建 了 
600个 features 包括 query dependent features and independent features . 
这个 数据集 提供 了 5个 等级 的 评分 4 perfect 
match to 0 bad match 为了 使 排序 更加 接近 
真实 情况 我们 创建 训练 数据集 的 时候 将 使用 
评 分等级 来 表示 关联 程度 的 高低 离散 关联 
判断 在 排名 性能 评估 上 我们 采用 两个 常用 
的 IR 评价 措 NDCG 和 MAP NDCG is designed 
to measure ranking accuracy when there are more than two 
levels of relevance judgments . For MAP it is assumed 
that there are two levels relevant and irrelevant . 关于 
这 两部分 的 理解 可以 参看 http / / www 
. cnblogs . com / HappyAngel / p / 3535919 
. html NDCG 主要 用于 评 分等级 大于 2个 的 
场景 而 MAP 主要 用于 评分 等级 为 相关 和不/nr 
相关 的 场景 6.2 排序 精度 对于 TREC 和 OHSUMED 
我们 把 每个 数据集 分成 5个 部分 实施 五折 交叉 
验证 在 每次 实验 中 3/5 用于 训练 1/5 用于 
验证 剩下 的 1/5 用于 测试 对于 RankNet 和 ListNet 
算法 在 每次 实验 中 验证 集 主要 用于 确定 
最 优化 的 迭代 次数 以便 训 练出 最优 的 
模型 对于 RankingSVM 算法 主要 是 调整 系数 C 而 
RankBoost 算法 主要 寻找 出 最佳 的 weak learns 的 
数量 在 第 6 部分 我们 输出 的 报告 精度 
为 五次 实验 的 平均值 Figure 1 和 Table 1 
给 出了 TREC 的 报告 结果 结果 显示 ListNet 算法 
的 表现 要 优于 其他 三 种方法 尤其在 Table1 的 
报告 中 我们 看到 在 第一次 和 第二 次 试验中 
ListNet 的 NDCG 值 超越 RankNet 大约 4个 point gain 
带来 大约 10% 的 搜索 结果 相关性 的 改进 Figure 
2 和 Table 2 显示 了 OHSUMED 数据集 的 试验 
结果 再一次 在 所有 的 评估 中 ListNet 仍然 优于 
RankNet 和 RankBoost 此外 除了 第 3次 和第/nr 5次 试验 
外 ListNet 算法 均 优于 RankSVM 用 NDCG 评估 CSearch 
的 数据 量 非常 庞大 我们 没有 采用 交叉 验证 
的 方式 我们 从中/nr 随机 选取 1/3 作为 训练 1/3 
用于 验证 剩下 的 1/3 用于 测试 Figure3 显示 了 
ListNet RankNet 和 RankBoost 的 试验 结果 ListNet 算法 再一次 
不负众望 由于 数据量 的 原因 我们 不能 实施 RankingSVM 6.3 
讨论 我们 来 讨论 一下 为什么 基于 listwise 的 方法 
ListNet 优于 基于 pairwise 的 方法 RankNet RankingSVM 还有 RankBoost 
就像 在 第一 部分 解释 过 的 那样 在 pairwise 
方法 中 文档 对儿 的 数量 受 查询 影响 很大 
结果/n 导致/v 在/p 训练/vn 时/n 训练/vn 模型/n 更加/d 偏向/n 于/p 
拥有/v 较多/i 文档/n 对儿/i 的/uj 查询/v 并且 我们 在 几乎 
所有 的 测试 数据集 中都 观察 到 这种 倾向 Table 
2 显示 了 在 OHSUMED 数据集 上 每一个 查询 的 
文档 对儿 的 分布 情况 我们 看到 分布 呈现 明显 
的 倾斜 更多 的 查询 只 拥有 很少 的 文档 
对儿 只有 少数 的 查询 拥有 较多 的 文档 对儿 
在 listwise 方法 中 损失 函数 在 每个 查询 中 
都有 定义 所以 这个 问题 跟 本 不存在 由于 listwise 
把 整个 文档 集 作为 训练 对象 不会 出现 训练 
模型 的 倾向 问题 This appears to be one of 
the reasons for the higher performance 高性能 by ListNet 第二 
个 问题 就是 pairwise 的 损失 函数 问题 由于 pairwise 
实际上 把 排序问题 转换成 了 分类 问题 使用 分类 算法 
的 损失 函数 对于 排序 来说 它 所 付出 的 
代价 可能会 更大 而且 对于 MAP 和 NDCG 这样 的 
评估 准则 更加 适合 用在 把 整个 文档 集 作为 
训练 集 的 场景 pairwise 的 损失 函数 对于 上述 
的 评估 准则 来说 会 显得 更加 松散 我们 更 
进一步 分析 两者 的 损失 函数 的 不同 点 这一次 
我们 使用 TREC 数据集 的 Figure4 和 Figure5 来 说明 
可以 看到 在 训练 中 pairwise 的 损失 函数 并 
不是 完全 和 NDCG 成反比 理想 状态 应该 是 呈现 
反比 关系 即 损失 函数 越小 NDCG 越大 从 数据 
中 我们 看到 从第/nr 20次 迭代 到 第 50次 迭代 
过程 中 两者 loss function and NDCG 还是 呈现 反比 
关系 的 然而 60次 以后 尽管 pairwise 的 损失 函数 
在 下降 NDCG 值 却 并 没有 上升 相比之下 listwise 
的 损失 函数 完全 和 NDCG 呈现 反比 关系 另外 
从 图中 明显 看出 pairwise 损失 函数 收敛 的 速度 
也 明显 慢 于 listwise 最终 我们 得出 结论 listwise 
方法 的 性能 明显 优于 pairwise 更 适合 于 机器学习 
排序 7 . 结论 在 本文 中 我们 提出 了 
一种 新 的 学习 方法 排名 称为 listwise 方法 我们/r 
认为/v 在/p 学习/v 排名/v 时/n 采用/v 这种/r 方法/n 比/p 传统/n 
的/uj 成/n 对法/i 更好/d 在 listwise 方法 中 不是 使用 
对象 对 作为 实例 我们 使用 对象 列表 作为 学习 
中 的 实例 Listwise 方法 的 关键 问题 是 定义 
一个 listwise 损失 函数 在 本文 中 我们 提出 采用 
概率 方法 来 解决 它 具体来说 我们 使用 概率模型 组合概率 
和 top one 概率 将 文档 排名 分数 转换 为 
概率分布 模型 然后 我们 可以 把 两个 概率分布 模型 之间 
的 任何 差值 度量 例如 交叉 熵 视为 listwise 损失 
函数 我们 然后 开发 了 一种 基于 该 方法 的 
学习 方法 使用 线性 神经网络 构建 评分 函数 使用 交叉 
熵 构建 损失 函数 使用 梯度 下 降法 对 损失 
函数 进行 优化 使用 三个 数据集 的 实验 结果 表明 
该 方法 比 现有 的 pairwise 方法 如 RanNet Ranking 
SVM 和 RankBoost 更好 这表明 最好 采用 listwise 方法 来 
学习 排名 除此之外 我们 还 调查 了 pairwise 损失 函数 
和 性能 评估 指标 如 NDCG 和 MAP 之间 的 
关系 8 . 致谢 Bin Gao 对 这项 工作 提出 
了 许多 有 价值 的 建议 我们 还要 感谢 Kai 
Yi 对 我们 实验 的 帮助 9 . 参考 工具 
Baeza Yates R . & Ribeiro Neto B . 1999 
. Modern information retrieval . Addison Wesley . Burges C 
. Shaked T . Renshaw E . Lazier A . 
Deeds M . Hamilton N . & Hullender G . 
2005 . Learning to rank using gradient descent . Proceedings 
of ICML 2005 pp . 89 – 96 . Cao 
Y . B . Xu J . Liu T . 
Y . Li H . Huang Y . L . 
& Hon H . W . 2006 . Adapting ranking 
SVM to document retrieval . Proceedings of SIGIR 2006 pp 
. 186 – 193 . Cohen W . W . 
Schapire R . E . & Singer Y . 1998 
. Learning to order things . Advances in Neural Information 
Processing Systems . The MIT Press . Crammer K . 
& Singer Y . 2001 . Pranking with ranking . 
Proceedings of NIPS 2001 . Craswell N . Hawking D 
. Wilkinson R . & Wu M . 2003 . 
Overview of the TREC 2003 web track . Proceedings of 
TREC 2003 pp . 78 – 92 . Freund Y 
. Iyer R . Schapire R . E . & 
Singer Y . 1998 . An efficient boosting algorithm for 
combining preferences . Proceedings of ICML 1998 pp . 170 
– 178 . Herbrich R . Graepel T . & 
Obermayer K . 1999 . Support vector learning for ordinal 
regression . Proceedings of ICANN 1999 pp . 97 – 
102 . Hersh W . R . Buckley C . 
Leone T . J . & Hickam D . H 
. 1994 . OHSUMED An interactive retrieval evaluation and new 
large test collection for research . Proceedings of SIGIR 1994 
pp . 192 – 201 . Jarvelin K . & 
Kekanainen J . 2000 . IR evaluation methods for retrieving 
highly relevant documents . Proceedings of SIGIR 2000 pp . 
41 – 48 . Joachims T . 1999 . Making 
large scale support vector machine learning practical . Advances in 
kernel methods support vector learning 169 – 184 . Joachims 
T . 2002 . Optimizing search engines using clickthrough data 
. Proceedings of KDD 2002 pp . 133 – 142 
. Lebanon G . & Lafferty J . 2002 . 
Cranking Combining rankings using conditional probability models on permutations . 
Proceedings of ICML 2002 pp . 363 – 370 . 
Luce R . D . 1959 . Individual choice behavior 
. Wiley . Matveeva I . Burges C . Burkard 
T . Laucius A . & Wong L . 2006 
. 10 . 附录 A Proof of Lemma 2End 