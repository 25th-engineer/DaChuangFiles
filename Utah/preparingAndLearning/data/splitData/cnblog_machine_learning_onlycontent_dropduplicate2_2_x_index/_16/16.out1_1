1 KNN 算法 1.1 KNN 算法 简介 KNN K Nearest 
Neighbor 工作 原理 存在 一个 样本数据 集合 也 称为 训练样本 
集 并且 样本 集中 每个 数据 都 存在 标签 即 
我们 知道 样本 集中 每一 数据 与 所属 分类 对应 
的 关系 输入 没有 标签 的 数据 后 将 新 
数据 中 的 每个 特征 与 样本 集中 数据 对应 
的 特征 进行 比较 提取 出 样本 集中 特征 最 
相似 数据 最 近邻 的 分类 标签 一般来说 我们 只 
选择 样本 数据集 中前 k 个 最 相似 的 数据 
这 就是 k 近邻 算法 中 k 的 出处 通常 
k 是 不大 于 20 的 整数 最后 选择 k 
个 最 相似 数据 中 出现 次数 最多 的 分类 
作为 新 数据 的 分类 说明 KNN 没有 显示 的 
训练 过程 它 是 懒惰 学习 的 代表 它 在 
训练 阶段 只是 把 数据 保存 下来 训练 时间 开销 
为 0 等 收到 测试 样本 后 进行 处理 举例 
以 电影 分类 作为 例子 电影 题材 可分为 爱情片 动作片 
等 那么 爱情片 有 哪些 特征 动作片 有 哪些 特征 
呢 也 就是说 给定 一部 电影 怎么 进行 分类 这里 
假 定将 电影 分为 爱情片 和 动作片 两类 如果 一部 
电影 中 接吻 镜头 很多 打斗 镜头 较少 显然 是 
属于 爱情片 反 之为 动作片 有人/r 曾/d 根据/p 电影/n 中/f 
打斗/v 动作/n 和/c 接吻/v 动作/n 数量/n 进行/v 评估/vn 数据 如下 
电影名称 打斗 镜头 接吻 镜头 电影 类别 Califoria Man3104 爱情片 
Beautigul Woman181 爱情片 Kevin Longblade10110 动作片 Amped II982 动作片 给定 
一部 电影 数据 18 90 打斗 镜头 18个 接吻 镜头 
90个 如何 知道 它 是 什么 类型 的 呢 KNN 
是 这样 做 的 首先 计算 未知 电影 与 样本 
集中 其他 电影 的 距离 这里 使用 曼哈顿 距离 数据 
如下 电影 名称 与 未知 分类 电影 的 距离 Califoria 
Man20 . 5Beautigul Woman19 . 2Kevin Longblade115 . 3Amped I 
I 118.9 现在 我们 按照 距离 的 递增 顺序 排序 
可以 找到 k 个 距离 最近 的 电影 加入 k 
= 3 那么 来看 排序 的 前 3个 电影 的 
类别 爱情片 爱情片 动作片 下面 来 进行 投票 这部 未知 
的 电影 爱情片 2票 动作片 1票 那么 我们 就 认为 
这部 电影 属于 爱情片 1.2 KNN 算法 优缺点 优点 精度高 
对 异常值 不 敏感 无 数据 输入 假定 缺点 计算 
复杂度 高 空间 复杂度 高 1.3 KNN 算法 python 代码 
实现 实现 步骤 1 计算 距离 2 选择 距离 最小 
的 k 个 点 3 排序 Python 3 代码 1 
import numpy as np 2 import operator 3 4 def 
classify intX dataSet labels k 5 6 KNN 算法 7 
8 # numpy 中 shape 0 返回 数组 的 行数 
shape 1 返回 列数 9 dataSetSize = dataSet . shape 
0 10 # 将 intX 在 横向 重复 dataSetSize 次 
纵向 重复 1次 11 # 例如 intX = 1 2 
1 2 1 2 1 2 1 2 便于 后面 
计算 12 diffMat = np . tile intX dataSetSize 1 
dataSet 13 # 二维 特征 相减 后 乘方 14 sqdifMax 
= diffMat * * 2 15 # 计算 距离 16 
seqDistances = sqdifMax . sum axis = 1 17 distances 
= seqDistances * * 0.5 18 print distances distances 19 
# 返回 distance 中 元素 从小到大 排序 后的/nr 索引 20 
sortDistance = distances . argsort 21 print sortDistance sortDistance 22 
classCount = { } 23 for i in range k 
24 # 取出 前 k 个 元素 的 类别 25 
voteLabel = labels sortDistance i 26 print 第 % d 
个 voteLabel = % s i voteLabel 27 classCount voteLabel 
= classCount . get voteLabel 0 + 1 28 # 
dict . get key default = None 字典 的 get 
方法 返回 指定 键 的 值 如果 值 不在 字典 
中 返回 默认值 29 # 计算 类别 次数 30 31 
# key = operator . itemgetter 1 根据 字典 的 
值 进行 排序 32 # key = operator . itemgetter 
0 根据 字典 的 键 进行 排序 33 # reverse 
降序 排序 字典 34 sortedClassCount = sorted classCount . items 
key = operator . itemgetter 1 reverse = True 35 
# 结果 sortedClassCount = 动作片 2 爱情片 1 36 print 
sortedClassCount sortedClassCount 37 return sortedClassCount 0 0 View Code2 KNN 
算法 实例 2.1 KNN 实现 电影 分类 1 import numpy 
as np 2 import operator 3 4 def createDataset 5 
# 四组 二维 特征 6 group = np . array 
5 115 7 106 56 11 66 9 7 # 
四组 对应 标签 8 labels = 动作片 动作片 爱情片 爱情片 
9 return group labels 10 11 def classify intX dataSet 
labels k 12 13 KNN 算法 14 15 # numpy 
中 shape 0 返回 数组 的 行数 shape 1 返回 
列数 16 dataSetSize = dataSet . shape 0 17 # 
将 intX 在 横向 重复 dataSetSize 次 纵向 重复 1次 
18 # 例如 intX = 1 2 1 2 1 
2 1 2 1 2 便于 后面 计算 19 diffMat 
= np . tile intX dataSetSize 1 dataSet 20 # 
二维 特征 相减 后 乘方 21 sqdifMax = diffMat * 
* 2 22 # 计算 距离 23 seqDistances = sqdifMax 
. sum axis = 1 24 distances = seqDistances * 
* 0.5 25 print distances distances 26 # 返回 distance 
中 元素 从小到大 排序 后的/nr 索引 27 sortDistance = distances 
. argsort 28 print sortDistance sortDistance 29 classCount = { 
} 30 for i in range k 31 # 取出 
前 k 个 元素 的 类别 32 voteLabel = labels 
sortDistance i 33 print 第 % d 个 voteLabel = 
% s i voteLabel 34 classCount voteLabel = classCount . 
get voteLabel 0 + 1 35 # dict . get 
key default = None 字典 的 get 方法 返回 指定 
键 的 值 如果 值 不在 字典 中 返回 默认值 
36 # 计算 类别 次数 37 38 # key = 
operator . itemgetter 1 根据 字典 的 值 进行 排序 
39 # key = operator . itemgetter 0 根据 字典 
的 键 进行 排序 40 # reverse 降序 排序 字典 
41 sortedClassCount = sorted classCount . items key = operator 
. itemgetter 1 reverse = True 42 # 结果 sortedClassCount 
= 动作片 2 爱情片 1 43 print sortedClassCount sortedClassCount 44 
return sortedClassCount 0 0 45 46 47 48 if _ 
_ name _ _ = = _ _ main _ 
_ 49 group labels = createDataset 50 test = 20 
101 51 test _ class = classify test group labels 
3 52 print test _ class View Code2 . 2 
改进 约会 网站 匹配 这个 例子 简单 说 就是 通过 
KNN 找到 你 喜欢 的 人 首先 数据 样本 包含 
三 个 特征 a 每年 获得 的 飞行 常客 里程数 
b 玩游戏 消耗 的 时间 c 每周 消耗 的 冰激淋 
公升 数 样本数据 放在 txt 中 如下 前 三 列为 
三个 特征值 最后 一 列为 标签 下面 首先 读取数据 获取 
数据集 和 标签 1 def file2matrix filename 2 fr = 
open filename 3 arraylines = fr . readlines 4 # 
获取 行数 5 numberoflines = len arraylines 6 # 返回 
numpy 的 数据 矩阵 目前 矩阵 数据 为 0 7 
returnMat = np . zeros numberoflines 3 8 # 返回 
的 分类 标签 9 classLabelVector = 10 # 行 的 
索引 11 index = 0 12 for line in arraylines 
13 # str . strip rm 删除 str 头 和尾/nr 
指定 的 字符 rm 为 空时/nr 默认 删除 空白符 包括 
\ n \ r \ t 14 line = line 
. strip 15 # 每行 数据 是 \ t 划分 
的 将 每行 数据 按照 \ t 进行 切片 划分 
16 listFromLine = line . split \ t 17 # 
取出 前 三列 数据 存放 到 returnMat 18 returnMat index 
= listFromLine 0 3 19 # 根据 文本 中 标记 
的 喜欢 程度 进行 分类 20 if listFromLine 1 = 
= didntLike 21 classLabelVector . append 1 22 elif listFromLine 
1 = = smallDoses 23 classLabelVector . append 2 24 
else 25 classLabelVector . append 3 26 index + = 
1 27 return returnMat c l a s s L 
a b e l V e c t o r 
V i e w Code 数据 和 标签 我们 可以 
打印 一下 下面 下面 用 Matplotlib 作图 看一下 数据 信息 
1 from matplotlib . font _ manager import FontProperties 2 
import numpy as np 3 import matplotlib . pyplot as 
plt 4 from prepareData _ 1 import file2matrix 5 import 
matplotlib . lines as mlines 6 # from matplotlib . 
font _ manage import FontProperties 7 8 函数 说明 数据 
可视化 9 Parameters 10 datingDataMat 特征 矩阵 11 datingLabels 分类 
标签 向量 12 Returns 13 无 14 15 def showDatas 
datingDataMat datingLabels 16 # 设置 汉子 格式 17 font = 
FontProperties fname = r c \ windows \ fonts \ 
simsun . ttc size = 14 18 # 函数 返回 
一个 figure 图像 和 一个 子图 ax 的 array 列表 
19 fig axs = plt . subplots nrows = 2 
ncols = 2 sharex = False sharey = False figsize 
= 13 8 20 21 numberofLabels = len datingLabels 22 
LabelColors = 23 for i in datingLabels 24 if i 
= = 1 25 LabelColors . append black 26 if 
i = = 2 27 LabelColors . append orange 28 
if i = = 3 29 LabelColors . append red 
30 # 画 散点图 以 数据 矩阵 的 第一 列 
飞行 常客 历程 第二列 玩游戏 数据 话 散点图 31 # 
散 点 大小 为 15 透明度 为 0.5 32 axs 
0 0 . scatter x = datingDataMat 0 y = 
datingDataMat 1 color = LabelColors 33 s = 15 alpha 
= 0.5 34 axs0 _ title _ text = axs 
0 0 . set _ title u 每年 获得 的 
飞行 里程数 与 玩 视频 游戏 消耗 时间 占 比 
35 FontProperties = font 36 axs0 _ xlabel _ text 
= axs 0 0 . set _ xlabel 每年 获得 
的 飞行 常客 里程数 FontProperties = font 37 axs0 _ 
ylabel _ text = axs 0 0 . set _ 
ylabel 玩游戏 消耗 的 时间 FontProperties = font 38 plt 
. setp axs0 _ title _ text size = 9 
weight = bold color = red 39 # 画 散点图 
以 数据 矩阵 的 第一 列 飞行 常客 历程 第三列 
冰激淋 公 斤数 数据 话 散点图 40 # 散 点 
大小 为 15 透明度 为 0.5 41 axs 0 1 
. scatter x = datingDataMat 0 y = datingDataMat 2 
color = LabelColors 42 s = 15 alpha = 0.5 
43 axs0 _ title _ text = axs 0 0 
. set _ title 每年 获得 的 飞行 里程数 与 
冰激淋 公 斤数 占 比 44 FontProperties = font 45 
axs0 _ xlabel _ text = axs 0 0 . 
set _ xlabel 每年 获得 的 飞行 常客 里程数 FontProperties 
= font 46 axs0 _ ylabel _ text = axs 
0 0 . set _ ylabel 所 吃 冰激淋 公 
斤数 FontProperties = font 47 plt . setp axs0 _ 
title _ text size = 9 weight = bold color 
= red 48 # 画 散点图 以 数据 矩阵 的 
第二列 玩游戏 第三列 冰激淋 公 斤数 数据 话 散点图 49 
# 散 点 大小 为 15 透明度 为 0.5 50 
axs 1 0 . scatter x = datingDataMat 1 y 
= datingDataMat 2 color = LabelColors 51 s = 15 
alpha = 0.5 52 axs0 _ title _ text = 
axs 0 0 . set _ title 玩 游戏 时间 
与 冰激淋 公 斤数 占 比 53 FontProperties = font 
54 axs0 _ xlabel _ text = axs 0 0 
. set _ xlabel 每年 获得 的 飞行 常客 里程数 
FontProperties = font 55 axs0 _ ylabel _ text = 
axs 0 0 . set _ ylabel 所 吃 冰激淋 
公 斤数 FontProperties = font 56 plt . setp axs0 
_ title _ text size = 9 weight = bold 
color = red 57 58 # 设置 图例 59 didntLike 
= mlines . Line2D color = black marker = . 
markersize = 6 label = didntlike 60 smallDose = mlines 
. Line2D color = orange marker = . markersize = 
6 label = smallDose 61 largeDose = mlines . Line2D 
color = red marker = . markersize = 6 label 
= largeDose 62 63 # 添加 图例 64 axs 0 
0 . legend handles = didntLike smallDose largeDose 65 axs 
0 1 . legend handles = didntLike smallDose largeDose 66 
axs 1 0 . legend handles = didntLike smallDose largeDose 
67 68 plt . show 69 70 if _ _ 
name _ _ = = _ _ main _ _ 
71 filename = datingTestSet . txt 72 returnMat classLabelVector = 
file2matrix filename 73 showDatas returnMat classLabelVector 74 75View Code 这里 
我 把 py 文件 分开 写了 还要 注意 txt 数据 
的 路径 高大 上 的 图 样本数据 中的 到底 喜欢 
什么 样子 的 人 自己 去 分析 一下 吧 下面 
要 对 数据 进行 归一化 归一化 的 原因 就 不多 
说 了 1 from prepareData _ 1 import file2matrix 2 
import numpy as np 3 4 函数 说明 数据 归一化 
5 Parameters 6 dataSet 特征 矩阵 7 Returns 8 normDataSet 
归一化 后的/nr 特征 矩阵 9 ranges 数据 范围 10 minVals 
数据 最小值 11 12 13 def autoNorm dataSet 14 # 
获得 数据 的 最大 最小值 15 print dataSet 16 print 
* * * * * * * * * * 
* * * * * * * * * * 
* * 17 minVals = dataSet . min 0 18 
maxVals = dataSet . max 0 19 print minValues minVals 
20 print maxValuse maxVals 21 # 计算 最大 最小值 的 
差 22 ranges = maxVals minVals 23 print 24 # 
shape dataSet 返回 dataSet 的 矩阵 行 列数 25 normDataSet 
= np . zeros np . shape dataSet 26 # 
返回 dataSet 的 行数 27 m = dataSet . shape 
0 28 # 原始 值 减去 最小值 29 normDataSet = 
dataSet np . tile minVals m 1 30 # 除以 
最大值 和 最小值 的 差 得到 的 归一化 的 数据 
31 normDataSet = normDataSet / np . tile ranges m 
1 32 return normDataSet ranges minValsView Code 归一化 后的/nr 数据 
如下 有了 以上 步骤 下面 就 可以 构建 完整 的 
约会 分类 去找 你 喜欢 的 人 了 1 from 
prepareData _ 1 import file2matrix 2 from dataNormal _ 3 
import autoNorm 3 import operator 4 import numpy as np 
5 6 函数 说明 knn 算法 分类器 7 Parameters 8 
inX 用于 分类 的 数据 测试 集 9 dataset 用于 
训练 的 数据 训练 集 10 labes 分类 标签 11 
k knn 算法 参数 选择 距离 最小 的 k 个 
点 12 Returns 13 sortedClassCount 0 0 分类 结果 14 
15 def classify0 inX dataset labes k 16 dataSetSize = 
dataset . shape 0 # 返回 行数 17 diffMat = 
np . tile inX dataSetSize 1 dataset 18 sqDiffMat = 
diffMat * * 2 19 sqDistances = sqDiffMat . sum 
axis = 1 20 distances = sqDistances * * 0.5 
21 s o r t e d D i s 
t I n d i c e s = distances 
. argsort 22 classCount = { } 23 for i 
in range k 24 voteLabel = labes s o r 
t e d D i s t I n d 
i c e s i 25 classCount voteLabel = classCount 
. get voteLabel 0 + 1 26 sortedClassCount = sorted 
classCount . items key = operator . itemgetter 1 reverse 
= True 27 return sortedClassCount 0 0 28 def datingClassTest 
29 # filename = test . txt 30 filename = 
datingTestSet . txt 31 datingDataMat datingLabels = file2matrix filename 32 
# 取 所有 数据 的 10% 33 hoRatio = 0.1 
34 # 数据 归一化 返回 归一化 后的/nr 矩阵 数据 范围 
数据 最小值 35 normMat ranges minVals = autoNorm datingDataMat 36 
# 获得 nornMat 的 行数 37 m = normMat . 
shape 0 38 # 百分之十 的 测试数据 的 个数 39 
numTestVecs = int m * hoRatio 40 # 分类 错误 
计数 41 errorCount = 0.0 42 43 for i in 
range numTestVecs 44 # 前 numTestVecs 个 数据 作为 测试 
集 后m/nr numTestVecs 个 数据 作为 训练 集 45 classifierResult 
= classify0 normMat i normMat numTestVecs m 46 datingLabels numTestVecs 
m 10 47 print 分类 结果 % d \ t 
真实 类别 % d % classifierResult datingLabels i 48 if 
classifierResult = datingLabels i 49 errorCount + = 1.0 50 
print 错误率 % f % errorCount / float numTestVecs * 
100 51 52 if _ _ name _ _ = 
= _ _ main _ _ 53 datingClassTest View Code 
都是 上面 的 步骤 这里 就 不 解释 了 结果 
如下 所示 2.3 手写 数字 识别 数据 可以 样例 可以 
打开 文本文件 进行 查看 其中 txt 文件名 的 第一 个 
数字 为本 txt 中的 数字 目录 trainingDigits 中 包含 了 
大约 2000个 例子 每个 数字 大约 有 200个 样本 testDigits 
中 包含 900个 测试数据 我们 使用 trainingDigits 中 的 数据 
训练 分类器 testDigits 中 的 数据 作为 测试 两组 数据 
没有 重合 数据 在 这里 https / / github . 
com / Jenny0611 / Ml _ Learning01 首先 我们 要 
将 图像 数据 处理 为 一个 向量 将 32 * 
32 的 二进制 图像 信息 转化 为 1 * 1024 
的 向量 再 使用 前 面的 分类器 代码 如下 1 
import numpy as np 2 import operator 3 from os 
import listdir 4 from sklearn . neighbors import K N 
e i g h b o r s C l 
a s s i f i e r as kNN 
5 6 7 函数 说明 将 32 * 32 的 
二进制 图片 转 换为 1 * 1024 向量 8 Parameters 
9 filename 文件名 10 Returns 11 returnVect 返回 的 二进制 
图像 的 1 * 1024 向量 12 13 def img2vector 
filename 14 # 创建 1 * 1024 的 0 向量 
15 returnVect = np . zeros 1 1024 16 fr 
= open filename 17 # 按 行 读取 18 for 
i in range 32 19 # 读 一行 数据 20 
lineStr = fr . readline 21 # 每 一行 的 
前 32个 数据 依次 添加到 returnVect 22 for j in 
range 32 23 returnVect 0 32 * i + j 
= int lineStr j 24 return returnVect 25 26 27 
函数 说明 手写 数字 分类 测试 28 Parameters 29 filename 
无 30 Returns 31 returnVect 无 32 33 def h 
a n d w r i t i n g 
C l a s s T e s t 34 
# 测试 集 的 labels 35 hwLabels = 36 # 
返回 trainingDigits 目 录下 的 文件名 37 trainingFileList = listdir 
trainingDigits 38 # 返回 文件夹 下 文件 的 个数 39 
m = len trainingFileList 40 # 初始化 训练 的 Mat 
矩阵 的 测试 集 41 trainingMat = np . zeros 
m 1024 42 # 从 文件名 中 解析 出 训练 
集 的 类别 43 for i in range m 44 
fileNameStr = trainingFileList i 45 classNumber = int fileNameStr . 
split _ 0 46 # 将 获取 的 类别 添加到 
hwLabels 中 47 hwLabels . append classNumber 48 # 将 
每一个 文件 的 1 * 1024 数据 存储 到 trainingMat 
矩阵 中 49 trainingMat i = img2vector trainingDigits / % 
s % fileNameStr 50 # 构建 KNN 分类器 51 neigh 
= kNN n _ neighbors = 3 algorithm = auto 
52 # 拟合 模型 trainingMat 为 测试 矩阵 hwLabels 为 
对应 的 标签 53 neigh . fit trainingMat hwLabels 54 
# 返回 testDigits 目 录下 的 文件 列表 55 testFileList 
= listdir testDigits 56 errorCount = 0.0 57 mTest = 
len testFileList 58 # 从文件 中 解析 出 测试 集 
的 类别 并 进行 分类 测试 59 for i in 
range mTest 60 fileNameStr = testFileList i 61 classNumber = 
int fileNameStr . split _ 0 62 # 获得 测试 
集 的 1 * 1024 向量 用于 训练 63 vectorUnderTest 
= img2vector testDigits / % s % fileNameStr 64 # 
获得 预测 结果 65 classifierResult = neigh . predict vectorUnderTest 
66 print 分类 返回 结果 % d \ t 真实 
结果 % d % classifierResult classNumber 67 if classNumber = 
classifierResult 68 errorCount + = 1.0 69 print 总共 错了 
% d 个 \ t 错误率 为 % f % 
% % errorCount errorCount / mTest * 100 70 71 
if _ _ name _ _ = = _ _ 
main _ _ 72 h a n d w r 
i t i n g C l a s s 
T e s t View Code2 . 4 小结 KNN 
是 简单 有效 的 分类 数据 算法 在/p 使用/v 时/n 
必须/d 有/v 训练/vn 样本数据/i 还要 计算 距离 如果 数据 量 
非常 大 会 非常 消耗 空间 和 时间 它 的 
另一个 缺陷 是 无法 给 出 任何 数据 的 基础 
结构 信息 因此 我们 无法 平均 实例 样本 和 典型 
实例 样本 具体 特征 而 决策树 将 使用 概率 测量 
方法 处理 分类 问题 以后 章节 会 介绍 本文 参考 
http / / blog . csdn . net / c406495762 
/ article / details / 75172850 机器学习 实战 