注 该 系列 文章 以及 使用 到 安装包 / 测试数据 
可以 在 倾情 大 奉送 Spark 入门 实战 系列 获取 
1 MLlib 实例 1.1   聚 类 实例 1 . 
1.1   算法 说明 聚 类 Cluster analysis 有时 也 
被 翻译 为 簇 类 其 核心 任务 是 将 
一组 目标 object 划分 为 若干 个 簇 每个 簇 
之间 的 object 尽可能 相似 簇 与 簇 之间 的 
object 尽可能 相异 聚 类 算法 是 机器学习 或者 说是 
数据挖掘 更 合适 中 重要 的 一部分 除了 最为 简单 
的 K Means 聚 类 算 法外 比较 常见 的 
还有 层次 法 CURE CHAMELEON 等 网格 算法 STING WaveCluster 
等 等等 较 权威 的 聚 类 问题 定义 所谓 
聚 类 问题 就是 给 定 一个 元素 集合 D 
其中 每个 元素 具有 n 个 可 观察 属性 使用 
某种 算法 将 D 划分 成k个/nr 子集 要求 每个 子集 
内部 的 元素 之间 相 异度 尽可能 低 而 不同 
子集 的 元素 相 异度 尽可能 高 其中 每个 子集 
叫 做一个 簇 K means 聚 类 属于 无 监督 
学习 以往 的 回归 朴素 贝叶斯 SVM 等 都是 有 
类别 标签 y 的 也 就是说 样例 中 已经 给 
出了 样例 的 分类 而 聚 类 的 样本 中 
却没有 给定 y 只有 特征 x 比如 假设 宇宙 中 
的 星星 可以 表示 成 三维空间 中的 点 集 聚 
类 的 目的 是 找到 每个 样本 x 潜在 的 
类别 y 并 将同 类别 y 的 样本 x 放在 
一起 比如 上面 的 星星 聚 类 后 结果 是 
一个 个 星团 星团 里面 的 点 相互 距离 比较 
近 星团 间 的 星星 距离 就 比较 远了 与 
分类 不同 分类 是 示例 式 学习 要求 分类 前 
明确 各 个 类别 并 断言 每个 元素 映射 到 
一个 类别 而 聚 类 是 观察 式 学习 在 
聚 类 前 可以 不 知道 类别 甚至不 给定 类别 
数量 是 无 监督 学习 的 一种 目前 聚 类 
广泛 应用于 统计学 生物学 数据库 技术 和 市场 营销 等 
领域 相应 的 算法 也 非常 多 1 . 1.2 
  实例 介绍 在 该 实例 中将 介绍 K Means 
算法 K Means 属于 基于 平方 误差 的 迭代 重 
分配 聚 类 算法 其 核心 思想 十分 简单 l 
随机 选择 K 个 中心点 l 计算所 有点 到这 K 
个 中心点 的 距离 选择 距离 最近 的 中心 点 
为其 所在 的 簇 l 简单 地 采用 算术 平均数 
mean 来 重新 计算 K 个 簇 的 中心 l 
重复 步骤 2 和3/nr 直至 簇 类 不再 发生 变化 
或者 达到 最大 迭代 值 l 输出 结果 K Means 
算法 的 结果 好坏 依赖于 对 初始 聚 类 中心 
的 选择 容易 陷入 局部 最优 解 对 K 值 
的 选择 没有 准 则可 依循 对 异常 数据 较为 
敏感 只能 处理 数值 属性 的 数据 聚 类 结构 
可能 不 平衡 本 实例 中 进行 如下 步骤 1 
. 装载 数据 数据 以 文本文件 方式 进行 存放 2 
. 将 数据 集聚 类 设置 2个 类 和 20次 
迭代 进行 模型 训练 形成 数据模型 3 . 打印 数据模型 
的 中心点 4 . 使用 误差 平方 之和 来 评估 
数据模型 5 . 使用 模型 测试 单点 数据 6 . 
交叉 评估 1 返回 结果 交叉 评估 2 返回 数据集 
和 结果 1 . 1.3 测试数据 说明 该 实例 使用 
的 数据 为 kmeans _ data . txt 可以 在 
本 系列 附带 资源 / data / class8 / 目录 
中 找到 在 该 文件 中 提供 了 6个 点 
的 空间 位置 坐标 使用 K means 聚 类 对 
这些 点 进行 分类 使用 的 kmeans _ data . 
txt 的 数据 如下 所示 0.0 0.0 0 . 00.1 
0.1 0 . 10.2 0.2 0 . 29.0 9.0 9 
. 09.1 9.1 9 . 19.2 9.2 9.21 . 1.4 
程序代码 import org . apache . log4j . { Level 
Logger } import org . apache . spark . { 
SparkConf SparkContext } import org . apache . spark . 
mllib . clustering . KMeansimport org . apache . spark 
. mllib . linalg . Vectorsobject Kmeans { def main 
args Array String { / / 屏蔽 不 必要 的 
日志 显示 在 终端 上 Logger . getLogger org . 
apache . spark . setLevel Level . WARN Logger . 
getLogger org . eclipse . jetty . server . setLevel 
Level . OFF / / 设置 运行 环境 val conf 
= new SparkConf . setAppName Kmeans . setMaster local 4 
val sc = new SparkContext conf / / 装载 数据集 
val data = sc . textFile / home / hadoop 
/ upload / class8 / kmeans _ data . txt 
1 val parsedData = data . map s = Vectors 
. dense s . split . map _ . toDouble 
/ / 将 数据 集聚 类 2个 类 20次 迭代 
进行 模型 训练 形成 数据模型 val numClusters = 2val numIterations 
= 20val model = KMeans . train parsedData numClusters numIterations 
/ / 打印 数据模型 的 中心点 println Cluster centers for 
c model . clusterCenters { println   + c . 
toString } / / 使用 误差 平方 之和 来 评估 
数据模型 val cost = model . computeCost parsedData println Within 
Set Sum of Squared Errors = + cost / / 
使用 模型 测试 单点 数据 println Vectors 0.2 0.2 0.2 
is belongs to clusters + model . predict Vectors . 
dense 0.2 0.2 0.2 . split . map _ . 
toDouble println Vectors 0.25 0.25 0.25 is belongs to clusters 
+ model . predict Vectors . dense 0.25 0.25 0.25 
. split . map _ . toDouble println Vectors 8 
8 8 is belongs to clusters + model . predict 
Vectors . dense 8 8 8 . split . map 
_ . toDouble / / 交叉 评估 1 只 返回 
结果 val testdata = data . map s = Vectors 
. dense s . split . map _ . toDouble 
val result1 = model . predict testdata result1 . saveAsTextFile 
/ home / hadoop / upload / class8 / result 
_ kmeans1 / / 交叉 评估 2 返回 数据集 和 
结果 val result2 = data . map { line = 
val linevectore = Vectors . dense line . split . 
map _ . toDouble val prediction = model . predict 
linevectore line + + prediction } . saveAsTextFile / home 
/ hadoop / upload / class8 / result _ kmeans2 
sc . stop } } 1 . 1.5   IDEA 
执行 情况 第一步     使用 如 下命令 启动 Spark 
集群 $ cd / app / hadoop / spark 1 
. 1.0 $ sbin / start all . sh 第二步 
    在 IDEA 中 设置 运行 环境 在 IDEA 
运行 配置 中 设置 Kmeans 运行 配置 由于 读入 的 
数据 已经 在 程序 中 指定 故在 该 设置 界面 
中 不 需要 设置 输入 参数 第三步     执行 
并 观察 输出 在 运行日志 窗口 中 可以 看到 通过 
计算 计算出 模型 并 找出 两个 簇 中心点 9.1 9.1 
9.1 和 0.1 0.1 0.1 使用 模型 对 测试 点 
进行 分类 求出 分 属于 族 簇 第四步     
查看 输出 结果 文件 在 / home / hadoop / 
upload / class8 目录 中 有 两个 输出 目录 查看 
结果 1 在 该 目录 中 只 输出 了 结果 
分别 列 出了 6个 点 所属 不同 的 族 簇 
查看 结果 2 在/p 该/r 目录/n 中/f 输出/v 了/ul 数据集/i 
和/c 结果/n 1.2/mx  /i 回归/v 算法/n 实例/n 1/m ./i 2.1/mx 
 /i 算法/n 说明/v 线性/n 回归/v 是/v 利用/n 称为/v 线性/n 回归方程/n 
的/uj 函数/n 对/p 一个/m 或/c 多个/m 自变量/l 和/c 因变量/n 之间/f 
关系/n 进行/v 建模/n 的/uj 一种/m 回归/v 分析方法/n 只有 一个 自 
变量 的 情况 称为 简单回归 大于 一个 自变量 情况 的 
叫做 多元回归 在 实际 情况 中 大多数 都是/nr 多元 回归 
线性 回归 Linear Regression 问题 属于 监督 学习 Supervised Learning 
范畴 又称 分类 Classification 或 归纳 学习 Inductive Learning 这类 
分析 中 训练 数据 集中 给出 的 数据 类型 是 
确定 的 机器 学习 的 目标 是 对于 给定 的 
一个 训练 数据集 通过/p 不断/d 的/uj 分析/vn 和/c 学习/v 产生/n 
一个/m 联系/n 属性/n 集合/v 和类标/nr 集合/v 的/uj 分类/n 函数/n Classification 
Function 或 预测 函数 Prediction Function 这个 函数 称为 分类 
模型 Classification Model 或 预测模型 Prediction Model 通过学习 得到 的 
模型 可以 是 一个 决策树 规格 集 贝叶斯 模型 或 
一个 超平面 通过 这个 模型 可以 对 输入 对象 的 
特征向量 预测 或 对 对象 的 类 标 进行 分类 
回归 问题 中 通常 使用 最小二乘 Least Squares 法来/nr 迭代 
最优 的 特征 中 每个 属性 的 比重 通过 损失 
函数 Loss Function 或 错误 函数 Error Function 定义 来 
设置 收敛 状态 即 作为 梯度 下降 算法 的 逼近 
参数 因子 1 . 2.2   实例 介绍 该 例子 
给出 了 如何 导入 训练 集 数据 将其 解析 为 
带 标签 点 的 RDD 然后 使用 了 L i 
n e a r R e g r e s 
s i o n W i t h G D 
算法 来 建立 一个 简单 的 线性 模型 来 预测 
标签 的 值 最后 计算 了 均方差 来 评估 预测值 
与 实际 值 的 吻 合度 线性 回归分析 的 整个 
过程 可以 简单 描述 为 如下 三 个 步骤 1 
寻找 合适 的 预测 函数 即 上文 中的 h x 
用来 预测 输入 数据 的 判断 结果 这个 过程 是 
非常 关键 的 需要 对 数据 有 一定 的 了解 
或 分析 知道 或者 猜测 预测 函数 的 大概 形式 
比 如是 线性函数 还 是非 线性函数 若是 非线性 的 则 
无法 用 线性 回 归来 得出 高质量 的 结果 2 
构造 一个 Loss 函数 损失 函数 该 函数 表示 预测 
的 输出 h 与 训练 数据 标签 之间 的 偏差 
可以 是 二者 之间 的 差 h y 或者 是 
其他 的 形式 如 平方差 开方 综合考虑 所有 训练 数据 
的 损失 将 Loss 求和 或者 求 平均 记为 J 
θ 函数 表示 所有 训练 数据 预测 值 与 实际 
类别 的 偏差 3 显然 J θ 函数 的 值 
越小 表示 预测 函数 越 准确 即 h 函数 越 
准确 所以 这 一步 需要 做 的 是 找到 J 
θ 函数 的 最小值 找 函数 的 最小值 有 不同 
的 方法 Spark 中 采用 的 是 梯度 下 降法 
stochastic gradient descent SGD 1 . 2.3 程序代码 import org 
. apache . log4j . { Level Logger } import 
org . apache . spark . { SparkContext SparkConf } 
import org . apache . spark . mllib . regression 
. L i n e a r R e g 
r e s s i o n W i t 
h G D i m p o r t org 
. apache . spark . mllib . regression . L 
a b e l e d P o i n 
t i m p o r t org . apache 
. spark . mllib . linalg . Vectorsobject LinearRegression { 
def main args Array String Unit = { / / 
屏蔽 不 必要 的 日志 显示终端 上 Logger . getLogger 
org . apache . spark . setLevel Level . ERROR 
Logger . getLogger org . eclipse . jetty . server 
. setLevel Level . OFF / / 设置 运行 环境 
val conf = new SparkConf . setAppName Kmeans . setMaster 
local 4 val sc = new SparkContext conf / / 
Load and parse the dataval data = sc . textFile 
/ home / hadoop / upload / class8 / lpsa 
. data val parsedData = data . map { line 
= val parts = line . split LabeledPoint parts 0 
. toDouble Vectors . dense parts 1 . split . 
map _ . toDouble } / / Building the modelval 
numIterations = 100val model = L i n e a 
r R e g r e s s i o 
n W i t h G D . train parsedData 
numIterations / / Evaluate model on training examples and compute 
training errorval valuesAndPreds = parsedData . map { point = 
val prediction = model . predict point . features point 
. label prediction } val MSE = valuesAndPreds . map 
{ case v p = math . pow v p 
2 } . reduce _ + _ / valuesAndPreds . 
countprintln training Mean Squared Error = + MSE sc . 
stop } } 1 . 2.4   执行 情况 第一步 
    启动 Spark 集群 $ cd / app / 
hadoop / spark 1 . 1.0 $ sbin / start 
all . sh 第二步     在 IDEA 中 设置 
运行 环境 在 IDEA 运行 配置 中 设置 LinearRegression 运行 
配置 由于 读入 的 数据 已经 在 程序 中 指定 
故在 该 设置 界面 中 不 需要 设置 输入 参数 
第三步     执行 并 观察 输出 1.3   协同 
过滤 实例 1 . 3.1   算法 说明 协同 过滤 
Collaborative Filtering 简称 CF WIKI 上 的 定义 是 简单 
来说 是 利用 某 个 兴趣 相投 拥有 共同 经验 
之 群体 的 喜好 来 推荐 感兴趣 的 资讯 给 
使用者 个人 透过 合作 的 机制 给予 资讯 相当 程度 
的 回应 如 评分 并 记录 下来 以 达到 过滤 
的 目的 进而 帮助 别人 筛选 资讯 回应 不 一定 
局限于 特别 感兴趣 的 特别 不 感兴趣 资讯 的 纪录 
也 相当 重要 协同 过滤 常被 应用于 推荐 系统 这些 
技术 旨在 补充 用户 商品 关联矩阵 中所 缺失 的 部分 
MLlib 当前 支持 基于 模型 的 协同 过滤 其中 用户 
和 商品 通过 一 小组 隐 性因子 进行 表达 并且 
这些 因子 也 用于 预测 缺失 的 元素 MLLib 使用 
交替 最小二乘 法 ALS 来 学习 这些 隐 性因子 用户 
对 物品 或者 信息 的 偏好 根据 应用 本身 的 
不同 可能 包括 用户 对 物品 的 评分 用户 查看 
物品 的 记录 用户 的 购买 记录 等 其实 这些 
用户 的 偏好 信息 可以 分为 两类 l   显 
式 的 用户 反馈 这类 是 用户 在 网站 上 
自然 浏览 或者 使用 网站 以外 显 式 地 提供 
反馈 信息 例如 用户 对 物品 的 评分 或者 对 
物品 的 评论 l   隐式 的 用户 反馈 这类 
是 用户 在 使用 网站 是 产生 的 数据 隐式 
地 反映 了 用户 对 物品 的 喜好 例如 用户 
购买 了 某 物品 用户 查看 了 某 物品 的 
信息 等等 显 式 的 用户 反馈 能 准确 地 
反映 用户 对 物品 的 真实 喜好 但 需要 用户 
付出 额外 的 代价 而 隐式 的 用户 行为 通过 
一些 分析 和 处理 也能 反映 用户 的 喜好 只是 
数据 不是 很 精确 有些 行为 的 分析 存在 较大 
的 噪音 但 只要 选择 正确 的 行为 特征 隐式 
的 用户 反馈 也 能 得到 很好 的 效果 只是 
行为 特征 的 选择 可能 在 不同 的 应用 中 
有 很大 的 不同 例如 在 电子 商务 的 网站 
上 购买 行为 其实 就是 一个 能 很好 表现 用户 
喜好 的 隐式 反馈 推荐 引擎 根据 不同 的 推荐 
机制 可能 用到 数据源 中的 一部分 然后 根据 这些 数据 
分析 出 一定 的 规则 或者 直接 对 用户 对 
其他 物品 的 喜好 进行 预测 计算 这样 推荐 引擎 
可以 在 用户 进入 时给他/nr 推荐 他 可能 感兴趣 的 
物品 MLlib 目前 支持 基于 协同 过滤 的 模型 在 
这个 模型 里 用户 和 产品 被 一组 可以 用来 
预测 缺失 项目 的 潜在 因子 来 描述 特别 是 
我们 实现 交替 最小二乘 ALS 算法 来 学习 这些 潜在 
的 因子 在 MLlib 中的 实现 有 如下 参数 l 
  numBlocks 是 用于 并行 化 计算 的 分块 个数 
设置 为 1时 为 自动 配置 l   rank 是 
模型 中 隐性 因子 的 个数 l   iterations 是 
迭代 的 次数 l   lambda 是 ALS 的 正则化 
参数 l   implicitPrefs 决定 了 是 用 显性 反馈 
ALS 的 版本 还是 用 隐性 反馈 数据集 的 版本 
l   alpha 是 一个 针对 于 隐性 反馈 ALS 
版本 的 参数 这个 参数 决定了 偏好 行为 强度 的 
基准 1 . 3.2   实例 介绍 在 本 实例 
中将 使用 协同 过滤 算法 对 GroupLens Research http / 
/ grouplens . org / datasets / movielens / 提供 
的 数据 进行 分析 该 数据 为 一组 从 20 
世纪 90 年末 到 21 世纪初 由 MovieLens 用户 提供 
的 电影 评分 数据 这些 数据 中 包括 电影 评分 
电影 元数据 风格 类型 和 年代 以及 关于 用户 的 
人口 统计学 数据 年龄 邮编 性别 和 职业 等 根据 
不同 需求 该 组织 提供 了 不同 大小 的 样本数据 
不同 样本 信息 中 包含 三 种 数据 评分 用户 
信息 和 电影 信息 对 这些 数据 分析 进行 如下 
步骤 1 .   装载 如下 两种 数据 a 装载 
样本 评分 数据 其中 最后 一 列 时间戳 除 10 
的 余数 作为 key Rating 为 值 b 装载 电影 
目录 对照表 电影 ID 电影 标题 2 . 将 样本 
评分表 以 key 值 切 分成 3个 部分 分别 用于 
训练 60% 并 加入 用户 评分 校验 20% and 测试 
20% 3 . 训练 不同 参 数下 的 模型 并再 
校验 集中 验证 获取 最佳 参 数下 的 模型 4 
. 用 最佳 模型 预测 测试 集 的 评分 计算 
和 实际 评分 之间 的 均方根 误差 5 . 根据 
用户 评分 的 数据 推荐 前 十部 最 感兴趣 的 
电影 注意 要 剔除 用户 已经 评分 的 电影 1 
. 3.3   测试数据 说明 在 MovieLens 提供 的 电影 
评分 数据 分为 三个 表 评分 用户 信息 和 电影 
信息 在 该 系列 提供 的 附属 数据 提供 大概 
6000位 读者 和 100 万个 评分 数据 具体 位置 为 
/ data / class8 / movielens / data 目 录下 
对 三个 表 数据 说明 可以 参考 该 目 录下 
README 文档 1 . 评分 数据 说明 ratings . data 
该 评分 数据 总共 四个 字段 格式 为 UserID MovieID 
Rating Timestamp 分为 为 用户 编号 电影 编号 评分 评分 
时间戳 其中 各个 字段 说明 如下 l 用户 编号 范围 
1 ~ 6040l 电影 编号 1 ~ 3952l 电影 评分 
为 五星 评分 范围 0 ~ 5l 评分 时间戳 单位 
秒 l 每个 用户 至少有 20个 电影 评分 使用 的 
ratings . dat 的 数据 样本 如下 所示 1 1193 
5 9783007601 661 3 9783021091 914 3 9783019681 3408 4 
9783002751 2355 5 9788242911 1197 3 9783022681 1287 5 9783020391 
2804 5 9783007192 . 用户 信息 users . dat 用户 
信息 五个 字段 格式 为 UserID Gender Age Occupation Zip 
code 分为 为 用户 编号 性别 年龄 职业 邮编 其中 
各个 字段 说明 如下 l 用户 编号 范围 1 ~ 
6040l 性别 其中 M 为 男性 F 为 女性 l 
不同 的 数字 代表 不同 的 年龄 范围 如 25 
代表 25 ~ 34岁 范围 l 职业信息 在 测试 数据 
中 提供 了 21中 职业 分类 l 地区 邮编 使用 
的 users . dat 的 数据 样本 如下 所示 1 
F 1 10 480672 M 56 16 700723 M 25 
15 551174 M 45 7 024605 M 25 20 554556 
F 50 9 551177 M 35 1 068108 M 25 
12 114133 . 电影 信息 movies . dat 电影 数据 
分为 三个 字段 格式 为 MovieID Title Genres 分为 为 
电影 编号 电影 名 电影 类别 其中 各个 字段 说明 
如下 l 电影 编号 1 ~ 3952l 由 IMDB 提供 
电影名称 其中 包括 电影 上映 年份 l 电影 分类 这里 
使用 实际 分 类名 非 编号 如 Action Crime 等 
使用 的 movies . dat 的 数据 样本 如下 所示 
1 Toy Story 1995 Animation | Children s | Comedy2 
Jumanji 1995 Adventure | Children s | Fantasy3 Grumpier Old 
Men 1995 Comedy | Romance4 Waiting to Exhale 1995 Comedy 
| Drama5 Father of the Bride Part II 1995 Comedy6 
Heat 1995 Action | Crime | Thriller7 Sabrina 1995 Comedy 
| Romance8 Tom and Huck 1995 Adventure | Children s1 
. 3.4   程序代码 import java . io . Fileimport 
scala . io . Sourceimport org . apache . log4j 
. { Level Logger } import org . apache . 
spark . SparkConfimport org . apache . spark . p 
a r k C o n t e x t 
i m p o r t org . apache . 
spark . SparkContext . _ import org . apache . 
spark . rdd . _ import org . apache . 
spark . mllib . recommendation . { ALS Rating M 
a t r i x F a c t o 
r i z a t i o n M o 
d e l } object MovieLensALS { def main args 
Array String { / / 屏蔽 不 必要 的 日志 
显示 在 终端 上 Logger . getLogger org . apache 
. spark . setLevel Level . WARN Logger . getLogger 
org . eclipse . jetty . server . setLevel Level 
. OFF if args . length = 2 { println 
Usage / path / to / spark / bin / 
spark submit driver memory 2g class week7 . MovieLensALS + 
week7 . jar movieLensHomeDir p e r s o n 
a l R a t i n g s F 
i l e sys . exit 1 } / / 
设置 运行 环境 val conf = new SparkConf . setAppName 
MovieLensALS . setMaster local 4 val sc = new SparkContext 
conf / / 装载 用户 评分 该 评 分由 评分 
器 生成 val myRatings = loadRatings args 1 val myRatingsRDD 
= sc . parallelize myRatings 1 / / 样本数据 目录 
val movieLensHomeDir = args 0 / / 装载 样本 评分 
数据 其中 最后 一 列 Timestamp 取 除 10 的 
余数 作为 key Rating 为 值 即 Int Rating val 
ratings = sc . textFile new File movieLensHomeDir ratings . 
dat . toString . map { line = val fields 
= line . split fields 3 . toLong % 10 
Rating fields 0 . toInt fields 1 . toInt fields 
2 . toDouble } / / 装载 电影 目录 对照表 
电影 ID 电影 标题 val movies = sc . textFile 
new File movieLensHomeDir movies . dat . toString . map 
{ line = val fields = line . split fields 
0 . toInt fields 1 } . collect . toMapval 
numRatings = ratings . count val numUsers = ratings . 
map _ . _ 2 . user . distinct . 
count val numMovies = ratings . map _ . _ 
2 . product . distinct . count println Got + 
numRatings + ratings from + numUsers + users on + 
numMovies + movies . / / 将 样本 评分表 以 
key 值 切 分成 3个 部分 分别 用于 训练 60% 
并 加入 用户 评分 校验 20% and 测试 20% / 
/ 该 数据 在 计算 过程 中 要 多次 应用到 
所以 cache 到 内存 val numPartitions = 4val training = 
ratings . filter x = x . _ 1 6 
. values . union myRatingsRDD / / 注意 ratings 是 
Int Rating 取 value 即可 . repartition numPartitions . cache 
val validation = ratings . filter x = x . 
_ 1 = 6 & & x . _ 1 
8 . values . repartition numPartitions . cache val test 
= ratings . filter x = x . _ 1 
= 8 . values . cache val numTraining = training 
. count val numValidation = validation . count val numTest 
= test . count println Training + numTraining + validation 
+ numValidation + test + numTest / / 训练 不同 
参 数下 的 模型 并在 校验 集中 验证 获取 最佳 
参 数下 的 模型 val ranks = List 8 12 
val lambdas = List 0.1 10.0 val numIters = List 
10 20 var bestModel Option M a t r i 
x F a c t o r i z a 
t i o n M o d e l = 
Nonevar b e s t V a l i d 
a t i o n R m s e = 
Double . MaxValuevar bestRank = 0var bestLambda = 1 . 
0var bestNumIter = 1for rank ranks lambda lambdas numIter numIters 
{ val model = ALS . train training rank numIter 
lambda val validationRmse = computeRmse model validation numValidation println RMSE 
validation = + validationRmse + for the model trained with 
rank = + rank + lambda = + lambda + 
and numIter = + numIter + . if validationRmse b 
e s t V a l i d a t 
i o n R m s e { bestModel = 
Some model b e s t V a l i 
d a t i o n R m s e 
= v a l i d a t i o 
n R m s e b e s t R 
a n k = rankbestLambda = l a m b 
d a b e s t N u m I 
t e r = numIter } } / / 用 
最佳 模型 预测 测试 集 的 评分 并 计算 和 
实际 评分 之间 的 均方根 误差 val testRmse = computeRmse 
bestModel . get test numTest println The best model was 
trained with rank = + bestRank + and lambda = 
+ bestLambda   + and numIter = + bestNumIter + 
and its RMSE on the test set is + testRmse 
+ . / / create a naive baseline and compare 
it with the best modelval meanRating = training . union 
validation . map _ . rating . meanval baselineRmse = 
math . sqrt test . map x = meanRating x 
. rating * meanRating x . rating . mean val 
improvement = baselineRmse testRmse / baselineRmse * 100println The best 
model improves the baseline by + % 1.2 f . 
format improvement + % . / / 推荐 前 十部 
最 感兴趣 的 电影 注意 要 剔除 用户 已经 评分 
的 电影 val myRatedMovieIds = myRatings . map _ . 
product . toSetval candidates = sc . parallelize movies . 
keys . filter myRatedMovieIds . contains _ . toSeq val 
recommendations = bestModel . get . predict candidates . map 
0 _ . collect . sortBy _ . rating . 
take 10 var i = 1println Movies recommended for you 
recommendations . foreach { r = println % 2d . 
format i + + movies r . product i + 
= 1 } sc . stop } / * * 
校验 集 预测 数据 和 实际 数据 之间 的 均方根 
误差 * * / def computeRmse model M a t 
r i x F a c t o r i 
z a t i o n M o d e 
l data RDD Rating n Long Double = { val 
predictions RDD Rating = model . predict data . map 
x = x . user x . product val p 
r e d i c t i o n s 
A n d R a t i n g s 
= predictions . map x = x . user x 
. product x . rating . join data . map 
x = x . user x . product x . 
rating . valuesmath . sqrt p r e d i 
c t i o n s A n d R 
a t i n g s . map x = 
x . _ 1 x . _ 2 * x 
. _ 1 x . _ 2 . reduce _ 
+ _ / n } / * * 装载 用户 
评分 文件 * * / def loadRatings path String Seq 
Rating = { val lines = Source . fromFile path 
. getLines val ratings = lines . map { line 
= val fields = line . split Rating fields 0 
. toInt fields 1 . toInt fields 2 . toDouble 
} . filter _ . rating 0.0 if ratings . 
isEmpty { sys . error No ratings provided . } 
else { ratings . toSeq } } } 1 . 
3.5   IDEA 执行 情况 第一步     使用 如 
下命令 启动 Spark 集群 $ cd / app / hadoop 
/ spark 1 . 1.0 $ sbin / start all 
. sh 第二步     进行 用户 评分 生成 用户 
样本数据 由于 该 程序 中 最终 推荐 给 用户 十部 
电影 这 需要 用户 提供 对 样本 电影 数据 的 
评分 然后 根据 生成 的 最佳 模型 获取 当前 用户 
推荐 电影 用户 可以 使用 / home / hadoop / 
upload / class8 / movielens / bin / rateMovies 程序 
进行 评分 最终 生成 personalRatings . txt 文件 第三步   
  在 IDEA 中 设置 运行 环境 在 IDEA 运行 
配置 中 设置 MovieLensALS 运行 配置 需要 设置 输入 数据 
所在 文件夹 和 用户 的 评分 文件 路径 l   
输入 数据 所 在 目录 输入 数据 文件目录 在 该 
目录 中 包含 了 评分 信息 用户 信息 和 电影 
信息 这里 设置 为 / home / hadoop / upload 
/ class8 / movielens / data / l   用户 
的 评分 文件 路径 前一 步骤 中 用户 对 十部 
电影 评分 结果 文件 路径 在 这里 设置 为 / 
home / hadoop / upload / class8 / movielens / 
personalRatings . txt 第四步     执行 并 观察 输出 
l   输出 Got 1000209 ratings from 6040 users on 
3706 movies 表示 本 算法 中 计算 数据 包括 大概 
100万 评分 数据 6000多 用户 和 3706部 电影 l   
输出 Training 602252 validation 198919 test 199049 表示 对 评分 
数据 进行 拆分 为 训练 数据 校验 数据 和 测试数据 
大致 占 比为 6 2 2 l   在 计算 
过程 中 选择 8种 不同 模型 对 数据 进行 训练 
然后 从中/nr 选择 最佳 模型 其中 最佳 模型 比 基准 
模型 提供 22.30% RMSE validation = 0 . 8680885498009973 for 
the model trained with rank = 8 lambda = 0.1 
and numIter = 10 . RMSE validation = 0 . 
868882967482595 for the model trained with rank = 8 lambda 
= 0.1 and numIter = 20 . RMSE validation = 
3 . 7558695311242833 for the model trained with rank = 
8 lambda = 10.0 and numIter = 10 . RMSE 
validation = 3 . 7558695311242833 for the model trained with 
rank = 8 lambda = 10.0 and numIter = 20 
. RMSE validation = 0 . 8663942501841964 for the model 
trained with rank = 12 lambda = 0.1 and numIter 
= 10 . RMSE validation = 0 . 8674684744165418 for 
the model trained with rank = 12 lambda = 0.1 
and numIter = 20 . RMSE validation = 3 . 
7558695311242833 for the model trained with rank = 12 lambda 
= 10.0 and numIter = 10 . RMSE validation = 
3 . 7558695311242833 for the model trained with rank = 
12 lambda = 10.0 and numIter = 20 . The 
best model was trained with rank = 12 and lambda 
= 0.1 and numIter = 10 and its RMSE on 
the test set is 0 . 8652326018300565 . The best 
model improves the baseline by 22.30% . l   利用 
前面 获取 的 最佳 模型 结合 用户 提供 的 样本数据 
最终 推荐 给 用户 如下 影片 Movies recommended for you 
1 Bewegte Mann Der 1994 2 Chushingura 1962 3 Love 
Serenade 1996 4 For All Mankind 1989 5 Vie est 
belle La Life is Rosey 1987 6 Bandits 1997 7 
King of Masks The Bian Lian 1996 8 I m 
the One That I Want 2000 9 Big Trees The 
1952 10 First Love Last Rites 1997 2 参考资料 1 
Spark 官网 mlllib 说明   http / / spark . 
apache . org / docs / 1 . 1.0 / 
mllib guide . html 2 机器学习 常见 算法 分类汇总 http 
/ / www . ctocio . com / hotnews / 
15919 . html 