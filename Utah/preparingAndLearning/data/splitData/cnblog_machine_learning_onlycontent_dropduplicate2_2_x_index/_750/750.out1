矩阵 参考 机器学习 基础 一般而言 一个 对象 应该 被 视为 
完整 的 个体 表 现实 中 有 意义 的 事物 
不能 轻易 拆分 对象 是 被 特征 化 的 客观 
事物 而 表 或 矩阵 是 容纳 这些 对象 的 
容器 换句话说 对象 是 表中 的 元素 表 是 对象 
的 集合 表中/i 的/uj 每个/r 对象/n 都有/nr 相同/d 的/uj 特征/n 
和/c 维度/ns 对象/n 对于/p 每个/r 特征/n 都有/nr 一定/d 的/uj 取值/v 
分类 或 聚 类 可以 看作 根据 对象 特征 的 
相似性 与 差异性 对 矩阵 空间 的 一种 划分 预测 
或 回归 可以 看作 根据 对象 在 某种 序列 时间 
上 的 相关性 表现 为 特征 取值 变化 的 一种 
趋势 import numpy as npa = np . arange 9 
. reshape 3 1 aarray 0 1 2 3 4 
5 6 7 8 b = a . copy id 
a = = id b Falserepr a = = repr 
b TrueLinalgA = np . mat 1 2 4 5 
7 9 12 11 8 2 6 4 3 2 
1 9 1 3 4 5 0 2 3 4 
1 行列式 np . linalg . det A 812 . 
00000000000068 逆 np . linalg . inv A matrix 7.14285714 
e 02 1.23152709 e 02 5.29556650 e 02 9.60591133 e 
02 8.62068966 e 03 2.14285714 e 01 3.76847291 e 01 
1.22044335 e + 00 4.60591133 e 01 3.36206897 e 01 
2.14285714 e 01 8.25123153 e 01 2.04802956 e + 00 
5.64039409 e 01 9.22413793 e 01 5.11521867 e 17 4.13793103 
e 01 8.79310345 e 01 1.72413793 e 01 8.10344828 e 
01 2.14285714 e 01 6.65024631 e 02 1.85960591 e 01 
8.12807882 e 02 1.46551724 e 01 转置 A . Tmatrix 
1 9 6 9 0 2 12 4 1 2 
4 11 3 3 3 5 8 2 4 4 
7 2 1 5 1 A * A . Tmatrix 
95 131 43 78 43 131 414 153 168 91 
43 153 66 80 26 78 168 80 132 32 
43 91 26 32 30 秩 np . linalg . 
matrix _ rank A 5 解方程 \ Ax = b 
\ b = 1 0 1 0 1 S = 
np . linalg . solve A b Sarray 0.0270936 1.77093596 
3.18472906 1.68965517 0.25369458 现代 数学 三大 基石 概率论 说明 了 
事物 可能会 是 什么样 数值分析 揭示 了 它们 为什么 这样 
以及 如何 变成 这样 线性代数 告诉 我们 事物 从来 不 
只有 一个 样子 使 我们 能够 从 多个 角度 来 
观察 事物 相似性 度量 闵可夫 斯基 Minkowski 距离 对 应于 
\ | | \ cdot | | _ p \ 
即 \ begin { aligned } d = | | 
x _ 1 x _ 2 | | _ p 
& & x _ 1 x _ 2 \ in 
\ mathbb { R } ^ n \ end { 
aligned } 曼哈顿 距离 Manhattan \ p = 1 \ 
又 称为 城市 街区 距离 City Block distance 切比雪夫 Chebyshev 
距离 \ p = ∞ \ 可 用来 计算 象棋 
走 的 步数 . 比较 常见 是 范数 如 欧式 
距离 \ L _ 2 \ 曼哈顿 距离 \ L 
_ 1 \ 切比雪夫 距离 \ L _ { \ 
infty } \ 和 夹角 余弦 下面 我 主要 说明 
一下 其他 的 几个 比较 有意思 的 度量 汉明 距离 
Hamming 定义 两个 等长 字符串 s1 与 s2 之间 的 
汉明 距离 定义 为 将 其中 一个 变成 另外 一个 
所 需要 的 最小 替换 次数 对应 于 \ | 
| \ cdot | | _ 0 \ 应用 信息 
编码 为了 增强 容错性 应该 使得 编码 间 的 最小 
汉明 距离 尽可能 大 A = np . mat 1 
1 0 1 0 1 0 0 1 0 1 
1 0 0 0 1 1 1 smstr = np 
. nonzero A 0 A 1 A 0 A 1 
matrix 1 0 1 1 0 1 1 1 0 
smstr array 0 0 0 0 0 0 dtype = 
int64 array 0 2 3 5 6 7 dtype = 
int64 d = smstr 0 . shape 0 d6 杰 
卡德 相似系数 Jaccard Similarity Coefficient 相似 度 \ J A 
B = \ frac { | \ A \ bigcap 
B \ | } { | \ A \ bigcup 
B \ | } \ 杰 卡德 距离 Jaccard Distance 
区分度 \ J _ { \ delta } A B 
= 1 J A B = 1 \ frac { 
| \ A \ bigcap B \ | } { 
| \ A \ bigcup B \ | } \ 
应用 样本 \ A \ 和 样本 \ B \ 
所有 维度 的 取值 为 \ 0 \ 或 \ 
1 \ 表示 包含 某个 元素 与否 import scipy . 
spatial . distance as distAmatrix 1 1 0 1 0 
1 0 0 1 0 1 1 0 0 0 
1 1 1 dist . pdist A jaccard array 0.75 
蝴蝶效应 洛伦兹 动力学 方程 确定性/n 与/p 随机性/n 相/v 统一/vn 系统/n 
未来/t 的/uj 所有/b 运动/vn 都被/nr 限制/v 在/p 一个/m 明确/ad 的/uj 
范围/n 之内/f 确定性 运动轨迹 变化 缠绕 的 规则 是 随机性 
的 任何 时候 你 都 无法 准确 判定 下一次 运动 
的 轨迹 将 落在 「 蝴蝶 」 的 哪 侧 
翅膀 上 的 哪个 点上 随机性 总而言之 系统 运动 大 
的 范围 是 确定 的 可测 的 但是 运动 的 
细节 是 随机 的 不可测 的 从 统计学 角度 来看 
蝴蝶效应 说明了 样本 总体 特征向量 或 对象 的 取值 范围 
一般 是 确定 的 所有 样本 对象 包括 已经 存在 
的 和未/nr 出现 的 的 取值 都 位于 此 空间 
内 无论 收集 再多 的 样本 对象 也 不能 使 
这种 随机性 降低 或 消失 随机性 是 事物 的 一种 
根本 的 内在 的 无法 根除 的 性质 也是 一切事物 
概率 的 本质属性 衡量 事物 运动 的 随机性 必须 从 
整体 而 不是 局部 来 认知 事物 因为 从 每个 
局部 事物 可能 看 起来 都是/nr 不同 的 或 相同 
的 概率论 便是 度量 随机性 的 一个 工具 一般地 上述 
所说 的 矩阵 被 称为 设计 矩阵 基本概念 重写 样本 
样本点 原指 随机 试验 的 一个 结果 可以 理解 为 
设计 矩阵 中 的 一个 对象 如 苹果 小猪 等 
样本空间 原指 随机 试验 所 有可能 结果 的 集合 可以 
理解 为 矩阵 的 所有 对象 引申为 对象 特征 的 
取值 范围 \ 10 \ 个 苹果 \ 2 \ 
只 小猪 随机事件 原指 样本空间 的 一个 子集 可以 理解 
为 某个 分类 它 实际 指向 一种 概率分布 苹果 为 
红色 小猪 为 白色 随机变量 可以 理解 为 指向 某个 
事件 的 一个 变量 \ X \ { x _ 
i = \ text { 黄色 } \ } \ 
随机变量 的 概率分布 给定 随机变量 的 取值 范围 导致 某种 
随机事件 出现 的 可能性 可以 理解 为 符合 随机变量 取值 
范围 的 某个 对象 属于 某个 类别 或 服从 某种 
趋势 的 可能性 空间 变换 由 特征 列 的 取值 
所 构成 的 矩阵 空间 应 具有 完整性 即 能够 
反映 事物 的 空间 形式 或 变换 规律 向量 具有 
大小 和 方向 向量 与 矩阵 的 乘积 就是 一个 
向量 从 一个 线性空间 坐标系 通过 线性变换 选取 一个 新的 
基底 变换 到 这个 新的 基底 所 构成 的 另一个 
线性空间 的 过程 矩阵 与 矩阵 的 乘法 \ C 
= A \ cdot B \ \ A \ 向量 
组 \ B \ 线性变换 下 的 矩阵 假设 我们 
考察 一组 对象 \ \ scr { A } = 
\ { \ alpha _ 1 \ cdots \ alpha 
_ m \ } \ 它们 在 两个 不同 维度 
的 空间 \ V ^ n \ 和 \ V 
^ p \ 的 基底 分别 是 \ \ { 
\ vec { e _ 1 } \ cdots \ 
vec { e _ n } \ } \ 和 
\ \ { \ vec { d _ 1 } 
\ cdots \ vec { d _ p } \ 
} \ \ T \ 即为 \ V ^ n 
\ 到 \ V ^ p \ 的 线性变换 且有 
\ k = \ { 1 \ cdots m \ 
} \ \ \ begin { align } & T 
\ begin { pmatrix } \ begin { bmatrix } 
\ vec { e _ 1 } \ \ \ 
vdots \ \ \ vec { e _ n } 
\ end { bmatrix } \ end { pmatrix } 
= A \ begin { bmatrix } \ vec { 
d _ 1 } \ \ \ vdots \ \ 
\ vec { d _ p } \ end { 
bmatrix } \ \ & \ alpha _ k = 
\ begin { bmatrix } x _ 1 ^ { 
k } & \ cdots & x _ n ^ 
k \ end { bmatrix } \ begin { bmatrix 
} \ vec { e _ 1 } \ \ 
\ vdots \ \ \ vec { e _ n 
} \ end { bmatrix } \ \ & T 
\ alpha _ k = \ begin { bmatrix } 
y _ 1 ^ { k } & \ cdots 
& y _ p ^ k \ end { bmatrix 
} \ begin { bmatrix } \ vec { d 
_ 1 } \ \ \ vdots \ \ \ 
vec { d _ p } \ end { bmatrix 
} \ end { align } \ 令 \ \ 
begin { cases } & X ^ k = \ 
begin { bmatrix } x _ 1 ^ { k 
} & \ cdots & x _ n ^ k 
\ end { bmatrix } \ \ & Y ^ 
k = \ begin { bmatrix } y _ 1 
^ { k } & \ cdots & y _ 
p ^ k \ end { bmatrix } \ end 
{ cases } \ 则 记 \ \ begin { 
cases } & X = \ begin { bmatrix } 
X ^ { 1 } \ \ \ vdots \ 
\ X ^ m \ end { bmatrix } \ 
\ & Y = \ begin { bmatrix } Y 
^ { 1 } \ \ \ vdots \ \ 
Y ^ m \ end { bmatrix } \ end 
{ cases } \ 由 式 1 可知 \ \ 
begin { align } XA = Y \ end { 
align } \ 因而 \ X \ 与 \ Y 
\ 表示 一组 对象 在 不同 的 线性 空间 的 
坐标 表示 \ A \ 表示 线性变换 在 某个 基 
偶 如 \ \ { \ vec { e _ 
1 } \ cdots \ vec { e _ n 
} \ } \ { \ vec { d _ 
1 } \ cdots \ vec { d _ p 
} \ } \ 下 的 矩阵 表示 使用 Numpy 
求解 矩阵 的 特征值 和 特征向量 \ A = \ 
lambda v \ A = 8 7 6 3 5 
7 4 9 1 evals evecs = np . linalg 
. eig A print 特征值 \ n % s \ 
n 特征向量 \ n % s % evals evecs 特征值 
16.43231925 2.84713925 5.2794585 特征向量 0.73717284 0.86836047 0.09167612 0.48286213 0.4348687 0.54207062 
0.47267364 0.23840995 0.83531726 有了 特征值 和 特征向量 我们 便 可以 
还原 矩阵 \ A = Q \ Sigma Q ^ 
{ 1 } \ sigma = evals * np . 
eye 3 sigmaarray 16.43231925 0 . 0 . 0 . 
2.84713925 0 . 0 . 0 . 5.2794585 或者 利用 
np . diag np . diag evals array 16.43231925 0 
. 0 . 0 . 2.84713925 0 . 0 . 
0 . 5.2794585 np . dot np . dot evecs 
sigma np . linalg . inv evecs array 8 . 
7 . 6 . 3 . 5 . 7 . 
4 . 9 . 1 . 我 的 学习 笔记 
ML 基础 我 的 Github https / / github . 
com / q735613050 / AI / tree / master / 
ML 关于 矩阵 的 一个 不 成熟 的 解释 机器学习 
中的 矩阵 