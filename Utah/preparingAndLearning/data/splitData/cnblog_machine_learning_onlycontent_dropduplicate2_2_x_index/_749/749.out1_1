知道 某个 算法 和 运用 一个 算法 是 两码事 儿 
当 你 训 练出 数据 后 发觉 模型 有 太大 
误差 怎么办 1 获取 更多 的 数据 也许有 用吧 2 
减少 特征 维度 你 可以 自己 手动 选择 也 可以 
利用 诸如 PCA 等 数学方法 3 获取 更多 的 特征 
当然 这个 方法 很 耗时 而且 不 一定 有用 4 
添加 多项式 特征 你 在 抓 救命稻草 么 5 构建 
属于 你 自己 的 新的 更好 的 特征 有点儿 冒险 
6 调整 正则化 参数 lambuda 以上 方法 的 尝试 有些 
碰运气 搞 不好 就是 浪费 大 把 时间 machine learning 
diagonostic . 机器学习 诊断 检查 正确性 提升 效率 节省 调试 
时间 一 评估 假设 loss 越小 不 代表 模型 越好 
有 可能 出现 过拟合 的 现象 正确 的 方法 是 
将 数据 分割 为 训练 集 和 测试 集 利用 
训练 集 训练 数据 测试 集 进行 测试 求出 测试 
集 误差 test set error 二 模型 选择 与 训练 
验证 测试 集 如何 选择 正则化 参数 和 多项式 次数 
模型 选择 尝试 不同 的 正则化 参数 和 多项式 次数 
选择 在 测试 集上 损失 最小 的 model 这 似乎 
可行 但 都是 针对 测试 集 计算 无法 验证 泛化 
能力 解决 的 方法 就是 划分 出 三个 集合 训练 
集 验证 集 和 测试 集 利用 验证 集 选择 
最佳 的 参数 模型 之后 再 在 测试 集上 计算 
泛化 损失 三 模型 诊断 bias vs variance 过拟合 和欠/nr 
拟合 的 判断 方法 绘制 曲线 当 d 过小 有 
可能 是 欠 拟合 当 d 过大 有 可能 是 
过拟合 对于 欠 拟合 而言 验证 集 和 训练 集 
的 loss 均 非常大 对于 过拟合 而言 训练 集 的 
loss 很小 而 验证 集 的 loss 很大 四 正则化 
参数 对 欠 拟合 过拟合 的 平衡 lambuda 很大 的话 
容易 欠 拟合 过小 则 容易 过拟合 如何 选择 设置 
一个 正则化 参数 的 选择 范围 在 验证 集上 计算 
每一个 值 所 对应 的 loss 的 大小 选择 最小 
的 那个 五 学习曲线 high bias Jcv 和 Jtrain 在 
m 很大 的 情况 下 都 很高 此时 增加 样本数 
将 没有 效果 因为 模型 本身 出了 问题 可能 的 
问题 是 模型 过于 简单 high variance Jcv 和 Jtrain 
之间 间隔 很大 此时 增加/v 训练/vn 样本数/n 有/v 可能会/i 有/v 
很好/i 的/uj 效果/n 六 总结 1 获取 更多 样本 解决 
过拟合 欠 拟合 则 不行 2 更小 的 特征 集 
同上 3 添加 其他 特征 解决 欠 拟合 4 添加 
多项式 解决 欠 拟合 5 减小 lambuda 解决 欠 拟合 
6 增大 Lambuda 解决 过拟合 