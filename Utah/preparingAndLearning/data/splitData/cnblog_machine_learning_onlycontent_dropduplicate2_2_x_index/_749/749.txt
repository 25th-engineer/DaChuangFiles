知道某个算法，和运用一个算法是两码事儿。
当你训练出数据后，发觉模型有太大误差，怎么办？
1）获取更多的数据。也许有用吧。
2）减少特征维度。你可以自己手动选择，也可以利用诸如PCA等数学方法。
3）获取更多的特征。当然这个方法很耗时，而且不一定有用。
4）添加多项式特征。你在抓救命稻草么？
5）构建属于你自己的，新的，更好的特征。有点儿冒险。
6）调整正则化参数lambuda。
以上方法的尝试有些碰运气，搞不好就是浪费大把时间。
machine learning diagonostic. 机器学习诊断。检查正确性，提升效率，节省调试时间。
一，评估假设
loss越小，不代表模型越好，有可能出现过拟合的现象。
正确的方法是：将数据分割为训练集和测试集。利用训练集训练数据，测试集进行测试求出测试集误差（test set error）
二，模型选择与训练验证测试集
如何选择正则化参数和多项式次数（模型选择）
尝试不同的正则化参数和多项式次数，选择在测试集上损失最小的model。这似乎可行，但都是针对测试集计算，无法验证泛化能力。
解决的方法就是划分出三个集合：训练集，验证集，和测试集。
利用验证集选择最佳的参数模型，之后再在测试集上计算泛化损失。
三，模型诊断：bias vs variance
过拟合和欠拟合的判断方法
绘制曲线
当d过小，有可能是欠拟合
当d过大，有可能是过拟合
对于欠拟合而言，验证集和训练集的loss均非常大
对于过拟合而言，训练集的loss很小，而验证集的loss很大。
四，正则化参数对欠拟合过拟合的平衡
lambuda很大的话，容易欠拟合，过小则容易过拟合。
如何选择？
设置一个正则化参数的选择范围，在验证集上计算每一个值所对应的loss的大小，选择最小的那个。
五，学习曲线
high bias:
Jcv和Jtrain在m很大的情况下，都很高。
此时，增加样本数将没有效果。因为模型本身出了问题。可能的问题是模型过于简单。
high variance:
Jcv和Jtrain之间间隔很大。
此时，增加训练样本数有可能会有很好的效果。
六、总结
1）获取更多样本：解决过拟合。欠拟合则不行。
2）更小的特征集：同上。
3）添加其他特征：解决欠拟合
4）添加多项式：解决欠拟合
5）减小lambuda: 解决欠拟合
6）增大Lambuda：解决过拟合