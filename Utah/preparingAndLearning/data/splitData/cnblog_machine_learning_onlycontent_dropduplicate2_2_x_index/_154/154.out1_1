机器学习 课程 使用 Kevin P . Murphy 图书 Machine Learning 
A Probabilistic Perspective 本 英语教材 本书 从 一个 独特 的 
数学 概率论 的 角度 解释 机器学习 的 所有 问题 要 
较强 的 数学 基础 由于 是 英文 教材 特 开 
一个 专题 在此 记录 自己 的 学习 过程 和 各种 
问题 以供 备忘 和 举一反三 之用 在 解说 了 机器 
学习 的 概述 之后 第二章 紧接着 就 開始 讲述 概率论 
的 知识 通过 兴许 的 学习 会 发现 这些 概率论 
知识 有 部分 在 本科 的 概率论 课程 中 学习 
过 可是 有 非常 多 其它 部分 是 没有 在 
现有 的 本科 阶段 甚至 研究生 阶段 也 非常 少 
涉及 的 知识点 在此 做 一个 总结 1 概率 学派 
频率 学派 概率 代表 的 是 对 一个 试验 反复 
运行 N 次 所 关注 的 事件 发生 的 频率 
这里 要求 的 是 须要 进行 反复 试验 这 对于 
一般 可 反复 运行 的 试验 是 比 較 好 
的 标识 方式 这 也 成为 实验 概率 贝叶斯 学派 
概率 代表 的 是 人们 对 一个 未知事件 发生 的 
不确定性 的 一种 表征 这里 不 要求 对 这个 事件 
进行 反复 试验 同一 时候 对于 不论什么 未知 的 事件 
都 能够 用 一个 概率 来 表征 人们 对 它 
的 认识 通过 上述 比 較 能够 发现 对于 某些 
不能 反复 试验 的 事件 比方 生成 灯管 的 工厂 
生成 的 灯管 的 平均 使用寿命 进行 反复 实验 是 
不 现实 的 使用 贝叶斯 概率 的 解释 更加 合理 
因此 在 整个 学习 中 都以 贝叶斯 学派 为准 2 
基本知识 概率 事件 空间 Ω 到 实 数域 R 的 
映射 对于 每 一个 事件 A 都 有一个 实数 p 
A 与之 相应 同一 时候 满足 1 非 负性 p 
A = 0 2 规范性 p Ω = 1 3 
可 列 可加 性 p A1 + A2 + An 
= p A1 + p A2 + p An 当中 
A1 A2 An 都是 互补 相容 的 事件 基本 概率 
公式 全/a 概率/n 公式/n 和/c 贝叶斯/nr 公式/n 通用 的 贝叶斯 
分类器 θ 为 模型 的 參 数 3 离散 型 
分布 1 二项分布 BinomialK 为 每次 试验 可能 出现 的 
结果 n 为 进行 试验 的 次数 贝努利 试验 就是 
K = { 0 1 } 且 n = 1 
的 试验 对于 n n 1 的 n 重 贝努利 
实验 就是 二项分布 分布 函数 例如 以下 mean = θ 
variance = n θ 1 θ 二项分布 描写 叙述 的 
典型 试验 就是 抛 硬币 每次 出现 正面 或者 反面 
两种 结果 这在 机器 学习 的 分类 算法 中 用于 
描写 叙述 二 值 的 特征 也 就是 每 一个 
数据 的 特征 的 取值 是 两个 状态 通常 是 
0 和1/nr 用来 表征 当前 数据 是否 有 这个 特征 
因此 能够 使用 二项分布 来 描写 叙述 当前 特征 的 
分布 2 多项 分布 Multinormial 当 每次 试验 出现 的 
结果 可能 有K/nr K 2 种 时 也 就是 一个 
特征 的 不 不过 表征 是否 出现 而是 须要 用 
一个 详细 数值 来 表征 该 特征 的 影响 大小 
此时 能够 用 多项 分布 进行 描写 叙述 此处 当 
K = 2时 也就是 两种 状态 能够 看出 多项 分布 
就 退化 到了 二项分布 能够 看出 x1 = k x2 
= n k x1 + x2 = n 条件 满足 
当中 当 n = 1时 也 就是 仅仅 进行 一次 
试验 此时 的 分布 称为 多维 贝努利 分布 由于 每次 
的 可能 状态 有K/nr K 2 个 也 成为 离散 
分布 discrete distribution 或者 分类 分布 categorical distribution 记为 Cat 
x | θ 3 泊松分布 Poisson 变量 X = { 
0 1 2 . . . . . } λ 
0 分布 例如 以下 泊松分布 能够 用来 模拟 以 时间 
序列 发送 的 事件 具有 无 记忆性 4 连续型 分布 
1 正态分布 Gaussian Normal mean = u mode = u 
variance = σ ^ 2 在 统计学 中 应用 很 
广泛 首先 两个 參 数 很好 理解 各 自是 均值 
和 标准差 同一 时候 中心 极限 定理 得到 相互 独立 
的 随机 变量 的 和的/nr 分布 近 似为 高斯分布 能够 
用来 模拟 噪声 数据 第三 高斯分布 使用 了 最小 的 
如果 也 就是 拥有 最大熵 第四 数学 形式 相对 简单 
很 利于 实现 2 Student t 分布 mean = u 
mode = u variance = ν σ ^ 2 / 
ν 2 ν 0 为 自由度 方差 在 ν 2 
时有 定义 均值 在 ν 1 时有 定义 此 分布 
形式 上 与 高斯分布 类似 弥补 了 高斯分布 的 一个 
不足 就是 高斯分布 对 离群 的 数据 非常 敏感 可是 
Student t 分布 更 鲁棒 一般 设置 ν = 4 
在 大多数 实际 问题 中 都有 非常好 的 性能 当 
ν 大于 等于 5时 将会 是 去 鲁棒性 同一 时候 
会 迅速 收敛 到 高斯分布 特别 的 当 ν = 
1时 被 称为 柯西分布 Cauchy 3 拉普拉斯 分布 Laplacemean = 
u mode = u variance = 2b ^ 2 也 
被 称为 双側/nr 指数分布 引出 了 绝对值 的 指数 次方 
因此在 x = u 处 不可导 b b 0 为 
缩放 因子 用来 调节 数据 的 分散 程度 拉普拉斯 分布 
对 离群 数据 的 鲁棒性 更好 同一 时候 在 x 
= u 处 给予 了 比 高斯分布 更大 的 概率密度 
这个 性质 能够 用来 修正 模型 中 稀疏 的 数据 
4 Gamma 分布 mean = a / b mode = 
a 1 / b variance = a / b ^ 
2 mean 在 a 1 时有 定义 variance 在 a 
2 时有 定义 当中 变量 T 的 范围 为 T 
0 a 0 称为 形状 參 数 b 0 称为 
速率 參 数 Exponential 分布 a = 1 b = 
λ 时 Expon x | λ = Ga x | 
1 λ 这个 分布 描写 叙述 了 连续 的 泊松过程 
与 离散 型 的 泊松分布 共轭 ErLang 分布 ErLang x 
| λ = Ga x | 2 λ Chi Squared 
分布 卡方 分布 ChiSq x | v = Ga x 
| v / 2 1/2 这是 N 个 高斯分布 的 
随机 变量 的 平方和 所 服从 的 分布 当 使用 
1 / x 取代 Gamma 分布 中的 变量 时 得到 
的 是 反 Gamma 分布 即 mean = b / 
a 1 mode = b / a + 1 variance 
= b ^ 2 / a 1 ^ 2 a 
2 当中 mean 在 a 1时 定义 variance 在 a 
2时 定义 5 Beta 分布 定义 在 0 1 区间 
上 要求 a 0 b 0 当 a = b 
= 1时 就是 0 1 上 的 均匀分布 mean = 
a / a + b mode = a 1 / 
a + b 2 variance = ab / a + 
b ^ 2 a + b + 1 这个 分布 
与 离散 的 二项分布 是 共轭 的 在 朴素 贝叶斯 
分类 应用 中 当 似 然 分布 为 二项分布 时 
选择 Beta 分布 为 共轭 先验 分布 则 后验/nr 分布 
也为 Beta 分布 很 便于 实际 操作 和 计算 6 
Pareto 分布 mean = km / k 1 k 1 
mode = m variance = mk ^ 2 / k 
1 ^ 2 k 2 k 2 这个 分布相 应有 
一个 Zipf s 定律 用来 描写 叙述 单词 的 排名 
和其/nr 出现 的 频率 的 关系 x 必须 比 一个 
常数 m 要 大 可是 不能超过 k 当 k 为 
无穷大 时 这个 分布 会 趋于 δ x m 上述 
分布 在 信息检索 中 对 索引 构建 中的 词频 预计 
非常 有效 7 狄利克雷 分布 Dirichletmean Xk = ak / 
a0 mode Xk = ak 1 / a0 K variance 
Xk = ak a0 ak / a0 ^ 2 a0 
+ 1 这是 beta 分布 在 多维 条件下 的 分布 
相应/v 的/uj 參/zg 数/n 和/c 变量/vn 都是/nr 一个/m 向量/n 这个 
分布 与 离散 的 多项 分布 时 共轭 的 在 
朴素 贝叶斯 分类 应用 中 似 然 使用 多项 分布 
时 选择 Dirichlet 分布 为 先验 分布 得到 后验/nr 分布 
也为 Dirichlet 分布 以上 对 机器 学习 中 使用 做一个 
概率分布 汇总 也许 在 时间 的 学习 笔记 和 复习 
版权 声明 本文 博主 原创 文章 博客 未经 同意 不得 
转载 