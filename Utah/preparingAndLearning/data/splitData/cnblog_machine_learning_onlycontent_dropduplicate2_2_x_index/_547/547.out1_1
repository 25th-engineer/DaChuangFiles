摘要 数据挖掘 机器 学习 和 推荐 系统 中 的 评测 
指标 准确率 Precision 召回率 Recall F 值 F Measure 简介 
引言 在 机器学习 数据挖掘 推荐 系统 完成 建模 之后 需要 
对 模型 的 效果 做 评价 业内 目前 常常 采用 
的 评价 指标 有 准确率 Precision 召回率 Recall F 值 
F Measure 等 下图 是 不同 机器学习 算法 的 评价 
指标 下文 讲对 其中 某些 指标 做 简要介绍 本文 针对 
二元 分类器 本文 针对 二元 分类器 本文 针对 二元 分类器 
对 分类 的 分类器 的 评价 指标 将 在 以后 
文章 中 介绍 在 介绍 指标 前 必须 先 了解 
混淆 矩阵 混淆 矩阵 True Positive 真正 TP 将 正 
类 预测 为 正 类 数 True Negative 真 负 
TN 将 负 类 预测 为 负 类 数 False 
Positive 假 正 FP 将 负 类 预测 为 正 
类 数 误报 Type I error False Negative 假 负 
FN 将 正 类 预测 为 负 类 数 → 
漏报 Type II error 1 准确率 Accuracy 准确率 accuracy 计算公式 
为 注 准确率 是 我们 最 常见 的 评价 指标 
而且 很容易 理解 就是 被 分对 的 样本 数 除以 
所有 的 样本 数 通常 来说 正确率 越高 分类器 越好 
准确率 确实 是 一个 很好 很 直观 的 评价 指标 
但是 有时候 准确率 高并/nr 不能 代表 一个 算法 就好 比如 
某个 地区 某天 地震 的 预测 假设 我们 有 一堆 
的 特征 作为 地震 分类 的 属性 类别 只有 两个 
0 不 发生 地震 1 发生 地震 一个 不加 思考 
的 分类器 对 每一个 测试用例 都将 类别 划分 为 0 
那 那么 它 就 可能 达到 99% 的 准确率 但 
真的 地震 来临 时 这个 分类器 毫无 察觉 这个 分类 
带来 的 损失 是 巨大 的 为什么 99% 的 准确率 
的 分类器 却 不是 我们 想要 的 因为 这里 数据分布 
不均衡 类别 1 的 数据 太少 完全 错分 类别 1 
依然 可以 达到 很高 的 准确率 却 忽视 了 我们 
关注 的 东西 再举 个 例子 说明 下 在 正负 
样本 不 平衡 的 情况 下 准确率 这个 评价 指标 
有 很大 的 缺陷 比如 在 互联网 广告 里面 点击 
的 数量 是 很少 的 一般 只有 千分之几 如果 用 
acc 即使 全部 预测 成负类/nr 不 点击 acc 也有 99% 
以上 没有意义 因此 单纯 靠 准确率 来 评价 一个 算法 
模型 是 远远 不够 科学 全面的 2 错误率 Error rate 
错误率 则 与 准确率 相反 描述 被 分类器 错分 的 
比例 error rate = FP + FN / TP + 
TN + FP + FN 对 某 一个 实例 来说 
分对 与 分 错 是 互斥事件 所以 accuracy = 1 
error rate 3 灵敏度 sensitive sensitive = TP / P 
表示 的 是 所有 正 例 中被 分对 的 比例 
衡 量了 分类器 对正 例 的 识别 能力 4 特 
效度 sensitive specificity = TN / N 表示 的 是 
所有 负 例 中被 分对 的 比例 衡 量了 分类器 
对 负 例 的 识别 能力 5 精确 率 精度 
Precision 精确 率 precision 定义 为 表示 被 分为 正 
例 的 示例 中 实际 为 正 例 的 比例 
6 召回率 recall 召回率 是 覆盖面 的 度量 度量 有 
多个 正 例 被 分为 正 例 recall = TP 
/ TP + FN = TP / P = sensitive 
可以 看到 召回率 与 灵敏度 是 一样 的 7 综合 
评价 指标 F Measure P 和R/nr 指标 有时候 会 出现 
的 矛盾 的 情况 这样 就 需要 综合 考虑 他们 
最 常见 的 方法 就是 F Measure 又 称为 F 
Score F Measure 是 Precision 和 Recall 加权 调和 平均 
当 参数 α = 1时 就是 最 常见 的 F1 
也即 可知 F1 综合 了 P 和R的/nr 结果 当 F1 
较高 时 则能 说明 试验 方法 比较 有效 8 其他 
评价 指标 计算速度 分类器 训练 和 预测 需要 的 时间 
鲁棒性 处理 缺失 值 和 异常值 的 能力 可扩展性 处理 
大 数据集 的 能力 可 解释性 分类器 的 预测 标准 
的 可理解 性 像 决策树 产生 的 规则 就是 很 
容易 理解 的 而 神经 网络 的 一堆 参数 就 
不好 理解 我们 只好 把 它 看成 一个 黑盒子 下面 
来 看一下 ROC 和 PR 曲线 以下 内容 为 自己 
总结 1 ROC 曲线 ROC Receiver Operating Characteristic 曲线 是以 
假 正 率 FP _ rate 和假负/nr 率 TP _ 
rate 为 轴 的 曲线 ROC 曲线 下面 的 面积 
我们 叫做 AUC 如下 图 所示 图片 根据 Paper Learning 
from eImbalanced Data 画出 其中 1 曲线 与 FP _ 
rate 轴 围成 的 面积 记作 AUC 越大 说明 性能 
越好 即 图上 L2 曲线 对应 的 性能 优于 曲线 
L1 对应 的 性能 即 曲线 越 靠近 A 点 
左上方 性能 越好 曲线 越 靠近 B 点 右下方 曲线 
性能 越差 2 A 点 是 最 完美 的 performance 
点 B 处 是 性能 最 差点 3 位于 C 
D 线上 的 点 说明 算法 性能 和 random 猜测 
是 一样 的 – 如 C D E 点 位于 
C D 之上 即 曲线 位于 白色 的 三角形 内 
说明 算法 性能 优于 随机 猜测 – 如 G 点 
位于 C D 之下 即 曲线 位于 灰色 的 三角形 
内 说明 算法 性能 差 于 随机 猜测 – 如 
F 点 4 虽然/c ROC/w 曲线/n 相比较/i 于/p Precision/w 和/c 
Recall/w 等/u 衡量/v 指标/n 更加/d 合理/vn 但是 其 在 高 
不平衡 数据 条件 下 的 的 表现 仍然 过于 理想 
不 能够 很好 的 展示 实际 情况 2 PR 曲线 
即 PR Precision Recall 曲线 举个 例子 例子 来自 Paper 
Learning from eImbalanced Data 假设 N _ c P _ 
c 即 Negative 的 数量 远远 大于 Positive 的 数量 
若 FP 很大 即 有 很多 N 的 sample 被 
预测 为 P 因为 因此 FP _ rate 的 值 
仍然 很小 如果 利用 ROC 曲线 则会 判断 其 性能 
很好 但是 实际上 其 性能 并 不好 但是 如果 利用 
PR 因为 Precision 综合 考虑 了 TP 和 FP 的 
值 因此 在 极度 不 平衡 的 数据 下 Positive 
的 样本 较少 PR 曲线 可能 比 ROC 曲线 更 
实用 转载自 机器学习 算法 中的 准确率 Precision 召回率 Recall F 
值 F Measure 是 怎么 一回 事 