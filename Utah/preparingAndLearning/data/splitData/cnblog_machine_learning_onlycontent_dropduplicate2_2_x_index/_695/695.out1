注 代价 函数 有的 地方 也叫 损失 函数 Loss Function 
在 机器 学习 中 的 每一种 算法 中都 很重要 因为 
训练 模型 的 过程 就是 优化 代价 函数 的 过程 
代价 函数 对 每个 参数 的 偏 导数 就是 梯度 
下降 中 提到 的 梯度 防止 过 拟 合时 添加 
的 正则化 项 也是 加在 代价 函数 后面 的 在 
学习 相关 算法 的 过程 中 对 代价 函数 的 
理解 也 在 不断 的 加深 在此 做 一个 小 
结 1 . 什么 是 代价 函数 假设有 训练样本 x 
y 模型 为 h 参数 为 θ h θ = 
  θ Tx θ T 表示 θ 的 转置 1 
概况 来讲 任何 能够 衡量 模型 预测 出来 的 值 
h θ 与 真实 值 y 之间 的 差异 的 
函数 都 可以 叫做 代价 函数 C θ 如果 有 
多个 样本 则 可以 将 所有 代价 函数 的 取值 
求 均值 记 做 J θ 因此 很 容易 就 
可以 得出 以下 关于 代价 函数 的 性质 对于 每种 
算法 来说 代价 函数 不是 唯一 的 代价 函数 是 
参数 θ 的 函数 总 的 代价 函数 J θ 
可以 用来 评价 模型 的 好坏 代价/n 函数/n 越小/i 说明/v 
模型/n 和/c 参数/n 越/d 符合/v 训练样本/n x y J θ 
是 一个 标量 2 当 我们 确定 了 模型 h 
后面 做 的 所有 事情 就是 训练 模型 的 参数 
θ 那么 什么 时候 模型 的 训练 才能 结束 呢 
这时候 也 涉及 到 代价 函数 由于 代价 函数 是 
用来 衡量 模型 好坏 的 我们 的 目标 当然 是 
得到 最好 的 模型 也 就是 最 符合 训练样本 x 
y 的 模型 因此 训练 参数 的 过程 就是 不断 
改变 θ 从而 得到 更小 的 J θ 的 过程 
理想 情况下 当 我们 取到 代价 函数 J 的 最小值 
时 就 得到 了 最优 的 参数 θ 记为 $ 
$ \ displaystyle \ min _ { \ theta } 
J \ theta $ $ 例如 J θ = 0 
表示 我们 的 模型 完美 的 拟合 了 观察 的 
数据 没有 任何 误差 3 在 优化 参数 θ 的 
过程 中 最 常用 的 方法 是 梯度 下降 这里 
的 梯度 就是 代价 函数 J θ 对 θ 1 
θ 2 . . . θ n 的 偏 导数 
由于 需 要求 偏 导 我们 可以 得到 另 一个 
关于 代价 函数 的 性质 选择 代价 函数 时 最好 
挑选 对 参数 θ 可微 的 函数 全 微分 存在 
偏 导数 一定 存在 2 . 代价 函数 的 常见 
形式 经过 上面 的 描述 一个 好 的 代价 函数 
需要 满足 两个 最 基本 的 要求 能够 评价 模型 
的 准确性 对 参数 θ 可微 2.1 均方 误差 在 
线性 回 归中 最 常用 的 是 均方 误差 Mean 
squared error 具体 形式 为 $ $ J \ theta 
_ 0 \ theta _ 1 = \ frac { 
1 } { 2m } \ displaystyle \ sum _ 
{ i = 1 } ^ { m } \ 
hat { y } ^ { i } y ^ 
{ i } ^ 2 = \ frac { 1 
} { 2m }   \ displaystyle \ sum _ 
{ i = 1 } ^ { m } h 
_ \ theta x ^ { i } y ^ 
{ i } ^ 2   $ $ m 训练样本 
的 个数 h θ x 用 参数 θ 和x/nr 预测 
出来 的 y 值 y 原 训练样本 中的 y 值 
也 就是 标准 答案 上 角标 i 第 i 个 
样本 2.2 交叉 熵 在 逻辑 回 归中 最 常用 
的 是 代价 函数 是 交叉 熵 Cross Entropy 交叉 
熵 是 一个 常见 的 代价 函数 在 神经 网络 
中 也会 用到 下面 是 神经 网络 与 深度 学习 
一 书 对 交叉 熵 的 解释 交叉 熵 是 
对 「 出乎意料 」 译者 注 原文 使用 suprise 的 
度量 神经元 的 目标 是 去 计算 函数 y 且 
y = y x 但是 我们 让 它 取而代之 计算 
函数 a 且 a = a x 假设 我们 把 
a 当作 y 等于 1 的 概率 1 − a 
是 y 等于 0 的 概率 那么 交叉 熵 衡量 
的 是 我们 在 知道 y 的 真实 值 时的/nr 
平均 「 出乎意料 」 程度 当 输出 是 我们 期望 
的 值 我们 的 「 出乎意料 」 程度 比较 低 
当 输出 不 是 我们 期望 的 我们 的 「 
出乎意料 」 程度 就 比较 高 在 1948年 克劳德 艾尔 
伍德 香农 将 热力学 的 熵 引入 到 信息论 因此 
它 又 被称为 香农 熵 Shannon Entropy 它 是 香农 
信息量 Shannon Information Content SIC 的 期望 香农 信息量 用来 
度量 不确定性 的 大小 一个 事件 的 香农 信息量 等于 
0 表示 该 事件 的 发生 不会 给 我们 提供 
任何 新 的 信息 例如 确定性 的 事件 发生 的 
概率 是 1 发生 了 也 不会 引起 任何 惊讶 
当 不 可能 事件 发生 时 香农 信息量 为 无穷大 
这 表示 给 我们 提供 了 无穷 多 的 新 
信息 并且 使 我们 无限 的 惊讶 更多 解释 可以 
看 这里 $ $ J \ theta = \ frac 
{ 1 } { m } \ sum _ { 
i = 1 } ^ { m } { y 
^ { i } \ log h _ \ theta 
x ^ { i } + 1 y ^ { 
i } \ log 1 h _ \ theta x 
^ { i } } $ $ 符号 说明 同上 
2.3 神经 网络 中 的 代价 函数 学习 过 神经 
网络 后 发现 逻辑 回归 其实 是 神经 网络 的 
一种 特例 没有 隐藏 层 的 神经 网络 因此 神经 
网络 中 的 代价 函数 与 逻辑 回归 中的 代价 
函数 非常 相似 $ $ J \ theta = \ 
frac { 1 } { m } \ sum _ 
{ i = 1 } ^ { m } \ 
sum _ { k = 1 } ^ { K 
}   { y _ k ^ { i } 
\ log h _ \ theta x ^ { i 
} + 1 y _ k ^ { i } 
\ log 1 h _ \ theta x ^ { 
i } _ k } $ $ 这里 之所以 多了 
一层 求和 项 是 因为 神经 网络 的 输出 一般 
都 不是 单一 的 值 K 表示 在 多 分类 
中的 类型 数 例如 在 数字 识别 中 K = 
10 表示 分了 10类 此时 对于 某一个 样本 来说 输出 
的 结果 如下 1.1266 e 004 1.7413 e 003 2.5270 
e 003 1.8403 e 005 9.3626 e 003 3.9927 e 
003 5.5152 e 003 4.0147 e 004 6.4807 e 003 
9.9573 e 001 一个 10 维 的 列 向量 预测 
的 结果 表示 输入 的 数字 是 0 ~ 9中 
的 某一个 的 概率 概率 最大 的 就被 当做 是 
预测 结果 例如 上面 的 预测 结果 是 9 理想 
情况下 的 预测 结果 应该 如下 9 的 概率 是 
1 其他 都是 0 0 0 0 0 0 0 
0 0 0 1 比较 预测 结果 和 理想 情况下 
的 结果 可以 看到 这 两个 向量 的 对应 元素 
之间 都 存在 差异 共有 10组 这里 的 10 就 
表示 代价 函 数里 的 K 相当于 把 每一种 类型 
的 差异 都 累加 起来 了 3 . 代价 函数 
与 参数 代价 函数 衡量 的 是 模型 预测值 h 
θ 与 标准 答案 y 之间 的 差异 所以 总 
的 代价 函数 J 是 h θ 和y的/nr 函数 即 
J = f h θ y 又 因为 y 都是 
训练样本 中 给定 的 h θ 由 θ 决定 所以 
最终 还是 模型 参数 θ 的 改变 导致 了 J 
的 改变 对于 不同 的 θ 对应 不同 的 预测 
值 h θ 也就 对应 着 不同 的 代价 函数 
J 的 取值 变化 过程 为 $ $ \ theta 
h \ theta J \ theta $ $ θ 引起 
了 h θ 的 改变 进而 改变 了 J θ 
的 取值 为了 更 直观 的 看到 参数 对 代价 
函数 的 影响 举个 简单 的 例子 有 训练样本 { 
0 0 1 1 2 2 4 4 } 即 
4对 训练样本 每个 样本 对 中 第 1 个数 表示 
x 的 值 第 2 个数 表示 y 的 值 
这 几个 点 很明显 都是 y = x 这条 直线 
上 的 点 如 下图 不 同参数 可以 拟合 出 
不同 的 直线 Spyder Editor Python 3.6 Belter 20170401 import 
matplotlib . pyplot as plt import numpy as np X 
= np . array 0 1 2 4 . T 
# 都 转换 成列 向量 y = np . array 
0 1 2 4 . T theta1 = np . 
array 0 0 . T # 三个 不同 的 theta 
_ 1 值 theta2 = np . array 0 0.5 
. T theta3 = np . array 0 1 . 
T X _ size = X . shape X _ 
0 = np . ones X _ size 0 1 
# 添加 x _ 0 X _ with _ x0 
= np . concatenate X _ 0 X axis = 
1 h1 = np . dot X _ with _ 
x0 theta1 h2 = np . dot X _ with 
_ x0 theta2 h3 = np . dot X _ 
with _ x0 theta3 plt . plot X y rx 
label = y plt . plot X h1 b label 
= h1 theta _ 1 = 0 plt . plot 
X h2 m label = h2 theta _ 1 = 
0.5 plt . plot X h3 g label = h3 
theta _ 1 = 1 plt . xlabel X plt 
. ylabel y / h plt . axis 0.1 4.5 
0.1 4.5 plt . legend loc = upper left plt 
. savefig liner _ gression _ error . png dpi 
= 200 View Code 常数项 为 0 所以 可以 取 
θ 0 = 0 然后 取 不同 的 θ 1 
可以 得到 不同 的 拟合 直线 当 θ 1 = 
0时 拟合 的 直线 是 y = 0 即 蓝色 
线段 此时 距离 样本点 最远 代价 函数 的 值 误差 
也 最大 当 θ 1 = 1时 拟合 的 直线 
是 y = x 即 绿色 线段 此时 拟合 的 
直线 经过 每一个 样本点 代价 函数 的 值 为 0 
通过 下图 可以 查看 随着 θ 1 的 变化 J 
θ 的 变化 情况 代价 函数 J θ 随 参数 
的 变化 而 变化 Spyder Editor Python 3.6 Belter 20170401 
# 计算 代价 函数 的 值 def calcu _ cost 
theta X y m = X . shape 0 # 
sample size X _ 0 = np . ones m 
1 X _ with _ x0 = np . concatenate 
X _ 0 X axis = 1 h = np 
. dot X _ with _ x0 theta return np 
. dot h y . T h y / 2 
* m X = np . array 0 1 2 
4 . T y = np . array 0 1 
2 4 . T theta _ 0 = np . 
zeros 101 1 theta _ 1 = np . array 
np . linspace 2 4 101 . T theta = 
np . concatenate theta _ 0 theta _ 1 axis 
= 1 # 101组 不同 的 参数 J _ list 
= for i in range 101 current _ theta = 
theta i i + 1 . T cost = calcu 
_ cost current _ theta X y J _ list 
. append cost 0 0 plt . plot theta _ 
1 J _ list plt . xlabel theta _ 1 
plt . ylabel J theta plt . savefig cost _ 
theta . png dpi = 200 View Code 从 图中 
可以 很 直观 的 看到 θ 对 代价 函数 的 
影响 当 θ 1 = 1时 代价 函数 J θ 
取到 最小值 因为 线性 回归模型 的 代价 函数 均方 误差 
的 性质 非常 好 因此 也 可以 直接 使用 代数 
的 方法 求 J θ 的 一 阶 导数 为 
0 的 点 就 可以 直接 求出 最优 的 θ 
值 正规 方程 法 4 . 代价 函数 与 梯度 
梯度 下降 中的 梯度 指 的 是 代价 函数 对 
各个 参数 的 偏 导数 偏 导数 的 方向 决定了 
在 学习 过程 中 参数 下降 的 方向 学习率 通常用 
α 表示 决定了 每步 变化 的 步长 有了 导数 和 
学习率 就 可以 使用 梯度 下降 算法 Gradient Descent Algorithm 
更新 参 数了 下图 中 展示 了 只有 两个 参数 
的 模型 运用 梯度 下降 算法 的 过程 下图 可以 
看做 是 代价 函数 J θ 与 参数 θ 做出 
的 图 曲 面上 的 一个 点 θ 0 θ 
1 J θ 有 无数条 切线 在 这些 切线 中 
与 x y 平面 底面 相当于 θ 0   θ 
1 夹角 最大 的 那条 切线 就是 该点 梯度 的 
方向 沿 该 方向 移动 会 产生 最大 的 高度 
变化 相对于 z 轴 这里 的 z 轴 相当于 代价 
函数 J θ 4.1 线性 回归模型 的 代价 函数 对 
参数 的 偏 导数 还是 以 两个 参数 为例 每个 
参数 都 有一个 偏 导数 且 综合 了 所有 样本 
的 信息 4.2 逻辑 回归模型 的 代价 函数 对 参数 
的 偏 导数 根据 逻辑 回归模型 的 代价 函数 以及 
sigmoid 函数 $ $ h _ { \ theta } 
x = g \ theta ^ { T } x 
$ $ $ $ g z = \ frac { 
1 } { 1 + e ^ { z } 
} $ $ 得到 对 每个 参数 的 偏 导数 
为 $ $ \ frac { \ partial } { 
\ partial \ theta _ { j } } J 
\ theta = \ sum _ { i = 1 
} ^ { m } h _ \ theta x 
^ { i } y ^ i x _ j 
^ i $ $ 详细 推导 过程 可以 看 这里 
逻辑 回归 代价 函数 的 导数 4.3 神经 网络 中 
的 代价 函数 对 参数 的 偏 导数 这里 的 
计算 过程 与 前面 都不/nr 一样 后面 再 补充 重大 
修订 2017 . 8.14 修改 排版 补充 对 交叉 熵 
的 解释 Referenceshttps / / www . quora . com 
/ How are the cost functions for Neural Networks derived 
/ answer / Daniel Watson 22 srid = uIoGQhttps / 
/ www . zhihu . com / question / 23468713https 
/ / zh . wikipedia . org / wiki / 
% E 7% 86% B5 _ % E 4% BF 
% A 1% E 6% 81% AF % E 8% 
AE % BA https / / hit scir . gitbooks 
. io / neural networks and deep learning zh _ 
cn / content / chap3 / c3s3 . htmlCoursera Andrew 
Ng   公开课 第一周 第三周 第 五周 http / / 
math . stackexchange . com / questions / 477207 / 
derivative of cost function for logistic regressionhttp / / math 
. stackexchange . com / questions / 947604 / gradient 
tangents planes and steepest direction 