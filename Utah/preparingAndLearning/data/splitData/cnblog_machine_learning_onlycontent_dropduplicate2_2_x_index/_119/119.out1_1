catalogue0 . 个人 理解 1 . 基本 使用 2 . 
MNIST multiclass classification 入门 3 . 深入 MNIST 4 . 
卷积 神经网络 CIFAR 10 数据集 分类 5 . 单词 的 
向量 表示 Vector Representations of Words 6 . 循环 神经网络 
RNN LSTM Long Short Term Memory LSTM 7 . 用 
深度 学习 网络 搭建 一个 聊天 机器人 0 . 个人 
理解 在 学习 的 最开始 我 在 这里 写 一个 
个人 对 deep leanring 和 神经 网络 的 粗略 理解 
不对 的 地方 请 多 指教 1 . deep learning 
神经网络 本质 是 在 lean 什么 我 觉得 是 在 
learn 一个 一组 参数 或者说 是 选择 模式 也 就是 
我们 常说 的 分类器 这个 分类器 可能 是 一个 高 
维度 分类器 由 一组 参数 组成 2 . 拿 图像 
验证码 识别 来说 这里 的 参数 就是指 图像 区域 中 
的 权重 分布 情况 数字 1 和 数字 2 的 
权重 像素 空间 分布 是 不同 的 如果 我们 选定 
图像 的 像素 空间 例如 32 * 32 + RGB 
色彩 通道 3 作为 输入 特征 本质上 这 就是 特征 
工程 这些 特征 会被 tensorflow 当成 神经元 并在 每 一层 
对 这些 神经元 进行 组合 并 计算 出 结果 而 
下一层 神经 网络 的 神经元 会把 这 一层 的 输出 
再 进行 组合 组 合时 根据 上 一次 预测 的 
准确性 会 自动 通过 back propogation 给 每个 组合 不同 
的 weight 比重 这个 过程 会 一直 进行 直到 调整 
出 一个 最佳 拟合 的 weight 这个 weight 往往 就是 
最 贴近 真实 图像 的 像素 空间 权重 3 . 
. 世界 上 的 所有 事物 都/d 可以/c 抽象/v 为/p 
一个/m 高/a 维度/ns 矩阵/n 这个 过程 在 不同 的 领域 
会 有 不同 的 提取 抽象 方式 即 特征 工程 
值得 注意 的 是 拥有 对应 领域 的 专业 知识 
非常 有助于 特征 工程 的 实施 4 . 我们 将 
特定 领域 的 需要 分类 / 识别 的 对象 抽象 
为高 维度 矩阵 后 进入 deep learn 算法 模型 中 
就 成为 了 神经元 节点 deep learn 模型 接下来 要做 
的 事 称之为 拟合 5 . 要 完成 分类 和 
识别 deep learn 的 目标 是 找到 一个 拟合 矩阵 
具象 来说 就是 高 维度 1 分类 切面 要 达到 
这个 目的 需要 3个 元素 1 拟合 函数 activation 激活 
函数 用于 生成 拟合 切面 2 误差函数 Loss Function 用于 
在 网络 计算 的 过程 中 计算 当前 拟合 参数 
得到 的 拟合 切面 离 最优 值 的 距离 以便 
随时 调整 参数 3 神经 网络结构 deep learn 深度 学习 
和 普通 神经 网络 的 区别 就 在于 层数 的 
不同 深度 神经网络 往往 有 3层 以上 输入 层 隐 
层 输出 层 当 层数 增加 后 在 每 一层 
选择 怎样 的 组合 的 交叉 结构 就成 了 一个 
很难 的 事情 当前/t 还/d 没有/v 完善/v 的/uj 理论/n 支撑/v 
能/v 精确/a 地/uv 计算/v 出/v 什么样/r 的/uj 网络/n 结构/n 能/v 
输出/v 最好/a 的/uj 结果/n 通常 的 做法 是 根据 不 
认同 的 业务 场景 去 不断 尝试 不同 的 网络结构 
直到 试出 一个 相对 较好 的 网络 结构 然后再 在 
这个 网络 结构 的 基础 之上 进行 参数 调整 值得 
注意 的 是 神经网络 最大 的 魔力 在于 就在于 即使 
我们 无法 准确 地 提取 出 各种各样 很多 的 特征 
而 只要 给与 足够 多层 的 神经 网络 和 神经元 
神经网络 自己 会 组合 出 有用 的 特征 之所以 可以 
做到 这点 我 么 可以 来看 一个 实验 http / 
/ playground . tensorflow . org / # activation = 
tanh & batchSize = 10 & dataset = spiral & 
regDataset = reg plane & learningRate = 0.03 & r 
e g u l a r i z a t 
i o n R a t e = 0 & 
noise = 0 & networkShape = 8 8 8 8 
8 8 & seed = 0.33671 & showTestData = false 
& discretize = false & percTrainData = 50 & x 
= true & y = true & xTimesY = false 
& xSquared = false & ySquared = false & cosX 
= false & sinX = false & cosY = false 
& sinY = false & collectStats = false & problem 
= classification & initZero = false & hideText = false 
对于 输入 来说 我们 只 给出 2个 维度 的 特征 
x1 x2 而 选择 1个 6层 的 每层 有 8个 
神经元 的 神经 网络 在 每层 网络 中 维度 被 
扩展到 了 8 神经 网络 会 自动 在 训练 过程 
中 寻找 对 它 有价值 的 维度 并给 与 一定 
的 weight 权重 根据 loss 函数 来 不断 递归 下降 
直到 找到 一个 最好 的 拟合 权重 参数 DL 大大 
降低 了 特征 工程 的 难度 0x1 神经网络 到底 理解 
了 什么 其一 神经网络 理解 了 如何 将 输入 空间 
解耦 为 分 层次 的 卷积 滤波器 组 其二 神经网络 
理解 了 从 一系列 滤波器 的 组合 到 一 系列 
特定 标签 的 概率 映射 神经 网络 学习 到 的 
东西 完全 达不到 人类 的 看见 的 意义 从 科学 
的 的 角度 讲 这 当然 也 不 意味着 我们 
已经 解决 了 计算机 视觉 的 问题 有些人 说 卷积 
神经 网络 学习 到 的 对 输入 空间 的 分 
层次 解耦 模拟 了 人类 视觉 皮层 的 行为 这种 
说法 可能 对 也 可能 不对 但 目前 未知 我们 
还 没有 比 较强 的 证据 来 承认 或 否认 
它 当然 有些 人 可以期望 人类 的 视觉 皮层 就是 
以 类似 的 方式 学 东西 的 某种 程度 上 
讲 这是 对 我们 视觉 世界 的 自然 解耦 就像 
傅里叶 变换 是 对 周期 声音 信号 的 一种 解耦 
一样 自然 这里 是 说 就像 声音 信号 的 傅里叶 
变换 表达 了 不同 频率 的 声音 信号 这种 很 
自然 很 物理 的 理解 一样 我们 可能 会 认为 
我们 对 视觉 信息 的 识别 就是 分层 来 完成 
的 圆 的 是 轮子 有 四个 轮子 的 是 
汽车 造型 炫 酷 的 汽车 是 跑车 像这样 但是 
人类 对 视觉 信号 的 滤波 分 层次 处理 的 
本质 很 可能 和 我们 弱 鸡 的 卷积 网络 
完全 不是 一回 事 视觉 皮层 不是 卷积 的 尽管 
它们 也 分层 但 那些 层 具有 皮质 列 的 
结构 而 这些 结构 的 真正 目的 目前 还 不得而知 
这种 结构 在 我们 的 人工 神经 网络 中 还 
没有 出现 尽管 乔 大帝 Geoff Hinton 正在 在 这个 
方面 努力 此外 人类 有比 给 静态 图像 分类 的 
感知器 多得多 的 视觉 感知器 这些 感知器 是 连续 而 
主动 的 不是 静态 而 被动 的 这些 感受器 还被 
如 眼动 等 多种 机制 复杂 控制 Relevant Link https 
/ / groups . google . com / a / 
tensorflow . org / forum / # forum / discuss 
https / / stackoverflow . com / questions / tagged 
/ tensorflow http / / www . tensorfly . cn 
/ tfdoc / resources / overview . html https / 
/ www . zhihu . com / question / 41667903 
http / / playground . tensorflow . org / # 
activation = tanh & batchSize = 10 & dataset = 
spiral & regDataset = reg plane & learningRate = 0.03 
& r e g u l a r i z 
a t i o n R a t e = 
0 & noise = 0 & networkShape = 8 8 
8 8 8 8 & seed = 0.33671 & showTestData 
= false & discretize = false & percTrainData = 50 
& x = true & y = true & xTimesY 
= false & xSquared = false & ySquared = false 
& cosX = false & sinX = false & cosY 
= false & sinY = false & collectStats = false 
& problem = classification & initZero = false & hideText 
= false1 . 基本 使用 0x1 综述 1 . 使 
用图 graph 来 表示 计算 任务 . 2 . 在被 
称之为 会话 Session 的 上下文 context 中 执行 图 . 
3 . 使用 tensor 表示 数据 . 4 . 通过 
变量 Variable 维护 状态 . 5 . 使用 feed 和 
fetch 可以为 任意 的 操作 arbitrary operation 赋值 或者 从 
其中 获取数据 . TensorFlow 是 一个 编程 系统 使 用图 
来 表示 计算 任务 . 图中 的 节点 被 称之为 
op operation 的 缩写 . 一个 op 获得 0 个 
或 多个 Tensor 执行 计算 产生 0 个 或 多个 
Tensor . 每个 Tensor 是 一个 类型化 的 多维 数组 
. 例如 你 可以 将 一 小组 图像 集 表示 
为 一个 四维 浮点数 数组 这四个 维度 分别 是 batch 
height width channels . 一个 TensorFlow 图 描述 了 计算 
的 过程 . 为了 进行 计算 图 必须 在 会话 
里 被 启动 . 会话 将 图 的 op 分发 
到 诸如 CPU 或 GPU 之类 的 设备 上 同时 
提供 执行 op 的 方法 . 这些 方法 执行 后 
将 产生 的 tensor 返回 . 在 Python 语言 中 
返回 的 tensor 是 numpy ndarray 对象 在 C 和 
C + + 语言 中 返回 的 tensor 是 tensorflow 
Tensor 实例 . 0x2 计 算图 TensorFlow 程序/n 通常/d 被/p 
组织/v 成/n 一个/m 构建/v 阶段/n 和/c 一个/m 执行/v 阶段/n ./i 
在 构建 阶段 op 的 执行 步骤 被 描述 成 
一个 图 . 在 执行 阶段 使用 会话 执行 执行 
图 中的 op . 例如 通常 在 构建 阶段 创建 
一个 图 来 表示 和 训练 神经网络 然后 在 执行 
阶段 反复 执行 图中 的 训练 op . 1 . 
构建 图 将 待 分类 对象 抽象 为 高维 矩阵 
构建 图 的 第一 步 是 创建 源 op source 
op . 源 op 不 需要 任何 输入 例如 常量 
Constant . 源 op 的 输出 被 传递 给 其它 
op 做 运算 . Python 库 中 op 构造器 的 
返回值 代表 被 构 造出 的 op 的 输出 这些 
返回值 可以 传递 给 其它 op 构造器 作为 输入 . 
# * coding utf 8 * import tensorflow as tf 
if _ _ name _ _ = = _ _ 
main _ _ # 创建 一个 常量 op 产生 一个 
1x2 矩阵 . 这个 op 被 作为 一个 节点 # 
加到 默认 图中 . # # 构造器 的 返回值 代表 
该 常量 op 的 返回值 . matrix1 = tf . 
constant 3 . 3 . # 创建 另外 一个 常量 
op 产生 一个 2x1 矩阵 . matrix2 = tf . 
constant 2 . 2 . # 创建 一个 矩阵 乘法 
matmul op 把 matrix1 和 matrix2 作为 输入 . # 
返回值 product 代表 矩阵 乘法 的 结果 . product = 
tf . matmul matrix1 matrix2 默认 图 现在 有 三个 
节点 两个 constant op 和 一个 matmul op . 为了 
真正 进行 矩阵 相乘 运算 并 得到 矩阵 乘法 的 
结果 必须 在 会 话里 启动 这个 图 . 2 
.   在 一个 会 话中 启动 图 构造 阶段 
完成 后 才能 启动 图 . 启动 图 的 第一步 
是 创建 一个 Session 对象 如果 无 任何 创建 参数 
会话 构造器 将 启动 默认 图 . # * coding 
utf 8 * import tensorflow as tf if _ _ 
name _ _ = = _ _ main _ _ 
# 创建 一个 常量 op 产生 一个 1x2 矩阵 . 
这个 op 被 作为 一个 节点 # 加到 默认 图中 
. # # 构造器 的 返回值 代表 该 常量 op 
的 返回值 . matrix1 = tf . constant 3 . 
3 . # 创建 另外 一个 常量 op 产生 一个 
2x1 矩阵 . matrix2 = tf . constant 2 . 
2 . # 创建 一个 矩阵 乘法 matmul op 把 
matrix1 和 matrix2 作为 输入 . # 返回值 product 代表 
矩阵 乘法 的 结果 . product = tf . matmul 
matrix1 matrix2 # 默认 图 现在 有 三个 节点 两个 
constant op 和 一个 matmul op . 为了 真正 进行 
矩阵 相乘 运算 并 得到 矩阵 乘法 的 结果 你 
必须 在 会 话里 启动 这个 图 . # 启动 
默认 图 . sess = tf . Session # 调用 
sess 的 run 方法 来 执行 矩阵 乘法 op 传入 
product 作为 该 方法 的 参数 . # 上面 提到 
product 代表 了 矩阵 乘法 op 的 输出 传入 它 
是 向 方法 表明 我们 希望 取回 # 矩阵 乘法 
op 的 输出 . # # 整个 执行 过程 是 
自动化 的 会话 负责 传递 op 所需 的 全部 输入 
. op 通常 是 并发 执行 的 . # # 
函数调用 run product 触发 了 图中 三个 op 两个 常量 
op 和 一个 矩阵 乘法 op 的 执行 . # 
# 返回值 result 是 一个 numpy ` ndarray ` 对象 
. result = sess . run product print result # 
= = 12 . # 任务 完成 关闭 会话 . 
sess . close 在 实现 上 TensorFlow 将 图形 定义 
转换成 分布式 执行 的 操作 以 充分 利用 可用 的 
计算资源 如 CPU 或 GPU . 一般 你 不需要 显 
式 指定 使用 CPU 还是 GPU TensorFlow 能 自动 检测 
. 如果 检测 到 GPU TensorFlow 会 尽可能 地 利用 
找到 的 第一 个 GPU 来 执行 操作 0x3 TensorTensorFlow 
程序 使用 tensor 数据结构 来 代表 所有 的 数据 计算 
图中 操作 间 传递 的 数据 都是 tensor . 你 
可以 把 TensorFlow tensor 看作 是 一个 n 维 的 
数组 或 列表 . 一个 tensor 包含 一个 静态 类型 
rank 和 一个 shape . 0x4 变量 变量 维护 图 
执行 过程 中 的 状态 信息 . 下面 的 例子 
演示 了 如何 使用 变量 实现 一个 简单 的 计数器 
# * coding utf 8 * import tensorflow as tf 
if _ _ name _ _ = = _ _ 
main _ _ # 创建 一个 变量 初始 化为 标量 
0 . state = tf . Variable 0 name = 
counter # 创建 一个 op 其 作用 是 使 state 
增加 1 one = tf . constant 1 new _ 
value = tf . add state one update = tf 
. assign state new _ value # 启动 图 后 
变量 必须 先 经过 ` 初始化 ` init op 初始化 
# 首先 必须 增加 一个 ` 初始化 ` op 到 
图中 . init _ op = tf . initialize _ 
all _ variables # 启动 图 运行 op with tf 
. Session as sess # 运行 init op sess . 
run init _ op # 打印 state 的 初始值 print 
sess . run state # 运行 op 更新 state 并打印 
state for _ in range 3 sess . run update 
print sess . run state 代码 中 assign 操作 是 
图 所 描绘 的 表达式 的 一部分 正如 add 操作 
一样 . 所以在 调用 run 执行 表达式 之前 它 并不 
会 真正 执行 赋值 操作 . 通常会 将 一个 统计 
模型 中 的 参数 表示 为 一组 变量 . 例如 
你 可以 将 一个 神经 网络 的 权重 作为 某个 
变量 存储 在 一个 tensor 中 . 在 训练 过程 
中 通过 重复 运行 训练 图 更新 这个 tensor . 
0x5 Fetch 为了 取回 操作 的 输出 内容 可以 在 
使用 Session 对象 的 run 调用 执行 图 时 传入 
一些 tensor 这些 tensor 会 帮助 你 取回 结果 . 
在 之前 的 例子 里 我们 只 取回 了 单个 
节点 state 但是 你 也 可以 取回 多个 tensor # 
* coding utf 8 * import tensorflow as tf if 
_ _ name _ _ = = _ _ main 
_ _ # 启动 默认 图 . sess = tf 
. Session input1 = tf . constant 3.0 input2 = 
tf . constant 2.0 input3 = tf . constant 5.0 
intermed = tf . add input2 input3 mul = tf 
. multiply input1 intermed with tf . Session result = 
sess . run mul intermed print result0x6 Feed 上述 示例 
在 计算 图中 引入 了 tensor 以 常量 或 变量 
的 形式 存储 . TensorFlow 还 提供 了 feed 机制 
该 机制 可以 临时 替代 图中 的 任意 操作 中的 
tensor 可以 对 图中 任何 操作 提交 补丁 直接插入 一个 
tensor . feed 使用 一个 tensor 值 临时 替 换一个 
操作 的 输出 结果 . 你 可以 提供 feed 数据 
作为 run 调用 的 参数 . feed 只在 调用 它 
的 方法 内有效 方法 结束 feed 就会 消失 . 最 
常见 的 用 例 是 将 某些 特殊 的 操作 
指定 为 feed 操作 标记 的 方法 是 使用 tf 
. placeholder 为 这些 操作 创建 占位符 . # * 
coding utf 8 * import tensorflow as tf if _ 
_ name _ _ = = _ _ main _ 
_ input1 = tf . placeholder tf . types . 
float32 input2 = tf . placeholder tf . types . 
float32 output = tf . multiply input1 input2 with tf 
. Session as sess print sess . run output print 
sess . run output feed _ dict = { input1 
7 . input2 2 . } 0x7 batch 深度 学习 
的 优化 算法 说白 了 就是 梯度 下降 每次 的 
参数 更新 有 两种 方式 1 . 第一种 遍历 全部 
数据集 算 一次 损失 函数 然后 算 函数 对 各个 
参数 的 梯度 更新 梯度 这种方法/i 每/zg 更新/d 一次/m 参数/n 
都/d 要把/i 数据集/i 里/f 的/uj 所有/b 样本/n 都/d 看一遍/v 计算 
量 开销 大 计算 速度慢 不支持 在线 学习 这 称为 
Batch gradient descent 批 梯度 下降 2 . 另一种 每 
看 一个 数据 就 算 一下 损失 函数 然后 求 
梯度 更新 参数 这个 称为 随机 梯度 下降 stochastic gradient 
descent 这个 方法 速度 比较 快 但是 收敛 性能 不太好 
可能 在 最优 点 附近 晃来晃去 hit 不到 最 优点 
两次 参数 的 更新 也 有可能 互 相抵 消掉 造成 
目标函数 震荡 的 比较 剧烈 为了 克服 两种 方法 的 
缺点 现在 一般 采用 的 是 一种 折中 手段 mini 
batch gradient decent 小批 的 梯度 下降 这种 方法 把 
数据 分为 若干个 批 按 批 来 更新 参数 这样 
一个 批 中的 一组 数据 共同 决定 了 本次 梯度 
的 方向 下降 起来 就 不容易 跑偏 减少 了 随机性 
另一方面 因为 批 的 样本 数 与 整个 数据集 相比 
小 了 很多 计算 量 也 不是 很 大 基本 
上 现在 的 梯度 下降 都是 基于 mini batch 的 
模块 中 经常 会 出现 batch _ size 就是 指 
这个 我们 在 代码 中 常见 的 优化 器 SGD 
是 stochastic gradient descent 的 缩写 但不 代表 是 一个 
样本 就 更新 一回 还是 基于 mini batch 的 Relevant 
Link http / / www . tensorfly . cn / 
tfdoc / get _ started / os _ setup . 
html http / / keras cn . readthedocs . io 
/ en / latest / getting _ started / concepts 
/ # batch2 . MNIST multiclass classification 入门 0x1 MNIST 
数据集 https / / tensorflow . googlesource . com / 
tensorflow / + / master / tensorflow / examples / 
tutorials / mnist / input _ data . py # 
下载 下来 的 数据集 被 分成 两部分 60000行 的 训练 
数据集 mnist . train 和 10000行 的 测试 数据集 mnist 
. test 这样 的 切分 很重要 在/p 机器学习/i 模型/n 设计/vn 
时/n 必须/d 有/v 一个/m 单独/d 的/uj 测试/vn 数据集/i 不/d 用于/v 
训练/vn 而是/c 用来/v 评估/vn 这个/r 模型/n 的/uj 性能/n 从而 更加 
容易 把 设计 的 模型 推广 到 其他 数据 集上 
泛化 正如 前面 提到 的 一样 每一个 MNIST 数据 单元 
有 两部分 组成 一张 包含 手写 数字 的 图片 和 
一个 对应 的 标签 监督 学习 中 正确 打 标的 
样本 特别 重要 我们 把 这些 图片 设为 xs 把 
这些 标签 设为 ys 训练/vn 数据集/i 和/c 测试/vn 数据集/i 都/d 
包含/v xs/w 和/c ys/w 比如 训练 数据集 的 图片 是 
mnist . train . images 训练 数据集 的 标签 是 
mnist . train . labels 每 一张 图片 包含 28 
像素 X28 像素 我们 可以 用 一个 数字 数组 来 
表示 这 张 图片 我们 把 这个 数 组展 开成 
一个 向量 长度 是 28x28 = 784 如何 展开 这个 
数组 数 字间 的 顺序 不重要 只要 保持 各个 图片 
采用 相同 的 方式 展开 从 这个 角度 来看 MNIST 
数据集 的 图片 就是 在 784 维 向量空间 里面 的 
点 并且 拥有 比较 复杂 的 结构 提醒 此类 数据 
的 可视化 是 计算 密集型 的 展平 图片 的 数字 
数组 会 丢失 图片 的 二维结构 信息 这 显然 是 
不 理想 的 最 优秀 的 计算机 视觉 方法 会 
挖掘 并 利用 这些 结构 信息 但在 当前 锁 学习 
的 简单 数学模型 softmax 回归 softmax regression 不会 利用 这些 
结构 信息 因此 在 MNIST 训练 数据 集中 mnist . 
train . images 是 一个 形状 为 60000 784 的 
张量 第一 个 维度 数字 用来 索引 图片 第二 个 
维度 数字 用来 索引 每张 图片 中的 像素点 在此 张量 
里 的 每一个 元素 都/d 表示/v 某/r 张/q 图片/n 里/f 
的/uj 某个/r 像素/n 的/uj 强度/n 值/n 值 介于 0 和1/nr 
之间 黑白图片 相 对应 的 MNIST 数据集 的 标签 是 
介于 0 到 9 的 数字 用来 描述 给定 图片 
里 表示 的 数字 为了 用 于 这个 教程 我们 
使 标签 数据 是 one hot vectors 一个 one hot 
向量 除了 某 一位 的 数字 是 1 以外 其余 
各 维度 数字 都是 0 所以 在此 教程 中 数字 
n 将 表示 成 一个 只有 在 第 n 维度 
从0/nr 开始 数字 为 1 的 10 维 向量 比如 
标签 0 将 表示 成 1 0 0 0 0 
0 0 0 0 0 0 因此 mnist . train 
. labels 是 一个 60000 10 的 数字 矩阵 0x2 
Softmax 回归 我们 知道 MNIST 的 每 一张 图片 都 
表示 一个 数字 从0到/nr 9 我们 希望 得到 给定 图片 
代表 每个 数字 的 概率 比如说 我们 的 模型 可能 
推测 一张 包含 9 的 图片 代表 数字 9 的 
概率 是 80% 但是 判断 它 是 8 的 概率 
是 5% 因为 8 和9/nr 都有 上半部分 的 小圆 然后 
给予 它 代表 其他 数字 的 概率 更小 的 值 
这 是 一个 使用 softmax 回归 softmax regression 模型 的 
经典 案例 softmax 模型 可以 用来 给 不同 的 对象 
分配 概率 即使 在 之后 我们 训练 更加 精细 的 
模型 时 最后 一步 也 需要 用 softmax 来 分配 
概率 softmax 回归 softmax regression 分 两步 1 .   
第一步 为了 得到 一张 给定 图片 属于 某个 特定 数 
字类 的 证据 evidence 我们 对 图片 像素 值 进行 
加权 求和 如果 这个 像素 具有 很强 的 证据 说明 
这 张 图片 不属于 该类 那么 相应 的 权值 为 
负数 相反 如果 这个 像素 拥有 有利 的 证据 支持 
这 张 图片 属于 这个 类 那么 权值 是 正数 
下面 的 图片 显示 了 一个 模型 学习 到 的 
图片 上 每个 像素 对于 特定 数 字类 的 权值 
红色 代表 负数 权值 蓝色 代表 正数 权值 我们 也 
需要 加入 一个 额外 的 偏置 量 bias 因为 输入 
往往会 带有 一些 无关 的 干扰 量 因此 对于 给定 
的 输入 图片 x 它 代表 的 是 数字 i 
的 证据 可以 表示 为 其中     代表 权重 
  代表 数字   i   类 的 偏置 量 
j   代表 给定 图片   x   的 像素 
索引 用于 像素 求和 然后 用 softmax 函数 可以 把 
这些 证据 转换成 概率   y 这里 的 softmax 可以 
看成 是 一个 激励 activation 函数 或者 链接 link 函数 
把 我们 定义 的 线性 函数 的 输出 转换 成 
我们 想要 的 格式 也 就是 关于 10 个数 字类 
的 概率分布 因此 给定 一张 图片 它 对于 每 一个 
数字 的 吻 合度 可以 被 softmax 函数 转换 成为 
一个 概率值 softmax 函数 可以 定义 为 展开 等式 右边 
的 子式 可以 得到 但是 更多 的 时候 把 softmax 
模 型函数 定义 为 前一种 形式 把 输入 值 当成 
幂指数 求值 再 正则化 这些 结果 值 这个 幂 运算 
表示 更大 的 证据 对应 更大 的 假设 模型 hypothesis 
里面 的 乘数 权重 值 反之 拥有 更少 的 证据 
意味着 在 假设 模型 里面 拥有 更小 的 乘数 系数 
假设 模型 里 的 权值 不 可以 是 0 值 
或者 负值 Softmax 然后 会 正则化 这些 权重 值 使 
它们 的 总和 等于 1 以此 构造 一个 有效 的 
概率分布 对于 softmax 回归模型 可以用 下面 的 图解 释 对于 
输入 的 xs 加权 求和 再 分别 加上 一个 偏置 
量 最后 再 输入 到 softmax 函数 中 如果把 它 
写成 一个 等式 我们 可以 得到 我们 也 可以 用 
向量 表示 这个 计算 过程 用 矩阵 乘法 和 向量 
相加 这 有助于 提高 计算 效率 也 是 一种 更 
有效 的 思考 方式 更进一步 可以 写成 更加 紧凑 的 
方式 验证码 识别 体现 了 模式识别 的 一个 很 朴素 
的 思想 就是 人 的 认字 过程 是 经历 了 
一个 学习 过程 在 看过 了 很多 人 各种 写法 
各种 字体 的 字后 人 脑中 对 某个 字 应该 
长 的 样子 形成 了 一个 权重 认知 模型 不管怎么 
潦草 只要 基本 形态 在 那里 人 就能 认出来 把 
这个 认知过程 抽象 为 数学 概念 本质 上 就是 特定 
像素 区域 给与 较高 的 权重 根据 像素 权重 划分 
出 区域 只要 大体 在 这个 区域 中 就 应该 
有 更大 的 概率 是 这个 字 0x3   实现 
回归模型 y = tf . nn . softmax tf . 
matmul x W + b TensorFlow 不仅仅 可以 使 softmax 
回归模型 计算 变得 特别 简单 它 也用 这种 非常 灵活 
的 方式 来 描述 其他 各种 数值 计算 从 机器学习 
模型 对 物理学 模拟 仿真 模型 一旦 被 定义 好 
之后 我们 的 模型 就 可以 在 不同 的 设备 
上 运行 计算机 的 CPU GPU 甚至 是 手机 0x4 
训练 模型 为了 训练 我们 的 模型 我们 首先 需要 
定义 一个 指标 来 评估 这个 模型 是 好 的 
其实 在 机器学习 我们 通常 定义 指标 来 表示 一个 
模型 是 坏 的 这个 指标 称为 成本 cost 或 
损失 loss 然后 尽量 最小化 这个 指标 但是 这 两种 
方式 是 相同 的 一个 非常 常见 的 非常 漂亮 
的 成本 函数 是 交叉 熵 cross entropy 交叉 熵 
产生于 信息论 里面 的 信息 压缩 编码 技术 但是 它 
后来 演变 成为 从 博弈 论到 机器学习 等 其他 领域 
里 的 重要 技术 手段 它 的 定义 如下 y 
  是 我们 预测 的 概率分布   y   是 
实际 的 分布 我们 输入 的 one hot vector 比较 
粗糙 的 理解 是 交叉 熵 是 用来 衡量 我们 
的 预测 用于 描述 真相 的 低效 性 即 如果 
我们 的 描述 越 不准确 则 不确定性 就 越高 熵值 
就 越大 TensorFlow 拥有 一张 描述 你 各个 计算 单元 
的 图 它 可以 自动 地 使用 反向 传播 算法 
backpropagation algorithm 来 有效 地 确定 你 的 变量 是 
如何 影响 你 想要 最小化 的 那个 成 本值 的 
然后 TensorFlow 会用 你 选择 的 优化 算法 来 不断 
地 修改 变量 以 降低成本 train _ step = tf 
. train . G r a d i e n 
t D e s c e n t O p 
t i m i z e r 0.01 . minimize 
cross _ entropy 在 这里 我们 要求 TensorFlow 用 梯度 
下降 算法 gradient descent algorithm 以 0.01 的 学习 速率 
最小化 交叉 熵 梯度 下降 算法 gradient descent algorithm 是 
一个 简单 的 学习 过程 TensorFlow 只需 将 每个 变量 
一点点 地 往 使 成本 不断 降低 的 方向 移动 
TensorFlow 在 这里 实际上 所做 的 是 它 会在 后台 
给 描述 你 的 计算 的 那张 图 里面 增加 
一 系列 新 的 计算 操作 单元 用于 实现 反向 
传播 算法 和 梯度 下降 算法 然后 它 返回 给 
你 的 只是 一个 单一 的 操作 当 运行 这个 
操作 时 它 用 梯度 下降 算法 训练 你 的 
模型 微调 你 的 变量 不断 减少 成本 0x5 评估 
我们 的 模型 首先 让 我们 找出 那些 预测 正确 
的 标签 tf . argmax 是 一个 非常 有用 的 
函数 它 能 给出 某个 tensor 对象 在 某一 维 
上 的 其 数据 softmax 预测出 了 一个 类似 1 
0 0 0 0 0 0 0 0 矩阵 对应 
为 1 的 那个 就是 它 预测出 的 最大 概率 
的 数字 最大值 所在 的 索引 值 对应 的 数字 
由于 标签 向量 是由 0 1 组成 因此 最大值 1 
所在 的 索引 位置 就是 类别 标签 比如 tf . 
argmax y 1 返回 的 是 模型 对于 任一 输入 
x 预测 到 的 标签 值 而 tf . argmax 
y _ 1 代表 正确 的 标签 我们 可以 用 
tf . equal 来 检测 我们 的 预测 是否 真实 
标签 匹配 索引 位置 一样 表示 匹配 correct _ prediction 
= tf . equal tf . argmax y 1 tf 
. argmax y _ 1 这行 代码 会 给 我们 
一组 布尔值 为了 确定 正确 预测 项的/nr 比例 我们 可以 
把 布尔值 转换成 浮点数 然后 取 平均值 例如 True False 
True True   会 变成   1 0 1 1 
  取 平均值 后 得到   0.75 . accuracy = 
tf . reduce _ mean tf . cast correct _ 
prediction float 最后 我们 计算所 学习 到 的 模型 在 
测试 数据集 上面 的 正确率 print sess . run accuracy 
feed _ dict = { x mnist . test . 
images y _ mnist . test . labels } 0x6 
mnist _ softmax . py # Copyright 2015 The TensorFlow 
Authors . All Rights Reserved . # # Licensed under 
the Apache License Version 2.0 the License # you may 
not use this file except in compliance with the License 
. # You may obtain a copy of the License 
at # # http / / www . apache . 
org / licenses / LICENSE 2.0 # # Unless required 
by applicable law or agreed to in writing software # 
distributed under the License is distributed on an AS IS 
BASIS # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either 
express or implied . # See the License for the 
specific language governing permissions and # limitations under the License 
. # = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
A very simple MNIST classifier . See extensive documentation at 
http / / tensorflow . org / tutorials / mnist 
/ beginners / index . md from _ _ future 
_ _ import absolute _ import from _ _ future 
_ _ import division from _ _ future _ _ 
import print _ function import argparse import sys import input 
_ data import tensorflow as tf FLAGS = None def 
main _ # Import data mnist = input _ data 
. read _ data _ sets MNIST _ data / 
one _ hot = True # Create the model x 
= tf . placeholder tf . float32 None 784 W 
= tf . Variable tf . zeros 784 10 b 
= tf . Variable tf . zeros 10 y = 
tf . matmul x W + b # Define loss 
and optimizer y _ = tf . placeholder tf . 
float32 None 10 # The raw formulation of cross entropy 
# # tf . reduce _ mean tf . reduce 
_ sum y _ * tf . log tf . 
nn . softmax y # reduction _ indices = 1 
# # can be numerically unstable . # # So 
here we use tf . nn . softmax _ cross 
_ entropy _ with _ logits on the raw # 
outputs of y and then average across the batch . 
cross _ entropy = tf . reduce _ mean tf 
. nn . softmax _ cross _ entropy _ with 
_ logits labels = y _ logits = y train 
_ step = tf . train . G r a 
d i e n t D e s c e 
n t O p t i m i z e 
r 0.5 . minimize cross _ entropy sess = tf 
. I n t e r a c t i 
v e e s s i o n tf . 
global _ variables _ initializer . run # Train for 
_ in range 1000 batch _ xs batch _ ys 
= mnist . train . next _ batch 100 sess 
. run train _ step feed _ dict = { 
x batch _ xs y _ batch _ ys } 
# Test trained model correct _ prediction = tf . 
equal tf . argmax y 1 tf . argmax y 
_ 1 accuracy = tf . reduce _ mean tf 
. cast correct _ prediction tf . float32 print sess 
. run accuracy feed _ dict = { x mnist 
. test . images y _ mnist . test . 
labels } if _ _ name _ _ = = 
_ _ main _ _ parser = argparse . ArgumentParser 
parser . add _ argument data _ dir type = 
str default = MNIST _ data / help = Directory 
for storing input data FLAGS unparsed = parser . parse 
_ known _ args tf . app . run main 
= main argv = sys . argv 0 + unparsed 
Relevant Link http / / yann . lecun . com 
/ exdb / mnist / https / / github . 
com / tensorflow / tensorflow / tree / master / 
tensorflow / examples / tutorials / mnist https / / 
github . com / aymericdamien / TensorFlow Examples / tree 
/ master / examples https / / www . tensorflow 
. org / get _ started / mnist / pros 
https / / www . tensorflow . org / get 
_ started / mnist / beginners3 . 深入 MNIST0x1   
构建 一个 多 层 卷积 网络 多层 深度 神经网络 1 
. 权重 初始化 为了 创建 这个 模型 我们 需要 创建 
大量 的 权重 和 偏置 项 这个 模型 中 的 
权重 在 初始 化时 应该 加入 少量 的 噪声 来 
打破 对称性 以及 避免 0 梯度 由于 我们 使用 的 
是 ReLU 神经元 因此 比 较好 的 做法 是 用 
一个 较小 的 正 数来 初始化 偏置 项 以 避免 
神经元 节点 输出 恒 为 0 的 问题 dead neurons 
为了 不 在 建立 模型 的 时候 反复 做 初始化 
操作 我们 定义 两个 函数 用于 初始化 def weight _ 
variable shape initial = tf . truncated _ normal shape 
stddev = 0.1 return tf . Variable initial def bias 
_ variable shape initial = tf . constant 0.1 shape 
= shape return tf . Variable initial 2 . 卷积/n 
和池化/nr 将 低维 特征 扩展到 高维空间 TensorFlow/w 在/p 卷积/n 和池/nr 
化上/i 有/v 很强/i 的/uj 灵活性/n 我们 怎么 处理 边界 步长 
应该 设 多大 在 这个 实例 里 我们 会 一直 
使用 vanilla 版本 我们 的 卷积 使用 1 步长 stride 
size 0 边距 padding size 的 模板 保证 输出 和 
输入 是 同一 个 大小 我们 的 池 化用 简单 
传统 的 2x2 大小 的 模板 做 max pooling 为了 
代码 更 简洁 我们 把 这 部分 抽象 成 一个 
函数 def conv2d x W return tf . nn . 
conv2d x W strides = 1 1 1 1 padding 
= SAME def max _ pool _ 2x2 x return 
tf . nn . max _ pool x ksize = 
1 2 2 1 strides = 1 2 2 1 
padding = SAME 3 . 第一层 卷积 现在 我们 可以 
开始 实现 第一层 了 它 由 一个 卷积 接 一个 
max pooling 完成 卷积 在 每个 5x5 的 patch 中 
算出 32个 特征 卷积 的 权重 张量 形状 是 5 
5 1 32 前 两个 维度 是 patch 的 大小 
接着 是 输入 的 通道 数目 最后 是 输出 的 
通道 数目 而 对于 每 一个 输出 通道 都 有一个 
对应 的 偏置 量 W _ conv1 = weight _ 
variable 5 5 1 32 b _ conv1 = bias 
_ variable 32 为了 用 这 一层 我们 把 x 
变成 一个 4d 向量 其 第 2 第 3 维 
对应 图片 的 宽 高 最后 一 维 代表 图片 
的 颜色 通 道数 因为 是 灰度 图 所以 这里 
的 通道 数 为 1 如果 是 rgb 彩色 图 
则为 3 x _ image = tf . reshape x 
1 28 28 1 We then convolve   x _ 
image   with the weight tensor add the bias apply 
the ReLU function and finally max pool . 我们 把 
x _ image 和 权值 向量 进行 卷积 加上 偏置 
项 然后 应用 ReLU 激活 函数 最后 进行 max pooling 
h _ conv1 = tf . nn . relu conv2d 
x _ image W _ conv1 + b _ conv1 
h _ pool1 = max _ pool _ 2x2 h 
_ conv1 4 . 第二层 卷积 为了 构建 一个 更深 
的 网络 我们 会 把 几个 类似 的 层 堆 
叠起来 第二层 中 每个 5x5 的 patch 会 得到 64个 
特征 上 一层 的 输出 是 32个 特征 作为 下 
一层 的 输入 W _ conv2 = weight _ variable 
5 5 32 64 b _ conv2 = bias _ 
variable 64 h _ conv2 = tf . nn . 
relu conv2d h _ pool1 W _ conv2 + b 
_ conv2 h _ pool2 = max _ pool _ 
2x2 h _ conv2 5 . 密集 连接 层 现在 
图片尺寸 减小 到 7x7 我们/r 加入/v 一个/m 有/v 1024个/mq 神经元/nz 
的/uj 全/a 连接/v 层/q 用于 处理 整个 图片 我们/r 把/p 
池化层/nr 输出/v 的/uj 张量/nr reshape/w 成/n 一些/m 向量/n 乘上 权重 
矩阵 加上 偏置 然后 对 其 使用 ReLUW _ fc1 
= weight _ variable 7 * 7 * 64 1024 
b _ fc1 = bias _ variable 1024 h _ 
pool2 _ flat = tf . reshape h _ pool2 
1 7 * 7 * 64 h _ fc1 = 
tf . nn . relu tf . matmul h _ 
pool2 _ flat W _ fc1 + b _ fc1 
6 . Dropout 为了 减少 过拟合 我们 在 输出 层 
之前 加入 dropout 我们 用 一个 placeholder 来 代表 一个 
神经元 的 输出 在 dropout 中 保持 不变 的 概率 
这样 我们 可以 在 训练 过程 中 启用 dropout 在 
测试过程 中 关闭 dropout TensorFlow 的 tf . nn . 
dropout 操作 除了 可以 屏蔽 神经元 的 输出 外 还会 
自动 处理 神经元 输出 值 的 scale 所以 用 dropout 
的 时候 可以 不用 考虑 scale keep _ prob = 
tf . placeholder float h _ fc1 _ drop = 
tf . nn . dropout h _ fc1 keep _ 
prob 7 . 输出 层 最后 我们 添加 一个 softmax 
层 就像 前面 的 单层 softmax regression 一样 W _ 
fc2 = weight _ variable 1024 10 b _ fc2 
= bias _ variable 10 y _ conv = tf 
. nn . softmax tf . matmul h _ fc1 
_ drop W _ fc2 + b _ fc2 注意 
这里 和 softmax regression 的 区别 在于 softmax regression 的 
输入 维度 是 图像 像素 的 768 维 而 该 
网络 的 输入 是 卷积 后的/nr 1024 高维空间 后者/n 抽象/v 
度/zg 更好/d 8/m ./i  /i 训练/vn 和/c 评估/vn 模型/n 为了/p 
进行/v 训练/vn 和/c 评估/vn 我们 使用 与 之前 简单 的 
单层 SoftMax 神经网络 模型 几乎 相同 的 一套 代码 只是 
我们 会 用 更加 复杂 的 ADAM 优 化器 来做 
梯度 最速 下降 在 feed _ dict 中 加入 额外 
的 参数 keep _ prob 来 控制 dropout 比例 然后 
每 100次 迭代 输出 一次 日志 cross _ entropy = 
tf . reduce _ sum y _ * tf . 
log y _ conv train _ step = tf . 
train . AdamOptimizer 1e 4 . minimize cross _ entropy 
correct _ prediction = tf . equal tf . argmax 
y _ conv 1 tf . argmax y _ 1 
accuracy = tf . reduce _ mean tf . cast 
correct _ prediction float sess . run tf . initialize 
_ all _ variables for i in range 20000 batch 
= mnist . train . next _ batch 50 if 
i % 100 = = 0 train _ accuracy = 
accuracy . eval feed _ dict = { x batch 
0 y _ batch 1 keep _ prob 1.0 } 
print step % d training accuracy % g % i 
train _ accuracy train _ step . run feed _ 
dict = { x batch 0 y _ batch 1 
keep _ prob 0.5 } print test accuracy % g 
% accuracy . eval feed _ dict = { x 
mnist . test . images y _ mnist . test 
. labels keep _ prob 1.0 } 9 .   
tensorflow deep _ convolution . pyimport input _ data mnist 
= input _ data . read _ data _ sets 
MNIST _ data / one _ hot = True import 
tensorflow as tf def weight _ variable shape initial = 
tf . truncated _ normal shape stddev = 0.1 return 
tf . Variable initial def bias _ variable shape initial 
= tf . constant 0.1 shape = shape return tf 
. Variable initial def conv2d x W return tf . 
nn . conv2d x W strides = 1 1 1 
1 padding = SAME def max _ pool _ 2x2 
x return tf . nn . max _ pool x 
ksize = 1 2 2 1 strides = 1 2 
2 1 padding = SAME sess = tf . I 
n t e r a c t i v e 
e s s i o n x = tf . 
placeholder float shape = None 784 y _ = tf 
. placeholder float shape = None 10 W _ conv1 
= weight _ variable 5 5 1 32 b _ 
conv1 = bias _ variable 32 x _ image = 
tf . reshape x 1 28 28 1 h _ 
conv1 = tf . nn . relu conv2d x _ 
image W _ conv1 + b _ conv1 h _ 
pool1 = max _ pool _ 2x2 h _ conv1 
W _ conv2 = weight _ variable 5 5 32 
64 b _ conv2 = bias _ variable 64 h 
_ conv2 = tf . nn . relu conv2d h 
_ pool1 W _ conv2 + b _ conv2 h 
_ pool2 = max _ pool _ 2x2 h _ 
conv2 W _ fc1 = weight _ variable 7 * 
7 * 64 1024 b _ fc1 = bias _ 
variable 1024 h _ pool2 _ flat = tf . 
reshape h _ pool2 1 7 * 7 * 64 
h _ fc1 = tf . nn . relu tf 
. matmul h _ pool2 _ flat W _ fc1 
+ b _ fc1 keep _ prob = tf . 
placeholder float h _ fc1 _ drop = tf . 
nn . dropout h _ fc1 keep _ prob W 
_ fc2 = weight _ variable 1024 10 b _ 
fc2 = bias _ variable 10 y _ conv = 
tf . nn . softmax tf . matmul h _ 
fc1 _ drop W _ fc2 + b _ fc2 
cross _ entropy = tf . reduce _ sum y 
_ * tf . log y _ conv train _ 
step = tf . train . AdamOptimizer 1e 4 . 
minimize cross _ entropy correct _ prediction = tf . 
equal tf . argmax y _ conv 1 tf . 
argmax y _ 1 accuracy = tf . reduce _ 
mean tf . cast correct _ prediction float tf . 
summary . scalar Training error cross _ entropy tf . 
summary . scalar Training accuracy accuracy tf . summary . 
scalar sparsity tf . nn . zero _ fraction h 
_ fc1 sess . run tf . global _ variables 
_ initializer merged _ summary _ op = tf . 
summary . merge _ all print merged _ summary _ 
op summary _ writer = tf . summary . FileWriter 
. / mnist _ logs sess . graph for i 
in range 20000 batch = mnist . train . next 
_ batch 50 sess . run train _ step feed 
_ dict = { x batch 0 y _ batch 
1 keep _ prob 0.5 } if i % 100 
= = 0 train _ accuracy = accuracy . eval 
feed _ dict = { x batch 0 y _ 
batch 1 keep _ prob 1.0 } print step % 
d training accuracy % g % i train _ accuracy 
summary _ str = sess . run merged _ summary 
_ op feed _ dict = { x batch 0 
y _ batch 1 keep _ prob 0.5 } summary 
_ writer . add _ summary summary _ str i 
print test accuracy % g % accuracy . eval feed 
_ dict = { x mnist . test . images 
y _ mnist . test . labels keep _ prob 
1.0 } 0x2 前馈 神经网络 feed forward neural network full 
connected MINST1 . 构建 图表 Build the Graph 在为 数据 
创建 占位符 之后 就 可以 运行 mnist . py 文件 
经过 三 阶段 的 模式 函数 操作 inference   loss 
和 training 图表 就 构建 完成 了 1 . inference 
尽可能 地 构建 好 图表 满足 促使 神经网络 向前 反馈 
并 做出 预测 的 要求 2 . loss 往 inference 
图表 中 添加 生成 损失 loss 所 需要 的 操作 
ops 3 . training 往 损失 图表 中 添加 计算 
并 应用 梯度 gradients 所需 的 操作 推理 Inference inference 
函数 会 尽可能 地 构建 图表 做到 返回 包含 了 
预测 结果 output prediction 的 Tensor 它 接受 图像 占位符 
为 输入 在此 基础 上 借助 ReLu Rectified Linear Units 
激活 函数 构建 一对 完全 连接 层 layers 以及 一个 
有着 十个 节点 node 指明 了 输出 logtis 模型 的 
线性 层 每/zg 一层/m 都/d 创建/v 于/p 一个/m 唯一/b 的/uj 
tf/w ./i name/w _/i scope/w 之下/f 创建/v 于该/nr 作用域/n 之下/f 
的/uj 所有/b 元素/n 都/d 将带/i 有其/i 前缀/v with tf . 
name _ scope hidden1 as scope 在 定义 的 作用 
域中 每 一层 所 使用 的 权重 和 偏差 都在 
tf . Variable 实例 中 生成 并且 包含 了 各自 
期望 的 shapeweights = tf . Variable tf . truncated 
_ normal IMAGE _ PIXELS hidden1 _ units stddev = 
1.0 / math . sqrt float IMAGE _ PIXELS name 
= weights biases = tf . Variable tf . zeros 
hidden1 _ units name = biases 例如 当 这些 层 
是 在 hidden1 作用域 下 生成 时 赋予 权重 变量 
的 独特 名称 将会 是 hidden1 / weights 每个 变量 
在 构建 时 都会 获得 初始化 操作 initializer ops 在 
这种 最 常见 的 情况 下 通过 tf . truncated 
_ normal 函数 初始化 权重 变量 给 赋予 的 shape 
则是 一个二维 tensor 其中 第一 个 维度 代表 该 层 
中 权重 变量 所 连接 connect from 的 单元 数量 
第二 个 维度 代表 该 层 中 权重 变量 所 
连 接到 的 connect to 单元 数量 对于 名叫 hidden1 
的 第一 层 相应 的 维度 则是 IMAGE _ PIXELS 
hidden1 _ units 显然 第一层 的 输入 是 图像 像素 
维度 因为 权重 变量 将 图像 输入 连接 到了 hidden1 
层 tf . truncated _ normal 初始 函数 将 根据 
所 得到 的 均值 和 标准差 生成 一个 随机分布 然后 
通过 tf . zeros 函数 初始化 偏差 变量 biases 确保 
所有 偏差 的 起始值 都是 0 而 它们 的 shape 
则是 其 在 该 层 中所 接到 的 connect to 
单元 数量 图表 的 三个 主要 操作 分别 是 两个 
tf . nn . relu 操作 它们 中 嵌入 了 
隐藏 层 所需 的 tf . matmul 以及 logits 模型 
所需 的 另外 一个 tf . matmul 三者 依次 生成 
各自 的 tf . Variable 实例 则 与 输入 占位符 
或 下 一层 的 输出 tensor 所 连接 hidden1 = 
tf . nn . relu tf . matmul images weights 
+ biases hidden2 = tf . nn . relu tf 
. matmul hidden1 weights + biases logits = tf . 
matmul hidden2 weights + biases 最后 程序 会 返回 包含 
了 输出 结果 的 logitsTensor 损失 Loss loss 函数 通过 
添加 所需 的 损失 操作 进一步 构建 图表 首先 labels 
_ placeholer 中的 值 将被 编码 为 一个 含有 1 
hot values 的 Tensor 例如 如 果类 标识符 为 3 
那么 该 值 就会 被 转换 为 0 0 0 
1 0 0 0 0 0 0 codebatch _ size 
= tf . size labels labels = tf . expand 
_ dims labels 1 indices = tf . expand _ 
dims tf . range 0 batch _ size 1 1 
concated = tf . concat 1 indices labels onehot _ 
labels = tf . sparse _ to _ dense concated 
tf . pack batch _ size NUM _ CLASSES 1.0 
0.0 之后 又 添加 一个 tf . nn . softmax 
_ cross _ entropy _ with _ logits 操作 用来 
比较 inference 函数 与 1 hot 标签 所 输出 的 
logits Tensor cross _ entropy = tf . nn . 
softmax _ cross _ entropy _ with _ logits logits 
onehot _ labels name = xentropy 然后 使用 tf . 
reduce _ mean 函数 计算 batch 维度 第一 维度 下 
交叉 熵 cross entropy 的 平均值 将 将该 值 作为 
总 损失 loss = tf . reduce _ mean cross 
_ entropy name = xentropy _ mean 最后 程序 会 
返回 包含 了 损失 值 的 Tensor 注意 交叉 熵 
是 信息 理论 中 的 概念 可以 让 我们 描述 
如果 基于 已有 事实 相信 神经网络 所做 的 推测 最坏 
会 导致 什么 结果 训练 training 函数 添加 了 通过 
梯度 下降 gradient descent 将 损失 最小化 所需 的 操作 
首先 该 函数 从 loss 函数 中 获取 损失 Tensor 
将其 交给 tf . scalar _ summary 后者 在与 SummaryWriter 
见下文 配合 使用 时 可以向 事件 文件 events file 中 
生成 汇 总值 summary values 在 实验 中 每次 写入 
汇 总值 时 它 都会 释放 损失 Tensor 的 当前 
值 snapshot value tf . scalar _ summary loss . 
op . name loss 接下来 我们 实例 化 一个 tf 
. train . G r a d i e n 
t D e s c e n t O p 
t i m i z e r 负责 按照 所 
要求 的 学习 效率 learning rate 应用 梯度 下 降法 
gradients optimizer = tf . train . G r a 
d i e n t D e s c e 
n t O p t i m i z e 
r FLAGS . learning _ rate 之后 我们 生成 一个 
变量 用于 保存 全局 训练 步骤 global training step 的 
数值 并 使用 minimize 函数 更新 系统 中 的 三角 
权重 triangle weights 增加 全局 步骤 的 操作 根据 惯例 
这个 操作 被称为 train _ op 是 TensorFlow 会话 session 
诱发 一个 完整 训练 步骤 所 必须 运行 的 操作 
global _ step = tf . Variable 0 name = 
global _ step trainable = False train _ op = 
optimizer . minimize loss global _ step = global _ 
step 最后 程序 返回 包含 了 训练 操作 training op 
输出 结果 的 Tensor2 . 训练 模型 一旦 图表 构建 
完毕 就 通过 fully _ connected _ feed . py 
文件 中 的 用户 代码 进行 循环 地 迭代 式 
训练 和 评估 3 . 训练 循环 完成 会 话中 
变量 的 初始化 之后 就 可以 开始 训练 了 训练 
的 每一步 都是/nr 通过 用户 代码 控制 而 能 实现 
有效 训练 的 最简单 循环 就是 for step in xrange 
max _ steps sess . run train _ op 向 
图表 提供 反馈 根据 误差 逐级 传递 执行 每一步 时 
我们 的 代码 会 生成 一个 反馈 字典 feed dictionary 
其中 包含 对应 步骤 中 训练所 要 使用 的 例子 
这些 例子 的 哈希 键 就是 其 所 代表 的 
占位符 操作 fill _ feed _ dict 函数 会 查询 
给定 的 DataSet 索要 下 一批 次 batch _ size 
的 图像 和 标签 与/p 占位符/i 相/v 匹配/v 的/uj Tensor/w 
则会/i 包含/v 下一/i 批次/d 的/uj 图像/n 和/c 标签/n images _ 
feed labels _ feed = data _ set . next 
_ batch FLAGS . batch _ size 然后 以 占位符 
为 哈希 键 创建 一个 Python 字典 对象 键值 则是 
其 代表 的 反馈 Tensorfeed _ dict = { images 
_ placeholder images _ feed labels _ placeholder labels _ 
feed } 这个 字典 随后 作为 feed _ dict 参数 
传入 sess . run 函数 中 为 这 一步 的 
训练 提供 输入 样例 这里 简单 理解 一下 前 向 
反馈 前馈 就是 信号 向前 传递 的 意思 BP 网络 
的 前馈 表现 为 输入 信号 从 输入 层 输入 
层 不参加 计算 开始 每 一层 的 神经 元 计算 
出 该 层 各 神经元 的 输出 并向 下一层 传递 
直到 输出 层 计算 出 网络 的 输出 结果 前馈 
只是 用于 计算 出 网络 的 输出 不对 网络 的 
参数 进行 调整 误差/n 反向/v 传播/vn 用于/v 训练/vn 时/n 网络/n 
权值/i 和/c 阈值/n 的/uj 调整/vn 网络 前 向 传播 计算 
出来 的 结果 与 实际 的 结果 存在 误差 在 
离线 训练 时 这时 网络 采用 批量 训练 方法 计算 
出 整个 样本数据 的 总 误差 然后/c 从/p 输出/v 层/q 
开始/v 向/p 前推/i 一般 采用 梯度 下 降法 逐层 求出 
每 一层 神经元 的 阈值 和 权值 的 调 增量 
循环 迭代 到 网络 参数 符合 要求 停止 检查 状态 
在 运行 sess . run 函数 时 要在 代码 中 
明确 其 需要 获取 的 两个 值 train _ op 
loss for step in xrange FLAGS . max _ steps 
feed _ dict = fill _ feed _ dict data 
_ sets . train images _ placeholder labels _ placeholder 
_ loss _ value = sess . run train _ 
op loss feed _ dict = feed _ dict 因为 
要 获取 这 两个 值 sess . run 会 返回 
一个 有 两个 元素 的 元组 其中 每 一个 Tensor 
对象 对应 了 返回 的 元组 中的 numpy 数组 而 
这些 数组 中 包含 了 当前 这步 训练 中 对应 
Tensor 的 值 由于 train _ op 并 不会 产生 
输出 其 在 返回 的 元祖 中的 对应 元素 就是 
None 所以会 被 抛弃 但是 如果 模型 在 训练 中 
出现 偏差 loss Tensor 的 值 可能 会 变成 NaN 
所以 我们 要 获取 它 的 值 并 记录 下来 
假设 训练 一切正常 没有 出现 NaN 训练 循环 会 每隔 
100个 训练 步骤 就 打印 一行 简单 的 状态 文本 
告知 用户 当前 的 训练 状态 if step % 100 
= = 0 print Step % d loss = % 
. 2f % . 3f sec % step loss _ 
value duration 状态 可视化 为了 释放 TensorBoard 所 使用 的 
事件 文件 events file 所有 的 即时 数据 在 这里 
只有 一个 都 要在 图表 构建 阶段 合并 至 一个 
操作 op 中 summary _ op = tf . merge 
_ all _ summaries 在 创建 好 会话 session 之后 
可以 实例 化 一个 tf . train . SummaryWriter 用于 
写入 包含 了 图表 本身 和 即时 数据 具体 值 
的 事件 文件 summary _ writer = tf . train 
. SummaryWriter FLAGS . train _ dir graph _ def 
= sess . graph _ def 最后 每次 运行 summary 
_ op 时 都会 往 事件 文件 中 写入 最新 
的 即时 数据 函数 的 输出 会 传入 事件 文件 
读写器 writer 的 add _ summary 函数 summary _ str 
= sess . run summary _ op feed _ dict 
= feed _ dict summary _ writer . add _ 
summary summary _ str step 事件 文件 写入 完毕 之后 
可以 就 训练 文件夹 打开 一个 TensorBoard 查看 即时 数据 
的 情况 保存 检查点 checkpoint 为了 得到 可以 用来 后续 
恢复 模型 以 进一步 训练 或 评估 的 检查 点 
文件 checkpoint file 我们 实例 化 一个 tf . train 
. Saversaver = tf . train . Saver 在 训练 
循环 中 将 定期 调用 saver . save 方法 向 
训练 文件夹 中 写入 包含 了 当前 所 有可 训练 
变量 值得 检查点 文件 saver . save sess FLAGS . 
train _ dir global _ step = step 这样 我们 
以后 就 可以 使用 saver . restore 方法 重载 模型 
的 参数 继续 训练 saver . restore sess FLAGS . 
train _ dir 4 . 评估 模型 每隔 一千个 训练 
步骤 我们 的 代码 会 尝试 使用 训练 数据集 与 
测试 数据集 对模型 进行 评估 do _ eval 函数 会被 
调用 三次 分别 使用 训练 数据集 验证 数据 集合 测试 
数据集 print Training Data Eval do _ eval sess eval 
_ correct images _ placeholder labels _ placeholder data _ 
sets . train print Validation Data Eval do _ eval 
sess eval _ correct images _ placeholder labels _ placeholder 
data _ sets . validation print Test Data Eval do 
_ eval sess eval _ correct images _ placeholder labels 
_ placeholder data _ sets . test 5 . fully 
_ connected _ feed . py # Copyright 2015 The 
TensorFlow Authors . All Rights Reserved . # # Licensed 
under the Apache License Version 2.0 the License # you 
may not use this file except in compliance with the 
License . # You may obtain a copy of the 
License at # # http / / www . apache 
. org / licenses / LICENSE 2.0 # # Unless 
required by applicable law or agreed to in writing software 
# distributed under the License is distributed on an AS 
IS BASIS # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND 
either express or implied . # See the License for 
the specific language governing permissions and # limitations under the 
License . # = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= Trains and Evaluates the MNIST network using a feed 
dictionary . from _ _ future _ _ import absolute 
_ import from _ _ future _ _ import division 
from _ _ future _ _ import print _ function 
# pylint disable = missing docstring import argparse import os 
. path import sys import time from six . moves 
import xrange # pylint disable = redefined builtin import tensorflow 
as tf from tensorflow . examples . tutorials . mnist 
import input _ data from tensorflow . examples . tutorials 
. mnist import mnist # Basic model parameters as external 
flags . FLAGS = None def placeholder _ inputs batch 
_ size Generate placeholder variables to represent the input tensors 
. These placeholders are used as inputs by the rest 
of the model building code and will be fed from 
the downloaded data in the . run loop below . 
Args batch _ size The batch size will be baked 
into both placeholders . Returns images _ placeholder Images placeholder 
. labels _ placeholder Labels placeholder . # Note that 
the shapes of the placeholders match the shapes of the 
full # image and label tensors except the first dimension 
is now batch _ size # rather than the full 
size of the train or test data sets . images 
_ placeholder = tf . placeholder tf . float32 shape 
= batch _ size mnist . IMAGE _ PIXELS labels 
_ placeholder = tf . placeholder tf . int32 shape 
= batch _ size return images _ placeholder labels _ 
placeholder def fill _ feed _ dict data _ set 
images _ pl labels _ pl Fills the feed _ 
dict for training the given step . A feed _ 
dict takes the form of feed _ dict = { 
placeholder tensor of values to be passed for placeholder . 
. . . } Args data _ set The set 
of images and labels from input _ data . read 
_ data _ sets images _ pl The images placeholder 
from placeholder _ inputs . labels _ pl The labels 
placeholder from placeholder _ inputs . Returns feed _ dict 
The feed dictionary mapping from placeholders to values . # 
Create the feed _ dict for the placeholders filled with 
the next # ` batch size ` examples . images 
_ feed labels _ feed = data _ set . 
next _ batch FLAGS . batch _ size FLAGS . 
fake _ data feed _ dict = { images _ 
pl images _ feed labels _ pl labels _ feed 
} return feed _ dict def do _ eval sess 
eval _ correct images _ placeholder labels _ placeholder data 
_ set Runs one evaluation against the full epoch of 
data . Args sess The session in which the model 
has been trained . eval _ correct The Tensor that 
returns the number of correct predictions . images _ placeholder 
The images placeholder . labels _ placeholder The labels placeholder 
. data _ set The set of images and labels 
to evaluate from input _ data . read _ data 
_ sets . # And run one epoch of eval 
. true _ count = 0 # Counts the number 
of correct predictions . steps _ per _ epoch = 
data _ set . num _ examples / / FLAGS 
. batch _ size num _ examples = steps _ 
per _ epoch * FLAGS . batch _ size for 
step in xrange steps _ per _ epoch feed _ 
dict = fill _ feed _ dict data _ set 
images _ placeholder labels _ placeholder true _ count + 
= sess . run eval _ correct feed _ dict 
= feed _ dict precision = float true _ count 
/ num _ examples print Num examples % d Num 
correct % d Precision @ 1 % 0.04 f % 
num _ examples true _ count precision def run _ 
training Train MNIST for a number of steps . # 
Get the sets of images and labels for training validation 
and # test on MNIST . data _ sets = 
input _ data . read _ data _ sets FLAGS 
. input _ data _ dir FLAGS . fake _ 
data # Tell TensorFlow that the model will be built 
into the default Graph . with tf . Graph . 
as _ default # Generate placeholders for the images and 
labels . images _ placeholder labels _ placeholder = placeholder 
_ inputs FLAGS . batch _ size # Build a 
Graph that computes predictions from the inference model . logits 
= mnist . inference images _ placeholder FLAGS . hidden1 
FLAGS . hidden2 # Add to the Graph the Ops 
for loss calculation . loss = mnist . loss logits 
labels _ placeholder # Add to the Graph the Ops 
that calculate and apply gradients . train _ op = 
mnist . training loss FLAGS . learning _ rate # 
Add the Op to compare the logits to the labels 
during evaluation . eval _ correct = mnist . evaluation 
logits labels _ placeholder # Build the summary Tensor based 
on the TF collection of Summaries . summary = tf 
. summary . merge _ all # Add the variable 
initializer Op . init = tf . global _ variables 
_ initializer # Create a saver for writing training checkpoints 
. saver = tf . train . Saver # Create 
a session for running Ops on the Graph . sess 
= tf . Session # Instantiate a SummaryWriter to output 
summaries and the Graph . summary _ writer = tf 
. summary . FileWriter FLAGS . log _ dir sess 
. graph # And then after everything is built # 
Run the Op to initialize the variables . sess . 
run init # Start the training loop . for step 
in xrange FLAGS . max _ steps start _ time 
= time . time # Fill a feed dictionary with 
the actual set of images and labels # for this 
particular training step . feed _ dict = fill _ 
feed _ dict data _ sets . train images _ 
placeholder labels _ placeholder # Run one step of the 
model . The return values are the activations # from 
the ` train _ op ` which is discarded and 
the ` loss ` Op . To # inspect the 
values of your Ops or variables you may include them 
# in the list passed to sess . run and 
the value tensors will be # returned in the tuple 
from the call . _ loss _ value = sess 
. run train _ op loss feed _ dict = 
feed _ dict duration = time . time start _ 
time # Write the summaries and print an overview fairly 
often . if step % 100 = = 0 # 
Print status to stdout . print Step % d loss 
= % . 2f % . 3f sec % step 
loss _ value duration # Update the events file . 
summary _ str = sess . run summary feed _ 
dict = feed _ dict summary _ writer . add 
_ summary summary _ str step summary _ writer . 
flush # Save a checkpoint and evaluate the model periodically 
. if step + 1 % 1000 = = 0 
or step + 1 = = FLAGS . max _ 
steps checkpoint _ file = os . path . join 
FLAGS . log _ dir model . ckpt saver . 
save sess checkpoint _ file global _ step = step 
# Evaluate against the training set . print Training Data 
Eval do _ eval sess eval _ correct images _ 
placeholder labels _ placeholder data _ sets . train # 
Evaluate against the validation set . print Validation Data Eval 
do _ eval sess eval _ correct images _ placeholder 
labels _ placeholder data _ sets . validation # Evaluate 
against the test set . print Test Data Eval do 
_ eval sess eval _ correct images _ placeholder labels 
_ placeholder data _ sets . test def main _ 
if tf . gfile . Exists FLAGS . log _ 
dir tf . gfile . D e l e t 
e R e c u r s i v e 
l y FLAGS . log _ dir tf . gfile 
. MakeDirs FLAGS . log _ dir run _ training 
if _ _ name _ _ = = _ _ 
main _ _ parser = argparse . ArgumentParser parser . 
add _ argument learning _ rate type = float default 
= 0.01 help = Initial learning rate . parser . 
add _ argument max _ steps type = int default 
= 20000 help = Number of steps to run trainer 
. parser . add _ argument hidden1 type = int 
default = 128 help = Number of units in hidden 
layer 1 . parser . add _ argument hidden2 type 
= int default = 32 help = Number of units 
in hidden layer 2 . parser . add _ argument 
batch _ size type = int default = 100 help 
= Batch size . Must divide evenly into the dataset 
sizes . parser . add _ argument input _ data 
_ dir type = str default = MNIST _ data 
/ help = Directory to put the input data . 
parser . add _ argument log _ dir type = 
str default = . / mnist _ logs help = 
Directory to put the log data . parser . add 
_ argument fake _ data default = False help = 
If true uses fake data for unit testing . action 
= store _ true FLAGS unparsed = parser . parse 
_ known _ args tf . app . run main 
= main argv = sys . argv 0 + unparsed 
Relevant Link http / / www . tensorfly . cn 
/ tfdoc / tutorials / mnist _ pros . html 
http / / www . tensorfly . cn / tfdoc 
/ tutorials / mnist _ tf . html4 . 卷积 
神经网络 CIFAR 10 数据集 分类 将 像素 空间 通 卷积 
扩展到 高维空间 输入 CNN 进行 计算 对 CIFAR 10 数据集 
的 分类 是 机器 学习 中 一个 公开 的 基准测试 
问题 其 任务 是 对 一组 32x32RGB 的 图像 进行 
分类 这些 图像 涵盖 了 10个 类别 飞机 汽车 鸟 
猫 鹿 狗 青蛙 马 船 以及 卡车 0x1 模型 
架构 本 教程 中的 模型 是 一个 多层 架构 由 
卷积 层 和 非线性 层 nonlinearities 交替 多次 排列 后 
构成 这些 层 最终 通过 全 连通 层 对 接到 
softmax 分类器 上 1 . 模型 输入 输入 模型 是 
通过 inputs 和 distorted _ inputs 函数 建立 起来 的 
这 2个 函数 会 从 CIFAR 10 二进制 文件 中 
读取 图片 文件 由于 每个 图片 的 存储 字节数 是 
固定 的 因此 可以 使用 tf . F i x 
e d L e n g t h R e 
c o r d R e a d e r 
函数 图片 文件 的 处理 流程 如下 图片 会被 统一 
裁 剪到 24x24 像素 大小 裁剪 中央 区域 用于 评估 
或 随机 裁剪 用于 训练 图片 会 进行 近似 的 
白化 处理 使得 模型 对 图片 的 动态 范围 变化 
不 敏感 让 识别 模型 对 图像 的 亮度 等 
因素 不 敏感 对于 训练 我们 另外 采取 了 一系列 
随机 变换 的 方法 来 人为 的 增加 数据集 的 
大小 对 图像 进行 随机 的 左右 翻转 随机 变换 
图像 的 亮度 随机 变换 图像 的 对比度 2 . 
模型 预测模型 的 预测 流程 由 inference 构造 该 函数 
会 添加 必要 的 操作 步骤 用于 计算 预测值 的 
  logits 其 对应 的 模型 组织 方式 如下 所示 
conv1 实现 卷积 以及 rectified linear activation . pool1 max 
pooling . norm1 局部 响应 归一化 . conv2 卷积 and 
rectified linear activation . norm2 局部 响应 归一化 . pool2 
max pooling . local3 基于 修正 线性 激活 的 全 
连接 层 . local4 基于 修正 线性 激活 的 全 
连接 层 . softmax _ linear 进行 线性变换 以 输出 
logits . 0x2 模型 训练 训练 一个 可 进行 N 
维 分类 的 网络 的 常用 方法 是 使用 多项式 
逻辑 回归 又被 叫做 softmax 回归 Softmax 回归 在 网络 
的 输出 层 上 附加 了 一个 softmax nonlinearity 并且 
计算 归一化 的 预测 值 和 label 的 1 hot 
encoding 的 交叉 熵 在 正则化 过程 中 我们 会 
对 所有 学习 变量 应用 权重 衰减 损失 和 手写 
文字 识别 类似 图像 识别 的 本质 就是 对应 某个 
形状 的 物理 对 应该 区域 的 权重 相应 较高 
这 也是 人 识别 图像 甚至 畸形 图像 的 本质 
道理 模型/n 的/uj 目标/n 函数/n 是/v 求/v 交叉/n 熵/g 损失/n 
和/c 所有/b 权重/n 衰减/v 项的和/nr loss 函数 的 返回值 就是 
这个 值 train 函数 会 添加 一些 操作 使得 目标函数 
最小化 这些 操作 包括 计算 梯度 更新 学习 变量 G 
r a d i e n t D e s 
c e n t O p t i m i 
z e r train 函数 最终 会 返回 一个 用 
以对 一批 图像 执行 所有 计算 的 操作 步骤 以便 
训练 并 更新 模型 0x3 开始 执行 并 训练 模型 
cifar10 _ train . py 输出 的 终端 信息 中 
提供 了 关于 模型 如何 训练 的 一些 信息 比如 
损失 是 真的 在 减小 还是 看到 的 只是 噪声 
数据 为 模型 提供 的 图片 是否 合适 梯度 激活 
权重 的 值 是否 合理 当前 的 学习 率 是 
多少 相比 于总/nr 损失 在 训练 过程 中 的 单项 
损失 尤其 值得 人们 的 注意 但是 由于 训练 中 
使用 的 数据 批量 比较 小 损失 值 中 夹杂 
了 相当多 的 噪声 在 实践 过程 中 我们 也 
发现 相比 于 原始 值 损失 值 的 移动 平均值 
显得 更为 有意义 cifar10 . py # Copyright 2015 Google 
Inc . All Rights Reserved . # # Licensed under 
the Apache License Version 2.0 the License # you may 
not use this file except in compliance with the License 
. # You may obtain a copy of the License 
at # # http / / www . apache . 
org / licenses / LICENSE 2.0 # # Unless required 
by applicable law or agreed to in writing software # 
distributed under the License is distributed on an AS IS 
BASIS # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either 
express or implied . # See the License for the 
specific language governing permissions and # limitations under the License 
. # = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
Builds the CIFAR 10 network . Summary of available functions 
# Compute input images and labels for training . If 
you would like to run # evaluations use inputs instead 
. inputs labels = distorted _ inputs # Compute inference 
on the model inputs to make a prediction . predictions 
= inference inputs # Compute the total loss of the 
prediction with respect to the labels . loss = loss 
predictions labels # Create a graph to run one step 
of training with respect to the loss . train _ 
op = train loss global _ step # pylint disable 
= missing docstring from _ _ future _ _ import 
absolute _ import from _ _ future _ _ import 
division from _ _ future _ _ import print _ 
function import gzip import os import re import sys import 
tarfile from six . moves import urllib import tensorflow as 
tf import cifar10 _ input FLAGS = tf . app 
. flags . FLAGS # Basic model parameters . tf 
. app . flags . DEFINE _ integer batch _ 
size 128 Number of images to process in a batch 
. tf . app . flags . DEFINE _ string 
data _ dir . / cifar10 _ data Path to 
the CIFAR 10 data directory . # Global constants describing 
the CIFAR 10 data set . IMAGE _ SIZE = 
cifar10 _ input . IMAGE _ SIZE NUM _ CLASSES 
= cifar10 _ input . NUM _ CLASSES NUM _ 
EXAMPLES _ PER _ EPOCH _ FOR _ TRAIN = 
cifar10 _ input . NUM _ EXAMPLES _ PER _ 
EPOCH _ FOR _ TRAIN NUM _ EXAMPLES _ PER 
_ EPOCH _ FOR _ EVAL = cifar10 _ input 
. NUM _ EXAMPLES _ PER _ EPOCH _ FOR 
_ EVAL # Constants describing the training process . MOVING 
_ AVERAGE _ DECAY = 0.9999 # The decay to 
use for the moving average . NUM _ EPOCHS _ 
PER _ DECAY = 350.0 # Epochs after which learning 
rate decays . LEARNING _ RATE _ DECAY _ FACTOR 
= 0.1 # Learning rate decay factor . INITIAL _ 
LEARNING _ RATE = 0.1 # Initial learning rate . 
# If a model is trained with multiple GPU s 
prefix all Op names with tower _ name # to 
differentiate the operations . Note that this prefix is removed 
from the # names of the summaries when visualizing a 
model . TOWER _ NAME = tower DATA _ URL 
= http / / www . cs . toronto . 
edu / ~ kriz / cifar 10 binary . tar 
. gz def _ activation _ summary x Helper to 
create summaries for activations . Creates a summary that provides 
a histogram of activations . Creates a summary that measure 
the sparsity of activations . Args x Tensor Returns nothing 
# Remove tower _ 0 9 / from the name 
in case this is a multi GPU training # session 
. This helps the clarity of presentation on tensorboard . 
tensor _ name = re . sub % s _ 
0 9 * / % TOWER _ NAME x . 
op . name tf . summary . histogram tensor _ 
name + / activations x tf . summary . scalar 
tensor _ name + / sparsity tf . nn . 
zero _ fraction x def _ variable _ on _ 
cpu name shape initializer Helper to create a Variable stored 
on CPU memory . Args name name of the variable 
shape list of ints initializer initializer for Variable Returns Variable 
Tensor with tf . device / cpu 0 var = 
tf . get _ variable name shape initializer = initializer 
return var def _ variable _ with _ weight _ 
decay name shape stddev wd Helper to create an initialized 
Variable with weight decay . Note that the Variable is 
initialized with a truncated normal distribution . A weight decay 
is added only if one is specified . Args name 
name of the variable shape list of ints stddev standard 
deviation of a truncated Gaussian wd add L2Loss weight decay 
multiplied by this float . If None weight decay is 
not added for this Variable . Returns Variable Tensor var 
= _ variable _ on _ cpu name shape tf 
. truncated _ normal _ initializer stddev = stddev if 
wd weight _ decay = tf . multiply tf . 
nn . l2 _ loss var wd name = weight 
_ loss tf . add _ to _ collection losses 
weight _ decay return var def distorted _ inputs Construct 
distorted input for CIFAR training using the Reader ops . 
Returns images Images . 4D tensor of batch _ size 
IMAGE _ SIZE IMAGE _ SIZE 3 size . labels 
Labels . 1D tensor of batch _ size size . 
Raises ValueError If no data _ dir if not FLAGS 
. data _ dir raise ValueError Please supply a data 
_ dir data _ dir = os . path . 
join FLAGS . data _ dir cifar 10 batches bin 
return cifar10 _ input . distorted _ inputs data _ 
dir = data _ dir batch _ size = FLAGS 
. batch _ size def inputs eval _ data Construct 
input for CIFAR evaluation using the Reader ops . Args 
eval _ data bool indicating if one should use the 
train or eval data set . Returns images Images . 
4D tensor of batch _ size IMAGE _ SIZE IMAGE 
_ SIZE 3 size . labels Labels . 1D tensor 
of batch _ size size . Raises ValueError If no 
data _ dir if not FLAGS . data _ dir 
raise ValueError Please supply a data _ dir data _ 
dir = os . path . join FLAGS . data 
_ dir cifar 10 batches bin return cifar10 _ input 
. inputs eval _ data = eval _ data data 
_ dir = data _ dir batch _ size = 
FLAGS . batch _ size def inference images Build the 
CIFAR 10 model . Args images Images returned from distorted 
_ inputs or inputs . Returns Logits . # We 
instantiate all variables using tf . get _ variable instead 
of # tf . Variable in order to share variables 
across multiple GPU training runs . # If we only 
ran this model on a single GPU we could simplify 
this function # by replacing all instances of tf . 
get _ variable with tf . Variable . # # 
conv1 with tf . variable _ scope conv1 as scope 
kernel = _ variable _ with _ weight _ decay 
weights shape = 5 5 3 64 stddev = 1e 
4 wd = 0.0 conv = tf . nn . 
conv2d images kernel 1 1 1 1 padding = SAME 
biases = _ variable _ on _ cpu biases 64 
tf . constant _ initializer 0.0 bias = tf . 
nn . bias _ add conv biases conv1 = tf 
. nn . relu bias name = scope . name 
_ activation _ summary conv1 # pool1 pool1 = tf 
. nn . max _ pool conv1 ksize = 1 
3 3 1 strides = 1 2 2 1 padding 
= SAME name = pool1 # norm1 norm1 = tf 
. nn . lrn pool1 4 bias = 1.0 alpha 
= 0.001 / 9.0 beta = 0.75 name = norm1 
# conv2 with tf . variable _ scope conv2 as 
scope kernel = _ variable _ with _ weight _ 
decay weights shape = 5 5 64 64 stddev = 
1e 4 wd = 0.0 conv = tf . nn 
. conv2d norm1 kernel 1 1 1 1 padding = 
SAME biases = _ variable _ on _ cpu biases 
64 tf . constant _ initializer 0.1 bias = tf 
. nn . bias _ add conv biases conv2 = 
tf . nn . relu bias name = scope . 
name _ activation _ summary conv2 # norm2 norm2 = 
tf . nn . lrn conv2 4 bias = 1.0 
alpha = 0.001 / 9.0 beta = 0.75 name = 
norm2 # pool2 pool2 = tf . nn . max 
_ pool norm2 ksize = 1 3 3 1 strides 
= 1 2 2 1 padding = SAME name = 
pool2 # local3 with tf . variable _ scope local3 
as scope # Move everything into depth so we can 
perform a single matrix multiply . dim = 1 for 
d in pool2 . get _ shape 1 . as 
_ list dim * = d reshape = tf . 
reshape pool2 FLAGS . batch _ size dim weights = 
_ variable _ with _ weight _ decay weights shape 
= dim 384 stddev = 0.04 wd = 0.004 biases 
= _ variable _ on _ cpu biases 384 tf 
. constant _ initializer 0.1 local3 = tf . nn 
. relu tf . matmul reshape weights + biases name 
= scope . name _ activation _ summary local3 # 
local4 with tf . variable _ scope local4 as scope 
weights = _ variable _ with _ weight _ decay 
weights shape = 384 192 stddev = 0.04 wd = 
0.004 biases = _ variable _ on _ cpu biases 
192 tf . constant _ initializer 0.1 local4 = tf 
. nn . relu tf . matmul local3 weights + 
biases name = scope . name _ activation _ summary 
local4 # softmax i . e . softmax WX + 
b with tf . variable _ scope softmax _ linear 
as scope weights = _ variable _ with _ weight 
_ decay weights 192 NUM _ CLASSES stddev = 1 
/ 192.0 wd = 0.0 biases = _ variable _ 
on _ cpu biases NUM _ CLASSES tf . constant 
_ initializer 0.0 softmax _ linear = tf . add 
tf . matmul local4 weights biases name = scope . 
name _ activation _ summary softmax _ linear return softmax 
_ linear def loss logits labels Add L2Loss to all 
the trainable variables . Add summary for for Loss and 
Loss / avg . Args logits Logits from inference . 
labels Labels from distorted _ inputs or inputs . 1 
D tensor of shape batch _ size Returns Loss tensor 
of type float . # Calculate the average cross entropy 
loss across the batch . labels = tf . cast 
labels tf . int64 cross _ entropy = tf . 
nn . sparse _ softmax _ cross _ entropy _ 
with _ logits logits = logits labels = labels name 
= cross _ entropy _ per _ example cross _ 
entropy _ mean = tf . reduce _ mean cross 
_ entropy name = cross _ entropy tf . add 
_ to _ collection losses cross _ entropy _ mean 
# The total loss is defined as the cross entropy 
loss plus all of the weight # decay terms L2 
loss . return tf . add _ n tf . 
get _ collection losses name = total _ loss def 
_ add _ loss _ summaries total _ loss Add 
summaries for losses in CIFAR 10 model . Generates moving 
average for all losses and associated summaries for visualizing the 
performance of the network . Args total _ loss Total 
loss from loss . Returns loss _ averages _ op 
op for generating moving averages of losses . # Compute 
the moving average of all individual losses and the total 
loss . loss _ averages = tf . train . 
E x p o n e n t i a 
l M o v i n g A v e 
r a g e 0.9 name = avg losses = 
tf . get _ collection losses loss _ averages _ 
op = loss _ averages . apply losses + total 
_ loss # Attach a scalar summary to all individual 
losses and the total loss do the # same for 
the averaged version of the losses . for l in 
losses + total _ loss # Name each loss as 
raw and name the moving average version of the loss 
# as the original loss name . tf . summary 
. scalar l . op . name + raw l 
tf . summary . scalar l . op . name 
loss _ averages . average l return loss _ averages 
_ op def train total _ loss global _ step 
Train CIFAR 10 model . Create an optimizer and apply 
to all trainable variables . Add moving average for all 
trainable variables . Args total _ loss Total loss from 
loss . global _ step Integer Variable counting the number 
of training steps processed . Returns train _ op op 
for training . # Variables that affect learning rate . 
num _ batches _ per _ epoch = NUM _ 
EXAMPLES _ PER _ EPOCH _ FOR _ TRAIN / 
FLAGS . batch _ size decay _ steps = int 
num _ batches _ per _ epoch * NUM _ 
EPOCHS _ PER _ DECAY # Decay the learning rate 
exponentially based on the number of steps . lr = 
tf . train . exponential _ decay INITIAL _ LEARNING 
_ RATE global _ step decay _ steps LEARNING _ 
RATE _ DECAY _ FACTOR staircase = True tf . 
summary . scalar learning _ rate lr # Generate moving 
averages of all losses and associated summaries . loss _ 
averages _ op = _ add _ loss _ summaries 
total _ loss # Compute gradients . with tf . 
control _ dependencies loss _ averages _ op opt = 
tf . train . G r a d i e 
n t D e s c e n t O 
p t i m i z e r lr grads 
= opt . compute _ gradients total _ loss # 
Apply gradients . apply _ gradient _ op = opt 
. apply _ gradients grads global _ step = global 
_ step # Add histograms for trainable variables . for 
var in tf . trainable _ variables tf . summary 
. histogram var . op . name var # Add 
histograms for gradients . for grad var in grads if 
grad is not None tf . summary . histogram var 
. op . name + / gradients grad # Track 
the moving averages of all trainable variables . variable _ 
averages = tf . train . E x p o 
n e n t i a l M o v 
i n g A v e r a g e 
MOVING _ AVERAGE _ DECAY global _ step variables _ 
averages _ op = variable _ averages . apply tf 
. trainable _ variables with tf . control _ dependencies 
apply _ gradient _ op variables _ averages _ op 
train _ op = tf . no _ op name 
= train return train _ op def maybe _ download 
_ and _ extract Download and extract the tarball from 
Alex s website . dest _ directory = FLAGS . 
data _ dir if not os . path . exists 
dest _ directory os . makedirs dest _ directory filename 
= DATA _ URL . split / 1 filepath = 
os . path . join dest _ directory filename if 
not os . path . exists filepath def _ progress 
count block _ size total _ size sys . stdout 
. write \ r Downloading % s % . 1f 
% % % filename float count * block _ size 
/ float total _ size * 100.0 sys . stdout 
. flush filepath _ = urllib . request . urlretrieve 
DATA _ URL filepath reporthook = _ progress print statinfo 
= os . stat filepath print Successfully downloaded filename statinfo 
. st _ size bytes . tarfile . open filepath 
r gz . extractall dest _ directory cifar10 _ train 
. py # Copyright 2015 Google Inc . All Rights 
Reserved . # # Licensed under the Apache License Version 
2.0 the License # you may not use this file 
except in compliance with the License . # You may 
obtain a copy of the License at # # http 
/ / www . apache . org / licenses / 
LICENSE 2.0 # # Unless required by applicable law or 
agreed to in writing software # distributed under the License 
is distributed on an AS IS BASIS # WITHOUT WARRANTIES 
OR CONDITIONS OF ANY KIND either express or implied . 
# See the License for the specific language governing permissions 
and # limitations under the License . # = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = A binary to train 
CIFAR 10 using a single GPU . Accuracy cifar10 _ 
train . py achieves ~ 86% accuracy after 100K steps 
256 epochs of data as judged by cifar10 _ eval 
. py . Speed With batch _ size 128 . 
System | Step Time sec / batch | Accuracy 1 
Tesla K20m | 0.35 0.60 | ~ 86% at 60K 
steps 5 hours 1 Tesla K40m | 0.25 0.35 | 
~ 86% at 100K steps 4 hours Usage Please see 
the tutorial and website for how to download the CIFAR 
10 data set compile the program and train the model 
. http / / tensorflow . org / tutorials / 
deep _ cnn / from _ _ future _ _ 
import absolute _ import from _ _ future _ _ 
import division from _ _ future _ _ import print 
_ function from datetime import datetime import os . path 
import time import numpy as np from six . moves 
import xrange # pylint disable = redefined builtin import tensorflow 
as tf import cifar10 FLAGS = tf . app . 
flags . FLAGS tf . app . flags . DEFINE 
_ string train _ dir . / cifar10 _ train 
Directory where to write event logs and checkpoint . tf 
. app . flags . DEFINE _ integer max _ 
steps 1000000 Number of batches to run . tf . 
app . flags . DEFINE _ boolean log _ device 
_ placement False Whether to log device placement . def 
train Train CIFAR 10 for a number of steps . 
with tf . Graph . as _ default global _ 
step = tf . Variable 0 trainable = False # 
Get images and labels for CIFAR 10 . images labels 
= cifar10 . distorted _ inputs # Build a Graph 
that computes the logits predictions from the # inference model 
. logits = cifar10 . inference images # Calculate loss 
. loss = cifar10 . loss logits labels # Build 
a Graph that trains the model with one batch of 
examples and # updates the model parameters . train _ 
op = cifar10 . train loss global _ step # 
Create a saver . saver = tf . train . 
Saver tf . global _ variables # Build the summary 
operation based on the TF collection of Summaries . summary 
_ op = tf . summary . merge _ all 
# Build an initialization operation to run below . init 
= tf . global _ variables _ initializer # Start 
running operations on the Graph . sess = tf . 
Session config = tf . ConfigProto log _ device _ 
placement = FLAGS . log _ device _ placement sess 
. run init # Start the queue runners . tf 
. train . start _ queue _ runners sess = 
sess summary _ writer = tf . summary . FileWriter 
FLAGS . train _ dir graph = sess . graph 
for step in xrange FLAGS . max _ steps start 
_ time = time . time _ loss _ value 
= sess . run train _ op loss duration = 
time . time start _ time assert not np . 
isnan loss _ value Model diverged with loss = NaN 
if step % 10 = = 0 num _ examples 
_ per _ step = FLAGS . batch _ size 
examples _ per _ sec = num _ examples _ 
per _ step / duration sec _ per _ batch 
= float duration format _ str = % s step 
% d loss = % . 2f % . 1f 
examples / sec % . 3f sec / batch print 
format _ str % datetime . now step loss _ 
value examples _ per _ sec sec _ per _ 
batch if step % 100 = = 0 summary _ 
str = sess . run summary _ op summary _ 
writer . add _ summary summary _ str step # 
Save the model checkpoint periodically . if step % 1000 
= = 0 or step + 1 = = FLAGS 
. max _ steps checkpoint _ path = os . 
path . join FLAGS . train _ dir model . 
ckpt saver . save sess checkpoint _ path global _ 
step = step def main argv = None # pylint 
disable = unused argument cifar10 . maybe _ download _ 
and _ extract if tf . gfile . Exists FLAGS 
. train _ dir tf . gfile . D e 
l e t e R e c u r s 
i v e l y FLAGS . train _ dir 
tf . gfile . MakeDirs FLAGS . train _ dir 
train if _ _ name _ _ = = _ 
_ main _ _ tf . app . run cifar10 
_ input . py # Copyright 2015 Google Inc . 
All Rights Reserved . # # Licensed under the Apache 
License Version 2.0 the License # you may not use 
this file except in compliance with the License . # 
You may obtain a copy of the License at # 
# http / / www . apache . org / 
licenses / LICENSE 2.0 # # Unless required by applicable 
law or agreed to in writing software # distributed under 
the License is distributed on an AS IS BASIS # 
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express or 
implied . # See the License for the specific language 
governing permissions and # limitations under the License . # 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = Routine for 
decoding the CIFAR 10 binary file format . from _ 
_ future _ _ import absolute _ import from _ 
_ future _ _ import division from _ _ future 
_ _ import print _ function import os from six 
. moves import xrange # pylint disable = redefined builtin 
import tensorflow as tf # Process images of this size 
. Note that this differs from the original CIFAR # 
image size of 32 x 32 . If one alters 
this number then the entire model # architecture will change 
and any model would need to be retrained . IMAGE 
_ SIZE = 24 # Global constants describing the CIFAR 
10 data set . NUM _ CLASSES = 10 NUM 
_ EXAMPLES _ PER _ EPOCH _ FOR _ TRAIN 
= 50000 NUM _ EXAMPLES _ PER _ EPOCH _ 
FOR _ EVAL = 10000 def read _ cifar10 filename 
_ queue Reads and parses examples from CIFAR10 data files 
. Recommendation if you want N way read parallelism call 
this function N times . This will give you N 
independent Readers reading different files & positions within those files 
which will give better mixing of examples . Args filename 
_ queue A queue of strings with the filenames to 
read from . Returns An object representing a single example 
with the following fields height number of rows in the 
result 32 width number of columns in the result 32 
depth number of color channels in the result 3 key 
a scalar string Tensor describing the filename & record number 
for this example . label an int32 Tensor with the 
label in the range 0 . . 9 . uint8image 
a height width depth uint8 Tensor with the image data 
class CIFAR10Record object pass result = CIFAR10Record # Dimensions of 
the images in the CIFAR 10 dataset . # See 
http / / www . cs . toronto . edu 
/ ~ kriz / cifar . html for a description 
of the # input format . label _ bytes = 
1 # 2 for CIFAR 100 result . height = 
32 result . width = 32 result . depth = 
3 image _ bytes = result . height * result 
. width * result . depth # Every record consists 
of a label followed by the image with a # 
fixed number of bytes for each . record _ bytes 
= label _ bytes + image _ bytes # Read 
a record getting filenames from the filename _ queue . 
No # header or footer in the CIFAR 10 format 
so we leave header _ bytes # and footer _ 
bytes at their default of 0 . reader = tf 
. F i x e d L e n g 
t h R e c o r d R e 
a d e r record _ bytes = record _ 
bytes result . key value = reader . read filename 
_ queue # Convert from a string to a vector 
of uint8 that is record _ bytes long . record 
_ bytes = tf . decode _ raw value tf 
. uint8 # The first bytes represent the label which 
we convert from uint8 int32 . result . label = 
tf . cast tf . slice record _ bytes 0 
label _ bytes tf . int32 # The remaining bytes 
after the label represent the image which we reshape # 
from depth * height * width to depth height width 
. depth _ major = tf . reshape tf . 
slice record _ bytes label _ bytes image _ bytes 
result . depth result . height result . width # 
Convert from depth height width to height width depth . 
result . uint8image = tf . transpose depth _ major 
1 2 0 return result def _ generate _ image 
_ and _ label _ batch image label min _ 
queue _ examples batch _ size Construct a queued batch 
of images and labels . Args image 3 D Tensor 
of height width 3 of type . float32 . label 
1 D Tensor of type . int32 min _ queue 
_ examples int32 minimum number of samples to retain in 
the queue that provides of batches of examples . batch 
_ size Number of images per batch . Returns images 
Images . 4D tensor of batch _ size height width 
3 size . labels Labels . 1D tensor of batch 
_ size size . # Create a queue that shuffles 
the examples and then # read batch _ size images 
+ labels from the example queue . num _ preprocess 
_ threads = 16 images label _ batch = tf 
. train . shuffle _ batch image label batch _ 
size = batch _ size num _ threads = num 
_ preprocess _ threads capacity = min _ queue _ 
examples + 3 * batch _ size min _ after 
_ dequeue = min _ queue _ examples # Display 
the training images in the visualizer . tf . summary 
. image images images return images tf . reshape label 
_ batch batch _ size def distorted _ inputs data 
_ dir batch _ size Construct distorted input for CIFAR 
training using the Reader ops . Args data _ dir 
Path to the CIFAR 10 data directory . batch _ 
size Number of images per batch . Returns images Images 
. 4D tensor of batch _ size IMAGE _ SIZE 
IMAGE _ SIZE 3 size . labels Labels . 1D 
tensor of batch _ size size . filenames = os 
. path . join data _ dir data _ batch 
_ % d . bin % i for i in 
xrange 1 6 for f in filenames if not tf 
. gfile . Exists f raise ValueError Failed to find 
file + f # Create a queue that produces the 
filenames to read . filename _ queue = tf . 
train . string _ input _ producer filenames # Read 
examples from files in the filename queue . read _ 
input = read _ cifar10 filename _ queue reshaped _ 
image = tf . cast read _ input . uint8image 
tf . float32 height = IMAGE _ SIZE width = 
IMAGE _ SIZE # Image processing for training the network 
. Note the many random # distortions applied to the 
image . # Randomly crop a height width section of 
the image . distorted _ image = tf . random 
_ crop reshaped _ image height width 3 # Randomly 
flip the image horizontally . distorted _ image = tf 
. image . random _ flip _ left _ right 
distorted _ image # Because these operations are not commutative 
consider randomizing # randomize the order their operation . distorted 
_ image = tf . image . random _ brightness 
distorted _ image max _ delta = 63 distorted _ 
image = tf . image . random _ contrast distorted 
_ image lower = 0.2 upper = 1.8 # Subtract 
off the mean and divide by the variance of the 
pixels . float _ image = tf . image . 
per _ image _ standardization distorted _ image # Ensure 
that the random shuffling has good mixing properties . min 
_ fraction _ of _ examples _ in _ queue 
= 0.4 min _ queue _ examples = int NUM 
_ EXAMPLES _ PER _ EPOCH _ FOR _ TRAIN 
* min _ fraction _ of _ examples _ in 
_ queue print Filling queue with % d CIFAR images 
before starting to train . This will take a few 
minutes . % min _ queue _ examples # Generate 
a batch of images and labels by building up a 
queue of examples . return _ generate _ image _ 
and _ label _ batch float _ image read _ 
input . label min _ queue _ examples batch _ 
size def inputs eval _ data data _ dir batch 
_ size Construct input for CIFAR evaluation using the Reader 
ops . Args eval _ data bool indicating if one 
should use the train or eval data set . data 
_ dir Path to the CIFAR 10 data directory . 
batch _ size Number of images per batch . Returns 
images Images . 4D tensor of batch _ size IMAGE 
_ SIZE IMAGE _ SIZE 3 size . labels Labels 
. 1D tensor of batch _ size size . if 
not eval _ data filenames = os . path . 
join data _ dir data _ batch _ % d 
. bin % i for i in xrange 1 6 
num _ examples _ per _ epoch = NUM _ 
EXAMPLES _ PER _ EPOCH _ FOR _ TRAIN else 
filenames = os . path . join data _ dir 
test _ batch . bin num _ examples _ per 
_ epoch = NUM _ EXAMPLES _ PER _ EPOCH 
_ FOR _ EVAL for f in filenames if not 
tf . gfile . Exists f raise ValueError Failed to 
find file + f # Create a queue that produces 
the filenames to read . filename _ queue = tf 
. train . string _ input _ producer filenames # 
Read examples from files in the filename queue . read 
_ input = read _ cifar10 filename _ queue reshaped 
_ image = tf . cast read _ input . 
uint8image tf . float32 height = IMAGE _ SIZE width 
= IMAGE _ SIZE # Image processing for evaluation . 
# Crop the central height width of the image . 
resized _ image = tf . image . resize _ 
image _ with _ crop _ or _ pad reshaped 
_ image width height # Subtract off the mean and 
divide by the variance of the pixels . float _ 
image = tf . image . per _ image _ 
whitening resized _ image # Ensure that the random shuffling 
has good mixing properties . min _ fraction _ of 
_ examples _ in _ queue = 0.4 min _ 
queue _ examples = int num _ examples _ per 
_ epoch * min _ fraction _ of _ examples 
_ in _ queue # Generate a batch of images 
and labels by building up a queue of examples . 
return _ generate _ image _ and _ label _ 
batch float _ image read _ input . label min 
_ queue _ examples batch _ size 0x4 评估 模型 
现在 可以 在 另一 部分 数据 集上 来 评估 训练 
模型 的 性能 脚本文件 cifar10 _ eval . py 对模型 
进行 了 评估 利用 inference 函数 重构 模型 并 使用 
了 在 评估 数据集 所有 10 000张 CIFAR 10 图片 
进行 测试 最终 计算出 的 精度 为 1 N N 
= 预测值 中 置信度 最高 的 一项 与 图片 真实 
label 匹配 的 频次 It calculates the precision at 1 
how often the top prediction matches the true label of 
the image 为了 监控 模型 在 训练 过程 中 的 
改进 情况 评估 用 的 脚本文件 会 周期性 的 在 
最新 的 检查 点 文件 上 运行 这些 检查点 文件 
是由 cifar10 _ train . py 产生 cifar10 _ eval 
. py # Copyright 2015 Google Inc . All Rights 
Reserved . # # Licensed under the Apache License Version 
2.0 the License # you may not use this file 
except in compliance with the License . # You may 
obtain a copy of the License at # # http 
/ / www . apache . org / licenses / 
LICENSE 2.0 # # Unless required by applicable law or 
agreed to in writing software # distributed under the License 
is distributed on an AS IS BASIS # WITHOUT WARRANTIES 
OR CONDITIONS OF ANY KIND either express or implied . 
# See the License for the specific language governing permissions 
and # limitations under the License . # = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = Evaluation for CIFAR 10 
. Accuracy cifar10 _ train . py achieves 83.0% accuracy 
after 100K steps 256 epochs of data as judged by 
cifar10 _ eval . py . Speed On a single 
Tesla K40 cifar10 _ train . py processes a single 
batch of 128 images in 0.25 0.35 sec i . 
e . 350 600 images / sec . The model 
reaches ~ 86% accuracy after 100K steps in 8 hours 
of training time . Usage Please see the tutorial and 
website for how to download the CIFAR 10 data set 
compile the program and train the model . http / 
/ tensorflow . org / tutorials / deep _ cnn 
/ from _ _ future _ _ import absolute _ 
import from _ _ future _ _ import division from 
_ _ future _ _ import print _ function from 
datetime import datetime import math import time import tensorflow . 
python . platform from tensorflow . python . platform import 
gfile import numpy as np import tensorflow as tf import 
cifar10 FLAGS = tf . app . flags . FLAGS 
tf . app . flags . DEFINE _ string eval 
_ dir . / cifar10 _ eval Directory where to 
write event logs . tf . app . flags . 
DEFINE _ string eval _ data test Either test or 
train _ eval . tf . app . flags . 
DEFINE _ string checkpoint _ dir . / cifar10 _ 
train Directory where to read model checkpoints . tf . 
app . flags . DEFINE _ integer eval _ interval 
_ secs 60 * 5 How often to run the 
eval . tf . app . flags . DEFINE _ 
integer num _ examples 10000 Number of examples to run 
. tf . app . flags . DEFINE _ boolean 
run _ once False Whether to run eval only once 
. def eval _ once saver summary _ writer top 
_ k _ op summary _ op Run Eval once 
. Args saver Saver . summary _ writer Summary writer 
. top _ k _ op Top K op . 
summary _ op Summary op . with tf . Session 
as sess ckpt = tf . train . get _ 
checkpoint _ state FLAGS . checkpoint _ dir if ckpt 
and ckpt . model _ checkpoint _ path # Restores 
from checkpoint saver . restore sess ckpt . model _ 
checkpoint _ path # Assuming model _ checkpoint _ path 
looks something like # / my favorite path / cifar10 
_ train / model . ckpt 0 # extract global 
_ step from it . global _ step = ckpt 
. model _ checkpoint _ path . split / 1 
. split 1 else print No checkpoint file found return 
# Start the queue runners . coord = tf . 
train . Coordinator try threads = for qr in tf 
. get _ collection tf . GraphKeys . QUEUE _ 
RUNNERS threads . extend qr . create _ threads sess 
coord = coord daemon = True start = True num 
_ iter = int math . ceil FLAGS . num 
_ examples / FLAGS . batch _ size true _ 
count = 0 # Counts the number of correct predictions 
. total _ sample _ count = num _ iter 
* FLAGS . batch _ size step = 0 while 
step num _ iter and not coord . should _ 
stop predictions = sess . run top _ k _ 
op true _ count + = np . sum predictions 
step + = 1 # Compute precision @ 1 . 
precision = true _ count / total _ sample _ 
count print % s precision @ 1 = % . 
3f % datetime . now precision summary = tf . 
Summary summary . ParseFromString sess . run summary _ op 
summary . value . add tag = Precision @ 1 
simple _ value = precision summary _ writer . add 
_ summary summary global _ step except Exception as e 
# pylint disable = broad except coord . request _ 
stop e coord . request _ stop coord . join 
threads stop _ grace _ period _ secs = 10 
def evaluate Eval CIFAR 10 for a number of steps 
. with tf . Graph . as _ default # 
Get images and labels for CIFAR 10 . eval _ 
data = FLAGS . eval _ data = = test 
images labels = cifar10 . inputs eval _ data = 
eval _ data # Build a Graph that computes the 
logits predictions from the # inference model . logits = 
cifar10 . inference images # Calculate predictions . top _ 
k _ op = tf . nn . in _ 
top _ k logits labels 1 # Restore the moving 
average version of the learned variables for eval . variable 
_ averages = tf . train . E x p 
o n e n t i a l M o 
v i n g A v e r a g 
e cifar10 . MOVING _ AVERAGE _ DECAY variables _ 
to _ restore = variable _ averages . variables _ 
to _ restore saver = tf . train . Saver 
variables _ to _ restore # Build the summary operation 
based on the TF collection of Summaries . summary _ 
op = tf . summary . merge _ all graph 
= tf . get _ default _ graph . as 
_ graph _ def summary _ writer = tf . 
summary . FileWriter FLAGS . eval _ dir graph = 
graph while True eval _ once saver summary _ writer 
top _ k _ op summary _ op if FLAGS 
. run _ once break time . sleep FLAGS . 
eval _ interval _ secs def main argv = None 
# pylint disable = unused argument cifar10 . maybe _ 
download _ and _ extract if gfile . Exists FLAGS 
. eval _ dir gfile . D e l e 
t e R e c u r s i v 
e l y FLAGS . eval _ dir gfile . 
MakeDirs FLAGS . eval _ dir evaluate if _ _ 
name _ _ = = _ _ main _ _ 
tf . app . run google 的 tensorflow api 在 
1.0 正式 版本 后 变化很大 旧 的 代码 在 迁移 
到 1.0 后 需要 修改 对应 的 api 名字 0x5 
在 GPU 上 运行 # Copyright 2015 Google Inc . 
All Rights Reserved . # # Licensed under the Apache 
License Version 2.0 the License # you may not use 
this file except in compliance with the License . # 
You may obtain a copy of the License at # 
# http / / www . apache . org / 
licenses / LICENSE 2.0 # # Unless required by applicable 
law or agreed to in writing software # distributed under 
the License is distributed on an AS IS BASIS # 
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express or 
implied . # See the License for the specific language 
governing permissions and # limitations under the License . # 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = A binary 
to train CIFAR 10 using multiple GPU s with synchronous 
updates . Accuracy cifar10 _ multi _ gpu _ train 
. py achieves ~ 86% accuracy after 100K steps 256 
epochs of data as judged by cifar10 _ eval . 
py . Speed With batch _ size 128 . System 
| Step Time sec / batch | Accuracy 1 Tesla 
K20m | 0.35 0.60 | ~ 86% at 60K steps 
5 hours 1 Tesla K40m | 0.25 0.35 | ~ 
86% at 100K steps 4 hours 2 Tesla K20m | 
0.13 0.20 | ~ 84% at 30K steps 2.5 hours 
3 Tesla K20m | 0.13 0.18 | ~ 84% at 
30K steps 4 Tesla K20m | ~ 0.10 | ~ 
84% at 30K steps Usage Please see the tutorial and 
website for how to download the CIFAR 10 data set 
compile the program and train the model . http / 
/ tensorflow . org / tutorials / deep _ cnn 
/ from _ _ future _ _ import absolute _ 
import from _ _ future _ _ import division from 
_ _ future _ _ import print _ function from 
datetime import datetime import os . path import re import 
time import numpy as np from six . moves import 
xrange # pylint disable = redefined builtin import tensorflow as 
tf import cifar10 FLAGS = tf . app . flags 
. FLAGS tf . app . flags . DEFINE _ 
string train _ dir . / cifar10 _ train Directory 
where to write event logs and checkpoint . tf . 
app . flags . DEFINE _ integer max _ steps 
1000000 Number of batches to run . tf . app 
. flags . DEFINE _ integer num _ gpus 1 
How many GPUs to use . tf . app . 
flags . DEFINE _ boolean log _ device _ placement 
False Whether to log device placement . def tower _ 
loss scope Calculate the total loss on a single tower 
running the CIFAR model . Args scope unique prefix string 
identifying the CIFAR tower e . g . tower _ 
0 Returns Tensor of shape containing the total loss for 
a batch of data # Get images and labels for 
CIFAR 10 . images labels = cifar10 . distorted _ 
inputs # Build inference Graph . logits = cifar10 . 
inference images # Build the portion of the Graph calculating 
the losses . Note that we will # assemble the 
total _ loss using a custom function below . _ 
= cifar10 . loss logits labels # Assemble all of 
the losses for the current tower only . losses = 
tf . get _ collection losses scope # Calculate the 
total loss for the current tower . total _ loss 
= tf . add _ n losses name = total 
_ loss # Compute the moving average of all individual 
losses and the total loss . loss _ averages = 
tf . train . E x p o n e 
n t i a l M o v i n 
g A v e r a g e 0.9 name 
= avg loss _ averages _ op = loss _ 
averages . apply losses + total _ loss # Attach 
a scalar summary to all individual losses and the total 
loss do the # same for the averaged version of 
the losses . for l in losses + total _ 
loss # Remove tower _ 0 9 / from the 
name in case this is a multi GPU training # 
session . This helps the clarity of presentation on tensorboard 
. loss _ name = re . sub % s 
_ 0 9 * / % cifar10 . TOWER _ 
NAME l . op . name # Name each loss 
as raw and name the moving average version of the 
loss # as the original loss name . tf . 
summary . scalar loss _ name + raw l tf 
. summary . scalar loss _ name loss _ averages 
. average l with tf . control _ dependencies loss 
_ averages _ op total _ loss = tf . 
identity total _ loss return total _ loss def average 
_ gradients tower _ grads Calculate the average gradient for 
each shared variable across all towers . Note that this 
function provides a synchronization point across all towers . Args 
tower _ grads List of lists of gradient variable tuples 
. The outer list is over individual gradients . The 
inner list is over the gradient calculation for each tower 
. Returns List of pairs of gradient variable where the 
gradient has been averaged across all towers . average _ 
grads = for grad _ and _ vars in zip 
* tower _ grads # Note that each grad _ 
and _ vars looks like the following # grad0 _ 
gpu0 var0 _ gpu0 . . . grad0 _ gpuN 
var0 _ gpuN grads = for g _ in grad 
_ and _ vars # Add 0 dimension to the 
gradients to represent the tower . expanded _ g = 
tf . expand _ dims g 0 # Append on 
a tower dimension which we will average over below . 
grads . append expanded _ g # Average over the 
tower dimension . grad = tf . concat 0 grads 
grad = tf . reduce _ mean grad 0 # 
Keep in mind that the Variables are redundant because they 
are shared # across towers . So . . we 
will just return the first tower s pointer to # 
the Variable . v = grad _ and _ vars 
0 1 grad _ and _ var = grad v 
average _ grads . append grad _ and _ var 
return average _ grads def train Train CIFAR 10 for 
a number of steps . with tf . Graph . 
as _ default tf . device / cpu 0 # 
Create a variable to count the number of train calls 
. This equals the # number of batches processed * 
FLAGS . num _ gpus . global _ step = 
tf . get _ variable global _ step initializer = 
tf . constant _ initializer 0 trainable = False # 
Calculate the learning rate schedule . num _ batches _ 
per _ epoch = cifar10 . NUM _ EXAMPLES _ 
PER _ EPOCH _ FOR _ TRAIN / FLAGS . 
batch _ size decay _ steps = int num _ 
batches _ per _ epoch * cifar10 . NUM _ 
EPOCHS _ PER _ DECAY # Decay the learning rate 
exponentially based on the number of steps . lr = 
tf . train . exponential _ decay cifar10 . INITIAL 
_ LEARNING _ RATE global _ step decay _ steps 
cifar10 . LEARNING _ RATE _ DECAY _ FACTOR staircase 
= True # Create an optimizer that performs gradient descent 
. opt = tf . train . G r a 
d i e n t D e s c e 
n t O p t i m i z e 
r lr # Calculate the gradients for each model tower 
. tower _ grads = for i in xrange FLAGS 
. num _ gpus with tf . device / gpu 
% d % i with tf . name _ scope 
% s _ % d % cifar10 . TOWER _ 
NAME i as scope # Calculate the loss for one 
tower of the CIFAR model . This function # constructs 
the entire CIFAR model but shares the variables across # 
all towers . loss = tower _ loss scope # 
Reuse variables for the next tower . tf . get 
_ variable _ scope . reuse _ variables # Retain 
the summaries from the final tower . summaries = tf 
. get _ collection tf . GraphKeys . SUMMARIES scope 
# Calculate the gradients for the batch of data on 
this CIFAR tower . grads = opt . compute _ 
gradients loss # Keep track of the gradients across all 
towers . tower _ grads . append grads # We 
must calculate the mean of each gradient . Note that 
this is the # synchronization point across all towers . 
grads = average _ gradients tower _ grads # Add 
a summary to track the learning rate . summaries . 
append tf . summary . scalar learning _ rate lr 
# Add histograms for gradients . for grad var in 
grads if grad is not None summaries . append tf 
. summary . histogram var . op . name + 
/ gradients grad # Apply the gradients to adjust the 
shared variables . apply _ gradient _ op = opt 
. apply _ gradients grads global _ step = global 
_ step # Add histograms for trainable variables . for 
var in tf . trainable _ variables summaries . append 
tf . summary . histogram var . op . name 
var # Track the moving averages of all trainable variables 
. variable _ averages = tf . train . E 
x p o n e n t i a l 
M o v i n g A v e r 
a g e cifar10 . MOVING _ AVERAGE _ DECAY 
global _ step variables _ averages _ op = variable 
_ averages . apply tf . trainable _ variables # 
Group all updates to into a single train op . 
train _ op = tf . group apply _ gradient 
_ op variables _ averages _ op # Create a 
saver . saver = tf . train . Saver tf 
. global _ variables # Build the summary operation from 
the last tower summaries . summary _ op = tf 
. summary . merge summaries # tf . summary . 
merge _ all summaries # Build an initialization operation to 
run below . init = tf . global _ variables 
_ initializer # Start running operations on the Graph . 
allow _ soft _ placement must be set to # 
True to build towers on GPU as some of the 
ops do not have GPU # implementations . sess = 
tf . Session config = tf . ConfigProto allow _ 
soft _ placement = True log _ device _ placement 
= FLAGS . log _ device _ placement sess . 
run init # Start the queue runners . tf . 
train . start _ queue _ runners sess = sess 
summary _ writer = tf . summary . FileWriter FLAGS 
. train _ dir graph = sess . graph for 
step in xrange FLAGS . max _ steps start _ 
time = time . time _ loss _ value = 
sess . run train _ op loss duration = time 
. time start _ time assert not np . isnan 
loss _ value Model diverged with loss = NaN if 
step % 10 = = 0 num _ examples _ 
per _ step = FLAGS . batch _ size * 
FLAGS . num _ gpus examples _ per _ sec 
= num _ examples _ per _ step / duration 
sec _ per _ batch = duration / FLAGS . 
num _ gpus format _ str = % s step 
% d loss = % . 2f % . 1f 
examples / sec % . 3f sec / batch print 
format _ str % datetime . now step loss _ 
value examples _ per _ sec sec _ per _ 
batch if step % 100 = = 0 summary _ 
str = sess . run summary _ op summary _ 
writer . add _ summary summary _ str step # 
Save the model checkpoint periodically . if step % 1000 
= = 0 or step + 1 = = FLAGS 
. max _ steps checkpoint _ path = os . 
path . join FLAGS . train _ dir model . 
ckpt saver . save sess checkpoint _ path global _ 
step = step def main argv = None # pylint 
disable = unused argument cifar10 . maybe _ download _ 
and _ extract if tf . gfile . Exists FLAGS 
. train _ dir tf . gfile . D e 
l e t e R e c u r s 
i v e l y FLAGS . train _ dir 
tf . gfile . MakeDirs FLAGS . train _ dir 
train if _ _ name _ _ = = _ 
_ main _ _ tf . app . run export 
LD _ LIBRARY _ PATH = $ LD _ LIBRARY 
_ PATH / usr / local / cuda 8.0 / 
lib64 export CUDA _ HOME = / usr / local 
/ cuda export PATH = / usr / local / 
cuda 8.0 / / bin $ PATH screen python cifar10 
_ multi _ gpu _ train . py num _ 
gpus = 1 python cifar10 _ eval . pyRelevant Link 
https / / www . tensorflow . org / api 
_ docs / python / tf / random _ crop 
https / / github . com / tensorflow / models 
/ commit / e 5 0 7 9 c 8 
3 9 0 5 8 f f 4 0 d 
c b d 1 5 5 1 5 a 9 
c f b 4 6 2 f a b b 
c 2 a # diff 5 a e 6 4 
c f 0 7 7 d b 8 f 0 
0 6 8 6 f f 8 b 5 d 
7 7 4 8 6 0 4 https / / 
github . com / tensorflow / tensorflow / tree / 
r 0.7 / tensorflow / models / image / cifar10 
https / / github . com / tensorflow / models 
/ pull / 864 / commits / e 9 3 
e c 3 7 2 0 1 f 5 f 
2 1 1 6 9 3 3 a e 9 
6 e 5 0 5 f 4 0 9 d 
d b f 3 4 4 d http / / 
qiita . com / shu223 / items / e f 
1 6 0 c b e 1 e 9 d 
9 f 5 7 c 2 4 8 5 . 
单词 的 向量 表示 Vector Representations of Words 0x1 Word 
Embeddings 通常 图像 或 音频系统 处理 的 是由 图片 中 
所有 单个 原始 像素点 强度 值 pix chanel 或者 音频 
中 功率 谱 密度 的 强度 值 把 它们 编码 
成 丰富 高纬度 的 向量 数据集 卷积 对于 物体 或 
语音 识别 这 一类 的 任务 我们 所需 的 全部 
信息 已经 都 存储 在 原始 数据 中 显然 人类 
本身 就是 依赖 原始数据 进行 日常 的 物体 或 语音 
识别 的 然后 自然语言 处理 系统 通常 将 词汇 作为 
离散 的 单一 符号 例如 cat 一 词 或可 表示 
为 Id537 而 dog 一 词 或可 表示 为 Id143 
这些 符号 编码 毫 无规律 无法 提供 不同 词汇 之间 
可能 存在 的 关联 信息 换句话说 在 处理 关于 dogs 
一 词 的 信息 时 模型 将 无法 利用 已知 
的 关于 cats 的 信息 例如 它们 都是/nr 动物 有 
四条 腿 可 作为 宠物 等等 可见 将 词汇 表达 
为 上述 的 独立 离散 符号 将 进一步 导致 数据 
稀疏 使 我们 在 训练 统计模型 时 不得不 寻求 更多 
的 数据 而 词汇 的 向量 表示 将 克服 上述 
的 难题 向量空间 模型 VSMs 将 词汇 表达 嵌套 于 
一个 连续 的 向量空间 中 语义 近似 的 词汇 被 
映射 为 相邻 的 数据 点 向量空间 模型 在 自然 
语言 处理 领域 中 有着 漫长 且 丰富 的 历史 
不过 几乎 所有 利用 这一 模型 的 方法 都 依赖 
于 分布式 假设 其/r 核心/n 思想/n 为/p 出现/v 于/p 上下文/l 
情景/n 中的/i 词汇/n 都有/i 相/v 类似/v 的/uj 语义/n 采用 这一 
假设 的 研究 方法 大致 分为 以下 两类 基于 计数 
的 方法 e . g . 潜在 语义分析 基于 计数 
的 方法 计算 某 词汇 与其 邻近 词汇 在 一个 
大型 语料库 中 共同 出现 的 频率 及 其他 统计量 
然后 将 这些 统计量 映射 到 一个 小型 且 稠密 
的 向量 中 预测 方法 e . g . 神经 
概率 化 语言 模型 预测 方法 则 试图 直接 从某/nr 
词汇 的 邻近 词汇 对其 进行 预测 在此 过程 中 
利用 已经 学习 到 的 小型 且 稠密 的 嵌套 
向量 Word2vec 是 一种 可以 进行 高 效率 词 嵌套 
学习 的 预测模型 其 两种 变体 分别 为 连续 词 
袋 模型 CBOW 从 算法 角度看 这 两种 方法 非常 
相似 其 区别 为 CBOW 根据 源 词 上下文 词汇 
the cat sits on the 来 预测 目标 词汇 例如 
mat Skip Gram 模型 Skip Gram 模型 做法 相反 它 
通过 目标 词汇 来 预测 源 词汇 Skip Gram 模型 
采取 CBOW 的 逆 过程 的 动机 在于 1 CBOW 
算法 对于 很多 分布式 信息 进行 了 平滑 处理 例如 
将 一 整段 上下文 信息 视为 一个 单一 观察 量 
很多 情况 下 对于 小型 的 数据 集 这一 处理 
是 有 帮助 的 2 相形之下 Skip Gram 模型 将 
每个 上下文 目标 词汇 的 组合 视为 一个 新 观察 
量 这种 做法 在 大型 数据 集中 会 更为 有效 
0x2   处理 噪声 对 比 训练 神经 概率 化 
语言 模型 通常 使用 极大 似 然 法 ML 进行 
训练 其中 通过 softmax function 来 最大化 当 提供 前 
一个 单词 h 代表 history 后 一个 单词 的 概率 
  代表 target 当 score w _ t h 计算 
了 文字 w _ t 和 上下文 h 的 相容性 
通常 使用 向量积 我们 使用 对数 似 然 函数 来 
训练 训练 集 的 最大值 比如 通过 这里 提出 了 
一个 解决 语言 概率模型 的 合适 的 通用 方法 然而 
这个 方法 实际 执行 起来 开销 非常大 因为 我们 需要 
去 计算 并 正则化 当前 上下文 环境 h 中 所有 
其他 V 单词 w 的 概率 得分 在 每一步 训练 
迭代 中 即 每一个 单词 我们 都要/nr 进行 一次 预测 
在 所有 语料 组合 中 最优 可能 紧跟 着地 单词 
是 什么 从 另一个 角度 来说 当 使用 word2vec 模型 
时 我们 并不 需要 对 概率模型 中 的 所有 特征 
进行 学习 而 CBOW 模型 和 Skip Gram 模型 为了 
避免 这种 情况 发生 使用 一个 二 分类器 逻辑 回归 
在 同一个 上下文 环境 里 从 k 虚构 的 噪声 
单词   区分 出 真正 的 目标 单词 我们 下面 
详细 阐述 一下 CBOW 模型 对于 Skip Gram 模型 只要 
简单 地做 相反 的 操作 即可 噪声 对 比 训练 
的 意义 在于 我们 假设 随机 产生 的 目标 单词 
上下文 都是 噪声 它们/r 不/d 可能/v 也/d 不/d 应该/v 和/c 
我们/r 的/uj 目标/n 单词/n 有/v 语境/n 关联/ns 训练 的 目标 
就 在于 找到 一组 参数 使得/v 尽可能/d 大/a 的/uj 区分/n 
目标/n 单词/n 的/uj 目标/n 上下文/l 和/c 噪音/n 上下文/l 从/p 数学/n 
角度/n 来说/u 我们 的 目标 是 对 每个 样本 最大化 
其中 代表 的 是 数据 集在 当前 上下文 h 根据 
所 学习 的 嵌套 向量   目标 单词 w 使用 
二 分类 逻辑 回归 计算 得出 的 概率 在 实践 
中 我们 通过 在 噪声 分布 中 绘制 比对 文字 
来 获得 近似 的 期望值 通过 计算 蒙特卡洛 平均值 当 
真实 地 目标 单词 被 分配 到 较高 的 概率 
同时 噪声 单词 的 概率 很低 时 目标函数 也就 达到 
最大 值了 从 技术 层面 来说 这种方法 叫做 负 抽样 
而且 使用 这个 损失 函数 在 数学 层面 上 也有 
很好 的 解释 这个 更新过程 也 近似于 softmax 函数 的 
更新 这在 计算 上将 会 有 很大 的 优势 因为 
当 计算 这个 损失 函数 时 只是 有 我们 挑选 
出来 的 k 个 噪声 单词 而 没有 使用 整个 
语料库 V 这 使得 训练 变得 非常 快 我们 实际 
上 使用 了 与 noise contrastive estimation NCE 介绍 的 
非常 相似 的 方法 这在 TensorFlow 中 已经 封装 了 
一个 很 便捷 的 函数 tf . nn . nce 
_ loss 0x3 Skip gram 模型 下面 来看 一下 这个 
数据集 the quick brown fox jumped over the lazy dog 
我们 首先 对 一些 单词 以及 它们 的 上下文 环境 
建立 一个 数据集 我们 可以 以 任何 合理 的 方式 
定义 上下文 而 通常 上 这个 方式 是 根据 文字 
的 句法 语境 的 使用 语法 原理 的 方式 处理 
当前 目标 单词 可 比如说 把 目标 单词 左边 的 
内容 当做 一个 上下文 或者 以 目标 单词 右边 的 
内容 等等 现在 我们 把 目标 单词 的 左右 单词 
视作 一个 上下文 使用 大小 为 1 的 窗口 这样 
就 得到 这样 一个 由 上下文 目标 单词 组成 的 
数据 集 the brown quick quick fox brown brown jumped 
fox . . . 文 提到 Skip Gram 模型 是 
把 目标 单词 和 上下文 颠倒过来 所以 在 这个 问题 
中 举个 例子 就是 用 quick 来 预测 the 和 
brown 用 brown 预测 quick 和 brown 因此 这个 数据集 
就 变成 由 输入 输出 组成 的 quick the quick 
brown brown quick brown fox . . . 目标函数 通常 
是 对 整个 数据集 建立 的 但是 本 问题 中 
要对 每一个 样本 或者 是 一个 batch _ size 很小 
的 样本 集 通常 设置 为 16 = batch _ 
size = 512 在 同一 时间 执行 特别 的 操作 
称之为 随机 梯度 下降 SGD 我们 来看 一下 训练 过程 
中 每一步 的 执行 假设 用 t 表示 上面 这个 
例子 中 quick 来 预测 the 的 训练 的 单个 
循环 用 num _ noise 定义 从 噪声 分布 中 
挑选 出来 的 噪声 相反 的 单词 的 个数 通常 
使用 一元 分布 P w 为了 简单 起见 我们 就 
定 num _ noise = 1 用 sheep 选作 噪声 
词 接下来 就 可以 计算 每 一对 观察 值 和 
噪声 值 的 损失 函 数了 每 一个 执行 步骤 
就可 表示 为 整个 计算 过程 的 目标 是 通过 
更新 嵌套 参数   来 逼近 目标函数 这个 这个 例子 
中 就是 使 目标函数 最大化 即 让 模型 向对/nr 目标值 
预测 概率 最高 而对 噪 音值 预测 概率 最低 为此 
我们 要 计算 损失 函数 中 嵌套 参数 的 梯度 
对于 整个 数据集 当 梯度 下降 的 过程 中 不断 
地 更新 参数 对应 产生 的 效果 就是 不断 地 
移动 每个 单词 的 嵌套 向量 直到 可以 把 真实 
单词 和 噪声 单词 很 好得 区分开 我们 可以 把 
学习 向量 映 射到 2 维 中 以便 我们 观察 
其中 用到 的 技术 可以 参考 t SNE 降 纬 
技术 当 我们 用 可视化 的 方式 来 观察 这些 
向量 就 可以 很 明显 的 获取 单词 之间 语义 
信息 的 关系 这 实际上 是 非常 有用 的 当 
我们 第一 次 发现 这样 的 诱导 向量空间 中 展示 
了 一些 特定 的 语义 关系 这 是 非常 有趣 
的 比如 文字 中 male female gender 甚至 还有 country 
capital 的 关系 这 也 解释 了 为什么 这些 向量 
在 传统 的 NLP 问题 中 可 作为 特性 使用 
比如 用 在对 一个 演讲 章节 打个 标签 或者 对 
一个 专有 名词 的 识别 0x4 建立 图形 先来 定义 
一个 嵌套 参数 矩阵 我们 用 唯一 的 随机 值 
来 初始化 这个 大 矩阵 embeddings = tf . Variable 
tf . random _ uniform vocabulary _ size embedding _ 
size 1.0 1.0 对 噪声 比对 的 损失 计算 就 
使用 一个 逻辑 回归模型 对此 我们 需要 对 语料库 中的 
每个 单词 定义 一个 权重 值 和 偏差 值 也可 
称之为 输出 权重 与之 对应 的 输入 嵌套 值 定义 
如下 nce _ weights = tf . Variable tf . 
truncated _ normal vocabulary _ size embedding _ size stddev 
= 1.0 / math . sqrt embedding _ size nce 
_ biases = tf . Variable tf . zeros vocabulary 
_ size 我们 有了/nr 这些 参数 之后 就 可以 定义 
Skip Gram 模型 了 简单 起见 假设 我们 已经 把 
语料库 中的 文字 整型 化了 这样 每个 整型 代表 一个 
单词 Skip Gram 模型 有 两个 输入 一个 是 一组 
用 整型 表示 的 上下文 单词 另 一个 是 目标 
单词 给 这些 输入 建立 占位符 节点 之后 就 可以 
填入 数据 了 # 建立 输入 占位符 train _ inputs 
= tf . placeholder tf . int32 shape = batch 
_ size train _ labels = tf . placeholder tf 
. int32 shape = batch _ size 1 然后 我们 
需要 对 批 数据 中 的 单词 建立 嵌套 向量 
embed = tf . nn . embedding _ lookup embeddings 
train _ inputs 现在 我们 有了/nr 每个 单词 的 嵌套 
向量 接下来 就是 使用 噪声 比对 的 训练 方式 来 
预测 目标 单词 找到 最 有可能 是 和 目标 单词 
对应 的 上下文 # 计算 NCE 损失 函数 每次 使用 
负 标签 的 样本 . loss = tf . reduce 
_ mean tf . nn . nce _ loss nce 
_ weights nce _ biases embed train _ labels num 
_ sampled vocabulary _ size 我们 对 损失 函数 建立 
了 图形 节点 然后 我们 需要 计算 相应 梯度 和 
更新 参数 的 节点 比如说 在 这里 我们 会 使用 
随机 梯度 下 降法 TensorFlow 也 已经 封装 好了 该 
过程 # 使用 SGD 控制器 . optimizer = tf . 
train . G r a d i e n t 
D e s c e n t O p t 
i m i z e r learning _ rate = 
1.0 . minimize loss 0x5 训练 模型 训练 的 过程 
很 简单 只要在 循环 中 使用 feed _ dict 不断 
给 占位符 填充 数据 同时 调用 session . run 即可 
for inputs labels in generate _ batch . . . 
feed _ dict = { training _ inputs inputs training 
_ labels labels } _ cur _ loss = session 
. run optimizer loss feed _ dict = feed _ 
dict 0x6 嵌套 学习 结果 可视化 # Copyright 2015 The 
TensorFlow Authors . All Rights Reserved . # # Licensed 
under the Apache License Version 2.0 the License # you 
may not use this file except in compliance with the 
License . # You may obtain a copy of the 
License at # # http / / www . apache 
. org / licenses / LICENSE 2.0 # # Unless 
required by applicable law or agreed to in writing software 
# distributed under the License is distributed on an AS 
IS BASIS # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND 
either express or implied . # See the License for 
the specific language governing permissions and # limitations under the 
License . # = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= from _ _ future _ _ import absolute _ 
import from _ _ future _ _ import division from 
_ _ future _ _ import print _ function import 
collections import math import os import random import zipfile import 
numpy as np from six . moves import urllib from 
six . moves import xrange # pylint disable = redefined 
builtin import tensorflow as tf # Step 1 Download the 
data . url = http / / mattmahoney . net 
/ dc / def maybe _ download filename expected _ 
bytes Download a file if not present and make sure 
it s the right size . if not os . 
path . exists filename filename _ = urllib . request 
. urlretrieve url + filename filename statinfo = os . 
stat filename if statinfo . st _ size = = 
expected _ bytes print Found and verified filename else print 
statinfo . st _ size raise Exception Failed to verify 
+ filename + . Can you get to it with 
a browser return filename filename = maybe _ download text8 
. zip 31344016 # Read the data into a list 
of strings . def read _ data filename Extract the 
first file enclosed in a zip file as a list 
of words with zipfile . ZipFile filename as f data 
= tf . compat . as _ str f . 
read f . namelist 0 . split return data words 
= read _ data filename print Data size len words 
# Step 2 Build the dictionary and replace rare words 
with UNK token . vocabulary _ size = 50000 def 
build _ dataset words count = UNK 1 count . 
extend collections . Counter words . most _ common vocabulary 
_ size 1 dictionary = dict for word _ in 
count dictionary word = len dictionary data = list unk 
_ count = 0 for word in words if word 
in dictionary index = dictionary word else index = 0 
# dictionary UNK unk _ count + = 1 data 
. append index count 0 1 = unk _ count 
reverse _ dictionary = dict zip dictionary . values dictionary 
. keys return data count dictionary reverse _ dictionary data 
count dictionary reverse _ dictionary = build _ dataset words 
del words # Hint to reduce memory . print Most 
common words + UNK count 5 print Sample data data 
10 reverse _ dictionary i for i in data 10 
data _ index = 0 # Step 3 Function to 
generate a training batch for the skip gram model . 
def generate _ batch batch _ size num _ skips 
skip _ window global data _ index assert batch _ 
size % num _ skips = = 0 assert num 
_ skips = 2 * skip _ window batch = 
np . ndarray shape = batch _ size dtype = 
np . int32 labels = np . ndarray shape = 
batch _ size 1 dtype = np . int32 span 
= 2 * skip _ window + 1 # skip 
_ window target skip _ window buffer = collections . 
deque maxlen = span for _ in range span buffer 
. append data data _ index data _ index = 
data _ index + 1 % len data for i 
in range batch _ size / / num _ skips 
target = skip _ window # target label at the 
center of the buffer targets _ to _ avoid = 
skip _ window for j in range num _ skips 
while target in targets _ to _ avoid target = 
random . randint 0 span 1 targets _ to _ 
avoid . append target batch i * num _ skips 
+ j = buffer skip _ window labels i * 
num _ skips + j 0 = buffer target buffer 
. append data data _ index data _ index = 
data _ index + 1 % len data # Backtrack 
a little bit to avoid skipping words in the end 
of a batch data _ index = data _ index 
+ len data span % len data return batch labels 
batch labels = generate _ batch batch _ size = 
8 num _ skips = 2 skip _ window = 
1 for i in range 8 print batch i reverse 
_ dictionary batch i labels i 0 reverse _ dictionary 
labels i 0 # Step 4 Build and train a 
skip gram model . batch _ size = 128 embedding 
_ size = 128 # Dimension of the embedding vector 
. skip _ window = 1 # How many words 
to consider left and right . num _ skips = 
2 # How many times to reuse an input to 
generate a label . # We pick a random validation 
set to sample nearest neighbors . Here we limit the 
# validation samples to the words that have a low 
numeric ID which by # construction are also the most 
frequent . valid _ size = 16 # Random set 
of words to evaluate similarity on . valid _ window 
= 100 # Only pick dev samples in the head 
of the distribution . valid _ examples = np . 
random . choice valid _ window valid _ size replace 
= False num _ sampled = 64 # Number of 
negative examples to sample . graph = tf . Graph 
with graph . as _ default # Input data . 
train _ inputs = tf . placeholder tf . int32 
shape = batch _ size train _ labels = tf 
. placeholder tf . int32 shape = batch _ size 
1 valid _ dataset = tf . constant valid _ 
examples dtype = tf . int32 # Ops and variables 
pinned to the CPU because of missing GPU implementation with 
tf . device / cpu 0 # Look up embeddings 
for inputs . embeddings = tf . Variable tf . 
random _ uniform vocabulary _ size embedding _ size 1.0 
1.0 embed = tf . nn . embedding _ lookup 
embeddings train _ inputs # Construct the variables for the 
NCE loss nce _ weights = tf . Variable tf 
. truncated _ normal vocabulary _ size embedding _ size 
stddev = 1.0 / math . sqrt embedding _ size 
nce _ biases = tf . Variable tf . zeros 
vocabulary _ size # Compute the average NCE loss for 
the batch . # tf . nce _ loss automatically 
draws a new sample of the negative labels each # 
time we evaluate the loss . loss = tf . 
reduce _ mean tf . nn . nce _ loss 
weights = nce _ weights biases = nce _ biases 
labels = train _ labels inputs = embed num _ 
sampled = num _ sampled num _ classes = vocabulary 
_ size # Construct the SGD optimizer using a learning 
rate of 1.0 . optimizer = tf . train . 
G r a d i e n t D e 
s c e n t O p t i m 
i z e r 1.0 . minimize loss # Compute 
the cosine similarity between minibatch examples and all embeddings . 
norm = tf . sqrt tf . reduce _ sum 
tf . square embeddings 1 keep _ dims = True 
normalized _ embeddings = embeddings / norm valid _ embeddings 
= tf . nn . embedding _ lookup normalized _ 
embeddings valid _ dataset similarity = tf . matmul valid 
_ embeddings normalized _ embeddings transpose _ b = True 
# Add variable initializer . init = tf . global 
_ variables _ initializer # Step 5 Begin training . 
num _ steps = 100001 with tf . Session graph 
= graph as session # We must initialize all variables 
before we use them . init . run print Initialized 
average _ loss = 0 for step in xrange num 
_ steps batch _ inputs batch _ labels = generate 
_ batch batch _ size num _ skips skip _ 
window feed _ dict = { train _ inputs batch 
_ inputs train _ labels batch _ labels } # 
We perform one update step by evaluating the optimizer op 
including it # in the list of returned values for 
session . run _ loss _ val = session . 
run optimizer loss feed _ dict = feed _ dict 
average _ loss + = loss _ val if step 
% 2000 = = 0 if step 0 average _ 
loss / = 2000 # The average loss is an 
estimate of the loss over the last 2000 batches . 
print Average loss at step step average _ loss average 
_ loss = 0 # Note that this is expensive 
~ 20% slowdown if computed every 500 steps if step 
% 10000 = = 0 sim = similarity . eval 
for i in xrange valid _ size valid _ word 
= reverse _ dictionary valid _ examples i top _ 
k = 8 # number of nearest neighbors nearest = 
sim i . argsort 1 top _ k + 1 
log _ str = Nearest to % s % valid 
_ word for k in xrange top _ k close 
_ word = reverse _ dictionary nearest k log _ 
str = % s % s % log _ str 
close _ word print log _ str final _ embeddings 
= normalized _ embeddings . eval # Step 6 Visualize 
the embeddings . def plot _ with _ labels low 
_ dim _ embs labels filename = tsne . png 
assert low _ dim _ embs . shape 0 = 
len labels More labels than embeddings plt . figure figsize 
= 18 18 # in inches for i label in 
enumerate labels x y = low _ dim _ embs 
i plt . scatter x y plt . annotate label 
xy = x y xytext = 5 2 textcoords = 
offset points ha = right va = bottom plt . 
savefig filename try from sklearn . manifold import TSNE import 
matplotlib . pyplot as plt tsne = TSNE perplexity = 
30 n _ components = 2 init = pca n 
_ iter = 5000 plot _ only = 500 low 
_ dim _ embs = tsne . fit _ transform 
final _ embeddings plot _ only labels = reverse _ 
dictionary i for i in xrange plot _ only plot 
_ with _ labels low _ dim _ embs labels 
except ImportError print Please install sklearn matplotlib and scipy to 
visualize embeddings . 0x7 嵌套 学习 的 评估 类比推理 词 
嵌 套在 NLP 的 预测 问题 中 是 非常 有用 
且 使用 广泛地 如果 要 检测 一个 模型 是否 是 
可以 成熟 地区 分 词性 或者 区分 专有 名词 的 
模型 最 简单 的 办法 就是 直接 检验 它 的 
预测 词性 语义 关系 的 能力 比如 让 它 解决 
形如 king is to queen as father is to 这样 
的 问题 这种方法 叫做 类比推理 # Copyright 2015 Google Inc 
. All Rights Reserved . # # Licensed under the 
Apache License Version 2.0 the License # you may not 
use this file except in compliance with the License . 
# You may obtain a copy of the License at 
# # http / / www . apache . org 
/ licenses / LICENSE 2.0 # # Unless required by 
applicable law or agreed to in writing software # distributed 
under the License is distributed on an AS IS BASIS 
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express 
or implied . # See the License for the specific 
language governing permissions and # limitations under the License . 
# = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = Multi 
threaded word2vec mini batched skip gram model . Trains the 
model described in Mikolov et . al . Efficient Estimation 
of Word Representations in Vector Space ICLR 2013 . http 
/ / arxiv . org / abs / 1301.3781 This 
model does traditional minibatching . The key ops used are 
* placeholder for feeding in tensors for each example . 
* embedding _ lookup for fetching rows from the embedding 
matrix . * sigmoid _ cross _ entropy _ with 
_ logits to calculate the loss . * G r 
a d i e n t D e s c 
e n t O p t i m i z 
e r for optimizing the loss . * skipgram custom 
op that does input processing . from _ _ future 
_ _ import absolute _ import from _ _ future 
_ _ import division from _ _ future _ _ 
import print _ function import os import sys import threading 
import time import tensorflow . python . platform from six 
. moves import xrange # pylint disable = redefined builtin 
import numpy as np import tensorflow as tf from tensorflow 
. models . embedding import gen _ word2vec as word2vec 
flags = tf . app . flags flags . DEFINE 
_ string save _ path None Directory to write the 
model and training summaries . flags . DEFINE _ string 
train _ data None Training text file . E . 
g . unzipped file http / / mattmahoney . net 
/ dc / text8 . zip . flags . DEFINE 
_ string eval _ data None File consisting of analogies 
of four tokens . embedding 2 embedding 1 + embedding 
3 should be close to embedding 4 . E . 
g . https / / word2vec . googlecode . com 
/ svn / trunk / questions words . txt . 
flags . DEFINE _ integer embedding _ size 200 The 
embedding dimension size . flags . DEFINE _ integer epochs 
_ to _ train 15 Number of epochs to train 
. Each epoch processes the training data once completely . 
flags . DEFINE _ float learning _ rate 0.2 Initial 
learning rate . flags . DEFINE _ integer num _ 
neg _ samples 100 Negative samples per training example . 
flags . DEFINE _ integer batch _ size 16 Number 
of training examples processed per step size of a minibatch 
. flags . DEFINE _ integer concurrent _ steps 12 
The number of concurrent training steps . flags . DEFINE 
_ integer window _ size 5 The number of words 
to predict to the left and right of the target 
word . flags . DEFINE _ integer min _ count 
5 The minimum number of word occurrences for it to 
be included in the vocabulary . flags . DEFINE _ 
float subsample 1e 3 Subsample threshold for word occurrence . 
Words that appear with higher frequency will be randomly down 
sampled . Set to 0 to disable . flags . 
DEFINE _ boolean interactive False If true enters an IPython 
interactive session to play with the trained model . E 
. g . try model . analogy france paris russia 
and model . nearby proton elephant maxwell flags . DEFINE 
_ integer statistics _ interval 5 Print statistics every n 
seconds . flags . DEFINE _ integer summary _ interval 
5 Save training summary to file every n seconds rounded 
up to statistics interval . flags . DEFINE _ integer 
checkpoint _ interval 600 Checkpoint the model i . e 
. save the parameters every n seconds rounded up to 
statistics interval . FLAGS = flags . FLAGS class Options 
object Options used by our word2vec model . def _ 
_ init _ _ self # Model options . # 
Embedding dimension . self . emb _ dim = FLAGS 
. embedding _ size # Training options . # The 
training text file . self . train _ data = 
FLAGS . train _ data # Number of negative samples 
per example . self . num _ samples = FLAGS 
. num _ neg _ samples # The initial learning 
rate . self . learning _ rate = FLAGS . 
learning _ rate # Number of epochs to train . 
After these many epochs the learning # rate decays linearly 
to zero and the training stops . self . epochs 
_ to _ train = FLAGS . epochs _ to 
_ train # Concurrent training steps . self . concurrent 
_ steps = FLAGS . concurrent _ steps # Number 
of examples for one training step . self . batch 
_ size = FLAGS . batch _ size # The 
number of words to predict to the left and right 
of the target word . self . window _ size 
= FLAGS . window _ size # The minimum number 
of word occurrences for it to be included in the 
# vocabulary . self . min _ count = FLAGS 
. min _ count # Subsampling threshold for word occurrence 
. self . subsample = FLAGS . subsample # How 
often to print statistics . self . statistics _ interval 
= FLAGS . statistics _ interval # How often to 
write to the summary file rounds up to the nearest 
# statistics _ interval . self . summary _ interval 
= FLAGS . summary _ interval # How often to 
write checkpoints rounds up to the nearest statistics # interval 
. self . checkpoint _ interval = FLAGS . checkpoint 
_ interval # Where to write out summaries . self 
. save _ path = FLAGS . save _ path 
# Eval options . # The text file for eval 
. self . eval _ data = FLAGS . eval 
_ data class Word2Vec object Word2Vec model Skipgram . def 
_ _ init _ _ self options session self . 
_ options = options self . _ session = session 
self . _ word2id = { } self . _ 
id2word = self . build _ graph self . build 
_ eval _ graph self . save _ vocab self 
. _ read _ analogies def _ read _ analogies 
self Reads through the analogy question file . Returns questions 
a n 4 numpy array containing the analogy question s 
word ids . questions _ skipped questions skipped due to 
unknown words . questions = questions _ skipped = 0 
with open self . _ options . eval _ data 
rb as analogy _ f for line in analogy _ 
f if line . startswith b # Skip comments . 
continue words = line . strip . lower . split 
b ids = self . _ word2id . get w 
. strip for w in words if None in ids 
or len ids = 4 questions _ skipped + = 
1 else questions . append np . array ids print 
Eval analogy file self . _ options . eval _ 
data print Questions len questions print Skipped questions _ skipped 
self . _ analogy _ questions = np . array 
questions dtype = np . int32 def forward self examples 
labels Build the graph for the forward pass . opts 
= self . _ options # Declare all variables we 
need . # Embedding vocab _ size emb _ dim 
init _ width = 0.5 / opts . emb _ 
dim emb = tf . Variable tf . random _ 
uniform opts . vocab _ size opts . emb _ 
dim init _ width init _ width name = emb 
self . _ emb = emb # Softmax weight vocab 
_ size emb _ dim . Transposed . sm _ 
w _ t = tf . Variable tf . zeros 
opts . vocab _ size opts . emb _ dim 
name = sm _ w _ t # Softmax bias 
emb _ dim . sm _ b = tf . 
Variable tf . zeros opts . vocab _ size name 
= sm _ b # Global step scalar i . 
e . shape . self . global _ step = 
tf . Variable 0 name = global _ step # 
Nodes to compute the nce loss w / candidate sampling 
. labels _ matrix = tf . reshape tf . 
cast labels dtype = tf . int64 opts . batch 
_ size 1 # Negative sampling . sampled _ ids 
_ _ = tf . nn . fixed _ unigram 
_ candidate _ sampler true _ classes = labels _ 
matrix num _ true = 1 num _ sampled = 
opts . num _ samples unique = True range _ 
max = opts . vocab _ size distortion = 0.75 
unigrams = opts . vocab _ counts . tolist # 
Embeddings for examples batch _ size emb _ dim example 
_ emb = tf . nn . embedding _ lookup 
emb examples # Weights for labels batch _ size emb 
_ dim true _ w = tf . nn . 
embedding _ lookup sm _ w _ t labels # 
Biases for labels batch _ size 1 true _ b 
= tf . nn . embedding _ lookup sm _ 
b labels # Weights for sampled ids num _ sampled 
emb _ dim sampled _ w = tf . nn 
. embedding _ lookup sm _ w _ t sampled 
_ ids # Biases for sampled ids num _ sampled 
1 sampled _ b = tf . nn . embedding 
_ lookup sm _ b sampled _ ids # True 
logits batch _ size 1 true _ logits = tf 
. reduce _ sum tf . mul example _ emb 
true _ w 1 + true _ b # Sampled 
logits batch _ size num _ sampled # We replicate 
sampled noise lables for all examples in the batch # 
using the matmul . sampled _ b _ vec = 
tf . reshape sampled _ b opts . num _ 
samples sampled _ logits = tf . matmul example _ 
emb sampled _ w transpose _ b = True + 
sampled _ b _ vec return true _ logits sampled 
_ logits def nce _ loss self true _ logits 
sampled _ logits Build the graph for the NCE loss 
. # cross entropy logits labels opts = self . 
_ options true _ xent = tf . nn . 
sigmoid _ cross _ entropy _ with _ logits true 
_ logits tf . ones _ like true _ logits 
sampled _ xent = tf . nn . sigmoid _ 
cross _ entropy _ with _ logits sampled _ logits 
tf . zeros _ like sampled _ logits # NCE 
loss is the sum of the true and noise sampled 
words # contributions averaged over the batch . nce _ 
loss _ tensor = tf . reduce _ sum true 
_ xent + tf . reduce _ sum sampled _ 
xent / opts . batch _ size return nce _ 
loss _ tensor def optimize self loss Build the graph 
to optimize the loss function . # Optimizer nodes . 
# Linear learning rate decay . opts = self . 
_ options words _ to _ train = float opts 
. words _ per _ epoch * opts . epochs 
_ to _ train lr = opts . learning _ 
rate * tf . maximum 0.0001 1.0 tf . cast 
self . _ words tf . float32 / words _ 
to _ train self . _ lr = lr optimizer 
= tf . train . G r a d i 
e n t D e s c e n t 
O p t i m i z e r lr 
train = optimizer . minimize loss global _ step = 
self . global _ step gate _ gradients = optimizer 
. GATE _ NONE self . _ train = train 
def build _ eval _ graph self Build the eval 
graph . # Eval graph # Each analogy task is 
to predict the 4th word d given three # words 
a b c . E . g . a = 
italy b = rome c = france we should # 
predict d = paris . # The eval feeds three 
vectors of word ids for a b c each of 
# which is of size N where N is the 
number of analogies we want to # evaluate in one 
batch . analogy _ a = tf . placeholder dtype 
= tf . int32 # N analogy _ b = 
tf . placeholder dtype = tf . int32 # N 
analogy _ c = tf . placeholder dtype = tf 
. int32 # N # Normalized word embeddings of shape 
vocab _ size emb _ dim . nemb = tf 
. nn . l2 _ normalize self . _ emb 
1 # Each row of a _ emb b _ 
emb c _ emb is a word s embedding vector 
. # They all have the shape N emb _ 
dim a _ emb = tf . gather nemb analogy 
_ a # a s embs b _ emb = 
tf . gather nemb analogy _ b # b s 
embs c _ emb = tf . gather nemb analogy 
_ c # c s embs # We expect that 
d s embedding vectors on the unit hyper sphere is 
# near c _ emb + b _ emb a 
_ emb which has the shape N emb _ dim 
. target = c _ emb + b _ emb 
a _ emb # Compute cosine distance between each pair 
of target and vocab . # dist has shape N 
vocab _ size . dist = tf . matmul target 
nemb transpose _ b = True # For each question 
row in dist find the top 4 words . _ 
pred _ idx = tf . nn . top _ 
k dist 4 # Nodes for computing neighbors for a 
given word according to # their cosine distance . nearby 
_ word = tf . placeholder dtype = tf . 
int32 # word id nearby _ emb = tf . 
gather nemb nearby _ word nearby _ dist = tf 
. matmul nearby _ emb nemb transpose _ b = 
True nearby _ val nearby _ idx = tf . 
nn . top _ k nearby _ dist min 1000 
self . _ options . vocab _ size # Nodes 
in the construct graph which are used by training and 
# evaluation to run / feed / fetch . self 
. _ analogy _ a = analogy _ a self 
. _ analogy _ b = analogy _ b self 
. _ analogy _ c = analogy _ c self 
. _ analogy _ pred _ idx = pred _ 
idx self . _ nearby _ word = nearby _ 
word self . _ nearby _ val = nearby _ 
val self . _ nearby _ idx = nearby _ 
idx def build _ graph self Build the graph for 
the full model . opts = self . _ options 
# The training data . A text file . words 
counts words _ per _ epoch self . _ epoch 
self . _ words examples labels = word2vec . skipgram 
filename = opts . train _ data batch _ size 
= opts . batch _ size window _ size = 
opts . window _ size min _ count = opts 
. min _ count subsample = opts . subsample opts 
. vocab _ words opts . vocab _ counts opts 
. words _ per _ epoch = self . _ 
session . run words counts words _ per _ epoch 
opts . vocab _ size = len opts . vocab 
_ words print Data file opts . train _ data 
print Vocab size opts . vocab _ size 1 + 
UNK print Words per epoch opts . words _ per 
_ epoch self . _ examples = examples self . 
_ labels = labels self . _ id2word = opts 
. vocab _ words for i w in enumerate self 
. _ id2word self . _ word2id w = i 
true _ logits sampled _ logits = self . forward 
examples labels loss = self . nce _ loss true 
_ logits sampled _ logits tf . scalar _ summary 
NCE loss loss self . _ loss = loss self 
. optimize loss # Properly initialize all variables . tf 
. initialize _ all _ variables . run self . 
saver = tf . train . Saver def save _ 
vocab self Save the vocabulary to a file so the 
model can be reloaded . opts = self . _ 
options with open os . path . join opts . 
save _ path vocab . txt w as f for 
i in xrange opts . vocab _ size f . 
write % s % d \ n % tf . 
compat . as _ text opts . vocab _ words 
i opts . vocab _ counts i def _ train 
_ thread _ body self initial _ epoch = self 
. _ session . run self . _ epoch while 
True _ epoch = self . _ session . run 
self . _ train self . _ epoch if epoch 
= initial _ epoch break def train self Train the 
model . opts = self . _ options initial _ 
epoch initial _ words = self . _ session . 
run self . _ epoch self . _ words summary 
_ op = tf . merge _ all _ summaries 
summary _ writer = tf . train . SummaryWriter opts 
. save _ path graph _ def = self . 
_ session . graph _ def workers = for _ 
in xrange opts . concurrent _ steps t = threading 
. Thread target = self . _ train _ thread 
_ body t . start workers . append t last 
_ words last _ time last _ summary _ time 
= initial _ words time . time 0 last _ 
checkpoint _ time = 0 while True time . sleep 
opts . statistics _ interval # Reports our progress once 
a while . epoch step loss words lr = self 
. _ session . run self . _ epoch self 
. global _ step self . _ loss self . 
_ words self . _ lr now = time . 
time last _ words last _ time rate = words 
now words last _ words / now last _ time 
print Epoch % 4d Step % 8d lr = % 
5.3 f loss = % 6.2 f words / sec 
= % 8.0 f \ r % epoch step lr 
loss rate end = sys . stdout . flush if 
now last _ summary _ time opts . summary _ 
interval summary _ str = self . _ session . 
run summary _ op summary _ writer . add _ 
summary summary _ str step last _ summary _ time 
= now if now last _ checkpoint _ time opts 
. checkpoint _ interval self . saver . save self 
. _ session opts . save _ path + model 
global _ step = step . astype int last _ 
checkpoint _ time = now if epoch = initial _ 
epoch break for t in workers t . join return 
epoch def _ predict self analogy Predict the top 4 
answers for analogy questions . idx = self . _ 
session . run self . _ analogy _ pred _ 
idx { self . _ analogy _ a analogy 0 
self . _ analogy _ b analogy 1 self . 
_ analogy _ c analogy 2 } return idx def 
eval self Evaluate analogy questions and reports accuracy . # 
How many questions we get right at precision @ 1 
. correct = 0 total = self . _ analogy 
_ questions . shape 0 start = 0 while start 
total limit = start + 2500 sub = self . 
_ analogy _ questions start limit idx = self . 
_ predict sub start = limit for question in xrange 
sub . shape 0 for j in xrange 4 if 
idx question j = = sub question 3 # Bingo 
We predicted correctly . E . g . italy rome 
france paris . correct + = 1 break elif idx 
question j in sub question 3 # We need to 
skip words already in the question . continue else # 
The correct label is not the precision @ 1 break 
print print Eval % 4d / % d accuracy = 
% 4.1 f % % % correct total correct * 
100.0 / total def analogy self w0 w1 w2 Predict 
word w3 as in w0 w1 vs w2 w3 . 
wid = np . array self . _ word2id . 
get w 0 for w in w0 w1 w2 idx 
= self . _ predict wid for c in self 
. _ id2word i for i in idx 0 if 
c not in w0 w1 w2 return c return unknown 
def nearby self words num = 20 Prints out nearby 
words given a list of words . ids = np 
. array self . _ word2id . get x 0 
for x in words vals idx = self . _ 
session . run self . _ nearby _ val self 
. _ nearby _ idx { self . _ nearby 
_ word ids } for i in xrange len words 
print \ n % s \ n = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = = = = = = = 
= = = = % words i for neighbor distance 
in zip idx i num vals i num print % 
20s % 6.4 f % self . _ id2word neighbor 
distance def _ start _ shell local _ ns = 
None # An interactive shell is useful for debugging / 
development . import IPython user _ ns = { } 
if local _ ns user _ ns . update local 
_ ns user _ ns . update globals IPython . 
start _ ipython argv = user _ ns = user 
_ ns def main _ Train a word2vec model . 
if not FLAGS . train _ data or not FLAGS 
. eval _ data or not FLAGS . save _ 
path print train _ data eval _ data and save 
_ path must be specified . sys . exit 1 
opts = Options with tf . Graph . as _ 
default tf . Session as session model = Word2Vec opts 
session for _ in xrange opts . epochs _ to 
_ train model . train # Process one epoch model 
. eval # Eval analogies . # Perform a final 
save . model . saver . save session os . 
path . join opts . save _ path model . 
ckpt global _ step = model . global _ step 
if FLAGS . interactive # E . g . # 
0 model . analogy france paris russia # 1 model 
. nearby proton elephant maxwell _ start _ shell locals 
if _ _ name _ _ = = _ _ 
main _ _ tf . app . run curl http 
/ / mattmahoney . net / dc / text8 . 
zip text8 . zip unzip text8 . zip curl https 
/ / storage . googleapis . com / google code 
archive source / v2 / code . google . com 
/ word2vec / source archive . zip source archive . 
zip unzip p source archive . zip word2vec / trunk 
/ questions words . txt questions words . txt rm 
text8 . zip source archive . zip TF _ INC 
= $ python c import tensorflow as tf print tf 
. sysconfig . get _ include g + + std 
= c + + 11 shared word2vec _ ops . 
cc word2vec _ kernels . cc o word2vec _ ops 
. so fPIC I $ TF _ INC O2 D 
_ GLIBCXX _ USE _ CXX11 _ ABI = 0 
python word2vec _ optimized . py \ train _ data 
= text8 \ eval _ data = questions words . 
txt \ save _ path = . / Relevant Link 
http / / www . cnblogs . com / rocketfan 
/ p / 4976806 . html https / / raw 
. g i t h u b u s e 
r c o n t e n t . com 
/ tensorflow / tensorflow / master / tensorflow / examples 
/ tutorials / word2vec / word2vec _ basic . py 
http / / www . aclweb . org / anthology 
/ N1 http / / msr waypoint . com / 
en us / um / people / gzweig / Pubs 
/ N A A C L 2 0 1 3 
R e g u l a r i t i 
e s . pdf3 1090 http / / www . 
tensorfly . cn / tfdoc / tutorials / word2vec . 
html https / / github . com / tensorflow / 
models / tree / master / tutorials / embedding http 
/ / www . tensorfly . cn / tfdoc / 
tutorials / word2vec . html6 . 循环 神经网络 RNN LSTM 
Long Short Term Memory LSTM 0x1 语言 模型 此 教程 
将 展示 如何 在 高难度 的 语言 模型 中 训练 
循环 神经网络 该 问题 的 目标 是 获得 一个 能 
确定 语句 概率 的 概率模型 为了 做到 这 一点 通过 
之前 已经 给出 的 词语 来 预测 后面 的 词语 
我们 将 使用 PTB Penn Tree Bank 数据集 这 是 
一种 常 用来 衡量 模型 的 基准 同时 它 比较 
小 而且 训练 起来 相对 快速 0x2 LSTM 模型 的 
核心 由 一个 LSTM 单元 组成 其 可以 在 某 
时刻 处理 一个 词语 以及 计算 语句 可能 的 延续性 
的 概率 网络 的 存储状态 由 一个零 矢量 初始化 并在 
读取 每 一个 词语 后 更新 而且 由于 计算 上 
的 原因 我们 将 以 batch _ size 为最 小批量 
来 处理 数据 基础 的 伪代码 就像 下面 这样 lstm 
= rnn _ cell . BasicLSTMCell lstm _ size # 
初始化 LSTM 存储状态 . state = tf . zeros batch 
_ size lstm . state _ size loss = 0.0 
for current _ batch _ of _ words in words 
_ in _ dataset # 每次 处理 一批 词语 后 
更新 状态值 . output state = lstm current _ batch 
_ of _ words state # LSTM 输出 可 用于 
产生 下 一个 词语 的 预测 logits = tf . 
matmul output softmax _ w + softmax _ b probabilities 
= tf . nn . softmax logits loss + = 
loss _ function probabilities target _ words 0x3 截断 反向 
传播 为 使 学习 过程 易于 处理 通常 的 做法 
是 将 反向 传播 的 梯度 在 按 时间 展开 
的 步骤 上照 一个 固定 长度 num _ steps 截断 
通过 在 一次 迭代 中的 每个 时刻 上 提供 长度 
为 num _ steps 的 输入 和 每次 迭代 完成 
之后 反向 传导 这会 很 容易 实现 一个 简化 版 
的 用于 计 算图 创建 的 截断 反向 传播 代码 
# 一次 给定 的 迭代 中的 输入 占位符 . words 
= tf . placeholder tf . int32 batch _ size 
num _ steps lstm = rnn _ cell . BasicLSTMCell 
lstm _ size # 初始化 LSTM 存储状态 . initial _ 
state = state = tf . zeros batch _ size 
lstm . state _ size for i in range len 
num _ steps # 每 处理 一批 词语 后 更新 
状态值 . output state = lstm words i state # 
其余 的 代码 . # . . . final _ 
state = state 迭代 整个 数据集 # 一个 numpy 数组 
保存 每 一批 词语 之后 的 LSTM 状态 . numpy 
_ state = initial _ state . eval total _ 
loss = 0.0 for current _ batch _ of _ 
words in words _ in _ dataset numpy _ state 
current _ loss = session . run final _ state 
loss # 通过 上 一次 迭代 结果 初始化 LSTM 状态 
. feed _ dict = { initial _ state numpy 
_ state words current _ batch _ of _ words 
} total _ loss + = current _ loss0x4 输入 
在 输入 LSTM 前 词语 ID 被 嵌入 到 了 
一个 密集 的 表示 中 单词 矢量 表示 可以 在 
不同 的 单词 之间 建立 关联性 的 依据 这种方式 允许 
模型 高效 地 表示 词语 也 便于 写 代码 # 
embedding _ matrix 张量 的 形状 是 vocabulary _ size 
embedding _ size word _ embeddings = tf . nn 
. embedding _ lookup embedding _ matrix word _ ids 
嵌入 的 矩阵 会被 随机 地 初始化 模型 会 学会 
通过 数据 分辨 不同 词语 的 意思 0x5 损失 函数 
我们 想 使 目标 词语 的 平均 负 对数 概率 
最小 论 文中 的 典型 衡量 标准 是 每个 词语 
的 平均 困惑 度 perplexity 计 算式 为 同时 我们 
会 观察 训练 过程 中 的 困惑 度 值 perplexity 
0x6 多个 LSTM 层 堆叠 要想 给 模型 更强 的 
表达 能力 可以 添加 多层 LSTM 来 处理 数据 第一层 
的 输出 作为 第二层 的 输入 以此类推 类 MultiRNNCell 可以 
无缝 的 将其 实现 lstm = rnn _ cell . 
BasicLSTMCell lstm _ size stacked _ lstm = rnn _ 
cell . MultiRNNCell lstm * number _ of _ layers 
initial _ state = state = stacked _ lstm . 
zero _ state batch _ size tf . float32 for 
i in range len num _ steps # 每次 处理 
一批 词语 后 更新 状态值 . output state = stacked 
_ lstm words i state # 其余 的 代码 . 
# . . . final _ state = state0x7 在 
GPU 上 编译 并 运行 wget http / / www 
. fit . vutbr . cz / ~ imikolov / 
rnnlm / simple examples . tgz python ptb _ word 
_ lm . py data _ path = . / 
simple examples / data / alsologtostderr model largeRelevant Link http 
/ / colah . github . io / posts / 
2015 08 Understanding LSTMs / http / / lib . 
csdn . net / article / deeplearning / 59839 http 
/ / www . tensorfly . cn / tfdoc / 
tutorials / recurrent . html7 . 用 深度 学习 网络 
搭建 一个 聊天 机器人 python udc _ train . py 
num _ gpus = 1 python udc _ test . 
py model _ dir = . / data python udc 
_ predict . py model _ dir = . / 
dataimport os import time import itertools import sys import numpy 
as np import tensorflow as tf import udc _ model 
import udc _ hparams import udc _ metrics import udc 
_ inputs from models . dual _ encoder import dual 
_ encoder _ model from models . helpers import load 
_ vocab tf . flags . DEFINE _ string model 
_ dir None Directory to load model checkpoints from tf 
. flags . DEFINE _ string vocab _ processor _ 
file . / data / vocab _ processor . bin 
Saved vocabulary processor file FLAGS = tf . flags . 
FLAGS if not FLAGS . model _ dir print You 
must specify a model directory sys . exit 1 def 
tokenizer _ fn iterator return x . split for x 
in iterator # Load vocabulary vp = tf . contrib 
. learn . preprocessing . V o c a b 
u l a r y P r o c e 
s s o r . restore FLAGS . vocab _ 
processor _ file # Load your own data here INPUT 
_ CONTEXT = how old are you POTENTIAL _ RESPONSES 
= fine thanks twenty six yesrs old def get _ 
features context utterance context _ matrix = np . array 
list vp . transform context utterance _ matrix = np 
. array list vp . transform utterance context _ len 
= len context . split utterance _ len = len 
utterance . split features = { context tf . convert 
_ to _ tensor context _ matrix dtype = tf 
. int64 context _ len tf . constant context _ 
len shape = 1 1 dtype = tf . int64 
utterance tf . convert _ to _ tensor utterance _ 
matrix dtype = tf . int64 utterance _ len tf 
. constant utterance _ len shape = 1 1 dtype 
= tf . int64 } return features None if _ 
_ name _ _ = = _ _ main _ 
_ hparams = udc _ hparams . create _ hparams 
model _ fn = udc _ model . create _ 
model _ fn hparams model _ impl = dual _ 
encoder _ model estimator = tf . contrib . learn 
. Estimator model _ fn = model _ fn model 
_ dir = FLAGS . model _ dir # Ugly 
hack seems to be a bug in Tensorflow # estimator 
. predict doesn t work without this line estimator . 
_ targets _ info = tf . contrib . learn 
. estimators . tensor _ signature . TensorSignature tf . 
constant 0 shape = 1 1 print Context { } 
. format INPUT _ CONTEXT for r in POTENTIAL _ 
RESPONSES prob = estimator . predict input _ fn = 
lambda get _ features INPUT _ CONTEXT r print { 
} { g } . format r prob 0 0 
我们 可以 利用 模型 训练 学习 得到 的 模型 和 
实际 的 场景 进行 对比 例如 我们 认为 INPUT _ 
CONTEXT = how old are you POTENTIAL _ RESPONSES = 
fine thanks twenty six yesrs old 然后 看 模型 是否 
得到 和 我们 假定 的 一样 的 结果 Relevant Link 
http / / naturali . io / deeplearning / chatbot 
/ introduction / 2016 / 04/28 / chatbot part1 . 
html http / / naturali . io / deeplearning / 
chatbot / introduction / 2016 / 05/16 / chatbot part2 
. html https / / arxiv . org / abs 
/ 1506.08909 https / / github . com / dennybritz 
/ chatbot r e t r i e v a 
l C o p y r i g h t 
c 2017 LittleHann All rights reserved 