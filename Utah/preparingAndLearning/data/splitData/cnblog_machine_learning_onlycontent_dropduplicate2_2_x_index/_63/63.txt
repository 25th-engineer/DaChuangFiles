4. Neural Networks (part one)
Content:
4. Neural Networks (part one)
4.1 Non-linear Classification.
4.2 Neural Model(神经元模型)
4.3 Forward Propagation
4.4 神经网络实现与或非门以及异或门
4.4.1 实现与或非门(AND/OR/NOT)
4.4.2 实现异或/同或门(XOR/XNOR)
4.5 Multi-class classification
key words: Neural networks, Neural model, Forward Propagation
4.1 Non-linear Classification
对于非线性的分类问题（如-1所示的非线性0-1分类问题），在特征量较少的情况，我们可以用多项式类型的Logistic回归来处理。但是一旦特征量较多，多项式的Logistic回归就会很困难。因为如果问题原有n个特征量，采用二次多项式特征量个数约等于(n^2)/ 2，也就是O(n^2)，而用三次多项式特征量的个数更是O(n^3)，等等。当n较大时(如n > 1000)，计算机无法承受这么大的向量运算。所以需要一种新的模型（算法）来处理特征量较大的非线性分类问题。
-1 非线性0-1分类问题
那么什么问题会有较多的特征量? 计算机视觉(Computer Vision)领域就常常会遇到。我们知道，对于人类所看到的一张图片，在计算机里是以矩阵存储的。如-2所示，以要判别一张图片是否为汽车的问题为例，我们有一张像素为50*50的图片，即至少一共有2500个像素点()对于RGB的图片有7500个)，所以特征量的个数n = 2500，如果用二次多项式预测，那么特征量个数将变成近3百万！这样计算代价太大了。下面将介绍一种新的模型-神经网络(Neural Networks)，可以不需要通过增加特征量个数来解决非线性分类问题（当然它在其他问题也有应用）。
-2 判断一张图片是否为汽车
4.2 Neural Model(神经元模型)
神经网络是一种模拟大脑的算法。一种较正规的定义是
神经网络是由具有适应性的简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应。
神经网络中最基本的成分是神经元模型(Neural Model)(又称Logistic unit)，即上述定义中的“简单单元”。对于人类而言，我们的视觉听觉是由大脑的神经中枢产生。而神经中枢是由大量的神经元相互连接而成。一个神经元通过树突接受其他神经元传来的化学物质（信息），从而改变该神经元的电位，当电位到达某一阙值(threshold)时，该神经元被激活，即“兴奋”起来，从而通过轴突向其他神经元发送化学物质，如-3所示。
-3 生物神经系统中的神经元
而神经元模型便是模拟上述的神经元接受信息并传递信息的过程。如-4所示，神经元接收来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与神经元的阙值进行比较，再通过激活函数(activation function)处理以产生神经元的输出。
-4 从阙值角度理解的神经元模型
理想中的激活函数是-5(a)所示的阶跃函数，它将输入值映射为输出值“0”或“1”, “1”对应神经元兴奋，“0”对应神经元抑制。但是，阶跃函数具有不连续，不光滑（不连续可导）等不太好的性质，因此实际中常用Logistic回归中应用到的sigmoid函数作为激活函数。典型的sigmoid函数如-5(b)所示，它把可能在较大范围内变化的输入值挤压到(0, 1)输出值范围内，因此有时又称之为“挤压函数”(squashing function).
-5 典型的神经元激活函数（图片来自《机器学习》， 周志华）
-6 从偏移单元角度理解的神经元模型
4.3 Forward Propagation
4.2节已经学习了神经网络的最基本成分-神经元模型，下面将介绍如何用神经元搭建多层前馈神经网络(multi-layer feedforward neural)和Forward Propagation算法。
如-7所示，多次前馈神经网络有三部分组成，分别是输入层(input layer)，隐藏层(hide layer)，输出层(output layer)。隐藏层可以有，也可以没有，输入层和输出层必须要有。没有隐藏层的神经网络是线性的，只能处理线性可分的问题（线性可分问题从二维的角度就是分界线是一条直线，多维就是存在线性超平面将其分类）。一个没有隐藏层且输出层只有一个单元的神经网络就相当于线性的Logistic模型。
-7 一个含两层隐藏层的多次前馈神经网络
前向传播(Forward Propagation)算法就是利用已经训练出的连接权重(或称映射权重)和4.2节神经元模型中的输出公式(1)来计算出每一层每一个神经元的激活值(activation)，最终得到输出层的激活值，也就是输出值.
-8给出了在一个具体的神经网络使用前向传播算法的例子，其中，激活函数是sigmoid函数g(x);
-8 一个使用前向传播算法(向量实现)的例子
4.4 神经网络实现与或非门以及异或门
4.4.1 实现与或非门(AND/OR/NOT)
4.4.2 实现异或/同或门(XOR/XNOR)
在4.4.1小节中发现，实现与或非门只需要输入层和输出层，不需要隐藏层，也就是说与或非问题是线性可分的。但是，异或/同或却是非线性可分的，如-9所示。
-9 异或/同或问题
在数字逻辑中我们知道可以利用与或非门搭出异或/同或门，那是因为有如下运算法则，
a XOR b = ((NOT a) AND b) OR (a AND (NOT b));
a XNOR b = NOT (a XOR b) = (a AND b) OR ((NOT a) AND (NOT b))
既然我们用神经网络实现了与或非门，那么也有理由可以实现异或和同或门，-10以实现同或门为例(只需在同或门后加上一个非门实现了异或门)。
-10 实现同或门
4.5 Multi-class classification
对于多分类问题，在2.6节已经用Logistic回归模型讨论过了。现在用神经网络来处理。假设我们需要识别一张图片是行人，汽车，摩托车，还是卡车，也就是有4种类别。所以我们设计如-10所示的神经网络。由于一共有4类，所以该神经网络有4个输出单元，分别将其标号为1，2，3，4，对应行人，汽车，摩托车，卡车。每次预测输出的是一个4维向量。所以我们的训练集相比于Logistic回归模型要做改变，即每一个样例的结果y(i)也是一个4维向量且是[1 0 0 0 ]’, [0 1 0 0]’, [0 0 1 0]’, [0 0 0 1]’中的一个。至于预测时的结果分析和Logistic回归模型中使用的One-vs-all类似，不再重复。仅给出例子如下：
若h = [0.12 0.71 0.13 0.45]’，则就相当于[0 1 0 0]’，故为第二个输出单元的标记，也就是汽车；
若h =[0.12 0.64 0.83 0.21]’, 则就相当于[0 1 1 0]’，此时我们选择置信度最大的，也就是max h = 0.83，即第三个输出单元的标记，也就是摩托车。
不管怎样，都是选择向量中最大的一个元素的标记(下标)，即matlab中的max(h, [], 2).
-11 一个处理4分类问题的神经网络
参考：
《机器学习》 周志华