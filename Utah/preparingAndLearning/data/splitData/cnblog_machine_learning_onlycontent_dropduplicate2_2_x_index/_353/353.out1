写 在前面 想 了 一下 这门 MOOC 可能 更 适合 
大一 大二 的 本科生 和 跨专业 学生 吧 本文 属于 
知识 分享 有兴趣 的 朋友 可以 结合 MOOC 看 这篇 
音译 P5 C 10.2 15分 59秒 下面 我们 讲 第十章 
第一节 Classification 分类 我们 首先 给出 分类 的 定义 根据 
定义 描述 的 长度 我们 给出 三种 定义 首先 给 
出 一个 较长 的 定义 分类 是 这样 一种 任务 
它 基于 已知 类别 的 训练 数据集 来 辨识 新的 
观测 数据 属于 哪 一组 类别 较短 的 描述 分类 
用于 解决 这样 一些 问题 其中 输出 被 分为 两个 
或 多个 类别 最短 的 描述 分类 是 对 每个 
输入 数据 下 指定 一个 类别 这三种 定义 尽管 描述 
的 长短 不同 但 他们 对 分类 的 要素 是 
相同 的 也 就是说 对 输入 数据 划分为 类别 并且 
这个 类别 是 已知 的 第一节 分成 四个 小节 首先 
我们 看 一下 分类 是 如何 工作 的 分类 需要 
有 一个 分类器 Classifier 什么 是 分类器 呢 它 是 
一种 实现 分类 功能 尤其 是 一种 具体 去 实现 
分类 的 算法 被 称为 一个 分类器 Classifier 下面 我们 
介绍 一下 分类 函数 Classifier function 分类器 这个 术语 有时 
还指 的 是由 分类 算法 所 实现 的 数学 函数 
它 将 输入 数据 映射 为 一个 类别 这张 图 
刻画 了 分类 的 训练 过程 即 Training 训练 数据 
是 一个 已 标注 的 数据 Labeled Data 即 这些 
训练 数据 的 类别 是 已知 的 有 一个 x 
通过 labeling function 标注 得到 y 标注 的 目的 呢 
是 创建 训练样本 通常 采用 手工 标注 的 方法 训练样本 
建立 好 之后 就 用来 对 学习 算法 f x 
进行 训练 每次 输入 一组 x y 的 训练 数据 
通过 训练 之后 我们 希望 得到 一个 h x h 
x 是 Hypothesis 假定 函数 集合 当中 的 一个 函数 
它 也 被称为 叫做 分类 函数 这个 分类 函数 h 
x 和 我们 目标 的 f x 之间 要 满足 
具有 最小 的 泛化 和 经验 错误 分类 算法 训练 
好了 之后 我们 得到 了 h x 就 可以 用来 
进行 实际 的 分类 了 我们 如图所示 这个 时候 的 
输入 数据 是 未知 数据 我们 根据 已 经训 练好 
的 假定 函数 h x 进行 分类 得到 相应 的 
y 的 映像 最后 得到 分类 结果 我们 看 在 
未知 类别 的 时候 通过 分类 得到 了 已知 的 
类别 刚才 的 两页 分别 是 分类 算法 的 训练 
和 实测 的 示意图 下面 给 出 一种 分类 的 
形式化 描述 设 Rn 表示 一个 n 维 实数 向量 
集合 输入 空间 X 是 Rn 的 子集 输出 空间 
Y 是 一个 类别 categories D 是 X 与 Y 
笛卡尔积 上 的 一个 未知 分布 我们 给 定 一个 
标注 函数 labeling function 这个 labeling function 也 可以 称 
其为 分类 函数 classifier function 然后 给 定 一个 训练 
的 集合 training dataset 也 称为 标注 好 的 训练样本 
集合 训练样本 集合 表示 为 x i 和y/nr j 元素 
的 集合 其中 x y 属于 大写 的 X Y 
的 笛卡尔 乘积 i/w 和j的/nr 取值/v 范围/n 分别/d 为/p 1/m 
到/v m/w 和1到/nr n/w 分类 算法 要给 定 一个 假定 
函数 集合 大写 的 H 是 X 到 Y 的 
一个 映射 的 函数 我们 的 目的 是 得到 一个 
假定 的 函数 属于 大写 的 H 集合 当中 的 
一个 小写 的 h h 是 X 到 Y 的 
映射 我们 的 目的 是 使得 h x 与 我们 
既定 的 f x 之间 具有 最小 的 泛化 错误 
和 经验 错误 把 分类 算法 训练 好 以后 已经 
得到 了 h x 我们 在 实际 的 分类 处理 
过程 中 就是 对 未知 的 数据 进行 实际 测试 
未知 的 数据 我们 可以 表示 成 一个 大写 的 
X 的 集合 我们 使用 刚才 已 经训 练好 的 
classifier function 小写 的 h x 将 X 映 射到 
Y 的 过程 我们 通过 分类 得到 这样 一个 分类 
的 集合 小写 的 y 属于 大写 的 Y 的 
空间 并且 呢 j 属于 1 到 n 它 是 
通过 每一个 x 向量 将其 映 射到 y 的 向量 
的 这么 个 过程 其中 大写 的 Y 是 输出 
空间 它 被 称为 一个 叫做 已知 的 类别 的 
集合 下面 我们 讲 第二 小节 线性 分类 和 非线性 
分类 首先 我们 看 线性 分类 所谓 线性 分类 是 
通过 线性 分类器 进行 分类 的 我们 如图所示 我们 会 
看到 有 这样 一个 线性 的 将 二维 数据 空间 
的 数据 分成 两个 类别 一个 线性 分类器 具有 如下 
两个 特征 首先 它 是 一个 线性 判别函数 此外 它 
还 具有 一个 线性 决策 边界 linear decision boundary 我们 
给 一个 简单 的 线性 分类器 的 案例 分析 这 
是 一个 简单 的 线性 分类器 的 一个 表达式 其中 
w 表示 行向量 它 是 权值 的 向量 x 则 
表示 为 列 向量 记作 这个 表达式 其中 b 则 
表示 偏 差值 从 右图 可以 看出 我们 这个 线性 
分类 函数 当 结果 等于 0 的 时候 恰好 为 
这 一条线 大于 0 和 小于 0 分别 将 数据 
分成 两个 类 因此 它 是 一个 线性 的 二元 
分类 的 例子 我们 再 看一下 非线性 分类 所谓 的 
非线性 分类 是 通过 一个 非线性 分类器 进行 分类 的 
非线性 分类器 也有 如下 两个 特点 第一     有 
若干 个 非线性 决定 边界 二 决定 边界 很 可能 
是 非 连续 的 下面 这个 图 呢 就是 一个 
非线性 分类 的 例子 它 通过 支持 向量 机 SVM 
中的 和 函数 来 解决 非线性 分类 问题 关于/p 支持/v 
向量/n 机/n 及其/c 和/c 函数/n 的/uj 介绍/v 的/uj 书籍/n 和/c 
参考/v 资料/n 有/v 很多/m 感 兴趣 的 可以 到 网上 
查阅 一下 那么 对 这张 图 我们 会 看到 这个 
非线性 的 分类器 的 这个 曲线 是非 连续 的 也 
就是说 不是 一条 曲线 可以 把 它 决定 下来 的 
下面 我们 讲 第三 小节 分类 的 维度 和类的/nr 个数 
首先 看 一下 类 的 维度 如果 问题空间 是 n 
维 的 则 它 的 分类器 的 维度 为 n 
1 的 超平面 超平面 英文 称为 hyper plane 例如 对 
二维 数据 来说 它 的 分类器 则是 一条线 也 就是说 
二维 的 数据 的 分类器 是 2 1 是 一维 
的 一条线 同样 对于 三维 的 数据 来说 它 的 
分类器 是 一个 二维 的 平面 如 右边 这两个 图 
所示 下面 我们 再 看一下 类 的 个数 也 就是说 
通过 分类 得到 的 类 的 个数 或者 我们 已知 
的 类 的 个数 为了 叙述 方便 起见 我们 在 
这个 线性 分类器 里面 增加 了 两个 个 下 角标 
k 对于 二元 分类 来说 k 等于 2 当 k 
大于 2时 它 是 一个 多 元 分类 的 问题 
左 下图 是 一个 二元 分类 也 就是说 通过 一条线 
把 数据 分成 两个 部分 这 叫做 二元 分类 当然 
对于 三维空间 的 数据 来说 它 是 一个 二维 的 
平面 多元 分类器 右下角 这个 例子 呢 则 是 一个 
三元 分类 也 就是 把 数据 分成 三个 已知 的 
类别 关于 分类 的 算法 的 介绍 在 其他 书籍 
和 相应 的 资料 呢 有 很多 比如说 支持 向量 
机 通过 线性 回归 的 方法 进行 分类 等等 算法 
很多很多 我们 这里 呢 是 给 一个 案例 分析 是 
分析 这种 叫做 Softmax 的 分类器 Softmax 分类器 呢 是 
一个 多元 分类器 它 通过 softmax 函数 来 实现 多元 
分类 Softmax 函数 如 中间 这个 表达式 所示 它 将 
一个 任意 实数值 的 k 维 向量 x 映射 到 
一个 实数值 的 k 维 向量 其中 j 等于 1 
到 k 表示 k 个 维度 也 就是说 把 它 
分为 k 个 类别 在 概率论 中 softmax 的 函数 
可以 用来 表示 一个 类 的 分布 就是说 一个 涵盖 
K 个 不同 类别 的 可能 结果 的 概率分布 如 
下面 这个 表达式 所示 其中 j 等于 1 到 k 
表示 它 是 第 j 个 类别 Softmax 函数 已经 
被 用于 各种 多元 分类 的 算法 当中 例如 在 
多项式 逻辑 回归 当中 这 里面 logistic regression 用 到了 
regression 这个词 regression 通常 被 翻译 成 回归 我们 后面 
会讲 到 回归 的 问题 但 在 这里 是 用来 
做 分类 的 尽管 它 的 名称 里面 用 到了 
regression 这个词 此外 多元 线性 判别分析 当中 也用 到了 softmax 
函数 此外 还有 朴素 贝叶斯 分类 用 的 比较 多 
的 呢 还有 人工神经网络 softmax 作为 人工 神经 网络 的 
最后 一层 来 进行 多元 分类 右侧 的 这个 图 
就是 多元 神经 网络 的 最后 一层 和 倒数 第一 
层 我们 会 看到 在 倒数 第一 层 经过 全 
连接 将 结果 送到 相应 的 多元 分类 的 神经元 
上 那么 每 一个 我们 会 看到 当 Y = 
1 2 和m的/nr 时候 分别 会 得到 它 相应 的 
类别 下面 讲 第四 小节 分类 的 应用 和 主要 
算法 分类 的 应用 应该 是 在 机器学习 当中 最多 
的 了 例 如像 计算机 视觉 当中 医学影像 与 图像 
分析 手写识别 与 OCR 动作 识别 与 视频 跟踪 等等 
此外 在 模式识别 当中 有 人脸识别 语音识别 指纹 识别 等 
各种 生物 识别 在 自然 语音 处理 当中 也要 大量 
地 用到 了 分类 问题 此外 还有 文档 分类 问题 
例如 垃圾邮件 分类 把 它 分成 垃圾 邮件 和非/nr 垃圾邮件 
此外 在 互联网 搜索引擎 当中 也要 用到 分类 的 问题 
还有 信用 评分 等等 分类 的 代表性 算法 有 很多 
常用 的 有 AdaBoost AdaBoost 是 adaptive boosting 的 缩写 
Boosting 是 一类 自适应 增强 算法 的 名称 此外 我们 
刚才 介绍 了 像 人工神经网络 还有 k 近邻 还有 支持 
向量 机 等等 