背景：本文只是对机器学习相关知识的梳理和复习用，因此顺序上可能有些随意
摘要：
1.各种算法的推导
2.各种算法的比较（或优缺点）
3.学习理论
4.特征选择方法
5.模型选择方法
6.特征工程
7.数据预处理
8.应用例子
内容：
1.各种算法的推导
线性回归（Liner Regression）:9个基本概念和10个基本算法总结的岭（ridge）回归部分  -- 最简单的线性分类器
机器学习-感知机 -- 线性分类器,SVM和神经网络的基石
LR：我的LR复习总结 -- 线性分类器,预测概率
支持向量机（SVM）：我的SVM复习总结 -- 线性/非线性分类器，核方法映射到高维线性可分
DT,RF,GBDT,XGBT:决策树和基于决策树的集成方法（DT,RF,GBDT,XGBT）复习总结 -- 非线性分类器，决策树，规则学习/条件概率
关联规则：FPGrowth算法总结复习 -- FP树，规则学习
KNN:k近邻(KNN)复习总结 -- 非线性模型，KD树和ball tree，基于距离的模型
k-means:K-Means聚类和EM算法复习总结 -- 基于距离的的模型，KD树和ball tree
NB: 朴素贝叶斯（NB）复习总结 -- 线性分类器，判别模型与生成模型
LDA：主题模型——隐式狄利克雷分布总结--概率图模型PGM,NLP
HMM：隐马尔可夫模型（HMM）总结--概率图模型PGM，NLP
CRF:条件随机场CRF
神经网络：我的机器学习/数据挖掘的书单--机器学习中的图模型，仿生学
TextRank与TF-IDF关键词提取--对比LDA语义模型的词义模型
wordEmbedding与Word2Vec/Doc2Vec:deep-learning-nlp-best-practices
CNN:待总结
RNN/LSTM：雪伦RNN的文章   雪伦LSTM的文章
WDL:待总结
2.各种算法的比较（或优缺点）
生成模型和判别模型（是否需要学习联合分布）：生成模型与判别模型
线性模型和非线性模型：机器学习常见面试题整理
LR和决策树类算法的比较：逻辑回归与决策树在分类上的一些区别
Bryan__的整理：机器学习算法比较
机器学习面试知识点总结(不断补充中)
3. 学习理论
理论部分：偏差-方差平衡
正则化：数据预处理中归一化（Normalization）与损失函数中正则化（Regularization）解惑
经验风险最小化与结构风险最小化:Andrew Ng机器学习公开课笔记 -- 学习理论
损失函数和分类模型的评价指标：损失函数和分类器评估方法；
二分类如何转换为多分类：机器学习面试知识点总结(不断补充中)
熵在机器学习中的身影：信息论中的熵（信息熵，联合熵，交叉熵，互信息）和最大熵模型
VC维:Andrew Ng机器学习公开课笔记 -- 学习理论
常见的距离算法和相似度（相关系数）计算方法
UCB与Hoeffing Bound:待总结
4.特征选择方法
使用sklearn做单机特征工程   附：自己实现的代码
特征选择与特征学习方法-jason(1遍)
skelearn中特征选择的一些方法了解
5.模型选择方法
SVM参数详解：SVM参数详解
RF和GBDT参数详解：《使用sklearn进行集成学习——实践》（还在研究）
XGBoost参数调优：XGBoost-Python完全调参指南-参数解释篇 （第二遍，考虑使用排序任务）
LightGBM参数调优:待总结
模型融合（blending和stacking）:http://m.blog.csdn.net/article/details?id=53054686 ( 多数投票/加权平均，自融合，blending，stacking)    github
贝叶斯信息准则(BIC)
你有哪些deep learning（rnn、cnn）调参的经验？
6.特征工程
7种常用的特征工程 （清晰易懂）
特征工程理论部分
美团的数据清洗和特征处理
byran_的总结帖子
sklearn中使用GBDT生成组合特征的例子
特征的生命周期（我的比赛经验总结）
7.数据预处理
weka进行预处理
数据清洗和数据预处理（pandas 和 sklearn）
数据挖掘笔记（三）—数据预处理
降维：用于降维可视化的t-SNE
聚类：kmeans,k-shit,谱聚类,密度聚类
8.应用例子
深入浅出谈数据挖掘——数据挖掘主要解决的四类问题
数赛刷题的冠军链接
使用SVD对图片进行降维的例子（github代码）
利用机器学习模型去做排序任务