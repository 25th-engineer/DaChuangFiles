一 概述 k 近邻 算法 采用 测量 不同 特征值 之间 
的 距离 方法 进行 分类 工作 原理 首先 有 一个 
样本数据 集合 训练样本 集 并且 样本数据 集合 中 每条 数据 
都 存在 标签 分类 即 我们 知道 样本数据 中 每 
一条 数据 与 所属 分类 的 对应 关系 输入 没有 
标签 的 数据 之后 将 新 数据 的 每个 特征 
与 样 本集 的 数据 对应 的 特征 进行 比较 
欧式 距离 运算 然后 算出 新 数据 与 样本 集中 
特征 最 相似 最 近邻 的 数据 的 分类 标签 
一般 我们 选择 样本 数据集 中前 k 个 最 相似 
的 数据 然后 再从 k 个 数据 集中 选出 出现 
分类 最多 的 分类 作为 新 数据 的 分类 二 
优缺点 优点 精度高 对 异常值 不 敏感 无 数据 输入 
假定 缺点 计 算度 复杂 空间 度 复杂 适用范围 数值 
型 和 标称 型 三 数学公式 欧式 距离 欧氏距离 是 
最 易于 理解 的 一种 距离 计算方法 源自 欧氏 空间 
中 两点 间 的 距离 公式 1 二维 平面 上 
两点 a x1 y1 与 b x2 y2 间 的 
欧氏距离 2 三维空间 两点 a x1 y1 z1 与 b 
x2 y2 z2 间 的 欧氏距离 3 两个 n 维 
向量 a x11 x12 x1n 与   b x21 x22 
x2n 间 的 欧氏距离 三 算法 实现 k 近邻 算法 
的 伪代码 对 未知 类型 属性 的 数据 集中 的 
每个 点 依次 执行 以 下 操作 1 计算 已知 
类别 数据 集中 的 点 与 当前 点 之间 的 
距离 2 按照 距离 增 序 排序 3 选取 与 
当前 点 距离 最近 的 k 个 点 4 决定 
这 k 个 点 所属 类别 的 出现 频率 5 
返回 前 k 个 点 出现 频率 最高 的 类别 
作为 当前 点 的 预测 分类 1 构造 数据 1 
def createDataSet 2 group = array 1.0 1.1 1.0 1.0 
0 0 0 0.1 3 labels = A A B 
B 4 return group labels 这里有 4组 数据 每组 数据 
的 列 代表 不同 属性 的 特征值 向量 labels 包含 
了 每个 数 据点 的 标签 信息 也 可以 叫 
分类 这里 有 两类 数据 A 和B/nr 2 实施 算法 
tile 重复 某个 数组 比如 tile A n 功能 是 
将 数组 A 重复 n 次 构成 一个 新的 数组 
. 1 tile 1 2 4 2 array 1 2 
1 2 1 2 1 2 3 tile 1 2 
4 1 4 array 1 2 5 1 2 6 
1 2 7 1 2 8 tile 1 2 4 
2 9 array 1 2 1 2 10 1 2 
1 2 11 1 2 1 2 12 1 2 
1 2 欧式 距离 算法 实现 1 def classify0 inX 
dataSet labels k 2 dataSetSize = dataSet . shape 0 
3 diffMat = tile inX dataSetSize 1 dataSet # 新 
数据 与 样本数据 每 一行 的 值 相减 x x1 
y y1 x x2 y y2 x x3 y y3 
. . . . . 4 sqDiffMat = diffMat * 
* 2 # 数组 每一项 进行 平方 x x1 ^ 
2 y y1 ^ 2 . . . . . 
. . . 5 sqDistances = sqDiffMat . sum axis 
= 1 # 数组 每个 特 证 求和 x xi 
^ 2 + y yi ^ 2 . . . 
. . . 6 distances = sqDistances * * 0.5 
# 数组 每个 值 开 根号 欧式 距离 公式 完成 
7 s o r t e d D i s 
t I n d i c i e s = 
distances . argsort # argsort 函数 返回 的 是 数组 
值 从小到大 的 索引 值 8 classCount = { } 
# 以下 是 选取 距离 最小 的 前 k 个 
值 的 索引 从k/nr 个中 选取 分类 最多 的 一个 
作为 新 数据 的 分类 9 for i in range 
k # 统计 前 k 个 点 所属 的 类别 
10 voteIlabel = labels s o r t e d 
D i s t I n d i c i 
e s i 11 classCount voteIlabel = classCount . get 
voteIlabel 0 + 1 12 sortedClassCount = sorted classCount . 
iteritems key = operator . itemgetter 1 reverse = True 
13 return sortedClassCount 0 0 # 返回 前 k 个 
点中 频率 最高 的 类别 其中 inX 需要 分类 的 
新 数据 dataSet 样本数据 特征 labels 样本数据 分类 k 选取 
前 k 个 最近 的 距离 测试 算法 1 group 
labels = kNN . createDataSet 2 group labels 3 array 
1 . 1.1 4 1 . 1 . 5 0 
. 0 . 6 0 . 0.1 A A B 
B 7 kNN . classify0 0 0 group labels 3 
8 B 9 测试 结果 0 0 属于 分类 B 
. 3 如何 测试 分类器 四   示例 使用 k 
近邻 算法 改进 约会 网站 的 配对 效果 我 的 
朋友 海伦 一直 使用 在线 约会 网站 寻找 适合 自己 
的 约会对象 尽管 约会 网站 会 推荐 不同 的 人选 
但她 并 不是 喜欢 每一个人 经过 一番 总结 她 发现 
曾 交往 过 三种 类型 的 人 不 喜欢 的 
人 魅力 一般 的 人极 具 魅力 的 人海 伦 
希望 我们 的 分类 软件 可以 更好 地 帮助 她 
将 匹配 对象 划分 到 确切 的 分类 中 此外 
海伦 还 收集 了 一些 约会 网站 未曾 记录 的 
数据 信息 她 认为 这些 数据 更 有助于 匹配 对象 
的 归类 1 准备 数据 从 文本文件 中 解析 数据 
数据 存放在 文本文件 datingTestSet . txt 中 每个 样本数据 占据 
一行 总共有 1000行 海伦 的 样本 主要 包含 以下 3种 
特征 每年 获得 的 飞行 常客 里程数 玩 视频 游戏 
所 耗时间 百分比 每周 消费 的 冰淇淋 公升 数 2 
分析 数据 使用 Matplotlib 创建 散点图 散点图 使用 datingDataMat 矩阵 
的 第一 第二列 数据 分别 表示 特征值 每年 获得 的 
飞行 常客 里程数 和 玩 视频 游戏 所 耗时间 百分比 
每年 赢得 的 飞行 常客 里程数 与 玩 视频 游戏 
所占 百分比 的 约会 数据 散点图 3 准备 数据 归一化/l 
数值/n 不同/a 特征值/n 有/v 不同/a 的/uj 均值/n 和/c 取值/v 范围/n 
如果 直接 使用 特征值 计算 距离 取值 范围 较大 的 
特征 将对 距离 计算 的 结果 产生 绝 对得 影响 
而使 较小 的 特征值 几乎 没有 作用 近乎 没有 用到 
该 属性 如 两组 特征 { 0 20000 1.1 } 
和{/nr 67 32000 0.1 } 计算 距离 的 算式 为 
显然 第二 个 特征 将对 结果 产生 绝 对得 影响 
第一 个 特征 和 第三 个 特征 几乎 不起作用 然而 
对于 识别 的 过程 我们 认为 这 不同 特征 是 
同等 重要 的 因此 作为 三个 等 权重 的 特征 
之一 飞行 常客 里程数 并不 应该 如此 严重 地 影响 
到 计算结果 在 处理 这种 不同 取值 范围 的 特征值 
时 我们 通常 采用 的 方法 是 将 数值 归一化 
如 将 取值 范围 处理 为 0 到 1 或者 
1 到 1 之间 下面 的 公式 可以 将 任意 
取值 范围 的 特征值 转化 为 0 到 1区 间内 
的 值 newValue = oldValue – min / max – 
min 其中/r min/w 和/c max/w 分别/d 是/v 数据/n 集中/v 的/uj 
最小/a 特征值/n 和/c 最大/a 特征值/n 添加 autoNorm 函数 用于 将 
数字 特征值 归一化 1 def autoNorm dataSet 2 minVals = 
dataSet . min 0 # 分别 求 各个 特征 的 
最小值 3 maxVals = dataSet . max 0 # 分别 
求 各个 特征 的 最大值 4 ranges = maxVals minVals 
# 各个 特征 的 取值 范围 5 normDataSet = zeros 
shape dataSet 6 m = dataSet . shape 0 7 
normDataSet = dataSet tile minVals m 1 # oldValue min 
8 normDataSet = normDataSet / tile ranges m 1 # 
element wise divide oldValue min / max min 数据 归一化 
处理 9 return normDataSet ranges minVals 对 这个 函数 要 
注意 返回 结果 除了 归一化 好 的 数据 还包括 用来 
归一化 的 范围 值 ranges 和 最小值 minVals 这将 用于 
对 测试数据 的 归一化 注意 对 测试 数据集 的 归一化 
过程 必须 使用 和 训练 数据集 相同 的 参数 ranges 
和 minVals 不能 针对 测试数据 单独 计算 ranges 和 minVals 
否则 将 造成 同 一组 数据 在 训练 数据集 和 
测试 数据 集中 的 不一致 4 测试 算法 作为 完整 
程序验证 分类器 机器学习 算法 一个 很 重要 的 工作 就是 
评估 算法 的 正确率 通常 我们 只 提供 已 有 
数据 的 90% 作为 训练样本 来 训练 分类器 而 使用 
其余 的 10% 数据 去 测试 分类器 检测 分类器 的 
正确率 需要 注意 的 是 10% 的 测试数据 应该 是 
随机 选择 的 由于 海伦 提供 的 数据 并 没有 
按照 特定 目的 来 排序 所以 我们 可以 随意 选择 
10% 数据 而 不 影响 其 随机性 创建 分类器 针对 
约会 网站 的 测试代码 利用 样 本集 数据 进行 测试 
算法 1 def datingClassTest 2 hoRatio = 0.50 # hold 
out 10% 3 datingDataMat datingLabels = file2matrix datingTestSet2 . txt 
# load data setfrom file 4 normMat ranges minVals = 
autoNorm datingDataMat 5 m = normMat . shape 0 6 
numTestVecs = int m * hoRatio 7 errorCount = 0.0 
8 for i in range numTestVecs 9 classifierResult = classify0 
normMat i normMat numTestVecs m datingLabels numTestVecs m 3 10 
print the classifier came back with % d the real 
answer is % d % classifierResult datingLabels i 11 if 
classifierResult = datingLabels i errorCount + = 1.0 12 print 
the total error rate is % f % errorCount / 
float numTestVecs 13 print errorCount 执行 分类器 测试程序 1 kNN 
. datingClassTest 2 3 the classifier came back with 2 
the real answer is 1 4 5 the classifier came 
back with 2 the real answer is 2 6 7 
the classifier came back with 1 the real answer is 
1 8 9 the classifier came back with 1 the 
real answer is 1 10 11 the classifier came back 
with 2 the real answer is 2 12 13 . 
. . . . . . . . . . 
. . . . . . . . . . 
. . . . . . . . . . 
. . . . . . . . . . 
. . . . . . . . 14 15 
the total error rate is 0.064000 16 17 32.0 分类器 
处理 约会 数据集 的 错误率 是 6.4% 这 是 一个 
相当 不错 的 结果 我们 可以 改变 函数 datingClassTest 内 
变量 hoRatio 和 变量 k 的 值 检测 错误率 是否 
随着 变量值 的 变化 而 增加 这个 例子 表明 我们 
可以 正确 地 预测 分类 错误率 仅仅 是 2.4% 海伦 
完全 可以 输入 未知 对象 的 属性 信息 由 分类 
软件 来 帮助 她 判定 某一 对象 的 可 交往 
程度 讨厌 一般 喜欢 非常 喜欢 5 使用 算法 构建 
完整 可用 系统 综合 上述 代码 我们 可以 构建 完整 
的 约会 网站 预测 函数 对 输入 的 数据 需要 
归一化 处理 1 def classifyPerson 2 resultList = not at 
all in small doses in large doses 3 percentTats = 
float raw _ input Percentage of time spent playing video 
game 4 ffMiles = float raw _ input Frequent flier 
miles earned per year 5 iceCream = float raw _ 
input Liters of ice cream consumed per year 6 datingDataMat 
datingLabels = file2matrix datingTestSet . txt 7 normMat ranges minVals 
= autoNorm datingDataMat 8 inArr = array ffMiles percentTats iceCream 
# 新 数据 需要 归一化 处理 9 classifierResult = classify 
inArr minVals / ranges normMat datingLabels 3 10 print You 
will probably like this person resultList classifierResult 1 目前 为止 
我们 已经 看到 如何 在 数据 上 构建 分类器 完整 
代码 1 2 Created on Sep 16 2010 3 kNN 
k Nearest Neighbors 4 5 Input inX vector to compare 
to existing dataset 1xN 6 dataSet size m data set 
of known vectors NxM 7 labels data set labels 1xM 
vector 8 k number of neighbors to use for comparison 
should be an odd number 9 10 Output the most 
popular class label 11 12 @ author pbharrin 13 14 
from numpy import * 15 import operator 16 from os 
import listdir 17 import matplotlib 18 import matplotlib . pyplot 
as plt 19 def show d l 20 # d 
l = kNN . file2matrix datingTestSet2 . txt 21 fig 
= plt . figure 22 ax = fig . add 
_ subplot 111 23 ax . scatter d 0 d 
1 15 * array l 15 * array l 24 
plt . show 25 def show2 26 datingDataMat datingLabels = 
file2matrix datingTestSet2 . txt 27 fig = plt . figure 
28 ax = fig . add _ subplot 111 29 
l = datingDataMat . shape 0 30 X1 = 31 
Y1 = 32 X2 = 33 Y2 = 34 X3 
= 35 Y3 = 36 for i in range l 
37 if datingLabels i = = 1 38 X1 . 
append datingDataMat i 0 Y1 . append datingDataMat i 1 
39 elif datingLabels i = = 2 40 X2 . 
append datingDataMat i 0 Y2 . append datingDataMat i 1 
41 else 42 X3 . append datingDataMat i 0 Y3 
. append datingDataMat i 1 43 type1 = ax . 
scatter X1 Y1 c = red 44 type2 = ax 
. scatter X2 Y2 c = green 45 type3 = 
ax . scatter X3 Y3 c = blue 46 # 
ax . axis 2 25 0.2 2.0 47 ax . 
legend type1 type2 type3 Did Not Like Liked in Small 
Doses Liked in Large Doses loc = 2 48 plt 
. xlabel Percentage of Time Spent Playing Video Games 49 
plt . ylabel Liters of Ice Cream Consumed Per Week 
50 plt . show 51 52 def classify0 inX dataSet 
labels k 53 dataSetSize = dataSet . shape 0 54 
diffMat = tile inX dataSetSize 1 dataSet 55 sqDiffMat = 
diffMat * * 2 56 sqDistances = sqDiffMat . sum 
axis = 1 57 distances = sqDistances * * 0.5 
58 s o r t e d D i s 
t I n d i c i e s = 
distances . argsort 59 classCount = { } 60 for 
i in range k 61 voteIlabel = labels s o 
r t e d D i s t I n 
d i c i e s i 62 classCount voteIlabel 
= classCount . get voteIlabel 0 + 1 63 sortedClassCount 
= sorted classCount . iteritems key = operator . itemgetter 
1 reverse = True 64 return sortedClassCount 0 0 65 
66 def createDataSet 67 group = array 1.0 1.1 1.0 
1.0 0 0 0 0.1 68 labels = A A 
B B 69 return group labels 70 71 def file2matrix 
filename 72 fr = open filename 73 numberOfLines = len 
fr . readlines # get the number of lines in 
the file 74 returnMat = zeros numberOfLines 3 # prepare 
matrix to return 75 classLabelVector = # prepare labels return 
76 fr = open filename 77 index = 0 78 
for line in fr . readlines 79 line = line 
. strip 80 listFromLine = line . split \ t 
81 returnMat index = listFromLine 0 3 82 classLabelVector . 
append int listFromLine 1 83 index + = 1 84 
return returnMat classLabelVector 85 86 def autoNorm dataSet 87 minVals 
= dataSet . min 0 88 maxVals = dataSet . 
max 0 89 ranges = maxVals minVals 90 normDataSet = 
zeros shape dataSet 91 m = dataSet . shape 0 
92 normDataSet = dataSet tile minVals m 1 93 normDataSet 
= normDataSet / tile ranges m 1 # element wise 
divide 94 return normDataSet ranges minVals 95 96 def datingClassTest 
97 hoRatio = 0.50 # hold out 10% 98 datingDataMat 
datingLabels = file2matrix datingTestSet2 . txt # load data setfrom 
file 99 normMat ranges minVals = autoNorm datingDataMat 100 m 
= normMat . shape 0 101 numTestVecs = int m 
* hoRatio 102 errorCount = 0.0 103 for i in 
range numTestVecs 104 classifierResult = classify0 normMat i normMat numTestVecs 
m datingLabels numTestVecs m 3 105 print the classifier came 
back with % d the real answer is % d 
% classifierResult datingLabels i 106 if classifierResult = datingLabels i 
errorCount + = 1.0 107 print the total error rate 
is % f % errorCount / float numTestVecs 108 print 
errorCount 109 110 def img2vector filename 111 returnVect = zeros 
1 1024 112 fr = open filename 113 for i 
in range 32 114 lineStr = fr . readline 115 
for j in range 32 116 returnVect 0 32 * 
i + j = int lineStr j 117 return returnVect 
118 119 def h a n d w r i 
t i n g C l a s s T 
e s t 120 hwLabels = 121 trainingFileList = listdir 
trainingDigits # load the training set 122 m = len 
trainingFileList 123 trainingMat = zeros m 1024 124 for i 
in range m 125 fileNameStr = trainingFileList i 126 fileStr 
= fileNameStr . split . 0 # take off . 
txt 127 classNumStr = int fileStr . split _ 0 
128 hwLabels . append classNumStr 129 trainingMat i = img2vector 
trainingDigits / % s % fileNameStr 130 testFileList = listdir 
testDigits # iterate through the test set 131 errorCount = 
0.0 132 mTest = len testFileList 133 for i in 
range mTest 134 fileNameStr = testFileList i 135 fileStr = 
fileNameStr . split . 0 # take off . txt 
136 classNumStr = int fileStr . split _ 0 137 
vectorUnderTest = img2vector testDigits / % s % fileNameStr 138 
classifierResult = classify0 vectorUnderTest trainingMat hwLabels 3 139 print the 
classifier came back with % d the real answer is 
% d % classifierResult classNumStr 140 if classifierResult = classNumStr 
errorCount + = 1.0 141 print \ nthe total number 
of errors is % d % errorCount 142 print \ 
nthe total error rate is % f % errorCount / 
float mTest View Code 