{"content2":"摘要过去几年，深度学习在解决诸如视觉识别、语音识别和自然语言处理等很多问题方面都表现出色。在不同类型的神经网络当中，卷积神经网络是得到最深入研究的。早期由于缺乏训练数据和计算能力，要在不产生过拟合的情况下训练高性能卷积神经网络是很困难的。标记数据和近来GPU的发展，使得卷积神经网络研究涌现并取得一流结果。本文中，我们将纵览卷积神经网络近来发展，同时介绍卷积神经网络在视觉识别方面的一些应用。引言卷积神经网络（CNN）是一种常见的深度学习架构，受生物自然视觉认知机制启发而来。1959年，Hubel & Wiesel [1] 发现，动物视觉皮层细胞负责检测光学信号。受此启发，1980年 Kunihiko Fukushima 提出了CNN的前身——neocognitron 。20世纪 90 年代，LeCun et al. [3] 等人发表论文，确立了CNN的现代结构，后来又对其进行完善。他们设计了一种多层的人工神经网络，取名叫做LeNet-5，可以对手写数字做分类。和其他神经网络一样， LeNet-5 也能使用 backpropagation 算法训练。CNN能够得出原始图像的有效表征，这使得CNN能够直接从原始像素中，经过极少的预处理，识别视觉上面的规律。然而，由于当时缺乏大规模训练数据，计算机的计算能力也跟不上，LeNet-5 对于复杂问题的处理结果并不理想。2006年起，人们设计了很多方法，想要克服难以训练深度CNN的困难。其中，最著名的是 Krizhevsky et al.提出了一个经典的CNN 结构，并在图像识别任务上取得了重大突破。其方法的整体框架叫做 AlexNet，与 LeNet-5 类似，但要更加深一些。AlexNet 取得成功后，研究人员又提出了其他的完善方法，其中最著名的要数 ZFNet [7], VGGNet [8], GoogleNet [9] 和 ResNet [10] 这四种。从结构看，CNN 发展的一个方向就是层数变得更多，ILSVRC 2015 冠军 ResNet 是 AlexNet 的20 多倍，是 VGGNet 的8 倍多。通过增加深度，网络便能够利用增加的非线性得出目标函数的近似结构，同时得出更好的特性表征。但是，这样做同时也增加了网络的整体复杂程度，使网络变得难以优化，很容易过拟合。研究人员提出了很多方法来解决这一问题。在下面的章节中，我们会先列出CNN的组成部分，然后介绍CNN不同方面的最近进展，接着引入快速计算技巧，并探讨CNN在图像分类、物体识别等不同方面的应用进展，最后归纳总结。基本组成部分在不同的参考资料中，对 CNN的组成部分都有着不同的描述。不过，CNN的基本组成成分是十分接近的。以分类数字的 LeNet-5 为例，这个 CNN 含有三种类型的神经网络层：卷积层：学会识别输入数据的特性表征池化（Pooling）：典型的操作包括平均 pooling [12] 和最大化 pooling [1315]全连接层：将卷积层和Pooling 层堆叠起来以后，就能够形成一层或多层全连接层，这样就能够实现高阶的推力能力。完善 CNN自从 2012 年 AlexNet 成功以后，研究人员设计了很多种完善 CNN 的方法。在这一节中，我们将从 6 方面进行介绍。1. 卷积层1）网络中的网络（Network in Network，NIN）：由 Lin et al. [21] 提出的基本网络结构2) Inception module: 由 Szegedy et al. [9] 提出，是 NIN 的拓展2. 池化层池化层是CNN的重要组成部分，通过减少卷积层之间的连接，降低运算复杂程度。以下是常用的几种循环方法：1）Lp 池化：Lp 池化是建立在复杂细胞运行机制的基础上，受生物启发而来 [24] [25]2) 混合池化：受随机Dropout [16] 和 DropConnect [28], Yu et al. 启发而来3）随机池化：随机循环 [30] 是受 drptout 启发而来的方法4）Spectral 池化3. 激活函数常用的非线性激活函数有sigmoid、tanh、relu等等，前两者sigmoid/tanh比较常见于全链接层，后者relu常见于卷积层。1) ReLU2) Leaky ReLU3) Parametric ReLU4) Randomized ReLU5) ELU6) Maxout:7) Probout4. Loss 函数1) Softmax loss2) Hinge loss3) Contrastive loss5. 正则化1）DropOut2) DropConnect6. 优化1) 初始化权重2) 随机梯度下降3) 批量标准化4) Shortcut 连接CNN 应用A 图像分类B 物体检测C 物体追踪D 姿态预估（Pose estimatation）E 文本检测识别F 视觉 saliency 检测G 行动识别H 场景标记讨论深度CNN在图像处理、视频、语音和文本中取得了突破。本文种，我们主要从计算机视觉的角度对最近CNN取得的进展进行了深度的研究。我们讨论了CNN在不同方面取得的进步：比如，层的设计，活跃函数、损失函数、正则化、优化和快速计算。除了从CNN的各个方面回顾其进展，我们还介绍了CNN在计算机视觉任务上的应用，其中包括图像分类、物体检测、物体追踪、姿态估计、文本检测、视觉显著检测、动作识别和场景标签。虽然在实验的测量中，CNN获得了巨大的成功，但是，仍然还有很多工作值得进一步研究。首先，鉴于最近的CNN变得越来越深，它们也需要大规模的数据库和巨大的计算能力，来展开训练。人为搜集标签数据库要求大量的人力劳动。所以，大家都渴望能开发出无监督式的CNN学习方式。同时，为了加速训练进程，虽然已经有一些异步的SGD算法，证明了使用CPU和GPU集群可以在这方面获得成功，但是，开放高效可扩展的训练算法依然是有价值的。在训练的时间中，这些深度模型都是对内存有高的要求，并且消耗时间的，这使得它们无法在手机平台上部署。如何在不减少准确度的情况下，降低复杂性并获得快速执行的模型，这是重要的研究方向。其次，我们发现，CNN运用于新任务的一个主要障碍是：如何选择合适的超参数？比如学习率、卷积过滤的核大小、层数等等，这需要大量的技术和经验。这些超参数存在内部依赖，这会让调整变得很昂贵。最近的研究显示，在学习式深度CNN架构的选择技巧上，存在巨大的提升空间。最后，关于CNN，依然缺乏统一的理论。目前的CNN模型运作模式依然是黑箱。我们甚至都不知道它是如何工作的，工作原理是什么。当下，值得把更多的精力投入到研究CNN的基本规则上去。同时，正如早期的CNN发展是受到了生物视觉感知机制的启发，深度CNN和计算机神经科学二者需要进一步的深入研究。有一些开放的问题，比如，生物学上大脑中的学习方式如何帮助人们设计更加高效的深度模型？带权重分享的回归计算方式是否可以计算人类的视觉皮质等等。我们希望这篇文章不仅能让人们更好地理解CNN，同时也能促进CNN领域中未来的研究活动和应用发展。新智元Top10智能汽车创客大赛招募！新智元于7月11日启动2016年【新智元100】人工智能创业公司评选，在人工智能概念诞生60周年之际，寻找中国最具竞争力的人工智能创业企业。智能驾驶技术是汽车行业的重点发展方向之一，同时也是人工智能相关产业创新落地的重要赛道之一。为此新智元联合北京中汽四方共同举办“新智元Top10智能汽车创客大赛”，共同招募智能汽车相关优质创业公司，并联合组织人工智能技术专家、传统汽车行业技术专家、关注智能汽车领域的知名风投机构，共同评审并筛选出Top 10进入决赛，在2016年10月16日“国际智能网联汽车发展合作论坛”期间，进行路演、颁奖及展览活动。"}
