{"content2":"今日CS.CV 计算机视觉论文速览Mon, 3 Jun 2019Totally 54 papers👉上期速览✈更多精彩请移步主页Daily Computer Vision PapersSketch2code: Generating a website from a paper mockupAuthors Alex Robinson开发面向用户的应用程序的早期阶段是创建一个线框来布局界面。一旦创建了线框，就会将其提供给开发人员以在代码中实现。开发锅炉板用户界面代码是一项耗时的工作，但仍需要有经验的开发人员。在本文中，我们提出了两种自动化这一过程的方法，一种是使用经典的计算机视觉技术，另一种是使用深层语义分割网络的新应用。我们发布了一个网站数据集，可用于培训和评估这些方法。此外，我们设计了一个新颖的评估框架，通过创建合成草图进行经验评估。我们的评估表明，我们的深度学习方法优于我们的经典计算机视觉方法，我们得出结论，深度学习是未来研究最有希望的方向。Multimodal Joint Emotion and Game Context Recognition in League of Legends LivestreamsAuthors Charles Ringer, James Alfred Walker, Mihalis A. Nicolaou视频游戏流向观众提供丰富的视听数据，通过游戏镜头和音频传达关于游戏本身的信息，以及通过网络摄像头镜头和音频的流光的情绪状态和行为。分析玩家行为并发现与游戏背景的相关性对于建模和理解直播的重要方面至关重要，但是会带来一系列重大挑战，例如融合不同传感器捕获的多模态数据，在野外条件下不受控制。首先，据我们所知，我们提供了英雄联盟直播的第一个数据集，注释了流光效果和游戏背景。其次，我们提出了一种利用张量分解进行多模态表示的高阶融合的方法。与一组基线融合方法（如晚期和早期融合）相比，所提出的方法在联合预测游戏背景和玩家影响的问题上进行了评估。A Riemanian Approach to Blob Detection in Manifold-Valued ImagesAuthors Aleksei Shestov, Mikhail Kumskov本文致力于解决多值图像中的斑点检测问题。我们的解决方案基于blob响应函数的新定义。我们通过图像图的曲率来定义斑点响应函数，图像图被视为子流形。我们称之为提议的框架黎曼斑点检测。我们证明我们的方法可以被视为灰度斑点检测技术的一般化。通过图像Hessian导出了黎曼斑点响应函数的表达式。我们为2D表面上的矢量值图像的情况提供实验，所提出的框架在化学化合物分类的任务上进行测试。Scene Text Visual Question AnsweringAuthors Ali Furkan Biten, Ruben Tito, Andres Mafla, Lluis Gomez, Mar al Rusi ol, Ernest Valveny, C.V. Jawahar, Dimosthenis Karatzas当前的视觉问题回答数据集不考虑图像中文本传达的丰富语义信息。在这项工作中，我们提出了一个新的数据集ST VQA，旨在强调利用图像中存在的高级语义信息作为VQA过程中的文本提示的重要性。我们使用该数据集来定义一系列增加难度的任务，其中在视觉信息提供的上下文中阅读场景文本是推理和生成适当答案所必需的。我们为这些任务提出了一个新的评估指标，以解决推理错误以及文本识别模块的缺点。此外，我们提出了一系列基线方法，为新发布的数据集提供了进一步的见解，并为进一步研究奠定了基础。3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework using Fully 3D Convolutional Neural NetworksAuthors Gary Storey, Richard Jiang, Shelagh Keogh, Ahmed Bouridane, Chang Tsun Li从视频序列执行面部分析的能力具有在许多生活领域中产生积极影响的巨大潜力。一个这样的领域涉及医学领域，特别有助于面神经麻痹患者的诊断和康复。考虑到这个应用程序，本文提出了一个名为3DPalsyNet的端到端框架，用于口腔运动识别和面部麻痹分级的任务。 3DPalsyNet利用具有ResNet骨干网的3D CNN架构来预测这些动态任务。利用从用于一般动作识别的动力学数据集预训练的3D CNN的转移学习，修改该模型以使用中心和softmax损失概念应用联合监督学习。 3DPalsyNet在由具有不同范围的面部麻痹和口腔运动的个体组成的测试集上进行评估，并且结果在这些任务分别为82和86中显示出有吸引力的分类准确度水平。根据所提出的3DPalsyNet的预测质量来研究帧持续时间和损失函数的影响，其中发现较短的帧持续时间s为8对于该特定任务执行最佳。中心损失和softmax在空间时间特征学习方面比单独的softmax损失有所改善，这与涉及空间领域的早期工作一致。Deep Dual Relation Modeling for Egocentric Interaction RecognitionAuthors Haoxin Li, Yijun Cai, Wei Shi Zheng以自我为中心的交互识别旨在识别相机佩戴者与以自我为中心的视频中面向相机佩戴者的交互者的交互。在这样的人类交互分析问题中，探索相机佩戴者和交互者之间的关系是至关重要的。然而，大多数现有作品直接模拟整个交互，并且缺乏对两个交互人之间关系的建模。为了利用强关系进行自我中心交互识别，我们引入了一种双关系建模框架，该框架学习基于两个人的个体动作表示来模拟相机佩戴者和交互者之间的关系。具体来说，我们开发了一个新颖的交互式LSTM模块，它是我们框架的关键组成部分，它基于各自的行动表示明确地模拟两个相互作用的人之间的关系，这些行动表示与交互者注意模块和全局本地运动模块协作学习。三个自我中心交互数据集的实验结果显示了我们的方法的有效性和优于现有技术的优势。Provably scale-covariant hierarchical continuous networks based on scale-normalized differential expressions coupled in cascadeAuthors Tony Lindeberg本文提出了一种构建连续分层网络的理论，使得网络保证可证明是规模协变的。我们首先提出了获得尺度协方差的一般充分性论证，该尺度协方差适用于由尺度归一化尺度空间导数表示的线性和非线性微分表达式定义的广泛类型的网络。然后，我们提供了一个更详细的发展，这个网络的一个例子是由数学推导的感受域模型和生物学启发的计 算的组合构成的。基于一阶和二阶方向高斯导数的定向准正交组合的复杂单元的功能模型，我们在图像取向上的组合扩展中级联这种原始计算。分析了计算基元的尺度空间属性，并且我们给出了结果表示如何允许尺度和旋转协方差的明确证明。开发了纹理分析的原型应用程序，并且证明了所得QuasiQuadNet的简化平均缩减表示导致在三个纹理数据集上的有希望的实验结果。Learning Robust Global Representations by Penalizing Local Predictive PowerAuthors Haohan Wang, Songwei Ge, Eric P. Xing, Zachary C. Lipton尽管他们对i.i.d.具有着名的预测能力。众所周知，卷积神经网络更多地依赖于人类认为表面的高频模式，而不是低频模式，这些模式与关于什么构成类别成员资格的直觉更加一致。本文提出了一种训练鲁棒卷积网络的方法，该方法通过惩罚早期层学习的局部表示的预测能力。直观地说，我们的网络被迫丢弃预测信号，例如颜色和纹理，这些信号可以从局部感受野收集，并依赖于图像的全局结构。通过一系列合成和基准域适应任务，我们的方法可以在域外提供更好的泛化。此外，为了评估跨域转移，我们引入了ImageNet Sketch，这是一个由类似草图的图像组成的新数据集，它与类别和比例中的ImageNet分类验证集相匹配。LeagueAI: Improving object detector performance and flexibility through automatically generated training data and domain randomizationAuthors Oliver Struckmeier在本技术报告中，我介绍了用于对象检测的自动合成数据集生成方法，并在视频游戏“英雄联盟”中进行了演示。此报告还作为如何自动生成数据集的手册，并作为LeagueAI框架的数据集生成部分的介绍。 LeagueAI框架是一个软件框架，它根据人类玩家所拥有的相同输入，即视觉，提供有关游戏英雄联盟的详细信息。该框架允许研究人员和爱好者开发自己的智能代理或提取有关游戏状态的详细信息。机器视觉应用的一个大问题通常是收集大量手工标记数据的繁重工作。因此，本报告中介绍了LeagueAI框架的视觉管道的关键部分，即数据集生成。该方法涉及从游戏的3D模型中提取图像原始数据并将它们与游戏背景组合以创建类似合成图像的游戏并自动生成相应的标签。在实验中，我将在合成数据上训练的模型与在手工标记数据上训练的模型和在组合数据集上训练的模型进行比较。在合成数据上训练的模型显示出更多类别的更高检测精度和更可靠的玩家角色跟踪性能。由于旧手标记数据集和合成数据的格式不同，在组合数据集上训练的模型表现不佳。High Frequency Component Helps Explain the Generalization of Convolutional Neural NetworksAuthors Haohan Wang, Xindi Wu, Pengcheng Yin, Eric P. Xing我们研究了图像数据的频谱与卷积神经网络CNN的泛化行为之间的关系。我们首先注意到CNN捕获图像的高频成分的能力。人体几乎察觉不到这些高频成分。因此，观察可以作为对抗性实例存在的解释之一，也可以帮助验证CNN在鲁棒性和准确性之间的权衡。我们的观察也立即导致可以改善训练有素的CNN的对抗强度的方法。最后，我们还利用这一观察设计了一种半黑盒子对抗攻击方法。Dynamic Distribution Pruning for Efficient Network Architecture SearchAuthors Xiawu Zheng, Rongrong Ji, Lang Tang, Yan Wan, Baochang Zhang, Yongjian Wu, Yunsheng Wu, Ling Shao通过Neural Architecture Search NAS获得的网络架构已经在各种计算机视觉任务中展示了最先进的性能。尽管取得了令人兴奋的进展，但是前向后向传播和搜索过程的计算复杂性使得在实践中难以应用NAS。特别是，大多数以前的方法需要数千个GPU天才能使搜索过程收敛。在本文中，我们提出了一种动态分布修剪方法，用于极其高效的NAS，它从联合分类分布中对架构进行采样。每隔几个时期动态地修剪搜索空间以更新该分布，并且当仅剩下一个结构时获得最佳神经结构。我们对NAS中两个广泛使用的数据集进行了实验。在CIFAR 10上，通过我们的方法获得的最佳结构实现了最先进的1.9测试错误，而在Tesla V100上搜索过程仅比原始NAS算法快1.5倍的GPU时间快1000倍。在ImageNet上，我们的模型在MobileNet设置下达到了75.2的前1精度，与最快的NAS算法相比，时间成本仅为2 GPU天，即100加速。该代码可在网址获取Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question AnsweringAuthors Junyeong Kim, Minuk Ma, Kyungsu Kim, Sungjin Kim, Chang D. Yoo本文提出了一种通过多任务学习获得多模态视频问答的额外监督方法。多模态视频问答是一项重要任务，旨在对视觉和语言的共同理解。然而，为多模态视频问答建立大规模数据集是昂贵的，并且现有基准相对较小以提供足够的监督。为了克服这一挑战，本文提出了一种多任务学习方法，它由三个主要组成部分组成：1个多模态视频问答网络，基于视频和字幕特征回答问题，2个时间检索网络预测时间。从中生成问题的视频剪辑和解决度量学习问题的3模态对齐网络，以找到视频和字幕模态的正确关联。通过利用分层共享的中间层同时解决相关的辅助任务，提供了额外的协同监督。在课程学习的推动下，提出了多任务比例调度，以便在训练开始时更早地学习更容易的任务来设置归纳偏差。公开数据集TVQA的实验显示了最先进的结果，并进行了消融研究以证明统计有效性。Unsupervised Object Segmentation by RedrawingAuthors Micka l Chen, Thierry Arti res, Ludovic Denoyer对象分割是一个至关重要的问题，通常通过在由图像和相应的对象掩模组成的非常大的数据集上使用监督学习方法来解决。由于必须在像素级别提供掩模，因此为任何新域构建这样的数据集可能非常昂贵。我们提出了ReDO，这是一种新模型，能够以无人监督的方式从图像中提取对象而无需任何注释。它依赖于这样的想法：应该可以在不改变数据集的整体分布的情况下更改对象的纹理或颜色。遵循这一假设，我们的方法基于对抗体系结构，其中生成器由给定图像的输入样本引导，它提取对象蒙版，然后在同一位置重绘新对象。生成器由鉴别器控制，该鉴别器确保生成的图像的分布与原始图像的分布对齐。我们在不同的数据集上试验这种方法，并展示了提取掩模的良好质量。Scaling Video Analytics on Constrained Edge NodesAuthors Christopher Canel, Thomas Kim, Giulio Zhou, Conglong Li, Hyeontaek Lim, David G. Andersen, Michael Kaminsky, Subramanya R. Dulloor随着摄像机部署的不断发展，处理大量实时数据的需求使广域网基础设施变得紧张。当每个摄像机带宽有限时，对于诸如交通监控和行人跟踪的应用来说，将高质量视频流卸载到数据中心是不可行的。本文介绍了FilterForward，这是一个新的云端系统，它使基于数据中心的应用程序能够通过安装仅回传相关视频帧的轻量级边缘过滤器来处理来自数千个摄像头的内容。 FilterForward引入了快速且富有表现力的每个应用程序微分类器，它们共享计算以同时检测计算受限的边缘节点上的许多事件。只有匹配的事件才会传输到云端。对两个真实世界相机馈送数据集的评估表明，FilterForward将带宽使用减少了一个数量级，同时提高了挑战性视频内容的计算效率和事件检测准确度。Autonomous Human Activity Classification from Ego-vision Camera and Accelerometer DataAuthors Yantao Lu, Senem Velipasalar关于人类活动分类的大量研究工作依赖于惯性测量单元IMU数据或来自提供第三人称视角的静态相机的数据。仅使用IMU数据限制了可以检测到的活动的多样性和复杂性。例如，可以通过IMU数据检测就座活动，但是不能确定对象是坐在椅子上还是坐在沙发上，或者对象在哪里。为了从自我中心视频执行细粒度活动分类，并区分仅通过IMU数据无法区分的活动，我们使用来自自我视觉相机和IMU的数据呈现自主且稳健的方法。与基于卷积神经网络的方法相比，我们建议使用胶囊网络从自我中心视频数据中获得特征。此外，在自我中心视频和IMU数据上采用卷积长短期记忆框架来捕捉动作的时间方面。我们还提出了一种基于遗传算法的方法来自主地和系统地设置各种网络参数，而不是使用手动设置。已经进行了实验以执行9和26标签活动分类，并且所提出的方法使用自主设置的网络参数，提供了非常有希望的结果，分别实现了86.6和77.2的总体准确度。与仅使用egovision数据和仅IMU数据相比，结合两种模态的所提出的方法还提供了增加的准确性。Deep interpretable architecture for plant diseases classificationAuthors Mohammed Brahimi, Said Mahmoudi, Kamel Boukhalfa, Abdelouhab Moussaoui最近，许多作品受到植物病害分类计算机视觉深度学习成功的启发。不幸的是，这些端到端的深度分类器缺乏透明度，这可能会限制它们在实践中的采用。在本文中，我们提出了一种新的可训练的植物疾病分类可视化方法，该方法基于由两个深度分类器组成的卷积神经网络CNN结构。第一个是教师，第二个是学生。该架构利用多任务学习来共同培训教师和学生。然后，教师和学生之间的通信表示被用作代理，以可视化最重要的图像区域以进行分类。这种新结构比植物疾病背景下的现有方法产生更清晰的可视化。所有实验均在包含54306植物图像的PlantVillage数据集上实现。Joint Representation of Multiple Geometric Priors via a Shape Decomposition Model for Single Monocular 3D Pose EstimationAuthors Mengxi Jiang, Zhuliang Yu, Cuihua Li, Yunqi Lei在本文中，我们的目标是从单个图像的2D身体关节恢复3D人体姿势。这项任务的主要挑战是深度模糊，因为不同的3D姿势可能会产生类似的2D姿势。尽管在无人监督和监督学习方法中都发现了该问题的许多最新进展，但是大多数这些方法的性能受到训练数据的不足和丰富性的极大影响。为了缓解这个问题，我们提出了一种无监督学习方法，该方法能够在有限的可用训练数据下很好地估计各种复杂姿态。具体来说，我们提出了一种形状分解模型SDM，其中3D姿势被认为是两个部分的叠加，这两个部分是全局结构和一些变形。基于SDM，我们通过求解两组不同的几何先验分布式组合系数来明确估计这两个部分。另外，为了获得几何先验，提出了一种联合字典学习算法，用于从有限的训练数据中同时提取粗略和精细的姿势线索。对几个广泛使用的数据集进行定量评估表明，我们的方法比其他竞争方法产生更好的性能。特别是，在某些具有更复杂变形的类别中，我们的方法可以实现显着的改进。此外，在野外图像中进行的定性实验也显示了所提出方法的有效性。Point Clouds Learning with Attention-based Graph Convolution NetworksAuthors Zhuyang Xie, Junzhou Chen, Bo Peng点云数据作为3D对象的一种表示，是3D传感器获得的最原始的输出。与2D图像不同，点云是无序的和非结构化的。因此，将诸如卷积神经网络的分类技术直接应用于点云分析并不是直截了当的。为了解决这个问题，我们提出了一种新的网络结构，名为Attention based Graph Convolution Networks AGCN，用于提取点云特征。将学习过程作为相邻点之间的消息传播，我们引入AGCN的注意机制来分析点的局部特征之间的关系。此外，我们引入了一个额外的全局图结构网络来补偿图结构网络中各个点的相对信息。所提出的网络还扩展到用于分段任务的编码器解码器结构。实验结果表明，所提出的网络可以在分类和分割任务中实现最先进的性能。TACNet: Transition-Aware Context Network for Spatio-Temporal Action DetectionAuthors Lin Song, Shiwei Zhang, Gang Yu, Hongbin Sun用于空间时间动作检测的现有技术方法已经获得了令人印象深刻的结果，但对于时间范围检测仍然不能令人满意。主要原因在于，有一些模糊的状态类似于真实的行为，甚至可以通过训练有素的网络将其视为目标行动。在本文中，我们将这些模糊样本定义为过渡状态，并提出过渡感知上下文网络TACNet来区分过渡状态。所提出的TACNet包括两个主要组件，即时间上下文检测器和转换感知分类器。时间上下文检测器可以通过构建循环网络来提取具有恒定时间复杂度的长期上下文信息。转换感知分类器可以通过同时分类动作和过渡状态来进一步区分过渡状态。因此，所提出的TACNet可以显着改善空间时间动作检测的性能。我们广泛评估了UCF101 24和J HMDB数据集上提出的TACNet。实验结果表明，TACNet在JHMDB上获得了竞争性能，并且在帧mAP和视频mAP方面明显优于未修剪的UCF101 24上的现有技术方法。Deep Representation Learning for Road Detection through Siamese NetworkAuthors Huafeng Liu, Xiaofeng Han, Xiangrui Li, Yazhou Yao, Pu Huang, Zhenming Tang强大的道路检测是安全自动驾驶的关键挑战。最近，随着3D传感器的快速发展，越来越多的研究人员正在尝试融合不同传感器之间的信息，以提高道路检测的性能。尽管在该领域已经取得了许多成功的工作，但深度学习框架下的数据融合方法仍然是一个悬而未决的问题。在本文中，我们提出了一个基于FCN 8s的连体深度神经网络来检测道路区域。我们的方法使用从单目彩色相机和Velodyne 64 LiDAR传感器收集的数据。我们将LiDAR点云投影到图像平面上以生成LiDAR图像并将它们馈送到网络的一个分支中。 RGB图像被馈送到我们建议的网络的另一个分支。这两个分支以多个尺度提取的特征图通过填充额外的融合层在每个合并层之前融合。公共数据集KITTI ROAD的广泛实验结果证明了我们提出的方法的有效性。Deep ordinal classification based on cumulative link modelsAuthors V ctor Manuel Vargas, Pedro Antonio Guti rrez, C sar Herv s Mart nez本文通过考虑输出层中的一族概率序数链路函数，提出了一种用于序数回归的深度卷积神经网络模型。链接函数是用于累积链接模型的函数，累积链接模型是基于将每个图案投影到一维空间中的传统统计线性模型。一组有序阈值将此空间拆分为问题的不同类。在我们的例子中，投影是通过非线性深度神经网络估计的。为了进一步改善结果，我们将这些序数模型与损失函数相结合，该函数基于加权Kappa指数考虑类别之间的距离。在实验研究中研究了三种不同的连接函数，并将结果与 统计分析进行了对比。实验在两个不同的序数分类问题上进行，统计检验证实这些模型改进了名义模型的结果，并且优于文献中考虑的其他建议。Rethinking Table Parsing using Graph Neural NetworksAuthors Shah Rukh Qasim, Hassan Mahmood, Faisal Shafait文档结构分析，例如区域分割和表格分析，是文档处理中的一个复杂问题，是一个活跃的研究领域。最近在解决各种计算机视觉和机器学习问题方面的深度学习的成功并未在文档结构分析中得到反映，因为传统的神经网络不太适合于问题的输入结构。在本文中，我们提出了一种基于图形网络的体系结构作为表格解析的标准神经网络的更好替代方案。我们认为图形网络是解决这些问题的更自然的选择，并探索了两种基于梯度的图形神经网络。我们提出的架构结合了卷积神经网络的优点，用于视觉特征提取和图形网络，以处理问题结构。我们凭经验证明我们的方法在很大程度上优于基线。此外，我们发现缺乏大规模数据集是结构分析深度学习研究的主要障碍，并为表解析问题提出了一个新的大规模综合数据集。最后，我们开源我们的数据集生成实现和图形网络的培训框架，以促进这方面的可重复研究。Vehicle Detection in Deep LearningAuthors Yao Xiao在深度学习技术的支持下，计算机视觉正在迅速发展。本文提出了一种基于对经典卷积神经网络的改进的先进车辆检测模型。先进的模型应用于车辆检测基准，并建立用于检测道路物体。首先，我们为我们的先进模型提出了一个高级架构，它采用了不同的最先进的深度学习技术。然后，我们利用残差神经网络和区域提议网络，根据车辆检测基准实现竞争性能。最后，我们描述了车辆检测技术的发展趋势和未来的研究方向。Multi-Precision Quantized Neural Networks via Encoding Decomposition of -1 and +1Authors Qigong Sun, Fanhua Shang, Kang Yang, Xiufang Li, Yan Ren, Licheng Jiao深度神经网络DNN的训练需要用于计算和存储性能的密集资源。因此，DNN不能有效地应用于移动电话和嵌入式设备，这严重限制了它们在工业应用中的适用性。为了解决这个问题，我们提出了一种利用1,1将量化神经网络QNN分解为多分支二进制网络的新型编码方案，可以通过按位运算xnor和bitcount有效地实现，以实现模型压缩，计算加速和资源节约。基于我们的方法，用户可以根据他们的要求和硬件资源轻松地任意地实现不同的编码精度。所提出的机制非常适合在数据存储和计算方面使用FPGA和ASIC，这为智能芯片提供了可行的思路。我们验证了我们的方法在大规模图像分类任务（例如ImageNet和对象检测任务）上的有效性。特别是，我们的低位编码方法仍然可以实现与其全精度对应方案几乎相同的性能。Design Light-weight 3D Convolutional Networks for Video Recognition Temporal Residual, Fully Separable Block, and Fast AlgorithmAuthors Haonan Wang, Jun Lin, Zhongfeng Wang深度三维3D卷积网络ConvNet凭借其强大的时空信息融合能力，在视频识别任务中表现出了良好的性能。但是，对内存访问和计算能力的极其严格的要求使其无法在资源受限的情况下使用，例如便携式和边缘设备。因此，在本文中，我们首先提出了一个两级完全可分块FSB，以显着压缩3D ConvNets的模型大小。然后开发了一种名为Temporal Residual Gradient TRG的特征增强方法，以提高压缩模型在视频任务上的性能，从而提供更高的准确性，更快的收敛性和更好的鲁棒性。此外，为了进一步减少计算工作量，我们提出了一种混合快速算法hFA，以大幅降低卷积的计算复杂度。这些方法有效地结合在一起，为视频识别任务设计了轻量级和高效的ConvNet。流行数据集上的实验报告2.3x压缩率，3.6倍工作负荷减少和6.3顶级1精度增益，超过现有技术的SlowFast模型，这已经是一个高度紧凑的模型。所提出的方法在传统的3D ConvNet上也表现出良好的适应性，展示了7.4倍的紧凑型号，11.0倍的工作量和3.0的更高精度Supervised Online Hashing via Similarity Distribution LearningAuthors Mingbao Lin, Rongrong Ji, Shen Chen, Feng Zheng, Xiaoshuai Sun, Baochang Zhang, Liujuan Cao, Guodong Guo, Feiyue Huang在面对流数据时，在线哈希引起了广泛的研究关注。大多数在线散列方法，基于训练实例的成对相似性来学习二进制代码，未能捕获语义关系，并且由于大的变化而在大规模应用中遭受差的泛化。在本文中，我们建议对输入数据和散列码之间的相似性分布进行建模，在此基础上提出了一种新的监督在线散列方法，称为基于相似性分布的在线散列SDOH，以保持产生的内在语义关系。汉明空间。具体而言，我们首先通过基于高斯的归一化将离散相似性矩阵变换为概率矩阵，以解决极不平衡的分布问题。然后，我们引入了一个扩展Student t分布来解决具有挑战性的初始化问题，并有效地弥合已知和未知分布之间的差距。最后，我们通过最小化具有随机梯度下降SGD的Kullback Leibler散度KL偏差来对齐这两个分布，通过该随机梯度下降SGD，通过其直观的相似性约束来更新新流数据上的散列模型，具有对过去数据的强大的泛化能力。对三个广泛使用的基准测试的广泛实验证实了所提出的SDOH优于在线检索任务中的现有技术方法的优越性。All-In-One Underwater Image Enhancement using Domain-Adversarial LearningAuthors Pritish Uplavikar, Zhenyu Wu, Zhangyang Wang由于波长依赖的光衰减和散射，原始水下图像降级，限制了它们在视觉系统中的适用性。使增强水下图像特别具有挑战性的另一个因素是捕获它们的水类型的多样性。例如，在深海水域捕获的图像与浅海岸水域捕获的图像具有不同的分布。这种多样性使得难以训练单个模型来增强水下图像。在这项工作中，我们提出了一个新的模型，通过解开对应于被视为不同领域的水类型的不需要的滋扰，通过对抗地学习图像的内容特征来很好地处理增强期间水的多样性。我们使用学习的领域不可知特征来生成增强的水下图像。我们在包含10种Jerlov水类型图像的数据集上训练我们的模型。实验结果表明，所提出的模型不仅在几乎所有Jerlov水类型的SSIM和PSNR得分方面都优于以前的方法，而且在现实世界数据集上得到了很好的推广。高级视觉任务对象检测的性能还显示了使用我们的模型使用增强图像的改进。Multitask Text-to-Visual Embedding with Titles and Clickthrough DataAuthors Pranav Aggarwal, Zhe Lin, Baldo Faieta, Saeid Motiian文本视觉或称为语义视觉嵌入是视觉语言研究中的核心问题。它通常涉及通过CNN图像编码器和RNN语言编码器将图像和文本描述映射到公共特征空间。在本文中，我们提出了一种使用图像标题和点击图像搜索引擎数据来学习文本视觉嵌入的新方法。我们还通过建模嵌入的积极意识来提出新的三重损失函数，并引入一种新颖的基于小批量的硬阴性采样方法，以在学习过程中提高数据效率。实验结果表明，我们提出的方法优于现有方法，对现实世界文本的视觉检索也有效。Graph Attention Memory for Visual NavigationAuthors Dong Li, Dongbin Zhao, Qichao Zhang, Yuzheng Zhuang, Bin Wang学习在复杂环境中导航的任务通常在深度强化学习框架中使用反应性策略或通用的经常性策略来解决。不幸的是，这两种策略不足以处理视觉导航中的长期记忆问题并导致长时间的学习。为解决这一问题，本文提出了一种基于图形注意记忆GAM的导航系统，包括三个模块：存储器构建模块，图形注意模块和控制模块。内存构建模块通过先前的探索构建基于监督学习的拓扑图。然后从图注意模块中提取引导注意特征。最后，基于深度强化学习的控制模块通过视觉观察和引导注意特征来做出决策。所提出的方法在复杂的3D环境中得到验证。结果表明，基于GAM的导航系统在学习速度和成功率方面均优于所有基线。我们还基于手动和随机探索策略提供了图表拓扑占用的详细分析。Technical Report of the DAISY System -- Shooter Localization, Models, Interface, and BeyondAuthors Junwei Liang, Jay D. Aronson, Alexander Hauptmann如今，每秒都会有大量用户生成的视频上传到社交媒体，从而可以瞥见世界各地的事件。这些视频为重建事件提供了重要且有用的信息。在本文中，我们描述了DAISY系统，该系统由已建立的机器学习技术和物理模型实现，可以仅基于捕获枪击声的几个用户生成的视频来定位射击者位置。 DAISY系统利用视频同步和枪声时间本地化等机器学习技术来组织非结构化社交媒体视频，并快速本地化视频中的枪声。它在循环验证中为人类提供了一个Web界面，以确保准确的估计。我们展示了估计2017年拉斯维加斯射击的射手位置的结果，并显示DAISY只能使用前几次射门获得准确的位置。然后，我们指出可以帮助改进系统的未来方向，并进一步减少过程中的人力。我们发布所有相关的源代码，包括Web界面和机器学习模型，希望这样的工具可以用来帮助保护生命并从研究和软件工程社区获得贡献，以使工具更好。Machine Learning Methods for Shark DetectionAuthors Jordan F. Masakuna本文回顾了基于人类观察者的方法，在梅森堡海滩的鲨鱼斑点中使用。它研究用于自动鲨鱼检测的机器学习方法，旨在增强人类观察。调查问卷和访谈用于收集有关鲨鱼发现的信息，实际Shark Spotter计划的动机及其局限性。我们为模型定义了一系列理想的属性，并选择了适当的数学技术。该研究的初步结果表明，我们可以期望从鲨鱼图像中提取有用的信息，尽管鲨鱼执行的几何变换，其特征不会改变。总之，我们已经部分实现了我们的模型，剩下的实现需要数据集。Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for Interrogating Learned RepresentationsAuthors Jesse A. Livezey, Ahyeon Hwang, Kristofer E. Bouchard可解释的数据表示对于测试假设或区分关于数据的多个潜在假设是有用的。相比之下，应用机器学习，特别是深度学习DL，通常用于性能优于可解释性的环境中。实际上，深度网络DN通常被视为黑盒子，并且不清楚他们从给定数据集中学习什么以及如何学习。这种缺乏理解严重阻碍了DN作为科学数据分析工具的应用，并提出了许多研究问题。一个问题是当前的深度学习研究数据集要么具有非常少的层次结构，要么对于其结构的分析来说太复杂，妨碍了对层次表示的精确预测。为了解决这一差距，我们提出了一个具有已知层次结构和组成结构的基准数据集，以及一组使用DN进行假设驱动数据分析的方法。韩文字体数据集由35种字体组成，每种字体有11,172个书写音节，由19个初始辅音，21个内侧元音和28个最终辅音组成。可以对将各个韩文字符组合和修改为块的规则进行编码，其中包括依赖于精确块内容的平移，缩放和样式变化，以及字体之间的自然变化。因此，韩文字体数据集将提供具有良好定义的分层特征的中间复杂度数据集，以询问所学习的表示。我们首先介绍数据集的结构。使用一组无监督和监督的方法，我们发现深层网络表示包含与字符的几何层次相关的结构。我们的结果为更好地理解深层网络从复杂的结构化数据集中学习的内容奠定了基础。Real-time Approximate Bayesian Computation for Scene UnderstandingAuthors Javier Felip, Nilesh Ahuja, David G mez Guti rrez, Omesh Tickoo, Vikash Mansinghka考虑场景理解问题，例如预测一个人可能到达的位置，或从深度图像推断3D物体的姿势，或推断在繁忙的十字路口可能的行人过街点。本文展示了如何使用近似贝叶斯计算来解决这些问题。基础生成模型是由真实的模拟软件构建的，包含在贝叶斯误差模型中，用于模拟输出和实际数据之间的差距。模拟器是从现成的计算机图形，视频游戏和交通模拟代码中提取的。本文介绍了两种加速推理的技术，可以单独使用或组合使用。第一种是训练模拟器的神经替代物，使用简单形式的域随机化使得替代物对模拟和现实之间的差距更加稳健。第二种是使用改编自计算机图形的树金字塔方法自适应地对潜在变量进行离散化。本文还展示了对现实世界问题的性能和准确度测量，确定了实时解决这些问题是可行的。Implicit Background Estimation for Semantic SegmentationAuthors Charles Lehman, Dogancan Temel, Ghassan AlRegib场景理解和语义分割是许多计算机视觉任务的核心，其中许多任务涉及以潜在危险的方式与人类进行交互。因此，最重要的是要开发用于鲁棒模型的原理设计的技术。在本文中，我们提供了分析和经验证据，即纠正由softmax函数产生的潜在错误的非独特映射可以改善现有语义分段模型的稳健性特征，对性能的影响最小，对代码库的改动最小。 。D$\\textbf{S}^3$L: Deep Self-Semi-Supervised Learning for Image RecognitionAuthors Tsung Wei Tsai, Chongxuan Li, Jun Zhu尽管最近在深度半监督学习Semi SL方面取得了进展，但标签的数量仍占主导地位。自我监督学习的成功Self SL暗示了利用一组额外的确定性标签来利用大量未标记数据的有希望的方向。在本文中，我们提出了Deep Self Semi Supervised learning D S 3 L，这是一个灵活的多任务框架，具有共享参数，将Self SL中的旋转任务与深半SL中基于一致性的方法相结合。我们的方法易于实现，并且是对所有基于一致性的方法的补充。实验表明，我们的方法在几个标准基准测试中显着改进了已发布的现有技术方法，特别是当呈现较少的标签时。A Survey on Biomedical Image CaptioningAuthors Vasiliki Kougia, John Pavlopoulos, Ion Androutsopoulos应用于生物医学图像的图像字幕可以帮助和加速临床医生遵循的诊断过程。本文是生物医学图像标题的第一次调查，讨论数据集，评估措施和最先进的方法。此外，我们建议使用两个基线，一个弱基线和一个更强基线，后者优于其中一个数据集的所有现有技术系统。Counting and Segmenting Sorghum HeadsAuthors Min hwan Oh, Peder Olsen, Karthikeyan Natesan Ramamurthy表型分型是测量生物体可观察性状的过程。对作物进行手工表型分析是一项劳动密集型，耗时，成本高且易出错的过程。准确，自动化，高通量的表型分析可以减轻作物育种管道的巨大负担。在本文中，我们提出了一种可扩展的高通量方法，用于自动计数和分割穗头，这是一种关键表型，来自空中高粱作物图像。我们的计数方法使用从点或区域注释获得的图像密度图作为目标，具有新颖的深度卷积神经网络结构。我们还提出了一种使用估计密度图的新型实例分割算法，以在存在遮挡的情况下识别各个圆锥花序。使用真正的高粱航拍图像，我们获得的计数平均绝对误差MAE为1.06，这比使用众所周知的人群计数方法（如CCNN，MCNN和CSRNet模型）更好。实例分割模型还产生可观的结果，这最终将有助于减少未来数据的手动注释工作量。Large Scale Incremental LearningAuthors Yue Wu, Yinpeng Chen, Lijuan Wang, Yuancheng Ye, Zicheng Liu, Yandong Guo, Yun Fu现代机器学习在逐步学习新课程时遭受灾难性遗忘。由于缺少旧类的数据，性能急剧下降。已经提出了增量学习方法来保留从旧类中获得的知识，通过使用知识提取并保留旧类中的一些示例。但是，这些方法难以扩展到大量类。我们认为这是因为新旧类之间数据不平衡的两个因素的组合，以及视觉上相似类的数量不断增加。当训练数据不平衡时，区分越来越多的视觉上相似的类别是特别具有挑战性的。我们提出了一种简单有效的方法来解决这一数据不平衡问题。我们发现最后一个完全连接的层对新类具有强烈的偏差，并且这种偏差可以通过线性模型来校正。通过两个偏差参数，我们的方法在两个大型数据集ImageNet 1000类和MS Celeb 1M 10000类上表现非常出色，分别优于11.1和13.2的最新算法。A survey of advances in vision-based vehicle re-identificationAuthors Sultan Daud Khan, Habib Ullah车辆识别V reID由于其应用和研究意义而在社区中变得非常流行。特别是，V reID是一个仍然面临众多开放挑战的重要问题。本文回顾了不同的V reID方法，包括基于传感器的方法，混合方法和基于视觉的方法，这些方法进一步分为手工制作的基于特征的方法和基于深度特征的方法。基于视觉的方法使V reID问题特别有趣，我们的评论首次系统地解决和评估这些方法。我们对四个综合基准数据集进行了实验，并比较了最近手工制作的基于特征的方法和基于深度特征的方法的性能。我们用平均精度mAP和累积匹配曲线CMC表示这些方法的详细分析。这些分析可以客观地了解这些方法的优缺点。我们还提供了不同V reID数据集的详细信息，并批判性地讨论了V reID方法的挑战和未来趋势。Unlabeled Data Improves Adversarial RobustnessAuthors Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, John C. Duchi我们在理论和经验上证明，对抗性稳健性可以从半监督学习中获益。从理论上讲，我们重新审视了Schmidt等人的简单高斯模型。这表明标准和稳健分类之间的样本复杂性差距。我们证明这个差距与标签无关，简单的半监督学习过程自我训练使用标准精度所需的相同数量的标签来实现稳健的准确性。根据经验，我们使用来自80万个微小图像的500K未标记图像来增强CIFAR 10，并使用强大的自我训练，通过对抗性训练以及通过对抗训练获得的几个强大攻击，超过5个点，超过5个点。并通过随机平滑来确定其稳健性。在SVHN上，添加数据集自己的额外训练集并删除标签可以获得4到10个点的增益，在使用额外标签的增益的1个点内。Are Labels Required for Improving Adversarial Robustness?Authors Jonathan Uesato , Jean Baptiste Alayrac , Po Sen Huang , Robert Stanforth, Alhussein Fawzi, Pushmeet Kohli最近的工作揭示了有趣且有些令人惊讶的发现，即训练模型对于对抗性扰动是不变的，需要比标准分类所需的数据集大得多的数据集。该结果是在许多真实世界应用中部署健壮的机器学习模型的关键障碍，其中标记数据是昂贵的。我们的主要观点是，未标记的数据可以成为标记数据的竞争替代品，用于培训对抗性强的模型。从理论上讲，我们表明，在一个简单的统计设置中，从未标记数据中学习一个对抗性强大模型的样本复杂度与完全监督的情况相匹配，直到恒定因子。在像CIFAR 10这样的标准数据集上，使用未标记数据的简单无监督对抗训练UAT方法比单独使用4K监督示例提高了21.7的稳健精度，并从相同数量的标记示例中捕获了95多项改进。最后，我们通过使用来自未经验证的80万个微小图像数据集的额外未标记数据，报告了对CIFAR 10的先前技术水平的改进 ，对抗已知最强的攻击。这表明我们的发现也延伸到更加现实的情况，其中未标记的数据也是未经确定的，因此开辟了改善对抗性训练的新途径。Partial Scan Electron Microscopy with Deep LearningAuthors Jeffrey M. Ede, Richard Beanland我们提出了一个多尺度条件生成对抗网络，从部分扫描完成512倍512电子显微照片。这使得电子束曝光和扫描时间减少了20倍，强度误差为2.6。我们的网络是根据16227扫描透射电子显微照片的新数据集创建的部分扫描的端到端训练。通过异常值损失的自适应学习率削减和辅助训练器网络实现高性能。我们的新数据集和经过培训的网络的源代码和链接已公开发布Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer LearningAuthors Tailai Wen, Roy Keyes时间序列异常检测在自动监测系统中起着至关重要的作用。以往大多数与时间序列异常检测相关的深度学习工作都是基于递归神经网络RNN。在本文中，我们提出了一种基于卷积神经网络CNN的异常检测时间序列分割方法。此外，我们提出了一种转移学习框架，该框架在大规模合成单变量时间序列数据集上预先训练模型，然后在小规模，单变量或多变量数据集上对其先前看不见的异常类别进行微调。对于多变量情况，我们引入了一种新颖的网络架构。该方法成功地在多个合成和实际数据集上进行了测试。Subspace Networks for Few-shot ClassificationAuthors Arnout Devos, Matthias Grossglauser我们建议子空间网络用于少数射击分类的问题，其中分类器必须推广到训练集中未见的新类，只给出每个类的少量示例。子空间网络学习嵌入空间，其中可以通过计算嵌入点到每个类的子空间表示的距离来执行分类。类子空间由属于同一类的示例跨越，由可学习的嵌入函数转换。与最近用于少数镜头学习的方法类似，子空间网络反映了简单的归纳偏差，这在这种有限的数据体系中是有益的，并且它们获得了优异的结果。特别地，当嵌入功能较深或者当训练和测试域被移位时，我们提出的方法显示出比其他现有技术少的射击距离度量学习方法更好的性能。Known-plaintext attack and ciphertext-only attack for encrypted single-pixel imagingAuthors Shuming Jiao, Yang Gao, Ting Lei, Zhenwei Xie, Xiaocong Yuan在许多先前的工作中，单像素成像SPI系统被构造为光学图像加密系统。未经授权的用户无法在不知道照明模式密钥的情况下从密文强度序列重建明文图像。然而，过去已经研究过很少关于加密SPI的密码分析。在这项工作中，我们首次提出了一种已知的明文攻击方案和一种仅对加密SPI系统的密文攻击方案。已知的明文攻击是通过在SPI模型中交换照明模式和对象图像的角色来实现的。仅基于单像素强度值的统计特征来实现仅密文攻击。这两种方案可以破解加密的SPI系统并成功恢复包含正确照明模式的密钥。Fast Solar Image Classification Using Deep Learning and its Importance for Automation in Solar PhysicsAuthors John A. Armstrong, Lyndsay Fletcher太阳物理中收集的数据量在过去十年中呈指数级增长，随着纹理Daniel K. Inouye太阳望远镜DKIST的推出，我们将进入PB级太阳能数据时代。自动特征检测将成为太阳图像后期处理的宝贵工具，可创建供研究人员使用的数据目录。我们提出了一个深度学习模型来实现这一目标，一个深度卷积神经网络擅长于特征提取和快速处理图像。我们使用来自textit Hinode太阳能光学望远镜的SOT H alpha图像来训练我们的网络。一小部分太阳能特征具有不同的几何形状细丝，突出物，耀斑带，太阳黑子和安静的太阳纹理，即没有任何其他四个特征。我们在4.66秒内将来自SOT的看不见的图像分类大约99.9，实现近乎完美的性能。我们还首次探索太阳能背景下的转移学习。转移学习使用预训练的深度神经网络来帮助训练新的深度学习模型文本，即它教导新模型。我们表明，我们的网络对于分辨率的变化是稳健的，通过降低图像从SOT分辨率降低约0.33素数在lambda 6563 AA到textit太阳动力学天文台大气成像组件SDO AIA分辨率大约1.2素数而不改变我们的网络性能。然而，我们还观察到网络无法推广到SDO AIA频段1600 1700 AA的太阳黑子，因为太阳黑子周围的小规模光亮以及由于日冕发射而在SDO AIA 304 AA中突出。Evaluating Artificial Systems for Pairwise Ranking Tasks Sensitive to Individual DifferencesAuthors Xing Liu, Takayuki Okatani由于深度学习的进步，人工系统现在在几种模式识别任务中与人类竞争，例如对象类别的视觉识别。然而，这仅仅是与人类感知无关的正确答案所存在的任务的情况。还有另一种类型的任务，预测的是人类感知本身，其中通常存在个体差异。然后，不再有单一的正确答案来预测，这使得人工系统的评估变得困难。在本文中，我们关注对个体差异敏感的成对排名任务，我们提出了一种评估方法。给定由人工系统生成的多个项目对的排名结果，我们的方法量化了人类生成相同排名结果的概率，并判断它是否与人类生成的结果可区分。我们引入了人类排名行为的概率模型，并提出了一种有效的判断计算方法。为了从小尺寸样本中准确地估计模型参数，我们提出了一种方法，该方法使用注释器给出的置信度分数来对每个项目对进行排序。以根据对象的材料属性对图像对进行排序的任务为例，我们演示了所提出的方法如何工作。FUNSD: A Dataset for Form Understanding in Noisy Scanned DocumentsAuthors Guillaume Jaume, Hazim Kemal Ekenel, Jean Philippe Thiran在本文中，我们为嘈杂的扫描文档FUNSD中的表单理解提供了一个新的数据集。表格理解FoUn旨在提取和构建表格的文本内容。该数据集包括200个完全注释的真实扫描形式。这些文件很嘈杂，在表现方面表现出很大的变化，使FoUn成为一项具有挑战性的任务。建议的数据集可用于各种任务，包括文本检测，光学字符识别OCR，空间布局分析和实体标记链接。据我们所知，这是第一个公开可用的数据集，其中包含针对FoUn任务的综合注释。我们还提供了一组基线，并介绍了评估FUNSD数据集性能的指标。 FUNSD数据集可以在https guillaumejaume.github下载。有趣的是FUNSD。Combining Noise-to-Image and Image-to-Image GANs: Brain MR Image Augmentation for Tumor DetectionAuthors Changhee Han, Leonardo Rundo, Ryosuke Araki, Yudai Nagano, Yujiro Furukawa, Giancarlo Mauri, Hideki Nakayama, Hideaki Hayashi卷积神经网络CNN可以依靠足够的注释训练数据实现出色的计算机辅助诊断性能。不幸的是，通常从各种扫描仪收集的大多数医学成像数据集都很小且碎片化。在这种情况下，作为数据增强DA技术，生成性对抗网络GAN可以合成逼真的多样化附加训练图像，以填补真实图像分布中缺乏的数据，研究人员通过增加具有噪声的图像来改进分类，例如随机噪声样本到多样化病理图像或图像到图像GAN，例如，良性图像到恶性图像。然而，没有研究报道将i噪声与图像GAN和图像与图像GAN或ii GAN和其他深度生成模型相结合的结果，以进一步提高性能。因此，为了使GAN组合的DA效应最大化，我们提出了一种基于两步GAN的DA，它可以分别生成和改进没有肿瘤的脑MR图像。逐步增长的GAN PGGAN，多级噪声到图像GAN，用于高分辨率图像生成，首先生成逼真的多样256 x 256图像，即使医生也无法通过视觉图灵测试二者将其与真实图像准确地区分开来。无监督图像到图像翻译或SimGAN，图像到图像GAN结合GAN变分自动编码器或使用GAN损失用于DA，进一步细化PGGAN的纹理形状生成的图像与真实的图像类似。我们彻底调查了基于CNN的肿瘤分类结果，同时考虑了预训练对ImageNet的影响，并丢弃了奇怪的GAN生成图像。结果表明，当与经典DA组合时，我们的基于两步GAN的DA在肿瘤检测中可以明显优于单独的经典DA，即将灵敏度从93.63提高到97.53以及其他任务。Residual Networks as Nonlinear Systems: Stability Analysis using LinearizationAuthors Kai Rothauge, Zhewei Yao, Zixi Hu, Michael W. Mahoney我们将预训练的残差网络ResNets视为非线性系统，并使用线性化（非线性系统的定性分析中常用的方法）来理解输入图像的小扰动下网络的行为。我们使用在CIFAR 10数据集上训练的ResNet 56和ResNet 110。我们在剩余单元和网络级的水平上线性化这些网络，并且奇异值分解用于这些组件的稳定性分析。发现残余单元的线性化的大多数奇异值是1，并且尽管线性化直接取决于激活图，但奇异值对于不同的输入图像仅略微不同。然而，调整跳过连接的缩放或残差单元中的权重值对奇异值分布具有显着影响。检查输入图像的随机和对抗扰动如何通过网络传播表明，在随机扰动的情况下，在网络最后阶段结束时，对抗性扰动的幅度急剧增加。我们试图通过将扰动投影到残余单元的线性化的奇异向量上来更好地理解这种现象。Multi-modal Discriminative Model for Vision-and-Language NavigationAuthors Haoshuo Huang, Vihan Jain, Harsh Mehta, Jason Baldridge, Eugene Ie视觉和语言导航VLN是一种自然语言基础任务，代理必须在动态环境中的视觉场景环境中解释自然语言指令，以实现规定的导航目标。成功的代理人必须能够解析不同语言风格的自然语言，将其置于可能不熟悉的场景中，计划并对模糊的环境反馈做出反应。泛化能力受人类注释数据量的限制。特别是，配对的视觉语言序列数据收集起来很昂贵。我们开发了一个鉴别器，用于评估指令在多模态对齐中解释VLN任务中给定路径的程度。我们的研究表明，只有一小部分来自citet Fried 2018扬声器的高质量增强数据，由我们的鉴别器评分，可用于训练在以前看不见的环境中具有类似性能的VLN代理。我们还表明，使用来自鉴别器的预先训练的组件开始的VLN代理温度优于基于以前看不见的环境的35.5乘10相对测量的基准成功率。Convolutional Restricted Boltzmann Machine Based-Radiomics for Prediction of Pathological Complete Response to Neoadjuvant Chemotherapy in Breast CancerAuthors Li Wang, Lihui Wang, Qijian Chen, Caixia Sun, Xinyu Cheng, Yuemin Zhu我们提出了一种新的卷积限制Boltzmann机CRBM基于放射学方法预测乳腺癌新辅助化疗治疗NACT的病理完全反应pCR。该方法包括从CRBM网络中提取语义特征和pCR预测。对57名患者的动态对比增强磁共振成像DCE MRI数据进行评估，并使用接收器操作特征曲线AUC下的面积。从在NACT管理之前和之后获得的图像中提取传统的放射学特征和从CRBM网络学习的语义特征。在特征选择之后，训练支持向量机SVM，逻辑回归LR和随机森林RF以预测pCR状态。与传统的放射学方法相比，所提出的基于CRBM的放射学方法对于在NACT之前和之后获得的图像的预测产生0.92的AUC，并且预处理预测的AUC为0.87，其增加了约38。结果表明，基于CRBM的放射免疫方法为治疗前准确预测乳腺癌中的PCR至NACT提供了一种潜在的手段，这对于制定更合适和个性化的治疗方案非常有用。Generative Imaging and Image Processing via Generative EncoderAuthors Lin Chen, Haizhao Yang本文介绍了一种新的生成编码器GE模型，用于生成成像和图像处理，应用于压缩感知和成像，图像压缩，去噪，修复，去模糊和超分辨率。 GE模型包括预训练阶段和解决阶段。在训练前阶段，我们分别训练两个深度神经网络，即生成对抗网络GAN，其中生成器G捕获给定图像集的数据分布，以及自动编码器AE网络，其具有编码器EN，其按照估计的分布压缩图像由GAN。在求解阶段，给定噪声图像x mathcal P x，其中x是目标未知图像，mathcal P是添加上瘾，乘法或卷积噪声的运算符，或等效地在压缩域中给出这样的图像x，即，给定m EN x，我们解决了优化问题Seeing the Wind: Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural NetworkAuthors Jennifer L Cardona, Michael F Howland, John O Dabiri风能资源量化，空气污染监测和天气预报都依赖于对当地风况的快速，准确的测量。视觉观察风的影响，树木的摇摆和旗帜的拍打，例如编码关于局部风况的信息，其可以潜在地用于廉价且普遍存在的视觉风速测量。在这里，我们展示了耦合卷积神经网络和递归神经网络架构，其提取在自然发生的风中的旗帜的视觉记录的流动结构相互作用中编码的风速。对于风速为0.75 11 m s的预测结果与现场杯式风速计的测量结果一致，均方根误差接近由于大气湍流引起的自然风速变化。通过基于现场中的其他旗帜的记录和在风洞测试中控制的风速的成功预测来证明网络的可概括性。此外，基于物理的抖动动态缩放精确地预测了网络性能对视频帧速率和持续时间的依赖性。Chinese Abs From Machine TranslationPapers from arxiv.org更多精彩请移步主页Interesting:📚基于草图生成前端代码，快速制作网页原型, (from 布里斯托大学)下图显示了具体的流程，首先抽取草图中对应区域，随后根据不同区域分类生成对应代码得到最终的网页结果：流程如下：研究人员构建的主页例子：https://getbootstrap.com/docs/4.0/examples/📚对高粱株的分割与计数方法, 提出了一种自动化高通量的高粱计数和分割方法，通过图像中的密度来对高粱植株进行分割和计数。(from IBM research)网络模型如下图所示，分为检测和密度估计网络两个部分。结果与相关方法的比较：video:https://youtu.be/McMRqPDyQjE https://youtu.be/B6wxXUfrUuw📚***+++基于域对抗的水下图像质量增强方法, 这篇文章提出了一种新的方法，通过对抗学习内容特征来解决水下图像的多样性问题，将不希望看到的与水质相关的因素解耦出来。同时利用学习到了特征来生成增强后的图像。(from 德州农工大学)data:Jerlov water types [1].real:Underwater Image Enhancement Benchmark Dataset (UIEBD) built by [18]synthesized dataset built using the method described in [3]📚ReDO通过重绘制图片来实现无监督的图像分割, 研究人员提出了一种从图像中抽取目标的无监督方法，这个想法来自于我们可以在改变目标的颜色和纹理的情况下不改变数据集的分布。所以利用了对抗架构，通过输入图像，抽取目标掩膜，而后重新在相同的位置绘制出新的目标。判别器控制着生成器来保证数据集的分布与原始情况相同。(from 巴黎索邦大学 )一些结果，下图显示了原始图像，基准mask和推测出的mask，以及基于这种方法得到新图像：dataset:Flowers dataset [38, 39]Labeled Faces in the Wild dataset [25, 31]Caltech-UCSD Birds 200 2011 (CUB-200-2011) dataset [48]code:https://github.com/mickaelChen/ReDO📚AGCN基于注意力的图网络用于点云学习, 提出了一种基于注意力的图卷积网络来抽取点云特征，研究人员将这一过程视为邻近点间的信息传输过程，引入了注意力机制来分析局域点云特征的相互关系。此外，引入了二外的全局图结构网络来补偿独立点的相关信息，并将编码器解码器结构拓展到了分割任务上。(from 西南交通大学)模型共分为三个部分，对电云进行采样，在M个节点上各采样L个点，并为每个节点抽取相应的特征。随后基于KNN图引入注意力机制，供堆了三层来实现分类。最后利用全局的点云图来补偿局部点云信息帮助点云的理解和学习。点注意力层，利用三层的图网络来汇集周围点的信息。其中箭头表示了信息流动的方向：基于点云注意力的编码器解码器架构，这是一个可逆操作，编码器抽取信息，解码器将高维信息解码为低维度细粒度信息，在每一层都加入了全局点云信息。全局点云信息的结构如下所示，基于KNN图构造的特征抽取，其中为k个最邻近点加上sj点本身：与其他方法的一些比较与一些结果：TL;DwR:基于视觉的车辆重识别FUNSD包含噪声的文件扫描数据集, reference website基于视觉的风速预测太阳表面图像数据预测，code:https://github.com/rhero12/Slic韩语字符数据集DAISY SYSTEM预测枪击地点的建模、接口和相关信息技术报告隐式方法背景估计, code:https://github.com/olivesgatech/implicit-background-estimationpic from pexels.com"}
