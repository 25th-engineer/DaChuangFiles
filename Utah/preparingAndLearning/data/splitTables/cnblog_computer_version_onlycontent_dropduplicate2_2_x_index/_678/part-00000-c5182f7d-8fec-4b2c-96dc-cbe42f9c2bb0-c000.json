{"content2":"计算机视觉赋予机器人“看”的功能正是“机器视觉”这个学科所研究的问题之一。这一领域十分广阔，不仅包括通用技术，而且也包括为数众多的专用技术——如NLP、指纹识别、相片解释和机器人控制等等。这里仅介绍一些计算机视觉的概念。引言计算机视觉首先是在一组感光性原件上，生成一个场景的图像。这个图像是摄像机通过镜头对在视野中的场景进行一个透视投影，然后后光电元件将其转化为一个二维的、随时间变化的亮度矩阵图像I(x,y,t)，其中x，y为光电元件在数组中的位置，t为时间（对于有色视觉则需要三个这样的矩阵来代表三原色）。一个由视觉引导的响应agent必须通过处理这个矩阵来产生这个场景的图标模型或者一组特征，从而使他能直接计算一个动作。希望获取信息的种类取决于agent的目的和任务。若要让一个agent平安地通过一个混乱的环境，这个agent必须了解其中物体的位置、边界、通路以及它所经路径表面的特性。agent也许还应具备根据每隔一段时间所有以上信息的变化来预测将来了能的变化。从一个或多个图像中获取此类信息将及其困难，所以，只能给出这类技术的一个概况。操纵一辆汽车在S-R agent的一些应用中，神经网络可用来把图像亮度矩阵直接转化为动作。其中一个突出的例子就是用来驾驶一辆汽车的ALVINN系统。网络第一层有5个隐藏单元，第二层有30个输出单元，以上所有单元均为sigmoid单元。输出单元通过线性排列来控制汽车高度。若此输出单元队列顶端附近的一个输出单元比其他大多数输出单元高，则车向左行驶；若此输出单元队列底端附近的一个输出单元比其他大多数输出单元高，则车向右行驶。此系统由改进过的“在空中（on-the-fly）”训练方式来传播，真人驾驶员开车，实际的驾驶角度被作为相应输入的正确标志。网络以反向传播的方式递增训练，从而使他能用驾驶员所指定的驾驶角度来响应实际驾驶车辆时出现的每一个视觉模式。机器视觉的两个阶段图像处理阶段把原始图像转换成更适合于景物分析的图像。图像处理包括降噪、增强边缘和寻找图像区域等不同的滤波操作。景物分析主要试图从已处理的图像中产生一个对原始场景的图标描述或基于特征的描述，并提供agent所处环境中与特定任务有关的信息。图像处理1. 平均法假设初始图像可表达为一个m*n的数组I(x,y),我们称之为“图像亮度数组”。他把图像平面分成许多被称为“像素（pixel）”的单元。这些数字表示这幅图相中某点的光亮度，图像中一些不规则之处可通过求平均数的方法得以平滑。这种滑动并求和的操作称为“卷积”。如果我们的得到的数组十二进制（1或0），那么就必须把这些加权总和和一个阈值比较。平均法不仅将压缩孤立的噪音点，而且将减小图像的卷曲度（crispness），放弃那些微不足道的图像元素。有时，我们把加权函数W(x,y)的值在x和y构成的长方形内看做1，长方形之外看做0.长方形大小决定平滑度，长方形越大平滑度越高。下图展示了一个求平均数操作是如何让对一个二进制图像先用一个长方形平滑函数平滑，然后将其与阈值比较来进行操作的。我们发现这个平滑操作加粗了宽线，去除了窄线和微小细节。2. 边缘增强如前所述，计算机视觉常常设计图像边缘的提取，然后用这些边缘来把图像转换成某种线条图形。获取轮廓的方法之一是先增强图像中的边界和边缘，边缘可以是图像个部分之间的任意边界。我们可以通过在以为图像上卷积一个位于垂直线上的、一半为负一半为正的窗口来增强这些图像的边缘强度。3. 边缘增强和平均法的结合还有其他的变化比拉普拉斯变换更好，其中突出的有：Canny变换、Sobel变化、Hueckel变换等。4. 区域查找首先，我们必须定义什么是图像的一个区域。一个区域就是满足一下特性的相互连接的像素：下图运用了亮度差别不超过1个单元这个同质的特性。当无需再进行分割时，可以合并那些满足此同质特性的相邻的候选区域。场景分析在用以上技术对图像进行处理后，我们力图从中获取所需有关场景的信息。计算机视觉的这个阶段被称为“场景分析”。1. 解释图像中的线条和曲线对已知的包含直线物体的场景进行分析时，其中关键的一步就是图像中线条的假定。可以通过采用把直线段与边缘或区域的边界拟合的技术来生成直线。下图就是对一个房间的解释。2.基于模型的视觉"}
