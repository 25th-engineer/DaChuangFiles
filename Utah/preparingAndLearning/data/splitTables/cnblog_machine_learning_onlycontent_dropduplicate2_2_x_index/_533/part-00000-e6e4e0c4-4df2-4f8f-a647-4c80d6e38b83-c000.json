{"content2":"截止目前，已经知道了常用的机器学习算法是怎么回事儿、学习的步骤是怎么进行的。但在机器学习的应用背景是多种多样的，做实际工程必须学会如何根据具体的问题评估一个学习模型的好坏，如何合理地选择模型、提取特征，如何进行参数调优。这些也是我以前做模式识别时欠缺的环节，所以在遇到识别率很低的情况时，往往很困惑，不知道该如何改进：到底是应该改进模型改变特征、还是应该增加训练样本数量，到底是应该优化迭代算法，还是应该改变目标函数。通过学习Learning Theory可以得到一些指导性的结论。\n首先，是bias-variance trade off问题。假设训练模型集合H中有k个备选模型，k表示了模型的复杂度，训练集中有m个样本，则式子 Test Error <= Training Error + 2*（log(2k/delta)*1/2m）^0.5 在概率1-delta成立。Training Error是所谓的bias，表征了训练样本跟模型的吻合程度，bias越大，即训练误差越大，训练样本跟模型的吻合程度越低，即出现“欠学习“的情况；2*（log(2k/delta)*1/2m）^0.5 是variance，k越大（即模型的复杂度越大）m越小（即训练样本数量越小）variance越大，模型的推广能力越差，即出现“过学习“的情况。这个结论还有另外一个推论：给定delta和gamma，如果Test Error <= Training Error + 2*gamma 在概率1-delta下成立，则训练样本数量m必须满足:m>=O(1/gamma*log(k/delta))。这个推论表明：为了保证Test Error不至于过大，训练样本的数量m必须同模型复杂度log(k)成正比。实际的模型复杂度一般不用k表示，而是假设模型有d个参数，则每个样本点的维数为d，每个参数为double型，那么k=2^(64d)，上面的条件变为：m>=O(d/gamma*log(1/delta))，即训练样本的数量m同模型参数个数d成正比。上面的结论是针对有限维空间的情况，对于无限维空间，d用H的VC维来代替，可以得到类似的结论。一般来讲，VC维与模型的参数个数d成正比，但在一些特殊情况下，VC维不一定与样本维数有关系，比如支持向量机。bias-variance trade off的过程实际上就是模型选择和特征选择的过程，对于模型选择，最实用的办法就是进行交叉验证，得到Test Error最小的模型；对于特征选择，可采用前向选择或后向选择的方法选择好的特征，删除不好的特征，或者采用滤波的方法，计算每个特征xi与y的互信息量，取互信息量较大的那个特征。\nbias-variance trade off的目的是寻找训练误差和推广能力的平衡，为了达到这个平衡也可以采用加入Regularation的办法。用统计推断的观点看待机器学习问题：不加Regularation对应频率学派的方法，即将参数theta看成一个未知的确定性变量，学习的过程就是求y和x的最大似然对应的theta，加Regularation对应贝叶斯学派的方法，即将参数theta看成一个随机变量，学习的过程就是已知theta的先验概率，求theta的最大后验概率。加入Regularation后，目标函数中加入了lamda*||theta||^2的正则项。对一个回归问题，加入正则项后，拟合的结果会更加平滑，有效地减少了”过拟合“。\n学习了这么多Learning Theory，我们回到笔记开头提出的问题：怎样优化学习算法。首先判别是high bias问题还是high variance问题，判断的方法有两个：一、test error大则是high variance问题、 training error大则是high bias问题；二、增加训练样本数量，看两类error的变化趋势，test error变小，则是high variance问题。增加训练样本数量，减少特征数量可以解决high variance问题，增加特征数量可以解决high bias问题。"}
