{"content2":"异常检测(Anomaly Detection)\n基本假设：多数情况下数据点落入正常的取值范围，但是当异常行为发生时，数据点的取值落入正常取值范围之外（如所示）。所以可以利用高斯分布，计算行为发生的概率，如果是概率小于给定阈值，则认为发生了异常行为。基本过程是利用训练数据点建立模型$p(x)$，对于新的数据点$x_{new}$, 如果$p(x_{new})<\\epsilon$则发生异常；否则正常。异常检测的应用包括：\n欺诈检测(Fraud detection)\n制造业(Manufacturing)\n数据中心监视电脑(Monitering computers in data center)\n\n高斯分布\n对于一元高斯分布$x \\sim N(\\mu, \\sigma^2)$，表达式如下，其中$\\mu$表示均值，对应于分布的对称轴；$\\sigma$表示数据点的离散程度，$\\sigma$越大函数图像的下端张口越大峰值越低；反之$\\sigma$越小，图像下端张口越小，峰值越高，如所示。\n$$p(x;\\mu, \\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\sigma}exp(-\\frac{(x-\\mu)^2}{2\\sigma^2})$$\n\n参数估计\n高斯分布的总体参数$\\mu$和$\\sigma$可以使用样本数据点进行估计，如下\n$$\\mu = \\frac{1}{m}\\sum\\limits_{i=1}^{m}x^{(i)}$$\n$$\\sigma^2=\\frac{1}{m}\\sum\\limits_{i=1}^{m}(x^{(i)}-\\mu)^2$$\n注意在统计学中，参数$\\sigma^2$的系数为$\\frac{1}{m-1}$而在机器学习中习惯使用$\\frac{1}{m}$.\n异常检测算法\n对于训练数据集$\\{x^{(1)}, x^{(2)}, \\ldots, x^{(m)}\\}$，其中数据点$x^{(i)}\\in R^n$并假设每个特征均服从高斯分布，即$x^{(i)}_j \\sim N(\\mu, \\sigma^2)$，可如下建立模型$p(x)$\n\\begin{align*}p(x)&=p(x_1; \\mu_1, \\sigma_1^2)p(x_2; \\mu_2, \\sigma_2^2)\\ldots p(x_n; \\mu_n, \\sigma_n^2) \\\\ &= \\prod\\limits_{j=1}^n p(x_j; \\mu_j, \\sigma_j^2)\\end{align*}\n算法步骤：\n1. 特征选择：选择能够指示异常行为的特征\n2. 参数估计：用训练数据集估计每个特征的整体均值$\\mu_j$和方差$\\sigma_j^2$，即$\\mu_j = \\frac{1}{m}\\sum\\limits_{i=1}^{m}x^{(i)}_j$, $\\sigma^2_j=\\frac{1}{m}\\sum\\limits_{i=1}^{m}(x^{(i)}_j-\\mu_j)^2$\n3. 用估计得到的参数$\\mu_1, \\mu_2, \\ldots, \\mu_n$,  $\\sigma^2_1, \\sigma^2_2, \\ldots, \\sigma^2_n$建立模型$p(x)$；\n4. 对于给定新的数据点$x_{new}$, 计算$p(x_{new})$；如果$p(x_{new})<\\epsilon$则发生异常，否则正常。\n算法评估:\n给定训练数据集(去掉标签建立模型)中$\\{x^{(1)}, x^{(2)}, \\ldots, x^{(m)}\\}$，训练模型$p(x)$。在交叉验证集(带标签)中，如果$p(x_{cv})<\\epsilon$，则预测$y=1$；否则预测$y=0$。最后计算指标Precision/Recall/F1Score等来评估算法性能。注意：也可以用验证集来选择阈值$\\epsilon$.\n异常检测与监督式学习对比：\n特征选择：\n选择的特征需要近似服从于高斯分布，如果明显不服从高斯分布，可以做适当的转换，例如$log(x), log(x+c), \\sqrt{x}, x^{1/3}$等\n多元高斯分布\n之前的模型假设各个特征之间是相互独立的，因此模型$p(x)$将各特征取值的概率相乘【$P(AB)=P(B)P(A|B)=P(A)P(B|A)$，当且仅当事件AB相互独立时才有$P(AB)=P(A)P(B)$】；然而当各个特征之间存在依赖关系时，一元的高斯模型将不能很好的刻画$p(x)$，需要多元高斯模型。模型$p(x)$的建立不再是各个概率相乘，而直接用多元高斯分布进行刻画$$p(x;\\mu, \\Sigma)=\\frac{1}{(2\\pi)^{n/2}|\\Sigma|^{1/2}}\\exp\\left(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\right)$$ 其中$\\mu$是$n$维行向量，$\\mu=\\frac{1}{m}\\sum\\limits_{i=1}^{m}x^{(i)}$； $\\Sigma$是$n\\times n$协方差矩阵，$\\Sigma=\\frac{1}{m}\\sum\\limits_{i=1}^{m}(x^{(i)}-\\mu)(x^{(i)}-\\mu)^T$，给出了在不同参数取值下的二维高斯模型及其对应的等高线图。\n\n多元高斯模型和一元高斯模型的关系：当协方差矩阵$\\Sigma$是对角阵且对角线元为一元高斯分布的估计参数$\\sigma_j^2$时，两个模型是等价的。区别在于前者能够自动获取特征之间的依赖关系而后者不能(后者假设特征之间是独立的)。当特征数$n$很大时，前者计算代价高昂而后者计算速度快。前者适用于$m>n$(一般要求$m>10n$)的情况，而后者当$m$很小时依然适用。\n推荐系统\n电影推荐系统问题：根据用户对已看过电影的打分，对用户未看过的电影(下表中以?表示)进行打分估计，以给其推荐合适的电影。\n符号说明：\n$n_u$表示用户数量\n$n_m$表示电影数量\n$r(i, j)$是符号变量，如果用户$j$已经对电影$i$进行评分则$r(i, j)=1$；反之，如果用户$j$尚未对电影$i$进行评分则$r(i, j)=0$.\n$y^{(i, j)}$表示用户$j$对电影$i$的评分（如果用户$j$对电影$i$已经评分，即$r(i, j)=1$）.\nMovie\nUser1\nUser2\nUser3\nUser4\nx1\nx2\nmovie1\n5\n5\n0\n0\n0.9\n0\nmovie2\n5\n?\n?\n0\n1.0\n0.01\nmovie3\n?\n4\n0\n?\n0.99\n0\nmovie4\n0\n0\n5\n4\n0.1\n1.0\nmovie5\n0\n0\n5\n?\n0\n0.9\n基于内容的推荐\n对每一部电影$i$抽出若干特征，然后每个用户$j$学习一个参数向量$\\theta^{(j)}$，然后用$(\\theta^{(j)})^Tx^{(i)}$来估计用户$j$对电影$i$的评分。例如对于上面的表格，我们对每一个电影抽取出2个特征$x_1,x_2$(对应表格最后2列)，然后每个用户$j$学习一个参数向量$\\theta^{(j)}\\in R^3$（包含bias项$\\theta_0=1$以及$x_1, x_2$的系数$\\theta_1, \\theta_2$）,然后就可以用$(\\theta^{(j)})^Tx^{(i)}$来预测评分。为了学习参数$\\theta$，定义代价函数为$$J(\\theta^{(1)},\\theta^{(2)},\\ldots,\\theta^{(n_u)})=\\frac{1}{2}\\sum\\limits_{j=1}^{n_u}\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum\\limits_{j=1}^{n_u}\\sum\\limits_{k=1}^n(\\theta^{(j)}_k)^2$$\n梯度下降法的参数更新：$$\\theta_k^{(j)}=\\theta_k^{(j)}-\\alpha\\left(\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\\lambda\\theta_k^{(j)}\\right)\\quad k > 0$$ $$\\theta_k^{(j)}=\\theta_k^{(j)}-\\alpha\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}\\quad k = 0$$\n协同过滤(Collaborative Filtering)\n基于内容的推荐假设电影的特征(如$x_1$, $x_2$)是已知的，仅需要学习参数$\\theta$；然而实际中电影的特征是未知的，现在假定已知用户的参数$\\theta$，需要学习电影的特征$x$，与上面的代价函数类似，定义$$J(x^{(1)},x^{(2)},\\ldots,x^{(n_m)})=\\frac{1}{2}\\sum\\limits_{i=1}^{n_m}\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum\\limits_{i=1}^{n_m}\\sum\\limits_{k=1}^n(x^{(i)}_k)^2$$这样我们发现，给定电影特征$x$可以学习到用户参数$\\theta$；反之给定用户参数$\\theta$可以学习到特征$x$。因此可以先随机猜一个$\\theta$，然后学习$x$，再由学习到的$x$学习$\\theta$，然后不断重复即可。然而事实上，两个参数$x, \\theta$可以如下同时更新，从而得到协同过滤的推荐算法$$J(x^{(1)},x^{(2)},\\ldots,x^{(n_m)},\\theta^{(1)},\\theta^{(2)},\\ldots,\\theta^{(n_u)})=\\frac{1}{2}\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\\frac{\\lambda}{2}\\sum\\limits_{j=1}^{n_u}\\sum\\limits_{k=1}^n(\\theta^{(j)}_k)^2+\\frac{\\lambda}{2}\\sum\\limits_{i=1}^{n_m}\\sum\\limits_{k=1}^n(x^{(i)}_k)^2$$\n协同过滤算法步骤:\n1. 初始化参数$x^{(1)},x^{(2)},\\ldots,x^{(n_m)},\\theta^{(1)},\\theta^{(2)},\\ldots,\\theta^{(n_u)}$为随机数，其中$x\\in R^n$表示电影特征，$\\theta \\in R^n$表示用户参数（注：不包含bias参数$\\theta_0$）\n2. 使用梯度下降或者其他高级优化算法，进行参数更新\n$$x_k^{(i)}=x_k^{(i)}-\\alpha\\left(\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\\lambda x_k^{(i)}\\right)$$\n$$\\theta_k^{(j)}=\\theta_k^{(j)}-\\alpha\\left(\\sum\\limits_{i:r(i,j)=1}((\\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\\lambda\\theta_k^{(j)}\\right)$$\n3. 用学习到的参数$\\theta$和$x$预测电影评分$\\theta^Tx$\n低秩矩阵分解(Low rank matrix factorization)\n协同过滤与低秩矩阵分解：协同过滤算法要求评分矩阵$Y$中元素$y^{(i,j)}$越接近$(\\theta^{(j)})^T x^{(i)}$越好，因此参数$\\theta$和$x$的求解，实际上等价于寻找两个矩阵$X$和$\\Theta$使得$Y \\approx X\\Theta^T$，从而协同过滤问题可以转化为低秩矩阵分解问题。\n均值归一化：对于尚未评分任何电影的用户，可以对$Y$矩阵按行求平均值作为该用户的初始评分；用均值化矩阵$Y-\\mu$进行参数学习，然后用$(\\theta^{(j)})^T\\theta^{(i)}+\\mu_i$进行评分预测。\n参考文献\n[1] Andrew Ng Coursera 公开课第九周\n[2] Recommender Systems: Collaborative Filtering. http://recommender-systems.org/collaborative-filtering/\n[3] Wikipedia: Low-rank approximation https://en.wikipedia.org/wiki/Low-rank_approximation"}
