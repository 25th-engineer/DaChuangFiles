{"content2":"写在前面的废话：\n好吧，不得不说鱼C的markdown文本编辑器挺不错的，功能齐全。再次感谢小甲鱼哥哥的python视频让我去年大三下学期的时候入门了编程，爱上了编程这门语言，由于是偏冷门的统计学，在实习以后就决定把方向放在数据挖掘方面了，越来越发现专业课的重要性。在大家都忙着参加各种培训的日子里面，我就在去年寒冷的冬天把甲鱼哥的python视频一字不落的看完了；现在，在别人拼命参加校招的日子里，我就来学习“机器学习”这里面的算法了（ps：工科学校的理科妹子表示很难找到数据分析工作，人家只要研究生）。好吧，我就不信邪了，硬是开启了持续两个月的Ng教授的coursera上面的“机器学习”课程（里面的assignment很简单，使用matlab完成），刚好实验室进货一本《机器学习实战》，也就拿来练练手，让自己的python进阶一下，之前各种web后台折腾，尤其是爬虫，然而我不想帮别人爬数据，我要分析数据，挖掘潜在信息，程序是工具，掌握业务趋势才是王道！\n不废话了，接下来的笔记系列都是我在coursera上面的领悟，根据自己的手写笔迹以及《机器学习实战》这本书的代码得来的，希望不习惯更新博客的我能把这件事情坚持下来。加油！\n正文：\n这两年估计很多人都听说过“大数据”，目前机器学习也在悄无声息的进入到部分数据挖掘领域。当然，国外数据挖掘已经很成熟了，机器算法应用的范围也就更加广泛，分别有：网络搜索，邮件分类；机器人；生物和医药学研究等等。\n这里举几个具体例子：\n网站数据：你可以根据网站的点击数据了解产品的欢迎程度；\n医疗数据：根据医疗记录了解病人的病情方便诊断；\n生物方面：比如基因DNA序列可以用于研究人类的某些特质甚至遗传方面的信息；\n工程领域：指导无人机自主运行，手写字体的识别，NLP(Natural Language Processing 俗称”自然语言处理“)，以及计算机视觉;\n推荐系统：亚马逊的产品推荐系统（貌似这个也可以被分到网站数据）。\n那么啰嗦了这么多，什么是机器学习呢？\n这里有两种定义：\n通俗点讲：研究让机器拥有人一样的学习能力，该能力不被固定的编程实现或操作，属于机器本身的一种自主学习行为。\n学术点讲：通过经验E，针对某些任务T，设计出一段计算机程序，该程序拥有特定的绩效指标P，程序的目的就是根据历史经验E的不断的积累在任务T中提高它的绩效指标P。\n学术就是学术，太生硬了，也是我不考研的原因之一，so boring~通俗的举个例子：\n下跳棋：\nE = 玩了多局跳棋所累积的经验\nT = 下跳棋本身就是一个任务\nP = 程序赢得下一次跳棋的可能性\n机器学习主要包括两个任务：分类和回归。前者非常容易理解，就是在一个预测任务中把数据分类；后者回归主要是统计意义上的，用于预测数据，做过数学建模的同学估计对拟合曲线相当熟悉；是的，回归里面一个非常重要的任务——数据拟合曲线：通过给定的数据集合拟合出最优曲线，使得该曲线尽量能够反应数据的趋势，在不过度拟合的情况下能让给定的数据集落在线附近（上）。而机器学习包括“监督学习”和“非监督学习”，那么分类和回归都属于“监督学习”。接下来抛砖引玉，本文的重点就是区分“监督学习”和“非监督学习”，后面的文章中讲分别对这两种学习进行细分，甚至回归和分类里面的细节更是数不甚数。\nSupervised Study\nExample 1：房价预测（线性回归）\n假设，你手上有一堆房价以及房子大小面积的数据，让你根据房子大小估算房价，然后你根据数据得出下图（图太丑，不许勿喷）\n你根据数据的分布分别拟合直线和曲线，两种拟合的线在x1这个点预测分别得到y1和y2；因此，不同的曲线对应不同的预测结果。那么，为什么我说这里的房价预测就是一种“监督学习”呢？因为有确定的答案被给出了，也就是说在数据集中，不同的房子的面积分别对应着不同的房价。也就是说，这类算法明确的知道自己预测的是什么（本例中预测房价），目标变量非常明确。\n以上问题也被称为回归问题：预测连续的输出值。\nExample 2：肿瘤癌的预测：良性肿瘤和恶性肿瘤（Logistic回归）\n上图中的“×”符号代表的就是数据集，指的是不同肿瘤大小对应是否为恶性肿瘤（1），如果是恶性肿瘤，那么对应数值1；反之对应数值2。这就是一个典型的二值化问题，也被称为（Logistic回归问题），常用于分类：离散的输出值（0或者1）。\n当然，在实际的预测中，肿瘤是否恶性的判断需要依据很多属性，比如：肿瘤块的厚度、细胞的形状等等，而影响肿瘤大小的因素也有很多，比如年龄等等。这么多属性，如果都用画图的方式来拟合数据，就显得比较低效率，因此，我们引入了“向量机”，以后我们会讨论到这个问题，有兴趣的可以谷歌一下。\nUnsupervised Study\n顾名思义就是没有给定的正确的答案\n先上图：\n单纯是给一堆数据，如上图的黑色小圆圈代表数据集，让你找到这些数据的结构特点，也就是聚类（正所谓：物以类聚，人以群分）。很明显，你没有标准答案，因此既可以把数据按照红色的椭圆形聚为2类，又可以按照紫色的线条圈起来的范围聚为3类，还可以按照蓝色正方形圈为2类，没有人说你这种聚类是错误的，只要你说出你的理由。\n看起来，非监督学习无理可循，但是应用范围相当广泛：组织计算机集群，社交网络分析，市场份额分割以及天文数据分析。在未来大数据下需要被探索的东西太多，未知数也往往深不可测，因此非监督学习这个学科的“水”相当深~\n嗯，暂且介绍到这里，老衲要午睡了，下午还要上courera的课程，第四周了，欢迎有兴趣的朋友和我成为同学~\n下集预告：线性回归以及梯度下降算法。"}
