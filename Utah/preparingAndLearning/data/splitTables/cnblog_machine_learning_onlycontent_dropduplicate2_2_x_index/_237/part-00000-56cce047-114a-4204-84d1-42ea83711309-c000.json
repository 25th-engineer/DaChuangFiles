{"content2":"不多说，直接上干货！\n我的集群机器情况是 bigdatamaster（192.168.80.10）、bigdataslave1（192.168.80.11）和bigdataslave2（192.168.80.12）\n然后，安装目录是在/home/hadoop/app下。\n官方建议在master机器上安装Hue，我这里也不例外。安装在bigdatamaster机器上。\nHue版本：hue-3.9.0-cdh5.5.4\n需要编译才能使用（联网）\n说给大家的话：大家电脑的配置好的话，一定要安装cloudera manager。毕竟是一家人的。\n同时，我也亲身经历过，会有部分组件版本出现问题安装起来要个大半天时间去排除，做好心里准备。废话不多说，因为我目前读研，自己笔记本电脑最大8G，只能玩手动来练手。\n纯粹是为了给身边没高配且条件有限的学生党看的！ 但我已经在实验室机器群里搭建好cloudera manager 以及 ambari都有。\n大数据领域两大最主流集群管理工具Ambari和Cloudera Manger\nCloudera安装搭建部署大数据集群（图文分五大步详解）（博主强烈推荐）\nAmbari安装搭建部署大数据集群（图文分五大步详解）（博主强烈推荐）\n一、默认的spark配置文件\n########################################################################### # Settings to configure the Spark application. ########################################################################### [spark] # Host address of the Livy Server. ## livy_server_host=localhost # Port of the Livy Server. ## livy_server_port=8998 # Configure livy to start with 'process', 'thread', or 'yarn' workers. ## livy_server_session_kind=process # If livy should use proxy users when submitting a job. ## livy_impersonation_enabled=true # List of available types of snippets ## languages='[{\"name\": \"Scala Shell\", \"type\": \"spark\"},{\"name\": \"PySpark Shell\", \"type\": \"pyspark\"},{\"name\": \"R Shell\", \"type\": \"r\"},{\"name\": \"Jar\", \"type\": \"Jar\"},{\"name\": \"Python\", \"type\": \"py\"},{\"name\": \"Impala SQL\", \"type\": \"impala\"},{\"name\": \"Hive SQL\", \"type\": \"hive\"},{\"name\": \"Text\", \"type\": \"text\"}]'\n二、以下是跟我机器集群匹配的配置文件（非HA集群下怎么配置Hue的spark模块）\n我的spark是安装在bigdatamaster、bigdataslave1和bigdataslave2机器上。\n注意： 要在Hue中使用Spark还需要安装spark-jobserver，但是这个东西没在CDH中，所以我们必须手动安装spark-jobserver 先要安装SBT。SBT = (not so) Simple Build Tool,是scala的构建工具，与java的maven地位相同。\ncurl https://bintray.com/sbt/rpm/rpm > bintray-sbt-rpm.repo sudo mv bintray-sbt-rpm.repo /etc/yum.repos.d/ sudo yum install sbt\n安装好SBT后，安装spark-jobserver\ngit clone https://github.com/ooyala/spark-jobserver.git cd spark-jobserver sbt re-start\n编辑jobserver 配置文件，将jobserver跟你的spark-master连接上。编辑 job-server/src/main/resources/application.conf 修改master属性\nmaster = \"spark://bigdatamaster:7077\"\n编辑 hue.ini 找到 [spark] 段落，修改 server_url 为正确的地址\n[spark] # URL of the REST Spark Job Server. server_url=http://host1:8090/\n三、以下是跟我机器集群匹配的配置文件（HA集群下怎么配置Hue的pig模块）\n跟非HA集群一样的配法。\n欢迎大家，加入我的微信公众号：大数据躺过的坑        人工智能躺过的坑\n同时，大家可以关注我的个人博客：\nhttp://www.cnblogs.com/zlslch/   和     http://www.cnblogs.com/lchzls/      http://www.cnblogs.com/sunnyDream/\n详情请见：http://www.cnblogs.com/zlslch/p/7473861.html\n人生苦短，我愿分享。本公众号将秉持活到老学到老学习无休止的交流分享开源精神，汇聚于互联网和个人学习工作的精华干货知识，一切来于互联网，反馈回互联网。\n目前研究领域：大数据、机器学习、深度学习、人工智能、数据挖掘、数据分析。 语言涉及：Java、Scala、Python、Shell、Linux等 。同时还涉及平常所使用的手机、电脑和互联网上的使用技巧、问题和实用软件。 只要你一直关注和呆在群里，每天必须有收获\n对应本平台的讨论和答疑QQ群：大数据和人工智能躺过的坑（总群）（161156071）"}
