{"content2":"1. Iris data set\nIris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。\n该数据集包含了5个属性：\nSepal.Length（花萼长度），单位是cm;\nSepal.Width（花萼宽度），单位是cm;\nPetal.Length（花瓣长度），单位是cm;\nPetal.Width（花瓣宽度），单位是cm;\nspecies (种类)：Iris Setosa（山鸢尾）、Iris Versicolour（杂色鸢尾），以及Iris Virginica（维吉尼亚鸢尾）。\n如表 11所示的iris部分数据集。\n表 11\n6.4\n2.8\n5.6\n2.2\n2\n5\n2.3\n3.3\n1\n1\n4.9\n2.5\n4.5\n1.7\n2\n4.9\n3.1\n1.5\n0.1\n0\n5.7\n3.8\n1.7\n0.3\n0\n4.4\n3.2\n1.3\n0.2\n0\n5.4\n3.4\n1.5\n0.4\n0\n6.9\n3.1\n5.1\n2.3\n2\n6.7\n3.1\n4.4\n1.4\n1\n5.1\n3.7\n1.5\n0.4\n0\n5.2\n2.7\n3.9\n1.4\n1\n6.9\n3.1\n4.9\n1.5\n1\n5.8\n4\n1.2\n0.2\n0\n5.4\n3.9\n1.7\n0.4\n0\n7.7\n3.8\n6.7\n2.2\n2\n6.3\n3.3\n4.7\n1.6\n1\n2. Neural Network\n2.1 Perform\nTensorFlow提供一个高水平的机器学习 API (tf.contrib.learn)，使得容易配置(configure)、训练(train)和评估(evaluate)各种机器学习模型。tf.contrib.learn库的使用可以概括为五个步骤，如下所示：\n1) Load CSVs containing Iris training/test data into a TensorFlow Dataset\n2) Construct a neural network classifier\n3) Fit the model using the training data\n4) Evaluate the accuracy of the model\n5)Classify new samples\n2.2 Code\n本节以对 Iris 数据集进行分类为例进行介绍，如下所示是完整的TensorFlow程序：\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport urllib\nimport numpy as np\nimport tensorflow as tf\n# Data sets\nIRIS_TRAINING = \"iris_training.csv\"\nIRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\nIRIS_TEST = \"iris_test.csv\"\nIRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\ndef main():\n# If the training and test sets aren't stored locally, download them.\nif not os.path.exists(IRIS_TRAINING):\nraw = urllib.urlopen(IRIS_TRAINING_URL).read()\nwith open(IRIS_TRAINING, \"w\") as f:\nf.write(raw)\nif not os.path.exists(IRIS_TEST):\nraw = urllib.urlopen(IRIS_TEST_URL).read()\nwith open(IRIS_TEST, \"w\") as f:\nf.write(raw)\n# Load datasets.\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TRAINING,\ntarget_dtype=np.int,\nfeatures_dtype=np.float32)\ntest_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TEST,\ntarget_dtype=np.int,\nfeatures_dtype=np.float32)\n# Specify that all features have real-value data\nfeature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n# Build 3 layer DNN with 10, 20, 10 units respectively.\nclassifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\nhidden_units=[10, 20, 10],\nn_classes=3,\nmodel_dir=\"/tmp/iris_model\")\n# Define the training inputs\ndef get_train_inputs():\nx = tf.constant(training_set.data)\ny = tf.constant(training_set.target)\nreturn x, y\n# Fit model.\nclassifier.fit(input_fn=get_train_inputs, steps=2000)\n# Define the test inputs\ndef get_test_inputs():\nx = tf.constant(test_set.data)\ny = tf.constant(test_set.target)\nreturn x, y\n# Evaluate accuracy.\naccuracy_score = classifier.evaluate(input_fn=get_test_inputs,\nsteps=1)[\"accuracy\"]\nprint(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n# Classify two new flower samples.\ndef new_samples():\nreturn np.array(\n[[6.4, 3.2, 4.5, 1.5],\n[5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\npredictions = list(classifier.predict(input_fn=new_samples))\nprint(\n\"New Samples, Class Predictions: {}\\n\"\n.format(predictions))\nif __name__ == \"__main__\":\nmain()\n3. Analysis\n3.1 Load data\n对于本文的程序，Iris数据集被分为两部分：\n训练集：有120个样例，保存在iris_training.csv文件中；\n测试集：有30个样例，保存在iris_test.csv文件中。\n1) import module\n首先程序引入必要module，然后定义了数据集的本地路径和网络路径；\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport urllib\nimport tensorflow as tf\nimport numpy as np\nIRIS_TRAINING = \"iris_training.csv\"\nIRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\nIRIS_TEST = \"iris_test.csv\"\nIRIS_TEST_URL = http://download.tensorflow.org/data/iris_test.csv\n2) Open File\n若本地路径上不存在数据集指定的文件，则通过网上下载。\nif not os.path.exists(IRIS_TRAINING):\nraw = urllib.urlopen(IRIS_TRAINING_URL).read()\nwith open(IRIS_TRAINING,'w') as f:\nf.write(raw)\nif not os.path.exists(IRIS_TEST):\nraw = urllib.urlopen(IRIS_TEST_URL).read()\nwith open(IRIS_TEST,'w') as f:\nf.write(raw)\n3) load Dataset\n接着将Iris数据集加载到TensorFlow框架中，使其TensorFlow能够直接使用。这其中使用了learn.datasets.base模块的load_csv_with_header()函数。该方法有三个参数:\nfilename：指定了CSV文件的名字；\ntarget_dtype：指定了数据集中目标数据类型，其为numpy datatype类型；\nfeatures_dtype：指定了数据集中特征向量的数据类型，其为numpy datatype类型。\n如表 11所示，Iris数据中的目标值为：0~2，所以可以定义为整型数据就可以了，即np.int，如下所示：\n# Load datasets.\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TRAINING,\ntarget_dtype=np.int,\nfeatures_dtype=np.float32)\ntest_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TEST,\ntarget_dtype=np.int,\nfeatures_dtype=np.float32)\n由于tf.contrib.learn中的数据类型（Datasets）是以元祖类型定义的，所以用户可以通过data 和 target两个域属性访问特征向量数据和目标数据。即training_set.data 和 training_set.target为训练数据集中的特征向量和目标数据。\n3.2 Construct Estimator\ntf.contrib.learn预定义了许多模型，称为：Estimators。用户以黑箱模型使用Estimator来训练和评估数据。本节使用tf.contrib.learn.DNNClassifier来训练数据，如下所示：\n# Specify that all features have real-value data\nfeature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n# Build 3 layer DNN with 10, 20, 10 units respectively.\nclassifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\nhidden_units=[10, 20, 10],\nn_classes=3,\nmodel_dir=\"/tmp/iris_model\")\n首先程序定义了模型的feature columns，其指定了数据集中特征向量的数据类型。每种类型都有一个名字，由于本节的数据是实数型，所以这里使用.real_valued_column类型。该类型第一个参数指定了列名字，第二个参数指定了列的数量。其中所有的特征类型都定义在：tensorflow/contrib/layers/python/layers/feature_column.py.\n然后程序创建了DNNClassifier模型，\nfeature_columns=feature_columns：指定所创建的特征向量类型；\nhidden_units=[10, 20, 10]：设置隐藏层的层数，并指定每层神经元的数据量；\nn_classes=3：指定目标类型的数量，Iris数据有三类，所以这里为3；\nmodel_dir=/tmp/iris_model：指定模型在训练期间保存的路径。\n3.3 Describe pipeline\nTensorFlow框架的数据都是以Tensor对象存在，即要么是constant、placeholder或Variable类型。通常训练数据是以placeholder类型定义，然后用户训练时，传递所有的数据。本节则将训练数据存储在constant类型中。如下所示：\n# Define the training inputs\ndef get_train_inputs():\nx = tf.constant(training_set.data)\ny = tf.constant(training_set.target)\nreturn x, y\n3.4 Fit DNNClassifier\n创建分类器后，就可以调用神经网络中DNNClassifier模型的fit()函数来训练模型了，如下所示：\n# Fit model.\nclassifier.fit(input_fn=get_train_inputs, steps=2000)\n通过向fit传递get_train_inputs函数返回的训练数据，并指定训练的步数为2000步。\n3.5 Evaluate Model\n训练模型后，就可以通过evaluate()函数来评估模型的泛化能力了。与fit函数类似，evaluate函数的输入数据也需为Tensor类型，所以定义了get_test_inputs()函数来转换数据。\n# Define the test inputs\ndef get_test_inputs():\nx = tf.constant(test_set.data)\ny = tf.constant(test_set.target)\nreturn x, y\n# Evaluate accuracy.\naccuracy_score = classifier.evaluate(input_fn=get_test_inputs, steps=1)[\"accuracy\"]\nprint(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n注意：\n由于evaluate函数的返回值是一个Map类型（即dict类型），所以直接根据\"accuracy\"键获取值：accuracy_score。\n3.6 Classify Samples\n在训练模型后，就可以使用estimator模型的predict()函数来预测样例。如表 31有所示的两个样例，希望预测其为什么类型。\n表 31\nSepal Length\nSepal Width\nPetal Length\nPetal Width\n6.4\n3.2\n4.5\n1.5\n5.8\n3.1\n5\n1.7\n如下所示的程序：\n# Classify two new flower samples.\ndef new_samples():\nreturn np.array(\n[[6.4, 3.2, 4.5, 1.5],\n[5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\npredictions = list(classifier.predict(input_fn=new_samples))\nprint(\n\"New Samples, Class Predictions: {}\\n\"\n.format(predictions))\n输出：\nNew Samples, Class Predictions: [1 2]\n注意：\n由于predict()函数执行的返回结果类型是generator。所以上述程序将其转换为一个list对象。\n4. Logging and Monitoring\n由于TensorFlow的机器学习Estimator是黑箱学习，用户无法了解模型执行发生了什么，以及模型什么时候收敛。所以tf.contrib.learn提供的一个Monitor API，可以帮助用户记录和评估模型。\n4.1 Default ValidationMonitor\n默认使用fit()函数训练Estimator模型时，TensorFlow会产生一些summary数据到fit()函数指定的路径中。用户可以使用Tensorborad来展示更详细的信息。如图 1所示，执行上述程序DNNClassifier的fit()和evaluate()函数后，默认在TensorBoard页面显示的常量信息。\n图 1\n4.2 Monitors\n为了让用户更直观地了解模型训练过程的细节，tf.contrib.learn提供了一些高级Monitors，使得用户在调用fit()函数时，可以使用Monitors来记录和跟踪模型的执行细节。如表 41所示是fitt()函数支持的Monitors类型：\n表 41\nMonitor\nDescription\nCaptureVariable\n每执行n步训练，就将保存指定的变量值到一个集合(collection)中\nPrintTensor\n每执行n步训练，记录指定的Tensor值\nSummarySaver\n每执行n步训练，使用tf.summary.FileWriter函数保存tf.Summary 缓存\nValidationMonitor\n每执行n步训练，记录一批评估metrics，同时可设置停止条件\n如\\tensorflow\\examples\\tutorials\\monitors\\ iris_monitors.py所示的程序：\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nimport os\nimport numpy as np\nimport tensorflow as tf\ntf.logging.set_verbosity(tf.logging.INFO)\n# Data sets\nIRIS_TRAINING = os.path.join(os.path.dirname(__file__), \"iris_training.csv\")\nIRIS_TEST = os.path.join(os.path.dirname(__file__), \"iris_test.csv\")\ndef main(unused_argv):\n# Load datasets.\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float)\ntest_set = tf.contrib.learn.datasets.base.load_csv_with_header(\nfilename=IRIS_TEST, target_dtype=np.int, features_dtype=np.float)\nvalidation_metrics = {\n\"accuracy\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_accuracy,\nprediction_key=\"classes\"),\n\"precision\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_precision,\nprediction_key=\"classes\"),\n\"recall\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_recall,\nprediction_key=\"classes\"),\n\"mean\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_mean,\nprediction_key=\"classes\")\n}\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\ntest_set.data,\ntest_set.target,\nevery_n_steps=50,\nmetrics=validation_metrics,\nearly_stopping_metric=\"loss\",\nearly_stopping_metric_minimize=True,\nearly_stopping_rounds=200)\n# Specify that all features have real-value data\nfeature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n# Build 3 layer DNN with 10, 20, 10 units respectively.\nclassifier = tf.contrib.learn.DNNClassifier(\nfeature_columns=feature_columns,\nhidden_units=[10, 20, 10],\nn_classes=3,\nmodel_dir=\"/tmp/iris_model\",\nconfig=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n# Fit model.\nclassifier.fit(x=training_set.data,\ny=training_set.target,\nsteps=2000,\nmonitors=[validation_monitor])\n# Evaluate accuracy.\naccuracy_score = classifier.evaluate(\nx=test_set.data, y=test_set.target)[\"accuracy\"]\nprint(\"Accuracy: {0:f}\".format(accuracy_score))\n# Classify two new flower samples.\nnew_samples = np.array(\n[[6.4, 3.2, 4.5, 1.5], [5.8, 3.1, 5.0, 1.7]], dtype=float)\ny = list(classifier.predict(new_samples))\nprint(\"Predictions: {}\".format(str(y)))\nif __name__ == \"__main__\":\ntf.app.run()\n4.3 Configuring ValidationMonitor\n如图 1所示，如果没有指定任何evaluation metrics，那么ValidationMonitor默认会记录loss和accuracy信息。但用户可以通过创建ValidationMonitor对象来自定义metrics信息。\n即通过向ValidationMonitor构造函数传递一个metrics参数，该参数是一个Map类型(dist)，其中的key是希望显示的名字，value是一个MetricSpec对象。\n其中tf.contrib.learn.MetricSpec类的构造函数有如下四个参数：\nmetric_fn：是一个函数，TensorFlow在tf.contrib.metrics模块中预定义了一些函数，用户可以直接使用；\nprediction_key：如果模型返回一个Tensor或与一个单一的入口，那么这个参数可以被忽略；\nlabel_key：可选\nweights_key：可选\n如下所示创建一个dist类型的对象：\nvalidation_metrics = {\n\"accuracy\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_accuracy,\nprediction_key=\"classes\"),\n\"precision\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_precision,\nprediction_key=\"classes\"),\n\"recall\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_recall,\nprediction_key=\"classes\"),\n\"mean\":\ntf.contrib.learn.MetricSpec(\nmetric_fn=tf.contrib.metrics.streaming_mean,\nprediction_key=\"classes\")\n}\nvalidation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\ntest_set.data,\ntest_set.target,\nevery_n_steps=50,\nmetrics=validation_metrics,\nearly_stopping_metric=\"loss\",\nearly_stopping_metric_minimize=True,\nearly_stopping_rounds=200)\n注意：Python中的dist可以直接以一对\"{}\"初始化元素，如上validation_metrics对象创建所示。\n5. 参考文献\n[1].TensorFlowà Develop à Get Started àtf.contrib.learn Quickstart；\n[2].TensorFlowà Develop à Get Started à Logging and Monitoring Basics with tf.contrib.learn；"}
