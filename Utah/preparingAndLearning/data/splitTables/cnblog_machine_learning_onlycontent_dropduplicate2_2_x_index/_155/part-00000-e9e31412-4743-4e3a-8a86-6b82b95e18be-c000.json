{"content2":"《机器学习》这本书算是很好的一本了解机器学习知识的一本入门书籍吧，是南京大学周志华老师所著的鸿篇大作，很早就听闻周老师大名了，算是国内机器学习领域少数的大牛了吧，刚好研究生做这个方向相关的内容，所以今天买了一本所谓的西瓜书，准备研读，光读书记性不好，边读边做笔记练习印象深刻，接下来我就把自己的学习过程按每章节的内容整理如下：\nDay1 第一章 绪论部分\n本书作者周志华老师通过聊天的口吻开篇，以日常生活的小案例和场景，向读者介绍什么是机器学习，以及什么是学习算法。在这一章介绍了很多机器学习相关的术语概念。\n首先，要做学习，先得有数据，我们要学习的对象记录收集起来组成的集合叫做一个“数据集（data set）”，把里面记录、对象的描述，称为一个“示例（instance）”或者“样本（sample）”，反应集合内事件或对象在某方面的表现或性质的事项，我们把它称为“属性（attribute）”或“特征（feature）”，属性张成的空间称为“属性空间（attribute space）”、 “样本空间（sample space）” 或者“输入空间”，由于空间中的每一个点对应一个坐标向量，因此我们把一个示例称为一个“特征向量（feature vector）”，这里的属性数量就是我们说的样本的“维数（dimensionality）”\n上面得到了数据了，我们要从数据中学得模型的过程叫“学习（learning）”或者“训练（training）”，在这个过程执行某个学习算法来完成，训练的过程使用的数据称为“训练数据（集）（training data）”，这其中的每一个小样本叫一个“训练样本（training sample）”，训练样本构成的集合组成的集合叫做“训练集training set”，训练得到的模型对应数据的某种潜在的规律，把这种结果称为“假设（hypothesis）”，我们要用学习的结果来“预测（prediction）”，用学得模型进行预测的过程称为“测试（testing）”，被预测的样本叫“测试样本（testing sample）”。\n我们要预测的是离散值，这类学习任务称为“分类（classification）”，要预测的是连续值，把这类学习任务称为“回归（regression）”，当然我们也可以对数据做“聚类（clustering）”，即把训练集中的对象分成若干组，每个组称为一个“簇（cluster）”。\n我们根据训练数据是否拥有标记信息，学习任务可大致分为两大类：“监督学习（supervised learning）”和“无监督学习（unsupervised learning）”，分类和回归是前者的代表，聚类是后者的代表。\n学得的模型适用于新样本的能力，称为“泛化（generation）”。\n通常，我们假设样本空间中全体样本服从一个未知“分布（distribution）”，我们获得的每一个样本都是独立从这分布上采样得到的，即“独立同分布（independent and identically distributed简称i.i.d.）”。\n归纳（induction）和演绎（deduction）是科学推理的两大基本手段，前者是从特殊到一般的“泛化（generation）”过程，后者是一般到特殊的“特化（specialization）”过程，如数学上由数学公理推出与之相洽的定理，这是演绎过程，而“从样本中学习”是一个归纳过程，叫做“归纳学习（inductive learning）”。\n归纳学习中有归纳偏好，这里遵循奥卡姆剃刀原则。\n发展历程：机器学习是人工智能（artificial intelligence）研究发展到一定阶段的必然产物。二十世纪五十年代到七十年代，人工智能研究处于“推理期”，那时的人们认为只要能赋予机器逻辑推理能力，机器就能拥有智能。二十世纪七十年代中期开始，人工智能研究进入“知识期”，这一时期大量的专家系统问世。二十世纪八十年代是机器学习成为一个独立的学科领域，各种机器学习技术百花初绽的时期。二十世纪九十年代中期，“统计学习（statistical learning）”闪亮登场并迅速占据主流舞台，代表技术是支持向量机（Support Vector Machine，简称SVM）以及更一般的“核方法（kernel methods）”。二十一世纪初，连接主义学习又卷土从来（五十年代中后期基于神经网络的“连接主义”），掀起了以“深度学习”为名的热潮，所谓深度学习，狭义地说就是“很多层”的神经网络\n现在，机器学习已经发展成为一个相当大的学科领域，当今算力的提升和大数据的加持，逐步把机器学习推向高潮。\n（第一章笔记到此，继续学习后续章节）"}
