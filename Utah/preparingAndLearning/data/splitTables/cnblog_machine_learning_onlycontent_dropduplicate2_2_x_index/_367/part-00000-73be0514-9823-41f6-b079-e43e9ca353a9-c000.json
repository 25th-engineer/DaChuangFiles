{"content2":"前段时间的“人机大战”——谷歌的Alpha Go战胜人类棋手的新闻甚嚣尘上，不禁有人会想起1997年IBM自主研发的深蓝战胜卡斯帕罗夫的事件。“人工智能”这个词再次被推上风口浪尖，而“认知计算”却鲜有人听说，同样是人类模拟机器思索，让机器具有自主思考能力，都是具有跨时代意义和里程碑式的存在。\n认知计算更加强调机器或人造大脑如何能够主动学习、推理、感知这个世界，并与人类、环境进行交互的反应。它会根据环境的变化做出动态的反应，所以认知更加强调它的动态性、自适应性、鲁棒性、交互性。\n计算机在体系架构上的发展历史主要体现在两个方面：\n计算能力的增强\n计算规模的增大\n随着计算机计算能力的大幅增强，具备了处理海量数据的能力；另一方面，日常生活中所产生的数据规模日益扩大，所拥有的数据源驱动了深层次分析的需求；同时大数据、云计算技术的不断完善，都促进了对数据进行深度挖掘，提取数据的特征，利用特征让机器具有自主学习与思考的能力。\n按照计算方式的不同，可以分为三个计算时代：\n1990s~1940s  打卡阶段（The Tabulating Era）       机械式\n1950s~现在     编程阶段（The Programming Era）   自主输入\n2011~将来      认知计算阶段（The Cognitive Era）    自动思考\n“大脑”项目：Think & Learn\n2006     IBM        Watson      利用自然语言分析，让机器自动推理事件与回答问题；涵盖医疗、数据分析、“危险游戏”等。\n2011     Google    谷歌大脑     通过神经网络，能够让更多的用户拥有完美的、没有错误的使用体验；谷歌无人驾驶汽车、谷歌眼镜等。\n2012     Baidu      百度大脑     融合深度学习算法、数据建模、大规模GPU并行化平台等技术，构造起深度神经网络。\n一、认知计算的概念：\n人工智能与认知计算的区别：\n人工，以人为主导；认知，机器对事物与外界的理解，交互的能力\n编程能力；学习与推理的能力\n确定性结果；概率性结果\n人并未参与；人、机器、环境之间的交互\n图灵测试或仿造人测量；实际应用中的测试\n2.  认知计算所涉及的技术领域：\n神经科学：机器模拟人脑神经元的思考过程；\n超计算：超级快速计算和处理能力；\n纳米技术：芯片、系统等底层架构设计。\n3. 认知计算系统的组成：\n需要一个能够理解、学习、推理的“大脑”，一个物物相连的外部环境，大脑与环境之间互相感知与交互。\n4.  认知计算的应用：\n典型系统特征：大规模、复杂、人与外界交互、大量非结构化数据、输出结果不定的系统；\n生命科学领域：医疗、保险；\n社会机构领域：金融银行、政府、能源、教育、商业、交通等。\n5.  案例：Watson-历史上第一个认知系统\n自然语言处理\n问答技术\n高性能计算\n知识的表达和推理\n机器学习\n非结构化信息管理\n6.  认知系统的五个核心功能：\n创造更深的人工参与\n测量和提升专业知识\n认知融入产品和服务\n实现认知过程和操作\n加强探索和发现\n7.  认知计算系统的挑战与要求：\n8.  认知计算系统的架构：\n底层架构：芯片设计（GPU、FPGA、ASIC、POWER8）\n基础设施：云环境、超级计算节点\n组织构架：caffe、Theano、Torch等\n库文件：数据库、工具、包等\n应用层：信息采集的有效性、人机交互界面、搜索引擎等\n二、人工智能的概述：\n人的大脑科学&计算机科学——>可视化、心理学、神经元组成、深度学习\n1. 人工智能发展过程：\n重要的时间节点与人物：\n1950-1956：两个重要的人物，诺伯特·维纳（控制论）和克劳德·艾尔伍德·香农（信息论）将事物从更高的层次进行抽象，奠定了AI坚实的理论基础；\n1950：图灵，提出了图灵测试的基本测试方法；\n1956：达特茅斯会议第一次正式提出AI的概念；\n1956-1974：AI得到极大发展，提出了许多新的理论，包括自然语言处理、reasoning as search、micro-worlds等；\n1974-1980：由于发展迅速所带来的副作用日益凸显，关于机器代替人类的社会、伦理等问题、投资人看不到长期受益问题等导致其发展陷入低谷；\n1980-1987：在日本的第五代项目提出，结合AI来发展现代工业生产，又给AI界打了一针强心剂（专家系统）；\n1987-1993：计算机的高速发展，给传统硬件组成的研究系统带来巨大挑战，更多的人将注意力放在计算能力更强、价格更为便宜的普通计算机上；\n1995：Sparse coding，将计算机科学理论与生物神经科学理论相结合；\n2006：Deep Learning，含多隐层的多层感知器的深度学习结构；\n2007：GPU CUDA，CPU与GPU并用的“协同处理”发展的统一计算设备架构；\n2011：Google Brain，谷歌在人工智能领域开发出的一款模拟人脑的软件。\n2. 机器学习的概述：\n机器学习两种传统分类：\n监督学习：已知label来对事物进行分类；\n无监督学习：未知label来学习事物特征。\n应用领域：图像识别、计算机视觉、语音识别、生物监控、机器人控制、经验科学、智能医疗等。\n机器学习的流程图（有监督学习）：\n分类算法（Classification）：\n支持向量机（SVM）\n神经网络（Neural Network）\n朴素贝叶斯（Naiive Bayes）\n贝叶斯网络（Bayesian network）\n逻辑回归（Logistic regression）\n随机森林（Randomized Forests）\n决策树（Boosted Decision Trees）\nk近邻（K-nearest neighbor）\nRBMs\n聚类算法（Clustering）：\nK-means\n合并聚类（agglomerative clustering）\n均值漂移聚类（mean shift clustering）\n谱聚类（spectral clustering）\n泛化问题（Generalization）：过拟合、欠拟合\n3. 深度学习的概述：\n深度学习是机器学习的一个分支，通过利用多层处理的复杂结构，基于一系列的算法来建立高维抽象的模型。其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。深度学习的概念由Hinton等人于2006年提出。基于深度置信网络(DBN)提出非监督贪心逐层训练算法，为解决深层结构相关的优化难题带来希望，随后提出多层自动编码器深层结构。此外Lecun等人提出的卷积神经网络（CNN）是第一个真正多层结构学习算法，它利用空间相对关系减少参数数目以提高训练性能。\n典型的深度学习：卷积神经网络CNN\n实验已经证明，CNN在图像和语音处理中能够取得比传统方法更好的识别效果，也产生了许多著名的深度学习网络VGG-Net、AlexNet等。\nVGG-Net与AlexNet的对比分析：\n深度学习网络\nAlexNet\nVGG-Net\n产生背景\n2012年，deep learning的大牛教授 Geoffrey Hinton的学生Alex Krizhevsky设计了一个8层的CNN，并把它用于ImageNet的image classification，直接把当时最好算法的错误率差不多减半。\nAndrew Zisserman 教授的组 (Oxford)，VGG-Net 在2014年的 ILSVRC localization and classification 两个问题上分别取得了第一名和第二名。\n结构层次\n总共有8层，由5层 convolutional layer，2层 fully connected layer，和最后一层 label layer (1000个node, 每个node代表ImageNet中的一个类别) 组成。\nVGG-Net使用更多的层，通常有16－19层，所有 convolutional layer 使用同样大小的 convolutional filter。\n结构示意\n特征描述\n中间层描述了图片的局部特征，全连接层表示了图像的全局特征。\n业界牛人：\n开发架构：\n机器学习的常用库和数据集："}
