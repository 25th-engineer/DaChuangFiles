{"content2":"从2016年年初，开始用python写一个简单的爬虫，帮我收集一些数据。\n6月份，开始学习Machine Learning的相关知识。\n9月开始学习Spark和Scala。\n现在想，整理一下思路。\n先感谢下我的好友王峰给我的一些建议。他在Spark和Scala上有一些经验，让我前进的速度加快了一些。\n学习算法\n作为一个程序猿，以前多次尝试看过一些机器学习方面的书，其过程可以说是步履阑珊，碰到的阻力很大。\n主要原因是，读这些机器学习的书，需要有一些数学方面的背景。\n问题就在这些数学背景上，这些背景不仅仅是数学技巧，也有一些共识。对于缺乏这些背景的我，即使一个简单的公式，也有时会感到困惑。\n如果你像我一样是一个程序猿，我建议读Peter Harrington写的Machine Learning in Action （中文书名是《机器学习实战》）。\n这本书是以开发者的知识背景来写的，并且提供的python代码可以下载，方便开发人员理解。\n我写了一些博文，主要作用是帮助我理解学习的算法。大部分写的不好，后来我自己都看不懂。以后慢慢修正一下。\n机器学习实战 - 读书笔记(03) - 决策树\n机器学习实战 - 读书笔记(04) - 朴素贝叶斯\n机器学习实战 - 读书笔记(05) - Logistic回归\n机器学习实战 - 读书笔记(06) – SVM支持向量机\n机器学习实战 - 读书笔记(07) - 利用AdaBoost元算法提高分类性能\n机器学习实战 - 读书笔记(08) - 预测数值型数据：回归\n机器学习实战 - 读书笔记(10) - 利用Ｋ-均值聚类算法对未标注数据分组\n机器学习实战 - 读书笔记(11) - 使用Apriori算法进行关联分析\n机器学习实战 - 读书笔记(12) - 使用FP-growth算法来高效发现频繁项集\n机器学习实战 - 读书笔记(13) - 利用PCA来简化数据\n机器学习实战 - 读书笔记(14) - 利用SVD简化数据\n学习算法的Level\nLevel 1： 了解如何使用算法\nLevel 2： 了解算法的正确使用场景\n正确的使用一个算法，需要经验和对算法理论的了解。\n我以前有些这方面的经验，很多错误在于不正确地使用了算法。\n当我们编程序给别人用时：\n需要理解算法\n最低要求，也要有一些基本的统计知识。\n需要实现算法\n实现算法一般比较简单，需要注意性能和精度。\n基本上这部分在实现好后，比较稳定。\n需要实现将用户数据应用到算法上的过程。\n这是程序员主要干的工作，接口、性能上的考虑很多。\n需要理解用户的使用场景。\n这部分价值很大。\n一方面，写单元测试是不可避免的，理解用户的场景才能写出有效的单元测试程序。\n另外，会有很多处理客户问题的工作，也是长经验的机会。\nLevel 3： 了解算法的后面的数学理论\n有人觉得这个用处不大。我觉得了解数学理论，可以：\n成为真正的行家\n未来的路还很远，怎么能戛然而止!\n使用算法来帮助自己的一些事情，或者实现一个新的算法。\n现在人工智能的潜力很大，可以自己好好玩玩。\n学习python\n在数据量不大的情况下（几个G），单机上就可以很好跑机器学习的程序。\n这时，Python的用途就很大，不仅有已经实现好的算法，也可以实现爬虫，从网上获取数据。\n学习Scala和函数式编程\n对于大数据处理来说，Spark和Scala结合是现在的大趋势。\n我写的博文有：\n学习Scala： 初学者应该了解的知识\n函数式编程 : 一个程序猿进化的故事\nScala underscore的用途\n不变(Invariant), 协变(Covarinat), 逆变(Contravariant) : 一个程序猿进化的故事\nScala Collection简介\nScala on Visual Studio Code\n学习Spark架构\n我写的博文有：\nSpark集群 + Akka + Kafka + Scala 开发(1) : 配置开发环境\nSpark集群 + Akka + Kafka + Scala 开发(2) : 开发一个Spark应用\nSpark集群 + Akka + Kafka + Scala 开发(3) : 开发一个Akka + Spark的应用\nSpark集群 + Akka + Kafka + Scala 开发(4) : 开发一个Kafka + Spark的应用\n学习在Spark上的机器学习项目开发经验\n学习更多的算法\n蒙特卡洛树算法\n成为Spark的Contributer\n成为Spark的Contributer是件很cool的事。\n可以读读Spark的代码，从中应该可以增长不少。\n然后，尝试修一些Spark的Bugs。\n深度学习\n路还很长。"}
