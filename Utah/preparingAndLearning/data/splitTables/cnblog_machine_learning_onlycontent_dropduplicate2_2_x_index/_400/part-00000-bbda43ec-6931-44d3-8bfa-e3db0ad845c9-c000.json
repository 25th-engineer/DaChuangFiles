{"content2":"原文：http://blog.csdn.net/heyongluoyao8/article/details/47840255\n常见的机器学习&数据挖掘知识点\n转载请说明出处\nBasis(基础)：\nSSE(Sum of Squared Error, 平方误差和)\nSAE(Sum of Absolute Error, 绝对误差和)\nSRE(Sum of Relative Error, 相对误差和)\nMSE(Mean Squared Error, 均方误差)\nRMSE(Root Mean Squared Error, 均方根误差)\nRRSE(Root Relative Squared Error, 相对平方根误差)\nMAE(Mean Absolute Error, 平均绝对误差)\nRAE(Root Absolute Error, 平均绝对误差平方根)\nMRSE(Mean Relative Square Error, 相对平均误差)\nRRSE(Root Relative Squared Error, 相对平方根误差)\nExpectation(期望)&Variance(方差)\nStandard Deviation(标准差，也称Root Mean Squared Error, 均方根误差)\nCP(Conditional Probability, 条件概率)\nJP(Joint Probability, 联合概率)\nMP(Marginal Probability, 边缘概率)\nBayesian Formula(贝叶斯公式)\nCC(Correlation Coefficient, 相关系数)\nQuantile (分位数)\nCovariance(协方差矩阵)\nGD(Gradient Descent, 梯度下降)\nSGD(Stochastic Gradient Descent, 随机梯度下降)\nLMS(Least Mean Squared, 最小均方)\nLSM(Least Square Methods, 最小二乘法)\nNE(Normal Equation, 正规方程)\nMLE(Maximum Likelihood Estimation, 极大似然估计)\nQP(Quadratic Programming, 二次规划)\nL1 /L2 Regularization(L1/L2正则, 以及更多的, 现在比较火的L2.5正则等)\nEigenvalue(特征值)\nEigenvector(特征向量)\nCommon Distribution(常见分布)：\nDiscrete Distribution(离散型分布)：\nBernoulli Distribution/Binomial Distribution(贝努利分布/二项分布)\nNegative Binomial Distribution(负二项分布)\nMultinomial Distribution(多项分布)\nGeometric Distribution(几何分布)\nHypergeometric Distribution(超几何分布)\nPoisson Distribution (泊松分布)\nContinuous Distribution (连续型分布)：\nUniform Distribution(均匀分布)\nNormal Distribution/Gaussian Distribution(正态分布/高斯分布)\nExponential Distribution(指数分布)\nLognormal Distribution(对数正态分布)\nGamma Distribution(Gamma分布)\nBeta Distribution(Beta分布)\nDirichlet Distribution(狄利克雷分布)\nRayleigh Distribution(瑞利分布)\nCauchy Distribution(柯西分布)\nWeibull Distribution (韦伯分布)\nThree Sampling Distribution(三大抽样分布)：\nChi-square Distribution(卡方分布)\nt-distribution(t-分布)\nF-distribution(F-分布)\nData Pre-processing(数据预处理)：\nMissing Value Imputation(缺失值填充)\nDiscretization(离散化)\nMapping(映射)\nNormalization(归一化/标准化)\nSampling(采样)：\nSimple Random Sampling(简单随机采样)\nOffline Sampling(离线等可能K采样)\nOnline Sampling(在线等可能K采样)\nRatio-based Sampling(等比例随机采样)\nAcceptance-rejection Sampling(接受-拒绝采样)\nImportance Sampling(重要性采样)\nMCMC(Markov Chain MonteCarlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting& Gibbs)\nClustering(聚类)：\nK-MeansK-Mediods\n二分K-Means\nFK-Means\nCanopy\nSpectral-KMeans(谱聚类)\nGMM-EM(混合高斯模型-期望最大化算法解决)\nK-Pototypes\nCLARANS(基于划分)\nBIRCH(基于层次)\nCURE(基于层次)\nSTING(基于网格)\nCLIQUE(基于密度和基于网格)\n2014年Science上的密度聚类算法等\nClustering Effectiveness Evaluation(聚类效果评估)：\nPurity(纯度)\nRI(Rand Index, 芮氏指标)\nARI(Adjusted Rand Index, 调整的芮氏指标)\nNMI(Normalized Mutual Information, 规范化互信息)\nF-meaure(F测量)\nClassification&Regression(分类&回归)：\nLR(Linear Regression, 线性回归)\nLR(Logistic Regression, 逻辑回归)\nSR(Softmax Regression, 多分类逻辑回归)\nGLM(Generalized Linear Model, 广义线性模型)\nRR(Ridge Regression, 岭回归/L2正则最小二乘回归)，LASSO(Least Absolute Shrinkage and Selectionator Operator , L1正则最小二乘回归)\nDT(Decision Tree决策树)\nRF(Random Forest, 随机森林)\nGBDT(Gradient Boosting Decision Tree, 梯度下降决策树)\nCART(Classification And Regression Tree 分类回归树)\nKNN(K-Nearest Neighbor, K近邻)\nSVM(Support Vector Machine, 支持向量机, 包括SVC(分类)&SVR(回归))\nCBA(Classification based on Association Rule, 基于关联规则的分类)\nKF(Kernel Function, 核函数)\nPolynomial Kernel Function(多项式核函数)\nGuassian Kernel Function(高斯核函数)\nRadial Basis Function(RBF径向基函数)\nString Kernel Function 字符串核函数\nNB(Naive Bayesian,朴素贝叶斯)\nBN(Bayesian Network/Bayesian Belief Network/Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)\nLDA(Linear Discriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别)\nEL(Ensemble Learning, 集成学习)\nBoosting\nBagging\nStacking\nAdaBoost(Adaptive Boosting 自适应增强)\nMEM(Maximum Entropy Model, 最大熵模型)\nClassification EffectivenessEvaluation(分类效果评估)：\nConfusion Matrix(混淆矩阵)\nPrecision(精确度)\nRecall(召回率)\nAccuracy(准确率)\nF-score(F得分)\nROC Curve(ROC曲线)\nAUC(AUC面积)\nLift Curve(Lift曲线)\nKS Curve(KS曲线)\nPGM(Probabilistic Graphical Models, 概率图模型)：\nBN(BayesianNetwork/Bayesian Belief Network/ Belief Network , 贝叶斯网络/贝叶斯信度网络/信念网络)\nMC(Markov Chain, 马尔科夫链)\nMEM(Maximum Entropy Model, 最大熵模型)\nHMM(Hidden Markov Model, 马尔科夫模型)\nMEMM(Maximum Entropy Markov Model, 最大熵马尔科夫模型)\nCRF(Conditional Random Field,条件随机场)\nMRF(Markov Random Field, 马尔科夫随机场)\nViterbi(维特比算法)\nNN(Neural Network, 神经网络)\nANN(Artificial Neural Network, 人工神经网络)\nSNN(Static Neural Network, 静态神经网络)\nBP(Error Back Propagation, 误差反向传播)\nHN(Hopfield Network)\nDNN(Dynamic Neural Network, 动态神经网络)\nRNN(Recurrent Neural Network, 循环神经网络)\nSRN(Simple Recurrent Network, 简单的循环神经网络)\nESN(Echo State Network, 回声状态网络)\nLSTM(Long Short Term Memory, 长短记忆神经网络)\nCW-RNN(Clockwork-Recurrent Neural Network, 时钟驱动循环神经网络, 2014ICML）等.\nDeep Learning(深度学习)：\nAuto-encoder(自动编码器)\nSAE(Stacked Auto-encoders堆叠自动编码器)\nSparse Auto-encoders(稀疏自动编码器)\nDenoising Auto-encoders(去噪自动编码器)\nContractive Auto-encoders(收缩自动编码器)\nRBM(Restricted Boltzmann Machine, 受限玻尔兹曼机)\nDBN(Deep Belief Network, 深度信念网络)\nCNN(Convolutional Neural Network, 卷积神经网络)\nWord2Vec(词向量学习模型)\nDimensionality Reduction(降维)：\nLDA(Linear Discriminant Analysis/Fisher Linear Discriminant, 线性判别分析/Fish线性判别)\nPCA(Principal Component Analysis, 主成分分析)\nICA(Independent Component Analysis, 独立成分分析)\nSVD(Singular Value Decomposition 奇异值分解)\nFA(Factor Analysis 因子分析法)\nText Mining(文本挖掘)：\nVSM(Vector Space Model, 向量空间模型)\nWord2Vec(词向量学习模型)\nTF(Term Frequency, 词频)\nTF-IDF(TermFrequency-Inverse Document Frequency, 词频-逆向文档频率)\nMI(Mutual Information, 互信息)\nECE(Expected Cross Entropy, 期望交叉熵)\nQEMI(二次信息熵)\nIG(Information Gain, 信息增益)\nIGR(Information Gain Ratio, 信息增益率)\nGini(基尼系数)\nx2 Statistic(x2统计量)\nTEW(Text Evidence Weight, 文本证据权)\nOR(Odds Ratio, 优势率)\nN-Gram Model\nLSA(Latent Semantic Analysis, 潜在语义分析)\nPLSA(Probabilistic Latent Semantic Analysis, 基于概率的潜在语义分析)\nLDA(Latent Dirichlet Allocation, 潜在狄利克雷模型)\nSLM(Statistical Language Model, 统计语言模型)\nNPLM(Neural Probabilistic Language Model, 神经概率语言模型)\nCBOW(Continuous Bag of Words Model, 连续词袋模型)\nSkip-gram(Skip-gram Model)\nAssociation Mining(关联挖掘)：\nApriori算法\nFP-growth(Frequency Pattern Tree Growth, 频繁模式树生长算法)\nMSApriori(Multi Support-based Apriori, 基于多支持度的Apriori算法)\nGSpan(Graph-based Substructure Pattern Mining, 频繁子图挖掘)\nSequential Patterns Analysis(序列模式分析)\nAprioriAll\nSpade\nGSP(Generalized Sequential Patterns, 广义序列模式)\nPrefixSpan\nForecast(预测)\nLR(Linear Regression, 线性回归)\nSVR(Support Vector Regression, 支持向量机回归)\nARIMA(Autoregressive Integrated Moving Average Model, 自回归积分滑动平均模型)\nGM(Gray Model, 灰色模型)\nBPNN(BP Neural Network, 反向传播神经网络)\nSRN(Simple Recurrent Network, 简单循环神经网络)\nLSTM(Long Short Term Memory, 长短记忆神经网络)\nCW-RNN(Clockwork Recurrent Neural Network, 时钟驱动循环神经网络)\n……\nLinked Analysis(链接分析)\nHITS(Hyperlink-Induced Topic Search, 基于超链接的主题检索算法)\nPageRank(网页排名)\nRecommendation Engine(推荐引擎)：\nSVD\nSlope One\nDBR(Demographic-based Recommendation, 基于人口统计学的推荐)\nCBR(Context-based Recommendation, 基于内容的推荐)\nCF(Collaborative Filtering, 协同过滤)\nUCF(User-based Collaborative Filtering Recommendation, 基于用户的协同过滤推荐)\nICF(Item-based Collaborative Filtering Recommendation, 基于项目的协同过滤推荐)\nSimilarity Measure&Distance Measure(相似性与距离度量)：\nEuclideanDistance(欧式距离)\nChebyshev Distance(切比雪夫距离)\nMinkowski Distance(闵可夫斯基距离)\nStandardized EuclideanDistance(标准化欧氏距离)\nMahalanobis Distance(马氏距离)\nCos(Cosine, 余弦)\nHamming Distance/Edit Distance(汉明距离/编辑距离)\nJaccard Distance(杰卡德距离)\nCorrelation Coefficient Distance(相关系数距离)\nInformation Entropy(信息熵)\nKL(Kullback-Leibler Divergence, KL散度/Relative Entropy, 相对熵)\nOptimization(最优化)：\nNon-constrained Optimization(无约束优化)：\nCyclic Variable Methods(变量轮换法)\nVariable Simplex Methods(可变单纯形法)\nNewton Methods(牛顿法)\nQuasi-Newton Methods(拟牛顿法)\nConjugate Gradient Methods(共轭梯度法)。\nConstrained Optimization(有约束优化)：\nApproximation Programming Methods(近似规划法)\nPenalty Function Methods(罚函数法)\nMultiplier Methods(乘子法)。\nHeuristic Algorithm(启发式算法)\nSA(Simulated Annealing, 模拟退火算法)\nGA(Genetic Algorithm, 遗传算法)\nACO(Ant Colony Optimization, 蚁群算法)\nFeature Selection(特征选择)：\nMutual Information(互信息)\nDocument Frequence(文档频率)\nInformation Gain(信息增益)\nChi-squared Test(卡方检验)\nGini(基尼系数)\nOutlier Detection(异常点检测)：\nStatistic-based(基于统计)\nDensity-based(基于密度)\nClustering-based(基于聚类)。\nLearning to Rank(基于学习的排序)：\nPointwise\nMcRank\nPairwise\nRankingSVM\nRankNet\nFrank\nRankBoost；\nListwise\nAdaRank\nSoftRank\nLamdaMART\nTool(工具)：\nMPI\nHadoop生态圈\nSpark\nIGraph\nBSP\nWeka\nMahout\nScikit-learn\nPyBrain\nTheano\n…\n以及一些具体的业务场景与case…"}
