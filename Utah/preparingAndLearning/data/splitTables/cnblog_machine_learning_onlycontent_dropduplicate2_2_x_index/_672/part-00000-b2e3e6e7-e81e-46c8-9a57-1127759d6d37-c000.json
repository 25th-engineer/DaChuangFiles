{"content2":"机器学习：需要从已知的数据 学习出需要的模型\n在线算法：需要及时处理收集的数据，并给出预测或建议结果，并更新模型\n通用的在线学习算法步骤如下：\n1. 收集和学习现有的数据\n2. 依据模型或规则，做出决策，给出结果\n3. 根据真实的结果，来训练和学习规则或模型\n常用的在线学习算法：\nPerception: 感知器\nPA: passive perception\nPA-I\nPA-II\nVoted Perception\nconfidence-weighted linear linear classification: 基于置信度加权的线性分类器\nWeight Majority algorithm\nAROW：adaptive regularization of weighted vector 加权向量的自适应正则化\n\"NHERD\"：Normal Herd 正态\n这里收集了一些算法伪代码，代码然后配上语言描述，就清晰多了。\n感知器Perception：\n线性分类器，是一个利用超平面来进行二分类的分类器，每次利用新的数据实例，预测，比对，更新，来调整超平面的位置。\n相对于SVM，感知器不要每类数据与分类面的间隔最大化。\n平均感知器Average Perception：\n线性分类器，其学习的过程，与Perception感知器的基本相同，只不过，它将所有的训练过程中的权值都保留下来，然后，求均值。\n优点：克服由于学习速率过大，所引起的训练过程中出现的震荡现象。即超平面围着一个中心，忽左忽右之类...\nPassive Aggressive Perception:\n修正权值时，增加了一个参数Tt，预测正确时，不需要调整权值，预测错误时，主动调整权值。并可以加入松弛变量的概念，形成其算法的变种。\n优点：能减少错误分类的数目，而且适用于不可分的噪声情况。\nTt 有三种计算方法：\na. Tt =  lt / (||Xt||^2)\nb. Tt =  min{C, lt / ||Xt||^2}\nc.  Tt =  lt / (||Xt||^2 + 1/(2C))\n分别对应PA, PA-I, PA-II 算法，三种类型。\nVoted Perception:\n存储和使用所有的错误的预测向量。\n优点：实现对高维数据的分类，克服训练过程中的震荡，训练时间比SVM要好。\n缺点：不能保证收敛\nConfidence Weight：\n线性分类器\n每个学习参数都有个信任度（概率），信任度小的参数更应该学习，所以会得到更频繁的修改机会。信任度，用参数向量的高斯分布表示。\n权值w符合高斯分布N(u, 离差阵)，而 由w*x的结果，可以预测其分类的结果。\n并对高斯分布（的参数）进行更新。\n这种方法能提供分类的准确性，并加快学习速度。其理论依据在在于算法正确的预测概率不小于高斯分布的一个值。\nAROW： adaptive regularition of weighted vector\n具有的属性：大间隔训练large margin training，置信度权值confidence weight，处理不可分数据（噪声）non-separable\n相对于SOP(second of perception)，PA, CW, 在噪声情况下，其效果会更好.\nNormal herding：\n线性分类器\nNHerd算法在计算全协方差阵和对角协方差阵时，比AROW更加的积极。\n\nWeight Majority:\n每个维度都可以作为一个分类器，进行预测；然后，依据权值，综合所有结果，给出一个最终的预测。\n依据最终的预测和实际测量结果，调整各个维度的权值，即更新模型。\n易于实施，错误界比较小，可推导。\n\nVoted Perception:\n存储和使用所有的错误的预测向量。\n优点：实现对高维数据的分类，克服训练过程中的震荡，训练时间比SVM要好。\n缺点：不能保证收敛"}
