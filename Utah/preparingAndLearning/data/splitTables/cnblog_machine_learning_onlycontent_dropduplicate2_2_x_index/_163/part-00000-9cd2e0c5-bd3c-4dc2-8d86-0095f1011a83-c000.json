{"content2":"【主页】 apachecn.org\n【Github】@ApacheCN\n暂时下线: 社区\n暂时下线: cwiki 知识库\n自媒体平台\n微博：@ApacheCN\n知乎：@ApacheCN\nCSDN\n简书\nOSChina\n博客园\n我们不是 Apache 的官方组织/机构/团体，只是 Apache 技术栈（以及 AI）的爱好者！\n合作or侵权，请联系【fonttian】fonttian@gmail.com | 请抄送一份到 apachecn@163.com\n预处理\n离散化\n等值分箱\n等量分箱\n独热 one-hot\n标准化\n最小最大 min-max\nz-score\nl2 标准化\n归一化\n特征选择\nANOVA\n信息增益/信息增益率\n模型验证\n评价指标\n回归\nMSE\nR 方\n分类\n准确率\n精确率\n召回率\nF1 得分\n宏平均 F1\n微平均 F1\n聚类\n互信息\n轮廓距离\n交叉验证\nK 折\n网格搜索\n最优化方法\n梯度下降\n随机梯度下降 SGD\n牛顿法/拟牛顿法\n动量法\nRMSProp\nAdam\n传统机器学习\n基本概念\n欠拟合/过拟合\n距离\n汉明距离\n曼哈顿距离\n欧几里得距离\n切比雪夫距离\n余弦相似度\npearson 相似度\n损失函数\nMSE\n交叉熵\nHinge\n线性模型\n线性回归\nLasso/岭回归\n正则化\n逻辑回归\nsoftmax 回归\n支持向量机\n拉格朗日对偶\n软边界支持向量机\n核方法\n树和森林\n决策树\n随机森林\nGDBT/XGBoost\nLightGBM\n集成学习\nBagging\nBoosting\nAdaboost\nBlending/Stacking\nKNN\n聚类\nKMenas\n层次聚类\n凝聚聚类\n分裂聚类\nDBSCAN\n谱聚类\n高斯混合模型 GMM\n概率图\n朴素贝叶斯\n隐马尔科夫 HMM\n降维\nPCA/SVD\nT-SNE\n深度学习\n基本概念\n正向传播\n反向传播\n激活函数\nsigmoid\nsoftmax\ntanh\nReLU\nELU\nLeaky ReLU\n丢弃 Dropout\n微调 Fine-Tune\n批量归一化 BatchNorm\n前馈神经网络 DNN/多层感知机 MLP\n输入层\n隐层\n输出层\n卷积神经网络 CNN\n层\n卷积层\n池化层\n全连接层\n经典结构\nLeNet\nAlexNet\nZFNet\nGoogLeNet\nVGG\nResNet\nDenseNet\n循环神经网络 RNN\n循环层\n经典结构\nLSTM\nGRU\nBiLSTM\n注意力\nSeq2Seq\n自编码器\n栈式自编码器\n稀疏自编码器\n去噪自编码器\n变分自编码器\n生成对抗网络 GAN\nDCGAN\n应用领域（待扩展）\n推荐系统\n机器视觉 CV\n自然语言处理 NLP\n生物信息\n常用工具\n数据分析\nNumPy\nPandas\n科学计算\nSciPy\n可视化\nMatplotlib\nSeaborn\n机器学习\nscikit-learn/sklearn\nXGBoost\nLightGBM\n深度学习\nKeras\nTensorFlow\nPyTorch"}
