{"content2":"机器学习-概率分布-伯努利分布\n概率论在机器学习领域发挥了重要的作用。目前机器学习的很多方法本质上是统计学习，而统计学习的本质则是概率论。在概率论中概率分布是一个非常重要的工具。概率分布\np(x)\np(\\mathbf{x}) 描述的是随机变量\nx\n\\mathbf{x} 的概率密度分布。\n首先介绍最简单的一种分布-伯努利分布。变量\nx∈{0,1}\nx\\in\\{0, 1\\} 即变量\nx\nx 要么为\n1\n1 要么为\n0\n0。真实世界中的一个例子是抛硬币，设硬币正面朝上表示\n1\n1, 反面朝上表示为\n0\n0。假设硬币经过了特定设计，那么正面朝上的概率和反面朝上的概率是不一样的，设正面朝上的概率为\nμ,0<μ<1\n\\mu, 0<\\mu<1。那么我们抛一次硬币，正面朝上的概率可表示为：\np(x=1|μ)=u\np(x=1|\\mu)=u\n同理，反面朝上的概率为：\np(x=0|μ)=1−u\np(x=0|\\mu)=1-u\n因此，变量\nx\nx的概率可写为：\np(x)=ux(1−u)1−x\np(x)=u^x(1-u)^{1-x}\n假设我们抛硬币抛了\nN\nN次，得到了\nN\nN次结果\nD={x1,x2,⋯,xN}\n\\mathcal{D}=\\{x_1,x_2,\\cdots,x_N\\}，那么这些观测变量的似然为：\np(D|μ)=∏n=1Np(xn|μ)=∏n=1Nuxn(1−μ)1−xn\np(\\mathcal{D}|\\mu)=\\prod_{n=1}^Np(x_n|\\mu)=\\prod_{n=1}^Nu^{x_n}(1-\\mu)^{1-x_n}\n我们可以通过最大似然来估计概率分布的参数\nμ\n\\mu。最大化似然等价于最大化对数似然。对上述求对数\nlnp(D|μ)=∑n=1N{xnlnμ+(1−xn)ln(1−μ)}\n\\ln p(\\mathcal{D}|\\mu)=\\sum_{n=1}^N\\left\\{x_n\\ln\\mu+\\left(1-x_n\\right)\\ln\\left(1-\\mu\\right)\\right\\}\n最大化上面的对数似然就可以得到参数\nμ\n\\mu的最大似然估计。具体过程为：\nlnp(D|μ)\n\\ln p(\\mathcal{D}|\\mu)对\nmu\nmu求导并令其为\n0\n0，可得：\n0μ==∑n=1Nxn1μ−∑n=1N(1−xn)11−μ1N∑n=1Nxn\n\\begin{eqnarray*} 0&=&\\sum_{n=1}^Nx_n\\frac{1}{\\mu}-\\sum_{n=1}^N(1-x_n)\\frac{1}{1-\\mu}\\\\ \\mu&=&\\frac{1}{N}\\sum_{n=1}^Nx_n \\end{eqnarray*}\n我们用python来实现上述的参数估计过程，用scipy包中的bernoulli分布来生成样本，再根据这些样本估计bernoulli分布的参数。下面的代码表示bernoulli分布的参数为0.32，我们用这个分布生成了10000个样本。再用这10000个样本估计该分布的参数。看看估计出来的参数是多少。减少生成样本的个数(size)，重新估计参数，看有什么变化。\n代码\n估计伯努利分布的参数：\nfrom scipy.stats import bernoulli,poisson,norm,expon import numpy X=bernoulli.rvs(0.32,size=10000) #根据伯努利分布来生成样本# mu=numpy.mean(X)#用样本来估计参数# print(mu)"}
