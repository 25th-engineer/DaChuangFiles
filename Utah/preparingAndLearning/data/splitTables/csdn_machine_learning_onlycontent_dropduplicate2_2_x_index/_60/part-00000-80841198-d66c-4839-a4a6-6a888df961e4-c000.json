{"content2":"Andrew Ng 机器学习第六课\n￼关于这个Precision和Recall的概念，我一直不能很好的理解，所以我找了个时间梳理的了一下。\n- Accuracy = 准确率 预测对的除以总样本数\n- Precision = 预测正率\n- Recall = 查对率 预测对占实际是对的\n理解资料\n￼\n￼\n￼\n以上内容都为转载.\n帮助理解的例子\n拿导弹的例子：雷达收到 100个导弹信号 ，只有3个是真的导弹 ，97 个全是假的模拟导弹信号。而我们的预测器(分类器) 预测出来 98个是 模拟导弹信号，而1个没有被预测出来，而这一个会带来毁灭性伤害。\n这时候我们希望 Precision 大一点 我们不希望 一个被没有预测出来而毁 了整座城市，更多的时候我们宁愿预测错多一点也不想放过一个真导弹 Recall低 Recall可以低一点。\n因为Recall低了把很对实际上是假导弹当为真导弹。但是它并没有漏掉(漏检)真导弹。\n￼\nRecall = 100% Precision = 66.7%\n另外一个例子：在法庭上有审判100个可疑的谋杀犯人。 95个是真的谋 杀犯，而5个并不是谋杀犯。而检察官(分类器)判定其中97个是谋杀犯， 显然其中有两个人是被冤枉的。\n这个这时候我们很大程度上并不希望有人会被冤枉。我们希望Recall高一点，被冤枉的人少一点。但是我们也希望Precision要高一点，因为我们又不想放过那些杀了人却逃过一劫的人。\n￼\nRecall = 97.9% Precision = 100%\n但是很多时候，鱼和熊掌不可兼得，所以我们更希望根据Precision和Recall的主次(权重)把模型优化到最优。"}
