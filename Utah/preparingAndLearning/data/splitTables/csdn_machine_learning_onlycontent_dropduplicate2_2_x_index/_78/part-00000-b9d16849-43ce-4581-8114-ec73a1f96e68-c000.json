{"content2":"http://antkillerfarm.github.io/\n因子分析的EM估计（续）\n去掉和各参数无关的部分后，可得：\n∑i=1mE[logp(x(i)|z(i);μ,Λ,Ψ)]=∑i=1mE[1(2π)n/2∣Ψ∣1/2exp(−12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i)))]=∑i=1mE[−12log∣Ψ∣−n2log(2π)−12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))]\n\\begin{align} &\\sum_{i=1}^mE\\left[\\log p(x^{(i)}\\vert z^{(i)};\\mu,\\Lambda,\\Psi)\\right] \\\\&=\\sum_{i=1}^mE\\left[\\frac{1}{(2\\pi)^{n/2}\\lvert\\Psi\\rvert^{1/2}}\\exp\\left(-\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\right)\\right] \\\\&=\\sum_{i=1}^mE\\left[-\\frac{1}{2}\\log\\lvert\\Psi\\rvert-\\frac{n}{2}\\log(2\\pi)-\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\right] \\end{align}\n去掉和\nΛ\n\\Lambda无关的部分，并求导可得：\n∇Λ∑i=1m−E[12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))](1)\n\\nabla_\\Lambda\\sum_{i=1}^m-E\\left[\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\right]\\tag{1}\n因为公式1中\nE[⋅]\nE[\\cdot]部分的结果实际上是个实数，因此该公式可变形为：\n∇Λ∑i=1m−E[tr(12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i)))]\n\\nabla_\\Lambda\\sum_{i=1}^m-E\\left[\\operatorname{tr}\\left(\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)})\\right)\\right]\n而：\n12(x(i)−μ−Λz(i))TΨ−1(x(i)−μ−Λz(i))=12[((x(i)−μ)T−(Λz(i))T)Ψ−1((x(i)−μ)−Λz(i))]=12[(x(i)−μ)TΨ−1(x(i)−μ)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)+(Λz(i))TΨ−1Λz(i)]\n\\begin{align} &\\frac{1}{2}(x^{(i)}-\\mu-\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu-\\Lambda z^{(i)}) \\\\&=\\frac{1}{2}\\left[((x^{(i)}-\\mu)^T-(\\Lambda z^{(i)})^T)\\Psi^{-1}((x^{(i)}-\\mu)-\\Lambda z^{(i)})\\right] \\\\&=\\frac{1}{2}\\left[(x^{(i)}-\\mu)^T\\Psi^{-1}(x^{(i)}-\\mu)-(x^{(i)}-\\mu)^T\\Psi^{-1}\\Lambda z^{(i)} \\\\-(\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu)+(\\Lambda z^{(i)})^T\\Psi^{-1}\\Lambda z^{(i)}\\right] \\end{align}\n去掉和\nΛ\n\\Lambda无关的部分，可得：\n12[(Λz(i))TΨ−1Λz(i)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)]\n\\frac{1}{2}\\left[(\\Lambda z^{(i)})^T\\Psi^{-1}\\Lambda z^{(i)}-(x^{(i)}-\\mu)^T\\Psi^{-1}\\Lambda z^{(i)}-(\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu)\\right]\n所以：\n∇Λ∑i=1m−E[tr(12[(Λz(i))TΨ−1Λz(i)−(x(i)−μ)TΨ−1Λz(i)−(Λz(i))TΨ−1(x(i)−μ)])]=∇Λ∑i=1m−E[12tr((Λz(i))TΨ−1Λz(i))−12tr((x(i)−μ)TΨ−1Λz(i))−12tr((Λz(i))TΨ−1(x(i)−μ))]=∑i=1m∇ΛE[−12tr(ΛTΨ−1Λz(i)(z(i))T)+tr(ΛTΨ−1(x(i)−μ)(z(i))T)](2)\n\\begin{align} &\\nabla_\\Lambda\\sum_{i=1}^m-E\\left[\\operatorname{tr}\\left(\\frac{1}{2}\\left[(\\Lambda z^{(i)})^T\\Psi^{-1}\\Lambda z^{(i)}-(x^{(i)}-\\mu)^T\\Psi^{-1}\\Lambda z^{(i)}-(\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu)\\right]\\right)\\right] \\\\&\\begin{split}=\\nabla_\\Lambda\\sum_{i=1}^m-E\\left[\\frac{1}{2}\\operatorname{tr}\\left((\\Lambda z^{(i)})^T\\Psi^{-1}\\Lambda z^{(i)}\\right)-\\frac{1}{2}\\operatorname{tr}\\left((x^{(i)}-\\mu)^T\\Psi^{-1}\\Lambda z^{(i)}\\right) \\\\-\\frac{1}{2}\\operatorname{tr}\\left((\\Lambda z^{(i)})^T\\Psi^{-1}(x^{(i)}-\\mu)\\right)\\right]\\end{split} \\\\&=\\sum_{i=1}^m\\nabla_\\Lambda E\\left[-\\frac{1}{2}\\operatorname{tr}\\left(\\Lambda^T \\Psi^{-1}\\Lambda z^{(i)}(z^{(i)})^T\\right)+\\operatorname{tr}\\left(\\Lambda^T \\Psi^{-1}(x^{(i)}-\\mu)(z^{(i)})^T\\right)\\right]\\tag{2} \\end{align}\n因为：\n∇AtrABATC=CAB+CTABT\n\\nabla_A\\operatorname{tr}ABA^TC=CAB+C^TAB^T\n所以：\n∇Atr(ΛTΨ−1Λz(i)(z(i))T)=z(i)(z(i))TΛTΨ−1+(z(i)(z(i))T)TΛT(Ψ−1)T=z(i)(z(i))TΛTΨ−1+((z(i))T)T(z(i))TΛTΨ−1=2z(i)(z(i))TΛTΨ−1\n\\begin{align} &\\nabla_A\\operatorname{tr}\\left(\\Lambda^T \\Psi^{-1}\\Lambda z^{(i)}(z^{(i)})^T\\right)=z^{(i)}(z^{(i)})^T\\Lambda^T \\Psi^{-1}+(z^{(i)}(z^{(i)})^T)^T\\Lambda^T(\\Psi^{-1})^T \\\\&=z^{(i)}(z^{(i)})^T\\Lambda^T \\Psi^{-1}+((z^{(i)})^T)^T(z^{(i)})^T\\Lambda^T\\Psi^{-1}=2z^{(i)}(z^{(i)})^T\\Lambda^T \\Psi^{-1} \\end{align}\n代入公式2，可得：\n∑i=1mE[−Ψ−1Λz(i)(z(i))T+Ψ−1(x(i)−μ)(z(i))T]\n\\sum_{i=1}^mE\\left[-\\Psi^{-1}\\Lambda z^{(i)}(z^{(i)})^T+\\Psi^{-1}(x^{(i)}-\\mu)(z^{(i)})^T\\right]\n由上式等于0，可得：\n∑i=1mΛEz(i)∼Qi[z(i)(z(i))T]=∑i=1m(x(i)−μ)Ez(i)∼Qi[(z(i))T]\n\\sum_{i=1}^m\\Lambda E_{z^{(i)}\\sim Q_i}\\left[z^{(i)}(z^{(i)})^T\\right]=\\sum_{i=1}^m(x^{(i)}-\\mu)E_{z^{(i)}\\sim Q_i}\\left[(z^{(i)})^T\\right]\n因此：\nΛ=(∑i=1m(x(i)−μ)Ez(i)∼Qi[(z(i))T])(∑i=1mEz(i)∼Qi[z(i)(z(i))T])−1(3)\n\\Lambda=\\left(\\sum_{i=1}^m(x^{(i)}-\\mu)E_{z^{(i)}\\sim Q_i}\\left[(z^{(i)})^T\\right]\\right)\\left(\\sum_{i=1}^m E_{z^{(i)}\\sim Q_i}\\left[z^{(i)}(z^{(i)})^T\\right]\\right)^{-1}\\tag{3}\n因为：\nCov(Y)=E[YYT]−E[Y]E[Y]T\n\\operatorname{Cov}(Y)=E[YY^T]-E[Y]E[Y]^T\n所以：\nE[YYT]=E[Y]E[Y]T+Cov(Y)\nE[YY^T]=E[Y]E[Y]^T+\\operatorname{Cov}(Y)\n因此根据之前的讨论可得：\nEz(i)∼Qi[(z(i))T]=μTz(i)|x(i)\nE_{z^{(i)}\\sim Q_i}\\left[(z^{(i)})^T\\right]=\\mu_{z^{(i)}\\vert x^{(i)}}^T\nEz(i)∼Qi[z(i)(z(i))T]=μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i)\nE_{z^{(i)}\\sim Q_i}\\left[z^{(i)}(z^{(i)})^T\\right]=\\mu_{z^{(i)}\\vert x^{(i)}}\\mu_{z^{(i)}\\vert x^{(i)}}^T+\\Sigma_{z^{(i)}\\vert x^{(i)}}\n将上式代入公式3，可得：\nΛ=(∑i=1m(x(i)−μ)μTz(i)|x(i))(∑i=1m(μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i)))−1\n\\Lambda=\\left(\\sum_{i=1}^m(x^{(i)}-\\mu)\\mu_{z^{(i)}\\vert x^{(i)}}^T\\right)\\left(\\sum_{i=1}^m \\left(\\mu_{z^{(i)}\\vert x^{(i)}}\\mu_{z^{(i)}\\vert x^{(i)}}^T+\\Sigma_{z^{(i)}\\vert x^{(i)}}\\right)\\right)^{-1}\n这里需要注意的是，和之前的混合高斯模型相比，我们不仅要计算\nΣz(i)|x(i)\n\\Sigma_{z^{(i)}\\vert x^{(i)}}，还要计算\nE[z]\nE[z]和\nE[zzT]\nE[zz^T]。\n此外，我们还可得出：（推导过程略）\nμ=1m∑i=1mx(i)\n\\mu=\\frac{1}{m}\\sum_{i=1}^mx^{(i)}\nΦ=1m∑i=1m(x(i)(x(i))T−x(i)μTz(i)|x(i)ΛT−Λμz(i)|x(i)(x(i))T+Λ(μz(i)|x(i)μTz(i)|x(i)+Σz(i)|x(i))ΛT)\n\\begin{split}\\Phi=\\frac{1}{m}\\sum_{i=1}^m\\left(x^{(i)}(x^{(i)})^T-x^{(i)}\\mu_{z^{(i)}\\vert x^{(i)}}^T\\Lambda^T-\\Lambda\\mu_{z^{(i)}\\vert x^{(i)}}(x^{(i)})^T \\\\+\\Lambda\\left(\\mu_{z^{(i)}\\vert x^{(i)}}\\mu_{z^{(i)}\\vert x^{(i)}}^T+\\Sigma_{z^{(i)}\\vert x^{(i)}}\\right)\\Lambda^T\\right)\\end{split}\n机器学习中的矩阵方法\n在继续Andrew Ng的讲义之前，我们需要加强一些矩阵的相关知识。虽然Andrew Ng的讲义中已经包含了一个线性代数方面的简介文章，然而真的就只是简介而已，好多内容都没有。\n这里推荐一本书《Matrix Methods in Data Mining and Pattern Recognition》。\n作者：Lars Eld´en，执教于Linköping University数学系。\nhttp://www.cnblogs.com/daniel-D/p/3204508.html\n这是daniel-D写的中文笔记。\n这一部分的内容属于数值计算领域，涉及的概念虽然不复杂，但提出一个高效算法，仍然不是件容易的事情。\n还有另外一本书《Liner Algebra Done Right》，也值得推荐。这本书从定义矩阵算子，而不是通过行列式，来解释各种线性代数原理，提供了一种独特的视角。因为算子是有明确的几何或物理意义的，而行列式则不然。\n作者：Sheldon Jay Axler，1949年生，美国数学家。普林斯顿大学本科，UCB博士，MIT博士后，San Francisco State University教授。美国的数学系基本就是本科和博士，很少有硕士。因为数学，尤其是理论数学，需要高度的抽象思维能力，半调子的硕士，既不好找工作，也不好搞科研。\n三角矩阵的求逆问题\n⎡⎣⎢l11l21l310l22l3200l33⎤⎦⎥⎡⎣⎢u1100u12u220u13u23u33⎤⎦⎥\n\\begin{bmatrix} l_{11} & 0 & 0 \\\\ l_{21} & l_{22} & 0 \\\\ l_{31} & l_{32} & l_{33} \\\\ \\end{bmatrix} \\begin{bmatrix} u_{11} & u_{12} & u_{13} \\\\ 0 & u_{22} & u_{23} \\\\ 0 & 0 & u_{33} \\\\ \\end{bmatrix}\n以3阶方阵为例，上面左边的矩阵被称为下三角矩阵（lower triangular matrix），而右边的矩阵被称为上三角矩阵（upper triangular matrix）。\n对于矩阵求逆问题来说，下三角矩阵是一类比较简单的矩阵，求逆难度仅高于对角阵。\n下三角矩阵的逆矩阵也是下三角矩阵，因此：\nAA−1=⎡⎣⎢⎢⎢a11a21…an10a22…an2…………00…ann⎤⎦⎥⎥⎥⎡⎣⎢⎢⎢b11b21…bn10b22…bn2…………00…bnn⎤⎦⎥⎥⎥=⎡⎣⎢⎢⎢10…001…0…………00…1⎤⎦⎥⎥⎥\nAA^{-1}=\\begin{bmatrix} a_{11} & 0 & \\dots & 0 \\\\ a_{21} & a_{22} & \\dots & 0 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ a_{n1} & a_{n2} & \\dots & a_{nn} \\\\ \\end{bmatrix} \\begin{bmatrix} b_{11} & 0 & \\dots & 0 \\\\ b_{21} & b_{22} & \\dots & 0 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ b_{n1} & b_{n2} & \\dots & b_{nn} \\\\ \\end{bmatrix} =\\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ 0 & 1 & \\dots & 0 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ 0 & 0 & \\dots & 1 \\\\ \\end{bmatrix}\n由矩阵乘法定义，可得：\ncij=∑k=jiaikbkj\nc_{ij}=\\sum_{k=j}^ia_{ik}b_{kj}\n由\ncij=1,i=j\nc_{ij}=1,i=j，可得：\nbii=1aii\nb_{ii}=\\frac{1}{a_{ii}}\n由\ncij=0,i≠j\nc_{ij}=0,i\\neq j，可得：\ncij=∑k=ji−1aikbkj+aiibij=0\nc_{ij}=\\sum_{k=j}^{i-1}a_{ik}b_{kj}+a_{ii}b_{ij}=0\n因此：\nbij=−1aii∑k=ji−1aikbkj=−bii∑k=ji−1aikbkj\nb_{ij}=-\\frac{1}{a_{ii}}\\sum_{k=j}^{i-1}a_{ik}b_{kj}=-b_{ii}\\sum_{k=j}^{i-1}a_{ik}b_{kj}\n上三角矩阵求逆，可通过转置转换成下三角矩阵求逆。这里会用到以下性质:\n(AT)−1=(A−1)T\n(A^T)^{-1}=(A^{-1})^T\nLU分解\nLU分解可将矩阵A分解为\nA=LU\nA=LU，其中L是下三角矩阵，U是上三角矩阵。\nLU分解的用途很多，其中之一是求逆：\nA−1=(LU)−1=U−1L−1\nA^{-1}=(LU)^{-1}=U^{-1}L^{-1}\nLU分解有若干种算法，常见的包括Doolittle、Cholesky、Crout算法。\n注：Myrick Hascall Doolittlee，1830~1913。\nAndr´e-Louis Cholesky，1875~1918，法国数学家、工程师、军官。死于一战战场。\nPrescott Durand Crout，1907~1984，美国数学家，22岁获MIT博士。\n这里只介绍一下Doolittle算法。\nA=⎡⎣⎢⎢⎢a11a21…an1a12a22…an2…………a1na2n…ann⎤⎦⎥⎥⎥=LU=⎡⎣⎢⎢⎢1l21…ln101…ln2…………00…1⎤⎦⎥⎥⎥⎡⎣⎢⎢⎢u110…0u12u22…0…………u1nu2n…unn⎤⎦⎥⎥⎥\nA=\\begin{bmatrix} a_{11} & a_{12} & \\dots & a_{1n} \\\\ a_{21} & a_{22} & \\dots & a_{2n} \\\\ \\dots & \\dots & \\dots & \\dots \\\\ a_{n1} & a_{n2} & \\dots & a_{nn} \\\\ \\end{bmatrix}=LU= \\begin{bmatrix} 1 & 0 & \\dots & 0 \\\\ l_{21} & 1 & \\dots & 0 \\\\ \\dots & \\dots & \\dots & \\dots \\\\ l_{n1} & l_{n2} & \\dots & 1 \\\\ \\end{bmatrix} \\begin{bmatrix} u_{11} & u_{12} & \\dots & u_{1n} \\\\ 0 & u_{22} & \\dots & u_{2n} \\\\ \\dots & \\dots & \\dots & \\dots \\\\ 0 & 0 & \\dots & u_{nn} \\\\ \\end{bmatrix}\n由矩阵乘法定义，可知：\na1j=u1j,j=1,2,…,n\na_{1j}=u_{1j},j=1,2,\\dots,n\naij={∑jt=1litutj,∑i−1t=1litutj+uij,j<ij≥i\na_{ij}=\\begin{cases} \\sum_{t=1}^jl_{it}u_{tj}, & j<i \\\\ \\sum_{t=1}^{i-1}l_{it}u_{tj}+u_{ij}, & j\\ge i \\\\ \\end{cases}\n因此：\nu1j=a1j,j=1,2,…,n\nu_{1j}=a_{1j},j=1,2,\\dots,n（U的第1行）\nlj1=aj1/u11,j=1,2,…,n\nl_{j1}=a_{j1}/u_{11},j=1,2,\\dots,n（L的第1列）\nFor\ni=2,3,…,n\ni=2,3,\\dots,n do\nuii=aii−∑i−1t=1litutj\nu_{ii}=a_{ii}-\\sum_{t=1}^{i-1}l_{it}u_{tj}\nuij=aij−∑i−1t=1litutj\nu_{ij}=a_{ij}-\\sum_{t=1}^{i-1}l_{it}u_{tj} for\nj=i+1,…,n\nj=i+1,\\dots,n（U的第i行）\nlji=aji−∑i−1t=1ljtutiuii\nl_{ji}=\\frac{a_{ji}-\\sum_{t=1}^{i-1}l_{jt}u_{ti}}{u_{ii}} for\nj=i+1,…,n\nj=i+1,\\dots,n（L的第i列）\nEnd\nunn=ann−∑n−1t=1lntutn\nu_{nn}=a_{nn}-\\sum_{t=1}^{n-1}l_{nt}u_{tn}\n参见：\nhttp://www3.nd.edu/~zxu2/acms40390F11/Alg-LU-Crout.pdf\nQR分解\n任意实数方阵A，都能被分解为\nA=QR\nA=QR。这里的Q为正交单位阵，即\nQTQ=I\nQ^TQ=I。R是一个上三角矩阵。这种分解被称为QR分解。\nQR分解也有若干种算法，常见的包括Gram–Schmidt、Householder和Givens算法。\n注：Jørgen Pedersen Gram，1850～1916，丹麦数学家，在矩阵、数论、泛函等领域皆有贡献。他居然是被自行车撞死的…\nErhard Schmidt，1876～1959，德国数学家，哥廷根大学博士，柏林大学教授。David Hilbert的学生。20世纪数学界的几位超级大神之一。1933年前的哥廷根大学数学系，秒杀其他所有学校。所谓“一流的学生去哥廷根，智商欠费才去藤校”。\nAlston Scott Householder，1904～1993，美国数学家，芝加哥大学博士，田纳西大学教授。ACM主席。\nJames Wallace Givens, Jr.，1910～1993，美国数学家，普林斯顿大学博士，西北大学教授。参与UNIVAC I机器项目（1951年），这是最早的商用计算机。\n这里只介绍Gram–Schmidt算法，这个算法虽然名为Gram–Schmidt，然而拉普拉斯和柯西早就已经用过了。\n首先介绍一下向量的投影运算的符号表示。\n如上图所示，根据余弦定理和向量点乘的定义可得：\na⋅b=|a||b|cosθ\na\\cdot b=|a||b|\\cos \\theta\n因此，向量a在向量b上的投影向量\na1\na_1，可表示为：\na1=|a|cosθb^=|a|a⋅b|a||b|b|b|=a⋅b|b|2b=a⋅bb⋅bb=⟨a,b⟩⟨b,b⟩b\na_1=|a|\\cos \\theta\\hat b=|a|\\frac{a\\cdot b}{|a||b|}\\frac{b}{|b|}=\\frac{a\\cdot b}{|b|^2}b=\\frac{a\\cdot b}{b\\cdot b}b=\\frac{\\langle a,b\\rangle}{\\langle b,b\\rangle}b\n特别的，当b为单位向量时：\na1=⟨a,b⟩(4)\na_1=\\langle a,b\\rangle\\tag{4}\n我们定义投影符号如下：\nprojea=⟨e,a⟩⟨e,e⟩e\n\\mathrm{proj}_{\\mathbf{e}}\\mathbf{a} = \\frac{\\left\\langle\\mathbf{e},\\mathbf{a}\\right\\rangle}{\\left\\langle\\mathbf{e},\\mathbf{e}\\right\\rangle}\\mathbf{e}"}
