{"content2":"1. 奥卡姆剃刀（Occam’s Razor）\n如无必要，勿增实体。也就是简单有效原理。\n具体到机器学习上，就是说，能够拟合数据的“simple model”(简单模型)才是我们需要的。\n“Simple model”包含两个层面的意思，一是指simple hypothesis，每一个假设都只有少数的参数；二是指simple hypothesis set，假设空间只包含少数的假设。\n简单的H，会有较小的成长函数mH(N),在一个二分类问题中，一个模型完全拟合数据的概率是(m_H （N）)/2^N ，也就意味着H完全拟合数据的概率会变小。在这样的情况下，模型对数据的拟合才是具有显著性的。\n即使是完全没有规律的随机数据，在mH(N)足够大的情况下，我们也能够找到一个完全拟合的模型。想象一下，一枚均匀的硬币，抛100次，如果现在我的mH(N)≥2100，这意味着我总可以在H里找到一个完全拟合的模型。但是这样的拟合完全没有意义。\nTips：每次拿到数据后，都先用线性模型进行拟合，如果线性模型对数据完全没有区分度，极有可能，数据本身就是杂乱无序的。\n2. 尽最大可能还原真实的测试环境\n1948年的美国总统竞选，一共有两个候选人，Truman和Dewey。一家报社为了预测选举结果，进行了电话投票，也就是打电话给选民，统计他们投票给了哪个候选人；结果显示，大部分接受采访的选民，都表示投票给了Dewey，于是，这家报社就发表了题为“Dewey Defeats Truman“的报道。\n但是结果却是Truman赢得了选举。\n为什么呢？是编辑的错误？参与调研的选民说谎？\n真实的原因其实是，Dewey的竞选政策偏向于富人，Truman的竞选政策偏向于穷人。而在1948年，电话还是很贵的，这家报社采样的对象都是富人，所以，得到的结果也自然是偏向富人的Dewey获胜。\n这告诉我们，训练集和最终的测试集一定要是iid同分布的。如果训练集的数据采样是有偏差的，那么学习得到的模型也一定是有偏差的。\n关于训练集和测试集划分的一个常见错误是忽略“时间”的影响，比如，我们的信贷模型。最初始的信贷模型，训练集和测试集是对总体数据集D进行的一个随机划分，这通常会导致一个很不错的测试结果（因为我们在训练的时候用到了“未来”的数据，而测试时，用到了“过去”的数据）。但是事实上，一个正确的划分应当是按照时间来划分，即某一时刻之后的用户记录为测试集，该时刻之前的用户记录为训练集。\nTips：如果用户记录是带有时间戳的，那么，测试集通常采用“最近的记录”，测试集采用“过去的记录”，并对“近期的记录”附以较大的权重，通常可以产生不错的结果。\n3. 平衡好“data-driven modeling（Snooping）和“Validation（no snooping）”\n上图是采用6年的外汇交易数据做训练集，最近2年的数据做测试集得到的一个外汇交易模型的测试结果。\n红线和蓝线的唯一区别在于：红线采用snooping方法，计算整体样本（训练集+测试集）的均值和方差，对所有样本进行变量归一（(X-u)/σ）；蓝线只对训练集计算均值和方差，然后进行变量归一。可以看到，snooping比no snooping方法有很大的“虚假”提升。\n同样的问题在学术界也经常发生，比如一个标准数据集D，第一篇Paper提出了H1；第二篇Paper提出了H2，H2比H1在D上表现要好；第三篇Paper提出了H3，H3比H2在D上表现要好……\n事实上上，因为后期模型实在前人研究基础上做出来的，作者通过阅读前人的论文而偷看了数据集， d_vc (H_m)=d_vc (∪H_m)，后期模型的VC维很大，通常会导致一个不错的in-sample error，糟糕的generalization error。学术界有句话叫做:If you torture the data long enough, it will confess.\n实际上，人们要做模型，不可避免的要调研数据，进而对数据集做出某种假设，比如正态分布或是密率分布。领域知识、对数据的调研都是对假设空间的一种污染，这其实都是snooping。一种比较极端的方法是，拿到数据集之后直接将测试集分隔，只对训练集进行分析。\nTips：对数据集进行snooping是不可避免的，关键是一定要平衡好data-driven modelling（snooping）和validation（no-snooping）二者之间的关系。"}
