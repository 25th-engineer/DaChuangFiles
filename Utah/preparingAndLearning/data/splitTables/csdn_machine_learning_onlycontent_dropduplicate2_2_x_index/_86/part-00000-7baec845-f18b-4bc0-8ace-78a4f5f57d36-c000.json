{"content2":"–本文章是笔者对于高扬、卫峥编著的《白话深度学习与Tensorflow》读后总结\n首先简单介绍一下，这本书是老师所推荐的，就教学意义来讲，是一本特别特别通俗易懂的教材，用简明扼要的理论和文字给读者讲解深度学习的各种理论，对于初学者来说是一本再好不过的教材，强力推荐\n从学习的种类来说，机器学习习惯分为两种。一种叫无监督学习，一种叫有监督学习。\n所谓“无监督学习”，是指人们在获得训练的向量数据后在没有标签的情况下尝试找出其内部蕴含关系的一种挖掘工作，在这个过程中，不需要对这些样本做任何的标记或者是干预。”有监督学习“与此不同，每一个样本数据都要有标签，最后我们只要总结出这些训练样本与标签的映射关系。\n一、聚类\n聚类是一种典型的”无监督学习“，是把物理对象或者抽象对象的集合分组为彼此类似的对象组成的多个类的分析过程。\n简单来说，就是把相似事物归为一类，面前有一群宠物，经过一个个观察后，我们能够分辨哪些是猫，哪些是狗，而在这些猫狗中，我们又能分辨出它们的不同种类，这就是一个聚类的过程。\n对于计算机来讲，在输入样本数据后，通过一定的算法就可以得出不同的聚类结果，这个过程是不需要干预的，所以为”非监督“。\n二、回归\n回归是一种解题方法。\n回归的英文为regression，中文释义可以理解为”倒推“，即”推导“的意思。就是一个”由果索因“的过程。可以理解为–当我看到大量的事实所呈现的样态，我推断出原因或客观蕴含的关系。\n比如函数 y=wx+b，在给出一些x和y的取值后，我们可以推导出w和b的取值，这就是简单的一个回归。\n回归可分为线性回归和非线性回归两种。\n线性回归就是向量和最终的函数值存在一种线性关系。\n非线性回归在机器学习领域应用最多当属逻辑回归，对于任何向量，这里的函数值可以假设只存在两种，即0和1，也可认为是“真”和“假”。\n三、分类\n分类属于机器学习中使用最多的一大类算法，通常这类算法也叫做“分类器”。\n在这里提一下，在传统的机器学习中，对于获取到的数据集一般会分为训练集和测试集（有叫验证集，一个意思）两种。训练集用作训练、归纳关系；测试集用来验证所得关系的精确度。一般数据集的划分为三七开或者二八开，实际应用会有不同，反正训练集一定是用数据多的那部分。\n分类算法就像一个黑盒子一样，有一个输入也有一个输出，我们输入一个样本，它输出样本的类别。\n我们在编写代码的时候，会教分类器如何建立一种输入到输出的映射逻辑，以及让它自己调整这种逻辑关系，是逻辑更为合理，而合理与否是通过召回率和精确率来衡量。下面通过一个例子介绍召回率和精确率。\n比如我们有1000张照片。其中有200张猫，200张狗，600张兔子。把它们输入到训练集去训练，经过多轮训练后，分类器已经基本获取了这三类的特征，然后再用分类器对这些图片进行分类。\n最后得到200张猫有180张正确识别为猫，其余20张误判为狗。\n200张狗全部判定正确。\n600张兔子有550张识别为兔子，其余30张误判为猫，20张误判为狗。\n那么对于这个例子，猫的召回率就是 正确识别的图片/猫的所有图片 = 180/200 = 90%，同样兔子的就是 550/600 ≈ 91.7%。而在这1000张图中，我们检索到240张狗，其中200张的确是狗，有20张是被误判的猫，还有20张是被误判的兔子，那么狗的精确率就是 200/240 ≈ 83.3%。这样就是这两个概念的意思了。\n分类的训练过程和回归的一样，都是极为套路化的程序。\n第一，输入样本和分类标签。\n第二，建立映射假说的某个 y=f(x) 的模型\n第三，求解出全局的损失函数loss和待定系数w的映射关系。loss=g（w）\n第四，通过迭代优化降低loss，最终找到一个w能使召回率和精确率满足场景需要。"}
