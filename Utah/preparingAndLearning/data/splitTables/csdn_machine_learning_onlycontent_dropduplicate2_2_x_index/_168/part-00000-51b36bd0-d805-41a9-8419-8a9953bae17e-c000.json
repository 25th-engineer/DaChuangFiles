{"content2":"人工智能的浪潮正在席卷全球，诸多词汇时刻萦绕在我们耳边：人工智能（Artificial Intelligence）、机器学习（Machine Learning）、深度学习（Deep Learning）。不少人对这些高频词汇的含义及其背后的关系总是似懂非懂、一知半解。\n为了帮助大家更好地理解人工智能，这篇文章用最简单的语言解释了这些词汇的含义，理清它们之间的关系，希望对大家有所帮助。\n人工智能（Artificial Intelligence）\n人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。“人工智能”是“一门技术科学”，它研究与开发的对象是“理论、技术及应用系统”，研究的目的是为了“模拟、延伸和扩展人的智能”。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。另外，人工智能在50年代就提出了。\n但目前的科研工作都集中在弱人工智能这部分，并很有希望在近期取得重大突破，电影里的人工智能多半都是在描绘强人工智能，而这部分在目前的现实世界里难以真正实现（通常将人工智能分为弱人工智能和强人工智能，前者让机器具备观察和感知的能力，可以做到一定程度的理解和推理，而强人工智能让机器获得自适应能力，解决一些之前没有遇到过的问题）。\n弱人工智能有希望取得突破，是如何实现的，“智能”又从何而来呢？这主要归功于一种实现人工智能的方法——机器学习。\n机器学习（Machine Learning）\n随着人对计算机科学的期望越来越高，要求它解决的问题越来越复杂，已经远远不能满足人们的诉求了。于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器学会如何执行任务。这里有三个重要的信息：\n1、“机器学习”是“模拟、延伸和扩展人的智能”的一条路径，所以是人工智能的一个子集；\n2、“机器学习”是要基于大量数据的，也就是说它的“智能”是用大量数据喂出来的；\n3、正是因为要处理海量数据，所以大数据技术尤为重要；“机器学习”只是大数据技术上的一个应用。常用的10大机器学习算法有：决策树、随机森林、逻辑回归、SVM、朴素贝叶斯、K最近邻算法、K均值算法、Adaboost算法、神经网络、马尔科夫。\n举个简单的例子，当我们浏览网上商城时，经常会出现商品推荐的信息。这是商城根据你往期的购物记录和冗长的收藏清单，识别出这其中哪些是你真正感兴趣，并且愿意购买的产品。这样的决策模型，可以帮助商城为客户提供建议并鼓励产品消费。\n深度学习（Deep Learning）\n相较而言，深度学习是一个比较新的概念，严格地说是2006年提出的。深度学习是用于建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据的一种机器学习技术。它的基本特点，是试图模仿大脑的神经元之间传递，处理信息的模式。最显著的应用是计算机视觉和自然语言处理(NLP)领域。显然，“深度学习”是与机器学习中的“神经网络”是强相关，“神经网络”也是其主要的算法和手段；或者我们可以将“深度学习”称之为“改良版的神经网络”算法。深度学习又分为卷积神经网络（Convolutional neural networks，简称CNN）和深度置信网（Deep Belief Nets，简称DBN）。其主要的思想就是模拟人的神经元，每个神经元接受到信息，处理完后传递给与之相邻的所有神经元即可。所以看起来的处理方式有点像下图（想深入了解的同学可以自行google）。\n神经网络的计算量非常大，事实上在很长时间里由于基础设施技术的限制进展并不大。而GPU的出现让人看到了曙光，也造就了深度学习的蓬勃发展，“深度学习”才一下子火热起来。击败李世石的Alpha go即是深度学习的一个很好的示例。Google的TensorFlow是开源深度学习系统一个比较好的实现，支持CNN、RNN和LSTM算法，是目前在图像识别、自然语言处理方面最流行的深度神经网络模型。事实上，提出“深度学习”概念的Hinton教授加入了google，而Alpha go也是google家的。\n总结：\n人工智能是一个很老的概念，机器学习是人工智能的一个子集，深度学习又是机器学习的一个子集。机器学习与深度学习都是需要大量数据来“喂”的，是大数据技术上的一个应用，同时深度学习还需要更高的运算能力支撑，如GPU。"}
