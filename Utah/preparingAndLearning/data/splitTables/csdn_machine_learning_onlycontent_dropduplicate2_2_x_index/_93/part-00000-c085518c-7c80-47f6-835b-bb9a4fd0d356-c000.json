{"content2":"一.明可夫斯基距离(Minkowski Distance)\n有两个n维的点，他们之间的明可夫斯基距离的定义为：\n你会发现这个式子和p-范数的形式很像。比如对于一个向量x，他的p-范数为：\n所以，要是在一些论文里面明可夫斯基距离写成下面的式子，也别感到奇怪：\n注意：\n说可夫斯基距离是一个距离，还不如说他是一类距离的定义，因为p值是可以变的，因为p值的不同，可以得到欧氏距离，曼哈顿距离，和切比雪夫距离等等。\nⅠ.曼哈顿距离\np=1的时候，就称之为曼哈顿距离\nⅡ.欧氏距离\n欧式距离用的是不是最多不知道，但是绝对是最熟悉的一种距离表示形式。从小就开始接触的形式。\np=1的时候，就称之为曼哈顿距离\nⅢ.切比雪夫距离\np→∞的时候，就称之为曼哈顿距离\n总结：\n闵可夫斯基距离比较直观，但是它与数据的分布无关，具有一定的局限性，如果 x 方向的幅值远远大于 y 方向的值，这个距离公式就会过度放大 x 维度的作用。\n二.余弦距离\n在几何中，夹角余弦能够衡量两个方向之间的差异，那么这种差异也能够用在机器学习里面。\n夹角余弦取值范围为[-1,1]。夹角余弦越大表示两个向量的夹角越小，夹角余弦越小表示两向量的夹角越大。当两个向量的方向重合时夹角余弦取最大值1，当两个向量的方向完全相反夹角余弦取最小值-1"}
