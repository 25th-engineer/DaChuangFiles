{"content2":"机器学习线路图：\n扎实的数学功底是机器学习的基础，然后就是机器学习典型的方法、算法，最后就是动手编程（Python），动手实践代码编写，如果想要积累实际的项目经验，最好要参加一些数据科学竞赛。\n本文主要内容：\n机器学习基础：机器学习的分类与一般思路\n微积分基础：泰勒公式、导数与梯度\n概率与统计基础：概率分布、常见分布、常见统计量\n线性代数基础：矩阵乘法的几何意义\n机器学习的其他名称：\n模式识别、数据挖掘、统计学习、计算机视觉、语音识别、自然语言处理等都属于机器学习的范畴。\n后三项（计算机视觉、语音识别、自然语言处理）为机器学习结合具体的知识产生的比较专业的一个领域：如，无人驾驶汽车，采集大量的公路照片，通过图像识别，来判断路况以及如何驾驶和躲避危险。\n机器学习的知识框架：\nHacking skills ：为计算机基础、编程基础\nSubstantive Expertise ：为相应领域的专业知识\nMath & Statistics Knowledges ：数学和统计知识、机器学习的算法\n如果只是懂懂编程，也有相应领域的专业知识，但是缺乏数学和统计知识，就会非常危险，下图中对应的区域为：Danger Zone！\n机器学习的分类：\n监督学习：分类是判断具体属于哪一类，是离散的；回归是连续的，比如说房价，股票价格等，各个价位的数据都有。\n无监督学习： 有时候要做一些无监督学习的任务，实际工程中不一定要用聚类，也不一定要用关联规则，而适合用编程人员对常识以及对业务的理解，自己人工抽象成一定的规则写到代码中可能会好很多。\n强化学习：\n监督学习——训练／分析——分类预测问题：\n已经有一组数据（训练集），并且已知每一份数据的特征（特征1-身高，特征2-发长，…，特征n-抽烟与否）和目标（目标通常称作标签，这里指 男 or 女），据此，训练出一套算法，来判断另外一组只知道特征的数据（但是不知道目标是）的目标是什么。这就是所谓的监督学习算法。因为数据是离散的，所以这个问题是分类预测问题。\n监督学习算法：训练／学习。\n根据上边得出的监督学习算法，来预测另外一组数据的目标。\n监督学习算法：预测。\n无监督学习——训练／分析\n做为训练集的已知的数据，特征已知，但它们的目标未知，也就是说在训练数据的时候，目标是未知的，这就是无监督学习模型。\n无监督学习——预测\n用图形来表示无监督学习，如下，在空间中有很多点集，横纵坐标分别代表某个特征，基于这些点在空间中的分布，分成类别，那么可以分为三类。\n总结：\n有监督学习，是基于知道特征和标签的训练集合，训练出一套算法， 去对测试集进行预测。测试集的标签或者说目标未知，测试集的特征已知。\n无监督学习，在训练的过程中就不知道训练集的目标或者说特征是什么，在预测的过程中也不知道，所以这种算法更难一些。\n半监督学习即强化学习，我们训练的数据集中特征都知道，但是，有一部分是知道目标或者说标签的，另外一部分不知道目标或者说标签。这样训练出来的算法为半监督学习算法。\n机器学习的核心思路（重点）：\n得分函数的输入是各个特征（高、富、帅、潜力、品德），输出是目标Z（能否成为富豪女婿），得分函数为Z=w1*高+w2*富+w3*帅+w4*潜+w5*德，w1，w2…w5是权重，权重就是我们机器学习算法所要得出的，得到权重的算法有很多种。\n求权重值需要知道损失函数：\n假设得分函数已知，但是该得分函数有误差，把所有训练集中有目标的数据的损失计算出来（比如说，原来，你已知某人为某个富豪的女婿，他的各项实际得分和你的得分函数不一致，有误差），就可以得到损失函数。就是通过损失函数来对权重进行修正，找到损失函数的最小值，以得到最优的得分函数，误差最小的得分函数为最优。\n如下图，有图的损失函数的最小值容易得出，在这一点得出的得分函数即为机器学习算法的最好结果。\n左边：非凸函数 ； 右边：凸函数。\n所以说，学习微积分的目的就是来求最优化的得分函数。\n机器学习常用算法一览表：\n上面一行： Unsupervised无监督的机器学习 Supervised有监督的机器学习\n左侧 ： Continuous 连续\n： Categorical 不连续\n开源机器学习框架：Scikit-learn官网有介绍去做数据分析时的一般思路。\n【scikit-learn algorithm cheat sheet】【汉化版】scikit-learn算法选择路径图\n英文原版链接：http://scikit-learn.org/stable/tutorial/machine_learning_map/\n下面是机器学习的一些资料：\n暂时Mark出来，后期学习用到时候，仔细看。\n李航，周志华经典\nAndrew Ng 视频也不错\n林轩田较难"}
