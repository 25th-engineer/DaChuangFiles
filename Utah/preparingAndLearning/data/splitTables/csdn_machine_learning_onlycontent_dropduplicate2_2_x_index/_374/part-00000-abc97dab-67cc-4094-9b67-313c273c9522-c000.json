{"content2":"机器学习常见问题\n1) 几种模型（ SVM，LR，GBDT，EM ）的原理以及公式推导；\n2) RF,GBDT 的区别； GBDT,XgBoost的区别（烂大街的问题最好从底层原理去分析回答）；\n3) 决策树处理连续值的方法；\n4) 特征选择的方法；\n5) 过拟合的解决方法；\n6) K-means 的原理，优缺点以及改进；\n7) 常见分类模型（ SVM ，决策树，贝叶斯等）的优缺点，适用场景以及如何选型；\n8) SVM 为啥要引入拉格朗日的优化方法；\n9) 假设面试官什么都不懂，详细解释 CNN 的原理；\n10) 梯度下降的优缺点\n11) EM与K-means的关系；\n12) L1与L2的作用，区别以及如何解决L1求导困难；\n13) 如何用尽可能少的样本训练模型同时又保证模型的性能；\n14) ID3和C4.5的优缺点，树的融合(RF和GBDT)\n15) 特征提取方法，如何判断特征是否重要\n16) BP神经网络以及推导\n17) HMM模型状态推导\n18) 过拟合原因以及解决办法(深度学习同)\n19) 常见损失函数\n20）机器学习性能评价，准确率，召回率,ROC\n22）降采样，PCA，LDA\n深度学习常见问题\n1）四种激活函数区别和作用\n2）过拟合解决方法\n3）(CNN)卷及神经网络各层作用\n4）(RNN)循环神经网络\n5）LSTM\n6）梯度弥散\n7）优化算法 adam，SGD等\n8）分析Alexnet,VGG的网络结构以及各层作用\n9）XgBoost(好像很多公司也面到了)\n10)梯度下降的优化\n12）卷积核参数计算\n算法工程师面试必备\n1. 成为算法工程师，应该学习哪些东西\n首先说算法工程师有几个方向：NLP，推荐，CV，深度学习，然后结合公司业务做得内容各不相同\n传统机器学习算法：感知机，SVM，LR，softmax，Kmeans，DBSCAN，决策树（CART，ID3，C45），GBDT，RF，Adaboost，xgboost，EM，BP神经网络，朴素贝叶斯，LDA，PCA，核函数，最大熵等\n深度学习：CNN，RNN，LSTM，常用激活函数，Adam等优化算法，梯度消失（爆炸）等\n推荐系统：itemBasedCF，userBasedCF，冷启动，SVD（各种变形），FM，LFM等\nNLP：TF-IDF，textrank，word2vec(能推导，看过源码)，LCA，simhash\n常见概念：最大似然估计，最小二乘法，模型融合方法，L1L2正则（Lasso，elestic net），判别式模型与生成式模型，熵-交叉熵-KL散度，数据归一化，最优化方法（梯度下降，牛顿法，共轭梯度法），无偏估计，F1（ROC，recall，precision等），交叉验证，bias-variance-tradeoff，皮尔逊系数，\n概率论，高数，线性代数（像我一样懒的人，就可以遇到哪里复习哪里，:D）\n常见问题（具体答案去搜知乎或者百度，最好能在实际项目中总结出来）：\n常见损失函数\nSGD与BGD\n如何处理样本非均衡问题\n过拟合原因，以及解决办法\n如何处理数据缺失问题\n如何选择特征\nL1为什么能让参数稀疏，L2为什么会让参数趋于较小值，L1优化方法\n各模型的优缺点，以及适用场景\n学明白上述所有内容你需要多长时间？反正我这么笨的人用了不到一年时间（我本科完全没接触过算法相关，完全是研一学的）\n2. 推荐书籍\nC++：《C++primer5》《STL源码分析》《深度探索C++对象模型》《Effective C++》《Effective STL》 （虽然有些书有点老，不过开卷有益吧）（其他语言就不管了哈）\npython：《python学习手册》《python源码分析》《改善python程序的91个建议》（Python必须要会）\n刷题：《编程之美》《剑指offer》《程序员代码面试指南》《leetcode》\n算法相关：《统计学习方法》（这本多看）《数据挖掘导论》《数学之美》《田林轩视频》《吴恩达视频》《西瓜书》\n参考文献：机器学习面试总结（具体的问题我很早之前在简书上写过）"}
