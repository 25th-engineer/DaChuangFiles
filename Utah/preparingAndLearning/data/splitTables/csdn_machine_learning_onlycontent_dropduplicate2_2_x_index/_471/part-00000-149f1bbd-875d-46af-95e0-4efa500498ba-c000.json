{"content2":"自带的机器学习库\nmeas:测试数据，一行代表一个样本，列代表样本属性，N*M\nspecies:每个样本对应的类,N*1\nkfoldLoos:交叉验证:确定样本训练后的模型的错误率\npredict:测试集经分类模型处理后分到的类\nknn分类器\nknn = fitcknn(meas,species,'NumNeighbors',5); CVMdl = crossval(knn); kloss = kfoldLoss(CVMdl); predict(knn,ones(1,size(meas,2)))\npca降维：主成分分析\n//latent:特征值（从大到小),score特征向量 [coeff, score, latent, tsquared, explained] = pca(data); //score即为从大到小排序后的特征矩阵，取前k列即为取样本最具代表性的k个属性 //explained即为每一列对应的影响力，所有列加起来为100\nbp神经网络\n命令行输入nntool\nsvm分类器\nsvm = fitcsvm(meas,species); CVMdl = crossval(svm); kloss = kfoldLoss(CVMdl);\n朴素贝叶斯\nnaivebayes = fitcnb(meas, species); nb = crossval(naivebayes); kloss = kfoldLoss(nb);\n决策树cart分类器\ncart = fitctree(meas,species); CVMdl = crossval(cart); kloss = kfoldLoss(CVMdl);\n随机森林分类器\nb = TreeBagger(nTree,meas,species,'OOBPrediction','on'); rf = oobError(b); kloss = rf(nTree,1);\n集成学习方法\nada = fitensemble(meas,species,'AdaBoostM1',100,'Tree','Holdout',0.5); kloss = kfoldLoss(ada,'mode','cumulative'); kloss = kloss(100,1);\nmatlab机器学习库\n有监督学习\n无监督学习\n集成学习"}
