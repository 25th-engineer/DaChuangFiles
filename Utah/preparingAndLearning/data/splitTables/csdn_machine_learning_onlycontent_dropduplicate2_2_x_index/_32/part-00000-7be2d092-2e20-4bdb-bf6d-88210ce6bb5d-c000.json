{"content2":"1、KNN算法原理\nK近邻分类器可以说是目前为止最简单的机器学习和图像分类算法。实际上，由于其过于简单，算法不“学习”任何东西，取而代之的是这个算法直接依赖于特征向量之间的距离。\n具体来说，就是将所有数据样本的特征向量直接存储下来，然后基于某种相似性度量准则，查询与当前样本最近似的k个样本来进行投票，将投票结果作为最终的分类结果，翻译过来就是：“告诉我你的邻居是谁，我将告诉你，你是谁。”\n为了保证KNN算法能够工作，这里做了一个假设，有相似内容的图片在n维空间上距离较近。因此，我们可以看一下表示猫、狗和熊猫三个类别的图片，如所示，x轴表示图片分布的蓬松性，y轴表示动物外观。\n\n为了应用KNN分类器进行分类，需要预先设定相似性度量准则，常见的度量准则有欧拉距离和曼哈顿距离，欧拉距离定义如式(1)所示。\n曼哈顿距离或  距离如式(2)所示。\n实际上，你可以选择最符合你数据的任何度量相似性准则（给你最好的分类结果）。\n2、KNN算法流程\n1) 收集数据集：获取样本图像，并将所有样本的大小都规范化到同一个尺寸；\n2) 分离数据集：将样本分为训练集和测试集两个部分；\n3) 训练分类器：使用训练样本集训练KNN分类器，其实就是将训练集存下来；\n4) 评估分类器：使用测试集来评估训练好的KNN分类器性能。\nKNN算法实例如所示。\nKNN算法实例（摘自参考资料[1]）\n中就是样本分布示意，当一张猫图像（红色边界）来了，首先，找最近似的K（这里K=3）个训练样本，然后，利用这K个样本进行投票（这里K个样本中，2个为猫，1个为熊猫），最后，得出结论，当前样本为猫。\n3、代码实现\nimport cv2 import struct import operator import numpy as np class KNN(object): def __init__(self, k, pathOfTrainingData, pathOfTrainingLabel, pathOfTestingData, pathOfTestingLabel, numOfTrainingData, dimOfTrainingData, numOfTestingData, dimOfTestingData): self._k = k self._pathOfTrainingData = pathOfTrainingData self._pathOfTrainingLabel= pathOfTrainingLabel self._pathOfTestingData = pathOfTestingData self._pathOfTestingLabel = pathOfTestingLabel self._numOfTrainingData = numOfTrainingData self._dimOfTrainingData = dimOfTrainingData self._numOfTestingData = numOfTestingData self._dimOfTestingData = dimOfTestingData self._trainingData = 0.1*np.random.randn(self._numOfTrainingData, self._dimOfTrainingData) self._trainingLabel = 0.1*np.random.randn(self._numOfTrainingData, 1) self._testingData = 0.1*np.random.randn(self._numOfTestingData, self._dimOfTestingData) self._testingLabel = 0.1*np.random.randn(self._numOfTestingData, 1) # normalize the vector def vectorNormalized(self, vec): minVal = np.min(vec) maxVal = np.max(vec) # print minVal, maxVal m = vec.shape[1] normVec = vec.copy() normVec = vec - np.tile(minVal, (1, m)) normVec = vec / np.tile(maxVal - minVal, (1, m)) return normVec # read the data of mnist def readMnistData(self): binfile = open(self._pathOfTrainingData , 'rb') buf = binfile.read() index = 0 #'>IIII'使用大端法读取四个unsigned int32 magic, numImages , numRows , numColumns = struct.unpack_from('>IIII' , buf , index) print(magic, numImages) index += struct.calcsize('>IIII') for i in range(self._numOfTrainingData): # upack_from从流中截取784位数据（图片像素值） im = struct.unpack_from('>784B' ,buf, index) index += struct.calcsize('>784B') im = np.array(im) im = im.reshape(1,784) imNormlized = self.vectorNormalized(im) self._trainingData[i,:] = imNormlized.copy() binfile.close() binfile = open(self._pathOfTrainingLabel , 'rb') buf = binfile.read() index = 0 magic, numLabels = struct.unpack_from('>II' , buf , index) print(magic, numLabels) index += struct.calcsize('>II') for i in range(self._numOfTrainingData): numtemp = struct.unpack_from('1B' ,buf, index) num = numtemp[0] self._trainingLabel[i] = num index += struct.calcsize('1B') binfile.close() binfile = open(self._pathOfTestingData , 'rb') buf = binfile.read() index = 0 #'>IIII'使用大端法读取四个unsigned int32 magic, numImages , numRows , numColumns = struct.unpack_from('>IIII' , buf , index) print(magic, numImages) index += struct.calcsize('>IIII') for i in range(self._numOfTestingData): # upack_from从流中截取784位数据（图片像素值） im = struct.unpack_from('>784B' ,buf, index) index += struct.calcsize('>784B') im = np.array(im) im = im.reshape(1,784) imNormlized = self.vectorNormalized(im) self._testingData[i,:] = imNormlized.copy() binfile.close() binfile = open(self._pathOfTestingLabel , 'rb') buf = binfile.read() index = 0 magic, numLabels = struct.unpack_from('>II' , buf , index) print(magic, numLabels) index += struct.calcsize('>II') for i in range(self._numOfTestingData): numtemp = struct.unpack_from('1B' ,buf, index) num = numtemp[0] self._testingLabel[i] = num index += struct.calcsize('1B') binfile.close() def classify(self): errorCount = 0.0 for i in range(self._numOfTestingData): testData = self._testingData[i,:].copy() # get the current data diffMat = np.tile(testData,(self._numOfTrainingData, 1)) - self._trainingData sqDiffMat = diffMat ** 2 sqDistances = np.sum(sqDiffMat, axis = 1) # add the elements of every row distances = sqDistances ** 0.5 sortedDistIndices = np.argsort(distances) classCount = np.zeros(10, dtype = np.int32) for j in range(self._k): voteILabel = self._trainingLabel[sortedDistIndices[j]] # get the ith voted result classCount[voteILabel.astype(int)] = classCount[voteILabel.astype(int)] + 1 sortedClassCountIndices = np.argsort(classCount) if(sortedClassCountIndices[9] != self._testingLabel[i].astype(int)): errorCount = errorCount + 1 print(errorCount / self._numOfTestingData) pathOfTrainingData = './/data//train-images.idx3-ubyte' pathOfTrainingLabel = './/data//train-labels.idx1-ubyte' pathOfTestingData = './/data//t10k-images.idx3-ubyte' pathOfTestingLabel = './/data//t10k-labels.idx1-ubyte' knn = KNN(3, pathOfTrainingData, pathOfTrainingLabel, pathOfTestingData, pathOfTestingLabel, 60000, 784, 10000, 784) knn.readMnistData() knn.classify()\n~~~~未完待续~~~~\n参考资料：\n[1] Deep_Learning_for_Computer_Vision_with_Python\n[2] 机器学习实战"}
