{"content2":"本章概括\n本章介绍模型评估与选择，包括：\n1. 误差产生：过拟合和欠拟合\n2. 评估方法：给定数据集后如何产生训练集和测试集\n3. 性能度量：建立衡量模型泛化能力的评价标准\n4. 比较检验：从统计角度比较机器学习性能\n5. 偏差与方差：解释学习算法泛化性能的一种工具\n第2章 模型评估与选择\n经验误差与过拟合\n评估方法\n性能度量\n错误率与精度\n查准率查全率与F1\nROC与AUC\n代价敏感错误率与代价曲线\n比较检验\n假设检验\n偏差与方差\n第2章 模型评估与选择\n经验误差与过拟合\n一般来说，学习器的预测输出和实际真实的输出是有差异的，称为误差。\n如果学习器学的太差，对训练样本的一般性质没学好，则称为欠拟合underfitting。\n相反，如果学的「太好」，把训练样本自身的一些特点当成了所有潜在样本都具有的一般性质，这种情况称为过拟合overfitting。\n欠拟合比较容易克服，往往因为学习器学习能力太强大导致的过拟合很难处理，实际上过拟合是机器学习面临的关键障碍。首先必须认识到，过拟合无法避免，我们需要做的是降低或者缓解。\n从理论上讲，\n机器学习面临的问题通常是NP难或者更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获得最优解，这就意味着我们构造性地证明了\nP=NP\nP=NP。因此只要相信\nP≠NP\nP\\neq NP，过拟合就不可避免。\n评估方法\n评估方法主要考虑的是在给定了数据集D后如何产生训练集S和测试集T。\n一般方法有留出法hold-out，交叉验证法和自助法。\n留出法也即\nS∪T=D,S∩T=∅\nS\\cup T = D, S \\cap T = \\varnothing 。\n交叉验证法也就是将数据集划分为\nk\nk个大小相似的数据集，即\nD1∪...∪Dk=D,D1∩...∩Dk=∅\nD_1\\cup ...\\cup D_k=D, D_1\\cap ...\\cap D_k=\\varnothing。然后取其中一份为测试集，其余为训练集，进行\nk\nk次训练和测试，即可得到平均结果。\n自助法以自助采样为基础，假设数据集D有m个样本，对数据集D做\nm\nm次独立放回的采样得到数据集\nD′\nD'。\n简单分析一下m次都没被去到概率是\n(1−1m)m\n(1-\\dfrac{1}{m})^m，对m取极限可知D中约有36.8%的样本不会出现在\nD′\nD'中。这样，就可以把\nD′\nD'当做训练集，\nD∖D′\nD\\backslash D'就是测试集了。\n如何选择方法？\n一般来说自助法比较适合数据集较小，难以有效划分训练/测试集的情况。而如果初始数据集比较足够时，留出法和交叉验证法更常用。\n性能度量\n一句话总结，性能度量就是建立衡量模型泛化能力的评价标准。\n回归任务最常用的性能度量是均方误差mean squared error\nE(f;D)=1m∑i=1m(f(xi)−yi)2\nE(f; D) = \\dfrac{1}{m}\\sum_{i=1}^m(f(x_i)-y_i)^2\n以下介绍分类任务常用的性能度量。\n1. 错误率与精度\n2. 查准率precision、查全率recall与F1\n3. ROC与AUC\n4. 代价敏感错误率与代价曲线\n错误率与精度\n错误率与精度自然就是算比例，最简单。\n不过不能满足所有的任务需求，比如挑瓜，错误率相当于是有多少比例的瓜被判别错误。但如果需要知道挑出来的瓜有多少比例是好瓜，或者所有好瓜中有多少比例被挑了出来，就需要第二个性能度量了。\n查准率、查全率与F1\n所谓的查准率P和查全率R分别定义为：\nP=TPTP+FP,R=TPTP+FN\nP=\\dfrac{TP}{TP+FP}, R=\\dfrac{TP}{TP+FN}\n变量是分类结果的混淆矩阵confusion matrix，表示为下表：\n真实情况\n预测结果正例\n预测结果反例\n正例\nTP（真正例）\nFN（反正例）\n反例\nFP（假正例）\nTN（真反例）\n所以它适用于二分类问题。查准率也就是在所有预测结果为正例的情况下的真实比例。查全率是所有真实情况为正例的情况下预测正确的比例。\nP和R是一对矛盾度量，所以一般会综合两方面考量学习器的好坏，找到最佳平衡点BEP（Break-Even Point）。衡点定义是查全率等于查准率时的取值。\nBEP过于简化，更常用的是F1变量，本质上是P和R的调和平均。\n1F1=12(1P+1R)\n\\dfrac{1}{F1} = \\dfrac{1}{2}(\\dfrac{1}{P}+\\dfrac{1}{R})\n具体应用中可能对P和R有不同的倚重。比如商品推荐中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，这时候查准率更重要。而在逃犯检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要。\nF1度量的一般形式\nFβ\nF_{\\beta}就可以表达这种偏好。\n1Fβ=11+β2(1P+β2R)\n\\dfrac{1}{F_\\beta} = \\dfrac{1}{1+\\beta^2}(\\dfrac{1}{P}+\\dfrac{\\beta^2}{R})\n也即是\nFβ=(1+β2)PRβ2P+R\nF_{\\beta}=\\dfrac{(1+\\beta^2)PR}{\\beta^2P+R}\n当\nβ>1\n\\beta>1意味着P占比重更大，反之则是R。\nROC与AUC\n考虑样本预测排序，见书P33-35\n代价敏感错误率与代价曲线\n本质上就是为权衡不同类型错误所造成的不同损失，可为错误赋予非均等代价unequal cost。\n比较检验\n比较机器学习的性能不能直接通过度量值比较得出结果。统计假设检验为机器学习性能比较提供重要依据。\n简单来说，若在测试集上观察到学习器A比B好，基于假设检验结果则能知道A的泛化性能是否在统计意义上优于B，以及这个结论的把握有多大。\n统计检验有四种方法：假设检验、交叉验证t检验、McNemar检验、Friedman检验与Nemenyi后续检验。\n以下介绍假设检验，其余方法见书P40-44。\n假设检验\n以错误率为性能度量，假设测试错误率为\nϵ̂\n\\hat{\\epsilon}，泛化错误率为\nϵ\n\\epsilon。由二项分布（独立采样基础上）知，泛化错误率为\nϵ\n\\epsilon的学习器被测得测试错误率为\nϵ̂\n\\hat{\\epsilon}的概率为：\nP(ϵ̂ ;ϵ)=Cϵ̂ xmmϵϵ̂ xm(1−ϵ)m−ϵ̂ xm\nP(\\hat{\\epsilon};\\epsilon)=C_m^{\\hat{\\epsilon}xm}\\epsilon^{\\hat{\\epsilon}xm}(1-\\epsilon)^{m-\\hat{\\epsilon}xm}\n概率函数对\nϵ\n\\epsilon求导可知当\nϵ̂ =ϵ\n\\hat{\\epsilon}=\\epsilon是概率最大。\n假设检验需要做的就是假设\nϵ≤ϵ0\n\\epsilon\\leq\\epsilon_0在\nα\n\\alpha的显著度下能否被拒绝。\nϵ0\n\\epsilon_0是给定的一个概率值，意味着泛化错误率不能小于\nϵ0\n\\epsilon_0，\nα\n\\alpha也是一个值，常用取值是0.05。如果不能被拒绝，也就意味着有95%的置信度认为学习器的泛化错误率不大于\nϵ0\n\\epsilon_0。\n比如\nϵ0=0.3\n\\epsilon_0=0.3，根据二项分布，如果是10个样本，那么有3个错误分类的概率最大。\n具体计算时只需把错误样本数大于3的概率求和，看是否小于\nα\n\\alpha即可。\n偏差与方差\n通过实验可以估计学习算法的泛化性能，另一方面通过偏差与方差可以了解为什么具有这样的性能，偏差-方差分解bias-variance decomposition就是用来解释学习算法泛化性能的一种工具，试图拆解期望泛化错误率。\n对测试样本x，定义\n1.\nyD\ny_D为x在数据集中的标记，\ny\ny为x的真实标记（有可能出现噪声使得两者不等）\n2. f(x;D)为训练集D上学的模型f在x上的预测输出\n3. 噪声\nϵ2=ED[(yD−y)2]\n\\epsilon^2=E_D[(y_D-y)^2]，这里假设噪声期望为零，即\nED[yD−y]=0\nE_D[y_D-y]=0\n4. 偏差：期望输出与真实标记的差别\nbias2(x)=(f¯(x)−y)2\nbias^2(x)=(\\bar f(x)-y)^2\n5. 使用样本数相同的不同训练集产生的方差\nvar(x)=ED[(f(x;D)−f¯(x))2]\nvar(x)=E_D[(f(x;D)-\\bar f(x))^2]\n以回归任务为例，学习算法的期望预测为\nf(x)=ED[f(x);D]\nf(x)=E_D[f(x);D]\n通过多项式展开合并，可将算法的期望泛化误差拆解为偏差、方差和噪声之和。（推导见书P45）\n也即有\nE(f;D)=bias2(x)+var(x)+ϵ2\nE(f;D)=bias^2(x)+var(x)+\\epsilon^2\n回顾三者的定义，\n1. 偏差：度量学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力\n2. 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响\n3. 噪声：表达了当前任务下任何学习算法所能达到的期望泛化误差的下限，即刻画了学习问题本身的难度\n当学习器刚开始学习时，因为学习程度不足，偏差会主导泛化错误率，随着学习器拟合能力逐渐增强，数据集发生的扰动会被学习到，这时方差开始主导泛化错误率。在最后拟合能力非常强的情况下训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。"}
