{"content2":"机器学习常见评价指标：AUC、Precision、Recall、F-measure、Accuracy\n主要内容\nAUC的计算\nPrecision、Recall、F-measure、Accuracy的计算\n1、AUC的计算\nAUC是一个模型评价指标，用于二分类模型的评价。AUC是“Area under Curve（曲线下的面积）”的英文缩写，而这条“Curve（曲线）”就是ROC曲线。\n为什么要用AUC作为二分类模型的评价指标呢？为什么不直接通过计算准确率来对模型进行评价呢？答案是这样的：机器学习中的很多模型对于分类问题的预测结果大多是概率，即属于某个类别的概率，如果计算准确率的话，就要把概率转化为类别，这就需要设定一个阈值，概率大于某个阈值的属于一类，概率小于某个阈值的属于另一类，而阈值的设定直接影响了准确率的计算。使用AUC可以解决这个问题，接下来详细介绍AUC的计算。\n例如，数据集一共有5个样本，真实类别为（1，0，0，1，0）；二分类机器学习模型，得到的预测结果为（0.5，0.6，0.4，0.7，0.3）。将预测结果转化为类别——预测结果降序排列，以每个预测值（概率值）作为阈值，即可得到类别。计算每个阈值下的“True Positive Rate”、“False Positive Rate”。以“True Positive Rate”作为纵轴，以“False Positive Rate”作为横轴，画出ROC曲线，ROC曲线下的面积，即为AUC的值。\n那么什么是“True Positive Rate”、“False Positive Rate”？\n首先，我们看如下的图示：\n然后，我们计算两个指标的值：\nTruePositiveRate=TPTP+FN\nTrue Positive Rate = \\frac{TP}{TP+FN}，代表将真实正将本划分为正样本的概率\nFalsePositiveRate=FPFP+TN\nFalse Positive Rate = \\frac{FP}{FP+TN}，代表将真实负样本划分为正样本的概率\n接着，我们以“True Positive Rate”作为纵轴，以“False Positive Rate”作为横轴，画出ROC曲线，ROC曲线下的面积，即为AUC的值。类似下图：\n2、Precision、Recall、F-measure、Accuracy的计算\n首先，我们看如下图示（与上边的图示相同）：\n精确率（Precision）：\nPrecision=TPTP+FP\nPrecision=\\frac{TP}{TP+FP}\n召回率（Recall）：\nRecall=TPTP+FN\nRecall=\\frac{TP}{TP+FN}\nF-measure：\nF−measure=2×Precision×RecallPrecision+Recall\nF-measure=\\frac{2\\times Precision\\times Recall}{Precision+Recall}\n准确率（Accuracy）：\nAccuracy=TP+TNTP+TN+FP+FN\nAccuracy=\\frac{TP+TN}{TP+TN+FP+FN}\n关于聚类的评价指标可以参考文章：\nClustering Algorithms and Evaluations\nEvaluation of clustering\nF-measure、RI 的计算"}
