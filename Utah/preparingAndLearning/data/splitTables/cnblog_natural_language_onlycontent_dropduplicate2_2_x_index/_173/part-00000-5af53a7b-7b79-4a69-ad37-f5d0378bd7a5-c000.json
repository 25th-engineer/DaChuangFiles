{"content2":"Python自然语言处理学习笔记(41)：5.2 标注语料库\n5.2   Tagged Corpora 标注语料库\nRepresenting Tagged Tokens 表示标注的语言符号\nBy convention in NLTK, a tagged token is represented using a tuple consisting of the token and the tag. We can create one of these special tuples from the standard string representation of a tagged token, using the function str2tuple():\n>>> tagged_token = nltk.tag.str2tuple('fly/NN')\n>>> tagged_token\n('fly', 'NN')\n>>> tagged_token[0]\n'fly'\n>>> tagged_token[1]\n'NN'\nWe can construct a list of tagged tokens directly from a string. The first step is to tokenize the string to access the individual word/tag strings, and then to convert each of these into a tuple (using str2tuple()).\n>>> sent = '''\n... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n... '''\n>>> [nltk.tag.str2tuple(t) for t in sent.split()]\n[('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'), ('commented', 'VBD'),\n('on', 'IN'), ('a', 'AT'), ('number', 'NN'), ... ('.', '.')]\nReading Tagged Corpora 读取已标注的语料库\nSeveral of the corpora included with NLTK have been tagged for their part-of-speech. Here's an example of what you might see if you opened a file from the Brown Corpus with a text editor:\nThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd / no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\nOther corpora use a variety of formats for storing part-of-speech tags. NLTK's corpus readers provide a uniform interface so that you don't have to be concerned with the different file formats. In contrast with the file extract shown above, the corpus reader for the Brown Corpus represents the data as shown below. Note that part-of-speech tags have been converted to uppercase, since this has become standard practice（标准惯例） since the Brown Corpus was published.\n>>> nltk.corpus.brown.tagged_words()\n[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ...]\n>>> nltk.corpus.brown.tagged_words(simplify_tags=True)\n[('The', 'DET'), ('Fulton', 'N'), ('County', 'N'), ...]\nWhenever a corpus contains tagged text, the NLTK corpus interface will have a tagged_words() method. Here are some more examples, again using the output format illustrated for the Brown Corpus:\n>>> print nltk.corpus.nps_chat.tagged_words()\n[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ...]\n>>> nltk.corpus.conll2000.tagged_words()\n[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ...]\n>>> nltk.corpus.treebank.tagged_words()\n[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]\nNot all corpora employ the same set of tags; see the tagset help functionality and the readme() methods mentioned above for documentation. Initially we want to avoid the complications of these tagsets, so we use a built-in mapping to a simplified tagset:\n>>> nltk.corpus.brown.tagged_words(simplify_tags=True)\n[('The', 'DET'), ('Fulton', 'NP'), ('County', 'N'), ...]\n>>> nltk.corpus.treebank.tagged_words(simplify_tags=True)\n[('Pierre', 'NP'), ('Vinken', 'NP'), (',', ','), ...]\nTagged corpora for several other languages are distributed with NLTK, including Chinese, Hindi, Portuguese, Spanish, Dutch and Catalan. These usually contain non-ASCII text, and Python always displays this in hexadecimal when printing a larger structure such as a list.\n>>> nltk.corpus.sinica_treebank.tagged_words()\n[('\\xe4\\xb8\\x80', 'Neu'), ('\\xe5\\x8f\\x8b\\xe6\\x83\\x85', 'Nad'), ...]\n>>> nltk.corpus.indian.tagged_words()\n[('\\xe0\\xa6\\xae\\xe0\\xa6\\xb9\\xe0\\xa6\\xbf\\xe0\\xa6\\xb7\\xe0\\xa7\\x87\\xe0\\xa6\\xb0', 'NN'),\n('\\xe0\\xa6\\xb8\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa6\\xbe\\xe0\\xa6\\xa8', 'NN'),\n...]\n>>> nltk.corpus.mac_morpho.tagged_words()\n[('Jersei', 'N'), ('atinge', 'V'), ('m\\xe9dia', 'N'), ...]\n>>> nltk.corpus.conll2002.tagged_words()\n[('Sao', 'NC'), ('Paulo', 'VMI'), ('(', 'Fpa'), ...]\n>>> nltk.corpus.cess_cat.tagged_words()\n[('El', 'da0ms0'), ('Tribunal_Suprem', 'np0000o'), ...]\nIf your environment is set up correctly, with appropriate editors and fonts, you should be able to display individual strings in a human-readable way. For example,Figure 5.1 shows data accessed using nltk.corpus.indian.\nFigure 5.1: POS-Tagged Data from Four Indian Languages: Bangla, Hindi, Marathi, and Telugu\nIf the corpus is also segmented into sentences, it will have a tagged_sents() method that divides up the tagged words into sentences rather than presenting them as one big list. This will be useful when we come to developing automatic taggers, as they are trained and tested on lists of sentences, not words.\nA Simplified Part-of-Speech Tagset   简化的词性标记集合\nTagged corpora use many different conventions for tagging words. To help us get started, we will be looking at a simplified tagset (shown in Table 5.1).\nTag\nMeaning\nExamples\nADJ\nadjective\nnew, good, high, special, big, local\nADV\nadverb\nreally, already, still, early, now\nCNJ\nconjunction\nand, or, but, if, while, although\nDET\ndeterminer\nthe, a, some, most, every, no\nEX\nexistential\nthere, there's\nFW\nforeign word\ndolce, ersatz, esprit, quo, maitre\nMOD\nmodal verb\nwill, can, would, may, must, should\nN\nnoun\nyear, home, costs, time, education\nNP\nproper noun\nAlison, Africa, April, Washington\nNUM\nnumber\ntwenty-four, fourth, 1991, 14:24\nPRO\npronoun\nhe, their, her, its, my, I, us\nP\npreposition\non, of, at, with, by, into, under\nTO\nthe word to\nto\nUH\ninterjection\nah, bang, ha, whee, hmpf, oops\nV\nverb\nis, has, get, do, make, see, run\nVD\npast tense\nsaid, took, told, made, asked\nVG\npresent participle\nmaking, going, playing, working\nVN\npast participle\ngiven, taken, begun, sung\nWH\nwh determiner\nwho, which, when, what, where, howTable 5.1:\nSimplified Part-of-Speech Tagset\nLet's see which of these tags are the most common in the news category of the Brown corpus:\n>>> from nltk.corpus import brown\n>>> brown_news_tagged = brown.tagged_words(categories='news', simplify_tags=True)\n>>> tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n>>> tag_fd.keys()\n['N', 'P', 'DET', 'NP', 'V', 'ADJ', ',', '.', 'CNJ', 'PRO', 'ADV', 'VD', ...]\nNote\nYour Turn: Plot the above frequency distribution using tag_fd.plot(cumulative=True). What percentage of words are tagged using the first five tags of the above list?   60%\nWe can use these tags to do powerful searches using a graphical POS-concordance tool nltk.app.concordance(). Use it to search for any combination of words and POS tags, e.g. N N N N, hit/VD, hit/VN, or the ADJ man.\nNouns 名词\nNouns generally refer to people, places, things, or concepts, e.g.: woman, Scotland, book, intelligence. Nouns can appear after determiners and adjectives, and can be the subject or object of the verb, （名词可以出现在限定词和形容词之后，并且可以做动词的主语或宾语）as shown in Table 5.2.\nWord\nAfter a determiner\nSubject of the verb\nwoman\nthe woman who I saw yesterday ...\nthe woman sat down\nScotland\nthe Scotland I remember as a child ...\nScotland has five million people\nbook\nthe book I bought yesterday ...\nthis book recounts the colonization of Australia\nintelligence\nthe intelligence displayed by the child ...\nMary's intelligence impressed her teachersTable 5.2:\nSyntactic Patterns involving some Nouns\nThe simplified noun tags are N for common nouns like book, and NP for proper nouns like Scotland.\nLet's inspect some tagged text to see what parts of speech occur before a noun, with the most frequent ones first. To begin with, we construct a list of bigrams whose members are themselves word-tag pairs such as (('The', 'DET'), ('Fulton', 'NP')) and (('Fulton', 'NP'), ('County', 'N')). Then we construct a FreqDist from the tag parts of the bigrams.\n>>> word_tag_pairs = nltk.bigrams(brown_news_tagged)\n>>> list(nltk.FreqDist(a[1] for (a, b) in word_tag_pairs if b[1] == 'N'))\n['DET', 'ADJ', 'N', 'P', 'NP', 'NUM', 'V', 'PRO', 'CNJ', '.', ',', 'VG', 'VN', ...]\n(a,b)也就是(('The', 'DET'), ('Fulton', 'NP'))，如果b[1]==’N’，则给出前面这个词的词性a[1]\nThis confirms our assertion that nouns occur after determiners and adjectives, including numeral adjectives (tagged as NUM).\nVerbs 动词\nVerbs are words that describe events and actions, e.g. fall, eat in Table 5.3. In the context of a sentence, verbs typically express a relation involving the referents of one or more noun phrases.\nWord\nSimple\nWith modifiers and adjuncts (italicized)\nfall\nRome fell\nDot com stocks suddenly fell like a stone\neat\nMice eat cheese\nJohn ate the pizza with gustoTable 5.3:\nSyntactic Patterns involving some Verbs\nWhat are the most common verbs in news text? Let's sort all the verbs by frequency:\n>>> wsj = nltk.corpus.treebank.tagged_words(simplify_tags=True)\n>>> word_tag_fd = nltk.FreqDist(wsj)\n>>> [word + \"/\" + tag for (word, tag) in word_tag_fd if tag.startswith('V')]\n['is/V', 'said/VD', 'was/VD', 'are/V', 'be/V', 'has/V', 'have/V', 'says/V',\n'were/VD', 'had/VD', 'been/VN', \"'s/V\", 'do/V', 'say/V', 'make/V', 'did/VD',\n'rose/VD', 'does/V', 'expected/VN', 'buy/V', 'take/V', 'get/V', 'sell/V',\n'help/V', 'added/VD', 'including/VG', 'according/VG', 'made/VN', 'pay/V', ...]\nNote that the items being counted in the frequency distribution are word-tag pairs. Since words and tags are paired, we can treat the word as a condition and the tag as an event, and initialize a conditional frequency distribution with a list of condition-event pairs. This lets us see a frequency-ordered list of tags given a word:\n>>> cfd1 = nltk.ConditionalFreqDist(wsj)\n>>> cfd1['yield'].keys()\n['V', 'N']\n>>> cfd1['cut'].keys()\n['V', 'VD', 'N', 'VN']\nWe can reverse the order of the pairs, so that the tags are the conditions, and the words are the events（词作为条件，标签作为事件）. Now we can see likely words for a given tag:\n>>> cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n>>> cfd2['VN'].keys()\n['been', 'expected', 'made', 'compared', 'based', 'priced', 'used', 'sold',\n'named', 'designed', 'held', 'fined', 'taken', 'paid', 'traded', 'said', ...]\nTo clarify the distinction between VD (past tense) and VN (past participle), let's find words which can be both VD and VN, and see some surrounding text:\n>>> [w for w in cfd1.conditions() if 'VD' in cfd1[w] and 'VN' in cfd1[w]]\n['Asked', 'accelerated', 'accepted', 'accused', 'acquired', 'added', 'adopted', ...]\n>>> idx1 = wsj.index(('kicked', 'VD'))\n>>> wsj[idx1-4:idx1+1]\n[('While', 'P'), ('program', 'N'), ('trades', 'N'), ('swiftly', 'ADV'),\n('kicked', 'VD')]\n>>> idx2 = wsj.index(('kicked', 'VN'))\n>>> wsj[idx2-4:idx2+1]\n[('head', 'N'), ('of', 'P'), ('state', 'N'), ('has', 'V'), ('kicked', 'VN')]\nIn this case, we see that the past participle of kicked is preceded by a form of the auxiliary verb have. Is this generally true?\nNote\nYour Turn: Given the list of past participles specified by cfd2['VN'].keys(), try to collect a list of all the word-tag pairs that immediately precede items in that list.\nAdjectives and Adverbs  形容词和副词\nTwo other important word classes are adjectives and adverbs. Adjectives describe nouns, and can be used as modifiers (e.g. large in the large pizza), or in predicates (e.g. the pizza is large). English adjectives can have internal structure (e.g. fall+ing in the falling stocks). Adverbs modify verbs to specify the time, manner, place or direction of the event described by the verb (e.g. quickly in the stocks fell quickly). Adverbs may also modify adjectives (e.g. really in Mary's teacher was really nice).\nEnglish has several categories of closed class words in addition to prepositions, such as articles (also often called determiners) (e.g., the, a), modals (e.g.,should, may), and personal pronouns (e.g., she, they). Each dictionary and grammar classifies these words differently.\nNote\nYour Turn: If you are uncertain about some of these parts of speech, study them using nltk.app.concordance(), or watch some of the Schoolhouse Rock! grammar videos available at YouTube, or consult the Further Reading section at the end of this chapter.\nUnsimplified Tags  未简化的标签\nLet's find the most frequent nouns of each noun part-of-speech type. The program in Example 5.2 finds all tags starting with NN, and provides a few example words for each one. You will see that there are many variants of NN; the most important contain $ for possessive nouns, S for plural nouns (since plural nouns typically end in s) and P for proper nouns. In addition, most of the tags have suffix modifiers: -NC for citations, -HL for words in headlines and -TL for titles (a feature of Brown tabs).\ndef findtags(tag_prefix, tagged_text):\ncfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\nif tag.startswith(tag_prefix))\nreturn dict((tag, cfd[tag].keys()[:5]) for tag in cfd.conditions())\n>>> tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))\n>>> for tag in sorted(tagdict):\n...     print tag, tagdict[tag]\n...\nNN ['year', 'time', 'state', 'week', 'man']\nNN$ [\"year's\", \"world's\", \"state's\", \"nation's\", \"company's\"]\nNN$-HL [\"Golf's\", \"Navy's\"]\nNN$-TL [\"President's\", \"University's\", \"League's\", \"Gallery's\", \"Army's\"]\nNN-HL ['cut', 'Salary', 'condition', 'Question', 'business']\nNN-NC ['eva', 'ova', 'aya']\nNN-TL ['President', 'House', 'State', 'University', 'City']\nNN-TL-HL ['Fort', 'City', 'Commissioner', 'Grove', 'House']\nNNS ['years', 'members', 'people', 'sales', 'men']\nNNS$ [\"children's\", \"women's\", \"men's\", \"janitors'\", \"taxpayers'\"]\nNNS$-HL [\"Dealers'\", \"Idols'\"]\nNNS$-TL [\"Women's\", \"States'\", \"Giants'\", \"Officers'\", \"Bombers'\"]\nNNS-HL ['years', 'idols', 'Creations', 'thanks', 'centers']\nNNS-TL ['States', 'Nations', 'Masters', 'Rules', 'Communists']\nNNS-TL-HL ['Nations']\nExample 5.2 (code_findtags.py):  Program to Find the Most Frequent Noun Tags\nWhen we come to constructing part-of-speech taggers later in this chapter, we will use the unsimplified tags.\nExploring Tagged Corpora  探索标注的语料库\nLet's briefly return to the kinds of exploration of corpora we saw in previous chapters, this time exploiting POS tags.\nSuppose we're studying the word often and want to see how it is used in text. We could ask to see the words that follow often\n>>> brown_learned_text = brown.words(categories='learned')\n>>> sorted(set(b for (a, b) in nltk.ibigrams(brown_learned_text) if a == 'often'))\n[',', '.', 'accomplished', 'analytically', 'appear', 'apt', 'associated', 'assuming',\n'became', 'become', 'been', 'began', 'call', 'called', 'carefully', 'chose', ...]\nHowever, it's probably more instructive use the tagged_words() method to look at the part-of-speech tag of the following words:\n>>> brown_lrnd_tagged = brown.tagged_words(categories='learned', simplify_tags=True)\n>>> tags = [b[1] for (a, b) in nltk.ibigrams(brown_lrnd_tagged) if a[0] == 'often']\n>>> fd = nltk.FreqDist(tags)\n>>> fd.tabulate()\nVN    V   VD DET ADJ ADV    P CNJ    ,   TO   VG   WH VBZ    .\n15   12    8    5    5    4    4    3    3    1    1    1    1    1\nNotice that the most high-frequency parts of speech following often are verbs. Nouns never appear in this position (in this particular corpus).\nNext, let's look at some larger context, and find words involving particular sequences of tags and words (in this case \"<Verb> to <Verb>\"). In code-three-word-phrase we consider each three-word window in the sentence , and check if they meet our criterion . If the tags match, we print the corresponding words .\nfrom nltk.corpus import brown\ndef process(sentence):\nfor (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):\nif (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\nprint w1, w2, w3\n>>> for tagged_sent in brown.tagged_sents():\n...     process(tagged_sent)\n...\ncombined to achieve\ncontinue to place\nserve to protect\nwanted to wait\nallowed to place\nexpected to become\n...\nExample 5.3 (code_three_word_phrase.py): Figure 5.3: Searching for Three-Word Phrases Using POS Tags\nFinally, let's look for words that are highly ambiguous as to their part of speech tag. Understanding why such words are tagged as they are in each context can help us clarify the distinctions between the tags.\n>>> brown_news_tagged = brown.tagged_words(categories='news', simplify_tags=True)\n>>> data = nltk.ConditionalFreqDist((word.lower(), tag)\n...                                 for (word, tag) in brown_news_tagged)\n>>> for word in data.conditions():\n...     if len(data[word]) > 3:\n...         tags = data[word].keys()\n...         print word, ' '.join(tags)\n...\nbest ADJ ADV NP V\nbetter ADJ ADV V DET\nclose ADV ADJ V N\ncut V N VN VD\neven ADV DET ADJ V\ngrant NP N V -\nhit V VD VN N\nlay ADJ V NP VD\nleft VD ADJ N VN\nlike CNJ V ADJ P -\nnear P ADV ADJ DET\nopen ADJ V N ADV\npast N ADJ DET P\npresent ADJ ADV V N\nread V VN VD NP\nright ADJ N DET ADV\nsecond NUM ADV DET N\nset VN V VD N -\nthat CNJ V WH DET\nNote\nYour Turn: Open the POS concordance tool nltk.app.concordance() and load the complete Brown Corpus (simplified tagset). Now pick some of the above words and see how the tag of the word correlates with the context of the word. E.g. search for near to see all forms mixed together, near/ADJ to see it used as an adjective, near N to see just those cases where a noun follows, and so forth.\n---我是低调的不显眼的简洁的不会被敌人发现的分割线--- 5.2   Tagged Corpora 标注语料库\nRepresenting Tagged Tokens 表示标注的语言符号\nBy convention in NLTK, a tagged token is represented using a tuple consisting of the token and the tag. We can create one of these special tuples from the standard string representation of a tagged token, using the function str2tuple():\n>>> tagged_token = nltk.tag.str2tuple('fly/NN')\n>>> tagged_token\n('fly', 'NN')\n>>> tagged_token[0]\n'fly'\n>>> tagged_token[1]\n'NN'\nWe can construct a list of tagged tokens directly from a string. The first step is to tokenize the string to access the individual word/tag strings, and then to convert each of these into a tuple (using str2tuple()).\n>>> sent = '''\n... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN\n... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC\n... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS\n... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB\n... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT\n... interest/NN of/IN both/ABX governments/NNS ''/'' ./.\n... '''\n>>> [nltk.tag.str2tuple(t) for t in sent.split()]\n[('The', 'AT'), ('grand', 'JJ'), ('jury', 'NN'), ('commented', 'VBD'),\n('on', 'IN'), ('a', 'AT'), ('number', 'NN'), ... ('.', '.')]\nReading Tagged Corpora 读取已标注的语料库\nSeveral of the corpora included with NLTK have been tagged for their part-of-speech. Here's an example of what you might see if you opened a file from the Brown Corpus with a text editor:\nThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd / no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\nOther corpora use a variety of formats for storing part-of-speech tags. NLTK's corpus readers provide a uniform interface so that you don't have to be concerned with the different file formats. In contrast with the file extract shown above, the corpus reader for the Brown Corpus represents the data as shown below. Note that part-of-speech tags have been converted to uppercase, since this has become standard practice（标准惯例） since the Brown Corpus was published.\n>>> nltk.corpus.brown.tagged_words()\n[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ...]\n>>> nltk.corpus.brown.tagged_words(simplify_tags=True)\n[('The', 'DET'), ('Fulton', 'N'), ('County', 'N'), ...]\nWhenever a corpus contains tagged text, the NLTK corpus interface will have a tagged_words() method. Here are some more examples, again using the output format illustrated for the Brown Corpus:\n>>> print nltk.corpus.nps_chat.tagged_words()\n[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ...]\n>>> nltk.corpus.conll2000.tagged_words()\n[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ...]\n>>> nltk.corpus.treebank.tagged_words()\n[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]\nNot all corpora employ the same set of tags; see the tagset help functionality and the readme() methods mentioned above for documentation. Initially we want to avoid the complications of these tagsets, so we use a built-in mapping to a simplified tagset:\n>>> nltk.corpus.brown.tagged_words(simplify_tags=True)\n[('The', 'DET'), ('Fulton', 'NP'), ('County', 'N'), ...]\n>>> nltk.corpus.treebank.tagged_words(simplify_tags=True)\n[('Pierre', 'NP'), ('Vinken', 'NP'), (',', ','), ...]\nTagged corpora for several other languages are distributed with NLTK, including Chinese, Hindi, Portuguese, Spanish, Dutch and Catalan. These usually contain non-ASCII text, and Python always displays this in hexadecimal when printing a larger structure such as a list.\n>>> nltk.corpus.sinica_treebank.tagged_words()\n[('\\xe4\\xb8\\x80', 'Neu'), ('\\xe5\\x8f\\x8b\\xe6\\x83\\x85', 'Nad'), ...]\n>>> nltk.corpus.indian.tagged_words()\n[('\\xe0\\xa6\\xae\\xe0\\xa6\\xb9\\xe0\\xa6\\xbf\\xe0\\xa6\\xb7\\xe0\\xa7\\x87\\xe0\\xa6\\xb0', 'NN'),\n('\\xe0\\xa6\\xb8\\xe0\\xa6\\xa8\\xe0\\xa7\\x8d\\xe0\\xa6\\xa4\\xe0\\xa6\\xbe\\xe0\\xa6\\xa8', 'NN'),\n...]\n>>> nltk.corpus.mac_morpho.tagged_words()\n[('Jersei', 'N'), ('atinge', 'V'), ('m\\xe9dia', 'N'), ...]\n>>> nltk.corpus.conll2002.tagged_words()\n[('Sao', 'NC'), ('Paulo', 'VMI'), ('(', 'Fpa'), ...]\n>>> nltk.corpus.cess_cat.tagged_words()\n[('El', 'da0ms0'), ('Tribunal_Suprem', 'np0000o'), ...]\nIf your environment is set up correctly, with appropriate editors and fonts, you should be able to display individual strings in a human-readable way. For example,Figure 5.1 shows data accessed using nltk.corpus.indian.\nFigure 5.1: POS-Tagged Data from Four Indian Languages: Bangla, Hindi, Marathi, and Telugu\nIf the corpus is also segmented into sentences, it will have a tagged_sents() method that divides up the tagged words into sentences rather than presenting them as one big list. This will be useful when we come to developing automatic taggers, as they are trained and tested on lists of sentences, not words.\nA Simplified Part-of-Speech Tagset   简化的词性标记集合\nTagged corpora use many different conventions for tagging words. To help us get started, we will be looking at a simplified tagset (shown in Table 5.1).\nTag\nMeaning\nExamples\nADJ\nadjective\nnew, good, high, special, big, local\nADV\nadverb\nreally, already, still, early, now\nCNJ\nconjunction\nand, or, but, if, while, although\nDET\ndeterminer\nthe, a, some, most, every, no\nEX\nexistential\nthere, there's\nFW\nforeign word\ndolce, ersatz, esprit, quo, maitre\nMOD\nmodal verb\nwill, can, would, may, must, should\nN\nnoun\nyear, home, costs, time, education\nNP\nproper noun\nAlison, Africa, April, Washington\nNUM\nnumber\ntwenty-four, fourth, 1991, 14:24\nPRO\npronoun\nhe, their, her, its, my, I, us\nP\npreposition\non, of, at, with, by, into, under\nTO\nthe word to\nto\nUH\ninterjection\nah, bang, ha, whee, hmpf, oops\nV\nverb\nis, has, get, do, make, see, run\nVD\npast tense\nsaid, took, told, made, asked\nVG\npresent participle\nmaking, going, playing, working\nVN\npast participle\ngiven, taken, begun, sung\nWH\nwh determiner\nwho, which, when, what, where, howTable 5.1:\nSimplified Part-of-Speech Tagset\nLet's see which of these tags are the most common in the news category of the Brown corpus:\n>>> from nltk.corpus import brown\n>>> brown_news_tagged = brown.tagged_words(categories='news', simplify_tags=True)\n>>> tag_fd = nltk.FreqDist(tag for (word, tag) in brown_news_tagged)\n>>> tag_fd.keys()\n['N', 'P', 'DET', 'NP', 'V', 'ADJ', ',', '.', 'CNJ', 'PRO', 'ADV', 'VD', ...]\nNote\nYour Turn: Plot the above frequency distribution using tag_fd.plot(cumulative=True). What percentage of words are tagged using the first five tags of the above list?   60%\nWe can use these tags to do powerful searches using a graphical POS-concordance tool nltk.app.concordance(). Use it to search for any combination of words and POS tags, e.g. N N N N, hit/VD, hit/VN, or the ADJ man.\nNouns 名词\nNouns generally refer to people, places, things, or concepts, e.g.: woman, Scotland, book, intelligence. Nouns can appear after determiners and adjectives, and can be the subject or object of the verb, （名词可以出现在限定词和形容词之后，并且可以做动词的主语或宾语）as shown in Table 5.2.\nWord\nAfter a determiner\nSubject of the verb\nwoman\nthe woman who I saw yesterday ...\nthe woman sat down\nScotland\nthe Scotland I remember as a child ...\nScotland has five million people\nbook\nthe book I bought yesterday ...\nthis book recounts the colonization of Australia\nintelligence\nthe intelligence displayed by the child ...\nMary's intelligence impressed her teachersTable 5.2:\nSyntactic Patterns involving some Nouns\nThe simplified noun tags are N for common nouns like book, and NP for proper nouns like Scotland.\nLet's inspect some tagged text to see what parts of speech occur before a noun, with the most frequent ones first. To begin with, we construct a list of bigrams whose members are themselves word-tag pairs such as (('The', 'DET'), ('Fulton', 'NP')) and (('Fulton', 'NP'), ('County', 'N')). Then we construct a FreqDist from the tag parts of the bigrams.\n>>> word_tag_pairs = nltk.bigrams(brown_news_tagged)\n>>> list(nltk.FreqDist(a[1] for (a, b) in word_tag_pairs if b[1] == 'N'))\n['DET', 'ADJ', 'N', 'P', 'NP', 'NUM', 'V', 'PRO', 'CNJ', '.', ',', 'VG', 'VN', ...]\n(a,b)也就是(('The', 'DET'), ('Fulton', 'NP'))，如果b[1]==’N’，则给出前面这个词的词性a[1]\nThis confirms our assertion that nouns occur after determiners and adjectives, including numeral adjectives (tagged as NUM).\nVerbs 动词\nVerbs are words that describe events and actions, e.g. fall, eat in Table 5.3. In the context of a sentence, verbs typically express a relation involving the referents of one or more noun phrases.\nWord\nSimple\nWith modifiers and adjuncts (italicized)\nfall\nRome fell\nDot com stocks suddenly fell like a stone\neat\nMice eat cheese\nJohn ate the pizza with gustoTable 5.3:\nSyntactic Patterns involving some Verbs\nWhat are the most common verbs in news text? Let's sort all the verbs by frequency:\n>>> wsj = nltk.corpus.treebank.tagged_words(simplify_tags=True)\n>>> word_tag_fd = nltk.FreqDist(wsj)\n>>> [word + \"/\" + tag for (word, tag) in word_tag_fd if tag.startswith('V')]\n['is/V', 'said/VD', 'was/VD', 'are/V', 'be/V', 'has/V', 'have/V', 'says/V',\n'were/VD', 'had/VD', 'been/VN', \"'s/V\", 'do/V', 'say/V', 'make/V', 'did/VD',\n'rose/VD', 'does/V', 'expected/VN', 'buy/V', 'take/V', 'get/V', 'sell/V',\n'help/V', 'added/VD', 'including/VG', 'according/VG', 'made/VN', 'pay/V', ...]\nNote that the items being counted in the frequency distribution are word-tag pairs. Since words and tags are paired, we can treat the word as a condition and the tag as an event, and initialize a conditional frequency distribution with a list of condition-event pairs. This lets us see a frequency-ordered list of tags given a word:\n>>> cfd1 = nltk.ConditionalFreqDist(wsj)\n>>> cfd1['yield'].keys()\n['V', 'N']\n>>> cfd1['cut'].keys()\n['V', 'VD', 'N', 'VN']\nWe can reverse the order of the pairs, so that the tags are the conditions, and the words are the events（词作为条件，标签作为事件）. Now we can see likely words for a given tag:\n>>> cfd2 = nltk.ConditionalFreqDist((tag, word) for (word, tag) in wsj)\n>>> cfd2['VN'].keys()\n['been', 'expected', 'made', 'compared', 'based', 'priced', 'used', 'sold',\n'named', 'designed', 'held', 'fined', 'taken', 'paid', 'traded', 'said', ...]\nTo clarify the distinction between VD (past tense) and VN (past participle), let's find words which can be both VD and VN, and see some surrounding text:\n>>> [w for w in cfd1.conditions() if 'VD' in cfd1[w] and 'VN' in cfd1[w]]\n['Asked', 'accelerated', 'accepted', 'accused', 'acquired', 'added', 'adopted', ...]\n>>> idx1 = wsj.index(('kicked', 'VD'))\n>>> wsj[idx1-4:idx1+1]\n[('While', 'P'), ('program', 'N'), ('trades', 'N'), ('swiftly', 'ADV'),\n('kicked', 'VD')]\n>>> idx2 = wsj.index(('kicked', 'VN'))\n>>> wsj[idx2-4:idx2+1]\n[('head', 'N'), ('of', 'P'), ('state', 'N'), ('has', 'V'), ('kicked', 'VN')]\nIn this case, we see that the past participle of kicked is preceded by a form of the auxiliary verb have. Is this generally true?\nNote\nYour Turn: Given the list of past participles specified by cfd2['VN'].keys(), try to collect a list of all the word-tag pairs that immediately precede items in that list.\nAdjectives and Adverbs  形容词和副词\nTwo other important word classes are adjectives and adverbs. Adjectives describe nouns, and can be used as modifiers (e.g. large in the large pizza), or in predicates (e.g. the pizza is large). English adjectives can have internal structure (e.g. fall+ing in the falling stocks). Adverbs modify verbs to specify the time, manner, place or direction of the event described by the verb (e.g. quickly in the stocks fell quickly). Adverbs may also modify adjectives (e.g. really in Mary's teacher was really nice).\nEnglish has several categories of closed class words in addition to prepositions, such as articles (also often called determiners) (e.g., the, a), modals (e.g.,should, may), and personal pronouns (e.g., she, they). Each dictionary and grammar classifies these words differently.\nNote\nYour Turn: If you are uncertain about some of these parts of speech, study them using nltk.app.concordance(), or watch some of the Schoolhouse Rock! grammar videos available at YouTube, or consult the Further Reading section at the end of this chapter.\nUnsimplified Tags  未简化的标签\nLet's find the most frequent nouns of each noun part-of-speech type. The program in Example 5.2 finds all tags starting with NN, and provides a few example words for each one. You will see that there are many variants of NN; the most important contain $ for possessive nouns, S for plural nouns (since plural nouns typically end in s) and P for proper nouns. In addition, most of the tags have suffix modifiers: -NC for citations, -HL for words in headlines and -TL for titles (a feature of Brown tabs).\ndef findtags(tag_prefix, tagged_text):\ncfd = nltk.ConditionalFreqDist((tag, word) for (word, tag) in tagged_text\nif tag.startswith(tag_prefix))\nreturn dict((tag, cfd[tag].keys()[:5]) for tag in cfd.conditions())\n>>> tagdict = findtags('NN', nltk.corpus.brown.tagged_words(categories='news'))\n>>> for tag in sorted(tagdict):\n...     print tag, tagdict[tag]\n...\nNN ['year', 'time', 'state', 'week', 'man']\nNN$ [\"year's\", \"world's\", \"state's\", \"nation's\", \"company's\"]\nNN$-HL [\"Golf's\", \"Navy's\"]\nNN$-TL [\"President's\", \"University's\", \"League's\", \"Gallery's\", \"Army's\"]\nNN-HL ['cut', 'Salary', 'condition', 'Question', 'business']\nNN-NC ['eva', 'ova', 'aya']\nNN-TL ['President', 'House', 'State', 'University', 'City']\nNN-TL-HL ['Fort', 'City', 'Commissioner', 'Grove', 'House']\nNNS ['years', 'members', 'people', 'sales', 'men']\nNNS$ [\"children's\", \"women's\", \"men's\", \"janitors'\", \"taxpayers'\"]\nNNS$-HL [\"Dealers'\", \"Idols'\"]\nNNS$-TL [\"Women's\", \"States'\", \"Giants'\", \"Officers'\", \"Bombers'\"]\nNNS-HL ['years', 'idols', 'Creations', 'thanks', 'centers']\nNNS-TL ['States', 'Nations', 'Masters', 'Rules', 'Communists']\nNNS-TL-HL ['Nations']\nExample 5.2 (code_findtags.py):  Program to Find the Most Frequent Noun Tags\nWhen we come to constructing part-of-speech taggers later in this chapter, we will use the unsimplified tags.\nExploring Tagged Corpora  探索标注的语料库\nLet's briefly return to the kinds of exploration of corpora we saw in previous chapters, this time exploiting POS tags.\nSuppose we're studying the word often and want to see how it is used in text. We could ask to see the words that follow often\n>>> brown_learned_text = brown.words(categories='learned')\n>>> sorted(set(b for (a, b) in nltk.ibigrams(brown_learned_text) if a == 'often'))\n[',', '.', 'accomplished', 'analytically', 'appear', 'apt', 'associated', 'assuming',\n'became', 'become', 'been', 'began', 'call', 'called', 'carefully', 'chose', ...]\nHowever, it's probably more instructive use the tagged_words() method to look at the part-of-speech tag of the following words:\n>>> brown_lrnd_tagged = brown.tagged_words(categories='learned', simplify_tags=True)\n>>> tags = [b[1] for (a, b) in nltk.ibigrams(brown_lrnd_tagged) if a[0] == 'often']\n>>> fd = nltk.FreqDist(tags)\n>>> fd.tabulate()\nVN    V   VD DET ADJ ADV    P CNJ    ,   TO   VG   WH VBZ    .\n15   12    8    5    5    4    4    3    3    1    1    1    1    1\nNotice that the most high-frequency parts of speech following often are verbs. Nouns never appear in this position (in this particular corpus).\nNext, let's look at some larger context, and find words involving particular sequences of tags and words (in this case \"<Verb> to <Verb>\"). In code-three-word-phrase we consider each three-word window in the sentence , and check if they meet our criterion . If the tags match, we print the corresponding words .\nfrom nltk.corpus import brown\ndef process(sentence):\nfor (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):\nif (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):\nprint w1, w2, w3\n>>> for tagged_sent in brown.tagged_sents():\n...     process(tagged_sent)\n...\ncombined to achieve\ncontinue to place\nserve to protect\nwanted to wait\nallowed to place\nexpected to become\n...\nExample 5.3 (code_three_word_phrase.py): Figure 5.3: Searching for Three-Word Phrases Using POS Tags\nFinally, let's look for words that are highly ambiguous as to their part of speech tag. Understanding why such words are tagged as they are in each context can help us clarify the distinctions between the tags.\n>>> brown_news_tagged = brown.tagged_words(categories='news', simplify_tags=True)\n>>> data = nltk.ConditionalFreqDist((word.lower(), tag)\n...                                 for (word, tag) in brown_news_tagged)\n>>> for word in data.conditions():\n...     if len(data[word]) > 3:\n...         tags = data[word].keys()\n...         print word, ' '.join(tags)\n...\nbest ADJ ADV NP V\nbetter ADJ ADV V DET\nclose ADV ADJ V N\ncut V N VN VD\neven ADV DET ADJ V\ngrant NP N V -\nhit V VD VN N\nlay ADJ V NP VD\nleft VD ADJ N VN\nlike CNJ V ADJ P -\nnear P ADV ADJ DET\nopen ADJ V N ADV\npast N ADJ DET P\npresent ADJ ADV V N\nread V VN VD NP\nright ADJ N DET ADV\nsecond NUM ADV DET N\nset VN V VD N -\nthat CNJ V WH DET\nNote\nYour Turn: Open the POS concordance tool nltk.app.concordance() and load the complete Brown Corpus (simplified tagset). Now pick some of the above words and see how the tag of the word correlates with the context of the word. E.g. search for near to see all forms mixed together, near/ADJ to see it used as an adjective, near N to see just those cases where a noun follows, and so forth."}
