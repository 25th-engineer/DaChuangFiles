{"content2":"服务机器人缺少了语音交互的话，就会让人觉得不像个机器人。在当前非常多的服务机器人上，语音交互成为一个非常大的亮点。\n当然如果我们从头做起，这样就太麻烦，还好当前有很多公司提供了解决方案。科大讯飞、百度语音等都提供了非常好的语音识别和语音合成工具。\n1.1 简介\n这里我采用图灵机器人作为语义理解的工具，搭建一个语音机器人。\n具体可以参考图灵机器人官网http://www.tuling123.com/help/h_cent_andriodsdk.jhtml?nav=doc\n大致框架如下：\n1.2 概念解释\n（1）语音识别：Automatic Speech Recognition（ASR），也称自动语音识别，其目标是将人类的语音中的词汇内容转换相应的文本。\n（2）自然语言理解：Natural Language Understanding（NLU），俗称人机对话，是人工智能的分支学科。本学科通过电子计算机模拟人的语言交际过程，从而使计算机能理解和运用人类社会的自然语言，实现人机之间的自然语言通信，进而代替人的部分脑力劳动，包括查询资料、解答问题、摘录文献、汇编资料以及一切有关自然语言信息的加工处理。\n（3）TRClient：TRClient 是一个封装了语音采集、处理、网络收发、语义理解等功能的语音识别和语义解析整体解决方案。\n（4）应用程序：在开发中使用了 TRClient，具有语音识别功能的产品线产品。\n1.3功能介绍\n（1）语音识别：将语音识别成相应的文本。\n（2）语义理解：将文本识别成领域相关的语义结果。\n（3）语音合成 : 将文本转化成语音读出\n1.4 环境搭建\n1.4.1 添加TRClient到工程\n1. 添加libs到工程\n开发者需要将Demo包中的libs目录整体Copy到工程目录，Libs目录包括了语音识别合成所需的so库以及jar包\n对于android studio的操作环境，配置jar包和so文件，\nJar包拷贝入app->libs文件\n在android studio中添加 file->project structure添加jar目录\n在app->src->main->jniLibs新建当前目录，copy->armeabi的so文件\n1.4.2 权限声明\n名称\n用途\nandroid.permission.RECORD_AUDIO\n允许使用麦克风录音\nandroid.permission.INTERNET\n允许联网，发送语音数据至服务器，获得识别结果\nandroid.permission.ACCESS_NETWORK_STATE\n允许获取当前网络状态，优化录音参数及网络参数\nandroid.permission.READ_PHONE_STATE\n允许获取用户手机的电话状态信息\nandroid.permission.MODIFY_AUDIO_SETTINGS\n允许蓝牙录音\nandroid.permission.BROADCAST_STICKY\n某些手机启动 SCO 音频连接需要此权限\nandroid.permission.BLUETOOTH\n允许蓝牙录音检测耳机状态\nandroid.permission.WRITE_SETTINGS\n允许修改和读取系统配置信息\nandroid.permission.WRITE_EXTERNAL_STORAGE\n允许向存储设备中写入\n需要在 AndroidManifest.xml 文件， 增加以上七个权限：\n<uses-permission android:name=\"android.permission.RECORD_AUDIO\" />\n<uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" />\n<uses-permission android:name=\"android.permission.INTERNET\" />\n<uses-permission android:name=\"android.permission.READ_PHONE_STATE\" />\n<uses-permission android:name=\"android.permission.MODIFY_AUDIO_SETTINGS\" />\n<uses-permission android:name=\"android.permission.BROADCAST_STICKY\" />\n<uses-permission android:name=\"android.permission.BLUETOOTH\" />\n<uses-permission android:name=\"android.permission.WRITE_SETTINGS\"/>\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\n<uses-permission android:name=\"android.permission.READ_CONTACTS\" />\n如果需要使用蓝牙设备作为输入源， 需要额外在AndroidManifest.xml 文件添加下列权限：\n<uses-permission android:name=\"android.permission.MODIFY_AUDIO_SETTINGS\"/>\n<uses-permission android:name=\"android.permission.BROADCAST_STICKY \"/>\n<uses-permission android:name=\"android.permission.BLUETOOTH \"/>\n1.4.3 Progurad配置\n如果应用配置了代码混淆， 需要在 Proguard配置文件增加以下参数：\n-keep class com.baidu.android.**{*;}\n-keep class com.baidu.voicerecognition.android.**{*;}\n-keep class com.turing.androidsdk.**{*;}\n1.5语音识别\n语音识别部分主要包括以下四个步骤\n1.5.1 实例化VoiceRecognizerManager\n实例化VoiceRecognizerManager，由于目前我们使用百度ASR方式，使用百度ASR，使用构造方法：\nVoiceRecognizerManager(Context context,String bdAPI_KEY,String bdSECRET_KEY)\n参数: bdAPI_KEY和bdSECRET_KEY\n这里的bdAPI_KEY和bdSECRET_KEY，需要自己到百度官方去申请，位置如图所示：\n百度语音开放平台的网址为：http://yuyin.baidu.com/\n1.5.2 设定ASR状态监听\n设定ASR状态监听\n示例：VoiceRecognizerManager.setVoiceRecognizeListener(listener);\n这个listener就是需要实现接口VoiceRecognizeListener，在不同的识别状态下回调其不同的方法。\n1.5.3 调用语音识别方法\n调用语音识别方法\nVoiceRecognizerManager.startRecognize();\n这个方法就是开始进行识别\n1.5.4 获取识别结果\n获取识别结果，在步骤2里listener的回调方法onRecognizeResult中获取识别结果。\npublic void onRecognizeResult(String result)\n{\nhandleRecognizeResult(result);\n}\n这里的result就是返回的结果\n1.6 语义理解\n语义理解部分主要包括以下四个步骤\n1.6.1 SDKInit类\nSDKInit类初始化\n调用SDKInit.init\npublic static void init(SDKInitBuilder builder,InitListener initListener)\n参数：（1）SDKInitBuilder是封装了初始化的各种参数，这个类的变量说明\nContex为上下文\nSecret为官网上机器人详情页中自动生成的一个secret（默认采用非加密模式，若采用加密模式时才开启），如下图\nturingKey为该机器人帐号的apikey，可在“机器人详情”页获取\nuniqueId为自己添加的一个标示符，如邮箱、手机号等等\n（2）参数InitListener是一个初始化后回调方法的接口\nonComplete()是成功后，回调的方法\nonFail(java.lang.String error)是失败后，回调的方法\n1.6.2 实例化TuringApiManager类\n实例化TuringApiManager类\n这里一定要在上一步SDKInit初始化成功后，再初始化TuringApiManager，否则很多功能将无法使用\n推荐的代码：\nonComplete()\n{\nTuringApiManager m = new TuringApiManager (this);\n}\n1.6.3 设置监听\n添加监听：\npublic void setHttpListener(HttpConnectionListener httpConnectionListener)\n参数：httpConnectionListener用于监听联网请求结果的回调\n代码形式如下：\nTuringApiManager m = new TuringApiManager (this);\nm.setHttpListener(httpConnectionListener);\n其中httpConnectionListener就是实现接口HttpConnectionListener\n1.6.4 发出请求\n发出请求\npublic void requestTuringAPI(String requestInfo)\n参数：requestInfo为传递的文本\n比如requestInfo = “你好”,那么在上一步的public void onSuccess(RequestResult result) 中result可以得到一串json字符串，其中json字符串根据不同的类型会有不同的格式\n1.7 语音合成（TTS）\n语音合成部分主要包括以下四个步骤\n1.7.1 实例化TTSManager类\n实例化TTSManager类\n该类为语音合成的管理类，要使用语音合成功能，首先要创建TTSManager的对象实例\n选用百度在线TTS，其构造函数如下：\npublic TTSManager(Context context, String bdAPI_KEY, String bdSECRET_KEY)\n这里的bdAPI_KEY和bdSECRET_KEY\n1.7.2 设置监听\n添加监听：\nTTSManager.setTTSListener(mTTSListener)\nmTTSListener需要实现接口TTSListener ，可以在不同的语音合成状态下回调其不同的方法\n1.7.3 开始语音合成\n调用TTSManager.startTTS(String ttsContent) 方法来进行语音合成\n参数：ttsContent就是需要被合成的文本，比如 ttsContent=“你好”,那么就会读出 你好。\n1.7.4 处理合成完成\n语音合成后，就会触发onSpeechFinish(),这样即可在其方法中添加相应的逻辑。"}
