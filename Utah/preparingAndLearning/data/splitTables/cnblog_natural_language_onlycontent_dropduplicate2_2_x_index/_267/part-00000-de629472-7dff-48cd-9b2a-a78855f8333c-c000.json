{"content2":"一、课程介绍\n斯坦福大学于2012年3月在Coursera启动了在线自然语言处理课程，由NLP领域大牛Dan Jurafsky 和 Chirs Manning教授授课：\nhttps://class.coursera.org/nlp/\n以下是本课程的学习笔记，以课程PPT/PDF为主，其他参考资料为辅，融入个人拓展、注解，抛砖引玉，欢迎大家在“我爱公开课”上一起探讨学习。\n课件汇总下载地址：斯坦福大学自然语言处理公开课课件汇总\n二、情感分析（Sentiment Analysis）\n1）What is Sentiment Analysis?\n情感分析（Sentiment analysis），又称倾向性分析，意见抽取（Opinion extraction），意见挖掘（Opinion mining），情感挖掘（Sentiment mining），主观分析（Subjectivity analysis），它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从评论文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向。\n更多例子如下：\nl  从电影评论中识别用户对电影的褒贬评价：\nl  Google Product Search识别用户对产品各种属性的评价，并从评论中选择代表性评论展示给用户：\nl  Bing Shopping识别用户对产品各种属性的评价：\nl  Twitter sentiment versus Gallup Poll of Consumer Confidence：挖掘Twitter（中文：微博）中的用户情感发现，其与传统的调查、投票等方法结果有高度的一致性（以消费者信心和政治选举为例，corelation达80%），详细见论文：Brendan O'Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series. In ICWSM-2010。（注：下图中2008年到2009年初，网民情绪低谷是金融危机导致，从2009年5月份开始慢慢恢复）\nl  Twitter sentiment: 通过Twitter用户情感预测股票走势，2012年5月，世界首家基于社交媒体的对冲基金 Derwent Capital Markets 在屡次跳票后终于上线。它会即时关注Twitter 中的公众情绪指导投资。正如基金创始人保罗•郝汀（Paul Hawtin）表示：“长期以来，投资者已经广泛地认可金融市场由恐惧和贪婪驱使，但我们从未拥有一种技术或数据来量化人们的情感。”一直为金融市场非理性举动所困惑的投资者，终于有了一扇可以了解心灵世界的窗户——那便是 Twitter 每天浩如烟海的推文，在一份八月份的报道中显示，利用 Twitter 的对冲基金 Derwent Capital Markets 在首月的交易中已经盈利，它以1.85%的收益率，让平均数只有0.76%的其他对冲基金相形见绌。类似的工作还有预测电影票房、选举结果等，均是将公众情绪与社会事件对比，发现一致性，并用于预测，如将“冷静CLAM”情绪指数后移3天后和道琼斯工业平均指数DIJA惊人一致。详细见论文： Johan Bollen, Huina Mao, Xiaojun Zeng. 2011. Twitter mood predicts the stock market, Journal of Computational Science 2:1, 1-8.（注：DIJA，全称Dow Jones Industrial Average）\nl  Target Sentiment on Twitter（Twitter Sentiment App）：对Twitter中包含给定query的tweets进行情感分类。对于公司了解用户对公司、产品的喜好，用于指导改善产品和服务，公司还可以据此发现竞争对手的优劣势，用户也可以根据网友甚至亲友评价决定是否购买特定产品。详细见论文：Alec Go, Richa Bhayani, Lei Huang. 2009. Twitter Sentiment Classification using Distant Supervision.\n情感分析的意义何在？下面以实际应用为例进行直观的阐述：\n•  Movie:  is this review positive or negative?\n•  Products:  what do people think about the new iPhone?\n•  Public sentiment:  how is consumer confidence? Is despair increasing?\n•  Politics:  what do people think about this candidate or issue?\n•  Prediction:  predict election outcomes or market trends from sentiment\n情感分析主要目的就是识别用户对事物或人的看法、态度（attitudes：enduring, affectively colored beliefs, dispositions towards objects or persons），参与主体主要包括：\nHolder (source) of attitude：观点持有者\nTarget (aspect) of attitude：评价对象\nType of attitude：评价观点\nFrom a set of types：Like, love, hate, value, desire, etc.\nOr (more commonly) simple weighted polarity: positive, negative, neutral, together withstrength\nText containing the attitude：评价文本，一般是句子或整篇文档\n更细更深入的还包括评价属性，情感词/极性词，评价搭配等、\n通常，我们面临的情感分析任务包括如下几类：\nSimplest task: Is the attitude of this text positive or negative?\nMore complex: Rank the attitude of this text from 1 to 5\nAdvanced: Detect the target, source, or complex attitude types\n后续章节将以Simplest task为例进行介绍。\n2）A Baseline Algorithm\n本小节对影评进行情感分析为例，向大家展示一个简单、实用的情感分析系统。详细见论文: Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.  2002.  Thumbs up? Sentiment Classification using Machine Learning Techniques. EMNLP-2002, 79—86.\nBo Pang and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.  ACL, 271-278\n我们面临的任务是“Polarity detection: Is an IMDB movie review positive or negative?”，数据集为“Polrity Data 2.0: http://www.cs.cornell.edu/people/pabo/movie-review-data”.作者将情感分析当作分类任务，拆分成如下子任务：\nTokenization：正文提取，过滤时间、电话号码等，保留大写字母开头的字符串，保留表情符号，切词；\nFeature Extraction：直观上，我们会认为形容词直接决定文本的情感，而Pang和Lee的实验表明，采用所有词（unigram）作为特征，可以达到更好的情感分类效果。\n其中，需要对否定句进行特别的处理，如句子”I didn’t like this movie”vs “I really like this movie”，unigram只差一个词，但是有着截然不同的含义。为了有效处理这种情况，Das and Chen (2001)提出了“Add NOT_ to every word between negation and following punctuation”，根据此规则可以将句子“didn’t like this movie , but I”转换为“didn’t NOT_like NOT_this NOT_movie, but I”。\n另外，在抽取特征时，直观的感觉“Word occurrence may matter more than word frequency”，这是因为最相关的情感词在一些文本片段中仅仅出现一次，词频模型起得作用有限，甚至是负作用，则使用多重伯努利模型事件空间代替多项式事件空间，实验也的确证明了这一点。所以，论文最终选择二值特征，即词的出现与否，代替传统的频率特征。log(freq(w))也是一种值得尝试的降低频率干扰的方法。\nClassification using different classifiers:如Naïve Bayes、MaxEnt、SVM，以朴素贝叶斯分类器为例，训练过程如下：\n预测过程如下：\n实验表明，MaxEnt和SVM相比Naïve Bayes可以得到更好的效果。\n最后，通过case review可以总结下，影评情感分类的难点是什么？\n语言表达的含蓄微妙：“If you are reading this because it is your darling fragrance, please wear it at home exclusively, and tape the windows shut.”，“ She runs the gamut of emotions from A to B”。\n挫败感表达方式：先描述开始的期待（不吝赞美之词），后表达最后失望感受，如“This film should be brilliant.  It sounds like a great plot, the actors are first grade, and the supporting cast is good as well, and Stallone is attempting to deliver a good performance. However, itcan’t hold up.”，“Well as usual Keanu Reeves is nothing special, but surprisingly, the verytalented Laurence Fishbourne is not so good either, I was surprised.”。\n3）Sentiment Lexicons\n情感分析模型非常依赖于情感词典抽取特征或规则，以下罗列了较为流行且成熟的开放情感词典资源：\nGI（The General Inquirer）：该词典给出了每个词条非常全面的信息，如词性，反义词，褒贬，等，组织结构如下：\n详细见论文：Philip J. Stone, Dexter C Dunphy, Marshall S. Smith, Daniel M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT Press\nLIWC (Linguistic Inquiry and Word Count)：该词典通过大量正则表达式描述不同类别的情感词规律，其类别体系与GI（The General Inquirer）基本一致，组织结构如下：\n详细见论文：Pennebaker, J.W., Booth, R.J., & Francis, M.E. (2007). Linguistic Inquiry and Word Count: LIWC 2007. Austin, TX\nMPQA Subjectivity Cues Lexicon：其中包含Positive words: 2718，Negative words: 4912，组织结构如下图所示：\n详细见论文：Theresa Wilson, Janyce Wiebe, and Paul Hoffmann (2005). Recognizing Contextual Polarity in Phrase-Level Sentiment Analysis. Proc. of HLT-EMNLP-2005.\nRiloff and Wiebe (2003). Learning extraction patterns for subjective expressions. EMNLP-2003.\nBing Liu Opinion Lexicon：其中包含Positive words: 2006，Negative words: 4783，需要特别说明的是，词典不但包含正常的用词，还包含了拼写错误、语法变形，俚语以及社交媒体标记等，详细见论文：Minqing Hu and Bing Liu. Mining and Summarizing Customer Reviews. ACM SIGKDD-2004.\nSentiWordNet：其通过对WordNet中的词条进行情感分类，并标注出每个词条属于positive和negative类别的权重大小，组织结构如下：\n详细见论文：Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010SENTIWORDNET 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. LREC-2010\n以上给出了一系列可用的情感词典资源，但是，如何选择一个合适的为我所用呢？这里，通过对比同一词条在不同词典之间的分类，衡量词典资源的不一致程度，如下：\n对于在不同词典中表现不一致的词条，我们至少可以做两件事情。第一，review这些词条，通过少量人工加以纠正；第二，可以得到一些存在褒贬歧义的词条。\n给定一个词，如何确定其以多大概率出现在某种情感类别文本中呢？以IMDB下不同打分下影评为例，最简单的方法就是计算每个分数（星的个数）对应的文本中词条出现的频率，如下图所示为Count(“bad”)分布情况：\n使用更多的是likelihood公式：\n为了使得不同词条在不同类别下的概率可比，通常使用Scaled likelihood公式代替，如下：\n如下图所示，列出了部分词条在不同类别下的Scaled likelihood，据此可以判断每个词条的倾向性。\n另外，我们通常会有这么一个疑问：否定词（如not, n’t, no, never）是否更容易出现在negative情感文本中？Potts, Christopher（2011）等通过实验给出了答案：More negation in negative sentiment，如下图所示：\n4）Learning Sentiment Lexicons\n我们在庆幸和赞扬众多公开情感词典为我所用的同时，我们不免还想了解构建情感词典的方法，正所谓知其然知其所以然。一方面在面临新的情感分析问题，解决新的情感分析任务时，难免会需要结合实际需求构建或完善情感词典，另一方面，可以将成熟的词典构建方法应用于其他领域，知识无边界，许多方法都是相通的。\n常见的情感词典构建方法是基于半指导的bootstrapping学习方法，主要包括两步：\nUse a small amount of information（Seed）\nA few labeled examples\nA few hand-built patterns\nTo bootstrap a lexicon\n接下来，通过相关的几篇论文，详细阐述下构建情感词典的方法。具体如下：\n1. Hatzivassiloglou & McKeown：论文见Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the Semantic Orientation of Adjectives. ACL, 174–181，基于这样的一种语言现象：“Adjectives conjoined by ‘and’’ have same polarity；Adjectives conjoined by ‘but ‘ do not”，如下示例：\nFair and legitimate, corrupt and brutal\n*fair and brutal, *corrupt and legitimate\nfair but brutal\nHatzivassiloglou & McKeown（1997）提出了基于bootstrapping的学习方法，主要包括四步：\nStep 1：Label seed set of 1336 adjectives (all >20 in 21 million word WSJ corpus)\n初始种子集包括657个 positive words（如adequate central clever famous intelligent remarkable reputed sensitive slender thriving…）和679个 negative words（如contagious drunken ignorant lanky listless primitive strident troublesome unresolved unsuspecting…）\nStep 2：Expand seed set to conjoined adjectives，如下图所示：\nStep 3：Supervised classifier assigns “polarity similarity” to each word pair, resulting in graph，如下图所示：\nStep 4：Clustering for partitioning the graph into two\n最终，输出新的情感词典，如下（加粗词条为自动挖掘出的词条）：\nPositive: bold decisive disturbing generous good honest important large mature patient peaceful positive proud sound stimulating straightforward strange talented vigorous witty…\nNegative: ambiguous cautious cynical evasive harmful hypocritical inefficient insecure irrational irresponsible minor outspoken pleasant reckless risky selfish tedious unsupported vulnerable wasteful…\n2.  Turney Algorithm：论文见Turney (2002):  Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews，具体步骤如下：\nStep 1：Extract a phrasal lexicon from reviews，通过规则抽取的phrasal如下图所示：\nStep 2：Learn polarity of each phrase，那么，如何评价phrase的polarity呢？直观上，有这样的结论：“Positive phrases co-occur more with ‘excellent’，Negative phrases co-occur more with ’poor’”，这时，将问题转换成如何衡量词条之间的共现关系？于是，学者们引入了点互信息（Pointwise mutual information，PMI），它经常被用于度量两个具体事件的相关程度，公式为：\n两个词条的PMI公式为：\n常用的计算PMI(word1, word2)方法是分别以”word1”，”word2”和”word1 NEAR word2”为query，根据搜索引擎检索结果，得到P(word)和P(word1, word2)，如下：\nP(word) = hits(word)/N\nP(word1,word2) = hits(word1 NEAR word2)/N2\n则有：\n那么，计算一个phrase的polarity公式为（excellent和poor也可以使用其它已知极性词代替）：\nTurney Algorithm在410 reviews（from Epinions）的数据集上，其中170 (41%) negative，240 (59%) positive，取得了74%的准确率（baseline为59%，均标注为positive）。\nStep 3：Rate a review by the average polarity of its phrases\n3. Using WordNet to learn polarity：论文见S.M. Kim and E. Hovy. 2004.Determining the sentiment of opinions. COLING 2004，M. Hu and B. Liu. Mining and summarizing customer reviews. In Proceedings of KDD, 2004.该方法步骤如下：\nCreate positive (“good”) and negative seed-words (“terrible”)\nFind Synonyms and Antonyms\nPositive Set:  Add  synonyms of positive words (“well”) and antonyms of negative words\nNegative Set: Add synonyms of negative words (“awful”)  and antonyms of positive words (”evil”)\nRepeat, following chains of synonyms\nFilter\n以上几个方法都有较好的领域适应性和鲁棒性，基本思想可以概括为“Use seeds and semi-supervised learning to induce lexicons”，即：\nStart with a seed set of words (‘good’, ‘poor’)\nFind other words that have similar polarity:\nUsing “and” and “but”\nUsing words that occur nearby in the same document\nUsing WordNet synonyms and antonyms\nUse seeds and semi-supervised learning to induce lexicons\n5）Other Sentiment Tasks\n上面介绍了文档级或句子级情感分析，但是，实际中，一篇文档（评论）中往往会提及不同的方面/属性/对象（以下统称属性），且可能对不同的属性持有不同的倾向性，如“The food was greatbut the service was awful”。一般通过Frequent phrases + rules的方法抽取评价属性，如下：\nFind all highly frequent phrases across reviews (“fish tacos”)\nFilter by rules like “occurs right after sentiment word”：“…great fish tacos” means fish tacos a likely aspect\n通常，我们还会面临一种问题：评价属性缺失，准确的讲，评价属性不在句子中。这是很常见的现象，此时就需要结合上下文环境，如来自某电影的评论缺失的评价属性基本上就是电影名或演员，可以基于已知评价属性的句子训练分类器，然后对评价属性缺失的句子进行属性预测。\nBlair-Goldensohn et al.提出了一套通用的aspect-based summarization models，如下图所示：\n详细见论文：S. Blair-Goldensohn, K. Hannan, R. McDonald, T. Neylon, G. Reis, and J. Reynar. 2008.  Building a Sentiment Summarizer for Local Service Reviews.  WWW Workshop\n另外，其他的一些情感分析的相关任务有：\nEmotion: 个人情绪\nDetecting annoyed callers to dialogue system\nDetecting confused/frustrated  versus confident students\nMood: 个人情绪\nFinding traumatized or depressed writers\nInterpersonal stances: 人际关系中的谈话方式\nDetection of flirtation or friendliness in conversations\nPersonality traits: 性格\nDetection of extroverts\n三、参考资料\nLecture Slides：Sentiment Analysis\nSentiment tutorial\n赵妍研，文本情感分析综述\n如转载52opencourse上的任何原创文章，请注明出处，谢谢！\n斯坦福大学\n自然语言处理\nnlp\n斯坦福\n公开课\n情感分析\n意见挖掘\n倾向性分析\n主客观分类\n主观分析\n评价词\n评价对象\n极性词\n褒贬分析\n情感词典\n极性词典\n互信息\n点互信息\npmi\n时间: 2012年 6月 24日 分类:自然语言处理 作者: fandywang (2,110 基本)\n编辑 2012年 7月 2日 作者:fandywang"}
