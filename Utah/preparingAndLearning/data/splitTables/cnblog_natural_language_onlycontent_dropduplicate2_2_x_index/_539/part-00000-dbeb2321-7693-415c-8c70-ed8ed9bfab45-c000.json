{"content2":"摘要： NLP 与情感分析、增强学习、深度学习的交叉领域，全年干货大合集。\n2018年对于自然语言处理（NPL）是很有意义的一年，见证了许多新的研究方向和尖端成果。Elvis Saravia 是计算语言学专家，也是2019 计算语言学会年度大会北美分部的项目委员之一。他总结了2018年 NLP 的重要进展，包括增强学习、情感分析和深度学习等领域。\n点击文章中的链接，可获得每一项研究的详细信息、论文或者代码。\n综合领域\nFacebook 研究员们发明了一种机器翻译的新方法，只需要使用单一语言语料库，这对于缺乏资料的语言非常有用。\nYoung 和同事更新了他们近期发表的论文《基于深度学习的自然语言处理的最新趋势》，增加了 NLP 文献中最新的 SQuAD 结果。\nBloomberg 研究员 Yi Yang 发表了 RNN 卷积筛选建模的最新论文及代码，称体现了语言中的长期依存性和组合性。\n百度发布了 Deep Voice 3，是一项基于注意、完全卷积的文字语音转换神经系统，比目前的循环系统在神经语音合成方面快几个量级。\nPair2vec 是一种学习文字嵌入对的新方法，能体现隐含关系的背景知识。\n百度发布了名为同声翻译与预测及可控延迟（STACL）的机器翻译算法，能够同时进行多个翻译。在同声传译时，这项技术不需要等发言者暂停发言，而可以预测发言者的下一个词语。\nDeep INFOMAX 是一种学习无监督表征的方法，将输入和高层特征矢量之间的共同信息最大化。\n蒙特利尔大学的 AI 研究团队 MILA 发表了多个超赞的研究成果，记录了自然语言生成（NLG）任务中 GAN 的限制。\n聊天机器人是 NLP 的一个重要研究领域，创业公司 lang.ai 如何使用无监督 AI 来解决打造聊天机器人的重要挑战之一：理解用户到底想要什么。\n这个模型提供了一种新方法进行文字生成，可以实现更强的解读性和控制性。\n谷歌 AI 发表了论文，探索语言建模的极限。\n亚马逊研究员提出了一种语言建模方法，这种新的训练策略的重要性在于，在现实中，要获得大量的训练数据来建立一种新能力经常是不现实的。\n增强学习\n许多研究员认为增强学习是机器学习的最前端。 我们来看看这个领域内，2018年都有哪些重大进展。\nDavid Ha 的“世界模型”，目标是研究个体能否在其自身的梦境中学习，需要利用增强学习来学习一项规则，依靠世界模型中抽取的特征来解决制定的任务。\nOpenAI 开发了一个类似人类的机器人手，通过增强学习算法获得操纵物体的灵活性。\nDeepMind 在《自然》杂志发布了一篇论文，讨论虚拟环境中，人工个体的网格表征怎样通过矢量导航找到解决。\nTextWorld 是以文字游戏为灵感的学习环境，用于训练增强学习代理。\nGoogle研究员开发了一项名为 MnasNet 的技术，是一种自动化神经网络架构搜索方法，用于通过增强学习设计移动化机器学习模型。\nOpenAI Five 利用增强学习，能在复杂游戏 Dota 2 中打败业余水准的人类选手。\nDeepMind 开发了名为 PopArt 的技术，利用增强学习在多任务环境中具有高精确度。\n三星的 CozNet 是一种增强学习算法，在两项知名的NPL比赛中展现了顶尖表现。\nArel 使用对抗奖励学习来讲故事，解决故事评估维度的局限。\nMetacar 是为无人驾驶汽车而设计的增强学习环境，在以 Tensorflow.js 打造的浏览器上使用。\nOpenAI 发布的 Gym Retro 平台提供 1000多个游戏，进行增强学习研究。\n情感分析\n机器学习系统需要更深的理解能力，才能与人类在情感层面互动。\n这篇新论文提出了“层级化CVAE用于精准的仇恨言论分类”，能够理解40多个群体和13中不同类别的仇恨言论。\n这篇论文讨论如何使用简单的支持向量机变量获得最佳结果，并指出模型方面需要注意的几点。目前大部分情感分析都是基于神经方法，研究时需要注意模型和特征的选择。\n这篇论文定量分析了推特表情肤色修改器的使用效果。\n这篇论文讨论如何使用深度卷积神经网络检测讽刺。另外，这项新研究使用眼动追踪、NLP和深度学习算法检测讽刺。\n研究员开发了一项成为“情感聊天机器”的方法，这个聊天机器人不仅能给出符合事实与逻辑的答案，还能在聊天中加入悲伤、厌烦等情绪。\nLei Zhang 等研究员发表了一篇论文，综合概括了深度学习方法如何用于情感分析。\n这个双向异步框架可以在聊天中生成有意义的情感回复。\n这项研究使用计算机视觉方法，研究语境中的情感识别。\n这篇在2018 NAACL 大会上发表的论文，提出了一种方法可以使用简单的递归神经网络模拟情感流。\n深度学习\nDeepMind 与哈佛大学教师 Wouter Kool 合作发表了论文，研究人类如何使用大脑来做决定，以及这些研究结果能如何启发人工智能的研究。\n这篇论文引入了“群组归一化”的概念，可以有效替代批归一化，被认为是深度学习的一项重要技术。\nSperichal CNN 是一种打造卷积神经网络的新方法。\nBAIR 发布了一篇文章，讨论目前循环神经网络和前馈神经网络在解决各种问题时的优缺点。\nFacebook 的 AI 研究小组开发了一项新技术，能将 AI 模型运行效率提升16%。这能提高 AI 模型的训练速度，并简化模型的量化和运行。\n这篇《自然》杂志论文，介绍了一种可以预测地震后余震位置的深度学习方法。\nDeepMind 研究员开发了一种新方法，利用神经算数逻辑单元（NALU）改善神经网络，追踪时间、用数字图片运行算数、数图片中的物体个数等等。\nDARTS 是一种架构搜索算法，可以设计高性能的图像分类卷积架构。\n这篇论文《实证验证序列建模中的通用卷积网络和神经网络》，讨论了序列建模中 CNN 和 RNN 的区别。\n图形神经网络如何帮助推断潜在关系结构、模拟多代理和物理动态。\n谷歌 AI 研究团队发布了一篇论文，提出了一种改进版的 RNN，能够提高自动数据解读的精确度。\nDistill 发布了新研究，可以在一个数据源的语境下分析另一个数据。\n如果没有任何数据、也没有任何人类知识工程，有可能习得精准的认知模型吗？这项研究会告诉你答案。\n这篇论文详细描述了针对深度神经网络的批归一化研究。\n这篇论文回顾了神经网络中，如何更好地进行批训练。\n这篇论文讨论如何正确评估深度半监督学习算法。"}
