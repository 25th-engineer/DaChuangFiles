{"content2":"HanLP是由一系列模型与算法组成的Java工具包，目标是促进自然语言处理在生产环境中的应用。HanLP具备功能完善、性能高效、架构清晰、语料时新、可自定义的特点。\nHanLP能提供以下功能：关键词提取、短语提取、繁体转简体、简体转繁体、分词、词性标注、拼音转换、自动摘要、命名实体识别（地名、机构名等）、文本推荐等功能，详细请参见以下链接：http://www.hankcs.com/nlp/hanlp.html\nHanLP下载地址：https://github.com/hankcs/HanLP/releases，HanLP项目主页：https://github.com/hankcs/HanLP\n1、HanLP安装\nhanlp是由jar包、properties文件和data数据模型组成，因此，在安装时，这三种文件都应该有。可以通过建立java工程即可运行。\nhanlp.properties文件中描述了不同词典的相对路径以及root根目录，因此，可以在此文件中修改其路径。\nhanlp-1.3.4.jar包中包含了各种算法及提取方法的api，大部分方法都是静态的，可以通过HanLP直接进行调用，因此，使用非常方便。\ndata文件夹中包含了dictionary和model文件夹，dictionary中主要是各种类型的词典，model主要是分析模型，hanlp api中的算法需要使用model中的数据模型。\n2、HanLP的使用\n普通java工程目录如下所示：\n3、HanLP的具体使用\n例如：对excel中的聊天记录字段进行热点词的提取，计算并排序，功能如下所示\npackage com.run.hanlp.demo;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Map.Entry;\nimport org.apache.log4j.Logger;\nimport com.hankcs.hanlp.HanLP;\nimport com.hankcs.hanlp.seg.common.Term;\nimport com.hankcs.hanlp.suggest.Suggester;\nimport com.hankcs.hanlp.summary.TextRankKeyword;\nimport com.hankcs.hanlp.tokenizer.NLPTokenizer;\nimport com.hankcs.hanlp.tokenizer.StandardTokenizer;\nimport com.run.util.ExcelUtil;\npublic class HanlpTest {\npublic static final Logger log = Logger.getLogger(HanlpTest.class);\npublic static void main(String[] args) {\nlog.info(\"关键词提取：\");\nHanlpTest.getWordAndFrequency();\n}\n/**\n* 获取所有关键词和频率\n*/\npublic static void getWordAndFrequency() {\n// String content =\n// \"程序员(英文Programmer)是从事程序开发、维护的专业人员。一般将程序员分为程序设计人员和程序编码人员，但两者的界限并不非常清楚，特别是在中国。软件从业人员分为初级程序员、高级程序员、系统分析员和项目经理四大类。\";\nList<Map<String, Integer>> content = ExcelUtil.readExcelByField(\"i:/rundata/excelinput\",5000,5);\nMap<String, Integer> allKeyWords=new HashMap<>();\nfor(int i=0;i<content.size();i++){\nMap<String, Integer> oneMap=content.get(i);\nfor(String str:oneMap.keySet()){\nint count = oneMap.get(str);\nCombinerKeyNum(str,count,allKeyWords);\n}\n}\nList<Map.Entry<String,Integer>> sortedMap=sortMapByValue(allKeyWords);\nlog.info(sortedMap);\n}\n/**\n*\n* @param allKeyWords 需要进行排序的map\n* @return 返回排序后的list\n*/\npublic static List<Map.Entry<String,Integer>> sortMapByValue(Map<String,Integer> allKeyWords){\nList<Map.Entry<String,Integer>> sortList=new ArrayList<>(allKeyWords.entrySet());\nCollections.sort(sortList, new Comparator<Map.Entry<String, Integer>>() {\npublic int compare(Map.Entry<String, Integer> o1, Map.Entry<String, Integer> o2) {\nreturn (o2.getValue() - o1.getValue());\n}\n});\nreturn sortList;\n}\n/**\n*\n* @param key 关键词变量\n* @param value 关键词词频变量\n* @param allKeyWords  存放关键词和词频的map\n*/\npublic static void CombinerKeyNum(String key,int value,Map<String,Integer> allKeyWords){\nif(allKeyWords.containsKey(key)){\nint count=allKeyWords.get(key);\ncount+=value;\nallKeyWords.put(key, count);\n}else{\nallKeyWords.put(key, value);\n}\n}\n/**\n*\n* @param content 需要提取关键词的字符串变量\n* @return 返回关键词以及关键词词频数的map\n*\n*/\npublic static HashMap<String, Integer> getKeyWordMap(String content) {\nList<Term> list = StandardTokenizer.SEGMENT.seg(content);\nTextRankKeyword textmap = new TextRankKeyword();\nMap<String, Float> map = textmap.getTermAndRank(content);\nMap<String, Integer> mapCount = new HashMap<>();\nfor (String str : map.keySet()) {\nString keyStr = str;\nint count = 0;\nfor (int i = 0; i < list.size(); i++) {\nif (keyStr.equals(list.get(i).word)) {\ncount++;\n}\n}\nmapCount.put(keyStr, Integer.valueOf(count));\n}\n//        log.info(mapCount);\nreturn (HashMap<String, Integer>) mapCount;\n}\n}\n运行之后，结果如下：\n由此可见，可以看见从excel中提取出来的热点词汇及其频率。\n文章来源于计算机之wind的博客"}
