{"content2":"自然语言处理（NLP）中的很多问题，都需要给文档中的词语一个定量化的权重值，进而可以完后词语重要性的排序，相似度的计算，相关性的排序，等等。本文就目前流行的权重计算方案进行了一个列举。\n1. TF-IDF\nwij=log(fij) x log(N/nj)\nwij是词语j在文档i中的权重， fij是词语j在文档i中出现的频率（TF）， N是所有的文档数，文章后面含义同此。\n主要思想：如果一个词语在一篇文章中出现的频率TF高，并且在其他文档中很少出现，则认为此词语具有很好的区分能力。对区分文档最有意义的词语应该是那些在文档中出现频率高而在整个文档集合中出现频率低的词语。考虑到每个词语区分不同类别的能力，TF-IDF认为一个词语出现的文档频率越小，它区分不同类别文档的能力就越大。\n2. MI （互信息）\n这里的N是所有文档中所有词语频率的和，而不是文档数。上面公式中，分子表示的是词语j在文档i中出现的概率；分母的前一项词语j在所有文档出现的概率，后一项是文档i出现的概率。\n互信息的意义：\n在某个特定文档出现频率高，但在其他文档出现频率比较低的词语与该文档的互信息比较大。通常用互信息作为特征词语和文档之间的相关度测量，如果特征词属于该文档，则他们的互信息量最大。\n3. ATC\n4. Okapi\n5. LTU\nnj是词语j至少出现过一次的文档， nj/N 是词语j的文档频率（DF）， 那么N/nj 就是逆向文档频率（IDF）， max_f是词语在所有文档中的最大频率， dl是文档长度，avg_dl是所有文档的平均长度。\n这三种权重方案都是TF-IDF的变种，是在其的基础上引入了其他的因素。ATC 引入了所有文档中的词语的最大频率，同时使用了欧几里德距离作为文档长度归一化考虑。Okapi和LTU使用了类似的方式\n来考虑文档长度（文档越长，那么相对来说，词语的频率也就越高，为了平衡，需要对长文档做出一定的惩罚，但又不能惩罚太厉害，所以引入了dl/avg_dl），但他们采用不同的方式来处理词语的频率。\nLTU使用的是log(fij),而Okapi使用的是fij/(fij+2).\n一般这几种方案没有绝对的优劣之分，根据具体情况选择合适的方案即可。"}
