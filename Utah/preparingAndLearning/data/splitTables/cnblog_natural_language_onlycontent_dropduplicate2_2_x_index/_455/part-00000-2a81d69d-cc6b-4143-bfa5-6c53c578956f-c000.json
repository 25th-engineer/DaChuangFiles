{"content2":"回家前，把python自然语言处理的nltk_data打包到360云盘，然后共享给朋友们，省的大家像我一样浪费时间。\n一次性下载解压后即可使用。官方的nltk.download()老是下载失败。无数遍了。浪费了我很多很多时间。\n打包下载（推荐）：\nhttp://yunpan.cn/cgGUPFzF3spir （提取码：504e）\n下载后放在python/nltk_data目录下即可.\n记录下错误提示，以便于朋友们搜索找到。\n当时遇到的错误是：\nnltk.download()\ncould not find maxent_treebank_pos_tagger / english .XXX\nsearched index:\nC:\\\\Python27\\\\nltk_data\\\nC:\\\\nltk_data\nD:\\\\nltk_data\nE:\\\\nltk_data\n然后我通过，nltk.download()下载，一直出现错误，只好到\n官方下载http://nltk.org/nltk_data/\n另外，也可以到nltk.code.google.com 下载，\n但是又遇到了下载后，直接放在nltk_data目录，却发现还是不行，程序找不到数据集。\n因此我就用nltk.download()试着下载了一个，观察他的文件位置，这才发现原来有好几个文档目录。\n用tree命令的到其目录结构如下：\n文件夹 PATH 列表\n卷序列号为 00000200 B2F8:ED9D\n├─chunkers #这一级为nltk_data下的文件夹\n│ └─maxent_ne_chunker #这一级为相对应文件夹下的数据文件\n├─corpora      #这一级为nltk_data下的文件夹\n│ ├─abc        #这一级为相对应文件夹下的数据文件\n│ ├─alpino\n│ ├─basque_grammars\n│ ├─biocreative_ppi\n│ ├─book_grammars\n│ ├─brown\n│ ├─brown_tei\n│ ├─cess_cat\n│ ├─cess_esp\n│ ├─chat80\n│ ├─city_database\n│ ├─cmudict\n│ ├─comtrans\n│ ├─conll2000\n│ ├─conll2002\n│ ├─conll2007\n│ ├─dependency_treebank\n│ ├─europarl_raw\n│ │\n│ ├─floresta\n│ ├─gazetteers\n│ ├─genesis\n│ ├─gutenberg\n│ ├─hmm_treebank_pos_tagger\n│ ├─ieer\n│ ├─inaugural\n│ ├─indian\n│ ├─jeita\n│ ├─kimmo\n│ ├─knbc\n│ │\n│ ├─langid\n│ ├─large_grammars\n│ ├─machado\n│ │\n│ ├─mac_morpho\n│ ├─maxent_ne_chunker\n│ ├─maxent_treebank_pos_tagger\n│ ├─movie_reviews\n│ │\n│ ├─names\n│ ├─nombank.1.0\n│ │\n│ ├─nps_chat\n│ ├─oanc_masc\n│ │\n│ ├─paradigms\n│ ├─pe08\n│ ├─pil\n│ ├─pl196x\n│ ├─ppattach\n│ ├─problem_reports\n│ ├─propbank\n│ │\n│ ├─ptb\n│ ├─punkt\n│ ├─qc\n│ ├─reuters\n│ │\n│ ├─rslp\n│ ├─rte\n│ ├─sample_grammars\n│ ├─semcor\n│ │\n│ ├─senseval\n│ ├─shakespeare\n│ ├─sinica_treebank\n│ ├─smultron\n│ ├─spanish_grammars\n│ ├─state_union\n│ ├─stopwords\n│ ├─swadesh\n│ ├─switchboard\n│ ├─tagsets\n│ ├─timit\n│ │\n│ ├─toolbox\n│ │\n│ ├─treebank\n│ │\n│ ├─udhr\n│ ├─udhr2\n│ ├─unicode_samples\n│ ├─verbnet\n│ ├─webtext\n│ ├─wordnet\n│ ├─wordnet_ic\n│ ├─words\n│ └─ycoe\n├─grammars\n│ ├─basque_grammars\n│ ├─book_grammars\n│ ├─large_grammars\n│ ├─sample_grammars\n│ └─spanish_grammars\n├─help\n│ └─tagsets\n├─stemmers\n│ └─rslp\n├─taggers\n│ ├─hmm_treebank_pos_tagger\n│ ├─maxent_ne_chunker\n│ └─maxent_treebank_pos_tagger\n└─tokenizers\n└─punkt"}
