{"content2":"一、两种分词标准：\n1. 粗粒度。\n将词作为最小基本单位。比如：浙江大学。\n主要用于自然语言处理的各种应用。\n2. 细粒度。\n不仅对词汇继续切分，也对词汇内部的语素进行切分。比如：浙江/大学。\n主要用于搜索引擎。一种常用方案是：\n索引的时候使用细粒度的分词以保证召回，比如浙江/大学\n询的时候使用粗粒度的分词以保证精度\n二、歧义\n1.分类：\n交集型切分歧义。对于AJB，AJ和JB都成词\n组合型切分歧义。对于AB，A、B、AB都成词\n多义组合型切分歧义。对于AB，（1）A、B、AB同时为词；（2）文本中至少存在一个上下文语境c，在c的约束下，A、B在语法和语义上都成立\nPS：语法与语义\n语法：语言符号之间的关系\n语义：语言符号与所指事物之间的关系\n2. 解决方法（分词算法）\n机械分词系统\n基于最大匹配方法MM（The Maximum Matching Method）\n设词典中的最长词条为L，每次先取L个词尝试匹配，若失败，就去掉最后一个字，取前L-1个词尝试匹配，以此类推\n双向匹配法\nMM的改进算法，分为正向最佳匹配法和逆向最佳匹配法\n两个方向得到的结果必然不同\n缺陷：只能正向或逆向得找出最长的词，而不能找出所有的候选词条\n双向扫描法\n以上的改进算法，能更快速的检测出歧义产生的位置\n整体缺点：没有考虑词汇上下文相关性，分词准确度不高\n机械分词系统揭示了一个语言规律：\n一个词汇的出现与其上下文环境中出现的词汇序列存在着紧密的联系\n上下文相关性：\n文本中第n个词的出现与其前后n-m和n+m个词有高度相关性，这个范围[-m,m]称为窗口范围\n计算：Markov假设+最大似然估计，看笔记\n三、未登录词识别（Named Entity Recognition, NER)\n未登录词中，九成是专有名词，其余为通用新词或专业术语。所以未登录词识别就是包括中国人名、译名、日本人名、地理位置名称、组织机构等专有名词的识别。\n在NLP中，通常将上述专有名词和数字、日期等词称为命名实体。\n算法\n基于构词编码的方法\n缺点：只适用于狭窄的专门领域等，在处理大规模不同领域的未登录词上存在很大的障碍\n基于语义的方法\n认为：不同语义类下的未登录词，在统计学规律上具有相似性。\n算法：基于半监督的条件随机场算法（semi-CRF）"}
