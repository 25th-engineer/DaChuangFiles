{"content2":"1、LTP [1]- 语言技术平台(LTP) 提供包括中文分词、词性标注、命名实体识别、依存句法分析、语义角色标注等丰富、 高效、精准的自然语言处理技术。经过哈工大社会计算与信息检索研究中心 11 年的持续研发和推广，\nLTP 已经成为国内外最具影响力的中文处理基础平台。\n2、NLPIR汉语分词系统 [2]- 又名ICTCLAS2013，主要功能包括中文分词；词性标注；命名实体识别；用户词典功能；支持GBK编码、UTF8编码、BIG5编码。新增微博分词、新词发现与关键词提取。\n3、结巴中文分词 [3]- 支持三种分词模式：精确模式，试图将句子最精确地切开，适合文本分析；全模式，把句子中所有的可以成词的词语都扫描出来,速度非常快，但是不能解决歧义；搜索引擎模式，\n在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。支持繁体分词；支持自定义词典。\n4、Boson中文语义开放平台 [4]- Boson中文语义开放平台提供使用简单、功能强大、性能可靠的中文自然语言分析云服务。通过自主研发的中文分词、句法分析、语义联想和实体识别技术，结合海量行业语料的不断积累，\n为企业和广大开发者提供简单、强大、可靠的中文语义分析云端API。\n5、NLPCN [5]- NLPCN是一个非盈利的自然语言处理组织。遵循开放自由的理念，乐于分享，勤于开源，为为数不多的数据处理的开发者提供了一个资源共享,开源项目介绍,开发者展示的平台。\n6、THUCTC [6]- 是由清华大学自然语言处理实验室推出的中文文本分类工具包，能够自动高效地实现用户自定义的文本分类语料的训练、评测、分类功能。文本文类通常包括特征选取、特征降维、分类模型学习三个步骤。\n7、SnowNLP [7]- 一个用来处理中文文本的库。它是一个python写的类库，可以方便的处理中文文本内容，是受到了TextBlob的启发而写，由于现在大部分的自然语言处理库基本都是针对英文的，\n于是写了一个方便处理中文的类库，并且和TextBlob不同的是，这里没有用NLTK，所有的算法都是自己实现的，并且自带了一些训练好的字典。\n8、TextGrocery [8]- 简单高效的短文本分类工具，基于 LibLinear 和 Jieba。"}
