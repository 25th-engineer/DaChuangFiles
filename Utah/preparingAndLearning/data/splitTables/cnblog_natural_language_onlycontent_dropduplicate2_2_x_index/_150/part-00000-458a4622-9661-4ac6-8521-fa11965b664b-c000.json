{"content2":"MIT自然语言处理第四讲：标注（第三部分）\n发表于 2009年03月24号 由 52nlp\n自然语言处理：标注\nNatural Language Processing: Tagging\n作者：Regina Barzilay（MIT,EECS Department, November 15, 2004)\n译者：我爱自然语言处理（www.52nlp.cn ，2009年3月24日）\n三、 马尔科夫模型（Markov Model）\na) 直观（Intuition）：对于序列中的每个单词挑选最可能的标记（Pick the most likely tag for each word of a sequence）\ni. 我们将对P(T,S)建模，其中T是一个标记序列，S是一个单词序列（We will model P(T,S), where T is a sequence of tags, and S is a sequence of words）\nii.　P({T}delim{|}{S}{})={P(T,S)}/{sum{T}{}{P(T,S)}}\nTagger(S)= argmax_{T in T^n}logP({T}delim{|}{S}{})\n= argmax_{T in T^n}logP({T,S}{})\nb) 参数估计（Parameter Estimation）\ni. 应用链式法则（Apply chain rule）:\nP(T,S)={prod{j=1}{n}{P({T_j}delim{|}{S_1,…S_{j-1},T_1,…,T_{j-1}}{})}}*\nP({S_j}delim{|}{S_1,…S_{j-1}T_1,…,T_{j}}{})\nii. 独立性假设（马尔科夫假设）（Assume independence (Markov assumption)）:\n={prod{j=1}{n}{P({T_j}delim{|}{T_{j-2},T_{j-1}}{})}}*P({S_j}delim{|}{T_j}{})\nc) 举例（Example）\ni. They/PRP never/RB stop/VB thinking/VBG about/IN new/JJ 　ways/NNS to/TO harm/VB our/PROPcountry/NNand/CCour/PRP 　people/NN, and/CC neither/DT do/VB we/PRP.\nii. P(T, S)=P(PRP|S, S)∗P(They|PRP)∗P(RB|S, PRP)∗P(never|RB)∗…\nd) 估计转移概率（Estimating Transition Probabilities）\nP({T_j}delim{|}{T_{j-2},T_{j-1}}{})=\n{lambda_1}*{{Count(T_{j-2},T_{j-1},T_j)}/{Count(T_{j-2},T_{j-1})}}\n+{lambda_2}*{{Count(T_{j-1},T_j)}/{Count(T_{j-1})}}\n+{lambda_3}*{{Count(T_j)}/{Count(sum{i}{}{T_i})}}\ne) 估计发射概率（Estimating Emission Probabilities）\nP({S_j}delim{|}{T_j}{})={Count(S_j,T_j)}/{Count(T_j)}\ni. 问题（Problem）: 未登录词或罕见词（unknown or rare words）\n1. 专有名词（Proper names）\n“King Abdullah of Jordan, the King of Morocco, I mean, there’s a series of places — Qatar, Oman – I mean, places that are developing— Bahrain — they’re all developing the habits of free societies.”\n2. 新词（New words）\n“They misunderestimated me.”\nf) 处理低频词（Dealing with Low Frequency Words）\ni. 将词表分为两个集合（Split vocabulary into two sets）\n1. 常用词（Frequent words）— 在训练集中出现超过5次的词（words occurring more than 5 times in training）\n2. 低频词（Low frequency words）— 训练集中的其他词（all other words）\nii. 依据前缀、后缀等将低频词映射到一个小的、有限的集合中（Map low frequency words into a small, finite set, depending on prefixes, suffixes etc. (see Bikel et al., 1998)）\n附：课程及课件pdf下载MIT英文网页地址：\nhttp://people.csail.mit.edu/regina/6881/"}
