{"content2":"郑捷2017年电子工业出版社出版的图书《NLP汉语自然语言处理原理与实践》\n第1章 中文语言的机器处理 1\n1.1 历史回顾 2\n1.1.1 从科幻到现实 2\n1.1.2 早期的探索 3\n1.1.3 规则派还是统计派 3\n1.1.4 从机器学习到认知计算 5\n1.2 现代自然语言系统简介 6\n1.2.1 NLP流程与开源框架 6\n1.2.2 哈工大NLP平台及其演示环境 9\n1.2.3 StanfordNLP团队及其演示环境 11\n1.2.4 NLTK开发环境 13\n1.3 整合中文分词模块 16\n1.3.1 安装Ltp Python组件 17\n1.3.2 使用Ltp 3.3进行中文分词 18\n1.3.3 使用结巴分词模块 20\n1.4 整合词性标注模块 22\n1.4.1 Ltp 3.3词性标注 23\n1.4.2 安装StanfordNLP并编写Python接口类 24\n1.4.3 执行Stanford词性标注 28\n1.5 整合命名实体识别模块 29\n1.5.1 Ltp 3.3命名实体识别 29\n1.5.2 Stanford命名实体识别 30\n1.6 整合句法解析模块 32\n1.6.1 Ltp 3.3句法依存树 33\n1.6.2 StanfordParser类 35\n1.6.3 Stanford短语结构树 36\n1.6.4 Stanford依存句法树 37\n1.7 整合语义角色标注模块 38\n1.8 结语 40\n第2章 汉语语言学研究回顾 42\n2.1 文字符号的起源 42\n2.1.1 从记事谈起 43\n2.1.2 古文字的形成 47\n2.2 六书及其他 48\n2.2.1 象形 48\n2.2.2 指事 50\n2.2.3 会意 51\n2.2.4 形声 53\n2.2.5 转注 54\n2.2.6 假借 55\n2.3 字形的流变 56\n2.3.1 笔与墨的形成与变革 56\n2.3.2 隶变的方式 58\n2.3.3 汉字的符号化与结构 61\n2.4 汉语的发展 67\n2.4.1 完整语义的基本形式——句子 68\n2.4.2 语言的初始形态与文言文 71\n2.4.3 白话文与复音词 73\n2.4.4 白话文与句法研究 78\n2.5 三个平面中的语义研究 80\n2.5.1 词汇与本体论 81\n2.5.2 格语法及其框架 84\n2.6 结语 86\n第3章 词汇与分词技术 88\n3.1 中文分词 89\n3.1.1 什么是词与分词规范 90\n3.1.2 两种分词标准 93\n3.1.3 歧义、机械分词、语言模型 94\n3.1.4 词汇的构成与未登录词 97\n3.2 系统总体流程与词典结构 98\n3.2.1 概述 98\n3.2.2 中文分词流程 99\n3.2.3 分词词典结构 103\n3.2.4 命名实体的词典结构 105\n3.2.5 词典的存储结构 108\n3.3 算法部分源码解析 111\n3.3.1 系统配置 112\n3.3.2 Main方法与例句 113\n3.3.3 句子切分 113\n3.3.4 分词流程 117\n3.3.5 一元词网 118\n3.3.6 二元词图 125\n3.3.7 NShort算法原理 130\n3.3.8 后处理规则集 136\n3.3.9 命名实体识别 137\n3.3.10 细分阶段与最短路径 140\n3.4 结语 142\n第4章 NLP中的概率图模型 143\n4.1 概率论回顾 143\n4.1.1 多元概率论的几个基本概念 144\n4.1.2 贝叶斯与朴素贝叶斯算法 146\n4.1.3 文本分类 148\n4.1.4 文本分类的实现 151\n4.2 信息熵 154\n4.2.1 信息量与信息熵 154\n4.2.2 互信息、联合熵、条件熵 156\n4.2.3 交叉熵和KL散度 158\n4.2.4 信息熵的NLP的意义 159\n4.3 NLP与概率图模型 160\n4.3.1 概率图模型的几个基本问题 161\n4.3.2 产生式模型和判别式模型 162\n4.3.3 统计语言模型与NLP算法设计 164\n4.3.4 极大似然估计 167\n4.4 隐马尔科夫模型简介 169\n4.4.1 马尔科夫链 169\n4.4.2 隐马尔科夫模型 170\n4.4.3 HMMs的一个实例 171\n4.4.4 Viterbi算法的实现 176\n4.5 最大熵模型 179\n4.5.1 从词性标注谈起 179\n4.5.2 特征和约束 181\n4.5.3 最大熵原理 183\n4.5.4 公式推导 185\n4.5.5 对偶问题的极大似然估计 186\n4.5.6 GIS实现 188\n4.6 条件随机场模型 193\n4.6.1 随机场 193\n4.6.2 无向图的团(Clique)与因子分解 194\n4.6.3 线性链条件随机场 195\n4.6.4 CRF的概率计算 198\n4.6.5 CRF的参数学习 199\n4.6.6 CRF预测标签 200\n4.7 结语 201\n第5章 词性、语块与命名实体识别 202\n5.1 汉语词性标注 203\n5.1.1 汉语的词性 203\n5.1.2 宾州树库的词性标注规范 205\n5.1.3stanfordNLP标注词性 210\n5.1.4 训练模型文件 213\n5.2 语义组块标注 219\n5.2.1 语义组块的种类 220\n5.2.2 细说NP 221\n5.2.3 细说VP 223\n5.2.4 其他语义块 227\n5.2.5 语义块的抽取 229\n5.2.6 CRF的使用 232\n5.3 命名实体识别 240\n5.3.1 命名实体 241\n5.3.2 分词架构与专名词典 243\n5.3.3 算法的策略——词典与统计相结合 245\n5.3.4 算法的策略——层叠式架构 252\n5.4 结语 259\n第6章 句法理论与自动分析 260\n6.1 转换生成语法 261\n6.1.1 乔姆斯基的语言观 261\n6.1.2 短语结构文法 263\n6.1.3 汉语句类 269\n6.1.4 谓词论元与空范畴 274\n6.1.5 轻动词分析理论 279\n6.1.6 NLTK操作句法树 280\n6.2 依存句法理论 283\n6.2.1 配价理论 283\n6.2.2 配价词典 285\n6.2.3 依存理论概述 287\n6.2.4 Ltp依存分析介绍 290\n6.2.5 Stanford依存转换、解析 293\n6.3 PCFG短语结构句法分析 298\n6.3.1 PCFG短语结构 298\n6.3.2 内向算法和外向算法 301\n6.3.3 Viterbi算法 303\n6.3.4 参数估计 304\n6.3.5 Stanford的PCFG算法训练 305\n6.4 结语 310\n第7章 建设语言资源库 311\n7.1 语料库概述 311\n7.1.1 语料库的简史 312\n7.1.2 语言资源库的分类 314\n7.1.3 语料库的设计实例：国家语委语料库 315\n7.1.4 语料库的层次加工 321\n7.2 语法语料库 323\n7.2.1 中文分词语料库 323\n7.2.2 中文分词的测评 326\n7.2.3 宾州大学CTB简介 327\n7.3 语义知识库 333\n7.3.1 知识库与HowNet简介 333\n7.3.2 发掘义原 334\n7.3.3 语义角色 336\n7.3.4 分类原则与事件分类 344\n7.3.5 实体分类 347\n7.3.6 属性与分类 352\n7.3.7 相似度计算与实例 353\n7.4 语义网与百科知识库 360\n7.4.1 语义网理论介绍 360\n7.4.2 维基百科知识库 364\n7.4.3 DBpedia抽取原理 365\n7.5 结语 368\n第8章 语义与认知 370\n8.1 回顾现代语义学 371\n8.1.1 语义三角论 371\n8.1.2 语义场论 373\n8.1.3 基于逻辑的语义学 376\n8.2 认知语言学概述 377\n8.2.1 象似性原理 379\n8.2.2 顺序象似性 380\n8.2.3 距离象似性 380\n8.2.4 重叠象似性 381\n8.3 意象图式的构成 383\n8.3.1 主观性与焦点 383\n8.3.2 范畴化：概念的认知 385\n8.3.3 主体与背景 390\n8.3.4 意象图式 392\n8.3.5 社交中的图式 396\n8.3.6 完形：压缩与省略 398\n8.4 隐喻与转喻 401\n8.4.1 隐喻的结构 402\n8.4.2 隐喻的认知本质 403\n8.4.3 隐喻计算的系统架构 405\n8.4.4 隐喻计算的实现 408\n8.5 构式语法 412\n8.5.1 构式的概念 413\n8.5.2 句法与构式 415\n8.5.3 构式知识库 417\n8.6 结语 420\n第9章 NLP中的深度学习 422\n9.1 神经网络回顾 422\n9.1.1 神经网络框架 423\n9.1.2 梯度下降法推导 425\n9.1.3 梯度下降法的实现 427\n9.1.4 BP神经网络介绍和推导 430\n9.2 Word2Vec简介 433\n9.2.1 词向量及其表达 434\n9.2.2 Word2Vec的算法原理 436\n9.2.3 训练词向量 439\n9.2.4 大规模上下位关系的自动识别 443\n9.3 NLP与RNN 448\n9.3.1Simple-RNN 449\n9.3.2 LSTM原理 454\n9.3.3 LSTM的Python实现 460\n9.4 深度学习框架与应用 467\n9.4.1 Keras框架介绍 467\n9.4.2 Keras序列标注 471\n9.4.3 依存句法的算法原理 478\n9.4.4 Stanford依存解析的训练过程 483\n9.5 结语 488\n第10章 语义计算的架构 490\n10.1 句子的语义和语法预处理 490\n10.1.1 长句切分和融合 491\n10.1.2 共指消解 496\n10.2 语义角色 502\n10.2.1 谓词论元与语义角色 502\n10.2.2PropBank简介 505\n10.2.3 CPB中的特殊句式 506\n10.2.4 名词性谓词的语义角色 509\n10.2.5PropBank展开 512\n10.3 句子的语义解析 517\n10.3.1 语义依存 517\n10.3.2 完整架构 524\n10.3.3 实体关系抽取 527\n10.4 结语 531 [29]"}
