{"content2":"1、利用结巴分词对中文句子进行分词，词性标注（词性标注使用的词性兼容了ICTCLAS汉语词性标准）\n参考https://gist.github.com/luw2007/6016931\n2、将词的文本和词性打包，视为“词对象”，对应 :class:Word(token,pos)\n3、利用REfo模块对词进行对象级别（object-level）的正则匹配，判断问题属于3中类型中的哪一种，并产生对应的SPARQL，对应:class:Rule(condition,action)\n传统数据主要分成两种，格式化数据和非格式化数据。格式化数据转化成知识图谱时需要将格式化的数据映射成实体关系组，从而构建知识图谱。而非格式化的数据转化时比较复杂，通常采用算法抽取和程序抽取两种方式。\n1.算法抽取方式：\n通过自然语言处理（NLP）技术对文本进行命名实体识别（NER），从非格式化的文本中识别出专有名词和有意义的短语并进行分类。比如上例中从“达观数据是一家人工智能公司”这段文本中识别出”达观数据”和“人工智能公司”这两个实体以及“是”这个从属关系，这样我们就可以通过”达观数据” “是” “人工智能公司” 这个实体组来构建知识图谱。由于目前NER识别技术还不够成熟，通常我们会对 NER 识别的实体进行人工矫正，确保所识别实体的准确性。\n2.程序抽取方式：\n在处理实体识别非格式化数据的过程中我们经常会碰到半格式化的数据，比如一段简历的文本，文本中经常会包含，姓名：XXX，公司名：XXX 等格式，遇到这样的半格式化文本，我们也可以采用正则等方式来抽取，确保知识图谱构建的完整性和准确性。\nNeo4j：返回一个关系：match (n {name:”A”})-[r:KNOWS]->(c) return r;\n在自然语言处理领域，针对知识图谱的研究主要在两个方面。一是信息抽取，目前互联网上大部分是非结构化的文本数据，如何从非结构的文本数据中抽取出知识图谱所需要的三元组是一项具有挑战的任务；二是语义解析，即将用户输入的自然语言问题转化成面向知识图谱的结构化查询。（子图匹配？）"}
