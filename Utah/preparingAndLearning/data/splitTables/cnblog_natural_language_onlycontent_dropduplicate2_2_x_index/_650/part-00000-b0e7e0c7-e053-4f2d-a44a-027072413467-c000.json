{"content2":"目的：把文本用数据的形式表达出来\n方法：传统基于规则，现代基于统计\n一、词编码方式1——离散表示\n1、One-hot编码\n和句子中顺序无关，耗空间耗时\n2、词袋模型\n每个数表示该词出现的次数（One-hot的加和）\n3、TF_IDF\n每个数代表该词在整个文档中的占比\n4、N-gram\n相邻N个词作为一组进行编码，缺点是浪费空间、无法衡量词之间的关系\n二、词编码方式2——分布式表示\n所谓分布式表示，就是将“红色小型汽车”变成“红色+小型+汽车”\n于是产生了现代统计自然语言处理中最有创见的想法之一：用一个词附近的其他词来表示该词。\n一开始用“共现矩阵”表示，后来发现它有耗空间过大、稀疏等问题，因此需要找到方法构造低维稠密向量作为词的分布式表示 (25~1000维)!\n一开始有用SVD分解的方法，后来发现它与其他深度学习模型框架差异大\n又有了NNLM方法如下图所示：（七月算法自然语言处理课程PPT）\n这个模型复杂度较高。于是有了现在最常用的word2vec模型。\n三、Work2Vec\n1、CBOW\n待续\n2、Skip-Gram\n待续\n当语料特别大时，多用Skip-Gram\n-》Word2Vec对多义词表示的并不好，因此有了改进版本GloVe，但用的不多。\n-》还有sense2vec模型，它是将词性和word2vec结合的技术。\n-》seq2seq 待续"}
