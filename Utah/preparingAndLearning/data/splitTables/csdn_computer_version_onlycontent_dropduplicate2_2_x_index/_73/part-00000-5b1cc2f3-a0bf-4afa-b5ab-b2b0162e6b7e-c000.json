{"content2":"https://www.toutiao.com/a6646959085440729608/\n行业级最先进的 计算机视觉技术\n如今，人工智能在工业领域有着蓬勃发展趋势，因为自动化以及优化仍是数字革命的主要焦点。\n在本文中，我们将回顾近几年在AI社区中那些令人兴奋的最先进的计算机视觉技术，这些技术被认为是工业就绪的，而且对工业用例产生重大而又实际的影响。\n其中一些技术对性能的提升达到了令人难以置信的程度，超越了人类能达到的性能水平，从而超出了大多数行业所期望的精度和可靠性标准。\n在基本的计算机视觉任务（例如图像分类）中取得的惊人进步，使得可靠地结合多种技术来创建新的复合技术从而实现之前从未在工业环境中探索过的全新用例成为可能。\n话虽如此，这些新技术已经证明其结果可与那些只能通过非常密集的硬件专用系统才能获得的精度和可靠性结果相媲美。虽然在实现这些专用系统和安装与之相关的硬件方面存在实际的困难和限制，但相机是很容易买到的，从而极大地扩大了用例范围。\nAI赋能的计算机视觉系统使得有可能跨入到一个新的领域，加速了工业4.0，真正数字化和物理现实增强的进程。\n在我们深入了解计算机视觉领域的最新进展之前，让我们先介绍一些基本概念以及深度学习和计算机视觉这方面的历史事件。\n计算机视觉是什么？\n计算机视觉是一门科学，旨在使计算机能够理解并从图形和视频中洞悉信息。计算机视觉，即自动执行视觉任务的能力，例如从图形或视频中提取和分析有用的信息。\n机器学习和深度学习的关系！\n机器学习是算法和统计模型的科学研究，它依赖于数据驱动的方法来做决策而不是基于规则的方法。给定大量高质量数据并通过改进算法，机器学习系统能够逐步提高其在特定任务上的性能。\n深度学习是机器学习的子类，完全侧重于一组可描述为网络的数学算法。它们起初受到人脑中发现的生物神经网络的启发，同样，人工神经网络具有数百万个人工突触，数学上由数百万个简单的线性代数方程表示。\n深度学习驱动计算机视觉\n自2012年深度学习神经网络一直是计算机视觉的主要关注点是有理由的。由深度学习驱动的计算机视觉系统的优点是它们具有更高准确性，更灵活，且对大量的光线条件变化，视点，尺度，方向，与背景融合，类内差异，变形以及视觉遮挡等情况具有更高容忍度。但最重要的是，它们启发了新的用例。\n早期的计算机视觉模型依赖于原始像素数据作为机器学习模型的输入。然而，单独的原始像素数据不足以包含图像中对象的千变万化。\n深度学习驱动的计算机视觉基于深度神经网络可在训练阶段自动提取和创建特定任务的特征，然后将其用于执行计算机视觉任务。\n下图突出了深度学习和计算机视觉近6年历史中最重要的一些事件。\n2012年引入深度神经网络所带来的突破使得图像分类误差减少了约10%（从2011年的25.8%降至2012年的16.4%）。\n2015年最先进的算法在图像分类方面的表现超过了人类水平（5.1%，Russakovsky et al.）,准确率为3.57%。\n总体而言，深度神经网络的引入导致图像分类误差减少10倍（从2011年的25.8%将至2017年的2.3%）。\n值得注意的是，上述结果是在ImageNet数据集上实现的，其中20,000个类别具有典型类别，例如“气球”或“草莓”，由数百个低分辨率469x387像素图像组成。计算机视觉系统应用于具有较少类别，较少变化和较多数量的较高分辨率图像的特定任务时，其准确度可以高达99.9%。这使得完全独立自信地运行一个系统成为可能。\n详细了解计算机视觉技术\n现在我们已经介绍了基础知识，我们可以更详细地了解这些技术了。\n图像分类\n在本节中，我们将介绍图像分类，这是将一组固定类别中的一个标签分配给图像的任务。这是计算机视觉中的核心问题之一，尽管其简单，但其具有各种各样的实际应用。许多其它看似不同的计算机视觉任务（例如图像 字幕，目标检测，关键点检测和分割）可以简化为图像分类，其它任务利用全新的神经网络架构。以下视频片段说明了一个非常简单的分类事例。\n图像关键字和字幕\n该技术处于计算机视觉和自然语言处理（NLP）这两AI中最有趣领域的交点。关键字是用于描述照片或图像元素的单词。关键字是对照片添加描述性术语的过程。\n图像字幕是指基于图像中的对象和动作从图像或视频生成文本描述的过程。在下图中可以看到这方面的一个例子。\n目标检测\n目标检测是一种计算机视觉技术，用于识别和定位图像或视频中的对象。这通常通过带边框标记的框包围对象来完成。目标检测是自动驾驶汽车背后的关键技术，使它们能够识别其他汽车或区分行人与灯柱。它还可以用于各种应用，例如工业检测和机器人视觉。由于ImageNet竞赛，仅2010年至2014年间，定位误差（从42.5%降至25.3%）就减少了1.7倍。下面的视频片段显示了该技术的实时实施结果，用于检测城市中发现的与一辆自动驾驶视觉系统相关的车，人以及其他常见物体。\n关键点检测和姿态估计\n关键点被视为图像有趣或重要部分的特征。它们是图像中的空间位置或点，定义图像中有趣的内容或突出的内容。关键点之所以特殊，是因为它使得跟踪修改后的图像中的相同关键点成为可能，其中图像或图像中的对象会发生旋转、收缩/膨胀或变形。\n姿态估计是计算机视觉中的一个普遍问题，其目的是检测物体的位置和方向。这通常意味着检测对象的关键点位置。这种技术可以用来创建一个非常精确的二维/三维模型，描述对象关键点的位置，然后可以用来创建一个数字孪生兄弟。\n例如，在姿态估计问题中，可以检测到常见的方形家居对象的角点，从而可以深入了解对象在环境中的三维位置。\n同样的方法也可以用于检测人体姿势，人体上的关键点如肩膀、肘部、手、膝盖和脚都会被检测到。\n语义分割\n下一种技术称为语义分割（也称为对象掩蔽），它解决了计算机视觉领域的一个关键问题：直观地分离图像中的物体。从大的图像上看，语义分割为完全理解场景铺平了道路。这是非常有用的，因为它使计算机能够精确地识别不同物体的边界。场景理解作为一个计算机视觉的核心问题，其重要性在于从语义分割中所获得的知识使得越来越多的应用程序的健壮性得以提升。在下面所示的自动驾驶汽车示例中，它帮助汽车识别道路和其他物体的准确位置。\n图像到图像转化\n下面提到的技术属于图像到图像转化的范畴。对于下面的技术，网络通过提高质量而不是提取见解或得出结论来增强图像和视频。\n超分辨率：\n此任务的目标是在同时提高细节级别的同时提高图像的分辨率。一个非常深的神经网络最近在图像超分辨率方面取得了巨大的成功。放大倍数适用于2倍放大，如下图所示。\n超分辨率图像残留的密集网络（Zhang等人,2018日三月）\n夜视\n在弱光下成像是一项挑战。短曝光图像会产生噪声，长曝光时间会导致动态模糊。后者通常也不切实际，尤其是对于手持摄影。人们已经提出了各种去噪、去模糊和增强技术，但它们的效果在极端条件下是有限的，例如夜间高速摄影。为了提高目前的标准，研究人员引入了一种基于深度网络端到端训练的低光图像处理技术。该网络直接利用原始传感器数据，取代了许多传统的图像处理技术。这可以在下面的图像中清楚地看到，暗噪声图像得到了显著的增强。\n在黑暗中学会看东西（Chen等人，2018年五月）\nSuper SloMo\n视频插值旨在在两个连续帧之间生成中间帧。这些人工生成的画面与原始图像有着不可区分的视觉特征。这项技术是放大摄像系统性能的理想方法。对多个数据集的实验结果表明，深度学习方法比现有的方法具有更好的一致性。这项技术的结果可以在下面的视频剪辑中看到，在原始帧之间添加7个中间帧来创建平滑的慢动作视频。\nSuper SloMo:视频插值多中间帧的高质量估计（Jiang等人,2018年7月）\n在本文中，我们研究了许多计算机视觉技术，这些技术是由最近几个月开发的深入学习提供动力的，并且已经展示了令人难以置信的结果，并准备在行业中实施。这些技术处于技术的前沿，通过提高速度、准确性、可靠性和灵活性，表现出明显的优于以前的技术。\n创新的关键驱动因素是近年来人工智能研究论文的数量激增，特别是在计算机视觉领域，使充分利用技术进步来改善工业运营的最新趋势变得更加重要。\n谢谢你的阅读！希望，你学到了一些新的和有用的关于最先进的计算机视觉技术的东西，这些技术已经为工业上的实际应用做好了准备。\n如果你想了解更多，请一定要为这篇文章鼓掌，并跟随我。"}
