{"content2":"视觉跟踪综述\n目标跟踪是绝大多数视觉系统中不可或缺的环节。在二维视频跟踪算法中，基于目标颜色信息或基于目标运动信息等方法是常用的跟踪方法。从以往的研究中我们发现，大多数普通摄像头（彩色摄像头）下非基于背景建模的跟踪算法都极易受光照条件的影响。这是因为颜色变化在某种程度上是光学的色彩变化造成的。如基于体素和图像像素守恒假设的光流算法它也是假设一个物体的颜色在前后两帧没有巨大而明显的变化。\n但在特定的场景应用中（如视频监控等领域），不失有一些经典的跟踪算法可以实现较好的跟踪效果。以下主要介绍三种经典的跟踪算法：CamShift算法、光流跟踪以及粒子滤波算法。最后将给出一个各种跟踪方法间的比较。\n1、  CamShift（Continuously Adaptive Mean Shift）跟踪算法\nCamShift算法是一种基于均值漂移的算法。均值移动的理论基础是概率密度估计。均值移动的过程实际上就是在概率密度空间中寻找局部极大点。从其全称可知CamShift的算法基础实际上是MeanShift算法，均值移动的操作过程可用如下几步来表示：\n(a)    计算以初始点x­0为中心的某一核窗所对应的均值移动向量mG(x0)；\n(b)    根据mG(x0)来移动核窗的中心位置，也即把mG(x0)中的加权平均值部分赋予x0，把x0作为新的初始点，并转回步骤(a)；\n(c)    重复(a)、(b)过程，直到满足某一预定的条件。\n因此，均值移动过程就是寻找数据分布最密处的过程。\n均值移动的实现过程可图示为：\n(1) 计算目标区域的均值、移动目标区域\n(2) 重新计算目标区域均值，还存在移动向量，继续移动目标区域\n(3) 移动向量越来越小\n(4)  找到局部极大点，停止移动\n以上过程只是一次MeanShift算法过程，在连续帧上使用MeanShift算法就是CamShift跟踪算法。CamShift同经典的均值移动跟踪算法的基本思想是相同的，所不同的它是建立在颜色概率分布图和矩的基础之上。CamShift对室内环境下的目标跟踪具有较高的鲁棒性。\n1、  光流跟踪算法\n将三维空间中的目标和场景对应于二维图像平面运动时，他们在二维图像平面的投影就形成了运动，这种运动以图像平面亮度模式表现出来的流动就称为光流。光流法是对运动序列图像进行分析的一个重要方法，光流不仅包含图像中目标的运动信息，而且包含了三维物理结构的丰富信息，因此可用来确定目标的运动情况以及反映图像其它等信息。\n光流是空间运动物体在观测成像面上的像素运动的瞬时速度。光流的研究是利用图像序列中的像素强度数据的时域变化和相关性来确定各自像素位置的“运动”，即研究图像灰度在时间上的变化与景象中物体结构及其运动的关系。一般情况下，光流由相机运动、场景中目标运动或两者的共同运动产生。光流计算方法大致可分为三类：基于匹配的、频域的和梯度的方法。\n(1) 基于匹配的光流计算方法包括基于特征和基于区域两种。基于特征的方法不断地对目标主要特征进行定位和跟踪，对大目标的运动和亮度变化具有鲁棒性。存在的问题是光流通常很稀疏，而且特征提取和精确匹配也十分困难。基于区域的方法先对类似的区域进行定位，然后通过相似区域的位移计算光流。这种方法在视频编码中得到了广泛的应用。然而，它计算的光流仍不稠密。\n(2) 基于频域的方法利用速度可调的滤波组输出频率或相位信息。虽然能获得高精度的初始光流估计，但往往涉及复杂的计算。另外，进行可靠性评价也十分困难。\n(3) 基于梯度的方法利用图像序列的时空微分计算2D速度场（光流）。由于计算简单和较好的效果，基于梯度的方法得到了广泛的研究。虽然很多基于梯度的光流估计方法取得了较好的光流估计，但由于在计算光流时涉及到可调参数的人工选取、可靠性评价因子的选择困难，以及预处理对光流计算结果的影响，在应用光流对目标进行实时监测与自动跟踪时仍存在很多问题。\n光流法检测运动物体的基本原理是：给图像中的每一个像素点赋予一个速度矢量，这就形成了一个图像运动场，在运动的一个特定时刻，图像上的点与三维物体上的点一一对应，这种对应关系可由投影关系得到，根据各个像素点的速度矢量特征，可以对图像进行动态分析。如果图像中没有运动物体，则光流矢量在整个图像区域是连续变化的。当图像中有运动物体时，目标和图像背景存在相对运动，运动物体所形成的速度矢量必然和邻域背景速度矢量不同，从而检测出运动物体及位置。采用光流法进行运动物体检测的问题主要在于大多数光流法计算耗时，实时性和实用性都较差。但是光流法的优点在于光流不仅携带了运动物体的运动信息，而且还携带了有关景物三维结构的丰富信息，它能够在不知道场景的任何信息的情况下，检测出运动对象。\n对于视频监控系统来说，所用的图像基本都是摄像机静止状态下摄取得，所以对有实时性和准确性要求的系统来说，纯粹使用光流法来检测目标不太实际。更多的是利用光流计算方法与其它方法相结合来实现对目标检测和运动估计。\n然而，在实际应用中，由于遮挡性、多光源、透明性和噪声等原因，使得光流场基本方程的灰度守恒假设条件不能满足，不能求解出正确的光流场，同时大多数的光流计算方法相当复杂，计算量巨大，不能满足实时的要求，因此，一般不被对精度和实时性要求比较高的监控系统所采用。\n3、  粒子滤波跟踪算法\n粒子滤波算法有很多变种，以Rob Hess实现的这种最基本的粒子滤波算法为例。它的核心思想是随机采样和重要性重采样。在不知道目标在哪里的情况下，随机向场景中分散粒子，撒完粒子后，根据特征相似度计算每个粒子的重要性，然后在重要的地方多撒粒子，不重要的地方少撒粒子。所以说粒子滤波较之蒙特卡洛滤波计算量较小。这种思想虽然简单，但效果往往很好。\n粒子滤波实现对目标的跟踪通常分以下四个步骤：\n(1)    初始化阶段-提取跟踪目标特征\n该阶段要人工指定跟踪目标，程序计算跟踪目标的特征，比如可以采用目标的颜色特征。这点和CamShift算法类似，不能实现自动初始化。但我们可以在初始时给定一个颜色样本，实现程序的半自动初始化。然后计算该区域色调(Hue)空间的直方图，即为目标的特征。直方图可以用一个向量来表示，所以目标特征就是一个N*1的向量V。\n(2)    搜索阶段—分撒搜索粒子\n获取目标特征后，在场景中分撒许多搜索粒子去搜索目标对象。粒子分撒有许多种方式。比如，a) 均匀分撒。即在整个图像平面均匀的撒粒子(uniform distribution)；b)在上一帧得到的目标附近按照高斯分布来放，可以理解成，靠近目标的地方多放，远离目标的地方少放。Rob Hess的代码用的是后一种方法。粒子放出去后按照初始化阶段得到的目标特征(色调直方图，向量V)计算它所处的位置处图像的颜色特征，得到一个色调直方图，向量Vi，计算该直方图与目标直方图的相似性（直方图匹配）。相似性有多种度量，最简单的一种是计算sum(abs(Vi-V))。每个粒子算出相似度后再做一次归一化，使得所有的粒子得到的相似度加起来等于1。\n(3)      决策阶段\n分撒出去的每个粒子将返回其所处位置的图像信息。比如，“一号粒子处图像与目标的相似度是0.3”,“二号粒子处图像与目标的相似度是0.02”,“三号粒子处图像与目标的相似度是0.0003”,“N号粒子处图像与目标的相似度是0.013”然后做加权平均。设N号粒子的图像像素坐标是(Xn,Yn),它报告的相似度是Wn,于是目标最可能的像素坐标X = sum(Xn*Wn),Y = sum(Yn*Wn)。\n(4)      重采样阶段Resampling\n在新的一帧图像里，为了搜索到目标的新位置，需要再分撒粒子进行搜索。但现在应该怎样分撒呢？这要根据上一帧各个粒子返回的相似度报告。比如，“一号粒子处图像与目标的相似度是0.3”,“二号粒子处图像与目标的相似度是0.02”,“三号粒子处图像与目标的相似度是0.0003”,“N号粒子处图像与目标的相似度是0.013”。综合所有粒子的报告，一号粒子处的相似度最高，三号粒子处的相似度最低，于是要重新分撒粒子，在相似度最高的粒子那里放更多条粒子，在相似度最低的粒子那里少放粒子，甚至把原来那条粒子也撤回来。这就是Sampling Importance Resampling，根据重要性重采样(更具重要性重新放粒子)。\n(2)->(3)->(4)->(2)如是反复循环，即完成了目标的动态跟踪。\n粒子滤波跟踪算法可用于视频监控领域，可以跟踪速度较快的跟踪目标。\n4、  其他跟踪算法及优缺点\n将其他一些常用的跟踪算法及优缺点形成了一个表，其原理不做赘述，可参阅相关文献。\nlocal orientation correlation (LOC) , flocks of features tracking (FF) , optical flow tracking using templates on a regular grid (OF) and local feature tracking, KLT-tracker(KLT) , and boosted detection (BD).\n参考\n[1] 《基于均值移动的人脸跟踪简介》 未公开\n[2] http://kb.cnblogs.com/a/1742263/\n[3] AIDIA – Adaptive Interface for Display Interaction\n[4] http://baike.baidu.com/view/2810997.htm\n分类: 目标跟踪\nposted @ 2012-04-18 16:05 Hanson-jun 阅读(68) 评论(0) 编辑\n机器视觉开源处理库汇总\n从cvchina搞到的机器视觉开源处理库汇总，转来了，很给力，还在不断更新。。。\n通用库/General Library\nOpenCV\n无需多言。\nRAVL\nRecognition And Vision Library. 线程安全。强大的IO机制。包含AAM。\nCImg\n很酷的一个图像处理包。整个库只有一个头文件。包含一个基于PDE的光流算法。\n图像，视频IO/Image, Video IO\nFreeImage\nDevIL\nImageMagick\nFFMPEG\nVideoInput\nportVideo\nAR相关/Augmented Reality\nARToolKit\n基于Marker的AR库\nARToolKitPlus\nARToolKit的增强版。实现了更好的姿态估计算法。\nPTAM\n实时的跟踪、SLAM、AR库。无需Marker，模板，内置传感器等。\nBazAR\n基于特征点检测和识别的AR库。\n局部不变特征/Local Invariant Feature\nVLFeat\n目前最好的Sift开源实现。同时包含了KD-tree，KD-Forest，BoW实现。\nFerns\n基于Naive Bayesian Bundle的特征点识别。高速，但占用内存高。\nSIFT By Rob Hess\n基于OpenCV的Sift实现。\n目标检测/Object Detection\nAdaBoost By JianXin.Wu\n又一个AdaBoost实现。训练速度快。\n行人检测 By JianXin.Wu\n基于Centrist和Linear SVM的快速行人检测。\n（近似）最近邻/ANN\nFLANN\n目前最完整的（近似）最近邻开源库。不但实现了一系列查找算法，还包含了一种自动选取最快算法的机制。\nANN\n另外一个近似最近邻库。\nSLAM & SFM\nSceneLib [LGPL]\nmonoSLAM库。由Androw Davison开发。\n图像分割/Segmentation\nSLIC Super Pixel\n使用Simple Linear Iterative Clustering产生指定数目，近似均匀分布的Super Pixel。\n目标跟踪/Tracking\nTLD\n基于Online Random Forest的目标跟踪算法。\nKLT\nKanade-Lucas-Tracker\nOnline boosting trackers\nOnline Boosting Trackers\n直线检测/Line Detection\nDSCC\n基于联通域连接的直线检测算法。\nLSD [GPL]\n基于梯度的，局部直线段检测算子。\n指纹/Finger Print\npHash [GPL]\n基于感知的多媒体文件Hash算法。（提取，对比图像、视频、音频的指纹）\n视觉显著性/Visual Salience\nGlobal Contrast Based Salient Region Detection\nMing-Ming Cheng的视觉显著性算法。\nFFT/DWT\nFFTW [GPL]\n最快，最好的开源FFT。\nFFTReal [WTFPL]\n轻量级的FFT实现。许可证是亮点。\n音频处理/Audio processing\nSTK [Free]\n音频处理，音频合成。\nlibsndfile [LGPL]\n音频文件IO。\nlibsamplerate [GPL ]\n音频重采样。\n小波变换\n快速小波变换（FWT）\nFWT\nBRIEF: Binary Robust Independent Elementary Feature 一个很好的局部特征描述子，里面有FAST corner + BRIEF实现特征点匹配的DEMO：http://cvlab.epfl.ch/software/brief/\nhttp://code.google.com/p/javacv\nJava打包的OpenCV, FFmpeg, libdc1394, PGR FlyCapture, OpenKinect, videoInput, and ARToolKitPlus库。可以放在Android上用~\nlibHIK,HIK SVM，计算HIK SVM跟Centrist的Lib。http://c2inet.sce.ntu.edu.sg/Jianxin/projects/libHIK/libHIK.htm\n一组视觉显著性检测代码的链接：http://cg.cs.tsinghua.edu.cn/people/~cmm/saliency/\n分类: 编码杂记\nposted @ 2012-04-18 16:05 Hanson-jun 阅读(175) 评论(0) 编辑\n不规则物体形状匹配综述\n不规则物体形状匹配综述\n物体识别是计算机视觉应用的一项基本任务。识别通常基于目标物体的灰度信息、颜色信息或形状信息。物体识别的目的就是要找到一个包含可以区分不同目标物体的有效信息的描述。由于要识别的物体是事先知道的，所以目标物体的几何特征可以被直接应用到识别任务中。\n不规则物体的形状匹配是一种有效的利用物体几何特征进行识别的方法。根据匹配对象的不同，可以将不规则物体的形状匹配分为基于区域的匹配方法和基于轮廓的匹配方法。\n一、基于轮廓特征的形状匹配\n基于轮廓特征的形状匹配在实际中更为常用，这主要有两方面的原因：一是基于轮廓特征的匹配计算量小，可以较好的满足实时性要求；二是要识别的目标物通常是预先知道的，那么它的几何信息完全可以被用于识别过程中。为了识别不规则物体，主要任务就是设计一种基于（少量的）目标物几何约束先验知识的有效匹配方法。\n1.   链码直方图(chain code histogram)\n链码直方图将人眼看上去相似的物体归为一类。因此利用它不能进行精确的识别和分类。\n方向链码（Freeman链码）是用来表示物体轮廓的典型链码表示法。一条离散曲线可以定义为Z2域内一组数量有限的8联通点。因此，一条数字化二值曲线可以用方向链码表示方向链码是相邻两像素连线的8种可能的方向值。一条曲线被网格离散化后形成n个链码方向，最终此曲线链码可表示为{ai}n，每条链指向8个方向重的一个方向，ai={0,1,2,3,4,5,6,7}，i为像素的索引值，ai是由像素(i)指向像素(i+1)的方向链码。\n链码直方图的计算简单而且快速。计算公式如下：\n其中，nk是一个链码中链码值k的数目，n是一个链码中的节点数。\n(a)编码的方向示意，(b)简单物体形状，(c)形状的链码表示，(d)链码直方图\n链码法的特点：\n(1) 计算量小，可满足实时性要求；\n(2) 具有平移、尺度不变性；\n(3) 具有90度旋转不变性；\n(4) 规格化链码直方图可以达到更好的旋转不变性。\n2.   成对几何直方图(Pairwise Geometric Histogram)\n成对几何直方图通过相对角和相对位置特征来描述目标轮廓，并采用关系直方图统计这对几何特征来进行形状索引。采用这种编码方式需要具备一定的前提，即对于一个不规则物体我们可以将其近似为一个几何多边形。这种编码方法可以很好地描述一个多边形物体。\n将不规则形状近似为多边形，并将其定义为边缘点的集合。这样它所包含的轮廓边缘（线段）就可以由连续的边缘点来表示。接下来我们计算多边形的PGH：将每一个轮廓边缘视为其方向上的基准线，那么它与其他轮廓边缘间的相对角 以及最大最小垂直距离(dmin和dmax)可以被计算出来。边缘之间的角度定义了直方图的行，然后在其中增加对应的计算出来的最大和最小距离的所有直方块，就得到了当前多边形的PGH。\n它具有如下特点：\n(1) 计算简单，可满足实时性要求；\n(2) 具有平移、尺度不变性；\n(3) 具有360度旋转不变性。\n3.   简单形状描述符的结合(Combination of Simple Shape Descriptors)\n如图，它们是几种简单的形状描述符，分别代表了凹凸性、主轴、致密性、差异性和椭圆差异性。\n凹凸性：轮廓凸包周长与原轮廓周长的比率。（所有凸起的覆盖轮廓称为凸包）\n主轴：过物体质心的正交轴，主轴之间的比例可以由物体轮廓的协方差矩阵计算出来\n致密性：物体区域面积与等面积的正方形周长的比例，也可以是圆。\n差异性：表现为与模板比较的比例均方误差。\n单独用这几种简单描述符的任何一种来表示形状进行匹配，都不能达到较好的匹配结果。但是如果我们将这五种简单形状描述符进行结合，同时用它们来描述一个形状，那么这个形状的描述信息就非常丰富了，匹配的结果也会很好。\n这种形状描述方式具有如下的特点：\n(1) 单独的任何一种简单描述符都不能用于精确识别物体，但是多种简单描述符的结合可以达到很高的识别效率；\n(2) 计算简单，可以达到实时性；\n(3) 具有平移、尺度不变性；\n(4) 理论上360度旋转不变性。\n4.   基于hausdorff距离的形状匹配\nHausdorff距离用来计算两个点集之间的匹配程度。给定两个有限集A={a1,a2,…,ap}和B={b1,b2,…,bq},A，B之间的Hausdorff距离定义如下：\n其中：\nHausdorff距离H(A,B)取h(A,B)和h(B,A)的最大值，这样通过计算h(A,B)和h(B,A)就可以获得两个点集A，B之间的匹配程度。\n为了减少计算量，可以取角点进行匹配。但这样匹配率将降低。基于hausdorff距离的形状匹配的特点;\n(1) 对每个边缘点进行hausdorff距离计算，计算量稍大，但对不是过于复杂的轮廓（如小尺寸轮廓），可以满足实时性；\n(2) 具有平移、尺度不变性；\n(3) 具有旋转不变性；\n二、基于区域特征的形状匹配\n基于不变矩的形状匹配是典型的基于区域的匹配方法。其中，基于Hu不变矩的形状匹配应用最为广泛。\n图像的矩函数在模式识别、目标分类中得到了广泛的应用。在1961年首先基于代数不变量引入矩不变量。通过对几何矩的非线性组合，导出了一组对于图像平移、尺度、旋转变化不变的矩，这种矩就成为Hu矩。\n一幅大小为M×N的二维图像其中(p+q)阶矩：\n对于二值图像，其零阶矩就是该形状区域的面积。因此，将面积归一化，每一个图像矩除以零阶矩得到的商具有形状的尺度变化无关性。\n求图像的p+q阶中心矩，面积归一化，使得具有平移、尺度不变性。\n(1)\n(2)\n计算图像的7个面积归一化的中心矩，{m11,m02,m20,m21,m12,m03,m30}Hu不变矩是关于这7个矩的函数。具有平移、旋转和尺度不变性。\n彩色图像Hu不变矩的计算流程如下：\n基于Hu矩的形状匹配所具有的特点：\n(1) Hu不变矩只能用于对区域的检测，不能用于边界的检测，但由于计算简单，计算量不大，可以满足实时性；\n(2) 具有平移、尺度不变性；\n(3) 具有旋转不变性。\n三、匹配方法间的比较\nCCH（链码直方图）：是一种基于轮廓匹配方法。具有较强的平移不变性，尺度不变性一般，具有90度的旋转不变性。由于编码简单，执行速度快。计算量和所需内存都较小，适合差别明显的物体，对平滑和非平滑物体的识别并不明显；\nPGH（成对几何直方图）：是一种基于轮廓匹配方法。具有较强的平移不变性和尺度不变性，具有360度的旋转不变性。执行速度快，可以较好地识别多边形物体和部分自封闭的物体，由于它的计算过程，对非多边形物体的识别可能会浪费计算量；\nCFSS（五种简单形状描述符结合）：是一种基于轮廓匹配方法。具有较强的平移不变性和尺度不变性，具有360度的旋转不变性。执行速度处于CCH方法和PGH方法之间。识别率与PGH相当，但是比它需要更少的计算时间和内存。\nHAUSDORFF距离：是一种基于轮廓匹配方法。具有较强的平移不变性，但是尺度不变性和旋转不变性都较差。由于处理的数据维数较多，执行效率是这五种方法中最慢的一个。可用于匹配部分重和形状物体。\nHu不变矩：是一种基于区域的形状匹配方法。具有较强的平移、尺度和旋转不变性，其中旋转不变性为360度。但由于匹配的数据量大，执行速度较慢。适合于进行一些更精确的匹配。\n分类: 目标识别\nposted @ 2012-04-18 16:04 Hanson-jun 阅读(42) 评论(0) 编辑\nHough变换原理\n一、简单介绍\nHough变换是图像处理中从图像中识别几何形状的基本方法之一。Hough变换的基本原理在于利用点与线的对偶性，将原始图像空间的给定的曲线通过曲线表达形式变为参数空间的一个点。这样就把原始图像中给定曲线的检测问题转化为寻找参数空间中的峰值问题。也即把检测整体特性转化为检测局部特性。比如直线、椭圆、圆、弧线等。\n二、Hough变换的基本思想\n设已知一黑白图像上画了一条直线，要求出这条直线所在的位置。我们知道，直线的方程可以用y=k*x+b 来表示，其中k和b是参数，分别是斜率和截距。过某一点(x0,y0)的所有直线的参数都会满足方程y0=kx0+b。即点(x0,y0)确定了一族直线。方程y0=kx0+b在参数k--b平面上是一条直线，(你也可以是方程b=-x0*k+y0对应的直线)。这样，图像x--y平面上的一个前景像素点就对应到参数平面上的一条直线。我们举个例子说明解决前面那个问题的原理。设图像上的直线是y=x, 我们先取上面的三个点：A(0,0), B(1,1), C(22)。可以求出，过A点的直线的参数要满足方程b=0, 过B点的直线的参数要满足方程1=k+b, 过C点的直线的参数要满足方程2=2k+b, 这三个方程就对应着参数平面上的三条直线，而这三条直线会相交于一点(k=1,b=0)。　同理，原图像上直线y=x上的其它点(如(3,3),(4,4)等)　对应参数平面上的直线也会通过点(k=1,b=0)。这个性质就为我们解决问题提供了方法，就是把图像平面上的点对应到参数平面上的线，最后通过统计特性来解决问题。假如图像平面上有两条直线，那么最终在参数平面上就会看到两个峰值点，依此类推。\n简而言之，Hough变换思想为：在原始图像坐标系下的一个点对应了参数坐标系中的一条直线，同样参数坐标系的一条直线对应了原始坐标系下的一个点，然后，原始坐标系下呈现直线的所有点，它们的斜率和截距是相同的，所以它们在参数坐标系下对应于同一个点。这样在将原始坐标系下的各个点投影到参数坐标系下之后，看参数坐标系下有没有聚集点，这样的聚集点就对应了原始坐标系下的直线。\n在实际应用中，y=k*x+b形式的直线方程没有办法表示x=c形式的直线(这时候，直线的斜率为无穷大)。所以实际应用中，是采用参数方程p=x*cos(theta)+y*sin(theta)。这样，图像平面上的一个点就对应到参数p---theta平面上的一条曲线上，其它的还是一样。\n三、Hough变换推广\n1、已知半径的圆\n其实Hough变换可以检测任意的已知表达形式的曲线，关键是看其参数空间的选择，参数空间的选择可以根据它的表达形式而定。比如圆的表达形式为 ，所以当检测某一半径的圆的时候，可以选择与原图像空间同样的空间作为参数空间。那么圆图像空间中的一个圆对应了参数空间中的一个点，参数空间中的一个点对应了图像空间中的一个圆，圆图像空间中在同一个圆上的点，它们的参数相同即a，b相同，那么它们在参数空间中的对应的圆就会过同一个点（a，b），所以，将原图像空间中的所有点变换到参数空间后，根据参数空间中点的聚集程度就可以判断出图像空间中有没有近似于圆的图形。如果有的话，这个参数就是圆的参数。\n2、未知半径的圆\n对于圆的半径未知的情况下，可以看作是有三个参数的圆的检测，中心和半径。这个时候原理仍然相同，只是参数空间的维数升高，计算量增大。图像空间中的任意一个点都对应了参数空间中的一簇圆曲线。 ，其实是一个圆锥型。参数空间中的任意一个点对应了图像空间中的一个圆。\n3、椭圆\n椭圆有5个自由参数，所以它的参数空间是5维的，因此他的计算量非常大，所以提出了许多的改进算法。\n四、总结\n图像空间中的在同一个圆，直线，椭圆上的点，每一个点都对应了参数空间中的一个图形，在图像空间中这些点都满足它们的方程这一个条件，所以这些点，每个投影后得到的图像都会经过这个参数空间中的点。也就是在参数空间中它们会相交于一点。所以，当参数空间中的这个相交点的越大的话，那么说明元图像空间中满足这个参数的图形越饱满。越象我们要检测的东西。\nHough变换能够查找任意的曲线，只要你给定它的方程。Hough变换在检验已知形状的目标方面具有受曲线间断影响小和不受图形旋转的影响的优点，即使目标有稍许缺损或污染也能被正确识别。\n转自：http://blog.csdn.net/icerain_3321/article/details/1665280\nposted @ 2012-04-18 16:02 Hanson-jun 阅读(24) 评论(0) 编辑\n介绍n款计算机视觉库/人脸识别开源库/软件\n计算机视觉库 OpenCV\nOpenCV是Intel®开源计算机视觉库。它由一系列 C 函数和少量 C++ 类构成，实现了图像处理和计算机视觉方面的很多通用算法。 OpenCV 拥有包括 300 多个C函数的跨平台的中、高层 API。它不依赖于其它的外部库——尽管也可以使用某些外部库。 OpenCV 对非商业...\n人脸识别 faceservice.cgi\nfaceservice.cgi 是一个用来进行人脸识别的 CGI 程序， 你可以通过上传图像，然后该程序即告诉你人脸的大概坐标位置。faceservice是采用 OpenCV 库进行开发的。\nOpenCV的.NET版 OpenCVDotNet\nOpenCVDotNet 是一个 .NET 对 OpenCV 包的封装。\n人脸检测算法 jViolajones\njViolajones是人脸检测算法Viola-Jones的一个Java实现，并能够加载OpenCV XML文件。 示例代码：http://www.oschina.net/code/snippet_12_2033\nJava视觉处理库 JavaCV\nJavaCV 提供了在计算机视觉领域的封装库，包括：OpenCV、ARToolKitPlus、libdc1394 2.x 、PGR FlyCapture和FFmpeg。此外，该工具可以很容易地使用Java平台的功能。 JavaCV还带有硬件加速的全屏幕图像显示（CanvasFrame），易于在多个内核中执行并行代码（并...\n运动检测程序 QMotion\nQMotion 是一个采用 OpenCV 开发的运动检测程序，基于 QT。\n视频监控系统 OpenVSS\nOpenVSS - 开放平台的视频监控系统 - 是一个系统级别的视频监控软件视频分析框架（VAF）的视频分析与检索和播放服务，记录和索引技术。它被设计成插件式的支持多摄像头平台，多分析仪模块（OpenCV的集成），以及多核心架构。\n手势识别 hand-gesture-detection\n手势识别，用OpenCV实现\n人脸检测识别 mcvai-tracking\n提供人脸检测、识别与检测特定人脸的功能，示例代码 cvReleaseImage( &gray ); cvReleaseMemStorage(&storage); cvReleaseHaarClassifierCascade(&cascade);...\n人脸检测与跟踪库 asmlibrary\nActive Shape Model Library (ASMLibrary©) SDK, 用OpenCV开发，用于人脸检测与跟踪。\nLua视觉开发库 libecv\nECV 是 lua 的计算机视觉开发库(目前只提供linux支持)\nOpenCV的.Net封装 OpenCVSharp\nOpenCVSharp 是一个OpenCV的.Net wrapper，应用最新的OpenCV库开发，使用习惯比EmguCV更接近原始的OpenCV，有详细的使用样例供参考。\n3D视觉库 fvision2010\n基于OpenCV构建的图像处理和3D视觉库。 示例代码： ImageSequenceReaderFactory factory; ImageSequenceReader* reader = factory.pathRegex(\"c:/a/im_%03d.jpg\", 0, 20); //ImageSequenceReader* reader = factory.avi(\"a.avi\"); if (reader == NULL) { ...\n基于QT的计算机视觉库 QVision\n基于 QT 的面向对象的多平台计算机视觉库。可以方便的创建图形化应用程序，算法库主要从 OpenCV，GSL，CGAL，IPP，Octave 等高性能库借鉴而来。\n图像特征提取 cvBlob\ncvBlob 是计算机视觉应用中在二值图像里寻找连通域的库.能够执行连通域分析与特征提取.\n实时图像/视频处理滤波开发包 GShow\nGShow is a real-time image/video processing filter development kit. It successfully integrates DirectX11 with DirectShow framework. So it has the following features: GShow 是实时 图像/视频 处理滤波开发包，集成DiretX11。...\n视频捕获 API VideoMan\nVideoMan 提供一组视频捕获 API 。支持多种视频流同时输入（视频传输线、USB摄像头和视频文件等）。能利用 OpenGL 对输入进行处理，方便的与 OpenCV，CUDA 等集成开发计算机视觉系统。\n开放模式识别项目 OpenPR\nPattern Recognition project（开放模式识别项目），致力于开发出一套包含图像处理、计算机视觉、自然语言处理、模式识别、机器学习和相关领域算法的函数库。\nOpenCV的Python封装 pyopencv\nOpenCV的Python封装，主要特性包括： 提供与OpenCV 2.x中最新的C++接口极为相似的Python接口，并且包括C++中不包括的C接口 提供对OpenCV 2.x中所有主要部件的绑定：CxCORE (almost complete), CxFLANN (complete), Cv (complete), CvAux (C++ part almost...\n视觉快速开发平台 qcv\n计算机视觉快速开发平台，提供测试框架，使开发者可以专注于算法研究。\n图像捕获 libv4l2cam\n对函数库v412的封装，从网络摄像头等硬件获得图像数据，支持YUYV裸数据输出和BGR24的OpenCV  IplImage输出\n计算机视觉算法 OpenVIDIA\nOpenVIDIA projects implement computer vision algorithms running on on graphics hardware such as single or multiple graphics processing units(GPUs) using OpenGL, Cg and CUDA-C. Some samples will soon support OpenCL and Direct Compute API&apos;...\n高斯模型点集配准算法 gmmreg\n实现了基于混合高斯模型的点集配准算法，该算法描述在论文： A Robust Algorithm for Point Set Registration Using Mixture of Gaussians, Bing Jian and Baba C. Vemuri. ，实现了C++/Matlab/Python接口...\n模式识别和视觉库 RAVL\nRecognition And Vision Library (RAVL) 是一个通用 C++ 库，包含计算机视觉、模式识别等模块。\n图像处理和计算机视觉常用算法库 LTI-Lib\nLTI-Lib 是一个包含图像处理和计算机视觉常用算法和数据结构的面向对象库，提供 Windows 下的 VC 版本和 Linux 下的 gcc 版本，主要包含以下几方面内容： 1、线性代数 2、聚类分析 3、图像处理 4、可视化和绘图工具\nOpenCV优化 opencv-dsp-acceleration\n优化了OpenCV库在DSP上的速度。\nC++计算机视觉库 Integrating Vision Toolkit\nIntegrating Vision Toolkit (IVT) 是一个强大而迅速的C++计算机视觉库，拥有易用的接口和面向对象的架构，并且含有自己的一套跨平台GUI组件，另外可以选择集成OpenCV\n计算机视觉和机器人技术的工具包 EGT\nThe Epipolar Geometry Toolbox (EGT) is a toolbox designed for Matlab (by Mathworks Inc.). EGT provides a wide set of functions to approach computer vision and robotics problems with single and multiple views, and with different vision se...\nOpenCV的扩展库 ImageNets\nImageNets 是对OpenCV 的扩展，提供对机器人视觉算法方面友好的支持，使用Nokia的QT编写界面。\nlibvideogfx\n视频处理、计算机视觉和计算机图形学的快速开发库。\nMatlab计算机视觉包 mVision\nMatlab 的计算机视觉包，包含用于观察结果的 GUI 组件，貌似也停止开发了，拿来做学习用挺不错的。\nScilab的计算机视觉库 SIP\nSIP 是 Scilab（一种免费的类Matlab编程环境）的图像处理和计算机视觉库。SIP 可以读写 JPEG/PNG/BMP 格式的图片。具备图像滤波、分割、边缘检测、形态学处理和形状分析等功能。\nSTAIR Vision Library\nSTAIR Vision Library (SVL) 最初是为支持斯坦福智能机器人设计的，提供对计算机视觉、机器学习和概率统计模型的支持。\nposted @ 2012-04-18 15:57 Hanson-jun 阅读(111) 评论(0) 编辑\nUIUC某童鞋收集的代码合集\nJia-Bin Huang童鞋收集，此童鞋毕业于国立交通大学，之前拍过很多CVPR举办地科罗拉多州的照片，这里大多为matlab code,\nlink: https://netfiles.uiuc.edu/jbhuang1/www/resources/vision/index.html\n包括：\nFeature Extraction：\nSIFT [1] [Demo program][SIFT Library] [VLFeat]\nPCA-SIFT [2] [Project]\nAffine-SIFT [3] [Project]\nSURF [4] [OpenSURF] [Matlab Wrapper]\nAffine Covariant Features [5] [Oxford project]\nMSER [6] [Oxford project] [VLFeat]\nGeometric Blur [7] [Code]\nLocal Self-Similarity Descriptor [8] [Oxford implementation]\nGlobal and Efficient Self-Similarity [9] [Code]\nHistogram of Oriented Graidents [10] [INRIA Object Localization Toolkit] [OLT toolkit for Windows]\nGIST [11] [Project]\nShape Context [12] [Project]\nColor Descriptor [13] [Project]\nPyramids of Histograms of Oriented Gradients [Code]\nSpace-Time Interest Points (STIP) [14] [Code]\nBoundary Preserving Dense Local Regions [15][Project]\nImage Segmentation：\nNormalized Cut [1] [Matlab code]\nGerg Mori’ Superpixel code [2] [Matlab code]\nEfficient Graph-based Image Segmentation [3] [C++ code] [Matlab wrapper]\nMean-Shift Image Segmentation [4] [EDISON C++ code] [Matlab wrapper]\nOWT-UCM Hierarchical Segmentation [5] [Resources]\nTurbepixels [6] [Matlab code 32bit] [Matlab code 64bit] [Updated code]\nQuick-Shift [7] [VLFeat]\nSLIC Superpixels [8] [Project]\nSegmentation by Minimum Code Length [9] [Project]\nBiased Normalized Cut [10] [Project]\nSegmentation Tree [11-12] [Project]\nEntropy Rate Superpixel Segmentation [13] [Code]\nObject Detection：\nA simple object detector with boosting [Project]\nINRIA Object Detection and Localization Toolkit [1] [Project]\nDiscriminatively Trained Deformable Part Models [2] [Project]\nCascade Object Detection with Deformable Part Models [3] [Project]\nPoselet [4] [Project]\nImplicit Shape Model [5] [Project]\nViola and Jones’s Face Detection [6] [Project]\nSaliency Detection\nItti, Koch, and Niebur’ saliency detection [1] [Matlab code]\nFrequency-tuned salient region detection [2] [Project]\nSaliency detection using maximum symmetric surround [3] [Project]\nAttention via Information Maximization [4] [Matlab code]\nContext-aware saliency detection [5] [Matlab code]\nGraph-based visual saliency [6] [Matlab code]\nSaliency detection: A spectral residual approach. [7] [Matlab code]\nSegmenting salient objects from images and videos. [8] [Matlab code]\nSaliency Using Natural statistics. [9] [Matlab code]\nDiscriminant Saliency for Visual Recognition from Cluttered Scenes. [10] [Code]\nLearning to Predict Where Humans Look [11] [Project]\nGlobal Contrast based Salient Region Detection [12] [Project]\nImage Classification\nPyramid Match [1] [Project]\nSpatial Pyramid Matching [2] [Code]\nLocality-constrained Linear Coding [3] [Project] [Matlab code]\nSparse Coding [4] [Project] [Matlab code]\nTexture Classification [5] [Project]\nMultiple Kernels for Image Classification [6] [Project]\nFeature Combination [7] [Project]\nSuperParsing [Code]\nImage Matting\nClosed Form Matting [Code]\nSpectral Matting [Project]\nLearning-based Matting [Code]\n等等等等。。。。\n大家可以去那个网址自己看。。。。\nposted @ 2012-04-18 15:53 Hanson-jun 阅读(49) 评论(0) 编辑\n图像处理方面的网站\nhttp://blog.damiles.com\nwww.bernardotti.it\nhttp://www.ohloh.net/tags/recognition\nhttp://www.diphernet.com/\nhttp://www.mat.ucsb.edu/projects/tater/\nhttp://enblend.sourceforge.net/\nhttp://www.infra.kth.se/courses/1N1652/\nhttp://www.csie.ntu.edu.tw/~b93082/VFX/hw2/vfx02.htm#t3\nhttp://graphics.cs.msu.ru/en/research/calibration/\nhttp://www.vlfeat.org/~vedaldi/\nhttp://svn.openframeworks.cc/browser/listing.php?repname=addons&path=%2FofxOpenCv%2Ftrunk%2FofxOpenCv%2F&rev=29&sc=1\nhttp://cvlab.epfl.ch/software/ferns/index.php\nhttp://staff.science.uva.nl/~rvalenti/index.php?content=projects\nhttp://mpac.ee.ntu.edu.tw/~ck/project_panorama/#Downloads\nhttp://www.sharewareconnection.com/titles/cross-stitch.htm\nhttp://mpac.ee.ntu.edu.tw/~sutony/vfx_stitching/pano.htm\nhttp://mpac.ee.ntu.edu.tw/people.php\nhttp://mpac.ee.ntu.edu.tw/index.php\nhttp://www.cse.cuhk.edu.hk/~csc5280/project3/RoyChan/index.htm\nhttp://personal.ie.cuhk.edu.hk/~gbq008/csc_project_3.htm\nhttp://graphics.cs.cmu.edu/courses/15-463/2008_fall/463.html\nhttp://www-2.cs.cmu.edu/%7ecdtwigg/\nhttp://cs-people.bu.edu/edwardaa/cs580/p1/p1.html#goals\nhttp://www.cs.toronto.edu/~smalik/2530/mosaic/results.html\nhttp://www.cs.princeton.edu/gfx/\nhttp://idea.hosting.lv/a/gfx/\nhttp://www.cs.toronto.edu/~esteger/mosaic/index.html\nhttp://home.so-net.net.tw/lioucy\nhttp://web.ics.purdue.edu/~kim497/\nCUDA:\nhttp://gforge.man.poznan.pl/gf/project/cudaopencv/scmsvn/\nhttp://wiki.livedoor.jp/mikk_ni3_92/d/CUDA::2%C3%CD%B2%BD::%CA%A3%BF%F4%CB%E7\nhttp://cudasample.net/\n一、研究群体\nhttp://www-2.cs.cmu.edu/~cil/vision.html\n这是卡奈基梅隆大学的计算机视觉研究组的主页，上面提供很全的资料，从发表文章的下载到演示程序、测试图像、常用链接、相关软硬件，甚至还有一个搜索引擎。\nhttp://www.cmis.csiro.au/IAP/zimage.htm\n这是一个侧重图像分析的站点，一般。但是提供一个Image Analysis环境---ZIMAGE and SZIMAGE。\nhttp://www.via.cornell.edu/\n康奈尔大学的计算机视觉和图像分析研究组，好像是电子和计算机工程系的。侧重医学方面的研究，但是在上面有相当不错资源，关键是它正在建设中，能够跟踪一些信息。\nhttp://www2.parc.com/istl/groups/did/didoverview.shtml\n有一个很有意思的项目：DID(文档图像解码)。\nhttp://www-cs-students.stanford.edu/\n斯坦福大学计算机系主页，自己找吧:(\nhttp://www.fmrib.ox.ac.uk/analysis/\n主要研究：Brain Extraction Tool,Nonlinear noise reduction,Linear Image Registration,\nAutomated Segmentation,Structural brain change analysis,motion correction,etc.\nhttp://www.cse.msu.edu/prip/\n这是密歇根州立大学计算机和电子工程系的模式识别--图像处理研究组，它的FTP上有许多的文章(NEW)。\nhttp://pandora.inf.uni-jena.de/p/e/index.html\n德国的一个数字图像处理研究小组，在其上面能找到一些不错的链接资源。\nhttp://www-staff.it.uts.edu.au/~sean/CVCC.dir/home.html\nCVIP(used to be CVCC for Computer Vision and Cluster Computing) is a research group focusing on cluster-based computer vision within the Spiral Architecture.\nhttp://cfia.gmu.edu/\nThe mission of the Center for Image Analysis is to foster multi-disciplinary research in image, multimedia and related technologies by establishing links\nbetween academic institutes, industry and government agencies, and to transfer key technologies to\nhelp industry build next\ngeneration commercial and military imaging and multimedia systems.\nhttp://peipa.essex.ac.uk/info/groups.html\n可以通过它来搜索全世界各地的知名的计算机视觉研究组(CV Groups)，极力推荐。\n二、图像处理GPL库\nhttp://www.ph.tn.tudelft.nl/~klamer/cppima.html\nCppima 是一个图像处理的C++函数库。这里有一个较全面介绍它的库函数的文档，当然你也可以下载压缩的GZIP包，里面包含TexInfo格式的文档。\nhttp://iraf.noao.edu/\nWelcome to the IRAF Homepage! IRAF is the Image Reduction and Analysis Facility, a general purpose software\nsystem for the reduction and analysis of astronomical data.\nhttp://entropy.brni-jhu.org/tnimage.html\n一个非常不错的Unix系统的图像处理工具，看看它的截图。你可以在此基础上构建自己的专用图像处理工具包。\nhttp://sourceforge.net/projects/\n这是GPL软件集散地，到这里找你想要得到的IP库吧。\n三、搜索资源\n当然这里基本的搜索引擎还是必须要依靠的，比如Google等，可以到我常用的链接看看。下面的链接可能会节省你一些时间：\nhttp://sal.kachinatech.com/\nhttp://cheminfo.pku.edu.cn/mirrors/SAL/index.shtml\n四、大拿网页\nhttp://www.ai.mit.edu/people/wtf/\n这位可是MIT人工智能实验室的BILL FREEMAN。大名鼎鼎！专长是：理解--贝叶斯模型。\nhttp://www.merl.com/people/brand/\nMERL(Mitsubishi Electric Research Laboratory)中的擅长“Style Machine”高手。\nhttp://research.microsoft.com/~ablake/\nCV界极有声望的A.Blake 1977年毕业于剑桥大学三一学院并或数学与电子科学学士学位。之后在MIT，Edinburgh，Oxford先后组建过研究小组并成为Oxford的教授，直到1999年进入微软剑桥研究中心。主要工作领域是计算机视觉。\nhttp://www-2.cs.cmu.edu/afs/cs.cmu.edu/user/har/Web/home.html\n这位牛人好像正在学习汉语，并且搜集了诸如“两只老虎(Two Tigers)”的歌曲，嘿嘿:)\n他的主页上面还有几个牛：Shumeet Baluja, Takeo Kanade。他们的Face Detection作的绝对是世界一流。他毕业于卡奈基梅隆大学的计算机科学系，兴趣是计算机视觉。\nhttp://www.ifp.uiuc.edu/yrui_ifp_home/html/huang_frame.html\n这位老牛在1963年就获得了MIT的博士学位！他领导的Image Lab比较出名的是指纹识别。\n--------------------------------------------------------------------------------\n下面这些是我搜集的牛群(大部分是如日中天的Ph.D们)，可以学习的是他们的Study Ways!\nFinn Lindgren(Sweden):Statistical image analysis http://www.maths.lth.se/matstat/staff/finn/\nPavel Paclik(Prague):statistical pattern recognition http://www.ph.tn.tudelft.nl/~pavel/\nDr. Mark Burge:machine learning and graph theory http://cs.armstrong.edu/burge/\nyalin Wang:Document Image Analysis http://students.washington.edu/~ylwang/\nGeir Storvik: Image analysis http://www.math.uio.no/~geirs/\nHeidorn http://alexia.lis.uiuc.edu/~heidorn/\nJoakim Lindblad:Digital Image Cytometry http://www.cb.uu.se/~joakim/index_eng.html\nS.Lavirotte: http://www-sop.inria.fr/cafe/Stephane.Lavirotte/\nSporring:scale-space techniques http://www.lab3d.odont.ku.dk/~sporring/\nMark Jenkinson:Reduction of MR Artefacts http://www.fmrib.ox.ac.uk/~mark/\nJustin K. Romberg:digital signal processing http://www-dsp.rice.edu/~jrom/\nFauqueur:Image retrieval by regions of interest http://www-rocq.inria.fr/~fauqueur/\nJames J. Nolan:Computer Vision http://cs.gmu.edu/~jnolan/\nDaniel X. Pape:Information http://www.bucho.org/~dpape/\nDrew Pilant:remote sensing technology http://www.geo.mtu.edu/~anpilant/index.html\n五、前沿期刊(TOP10)\n这里的期刊大部分都可以通过上面的大拿们的主页间接找到，在这列出主要是为了节省直接想找期刊投稿的兄弟的时间:)\nIEEE Trans. On PAMI http://www.computer.org/tpami/index.htm\nIEEE Transactionson Image Processing http://www.ieee.org/organizations/pubs/transactions/tip.htm\nPattern Recognition http://www.elsevier.com/locate/issn/00313203\nPattern Recognition Letters http://www.elsevier.com/locate/issn/01678655\n神经网络\nNeural Networks Tutorial Review\nhttp://hem.hj.se/~de96klda/NeuralNetworks.htm\nftp://ftp.sas.com/pub/neural/FAQ.html\nImage Compression with Neural Networks\nhttp://www.comp.glam.ac.uk/digimaging/neural.htm\nBackpropagator's Review\nhttp://www.dontveter.com/bpr/bpr.html\nBibliographies on Neural Networks\nhttp://liinwww.ira.uka.de/bibliography/Neural/\nIntelligent Motion Control with an Artificial Cerebellum\nhttp://www.q12.org/phd.html\nKernel Machines\nhttp://www.kernel-machines.org/\nSome Neural Networks Research Organizations\nhttp://www.ieee.org/nnc/\nhttp://www.inns.org/\nNeural Network Modeling in Vision Research\nhttp://www.rybak-et-al.net/nisms.html\nNeural Networks and Machine Learning\nhttp://learning.cs.toronto.edu/\nNeural Application Software\nhttp://attrasoft.com\nNeural Network Toolbox for MATLAB\nhttp://www.mathworks.com/products/neuralnet/\nNetlab Software\nhttp://www.ncrg.aston.ac.uk/netlab/\nKunama Systems Limited\nhttp://www.kunama.co.uk/\nComputer Vision\nComputer Vision Homepage, Carnegie Mellon University\nwww.cs.cmu.edu/~cil/vision.html\nAnnotated Computer Vision Bibliography\nhttp://iris.usc.edu/Vision-Notes/bibliography/contents.html\nhttp://iris.usc.edu/Vision-Notes/rosenfeld/contents.html\nLawrence Berkeley National Lab Computer Vision and Robotics Applications\nhttp://www-itg.lbl.gov/ITG.hm.pg.docs/VISIon/vision.html\nCVonline by University of Edinburgh\nThe Evolving, Distributed, Non-Proprietary, On-Line Compendium of Computer Vision, www.dai.ed.ac.uk/CVonline\nComputer Vision Handbook, www.cs.hmc.edu/~fleck/computer-vision-handbook\nVision Systems Courseware\nwww.cs.cf.ac.uk/Dave/Vision_lecture/Vision_lecture_caller.html\nResearch Activities in Computer Vision\nhttp://www-syntim.inria.fr/syntim/analyse/index-eng.html\nVision Systems Acronyms\nwww.vision-systems-design.com/vsd/archive/acronyms.html\nDictionary of Terms in Human and Animal Vision\nhttp://cns-web.bu.edu/pub/laliden/WWW/Visionary/Visionary.html\nMetrology based on Computer Vision\nwww.cranfield.ac.uk/sme/amac/research/metrology/metrology.html\nDigital Photography\nDigital Photography, Scanning, and Image Processing\nwww.dbusch.com/scanners/scanners.html\nEducational Resources, Universities\nCenter for Image Processing in Education\nwww.cipe.com\nLibrary of Congress Call Numbers Related to Imaging Science by Rochester Institute of Technology\nhttp://wally2.rit.edu/pubs/guides/imagingcall.html\nMathematical Experiences through Image Processing, University of Washington\nwww.cs.washington.edu/research/metip/metip.html\nVismod Tech Reports and Publications, MIT\nhttp://vismod.www.media.mit.edu/cgi-bin/tr_pagemaker\nVision Lab PhD dissertation list, University of Antwerp\nhttp://wcc.ruca.ua.ac.be/~visielab/theses.html\nINRIA (France) Research Projects: Human-Computer Interaction, Image Processing, Data Management, Knowledge Systems\nwww.inria.fr/Themes/Theme3-eng.html\nImage Processing Resources\nhttp://eleceng.ukc.ac.uk/~rls3/Contents.htm\nPublications of Carsten Steger\nhttp://www9.informatik.tu-muenchen.de/people/steger/publications.html\nFAQs\ncomp.dsp FAQ\nwww.bdti.com/faq/dsp_faq.htm\nRobotics FAQ\nwww.frc.ri.cmu.edu/robotics-faq\nWhere's the sci.image.processing FAQ?\nwww.cc.iastate.edu/olc_answers/packages/graphics/sci.image.processing.faq.html\ncomp.graphics.algorithms FAQ, Section 3, 2D Image/Pixel Computations\nwww.exaflop.org/docs/cgafaq\nAstronomical Image Processing System FAQ\nwww.cv.nrao.edu/aips/aips_faq.html\n来自: http://hi.baidu.com/jiamn/blog/item/aaa063f9ae34141d6c22ebce.html\nposted @ 2012-04-18 15:48 Hanson-jun 阅读(45) 评论(0) 编辑\n计算机视觉文献与代码资源及资料\n下面是前端时间搜集整理的一些和计算机视觉、模式识别的资源，拿出来与大家分享下。以后，我将把图像处理真正的作为我的兴趣来玩玩了，也许不把研究作为谋生的手段，会更好些。\n标题\n作者\n主题\n关键字\n类别\n来源\n备注\nnipsfast.ppt\nNando de Freitas\nN-Body problems in learning\nFast N-Body Learning\nPpt\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nnipsfgtf.ppt\nRamani Duraiswami\nFast Multipole Methods Fast Gaussian Transform\nFM and FGT\nppt\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nGray.pdf/ppt\nAlex Gray\nStatistical N-Body/Proximity Data Structures\nN-Body and Data Structures\nPpt/pdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\ndt-nips04.pdf/ppt\nDan Huttenlocher\nFast Distance Transforms\nFDT\nPpt/pdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nHigh.pdf/ppt\nAlexander Gray\nFast high-dimensional function integration\nFast integration\nPpt/pdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nFast04.pdf/ppt\nDavid Lowe\nFast high-dimensional feature indexing for object recognition\nFeature indexing\nPpt/pdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nihler-fast.pdf/ppt\nAlexander lhler\nFast methods and non-parametric BP\nNon-parametric BP\nPpt/pdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nfastview.pdf\nDustin Lang\nComparing fast methods\nOverview fast methods\npdf\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nnbody_methods.tar.gz\ncode\nhttp://www.cs.ubc.ca/~awll/nbody_methods.html\ndemo_rbpf_gauss.tar\nRao Blackwellised particle filtering for conditionally Gaussian Models\nparticle filtering for conditionally\ncode\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\ndemorbpfdbn.tar.gz\nRao Blackwellised Particle Filtering\ncode\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nhttp://www.cs.ubc.ca/~nando/software.html\nupf_demos.tar.gz\nUnscented Particle Filter\nParticle Filter\ncode\nhttp://www.cs.ubc.ca/~nando/nipsfast/schedule.html\nBPF_1_3.zip\nBoosted Particle Filter\nTracking\ncode\nhttp://www.cs.ubc.ca/~okumak/research.html\n1\nflyer_14_800.mpg\nSource image\nDatabase\nImage\nhttp://www.cs.ubc.ca/~okumak/research.html\n1\ntrans_flyer_14_800.mpg\nimage transformed\nDatabase\nImage\nhttp://www.cs.ubc.ca/~okumak/research.html\n1\nLBP.c/h\nTopi Mäenpää\nLBP operator\nTexture\ncode\nhttp://www.ee.oulu.fi/~topiolli/cpplibs/files/\ncalibr_v30.zip\nCamera Calibration\nComputer vision\ncode\nhttp://www.ee.oulu.fi/mvg/page/camera_calibration\n_toolbox_for_matlab\n2\nLEAR(Learning and Recognition in Vision\nCommon dataset\nHuman/car horse soccer human actions\ndataset\nhttp://lear.inrialpes.fr/data\n3\nLic.zip/highlight.zip\nRobby T. Tan\nColor Constancy Through Inverse Intensity Chromaticity Space\nHighlight Removal from single image\ncode\nhttp://www.commsp.ee.ic.ac.uk/~rtan/\n2008_oxford_fog.pdf\nRobby T. Tan\nDefog\nDefog from single\npdf\nhttp://www.commsp.ee.ic.ac.uk/~rtan/\n08_cvpr.pdf\nRobby T. Tan\nDefog\nDefog from single\npdf\nhttp://www.commsp.ee.ic.ac.uk/~rtan/\nRetinex_frankle_mccann\nRetinex\nCode\nhttp://www.cs.sfu.ca/~colour/publications/IST-2000/\nSome\nRetinex_maccann99\nRetinex\ncode\nhttp://www.cs.sfu.ca/~colour/publications/IST-2000/\npictures\nGamut.tar.bz2\nRetinex\ncode\nhttp://kobus.ca/research/programs/colour_constancy/index.html\nVideo.avi/dehaze.m\ndehazing\nRaanan Fattal\ncode\nhttp://www.cs.huji.ac.il/~raananf/projects/defog/index.html\nMPTK-Windows-bin-0-5-6-beta.zip\nMatching pursuit(MP)\nAlogrithm\nCNRS\nCode\nhttp://mptk.irisa.fr/downloads\ngenerateDictionaries.txt\nGenerateGabor\nAlogrithm\ncode\nhttp://www.scholarpedia.org/article/Matching_pursuit\nNotes:\n1.      视频和源码都是对应的文章的：\nKenji Okuma, Ali Taleghani, Nando De Freitas, Jim Little, David G. Lowe. Boosted Particle Filter: Multitarget Detection and Tracking. the European Conference on Computer Vision(ECCV), May 2004.\n2.      该网站下面还有其他一些资源可以下载：\nhttp://www.ee.oulu.fi/mvg/page/downloads\n是个研究组织：http://lear.inrialpes.fr/ ， 除此之外，还有一些源码。\n计算机视觉文献与代码资源\nCVonline\nhttp://homepages.inf.ed.ac.uk/rbf/CVonline\nhttp://homepages.inf.ed.ac.uk/rbf/CVonline/unfolded.htm\nhttp://homepages.inf.ed.ac.uk/rbf/CVonline/CVentry.htm\n李子青的大作：\nMarkov Random Field Modeling in Computer Vision\nhttp://www.cbsr.ia.ac.cn/users/szli/mrf_book/book.html\nHandbook of Face Recognition (PDF)\nhttp://www.umiacs.umd.edu/~shaohua/papers/zhou04hfr.pdf\n张正友的有关参数鲁棒估计著作：\nParameter Estimation Techniques:A Tutorial with Application to Conic Fitting\nhttp://research.microsoft.com/~zhang/INRIA/Publis/Tutorial-Estim/Main.html\nAndrea Fusiello“计算机视觉中的几何”教程：Elements of Geometric Computer Vision\nhttp://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/FUSIELLO4/tutorial.html#x1-520007\n有关马尔可夫蒙特卡罗方法的资料：\nAn introduction to Markov chain Monte Carlo\nhttp://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/SENEGAS/mcmc.html\nMarkov Chain Monte Carlo for Computer Vision--- A tutorial at ICCV05\nhttp://civs.stat.ucla.edu/MCMC/MCMC_tutorial.htm\n有关独立成分分析（Independent Component Analysis , ICA）的资料：\nAn ICA-Page\nhttp://www.cnl.salk.edu/~tony/ica.html\nFast ICA\nhttp://www.cis.hut.fi/projects/ica/fastica/\nThe Kalman Filter (介绍卡尔曼滤波器的终极网页)\nhttp://www.cs.unc.edu/~welch/kalman/index.html\nCached k-d tree search for ICP algorithms\nhttp://kos.informatik.uni-osnabrueck.de/download/3dim2007/paper.html\n几个计算机视觉研究工具\nMachine Vision Toolbox for Matlab\nhttp://www.petercorke.com/Machine%20Vision%20Toolbox.html\nMatlab and Octave Function for Computer Vision and Image Processing\nhttp://www.csse.uwa.edu.au/~pk/research/matlabfns/\nBayes Net Toolbox for Matlab\nhttp://www.cs.ubc.ca/~murphyk/Software/BNT/bnt.html\nOpenCV (Chinese)\nhttp://www.opencv.org.cn/index.php/%E9%A6%96%E9%A1%B5\nGandalf (A Computer Vision and Numerical Algorithm Labrary)\nhttp://gandalf-library.sourceforge.net/\nCMU Computer Vision Home Page\nhttp://www.cs.cmu.edu/afs/cs/project/cil/ftp/html/vision.html\nMachine Learning Resource Links\nhttp://www.cse.ust.hk/~ivor/resource.htm\nThe Bayesian Filtering Library\nhttp://www.orocos.org/bfl\nOptical Flow Algorithm Evaluation (提供了一个动态贝叶斯网络框架，例如递归信息处理与分析、卡尔曼滤波、粒子滤波、序列蒙特卡罗方法等，C++写的)\nhttp://of-eval.sourceforge.net/\nMATLAB code for ICP algorithm\nhttp://www.usenet.com/newsgroups/comp.graphics.visualization/msg00102.html\n牛人主页：\n朱松纯（Song-Chun Zhu）\nhttp://www.stat.ucla.edu/~sczhu/\nDavid Lowe (SIFT) (很帅的一个老头哦 ^ ^)\nhttp://www.cs.ubc.ca/~lowe/\nAndrea Vedaldi (SIFT)\nhttp://vision.ucla.edu/~vedaldi/index.html\nPedro F. Felzenszwalb\nhttp://people.cs.uchicago.edu/~pff/\nDougla Dlanman (Brown的一个研究生，在其主页上搜集了大量算法教程和源码)\nhttp://mesh.brown.edu/dlanman/courses.html\nJianbo Shi (Ncuts 的始作俑者)\nhttp://www.cis.upenn.edu/~jshi/\nActive Vision Group (Oxford的一个机器视觉研究团队，特色是SLAM，监视，导航)\nhttp://www.robots.ox.ac.uk/ActiveVision/index.html\nJuyang Weng（机器学习的专家，Autonomous Mental Development 是其特色）\nhttp://www.cse.msu.edu/~weng/\n测试图片或视频：\nMiddlebury College‘s Stereo Vision Data Set\nhttp://cat.middlebury.edu/stereo/data.html\nIntelligent Vehicle:\nIVSource\nwww.ivsoruce.net\nRobot Car\nhttp://www.plyojump.com/robot_cars.html\nHow to Build a Robot: The Computer Vision Part\nhttp://www.societyofrobots.com/programming_computer_vision_tutorial.shtml\n计算机视觉应关注的资源\n来自美国帝腾大学的链接。\nCamera Calibration Links to toolboxes (mostly MATLAB) for camera calibration.\nPaul Debevec. Modeling and Rendering Architecture from Photographs.\nMarc Pollefeys, Tutorial on 3D Modeling from Images,, ECCV 2000,\nAvailable here: notes (12.1MB pdf)\nRichard Szeliski NIPS 2004 Tutorial on Acquiring Detailed 3D Models From Images and Video,\nAvailable here: slides (37.6 MB, ppt)\nPeter Corke did his thesis work on visual servoing for robot applications and has authored a robotics toolkit and vision toolkit for MATLAB.\nlocal copy of thesis: Corke thesis (4.36 MB, pdf)\nrobot toolkit: robot.zip (568 KB, zip)\nvision toolkit: mv.zip (1.08 MB, zip)\nP. D. Kovesi., MATLAB Functions for Computer Vision and Image Analysis.\nSchool of Computer Science & Software Engineering, The University of Western Australia.\nAvailable locally as a zip archive MatlabFns.zip (4.8 MB, updated 21 May 2005)\nPhilip Torr, among many other contributions, submitted a Structure and motion toolkit in Matlab to the MathSoft File Exhange.\nLocal copy here: torrsam.zip (2.4 MB, zip).\n本文引用地址：http://blog.sciencenet.cn/home.php?mod=space&uid=454498&do=blog&id=456240\nposted @ 2012-04-18 15:45 Hanson-jun 阅读(54) 评论(0) 编辑\n描述子距离种类\n1.hausdorff距离\n微分动力系统原理 这本书里有介绍\nHausdorff距离是描述两组点集之间相似程度的一种量度，它是两个点集之间距离的一种定义形式：假设有两组集合A={a1,…,ap},B={b1,…,bq},则这两个点集合之间的Hausdorff距离定义为H(A,B)=max(h(A,B),h(B,A)) (1)\n其中,\nh(A,B)=max（a∈A）min（b∈B）‖a-b‖ (2)\nh(B,A)=max（b∈B）min（a∈A）‖b-a‖ (3)\n‖·‖是点集A和B点集间的距离范式(如:L2或Euclidean距离).\n这里,式(1)称为双向Hausdorff距离,是Hausdorff距离的最基本形式;式(2)中的h(A,B)和h(B,A)分别称为从A集合到B集合和从B集合到A集合的单向Hausdorff距离.即h(A,B)实际上首先对点集A中的每个点ai到距离此点ai最近的B集合中点bj之间的距离‖ai-bj‖进行排序,然后取该距离中的最大值作为h(A,B)的值.h(B,A)同理可得.\n由式(1)知,双向Hausdorff距离H(A,B)是单向距离h(A,B)和h(B,A)两者中的较大者,它度量了两个点集间的最大不匹配程度\n2.欧式距离\n欧几里得距离定义： 欧几里得距离（ Euclidean distance）也称欧式距离，它是一个通常采用的距离定义，它是在m维空间中两个点之间的真实距离。\n在二维和三维空间中的欧式距离的就是两点之间的距离，二维的公式是\nd = sqrt((x1-x2)^+(y1-y2)^)\n三维的公式是\nd=sqrt((x1-x2)^+(y1-y2)^+(z1-z2)^)\n推广到n维空间，欧式距离的公式是\nd=sqrt( ∑(xi1-xi2)^ ) 这里i=1,2..n\nxi1表示第一个点的第i维坐标,xi2表示第二个点的第i维坐标\nn维欧氏空间是一个点集,它的每个点可以表示为(x(1),x(2),...x(n)),其中x(i)(i=1,2...n)是实数,称为x的第i个坐标,两个点x和y=(y(1),y(2)...y(n))之间的距离d(x,y)定义为上面的公式.\n欧氏距离看作信号的相似程度。 距离越近就越相似，就越容易相互干扰，误码率就越高。\n所谓欧氏距离变换，是指对于一张二值图像（再次我们假定白色为前景色，黑色为背景色），将前景中的像素的值转化为该点到达最近的背景点的距离。\n欧氏距离变换在数字图像处理中的应用范围很广泛，尤其对于图像的骨架提取，是一个很好的参照。\n所谓欧氏距离变换，是指对于一张二值图像（再次我们假定白色为前景色，黑色为背景色），将前景中的像素的值转化为该点到达最近的背景点的距离。\n欧氏距离变换在数字图像处理中的应用范围很广泛，尤其对于图像的骨架提取，是一个很好的参照。\n========\n欧氏距离：（∑（Xi-Yi）2）1/2，即两项间的差是每个变量值差的平方和再平方根，目的是计算其间的整体距离即不相似性。\n我们熟悉的 欧氏距离虽然很有用，但也有明显的缺点。它将样品的不同属性（即各指标或各变量）之间的差别等同看待，这一点有时不能满足实际要求。例如，在教育研究中， 经常遇到对人的分析和判别，个体的不同属性对于区分个体有着不同的重要性。因此，有时需要采用不同的距离函数。\n3.马氏距离：\n马氏距离是由印度统计学家马哈拉诺比斯(P. C. Mahalanobis)提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧式距离不同的是它考虑到各种特性之间的联系（例如：一条关于身高的信息会带来一条关于体重的信息，因为两者是有关联的）并且是尺度无关的(scale-invariant)，即独立于测量尺度。对于一个均值μ，为协方差矩阵为Σ的多变量向量,其马氏距离为((x-μ)'Σ^(-1)(x-μ))^(1/2)。\n马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为Σ的随机变量与的差异程度:\n如果协方差矩阵为单位矩阵,那么马氏距离就简化为欧式距离,如果协方差矩阵为对角阵,则其也可称为正规化的欧氏距离'.\n其中σi 是 xi 的标准差.\n马氏优缺点：\n1）马氏距离的计算是建立在总体样本的基础上的，这一点可以从上述协方差矩阵的解释中可以得出，也就是说，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；\n2）在计算马氏距离过程中，要求总体样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。\n3）还有一种情况，满足了条件总体样本数大于样本的维数，但是协方差矩阵的逆矩阵仍然不存在，比如三个样本点（3，4），（5，6）和（7，8），这种情况是因为这三个样本在其所处的二维空间平面内共线。这种情况下，也采用欧式距离计算。\n4）在实际应用中“总体样本数大于样本的维数”这个条件是很容易满足的，而所有样本点出现3）中所描述的情况是很少出现的，所以在绝大多数情况下，马氏距离是可以顺利计算的，但是马氏距离的计算是不稳定的，不稳定的来源是协方差矩阵，这也是马氏距离与欧式距离的最大差异之处。\n优点：它不受量纲的影响，两点之间的马氏距离与原始数据的测量单位无关；由标准化数据和中心化数据(即原始数据与均值之差）计算出的二点之间的马氏距离相同。马氏距离还可以排除变量之间的相关性的干扰。缺点：它的缺点是夸大了变化微小的变量的作用。\n如果用dij表示第i个样品和第j个样品之间的距离，那么对一切i，j和k，dij应该满足如下四个条件：\n①当且仅当i=j时，dij=0\n②dij>0\n③dij=dji（对称性）\n④dij≤dik+dkj（三角不等式）\n显然，欧氏距离满足以上四个条件。满足以上条件的函数有多种，本节将要用到的马氏距离也是其中的一种。\n第i个样品与第j个样品的马氏距离dij用下式计算：\ndij =((x i 一x j)TS-1(x i一xj) )1/2(T、-1、1/2都是上标)\n其中，T表示转置，x i 和x j分别为第i个和第j个样品的m个指标所组成的向量，S为样本协方差矩阵。\n\n本文引用地址：http://blog.sciencenet.cn/home.php?mod=space&uid=261330&do=blog&id=526762\nposted @ 2012-04-18 15:44 Hanson-jun 阅读(40) 评论(0) 编辑\n涉足计算机视觉领域要知道的\n做机器视觉和图像处理方面的研究工作，最重要的两个问题：其一是要把握住国际上最前沿的内容；其二是所作工作要具备很高的实用背景。解决第一个问题的办法就是找出这个方向公认最高成就的几个超级专家(看看他们都在作什么)和最权威的出版物(阅读上面最新的文献)，解决第二个问题的办法是你最好能够找到一个实际应用的项目，边做边写文章。 做好这几点的途径之一就是利用网络资源，利用权威网站和专家们的个人主页。\n依照下面目录整理：\n[1]研究群体(国际国内)[2]专家主页[3]前沿国际国内期刊与会议[4]搜索资源[5]GPL软件资源\n一、研究群体\n用来搜索国际知名计算机视觉研究组(CV Groups)：\n国际计算机视觉研究组清单http://peipa.essex.ac.uk/info/groups.html\n美国计算机视觉研究组清单 http://peipa.essex.ac.uk/info/groups.html#USA\nhttp://www-2.cs.cmu.edu/~cil/vision.html或 http://www.cs.cmu.edu/~cil/vision.html\n这是卡奈基梅隆大学的计算机视觉研究组的主页，上面提供很全的资料，从发表文章的下载到演示程序、测试图像、常用链接、相关软硬件，甚至还有一个搜索引擎。著名的有人物Tomasi， Kanade等。\n卡内基梅隆大学双目实验室http://vision.middlebury.edu/stereo/\n卡内基梅隆研究组http://www.cs.cmu.edu/~cil/v-groups.html\n还有几个实验室：\nCalibrated Imaging Laboratory 图像\nDigital Mapping Laboratory 映射\nInteractive Systems Laboratory 互动\nVision and Autonomous Systems Center视觉自适应\nhttp://www.via.cornell.edu/\n康奈尔大学的计算机视觉和图像分析研究组，好像是电子和计算机工程系的。侧重医学方面的研究，但是在上面有相当不错资源，关键是它正在建设中，能够跟踪一些信息。\nCornell University——Robotics and Vision group\nhttp://www-cs-students.stanford.edu/ 斯坦福大学计算机系主页\n1. http://white.stanford.edu/\n2. http://vision.stanford.edu/\n3. http://ai.stanford.edu/美国斯坦福大学人工智能机器人实验室\nThe Stanford AI Lab (SAIL) is the intellectual home for researchers in the Stanford Computer Science Department whose primary research focus is Artificial Intelligence. The lab is located in the Gates...\nVision and Imaging Science and Technology\nhttp://www.fmrib.ox.ac.uk/analysis/\n主要研究：Brain Extraction Tool， Nonlinear noise reduction， Linear Image Registration， Automated Segmentation， Structural brain change analysis， motion correction， etc.\nhttp://www.cse.msu.edu/prip/—密歇根州立大学计算机和电子工程系的模式识别--图像处理研究组，它的FTP上有许多的文章(NEW)。\n美国密歇根州大学认知模型和图像处理实验室\nThe Pattern Recognition and Image Processing (PRIP) Lab faculty and students investigate the use of machines to recognize patterns or objects. Methods are developed to sense objects， to discover which...http://www.cse.msu.edu/rgroups/prip/\nhttp://pandora.inf.uni-jena.de/p/e/index.html\n德国的一个数字图像处理研究小组，在其上面能找到一些不错的链接资源。\n柏林大学 http://www.cv.tu-berlin.de/\n德国波恩大学视觉和认识模型小组\nComputer Vision Group located within the Division III of the Computer Science Department in the University of Bonn in Germany. This server offers information on topics concerning our computer vision http://www-dbv.informatik.uni-bonn.de/\nhttp://www-staff.it.uts.edu.au/~sean/CVCC.dir/home.html\nCVIP(used to be CVCC for Computer Vision and Cluster Computing) is a research group focusing on cluster-based computer vision within the Spiral Architecture.\nhttp://cfia.gmu.edu/\nThe mission of the Center for Image Analysis is to foster multi-disciplinary research in image， multimedia and related technologies by establishing links between academic institutes， industry and government agencies， and to transfer key technologies to help industry build next generation commercial and military imaging and multimedia systems.\n英国的Bristol大学的Digital Media Group在高级图形图像方面不错。主要就是涉及到场景中光线计算的问题，比如用全局光照或是各种局部光照对高动态图的处理，还有近似真实的模拟现实环境 (照片级别的)，还有用几张照片来建立3D模型(人头之类的)。另外也有对古代建筑模型复原。http://www.cs.bristol.ac.uk/Research/Digitalmedia/\n而且根据Times全英计算机排名在第3， 也算比较顶尖的研究了\nhttp://www.cmis.csiro.au/IAP/zimage.htm\n这是一个侧重图像分析的站点，一般。但是提供一个Image Analysis环境---ZIMAGE and SZIMAGE。\n麻省理工视觉实验室MIT http://groups.csail.mit.edu/vision/welcome/\nAI Laboratory Computer Vision group\nCenter for Biological and Computational Learning\nMedia Laboratory， Vision and Modeling Group\nPerceptual Science group\nUC Berkeley http://0-vision.berkeley.edu.ilstest.lib.neu.edu/vsp/index.html\nhttp://www.cs.berkeley.edu.ilste ... n/vision_group.html\n加州大学伯克利分校视觉实验室David A. Forsyth：http://www.cs.berkeley.edu/~daf/\nUCLA(加州大学洛杉矶分校) http://vision.ucla.edu/视觉实验室\n英国牛津的A.Zisserman：http://www.robots.ox.ac.uk/~az/ 机器人实验室\n美国南加州大学智能机器人和智能系统研究所University of Southern California， Los Angeles\nIRIS is an interdepartmental unit of USC's School of Engineering with ties to USC's Information Sciences Institute (ISI). Members include faculty， graduate students， and research staff associated with... http://iris.usc.edu/ Computer Vision 实验室\n美国南加州大学计算机视觉实验室介绍：\nComputer Vision Laboratory at the University of Southern California is one of the major centers of computer vision research for thirty years. they conduct research in a number of basic and applied are...http://iris.usc.edu/USC-Computer-Vision.html\n英国约克大学高级计算机结构神经网络小组\nThe Advanced Computer Architecture Group has had a thriving research programme in neural networks for over 10 years. The 15 researchers， led by Jim Austin， focus their work in the theory and applicati...http://www.cs.york.ac.uk/arch/neural/\n瑞士戴尔莫尔感知人工智能研究所\nIDIAP is a research institute established in Martigny in the Swiss Alps since 1991. Active in the areas of multimodal interaction and multimedia information management， the institute is also the leade...http://www.idiap.ch/\n英国萨里大学视觉，语言和信号处理中心\nThe Centre for Vision， Speech and Signal Processing (CVSSP) is more than 60 members strong， comprising 12 academic staff， 18 research fellows and more than 44 research students. The activities of the ...http://www.ee.surrey.ac.uk/Research/VSSP/\n美国阿默斯特马萨诸塞州立大学计算机视觉实验室\nThe Computer Vision Laboratory was established in the Computer Science Department at the University of Massachusetts in 1974 with the goal of investigating the scientific principles underlying the con...http://vis-www.cs.umass.edu\nUniversity of Massachusetts——Computer Vision Laboratory for Perceptual Robotics\n美国芝加哥伊利诺伊斯大学贝克曼研究中心智能机器人和计算机视觉实验室\nIncludes the following groups: Professor Seth Hutchinson's Research Group Professor David Kriegman's Research Group Professor Jean Ponce's Research Group Professor Narendra Ahuja's Research Gro...http://www-cvr.ai.uiuc.edu/\nComputer Vision and Robotics Laboratory\nVision Interfaces and Systems Laboratory (VISLab)\n英国伯明翰大学计算机科学学校视觉研究小组\nThe vision group at the School of Computer Science (a RAE 5 rated department) performs research into a wide variety of computer vision and image understanding areas. Much of this work is performed in ...http://www.cs.bham.ac.uk/research/vision/\n微软研究院机器学习与理解研究小组 / 计算机视觉小组\nThe research group focuses on the development of more advanced and intelligent computer systems through the exploitation of statistical methods in machine learning and computer vision. The site lists ...http://research.microsoft.com/mlp/\nhttp://research.microsoft.com/en-us/groups/vision/\n微软公司的文献：http://research.microsoft.com/research/pubs\n微软亚洲研究院：http://research.microsoft.com/asia/，值得关注Harry Shum， Jian Sun， Steven Lin， Long Quan(兼职HKUST)etc.\n瑞典隆德大学数学系视觉组：http://www.maths.lth.se/matematiklth/personal/andersp/\n感觉国外搞视觉的好多是数学系出身，大约做计算机视觉对数学要求很高吧。\n澳大利亚国立大学：http://users.rsise.anu.edu.au/~hartley/\n美国北卡大学：http://www.cs.unc.edu/~marc/\n法国INRIA：http://www-sop.inria.fr/odyssee/team/ 由Olivier.Faugeras领衔的牛人众多。\n比利时鲁汶大学的L.Van Gool： www.esat.kuleuven.ac.be/psi/visics/\n据说在这个只有中国一个小镇大小的地方的鲁汶大学在欧洲排行top10，名列世界top100，还出了几个诺贝尔奖，视觉研究也很强.\n美国明德http://vision.middlebury.edu/stereo/\n以下含有非顶尖美国学校研究组，没有链接(个别的上面已经提到)，供参考。\nAmerinex Applied Imaging， Inc.\nBoston University\nImage and Video Computing Research group\nUniversity of California at Santa Barbara加州大学芭芭拉分校\nVision Research Lab\nUniversity of California at San Diego加州大学圣迭戈分校\nComputer Vision & Robotics Research Laboratory\nVisual Computing laboratory\nUniversity of California at Irvine加州大学欧文分校，加州南部一城，在圣安娜东南，\nComputer Vision laboratory\nUniversity of California， Riverside加州大学河滨分校\nVisualization and Intelligent Systems Laboratory (VISLab)\nUniversity of California at Santa Cruz\nPerceptual Science Laboratory\nCaltech (加州理工)\nVision group\nUniversity of Central Florida\nComputer Vision laboratory\nUniversity of Florida\nCenter for Computer Vision and Visualization\nColorado State University\nComputer Vision group\nColumbia University\nAutomated Vision Environment (CAVE)\nRobotics group\nUniversity of Georgia， Athens\nVisual and Parallel Computing Laboratory\nHarvard University（哈佛）\nRobotics Laboratory\nUniversity of Illinois at Urbana-Champaign\nRobotics and Computer Vision\nUniversity of Iowa\nDivision of Physiologic Imaging\nJet Propulsion Laboratory\nMachine Vision and Tracking Sensors group\nKhoral Research， Inc\nLawrence Berkeley Laboratories\nImaging and Collaborative Computing Group\nImaging and Distributed Computing\nLehigh University\nImage Processing and Pattern Analysis Lab\nVision And Software Technology Laboratory\nUniversity of Louisville\nComputer Vision and Image Processing Lab\nUniversity of Maryland\nComputer Vision Laboratory\nUniversity of Miami\nUnderwater Vision and Imaging Laboratory\nUniversity of Michigan密歇根\nAI Laboratory\nMichigan State University 密歇根州立\nPattern Recognition and Image Processing laboratory\nEnvironmental Research Institute of Michigan (ERIM) 密歇根大学有汽车车身检测研究\nUniversity of Missouri-Columbia\nComputational Intelligence Research Laboratory\nNEC\nComputer Vision and Image Processing\nUniversity of Nevada\nComputer Vision Laboratory\nNotre-Dame University\nVision-Based Robotics using Estimation\nOhio State University\nSignal Analysis and Machine Perception Laboratory\nUniversity of Pennsylvania\nGRASP laboratory\nMedical Image Processing group\nVision Analysis and Simulation Technologies (VAST) Laboratory\nPenn State University 宾夕法尼亚大学\nComputer Vision\nPrecision Digital Images\nPurdue University普渡大学\nRobot Vision laboratory\nVideo and Image Processing Laboratory (VIPER)\nRensselaer Polytechnic Institute (RPI)\nComputer Science Vision\nUniversity of Rochester\nCenter for Electronic Imaging Systems\nVision and Robotics laboratory\nRutgers University (The State University of New Jersey)\nImage Understanding Lab\nUniversity of Southern California\nComputer Vision\nUniversity of South Florida\nImage Analysis Research group\nStanford Research Institute International (SRI)\nRADIUS -- Research and Development for Image Understanding Systems\nThe Perception program at SRI's AI Center\nSUNY at Stony Brook\nComputer Vision Lab\nUniversity of Tennessee\nImaging， Robotics and Intelligent Systems laboratory\nUniversity of Texas， Austin\nLaboratory for Vision Systems\nUniversity of Utah\nCenter for Scientific Computing and Imaging\nRobotics and Computer Vision\nUniversity of Virginia\nComputer Vision Research (CS)\nUniversity of Washington\nImage Computing Systems Laboratory\nInformation Processing Laboratory\nCVIA Laboratory\nUniversity of West Florida\nImage Analysis/Robotics Research Laboratory\nUniversity of Wisconsin\nComputer Vision group\nVanderbilt University\nCenter for Intelligent Systems\nWashington State University\nImaging Research laboratory\nWright-Patterson\nModel-Based Vision laboratory\nWright State University\nIntelligent Systems Laboratory\nUniversity of Wyoming\nWyoming Image and Signal Processing Research (WISPR)\nYale University\nComputational Vision Group http://www.cs.yale.edu/\nSchool of Medicine， Image Processing and Analysis group\n国内：\n中科院模式识别国家重点实验室 http://www.nlpr.ia.ac.cn/English/rv/mainpage.html\n虹膜识别、掌纹识别、人脸识别、\n莲花山http://www.stat.ucla.edu/~sczhu/Lotus/\n天津大学精密测试技术及仪器国家重点实验室\n研究方向包括：激光及光电测试技术、传感及测量信息技术、微纳测试与制造技术、制造质量控制技术。该实验室是国内精密测试领域惟一的国家重点实验室。\n“智能微系统及其集成应用技术”、“微结构光学测试技术”、“油气储运安全检测技术”、“先进制造中的视觉测量及其关键技术”、“正交偏振激光器原理、特性及其在精密计量中的应用研究”等5项代表性成果（07.3）。\n中科院长春光机所 http://www.ciomp.ac.cn/ny/keyan.asp\n中科院沈阳自动化所http://www.sia.ac.cn/index.php\n中科院西安光机所http://www.opt.ac.cn/yanjiushi/gpcxjs1.htm\n北京大学智能科学系http://www.cis.pku.edu.cn/vision/vision.htm\n三维视觉计算与机器人，生物特征识别与图像识别\n二、专家网页\nhttp://www.ai.mit.edu/people/wtf/\n这位可是MIT人工智能实验室的BILL FREEMAN。专长是：理解--贝叶斯模型。\nhttp://www.merl.com/people/brand/\nMERL(Mitsubishi Electric Research Laboratory)中的擅长“Style Machine”。\nhttp://research.microsoft.com/~ablake/\nCV界极有声望的A.Blake 1977年毕业于剑桥大学三一学院并或数学与电子科学学士学位。之后在MIT，Edinburgh，Oxford先后组建过研究小组并成为Oxford的教授，直到1999年进入微软剑桥研究中心。主要工作领域是计算机视觉。\nhttp://www-2.cs.cmu.edu/afs/cs.cmu.edu/user/har/Web/home.html\n这位专家好像正在学习汉语，主页并且搜集了诸如“两只老虎(Two Tigers)”的歌曲。\n他的主页上面还有几个专家：Shumeet Baluja， Takeo Kanade。他们的Face Detection作的绝对是世界一流。毕业于卡奈基梅隆大学的计算机科学系，兴趣是计算机视觉。\n三、前沿国际国内期刊与会议\n这里的期刊大部分都可以通过上面的专家们的主页间接找到\n1.国际会议 2.国际期刊 3.国内期刊 4.神经网络 5.CV 6.数字图象 7.教育资源，大学 8.常见问题\n1. 国际会议\n现在，国际上计算机视觉方面的三大国际会议是ICCV， CVPR和ECCV，统称之为ICE。\nICCV的全称是International Comference on Computer Vision。ICCV两年一次，与ECCV正好错开，是公认的三个会议中级别最高的。\nECCV的全称是Europeon Conference on Computer Vision，是一个欧洲的会议。\nCVPR的全称是Internaltional Conference on Computer Vision and Pattern Recogintion国际计算机视觉与模式识别会议。这是一个一年一次的会议，举办地在美国。\nICIP—\nBMVC—\nMVA—\n国际模式识别会议(ICPR )：\n亚洲计算机视觉会议(ACCV)：\n2.国际期刊\n以计算机视觉为主要内容之一的国际刊物也有很多，如:\nInternational Journal of Computer Vision\nIEEE Trans. On PAMI http://www.computer.org/tpami/index.htm\nIEEE Transactionson Image Processing http://www.ieee.org/organizations/pubs/transactions/tip.htm\nPattern Recognition http://www.elsevier.com/locate/issn/00313203\nPattern Recognition Letters http://www.elsevier.com/locate/issn/01678655\nIEEE Trans. on Robotics and Automation，\nIEEE TPAMI\nIEEE TIP\nCVGIP Computer Vision. Graphics and Image Processing，\nVisual Image Computing，\nIJPRAI(Internatiorial Journat of Pattern Recognition and Artificial Intelligence)\n众所周知， computer vision(cv) 存在ICCV/CVPR/ECCV三个顶级会议，它们档次差不多，都应该在一流会议行列， 没有必要给个高下。有些us的人认为ICCV/CVPR略好于ECCV，而欧洲人大都认为ICCV/ECCV略好于CVPR，某些英国的人甚至认为BMVC好于CVPR。简言之， 三个会议差不多， 各有侧重和偏好。\n笔者就个人经验浅谈三会异同， 以供大家参考和讨论。 三者乃cv领域的旗舰和风向标，其oral paper (包括best paper) 代表当年度cv的最高水准， 在此引用Harry Shum的一句话， 想知道某个领域在做些什么，找最近几年此领域的proceeding看看就知道了。 ICCV/CVPR由IEEE Computer Society牵头组织， ECCV好像没有专门负责的组织。 CVPR每年(除2002年)都在美国开， ECCV每两年开一次，仅限欧洲， ICCV也是每两年一次，各洲轮值。 基本可以保证每年有两个会议开， 这样研究者就有两次跻身牛会的机会。\n就录取率而言， 三会都有波动。 如ICCV2001录取率>30%，且出现两个人(华人)各有三篇第一作者的paper的情况， 这在顶级牛会是不常见的 (灌水嫌疑)。 但是， ICCV2003， 2005两次录取率都很低， 大约20%左右。 ECCV也是类似规律， 在2004年以前都是>30%， 2006年降低到20%左右。 CVPR的录取率近年来一直偏高，从2004年开始一直都在[25%，30%]。最近一次CVPR2006是28.1%， CVPR2007还不知道统计数据。笔者猜测为了维持录取paper的绝对数量， 当submission少的时候录取率偏高， 反之偏低，近几年三大会议的投稿数量全部超过1000， 相对2000年前， 三会录取率均大幅度降低，最大幅度50%->20%。 对录取率走势感兴趣的朋友， 可参考 http://vrlab.epfl.ch/~ulicny/statistics/(CVPR2004的数据是错的)，http://www.adaptivebox.net/research/bookmark/CICON_stat.html.\n显然， 投入cv的人越来越多，这个领域也是越来越大， 这点颇不似machine learning一直奉行愚蠢的小圈子主义。另外一点值得注意， ICCV/ECCV只收vision相关的topic，而cvpr会收少量的pattern recognition paper， 如finger print等，但是不收和image/video完全不占边的pr paper，如speech recognition等。我一个朋友曾经review过一篇投往CVPR的speech的paper， 三个reviewer一致拒绝，其中一个reviewer搞笑的指出， 你这篇paper应该是投ICASSP被据而转投CVPR的。 就topic而言， CVPR涵盖最广。 还有一个没有验证过的原因导致CVPR录取率高: 很多us的researcher不愿意或没有足够的经费到us以外的地方开会， 故CVPR会优先接收很多来自us的paper (让大家都happy)。\n以上对三会的分析对我们投paper是很有指导作用的。 目前的research我想绝大部分还是纸上谈兵， 必经 read paper -> write paper -> publish paper -> publish paper on top conferences and journals流程。故了解投paper的一些基本技巧， 掌握领域的走向和热点， 是非常必要的。 避免做无用功，选择切合的topic，改善presentation， 注意格式 (遵守规定的模板)， 我想这是很多新手需要注意的问题。如ICCV2007明文规定不写summary page直接reject， 但是仍然有人忽视， 这是相当不值得的。\n3.国内期刊\n自动化学报、计算机学报、软件学报、电子学报，中国图象图形学报，模式识别与人工智能，光电子激光，精密光学工程等。\n4.神经网络\n神经网络-Neural Networks Tutorial Review\nhttp://hem.hj.se/~de96klda/NeuralNetworks.htm\nftp://ftp.sas.com/pub/neural/FAQ.html\nImage Compression with Neural Networks\nhttp://www.comp.glam.ac.uk/digimaging/neural.htm\nBackpropagator's Review\nhttp://www.dontveter.com/bpr/bpr.html\nBibliographies on Neural Networks\nhttp://liinwww.ira.uka.de/bibliography/Neural/\nIntelligent Motion Control with an Artificial Cerebellum\nhttp://www.q12.org/phd.html\nKernel Machines\nhttp://www.kernel-machines.org/\nSome Neural Networks Research Organizations\nhttp://www.ieee.org/nnc/\nhttp://www.inns.org/\nNeural Network Modeling in Vision Research\nhttp://www.rybak-et-al.net/nisms.html\nNeural Networks and Machine Learning\nhttp://learning.cs.toronto.edu/\nNeural Application Software\nhttp://attrasoft.com\nNeural Network Toolbox for MATLAB\nhttp://www.mathworks.com/products/neuralnet/\nNetlab Software\nhttp://www.ncrg.aston.ac.uk/netlab/\nKunama Systems Limited http://www.kunama.co.uk/\n5.Computer Vision(计算机视觉)\nAnnotated Computer Vision Bibliography\nhttp://iris.usc.edu/Vision-Notes/bibliography/contents.html\nhttp://iris.usc.edu/Vision-Notes/rosenfeld/contents.html\nLawrence Berkeley National Lab Computer Vision and Robotics Applications\nhttp://www-itg.lbl.gov/ITG.hm.pg.docs/VISIon/vision.html\nCVonline by University of Edinburgh\nThe Evolving， Distributed， Non-Proprietary， On-Line Compendium of Computer Vision， www.dai.ed.ac.uk/CVonline\nComputer Vision Handbook，\nwww.cs.hmc.edu/~fleck/computer-vision-handbook\nVision Systems Courseware\nwww.cs.cf.ac.uk/Dave/Vision_lecture/Vision_lecture_caller.html\nResearch Activities in Computer Vision\nhttp://www-syntim.inria.fr/syntim/analyse/index-eng.html\nVision Systems Acronyms\nwww.vision-systems-design.com/vsd/archive/acronyms.html\nDictionary of Terms in Human and Animal Vision\nhttp://cns-web.bu.edu/pub/laliden/WWW/Visionary/Visionary.html\nMetrology based on Computer Vision\nwww.cranfield.ac.uk/sme/amac/research/metrology/metrology.html\n6.Digital Photography 数字图像\nDigital Photography， Scanning， and Image Processing\nwww.dbusch.com/scanners/scanners.htm l\n7.Educational Resources， Universities 教育资源，大学\nCenter for Image Processing in Education\nwww.cipe.com\nLibrary of Congress Call Numbers Related to Imaging Science by Rochester Institute of Technology\nhttp://wally2.rit.edu/pubs/guides/imagingcall.html\nMathematical Experiences through Image Processing， University of Washington\nwww.cs.washington.edu/research/metip/metip.html\nVismod Tech Reports and Publications， MIT\nhttp://vismod.www.media.mit.edu/cgi-bin/tr_pagemaker\nVision Lab PhD dissertation list， University of Antwerp\nhttp://wcc.ruca.ua.ac.be/~visielab/theses.html\nINRIA (France) Research Projects: Human-Computer Interaction， Image Processing， Data Management， Knowledge Systems\nwww.inria.fr/Themes/Theme3-eng.html\nImage Processing Resources\nhttp://eleceng.ukc.ac.uk/~rls3/Contents.htm\nPublications of Carsten Steger\nhttp://www9.informatik.tu-muench ... r/publications.html\n8.FAQs（常见问题）\ncomp.dsp FAQ\nwww.bdti.com/faq/dsp_faq.htm\nRobotics FAQ\nwww.frc.ri.cmu.edu/robotics-faq\nWhere's the sci.image.processing FAQ?\nwww.cc.iastate.edu/olc_answers/p ... processing.faq.html\ncomp.graphics.algorithms FAQ， Section 3， 2D Image/Pixel Computations\nwww.exaflop.org/docs/cgafaq\nAstronomical Image Processing System FAQ\nwww.cv.nrao.edu/aips/aips_faq.html\n四、搜索资源\nhttp://sal.kachinatech.com/\nhttp://cheminfo.pku.edu.cn/mirrors/SAL/index.shtml 北京大学\nGoogle输入：computer vision 或computer vision groups可以获得很多结果\n网络资源：\nCVonline http://homepages.inf.ed.ac.uk/rbf/CVonline/视觉研究组列表\nComputer vision test Image http://www.cs.cmu.edu/~cil/v-images.html卡内基梅隆标准图片库\n视觉论文搜索：Paper search\nhttp://www.researchindex.com\n五、图像处理GPL库（代码库图像库等）\nhttp://www.ph.tn.tudelft.nl/~klamer/cppima.html\nCppima 是一个图像处理的C++函数库。这里有一个较全面介绍它的库函数的文档，当然你也可以下载压缩的GZIP包，里面包含TexInfo格式的文档。\nhttp://iraf.noao.edu/\nWelcome to the IRAF Homepage! IRAF is the Image Reduction and Analysis Facility， a general purpose software system for the reduction and analysis of astronomical data\nhttp://entropy.brni-jhu.org/tnimage.html\n一个非常不错的Unix系统的图像处理工具，看看它的截图。你可以在此基础上构建自己的专用图像处理工具包。\nhttp://sourceforge.net/projects/\n这是GPL软件集散地，可以搜索IP库。\n国内的CSDN http://www.csdn.net/\n转载：http://blog.sciencenet.cn/home.php?mod=space&uid=509980&do=blog&id=436782\n原文：http://blog.csdn.net/shaoshuaiche/article/details/16850167#t9"}
