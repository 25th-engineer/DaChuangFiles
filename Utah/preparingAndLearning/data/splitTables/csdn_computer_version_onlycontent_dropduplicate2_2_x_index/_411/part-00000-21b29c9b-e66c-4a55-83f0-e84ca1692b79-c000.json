{"content2":"计算机视觉领域经典论文整理\n计算机视觉论文整理git项目\n计算机视觉的研究方向：\nImageNet分类\n物体检测\n物体跟踪\n低级视觉\n边缘检测\n语义分割\n视觉注意力和显著性\n物体识别\n人体姿态估计\nCNN原理和性质（Understanding CNN）\n图像和语言\n图像解说\n视频解说\n图像生成\n微软ResNet\n论文：用于图像识别的深度残差网络\n作者：何恺明、张祥雨、任少卿和孙剑\n链接：http://arxiv.org/pdf/1512.03385v1.pdf\n微软PRelu（随机纠正线性单元/权重初始化）\n论文：深入学习整流器：在ImageNet分类上超越人类水平\n作者：何恺明、张祥雨、任少卿和孙剑\n链接：http://arxiv.org/pdf/1502.01852.pdf\n谷歌Batch Normalization\n论文：批量归一化：通过减少内部协变量来加速深度网络训练\n作者：Sergey Ioffe, Christian Szegedy\n链接：http://arxiv.org/pdf/1502.03167.pdf\n谷歌GoogLeNet\n论文：更深的卷积，CVPR 2015\n作者：Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich\n链接：http://arxiv.org/pdf/1409.4842.pdf\n牛津VGG-Net\n论文：大规模视觉识别中的极深卷积网络，ICLR 2015\n作者：Karen Simonyan & Andrew Zisserman\n链接：http://arxiv.org/pdf/1409.1556.pdf\nAlexNet\n论文：使用深度卷积神经网络进行ImageNet分类\n作者：Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton\n链接：http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n物体检测\nPVANET\n论文：用于实时物体检测的深度轻量神经网络（PVANET：Deep but Lightweight Neural Networks for Real-time Object Detection）\n作者：Kye-Hyeon Kim, Sanghoon Hong, Byungseok Roh, Yeongjae Cheon, Minje Park\n链接：http://arxiv.org/pdf/1608.08021\n纽约大学OverFeat\n论文：使用卷积网络进行识别、定位和检测（OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks），ICLR 2014\n作者：Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus, Yann LeCun\n链接：http://arxiv.org/pdf/1312.6229.pdf\n伯克利R-CNN\n论文：精确物体检测和语义分割的丰富特征层次结构（Rich feature hierarchies for accurate object detection and semantic segmentation），CVPR 2014\n作者：Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik\n链接：http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf\n微软SPP\n论文：视觉识别深度卷积网络中的空间金字塔池化（Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition），ECCV 2014\n作者：何恺明、张祥雨、任少卿和孙剑\n链接：http://arxiv.org/pdf/1406.4729.pdf\n微软Fast R-CNN\n论文：Fast R-CNN\n作者：Ross Girshick\n链接：http://arxiv.org/pdf/1504.08083.pdf\n微软Faster R-CNN\n论文：使用RPN走向实时物体检测（Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks）\n作者：任少卿、何恺明、Ross Girshick、孙剑\n链接：http://arxiv.org/pdf/1506.01497.pdf\n牛津大学R-CNN minus R\n论文：R-CNN minus R\n作者：Karel Lenc, Andrea Vedaldi\n链接：http://arxiv.org/pdf/1506.06981.pdf\n端到端行人检测\n论文：密集场景中端到端的行人检测（End-to-end People Detection in Crowded Scenes）\n作者：Russell Stewart, Mykhaylo Andriluka\n链接：http://arxiv.org/pdf/1506.04878.pdf\n实时物体检测\n论文：你只看一次：统一实时物体检测（You Only Look Once: Unified, Real-Time Object Detection）\n作者：Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi\n链接：http://arxiv.org/pdf/1506.02640.pdf\nInside-Outside Net\n论文：使用跳跃池化和RNN在场景中检测物体（Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks）\n作者：Sean Bell, C. Lawrence Zitnick, Kavita Bala, Ross Girshick\n链接：http://arxiv.org/abs/1512.04143.pdf\n微软ResNet\n论文：用于图像识别的深度残差网络\n作者：何恺明、张祥雨、任少卿和孙剑\n链接：http://arxiv.org/pdf/1512.03385v1.pdf\nR-FCN\n论文：通过区域全卷积网络进行物体识别（R-FCN: Object Detection via Region-based Fully Convolutional Networks）\n作者：代季峰，李益，何恺明，孙剑\n链接：http://arxiv.org/abs/1605.06409\nSSD\n论文：单次多框检测器（SSD: Single Shot MultiBox Detector）\n作者：Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg\n链接：http://arxiv.org/pdf/1512.02325v2.pdf\n速度/精度权衡\n论文：现代卷积物体检测器的速度/精度权衡（Speed/accuracy trade-offs for modern convolutional object detectors）\n作者：Jonathan Huang, Vivek Rathod, Chen Sun, Menglong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, Kevin Murphy\n链接：http://arxiv.org/pdf/1611.10012v1.pdf\n物体跟踪\n论文：用卷积神经网络通过学习可区分的显著性地图实现在线跟踪（Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network）\n作者：Seunghoon Hong, Tackgeun You, Suha Kwak, Bohyung Han\n地址：arXiv:1502.06796.\n论文：DeepTrack：通过视觉跟踪的卷积神经网络学习辨别特征表征（DeepTrack: Learning Discriminative Feature Representations by Convolutional Neural Networks for Visual Tracking）\n作者：Hanxi Li, Yi Li and Fatih Porikli\n发表： BMVC, 2014.\n论文：视觉跟踪中，学习深度紧凑图像表示（Learning a Deep Compact Image Representation for Visual Tracking）\n作者：N Wang, DY Yeung\n发表：NIPS, 2013.\n论文：视觉跟踪的分层卷积特征（Hierarchical Convolutional Features for Visual Tracking）\n作者：Chao Ma, Jia-Bin Huang, Xiaokang Yang and Ming-Hsuan Yang\n发表： ICCV 2015\n论文：完全卷积网络的视觉跟踪（Visual Tracking with fully Convolutional Networks）\n作者：Lijun Wang, Wanli Ouyang, Xiaogang Wang, and Huchuan Lu,\n发表：ICCV 2015\n论文：学习多域卷积神经网络进行视觉跟踪（Learning Multi-Domain Convolutional Neural Networks for Visual Tracking）\n作者：Hyeonseob Namand Bohyung Han\n对象识别（Object Recognition）\n论文：卷积神经网络弱监督学习（Weakly-supervised learning with convolutional neural networks）\n作者：Maxime Oquab，Leon Bottou，Ivan Laptev，Josef Sivic，CVPR，2015\n链接：\nhttp://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Oquab_Is_Object_Localization_2015_CVPR_paper.pdf\nFV-CNN\n论文：深度滤波器组用于纹理识别和分割（Deep Filter Banks for Texture Recognition and Segmentation）\n作者：Mircea Cimpoi, Subhransu Maji, Andrea Vedaldi, CVPR, 2015.\n链接：\nhttp://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Cimpoi_Deep_Filter_Banks_2015_CVPR_paper.pdf\n人体姿态估计（Human Pose Estimation）\n论文：使用 Part Affinity Field的实时多人2D姿态估计（Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields）\n作者：Zhe Cao, Tomas Simon, Shih-En Wei, and Yaser Sheikh, CVPR, 2017.\n论文：Deepcut：多人姿态估计的联合子集分割和标签（Deepcut: Joint subset partition and labeling for multi person pose estimation）\n作者：Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele, CVPR, 2016.\n论文：Convolutional pose machines\n作者：Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh, CVPR, 2016.\n论文：人体姿态估计的 Stacked hourglass networks（Stacked hourglass networks for human pose estimation）\n作者：Alejandro Newell, Kaiyu Yang, and Jia Deng, ECCV, 2016.\n论文：用于视频中人体姿态估计的Flowing convnets（Flowing convnets for human pose estimation in videos）\n作者：Tomas Pfister, James Charles, and Andrew Zisserman, ICCV, 2015.\n论文：卷积网络和人类姿态估计图模型的联合训练（Joint training of a convolutional network and a graphical model for human pose estimation）\n作者：Jonathan J. Tompson, Arjun Jain, Yann LeCun, Christoph Bregler, NIPS, 2014.\n理解CNN\n论文：通过测量同变性和等价性来理解图像表示(Understanding image representations by measuring their equivariance and equivalence)\n作者：Karel Lenc, Andrea Vedaldi, CVPR, 2015.\n链接：\nhttp://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lenc_Understanding_Image_Representations_2015_CVPR_paper.pdf\n论文：深度神经网络容易被愚弄：无法识别的图像的高置信度预测（Deep Neural Networks are Easily Fooled:High Confidence Predictions for Unrecognizable Images）\n作者：Anh Nguyen, Jason Yosinski, Jeff Clune, CVPR, 2015.\n链接：\nhttp://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf\n论文：通过反演理解深度图像表示（Understanding Deep Image Representations by Inverting Them）\n作者：Aravindh Mahendran, Andrea Vedaldi, CVPR, 2015\n链接：\nhttp://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Mahendran_Understanding_Deep_Image_2015_CVPR_paper.pdf\n论文：深度场景CNN中的对象检测器（Object Detectors Emerge in Deep Scene CNNs）\n作者：Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba, ICLR, 2015.\n链接：http://arxiv.org/abs/1412.6856\n论文：用卷积网络反演视觉表示（Inverting Visual Representations with Convolutional Networks）\n作者：Alexey Dosovitskiy, Thomas Brox, arXiv, 2015.\n链接：http://arxiv.org/abs/1506.02753\n论文：可视化和理解卷积网络（Visualizing and Understanding Convolutional Networks）\n作者：Matthrew Zeiler, Rob Fergus, ECCV, 2014.\n链接：http://www.cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf\n图像与语言\n图像说明（Image Captioning）\nUCLA / Baidu\n用多模型循环神经网络解释图像（Explain Images with Multimodal Recurrent Neural Networks）\nJunhua Mao, Wei Xu, Yi Yang, Jiang Wang, Alan L. Yuille, arXiv:1410.1090\nhttp://arxiv.org/pdf/1410.1090\nToronto\n使用多模型神经语言模型统一视觉语义嵌入（Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models）\nRyan Kiros, Ruslan Salakhutdinov, Richard S. Zemel, arXiv:1411.2539.\nhttp://arxiv.org/pdf/1411.2539\nBerkeley\n用于视觉识别和描述的长期循环卷积网络（Long-term Recurrent Convolutional Networks for Visual Recognition and Description）\nJeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrell, arXiv:1411.4389.\nhttp://arxiv.org/pdf/1411.4389\nGoogle\n看图写字：神经图像说明生成器（Show and Tell: A Neural Image Caption Generator）\nOriol Vinyals, Alexander Toshev, Samy Bengio, Dumitru Erhan, arXiv:1411.4555.\nhttp://arxiv.org/pdf/1411.4555\nStanford\n用于生成图像描述的深度视觉语义对齐（Deep Visual-Semantic Alignments for Generating Image Description）\nAndrej Karpathy, Li Fei-Fei, CVPR, 2015.\nWeb：http://cs.stanford.edu/people/karpathy/deepimagesent/\nPaper：http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\nUML / UT\n使用深度循环神经网络将视频转换为自然语言（Translating Videos to Natural Language Using Deep Recurrent Neural Networks）\nSubhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko, NAACL-HLT, 2015.\nhttp://arxiv.org/pdf/1412.4729\nCMU / Microsoft\n学习图像说明生成的循环视觉表示（Learning a Recurrent Visual Representation for Image Caption Generation）\nXinlei Chen, C. Lawrence Zitnick, arXiv:1411.5654.\nXinlei Chen, C. Lawrence Zitnick, Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation, CVPR 2015\nhttp://www.cs.cmu.edu/~xinleic/papers/cvpr15_rnn.pdf\nMicrosoft\n从图像说明到视觉概念（From Captions to Visual Concepts and Back）\nHao Fang, Saurabh Gupta, Forrest Iandola, Rupesh Srivastava, Li Deng, Piotr Dollár, Jianfeng Gao, Xiaodong He, Margaret Mitchell, John C. Platt, C. Lawrence Zitnick, Geoffrey Zweig, CVPR, 2015.\nhttp://arxiv.org/pdf/1411.4952\nUniv. Montreal / Univ. Toronto\nShow, Attend, and Tell：视觉注意力与神经图像标题生成（Show, Attend, and Tell: Neural Image Caption Generation with Visual Attention）\nKelvin Xu, Jimmy Lei Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard S. Zemel, Yoshua Bengio, arXiv:1502.03044 / ICML 2015\nhttp://www.cs.toronto.edu/~zemel/documents/captionAttn.pdf\nIdiap / EPFL / Facebook\n基于短语的图像说明（Phrase-based Image Captioning）\nRemi Lebret, Pedro O. Pinheiro, Ronan Collobert, arXiv:1502.03671 / ICML 2015\nhttp://arxiv.org/pdf/1502.03671\nUCLA / Baidu\n像孩子一样学习：从图像句子描述快速学习视觉的新概念（Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images）\nJunhua Mao, Wei Xu, Yi Yang, Jiang Wang, Zhiheng Huang, Alan L. Yuille, arXiv:1504.06692\nhttp://arxiv.org/pdf/1504.06692\nMS + Berkeley\n探索图像说明的最近邻方法（ Exploring Nearest Neighbor Approaches for Image Captioning）\nJacob Devlin, Saurabh Gupta, Ross Girshick, Margaret Mitchell, C. Lawrence Zitnick, arXiv:1505.04467\nhttp://arxiv.org/pdf/1505.04467.pdf\n图像说明的语言模型（Language Models for Image Captioning: The Quirks and What Works）\nJacob Devlin, Hao Cheng, Hao Fang, Saurabh Gupta, Li Deng, Xiaodong He, Geoffrey Zweig, Margaret Mitchell, arXiv:1505.01809\nhttp://arxiv.org/pdf/1505.01809.pdf\n阿德莱德\n具有中间属性层的图像说明（ Image Captioning with an Intermediate Attributes Layer）\nQi Wu, Chunhua Shen, Anton van den Hengel, Lingqiao Liu, Anthony Dick, arXiv:1506.01144\n蒂尔堡\n通过图片学习语言(Learning language through pictures)\nGrzegorz Chrupala, Akos Kadar, Afra Alishahi, arXiv:1506.03694\n蒙特利尔大学\n使用基于注意力的编码器-解码器网络描述多媒体内容（Describing Multimedia Content using Attention-based Encoder-Decoder Networks）\nKyunghyun Cho, Aaron Courville, Yoshua Bengio, arXiv:1507.01053\n康奈尔\n图像表示和神经图像说明的新领域（Image Representations and New Domains in Neural Image Captioning）\nJack Hessel, Nicolas Savva, Michael J. Wilber, arXiv:1508.02091\nMS + City Univ. of HongKong\nLearning Query and Image Similarities with Ranking Canonical Correlation Analysis\nTing Yao, Tao Mei, and Chong-Wah Ngo, ICCV, 2015\n视频字幕（Video Captioning）\n伯克利\nJeff Donahue, Lisa Anne Hendricks, Sergio Guadarrama, Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, Trevor Darrell, Long-term Recurrent Convolutional Networks for Visual Recognition and Description, CVPR, 2015.\n犹他州/ UML / 伯克利\nSubhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko, Translating Videos to Natural Language Using Deep Recurrent Neural Networks, arXiv:1412.4729.\n微软\nYingwei Pan, Tao Mei, Ting Yao, Houqiang Li, Yong Rui, Joint Modeling Embedding and Translation to Bridge Video and Language, arXiv:1505.01861.\n犹他州/ UML / 伯克利\nSubhashini Venugopalan, Marcus Rohrbach, Jeff Donahue, Raymond Mooney, Trevor Darrell, Kate Saenko, Sequence to Sequence–Video to Text, arXiv:1505.00487.\n蒙特利尔大学/ 舍布鲁克\nLi Yao, Atousa Torabi, Kyunghyun Cho, Nicolas Ballas, Christopher Pal, Hugo Larochelle, Aaron Courville, Describing Videos by Exploiting Temporal Structure, arXiv:1502.08029\nMPI / 伯克利\nAnna Rohrbach, Marcus Rohrbach, Bernt Schiele, The Long-Short Story of Movie Description, arXiv:1506.01698\n多伦多大学 / MIT\nYukun Zhu, Ryan Kiros, Richard Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, Sanja Fidler, Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books, arXiv:1506.06724\n蒙特利尔大学\nKyunghyun Cho, Aaron Courville, Yoshua Bengio, Describing Multimedia Content using Attention-based Encoder-Decoder Networks, arXiv:1507.01053\nTAU / 美国南加州大学\nDotan Kaufman, Gil Levi, Tal Hassner, Lior Wolf, Temporal Tessellation for Video Annotation and Summarization, arXiv:1612.06950.\n图像生成\n卷积/循环网络\n论文：Conditional Image Generation with PixelCNN Decoders”\n作者：Aäron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, Koray Kavukcuoglu\n论文：Learning to Generate Chairs with Convolutional Neural Networks\n作者：Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox\n发表：CVPR, 2015.\n论文：DRAW: A Recurrent Neural Network For Image Generation\n作者：Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, Daan Wierstra\n发表：ICML, 2015.\n对抗网络\n论文：生成对抗网络（Generative Adversarial Networks）\n作者：Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio\n发表：NIPS, 2014.\n论文：使用对抗网络Laplacian Pyramid 的深度生成图像模型（Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks）\n作者：Emily Denton, Soumith Chintala, Arthur Szlam, Rob Fergus\n发表：NIPS, 2015.\n论文：生成模型演讲概述 （A note on the evaluation of generative models）\n作者：Lucas Theis, Aäron van den Oord, Matthias Bethge\n发表：ICLR 2016.\n论文：变分自动编码深度高斯过程（Variationally Auto-Encoded Deep Gaussian Processes）\n作者：Zhenwen Dai, Andreas Damianou, Javier Gonzalez, Neil Lawrence\n发表：ICLR 2016.\n论文：用注意力机制从字幕生成图像 （Generating Images from Captions with Attention）\n作者：Elman Mansimov, Emilio Parisotto, Jimmy Ba, Ruslan Salakhutdinov\n发表： ICLR 2016\n论文：分类生成对抗网络的无监督和半监督学习（Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks）\n作者：Jost Tobias Springenberg\n发表：ICLR 2016\n论文：用一个对抗检测表征（Censoring Representations with an Adversary）\n作者：Harrison Edwards, Amos Storkey\n发表：ICLR 2016\n论文：虚拟对抗训练实现分布式顺滑 （Distributional Smoothing with Virtual Adversarial Training）\n作者：Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Ken Nakae, Shin Ishii\n发表：ICLR 2016\n论文：自然图像流形上的生成视觉操作（Generative Visual Manipulation on the Natural Image Manifold）\n作者：朱俊彦, Philipp Krahenbuhl, Eli Shechtman, and Alexei A. Efros\n发表： ECCV 2016.\n论文：深度卷积生成对抗网络的无监督表示学习（Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks）\n作者：Alec Radford, Luke Metz, Soumith Chintala\n发表： ICLR 2016\n问题回答\n弗吉尼亚大学 / 微软研究院\n论文：VQA: Visual Question Answering, CVPR, 2015 SUNw:Scene Understanding workshop.\n作者：Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, Devi Parikh\nMPI / 伯克利\n论文：Ask Your Neurons: A Neural-based Approach to Answering Questions about Images\n作者：Mateusz Malinowski, Marcus Rohrbach, Mario Fritz,\n发布 ： arXiv:1505.01121.\n多伦多\n论文： Image Question Answering: A Visual Semantic Embedding Model and a New Dataset\n作者：Mengye Ren, Ryan Kiros, Richard Zemel\n发表： arXiv:1505.02074 / ICML 2015 deep learning workshop.\n百度/ 加州大学洛杉矶分校\n作者：Hauyuan Gao, Junhua Mao, Jie Zhou, Zhiheng Huang, Lei Wang, 徐伟\n论文：Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering\n发表： arXiv:1505.05612.\nPOSTECH（韩国）\n论文：Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction\n作者：Hyeonwoo Noh, Paul Hongsuck Seo, and Bohyung Han\n发表： arXiv:1511.05765\nCMU / 微软研究院\n论文：Stacked Attention Networks for Image Question Answering\n作者：Yang, Z., He, X., Gao, J., Deng, L., & Smola, A. (2015)\n发表： arXiv:1511.02274.\nMetaMind\n论文：Dynamic Memory Networks for Visual and Textual Question Answering\n作者：Xiong, Caiming, Stephen Merity, and Richard Socher\n发表： arXiv:1603.01417 (2016).\n首尔国立大学 + NAVER\n论文：Multimodal Residual Learning for Visual QA\n作者：Jin-Hwa Kim, Sang-Woo Lee, Dong-Hyun Kwak, Min-Oh Heo, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhang\n发表：arXiv:1606:01455\nUC Berkeley + 索尼\n论文：Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\n作者：Akira Fukui, Dong Huk Park, Daylen Yang, Anna Rohrbach, Trevor Darrell, and Marcus Rohrbach\n发表：arXiv:1606.01847\nPostech\n论文：Training Recurrent Answering Units with Joint Loss Minimization for VQA\n作者：Hyeonwoo Noh and Bohyung Han\n发表： arXiv:1606.03647\n首尔国立大学 + NAVER\n论文： Hadamard Product for Low-rank Bilinear Pooling\n作者：Jin-Hwa Kim, Kyoung Woon On, Jeonghee Kim, Jung-Woo Ha, Byoung-Tak Zhan\n发表：arXiv:1610.04325.\n视觉注意力和显著性\n论文：Predicting Eye Fixations using Convolutional Neural Networks\n作者：Nian Liu, Junwei Han, Dingwen Zhang, Shifeng Wen, Tianming Liu\n发表：CVPR, 2015.\n学习地标的连续搜索\n作者：Learning a Sequential Search for Landmarks\n论文：Saurabh Singh, Derek Hoiem, David Forsyth\n发表：CVPR, 2015.\n视觉注意力机制实现多物体识别\n论文：Multiple Object Recognition with Visual Attention\n作者：Jimmy Lei Ba, Volodymyr Mnih, Koray Kavukcuoglu,\n发表：ICLR, 2015.\n视觉注意力机制的循环模型\n作者：Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu\n论文：Recurrent Models of Visual Attention\n发表：NIPS, 2014.\n低级视觉\n超分辨率\nIterative Image Reconstruction\nSven Behnke: Learning Iterative Image Reconstruction. IJCAI, 2001.\nSven Behnke: Learning Iterative Image Reconstruction in the Neural Abstraction Pyramid. International Journal of Computational Intelligence and Applications, vol. 1, no. 4, pp. 427-438, 2001.\nSuper-Resolution (SRCNN)\nChao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Learning a Deep Convolutional Network for Image Super-Resolution, ECCV, 2014.\nChao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, Image Super-Resolution Using Deep Convolutional Networks, arXiv:1501.00092.\nVery Deep Super-Resolution\nJiwon Kim, Jung Kwon Lee, Kyoung Mu Lee, Accurate Image Super-Resolution Using Very Deep Convolutional Networks, arXiv:1511.04587, 2015.\nDeeply-Recursive Convolutional Network\nJiwon Kim, Jung Kwon Lee, Kyoung Mu Lee, Deeply-Recursive Convolutional Network for Image Super-Resolution, arXiv:1511.04491, 2015.\nCasade-Sparse-Coding-Network\nZhaowen Wang, Ding Liu, Wei Han, Jianchao Yang and Thomas S. Huang, Deep Networks for Image Super-Resolution with Sparse Prior. ICCV, 2015.\nPerceptual Losses for Super-Resolution\nJustin Johnson, Alexandre Alahi, Li Fei-Fei, Perceptual Losses for Real-Time Style Transfer and Super-Resolution, arXiv:1603.08155, 2016.\nSRGAN\nChristian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Wenzhe Shi, Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network, arXiv:1609.04802v3, 2016.\n其他应用\nOptical Flow (FlowNet)\nPhilipp Fischer, Alexey Dosovitskiy, Eddy Ilg, Philip Häusser, Caner Hazırbaş, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers, Thomas Brox, FlowNet: Learning Optical Flow with Convolutional Networks, arXiv:1504.06852.\nCompression Artifacts Reduction\nChao Dong, Yubin Deng, Chen Change Loy, Xiaoou Tang, Compression Artifacts Reduction by a Deep Convolutional Network, arXiv:1504.06993.\nBlur Removal\nChristian J. Schuler, Michael Hirsch, Stefan Harmeling, Bernhard Schölkopf, Learning to Deblur, arXiv:1406.7444\nJian Sun, Wenfei Cao, Zongben Xu, Jean Ponce, Learning a Convolutional Neural Network for Non-uniform Motion Blur Removal, CVPR, 2015\nImage Deconvolution\nLi Xu, Jimmy SJ. Ren, Ce Liu, Jiaya Jia, Deep Convolutional Neural Network for Image Deconvolution, NIPS, 2014.\nDeep Edge-Aware Filter\nLi Xu, Jimmy SJ. Ren, Qiong Yan, Renjie Liao, Jiaya Jia, Deep Edge-Aware Filters, ICML, 2015.\nComputing the Stereo Matching Cost with a Convolutional Neural Network\nJure Žbontar, Yann LeCun, Computing the Stereo Matching Cost with a Convolutional Neural Network, CVPR, 2015.\nColorful Image Colorization Richard Zhang, Phillip Isola, Alexei A. Efros, ECCV, 2016\nFeature Learning by Inpainting\nDeepak Pathak, Philipp Krahenbuhl, Jeff Donahue, Trevor Darrell, Alexei A. Efros, Context Encoders: Feature Learning by Inpainting, CVPR, 2016\n边缘检测\nSaining Xie, Zhuowen Tu, Holistically-Nested Edge Detection, arXiv:1504.06375.\nDeepEdge\nGedas Bertasius, Jianbo Shi, Lorenzo Torresani, DeepEdge: A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection, CVPR, 2015.\nDeepContour\nWei Shen, Xinggang Wang, Yan Wang, Xiang Bai, Zhijiang Zhang, DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection, CVPR, 2015.\n语义分割\nSEC: Seed, Expand and Constrain\nAlexander Kolesnikov, Christoph Lampert, Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation, ECCV, 2016.\nAdelaide\nGuosheng Lin, Chunhua Shen, Ian Reid, Anton van dan Hengel, Efficient piecewise training of deep structured models for semantic segmentation, arXiv:1504.01013. (1st ranked in VOC2012)\nGuosheng Lin, Chunhua Shen, Ian Reid, Anton van den Hengel, Deeply Learning the Messages in Message Passing Inference, arXiv:1508.02108. (4th ranked in VOC2012)\nDeep Parsing Network (DPN)\nZiwei Liu, Xiaoxiao Li, Ping Luo, Chen Change Loy, Xiaoou Tang, Semantic Image Segmentation via Deep Parsing Network, arXiv:1509.02634 / ICCV 2015 (2nd ranked in VOC 2012)\nCentraleSuperBoundaries, INRIA\nIasonas Kokkinos, Surpassing Humans in Boundary Detection using Deep Learning, arXiv:1411.07386 (4th ranked in VOC 2012)\nBoxSup\nJifeng Dai, Kaiming He, Jian Sun, BoxSup: Exploiting Bounding Boxes to Supervise Convolutional Networks for Semantic Segmentation, arXiv:1503.01640. (6th ranked in VOC2012)\nPOSTECH\nHyeonwoo Noh, Seunghoon Hong, Bohyung Han, Learning Deconvolution Network for Semantic Segmentation, arXiv:1505.04366. (7th ranked in VOC2012)\nSeunghoon Hong, Hyeonwoo Noh, Bohyung Han, Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation, arXiv:1506.04924.\nSeunghoon Hong,Junhyuk Oh,Bohyung Han, andHonglak Lee, Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network, arXiv:1512.07928\nConditional Random Fields as Recurrent Neural Networks\nShuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip H. S. Torr, Conditional Random Fields as Recurrent Neural Networks, arXiv:1502.03240. (8th ranked in VOC2012)\nDeepLab\nLiang-Chieh Chen, George Papandreou, Kevin Murphy, Alan L. Yuille, Weakly-and semi-supervised learning of a DCNN for semantic image segmentation, arXiv:1502.02734. (9th ranked in VOC2012)\nZoom-out\nMohammadreza Mostajabi, Payman Yadollahpour, Gregory Shakhnarovich, Feedforward Semantic Segmentation With Zoom-Out Features, CVPR, 2015\nJoint Calibration\nHolger Caesar, Jasper Uijlings, Vittorio Ferrari, Joint Calibration for Semantic Segmentation, arXiv:1507.01581.\nFully Convolutional Networks for Semantic Segmentation\nJonathan Long, Evan Shelhamer, Trevor Darrell, Fully Convolutional Networks for Semantic Segmentation, CVPR, 2015.\nHypercolumn\nBharath Hariharan, Pablo Arbelaez, Ross Girshick, Jitendra Malik, Hypercolumns for Object Segmentation and Fine-Grained Localization, CVPR, 2015.\nDeep Hierarchical Parsing\nAbhishek Sharma, Oncel Tuzel, David W. Jacobs, Deep Hierarchical Parsing for Semantic Segmentation, CVPR, 2015.\nLearning Hierarchical Features for Scene Labeling\nClement Farabet, Camille Couprie, Laurent Najman, Yann LeCun, Scene Parsing with Multiscale Feature Learning, Purity Trees, and Optimal Covers, ICML, 2012.\nClement Farabet, Camille Couprie, Laurent Najman, Yann LeCun, Learning Hierarchical Features for Scene Labeling, PAMI, 2013.\nUniversity of Cambridge\nVijay Badrinarayanan, Alex Kendall and Roberto Cipolla “SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation.” arXiv preprint arXiv:1511.00561, 2015.\nAlex Kendall, Vijay Badrinarayanan and Roberto Cipolla “Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder Architectures for Scene Understanding.” arXiv preprint arXiv:1511.02680, 2015.\nPrinceton\nFisher Yu, Vladlen Koltun, “Multi-Scale Context Aggregation by Dilated Convolutions”, ICLR 2016\nUniv. of Washington, Allen AI\nHamid Izadinia, Fereshteh Sadeghi, Santosh Kumar Divvala, Yejin Choi, Ali Farhadi, “Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing”, ICCV, 2015\nINRIA\nIasonas Kokkinos, “Pusing the Boundaries of Boundary Detection Using deep Learning”, ICLR 2016\nUCSB\nNiloufar Pourian, S. Karthikeyan, and B.S. Manjunath, “Weakly supervised graph based semantic segmentation by learning communities of image-parts”, ICCV, 2015\n其他资源\n课程\n深度视觉\n[斯坦福] CS231n: Convolutional Neural Networks for Visual Recognition\n[香港中文大学] ELEG 5040: Advanced Topics in Signal Processing(Introduction to Deep Learning)\n· 更多深度课程推荐\n[斯坦福] CS224d: Deep Learning for Natural Language Processing\n[牛津 Deep Learning by Prof. Nando de Freitas\n[纽约大学] Deep Learning by Prof. Yann LeCun\n图书\n免费在线图书\nDeep Learning by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\nNeural Networks and Deep Learning by Michael Nielsen\nDeep Learning Tutorial by LISA lab, University of Montreal\n视频\n演讲\nDeep Learning, Self-Taught Learning and Unsupervised Feature Learning By Andrew Ng\nRecent Developments in Deep Learning By Geoff Hinton\nThe Unreasonable Effectiveness of Deep Learning by Yann LeCun\nDeep Learning of Representations by Yoshua bengio\n软件\n框架\nTensorflow: An open source software library for numerical computation using data flow graph by Google [Web]\nTorch7: Deep learning library in Lua, used by Facebook and Google Deepmind [Web]\nTorch-based deep learning libraries: [torchnet],\nCaffe: Deep learning framework by the BVLC [Web]\nTheano: Mathematical library in Python, maintained by LISA lab [Web]\nTheano-based deep learning libraries: [Pylearn2], [Blocks], [Keras], [Lasagne]\nMatConvNet: CNNs for MATLAB [Web]\nMXNet: A flexible and efficient deep learning library for heterogeneous distributed systems with multi-language support [Web]\nDeepgaze: A computer vision library for human-computer interaction based on CNNs [Web]\n应用\n对抗训练 Code and hyperparameters for the paper “Generative Adversarial Networks” [Web]\n理解与可视化 Source code for “Understanding Deep Image Representations by Inverting Them,” CVPR, 2015. [Web]\n词义分割 Source code for the paper “Rich feature hierarchies for accurate object detection and semantic segmentation,” CVPR, 2014. [Web] ； Source code for the paper “Fully Convolutional Networks for Semantic Segmentation,” CVPR, 2015. [Web]\n超分辨率 Image Super-Resolution for Anime-Style-Art [Web]\n边缘检测 Source code for the paper “DeepContour: A Deep Convolutional Feature Learned by Positive-Sharing Loss for Contour Detection,” CVPR, 2015. [Web]\nSource code for the paper “Holistically-Nested Edge Detection”, ICCV 2015. [Web]\n讲座\n[CVPR 2014] Tutorial on Deep Learning in Computer Vision\n[CVPR 2015] Applied Deep Learning for Computer Vision with Torch\n博客\nDeep down the rabbit hole: CVPR 2015 and beyond@Tombone’s Computer Vision Blog\nCVPR recap and where we’re going@Zoya Bylinskii (MIT PhD Student)’s Blog\nFacebook’s AI Painting@Wired\nInceptionism: Going Deeper into Neural Networks@Google Research\nImplementing Neural networks"}
