{"content2":"1.计算机视觉\n对于计算机视觉领域来说，贡献最大的当然是 CVPR 与 ICCV，其它如 IJCAI 等也有相关主题的获奖论文。这些获奖论文具体研究的方向主要有目标检测、图像标注、图像生成、语义分割、卷积神经网络架构等方面。今年唯一以研究卷积架构为主题的获奖论文是康奈尔与清华大学联合完成的 Densely Connected Convolutional Networks，他们发现如果卷积神经网络在接近输入层和输出层的层级中包含较短的连接，那么 CNN 就能在训练上显著地变得更深、更精确和拥有更高的效率。据此，他们提出了密集卷积网络（DenseNet），这种卷积神经网络以前馈的方式将每一层与其他层相连接起来。这篇论文的评价非常高，很多研究者认为 DenseNet 在 ResNet 基础上提出了更优秀的密集型连接方式，这种连接不仅能使得特征更加稳健，同时还能产生更快的收敛速度。虽然有学者指出 DenseNet 的内存占用太大，训练成本很高，但也有研究者测试表明在推断时它所需要的内存要比 ResNet 少。以下展示了 DenseNet 的基本架构：\n除了卷积架构外，语义分割或目标实例分割最有影响力之一的获奖论文就是何凯明等研究者提出来的 Mask R-CNN，它是一种简单、灵活和高效的通用目标分割框架。Mask R-CNN 是基于 Faster R-CNN 的扩展，它在用于边界框识别的分支上添加了一个并行的分支用于预测目标的掩码。因此这种方法不仅能够有效地检测图像中的目标，同时还能为每个实例生成一个高质量的分割掩码。值得注意的是，何凯明是该最佳论文的第一作者，同时是今年最佳学生论文的作者之一，若加上 CVPR 2009、CVPR 2016 两篇最佳论文，那么他已有四篇获计算机视觉顶会的最佳论文。\nMask R-CNN 框架\n在计算机视觉研究主题中，今年获奖论文讨论得比较多的可能就是目标检测。在 YOLO9000: Better, Faster, Stronger 论文中，作者提出了 YOLOv2 和 YOLO9000 检测系统。YOLOv2 能大大改善 YOLO 模型，并且以非常高的 FPS 获得更好的结果，而 YOLO9000 这一网络结构可以实时地检测超过 9000 种物体分类，这主要可以归因于 WordTree 混合了目标检测数据集与目标识别数据集，因此通过联合训练能实现非常好的效果。而在 Focal Loss for Dense Object Detection 论文中，研究者提出的全新 Focal Loss 方法，它集中于稀疏、困难样本中的训练，避免了训练过程中可能出现的大量负面因素。他们表明使用 Focal Loss 进行训练的 RetinaNet 可以在目标检测任务上达到一步检测器的速度，同时准确性高于业内最佳的两步检测器。\n图像生成其实也是今年获奖论文比较关注的主题，例如苹果公司的 Learning from Simulated and Unsupervised Images through Adversarial Training 提出了模拟加非监督学习方法在使用合成图像方面展现出了显著的提升效果。而另一篇 Tag Disentangled Generative Adversarial Networks for Object Image Re-rendering 提出了一种条理化的标签解纠缠的生成对抗网络（TDGAN），该 TDGAN 通过指定多个场景属性（如视角、照明和表现等）从单张图片重新渲染出感兴趣目标的新图片。若给定一张输入图像，解纠缠网络会抽取解开的、可解释性的表征，然后这些表征再投入到生成网络以生成图片。"}
