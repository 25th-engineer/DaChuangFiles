{"content2":"计算机视觉的发展历史：\n动物进化出眼睛；生物视觉-》机器视觉-》照相机；\n生物学家开始研究视觉的机理，Hubel & Wiesel，1959，他们的问题是：哺乳动物的视觉处理机制是怎样的呢？他们将电极插进主要控制猫视觉的后脑上的初级视觉皮层（V1），然后观察，何种刺激会引起视觉皮层神经元的反应。他们发现猫的大脑的初级视觉皮层有各种各样的细胞，其中最重要的细胞是当它们朝着某个特定的方向运动的时候，对面向边缘产生反应的细胞。当然还有更加复杂的细胞，但是总的来说，它们发现视觉初级是始于视觉世界的简单结构，面向边缘，沿着视觉处理途径的移动，信息也在变化，大脑建立了复杂的视觉信息，直到它可以识别更为复杂的视觉世界。\n计算机视觉的历史是从60年代初开始的，Block World 是由Larry Roberts出版的一部作品，被广泛地称为计算机视觉的第一篇博士论文，其中视觉世界被简化为简单的几何形状，目的是能够识别它们，重建这些形状是什么。1966年MIT的暑期视觉项目，目的是为了构建视觉系统的重要组成部分。David Marr，一个MIT 视觉科学家提出了使得计算机识别视觉世界的算法，他指出，为了获取视觉世界完整的3D图像，需要经历几个阶段：第一个阶段是原始草图，大部分边缘、端点和虚拟线条，这是受到了神经科学家的启发，Hubel &Wiesel 告诉我们视觉处理的早期阶段有很多关于像边缘的简单结构；第二阶段是David Marr 所说的“2.5维草图”我们开始将表面、深度信息、不同的层次以及视觉场景的不连续性拼凑在一起的；最后一个阶段是将所有的内容放在一起，组成一个3D模型。这是一个非常理想化的思想过程，这种思维方式实际上已经在计算机视觉领域影响了几十年。这也是一个非常直观的方式，并考虑如何解构视觉信息。\n七十年代另外一个非常重要的工作（Brooks&Binford,1979 Fischler & Elschlager 1973），这个时候他们提出了一个问题，我们如何越过简单的块状世界，开始识别和表示现实世界的对象。70年代是一个没有数据可用的时代，计算机的速度很慢，计算机科学家开始思考如何识别和表示对象，在斯坦福大学的帕洛阿尔托以及斯里兰卡提出了类似的想法，一个被称为广义圆柱体，一个被称为圆形结构，他们的基本思想是每个对象都是由简单的几何图单位组成，任何一种表示的方法就是讲物体的复杂结构，简约成一个集合体，有更简单的形状和几何结构，这些研究已经影响了很长很长的一段时间。\n80年代，David Lowe思考如何重建或者识别由简单的物体结构组成的视觉空间，他尝试识别剃须刀，通过先和边缘进行构建，其中大部分都是直线以及直线之间的组合。那个时候由于样本小，物体识别是很难的。\n如果物体识别太难了，那么我们首先要做的是目标分割，这个任务就是把一张图片中的像素点归类到有意义的区域，我们可能不知道这些像素点组合到一起是一个人型，但是我们可以把这些属于这人的像素点从背景中抠出来，这个过程就叫做图像分割，这项工作是由Berkeley的 Jitendra Malik和他的学生Jianbo Shi 所完成的。他们用一个图论算法对图像进行分割，还有另外一个问题，先于其他计算机视觉问题有进展，也就是面部检测，脸部是人类最重要的部位之一。\n1999-2000年机器学习技术，特别是统计机器学习方法，开始加速发展，出现了很多方法：支持向量机模型，boosting方法，图模型。有一种工作做出了很多贡献，技术使用AdaBoost 算法进行实时面部检测，由Paul Viola和Michal Jones 完成。在他们发表论文后的第五年，也就是2006年，富士康推出了第一个具有实时面部识别的照相机。这是从基础科学研究到实际应用的一个快速转化，关于如何才能能够做到更好的目标识别，这是一个我们可以继续研究的领域。从90年代末到2000年的前十年有一个非常有影响力的思想方法是基于特征的目标识别，这里有一个影响深远的工作，由 David Lowe完成，叫做SIFT特征，思路就是去匹配整个目标。例如这里有一个stop标识去匹配另外一个stop标识是非常困难的，因为有很多变化的因素，比如相机的角度、遮挡、视角、光线以及目标自身的内在变化，但是可以得到一些启发，通过观察目标的某些部分，某些特征是能够在变化中保持不变性，所以目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的特征进行匹配，它比匹配整个目标要容易得多。我们这个领域另外一些进展是识别整幅图的场景，有一个算法叫空间金字塔匹配，背后的思想是图片里面有各种特征，这些特征可以告诉我们这是哪种场景，到底是风景还是厨房，或者是高速公路等等 。这个算法从图片的各部分，各个像素抽取特征，并把他们放在一起，作为一个特征描述符，然后在特征描述符上做一个支持向量机。有个在人类认知方面很类似的工作正处于风头浪尖。有些工作是把这些特征放在一起之后，研究如果在实际图片中合理地设计人体姿态和辨认人体姿态，这方面一个工作被称为方向梯度直方图；另外一个被称为可变形部件模型。\n可以看到我们从60年代、70年代、80年代一步步走到20世纪，有一件事情一直在变化，就是图片的质量，随着互联网的发展，随着数码相机的发展，计算机视觉的研究也能拥有更好的数据了，计算机视觉在21世纪早期提出了一个非常重要的基本问题，我们一直在目标识别，但是直到21世纪的早期，我们才开始真正拥有标注的数据集，能供我们衡量在弥补识别方面取得的成果，其中最具有影响力的标记数据集之一叫PASCAL Visual Object Challenge 这个数据集由20个类别的图片，数据集中的每个种类都有成千上万张图片，\n现场不同的团队开发算法来和数据测试集做对抗训练，来看有没有优化，这里有一张图表列举了从2007年到2012年在基准数据集上检测图像中的20中目标的检测效果，可以看到在稳步提升。在差不多时候，普林斯顿和斯坦福中的一批人开始，向我们或者说我们这个领域提出了一个更加困难的问题，我们是否具备了识别真实世界中的每一个物体的能力，或者说大部分物体。这个问题是由机器学习中的一个现象驱动的，就是大部分的机器学习算法，无论是图模型，还是支持向量机或者是AdaBoost都可能会在训练过程中过拟合，部分原因是可视化的数据非常复杂，我们的模型的维数就很高，参数量就很大，输入是高维的模型，则还有一堆参数需要调优，当我们的训练数据量不够时，很快就产生了过拟合的现象，这样我们就无法很好地泛化，因此即使有两方面的动力，一是我们单纯地想识别自然世界中的万物，二是要回归机器学习克服机器学习中的瓶颈问题，过拟合问题。 LIfeifei开展了一个叫ImageNet的项目，汇集所有能够找到的图片，包含世界万物，组建一个尽可能大的数据集，用一个称为WorldNet的字典来排序，这个字典里有上万个物体类别，用亚马逊土耳其机器人平台进行排序清洗数据，给每张图片打上标签，最终的结果是一个ImageNet,最后由将近500万甚至4000万多的图片，分成22000类的舞台或者场景，这是一个巨大的，很有可能是由当时AI领域最大的数据集，它将目标检测算法的发展推到了一个新的高度。从2009年开始，ImageNet团队组织了一场国际比赛，叫做ImageNet大规模视觉识别竞赛，这是一个筛选更严格的测试集，总共140万的目标图像有1000种目标类别，分别识别来测试计算机视觉算法。2012年卷积神经网络算法击败了所有其他的算法。CNN模型展现了强大的能量。"}
