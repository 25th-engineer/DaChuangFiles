{"content2":"计算机视觉中常用的评价标准\n1 召回率\nRecall，又称“查全率”——还是查全率好记，也更能体现其实质意义。\n2 准确率\nPrecision，又称“精度”、“正确率”。\n以检索为例，可以把搜索情况用下图表示：\n相关 不相关\n检索到 A B\n未检索到 C D\nA：检索到的，相关的 （搜到的也想要的）\nB：检索到的，但是不相关的\n（搜到的但没用的）\nC：未检索到的，但却是相关的\n（没搜到，然而实际上想要的）\nD：未检索到的，也不相关的\n（没搜到也没用的）\n如果我们希望：被检索到的内容越多越好，这是追求“查全率”，即\nA/(A+C)，越大越好。\n如果我们希望：检索到的文档中，真正想要的、也就是相关的越多越好，不相关的越少越好，这是追求“准确率”，即A/(A+B)，越大越好。\n“召回率”与“准确率”虽然没有必然的关系（从上面公式中可以看到），在实际应用中，是相互制约的。\n要根据实际需求，找到一个平衡点。\n3 举例\n假设原始样本中有两类，其中：\n1：总共有 P个类别为1的样本，假设类别1为正例。\n2：总共有N个类别为0 的样本，假设类别0为负例。\n经过分类后：\n3：有 TP个类别为1 的样本被系统正确判定为类别1，FN 个类别为1 的样本被系统误判定为类别 0，显然有P=TP+FN；\n4：有 FP 个类别为0 的样本被系统误判断定为类别1，TN 个类别为0 的样本被系统正确判为类别 0，显然有N=FP+TN；\n精确度（Precision）\nP = TP/(TP+FP) ; 反映了被分类器判定的正例中真正的正例样本的比重\n准确率（Accuracy）\nA = (TP + TN)/(P+N) = (TP + TN)/(TP + FN + FP + TN); 反映了分类器统对整个样本的判定能力——能将正的判定为正，负的判定为负\n召回率(Recall)，也称为 True Positive Rate\nR = TP/(TP+FN) = 1 - FN/T; 反映了被正确判定的正例占总的正例的比重\n转移性（Specificity，不知道这个翻译对不对，这个指标用的也不多），也称为 True NegativeRate\nS = TN/(TN + FP) = 1 – FP/N； 明显的这个和召回率是对应的指标，只是用它在衡量类别0 的判定能力。\nF-measure(综合评价指标) or balanced F-score\nF = 2 * 召回率 * 准确率/ (召回率+准确率)；这就是传统上通常说的F1 measure\ntrue positives (纳真) false positives（纳伪）\nfalse negatives（去真）true negatives (去伪)\n其中false positives（纳伪）也通常称作误报，false negatives也通常称作漏报！\n以上均参考网上大牛！感谢万能的互联网！"}
