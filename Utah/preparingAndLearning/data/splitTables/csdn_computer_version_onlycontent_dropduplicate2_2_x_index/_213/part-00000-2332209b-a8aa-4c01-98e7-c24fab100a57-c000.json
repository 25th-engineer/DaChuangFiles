{"content2":"基于双目计算机视觉的自适应识别算法及其监控应用\n摘要：双时时彩奖金1800，凤凰平台，十年信誉全网第一\n平台总代QQ：2317365898\n目计算机视觉是利用仿生学原理,通过标定后的双摄像头来得到同步曝光图像,然后计算获取的2维图像像素点的第3维深度信息。为了对不同环境场景进行监控提出了一种新的基于双目计算机视觉的自适应识别算法。该算法首先利用像素点的深度信息对场景进行识别判断,然后采用统计的方法为场景建模,并通过时间滤波克服光照渐变,以及通过深度算法特性克服光照突变。与单摄像头监控系统相比,利用该算法实现的视频监控原型系统,可应用于更多场合,并利用深度信息设置报警级别,来降低误检率。\n关键词：双目计算机视觉　深度信息　自适应　光照变化　视频监控\n1　引　言\n面对日益复杂的社会和政治环境,国家安全、社会安全、个人人生安全和财产安全等都面临着不同程度的威胁,都需要各种安全保护措施,在众多场所建立切实有效的安保措施,成为一个迫切的课题。本文提出了一种基于双目计算机视觉的自适应识别算法,将该算法应用于现有的监控系统,并赋予监控终端智能性,不仅使其脱离人而具有独立智能、自主判断的能力,而且使得视频监控系统在安防方面的作用大大提高。\n在现有的背景建模方法中,大多对于背景象素点的亮度值,例如最小亮度值、最大亮度值和最大亮度差值[ 1 ] ,或是对颜色信息进行建模[ 2 ] 。对于背景的更新,一般使用自适应滤波器对像素的统计特性进行递归更新,为了考虑到噪声的影响,文献[ 3 ]提出了Kalman滤波器的方法,该文认为系统的最优信息可通过估计获得。考虑到环境的动态缓慢改变,文献[ 4 ]利用统计模型给背景建模,即由一个时域滤波器保留着一个序列均值和一个标准偏差,并通过滤波过程统计值随时间改变来反映环境的动态特性。另外有一些方法解决了光照渐变等影响[ 5～7 ] ,但计算较复杂。\n2双目计算机视觉深度算法\n基于实际应用考虑,摄像头的数量关系着成本和计算量,所以选择支持双摄像头(双目视觉)的算法是最合适的。在支持双目视觉的算法中,Princeton NEC research institute 基于最大流算法(maximum2flow)的计算机视觉算法( Stereo2MF)在深度效果平滑性上做得较好[ 8, 9 ] ,适用于监控区域深度计算的应用背景。但原有算法所需的计算量和计算过程中的暂存数据量是较大的,虽然支持计算量的削减,但只是机械地在一块区域中选择中心点来进行计算,这样计算的结果会因选择的机械性,而出现大量的“伪点”,这些伪点错误地表现了该区域的平均深度信息。本文采用统计平均值选取计算点,通过距离因子的Gauss分布将块内其他点的值融合计算,从而使得计算出的值较准确的代表了这一块内的大致深度分布。\nm, n分别是图像的长和宽所包含的像素点个数,M、N 表示像素点的横纵坐标, .d 是块内深度统计平均值, dM, N为计算点的深度值, q为距离因子, dB是计算所得的块深度代表值。为改进后双目视觉深度算法与原算法识别效果比较。由可以明显看出,修改后的算法效果在细节表现、平滑性、伪点减少上均有明显改善,而且深度计算精确度能够完全满足视频\n　改进后双目视觉深度算法与原算法识别效果比较Fig. 1Effect comparison after algorithm modification\n度计算精确度能够完全满足视频监控应用的需要。\n3　自适应识别算法\n对于一个固定的场景,场景各像素点的深度值是符合一个随机概率分布。以某一均值为基线,在其附近做不超过某一偏差的随机振荡,这种情况下的场景称之为背景。而场景环境往往是动态变化的,如环境自然光的缓变,灯光的突然熄灭或点亮,以及运动对象的出现、运动和消失等。如果能识别出场景中的动态变化,就能自适应的更新背景值,将光照的改变融合到背景值中。本文采取了用统计模型的方式给每个像素点建模,而以像素点变化的分布情况来确定光照突变引起的深度突变,并结合深度计算本身特性,解决光照缓变突变引起的误判问题,以及判别场景中对象的主次性。\n3. 1　背景象素点的深度值建模\n由于双目计算机视觉算法得到的深度值,已经是块融合的,可以根据精度要求,来加大块面积, 减少数据量。本文获得的数据量只有原像素点的( k, l分别是块的长和宽所包含的像素点个数) 。以统计的方法给每个像素点的深度值建模, 设为第u帧图像的某个像素点的深度值, 其中u代表第u帧图像, i, j分别代表像素点的横坐标和纵坐标。由一个时间滤波器来保持该像素点深度值的序列均值和时间偏差\n其中,α是一个可调增益参数, 其与采样频率有关。通过滤波过程,来得到每个像素点的深度值基于时间的统计特性,由于这些统计特性反映了环境的动态特性,据此可以了解到是环境的光照发生了突变,还是有运动对象的运动。\n3. 2　背景更新与场景识别\n通过上述滤波过程,就可以将光照缓变融入到背景中去,实现背景的自适应更新。而对于光照突变,此时几乎所有的象素点的亮度值会同时增大或减小,但根据最大流算法的特性,同方向的变化对流量差不会引起太大变化, 而对深度计算结果只会引起较小的同方向变化。这种全局的等量变化, 可以认为是光照突变引起的。\n其中, a、b和c是3个可调节系数,他们的取值可依据场景的情况及检测光照突变的速度与误差来进行选取。s, t分别是深度图像的长和宽所包含的像素点个数。Q是符合式( 9)的像素点个数。一旦检测到环境光照发生了突变, 就把背景点像素的深度序列均值,全部以当前帧像素点的深度值的测量\n值代替,而j以0取代,从而实现背景的及时更新。\n如果式(10)式(12)中任意一个不成立的话,则认为像素块深度值的变化并非由光照突变引起, 而是场景中有运动对象出现。\n4　算法分析与实验\n4. 1　算法复杂度\n对于光照突变检测,若有突变的话,则会立即检测出来,当有运动对象出现时, 并且式( 10)式( 12)都接近满足时,处理会较慢,因为需要处理突变检测和运动对象两个过程。当b取25% s ×t时的处理速度与变化点比例关系如所示。\n相对于一般的光强、灰度的识别检测算法,本算法的优势在于不仅可以利用深度特性更容易地检测到光照的渐变与突变, 而且可以判断出现的多个运动对象的主次性。\n4. 2　算法误检率\n由于光照直接对于像素点的光强、灰度等产生影响,所以深度算法的噪声容限更大,这样可降低了误检率,多组实验后得到的误检率对比图如所示。但是由于深度算法本身对于反光或者阴暗面会产生伪点,所以,某些时候由于光照突变中光源的位置变化而会误检为运动对象,为此算法还需进一步改进能判别伪点的出现, 除去它在光照突变检测中的影响。另外,公式中可调系数a, b, c的选取也会对不同场景产生影响。\n笔者在实验室环境下做了不同光照角度、不同环境光强度、不同运动物体的多组实验,发现在反光面或是阴暗面较多的情况下,光照突变检测不是很灵敏,而且会出错,但是在增加系数a, c的值后, 误检率有所降低(如所示) 。\n5　基于算法的监控系统\n我们利用该算法实现了视频监控原型系统。计算机视觉算法对于摄像头的同步曝光要求很高,所以本系统终端用一块单独的MCU (micro control unit)控制同步曝光。核心算法用DSP处理。系统结构如所示。实际系统原型图如所示。\n6　结　论\n利用深度信息做智能场景识别,是一种新的尝试,有其优势。将这种方法应用到智能视频监控中,能起到很好的效果,克服了其他方法较难处理的光照渐变和突变等问题。对比单摄像头监控系统,该系统可应用于更多场合。后续研发准备在系统上加上更多功能,以适用于更多的环境,并与其他保安类监控系统互联,以组成一整套功能强大、达到国内外一流水平的安防系统。\n参考文献( References)\n1Ude A, Riley M. Prediction of body configurations and appearance for model-based estimation of articulated human motions [A ]. In: IEEE SMC’99 Conference Proceeding [ C ] , Tokyo, Japan, 1999: 687～691.\n2Ricquebourg Y, Bouthemy P. Real-time tracking of moving persons by exp loiting spatio2tempp ral image slices[ J ]. IEEE Transactions on Pattern Analysis andMachine Intelligence, 2000, 22 (8) : 797～808.\n3Tsap L V, Goldof D B, Sarkar S. Nonrigid motion analysis based on dynamic refinement of finite elementmodelsp [ J ]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2000, 22 ( 5 ) : 526～543.\n4Haritaoglu I, Harwood D, Davis L. A real time system for detecting and tracking peop le [ A ]. In: Third International Conference on Automatic Face and Gesture[ C ] , Nara, Japan, Ap ril 1998.\n5Wren C, AzarbayejaniA, Darrell T. Real-time tracking of the human body [ J ]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1997, 19 (7) : 780～785.\n6Ridder C, Munkelt O, Kirchner H. Adap tive background estimation and foreground detection using Kalman filtering[A ]. In: Proceedings International Conference. Recent Advances in Mechatronics, ICRAM’95, Istanbul, Turkey, 1995: 193～199.\n7Fujiyoshi H, Lip ton A J. Real-time human motion analysis by image skeletonization[A ]. In: Proceedings of theWorkshop on App lication of ComputerVision, Freiburg, Germany, October 1998.\n8Sebastien Roy, Ingemar J Cox. A maximum-flow formulation of the n-camera stereo correspondence p roblem [ A ]. In: International Conference on Computer Vision ( ICCV’98 ) [ C ] , Bombay, India, January 1998: 492～499.\n9Cox I J, Hingorani S, Maggs B M. A maximum likelihood stereo algorithm[ J ]. Computer Vision and Image Understanding, 1996, 63 (3) : 542～567."}
