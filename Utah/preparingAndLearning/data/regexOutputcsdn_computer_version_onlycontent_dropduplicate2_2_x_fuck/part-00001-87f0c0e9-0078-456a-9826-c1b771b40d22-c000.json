{"content2":"计算机视觉简介\n计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和计算机代替人眼对目标进行识别、跟踪和测量等，并进一步做图像处理，用计算机处理成为更适合人眼观察或传送给仪器检测的图像\n计算机图形学和计算机视觉：\n可能刚开始学习视觉相关的小伙伴对计算机视觉和计算机图形学的概念有些蒙圈，感觉两者非常像。但其实他们还是有很大区别的，简单的来说，计算机视觉侧重于对图像的识别，得到一些结论，而计算机图形学侧重于如何从其他数据产生到图像。具体来说\n计算机图形学（Computer Graphics）讲的是图形，也就是图形的构造方式，是一种从无到有的概念，从数据得到图像。是给定关于景象结构、表面反射特性、光源配置及相机模型的信息，生成图像。\n计算机视觉（Computer Vision）是给定图象，从图象提取信息，包括景象的三维结构，运动检测，识别物体等。\n主要任务\n在现在的计算机视觉研究中，可以主要分类为几个主要的任务\n1. 图像分类：分类任务是基础任务，而图像分类问题就是给输入图像分配标签类别的任务，这是计算机视觉的核心问题之一。一般说来，经典的图像分类算法是通过手工特征或者特征学习方法对整个图像进行全局描述，然后使用分类器判断是否存在某类物体。现在更多的是用端到端的深度学习技术。\n2.物体检测：物体检测是视觉感知的第一步，也是计算机视觉的一个重要分支。物体检测的目标，就是用框去标出物体的位置，并给出物体的类别。物体检测和图像分类不一样，检测侧重于物体的搜索，而且物体检测的目标必须要有固定的形状和轮廓。图像分类可以是任意的目标，这个目标可能是物体，也可能是一些属性或者场景。\n3、物体定位：如果说图像识别解决的是what，那么，物体定位解决的则是where的问题。利用计算视觉技术找到图像中某一目标物体在图像中的位置，即定位。目标物体的定位对于计算机视觉在安防、自动驾驶等领域的应用有着至关重要的意义。\n另外，物体定位的延伸目标跟踪，是指在给定场景中跟踪感兴趣的具体对象或多个对象的过程。简单来说，给出目标在跟踪视频第一帧中的初始状态（如位置、尺寸），自动估计目标物体在后续帧中的状态。该技术对自动驾驶汽车等领域显得至关重要。\n4. 图像分割：图像分割指的是将数字图像细分为多个图像子区域（像素的集合，也被称作超像素）的过程。图像分割的目的是简化或改变图像的表示形式，使得图像更容易理解和分析。更精确地说，图像分割是对图像中的每个像素加标签的一个过程，这一过程使得具有相同标签的像素具有某种共同视觉特性。\n另外，“图像语义分割”是一个像素级别的物体识别，即每个像素点都要判断它的类别。它和检测的区别是，物体检测是一个物体级别的，他只需要一个框，去框住物体的位置，而通常分割是比检测要更难的问题。\n5. 图像标注–看图说话：图像标注是一项引人注目的研究领域，它的研究目的是给出一张图片，你给我用一段文字描述它，具体例子如下图所示，近几年，工业界的百度，谷歌和微软 以及学术界的加大伯克利，深度学习研究重地多伦多大学都在做相应的研究。\n6. 图像生成–文字转图像：图片标注任务本来是一个半圆，既然我们可以从图片产生描述文字，那么我们也能从文字来生成图片。这个任务也是非常有趣的，特别是在深度学习模型GAN被研发出来之后，这个任务也有更多的方法来解决。\n主要模型和技术\n图像分类设计主要的模型-卷积神经网络（CNN）\n目标检测涉及主要模型是Fast R-CNN算法、YOLO、SSD以及R-FCN等等\n基于CNN完成目标跟踪的典型算法是FCNT和MD Net。\n图像分割的经典模型包括FCN模型，Mask R-CNN。\n图像标注的话可以看下谷歌开源的“Show and Tell”\n图像生成在今年来主流的方式是GAN模型和VAE模型，这两个生成模型都值得好好研究。\n相关资料推荐\n对于学习基础，我比较推荐的是《数字图像处理与分析》https://www.bilibili.com/video/av43045572和OpenCV这个计算机视觉库，对于OpenCV，这里推荐一本比较基础的介绍资料\n《OpenCV_2 Computer Vision Application Programming Cookbook》\n2. 然后推荐一些视频，非常推荐大牛Andrew Ng吴恩达的那门《深度学习》专项课程 ，首先这门课也是对入门者非常友好的，然后Ng讲课也非常的深入浅出除了看视频，建议要把作业全部写完，这样才会理解得更加深刻。然后还有斯坦福的《计算机视觉cs231n》这门课，想当年我就是从这节课入的门，这门课也有很多相应的练习，都可以做一下，对巩固深度学习，视觉的知识非常的有好处\n3.最后推荐一些书籍 和网站，书籍的话推荐《Deep Learning》和《Computer Vision : Algorithms and Applications》这两本书应该也是非常出名的的，建议研读几遍，内力必定大增。网站的话肯定是arxiv的Computer Vision and Pattern Recognition模块了，这个模块每天都有新的关于计算机视觉的论文，大家可以经常上去看看。\n总结及看法\n近年来，计算机视觉的发展越来越迅猛，大大小小的应用也越来多，从日常超市条形码检测、上下班指纹考勤、人脸识别考勤、电影特效制作、工业生产自动化检测、 医学影像检测，再到航空天文领域，航空遥感测控地形地貌等等。我觉得首先这得益于深度学习技术的发展和应用，目前为止，相对于自然语言处理，计算机视觉的研究和应用更加的激动人心，更加的贴近人民生活的方方面面。\n对于未来计算机视觉的发展，我最感兴趣的是在自动驾驶方面，虽然说这个领域现在有很多的困难和挑战，但是我觉得在知识目标跟踪和检测技术的不断发展前提下，自动驾驶是变得越来越有可能。\n最后，现在计算机视觉很火热，这个领域也非常的有趣，也欢迎你们走进计算机视觉的世界~\n本文首发于我自己的公众号，欢迎大家关注~"}
{"content2":"人工智能发展至今，在计算机视觉上。我们人看到的是图像，而计算机看到矩阵数值，人工智能在计算机视觉上的目标就是解决像素值和语义之间关系，主要的问题有图片检测，图片识别，图片分割和图片检索。什么是语义，通俗点讲就是它有什么信息。我们通过对数值距阵进行处理，得到一些信息，一些理解层次上的，比如这个7x7的数值矩阵表示一个人。但我们想让计算机知道这是一个人，并不是一件简单的事情，需要一些各种处理和操作。\n图片检测就是检测它是什么，比如行人检测，人脸检测等。识别是更深层次的，比如人脸，车牌，但这里的人脸识别是更为精确的，之前的检测是检测这是不是一个人脸，而识别则倾向于这是谁的人脸。分割是把感兴趣的分割出来，有前景分割，语义分割。检索找岀相似的。它们用到的方法，有传统的方法，也有深度学习的方法。\n下面我还想说一下一些深度学习名词和它们解决的问题。CNN卷积深经网络，这个主要是特征的描述，我们提取CNN特征，有人会问什么是特征，通俗一点讲，比如一个西瓜，他的大小，甜度都可以是他的特征，用来描述这个物体的，也可以用来判断这个物体。我们人看到的物体有这些特征来让我们判断这是什么，而计算机而言，也需要特征来让计算机知道他是什么，其实很多是有做人工智能，多想想我们是怎么认知的，可以模拟让计算机也这样，可以解决很多问题；rCNN是region区域的CNN，这个就解决检测相关问题，像fast－rCNN，faster－rCNN，本质上是每个区域的CNN特征，给出一个分数，设置一个阈值，阈值达到多少以后就是什么物体，这里我想说一个分数和阈值的问题，这两个东西在人工智能和机器学习中是很重要的，因为计算机不能像人一样很直观的知道这是什么， 他在干什么，计算机需要一个评判标准，而分数和阈值就是一个评判标准，分数可以理解为相似度，可能是某个东西的可能性，然后你可以定义一个阈值，就是说分数大于多少，就认为他是什么，在计算机视觉中，比如多分类中，一个东西会给出他可能是各种物体的分数，然后通过设置知道他最可能是什么，那他就是什么。至于这个分数怎么来的 ，在以后的我会更新说明。FCN，全卷积神经网络，解决分割问题。\n后面我会更新一些个人目前常用的方法的理解想法，新的论文新的方法等。大家一起交流。最后附上一张计算机看到图，我们很多时候就是解决这些数值与语义也就是理解的问题。\n图片发自简书App"}
{"content2":"【作者】：唐宇迪，计算机博士，专注于机器学习与计算机视觉领域，深度学习领域一线实战专家。在图像识别领域有着丰富经验，实现过包括人脸识别，物体识别，关键点检测等多种应用的最新算法。 参与多个国家级计算机视觉项目，多年数据领域培训经验，丰富的教学讲解经验，出品多套机器学习与深度学习系列课程，课程生动形象，风格通俗易懂。\n【导读】：本篇文章旨在帮助大家建立一份人工智能的学习计划以及我的一些个人建议，希望大家在AI之路都能早日成为大神！本篇主要内容如下：\n人工智能现在被吹的这么火（实际上也蛮厉害的），越来越多的小伙要加入到这个大家庭中来啦，那么最大的问题也就随之而来了，如何学习人工智能呢？万事开头难，如何走第一步十分关键，学习的成本现在来说还是蛮高的，我们不可能一味广泛的学习而不去赚钱嘛！本文咱们就来说说当下最合适的学习规划！\n大家的问题是不是好多呀？\n（1）：语言怎么选？\n（2）：该从哪里开始？学什么？怎么学？\n（3）：算法就要涉及到数学啦，怎么办呀！\n（4）：学了之后怎么用？案例怎么做？\n我们先从语言开始，当然首选Python啦！\n语言的选择肯定是Python无疑了，为什么？人生苦短。。。这句我就不说了，最主要的原因在于大家都在用，公司里你的同事和老大都用Python玩数据建模型，你难道还敢不用吗！（说白了，我一天能干完的活我要花两天吗？当然不需要的！）\n我是个小白呀，并不是程序员，怎么办呀，这些安装配置啥的好麻烦啊！没关系！我们有大礼包（全家桶），一站式帮你解决安装问题，下一步，下一步，选路径，OK啦！推荐大家使用Anaconda去安装（直接百度它就得了）。\n学习是一件苦事，但是也得按照合适的方法，这些都是我的个人建议，大家可以参考，我觉得语言知识一门工具，边用边学是最好的方式，千万不要花几个月先学个Python再去用，这样等你用的时候也忘的差不多了！\n人工智能听着这么牛的一个词，那到底该怎么学呀？这个圈子太大了，但是基础是不会变的就是我们的机器学习，它是咱们后续学习的保障也是最核心的内容了！人工智能的大家庭中有很多比较高大上的词，这些虽然很牛，但是核心都离不开机器学习的！\n机器学习能做的就太多了，数据处理分析，图像识别，文本挖掘，自然语言处理，语音识别等等。各大公司也是越来越注重这方面啦，都在比技术！应用面还在慢慢拓展，越来越多的公司开始重视机器学习的作用啦！\n机器学习处理任务的流程说起来还是比较简单的（做起来你就知道了！），让机器做事情你得有数据（非常重要）才行，选择一个合适的机器学习算法，让它去学吧，学完之后我们评估搞定了就开始用吧！\n机器学习我该怎么学呀？我觉得算法与应用都是很重要的，很多人都忽略了算法的推导，这对你之后的应用肯定是不利的，因为我们要做事情不能盲目去做，需要知道为什么要这么做！我最常说的一句话就是哪里不会点哪里（其实是广告看多了），查找资料的能力也很重要，遇到问题了还是要及时解决！\n关于数学，大家意见可能会不一样，我觉得如果有时间，还是都学学吧，技多不压身，帮助是大大的！\n深度学习现在太火了，那它是什么呢？说白了就是机器学习的一个分支，建议大家还是先从基本的机器学习算法开始，逐步过度到深度学习（很难一口吃成个胖子）。\n学习的路径和很多种，只要你愿意花时间任何渠道都是可以的，但是一些好习惯也是需要的，自己懂才是真的懂，光看别人的效果未必会好！\n案例资源怎么找呢？Github上满满都是，Kaggle竞赛提供了完美的环境，这些都是我们最常逛的地方啦！如果还能有几个伙伴一起学，那岂不是美滋滋！入学指南就给大家推荐到这里啦，作为参考快制定你的学习规划吧！\n另外，小编给大家推荐一些系统性人工智能学习的相关课程，现在购买最划算，有双十一优惠哟：\n推荐在线直播课\n《python数据分析与机器学习实战》\n课程介绍：\n课程风格通俗易懂，真实案例实战。精心挑选真实的数据集为案例，通过python数据科学库numpy,pandas,matplot结合机器学习库scikit-learn完成一些列的机器学习案例。课程以实战为基础，所有课时都结合代码演示如何使用这些python库来完成一个真实的数据案例。算法与项目相结合，选择经典kaggle项目，从数据预处理开始一步步代码实战带大家快速入门机器学习。\n课程特色：专属答疑+课件资料提供+视频无限时回放+VIP交流群\n开课时间：随到随学，自由支配\n报名链接：http://edu.csdn.net/course/detail/3904?utm_source=blog11\n《深度学习入门》\n课程介绍：\n深度学习入门视频课程从最基本的神经网络开始讲起，将复杂的神经网络分成几个小模块，先对必备的知识点的细节进行详细讲解再拓展到整个神经网络，从神经网络的架构，细节进行全面分析，并使用python代码完成的神经网络，从效果上感受神经网络的强大。熟悉神经网络后再进军卷积神经网络与递归神经网络，详解CNN与RNN的原理与细节。对经典网络模型结构详细分析讲解，选择经典论文剖析。带大家快速上手深度学习！\n课程特色：专属答疑+课件资料提供+视频无限时回放+VIP交流群\n开课时间：随到随学，自由支配\n报名链接：http://edu.csdn.net/course/detail/3921?utm_source=blog11"}
{"content2":"计算机视觉引论\n什么是计算机视觉； 构建第一个视觉程序； 视觉系统构成； 让程序做点事情； 课程体系结构； 照明模型； 颜色模型； 图像的采集与传输； 图像/视频的压缩与显示；\n视觉处理与分析\n图像滤波及去噪； 图像边缘检测； 直方图与图像分割； 图像特征描述； 再论图像分割； 综合示例； 直线检测； HARRIS角点检测； SIFT特征提取； ORB特征检测； 特征检测综合示例； 背景建模； 光流估计； 综合示例； 视觉编程工具；\n机器学习入门\n线性回归简介； 回归中的损失函数； 损失函数的概率解释； 过拟合； Scikit-Learn中带正则的线性回归模型； 正则的概率解释； 线性回归模型解析求解； 线性回归模型梯度下降法求解； 线性回归模型坐标轴下降求解； 回归模型性能评价指标； 交叉验证与模型评估； 线性回归案例分析： Boston房价预测； 特征工程：共享单车骑行量预测； Logistic回归简介； Logistic损失函数； 正则项； 牛顿法； Logistic回归的优化求解； 多类分类任务； 类别样本不均衡数据； 分类模型评价指标； Scikit-Learn中的Logistic回归； Logistic回归案例分析：Otto商品分类； 特征工程：糖尿病发病预测；\n机器学习基础算法\nSVM简介； 带松弛变量的SVM模型: CSVM； 对偶问题； 核方法； 支持向量回归：SVR； Scikit-Learn中的SVM； SVM案例分析：Otto商品分类； 决策树； Scikit-Learn中的决策树模型； 决策树案例分析：Otto商品分类； Bagging和随机森林； Scikit-Learn中的随机森林模型； 随机森林案例分析：Otto商品分类； Adaboost； GBM； Scikit-Learn中的GBM； XGBoost原理； XGBoost工具包使用指南； XGBoost的Scikit-Learn接口； XGBoost案例分析：Otto商品分类； LightGBM原理； LightGBM使用指南； LightGBM案例分析：Otto商品分析； PCA降维原理； Scikit-Learn中的PCA； t-SNE； Scikit-Learn中的 t-SNE； 降维案例分析：Otto商品数据降维分析； 聚类简介； KMean聚类算法； Scikit-Learn中的 KMean聚类； 聚类案例分析：Event聚类； 推荐系统简介； 基于内容的推荐； 基于用户的协同过滤； 基于物品的协同过滤； 基于矩阵分解的协同过滤； 协同过滤推荐案例分析：MovieLens电影推荐； CTR预估简介； FTRL模型； FM与FFM； GBDT； Wide and Deep Learning模型； CTR案例分析：Criteo CTR预估；\n深度学习入门\n深度学习历史与介绍； 深度学习解决的问题； 感知器介绍； 神经网络的拟合能力； 全连接神经网络介绍； 前向传播； 反向传播；\n深度学习基础算法\n整体介绍； 数据预处理； 神经网络简介； 激活函数； Batchnorm； Dropout； 网络连接方式； Ground truth； 损失函数； 学习率； 优化算法； 过拟合与欠拟合； 正则化； 参数的初始化；\n框架与环境\nTensorflow 使用tensorflow构建神经网络\n位姿估计与三维重构\n坐标系与相机模型； 相对位姿测量算法； 相机标定； 极线几何； 立体视觉与三维重构； 特征匹配；\n计算机视觉与神经网络\n卷积和池化； 卷积的反向传播； Tensorflow基础； 卷积神经网络的tensorflow实现； 经典卷积神经网络案例 Vgg/inception网络代码讲解； 基于slim的神经网模型训练； 分类定位； 检测； 检测模型的训练与使用； 分割； 人脸； 其他； 特征使用-相似图；"}
{"content2":"对应岗位为：基础研究或图像相关岗位，题目来源自同学们的汇总。。\n一部分是我自行总结的，所以也不一定正确，欢迎捉虫。\n每个问题都不停止的追问自己为什么，因为在面试中面试官肯定会不停的追问的。\n–2017.9.7\n之所以现在才发，是因为之前曾经有面试官照着我这篇东西问我（因为写了博客地址），而现在，完全没在怕的~\n提供的回答仅供参考，不一定对。存在一些没有提供参考回答的，纯粹因为我懒了 。。\n以及没有概括到的阿里、滴滴、华为啥的我没面试的岗位就写的不细，不过根据打听的情况，都是差不多的。\n当然了，这个领域日新月异的，加上我比较关注生成式任务，肯定会有其他概括不到的地方，见谅见谅。\n找工作运气也很重要，不要因为一时打击就灰心哦。\n–2018.1.30\n理论部分\n深度学习\n（通甲优博实习面试）视觉计算任务有哪些，你怎么分类\n我把任务分为像素级别、目标级别、理解级别。\n像素级别的任务一般是传统的图像处理任务，他们不需要用到图像的语义信息，或者最多用到底层特征（比如图像的边缘、纹理），这些任务有图像增强、传统的图像复原（如去噪、去模糊）、传统的图像分割（比如基于种子生长的方法）、图像加密等。\n目标级别的任务需要用到语义信息，所以提取的特征是高层特征，CNN作为优良的特征提取器在这个级别的任务上能够大展拳脚，比如目标定位、识别、检测，以及用到语义特征的分割和大量的图像生成。\n理解级别的任务不仅描述图象中的目标，还要解释他们之间的联系，比如一些“看图说话“的图像翻译任务。\nCNN的特点以及优势\nCNN使用范围是具有局部空间相关性的数据，比如图像，自然语言，语音\n局部连接：可以提取局部特征。\n权值共享：减少参数数量，因此降低训练难度（空间、时间消耗都少了）。\n可以完全共享，也可以局部共享（比如对人脸，眼睛鼻子嘴由于位置和样式相对固定，可以用和脸部不一样的卷积核）\n降维：通过池化或卷积stride实现。\n多层次结构：将低层次的局部特征组合成为较高层次的特征。不同层级的特征可以对应不同任务。\n（17网易校招笔试）推导backward\n这些层如何backword计算：\nconv：\npooling：\ndeconv：\n（17yy校招面试）解释deconv的作用：\n（美图面试）解释BN（写出公式）以及实现机制：\n（美图面试）解释dropout以及实现机制：\n（美图面试）深度学习中有什么加快收敛/降低训练难度的方法：\n瓶颈结构\n残差\n学习率、步长、动量\n优化方法\n预训练\n（美图面试，yy面试）什么造成过拟合，如何防止过拟合：\ndata agumentation\nearly stop\n参数规则化\n用更简单模型\ndropout\n加噪声\n预训练网络freeze某几层\n（yy面试）规则化项有什么，各有什么样的效果，为什么起作用\n（腾讯笔试）为什么梯度会消失和爆炸：\n深度网络激活元的作用、分类和各自使用范围/优劣\n（腾讯笔试）正则化方法以及特点：\n损失度量：\n（腾讯面试，yy面试）解释softmax、logit regression、交叉熵（要回推导）：\n有什么优化方法：\n（阿里面试）解释alpha狗：\n解释resnet、优缺点以及适用范围：\n解释inception net、优缺点以及适用范围：\n解释RNN：\nGAN的公式以及发展历程：\n会写公式\n知道变体\n优缺点\n（2017网易校招笔试 ）densenet结构优缺点以及应用场景\n（2017网易校招笔试 ）dilated conv优缺点以及应用场景\n（2017网易校招笔试 ）moblenet、shufflenet的结构\n机器学习\n（腾讯面试）有什么降维方法：\n有什么分类算法：\n偏差和方差：\n判别模型和生成模型：\n（腾讯面试）设计一个企鹅音乐的推荐系统：\n（滴滴笔试）增强学习的相关内容：\n（2017腾讯实习笔试）\n概率论（几个重点分布、切比雪夫不等式、t检验）\n线性代数（特征值计算、行列式计算）\n实践部分\n你使用什么编程框架，有什么特点：\n使用该框架搭建一个网络并训练的具体流程有什么：\n如何解决梯度消失：\n如何解决梯度爆炸：\n如何判断是否收敛：\n如何选择优化方法：\n实现卷积层的backward编程：\n（17yy面试）用c++/python实现读取文本文件（txt）行数的功能\n（17yy面试）python中有什么数据结构，有什么不同\nlist，tuple，dict，set\n（17yy面试）python中range和xrange有什么不同\n（17yy面试）python中如何重写一个len函数，解释__call（）\n12.\n课题部分\n度量\n重建任务的度量有哪些，给出解释/公式：\n识别任务的度量有哪些：\n传统图像处理\n有什么图像的锐化方法：\n全局和局部特征提取算法分别有：\n全局和局部特征提取算法有啥不同：\n解释HOG：\n解释sift：\n解释\n风格转换\n介绍该领域\n图像生成\n介绍该领域\n解释重建任务中的常用技巧：\n图像复原\n介绍该领域\n图像分割\n介绍该领域\n目标检测\n介绍该领域\nREFERENCE:\n知乎专栏——深度学习岗位面试问题整理笔记"}
{"content2":"编者按：2017年是不平凡的一年（当然，事实上，每一年都是），迄今为止，新增了哪些对机器学习和人工智能学习者有帮助的福利资源呢？我们来盘点一下。\n课程视频：\n1）斯坦福开放CS231n Spring 2017全部课程视频\n关键词：计算机视觉   深度学习\n传送门：http://www.aqinet.cn/thread-576-1-1.html\n2）李飞飞女神对深度学习与计算机视觉的讲解：\n关键词：李飞飞  计算机视觉   深度学习\n传送门：http://www.aqinet.cn/thread-569-1-1.html  （提供百度网盘下载）\n3) 男神Andrew Ng在离开百度以后，正式发布深度学习课程项目Deeplearning.ai\n关键词：吴恩达  andrew  coursera\n传送门：http://www.aqinet.cn/thread-561-1-1.html\n4）宝岛台湾的李宏毅又给深度学习初学者送来大礼，这次，讲的是GAN\n传送门：2017年5月份-李宏毅-最新GAN中文视频教程分享   （提供百度网盘下载）\n5）CS 294: Deep Reinforcement Learning, Spring 2017授课视频\n讲师阵容空前豪华，网红Andrej Karpathy领衔。\n传送门：http://www.aqinet.cn/thread-327-1-1.html    （提供百度网盘下载）\n6）国际大腕MIT给自动驾驶界又添了一把火，发布课程《Deep Learning for Self-Driving Cars》\n关键词：MIT——清华人梦中的学府\n传送门：http://www.aqinet.cn/thread-139-1-1.html    （提供百度网盘下载）\n7)  NLP界新增福利，斯坦福大学放出cs224n课程\n官网：http://web.stanford.edu/class/cs224n/\n开放数据：\n1)百度开放中文问答数据集WebQA\n开源代码：\n1）Facebook开源问答系统DrQA：基于单一信源回答开放域提问\n2）腾讯优图实验室开源项目，手机能用的神经网络\n3) 百度开源无人驾驶核心代码 阿波罗   https://github.com/ApolloAuto/apollo"}
{"content2":"目前国外计算机界评价学术水平主要看在顶级学术会议上发表的论文。特别是在机器学习、计算机视觉和人工智能领域，顶级会议才是王道。\n计算机视觉方面的三大顶级国际会议：ICCV，CVPR，ECCV\nICCV的全称是International Comference on Computer Vision。\nICCV两年一次，与ECCV正好错开，是公认的三个会议中级别最高的。\n它的举办地方会在世界各地选。\nICCV上的文章看起来一般都比较好懂。\nCVPR的全称是International Conference on Computer Vision and Pattern Recogintion。\n一年一次，举办地在美国。\n这个会上除了视觉的文章，还有不少模式识别的文章，当然两方面的结合也是重点。\nECCV的全称是Europeon Conference on Computer Vision，是欧洲的会议。\n虽然名字不是International，但是会议的级别不比前面两个差多少。\n欧洲人一般比较看中理论，但是从最近一次会议来看，似乎大家也开始注重应用了。\n总结：\n以上三个会议是做计算机视觉人必须关注的会议，建议每一期的oral都要精读，poster挑自己相关的仔细看看。\n如果有好的进一步的想法，可以马上发表，因为他们已经是最新的了，对他们的改进通常也是最新的。\n同时如果你做了类似的工作，却没有引用这些会议的文章，很有可能会被人指出综述部分的问题，因为评审的人一般都是牛人，对这三个会议也会很关注的。\nICCV/CVPR/ECCV三个顶级会议, 都是一流会议, 没有必要分个高下."}
{"content2":"1.计算机视觉\n是指计算机从图像中识别出物体、场景和活动的能力。计算机视觉技术运用由图像处理操作及其他技术所组成的序列来将图像分析任务分解为便于管理的小块任务。比如，一些技术能够从图像中检测到物体的边缘及纹理。分类技术可被用作确定识别到的特征是否能够代表系统已知的一类物体。\n计算机视觉有着广泛应用。其中包括，医疗成像分析被用来提高疾病的预测、诊断和治疗；人脸识别被Facebook用来自动识别照片里的人物；在安防及监控领域被用来指认嫌疑人；在购物方面，消费者现在可以用智能手机拍摄下产品以获得更多购买选择。\n机器视觉作为一个相关学科，泛指在工业自动化领域的视觉应用。在这些应用里，计算机在高度受限的工厂环境里识别诸如生产零件一类的物体，因此相对于寻求在非受限环境里操作的计算机视觉来说目标更为简单。计算机视觉是一个正在进行中的研究，而机器视觉则是“已经解决的问题”，是系统工程方面的课题而非研究层面的课题。因为应用范围的持续扩大，计算机视觉领域的初创公司自2011年起已经吸引了数亿美元的风投资本。\n2.机器学习\n指的是计算机系统无需遵照显式的程序指令而只是依靠暴露在数据中来提升自身性能的能力。其核心在于，机器学习是从数据中自动发现模式，模式一旦被发现便可用于做预测。比如，给予机器学习系统一个关于交易时间、商家、地点、价格及交易是否正当等信用卡交易信息的数据库，系统就会学习到可用来预测信用卡欺诈的模式。处理的交易数据越多，预测就会越好。\n机器学习的应用范围非常广泛，针对那些产生庞大数据的活动，它几乎拥有改进一切性能的潜力。除了欺诈甄别之外，这些活动还包括销售预测、库存管理、石油和天然气勘探、以及公共卫生。机器学习技术在其他的认知技术领域也扮演着重要角色，比如计算机视觉，它能在海量图像中通过不断训练和改进视觉模型来提高其识别对象的能力。现如今，机器学习已经成为认知技术中最炙手可热的研究领域之一，在2011-2014年中这段时间内就已吸引了近十亿美元的风险投资。谷歌也在2014年斥资4亿美金收购Deepmind这家研究机器学习技术的公司。\n3.自然语言处理\n是指计算机拥有的人类般文本处理的能力，比如，从文本中提取意义，甚至从那些可读的、风格自然、语法正确的文本中自主解读出含义。一个自然语言处理系统并不了解人类处理文本的方式，但是它却可以用非常复杂与成熟的手段巧妙处理文本，例如自动识别一份文档中所有被提及的人与地点；识别文档的核心议题；或者在一堆仅人类可读的合同中，将各种条款与条件提取出来并制作成表。以上这些任务通过传统的文本处理软件根本不可能完成，后者仅能针对简单的文本匹配与模式进行操作。请思考一个老生常谈的例子，它可以体现自然语言处理面临的一个挑战。在句子“光阴似箭（Timeflieslikeanarrow）”中每一个单词的意义看起来都很清晰，直到系统遇到这样的句子“果蝇喜欢香蕉（Fruitflieslikeabanana）”，用“水果（fruit）”替代了“时间（time）”，并用“香蕉（banana）”替代“箭（arrow）”，就改变了“飞逝／飞着的（like）”与“像／喜欢（like）”这两个单词的意思。\n自然语言处理，像计算机视觉技术一样，将各种有助于实现目标的多种技术进行了融合。建立语言模型来预测语言表达的概率分布，举例来说，就是某一串给定字符或单词表达某一特定语义的最大可能性。选定的特征可以和文中的某些元素结合来识别一段文字，通过识别这些元素可以把某类文字同其他文字区别开来，比如垃圾邮件同正常邮件。以机器学习为驱动的分类方法将成为筛选的标准，用来决定一封邮件是否属于垃圾邮件。\n因为语境对于理解“timeflies（时光飞逝）”和“fruitflies（果蝇）”的区别是如此重要，所以自然语言处理技术的实际应用领域相对较窄，这些领域包括分析顾客对某项特定产品和服务的反馈、自动发现民事诉讼或政府调查中的某些含义、以及自动书写诸如企业营收和体育运动的公式化范文等。\n4.机器人技术\n将机器视觉、自动规划等认知技术整合至极小却高性能的传感器、致动器、以及设计巧妙的硬件中，这就催生了新一代的机器人，它有能力与人类一起工作，能在各种未知环境中灵活处理不同的任务。例如无人机，还有可以在车间为人类分担工作的“cobots”，还包括那些从玩具到家务助手的消费类产品。\n5.语音识别技术\n主要是关注自动且准确的转录人类的语音。该技术必须面对一些与自然语言处理类似的问题，在不同口音的处理、背景噪音、区分同音异形异义词(“buy”和“by”听起来是一样的)方面存在一些困难，同时还需要具有跟上正常语速的工作速度。语音识别系统使用一些与自然语言处理系统相同的技术，再辅以其他技术，比如描述声音和其出现在特定序列和语言中概率的声学模型等。语音识别的主要应用包括医疗听写、语音书写、电脑系统声控、电话客服等。比如Domino’sPizza最近推出了一个允许用户通过语音下单的移动APP。\n上面提到的认知技术进步飞快并吸引了大量投资，其他相对成熟的认知技术仍然是企业软件系统的重要组成部分。这些日渐成熟的认知技术包括决策最优化——自动完成对复杂决策或者在资源有限的前提下做出最佳权衡；规划和调度——使设计一系列行动流程来满足目标和观察约束；规则导向系统——为专家系统提供基础的技术，使用知识和规则的数据库来自动完成从信息中进行推论的处理过程。\n人工智能、大数据、云计算和物联网的未来发展值得重视，均为前沿产业，多智时代专注于人工智能和大数据的入门和科谱，在此为你推荐几篇优质好文：\n未来人工智能技术，主要包含哪几种？\nhttp://www.duozhishidai.com/article-4938-1.html\n一文掌握人工智能各大分支技术，最全技术图谱！\nhttp://www.duozhishidai.com/article-2290-1.html\n人工智能来势凶猛，人工智能最热门的技术趋势是什么？\nhttp://www.duozhishidai.com/article-923-1.html\n多智时代-\n人工智能\n和\n大数据\n学习入门网站|人工智能、大数据、\n物联网\n、\n云计算\n的学习交流网站"}
{"content2":"计算机视觉是一门研究如何使机器“看”的科学。\n更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给一起检测的图像\n作为一个科学学科，计算机视觉研究相关的理论和技术，视图建立能够从图像或者多维数据中获取“信息”的人工智能系统。\n目前，非常火的VR、AR，3D处理等方向，都是计算机视觉的一部分。\n计算机视觉的应用\n无人驾驶\n无人安防\n人脸识别\n车辆车牌识别\n以图搜图\nVR/AR\n3D重构\n医学图像分析\n无人机\n其他\n了解了计算机视觉是什么之后，给大家列了一下当前计算机视觉领域的一些应用，几乎可以说是无处不在，而且当前最火的所有创业的方向都涵盖在里面了。其中包括我们经常提到的无人驾驶、无人安防、人脸识别。人脸识别相对来说已经是一个最成熟的应用领域了，然后还有文字识别、车辆车牌识别，还有以图搜图、VR/AR，还包括3D重构，以及当下很有前景的领域–医学图像分析。\n人工智能、大数据、云计算和物联网的未来发展值得重视，均为前沿产业，多智时代专注于人工智能和大数据的入门和科谱，在此为你推荐几篇优质好文：\n深度学习与计算机视觉的具体介绍\nhttp://www.duozhishidai.com/article-15924-1.html\n人工智能与计算机视觉\nhttp://www.duozhishidai.com/article-15129-1.html\n计算机视觉影响人工智能的发展方式，主要有哪五种？\nhttp://www.duozhishidai.com/article-2903-1.html\n多智时代-\n人工智能\n和\n大数据\n学习入门网站|人工智能、大数据、\n物联网\n、\n云计算\n的学习交流网站"}
{"content2":"一文看尽2018全年计算机视觉大突破\n摘要：计算机视觉领域同样精彩纷呈，与四年前相比GAN生成的假脸逼真到让人不敢相信；新工具、新框架的出现，也让这个领域的明天特别让人期待……\n近日，Analytics Vidhya发布了一份2018人工智能技术总结与2019趋势预测报告，原文作者PRANAV DAR。这份报告总结和梳理了全年主要AI技术领域的重大进展，同时也给出了相关的资源地址，以便大家更好的使用、查询。\n重点为大家介绍这份报告中的两个部分：计算机视觉工具和库。\n下面我们就逐一来盘点和展望。\n计算机视觉今年，无论是图像还是视频方向都有大量新研究问世，有三大研究曾在CV圈掀起了集体波澜。\nBigGAN\n今年9月，当搭载BigGAN的双盲评审中的ICLR 2019论文现身，行家们就沸腾了：简直看不出这是GAN自己生成的。\n在计算机图像研究史上，BigGAN的效果比前人进步了一大截。比如在ImageNet上进行128×128分辨率的训练后，它的Inception Score（IS）得分166.3，是之前最佳得分52.52分3倍。\n除了搞定128×128小图之外，BigGAN还能直接在256×256、512×512的ImageNet数据上训练，生成更让人信服的样本。\n在论文中研究人员揭秘，BigGAN的惊人效果背后，真的付出了金钱的代价，最多要用512个TPU训练，费用可达11万美元，合人民币76万元。\n不止是模型参数多，训练规模也是有GAN以来最大的。它的参数是前人的2-4倍，批次大小是前人的8倍。\n研究论文：https://openreview.net/pdf?id=B1xsqj09Fm\nFast.ai 18分钟训练整个ImageNet\n在完整的ImageNet上训练一个模型需要多久？各大公司不断下血本刷新着记录。\n不过，也有不那么烧计算资源的平民版。\n今年8月，在线深度学习课程Fast.ai的创始人Jeremy Howard和自己的学生，用租来的亚马逊AWS的云计算资源，18分钟在ImageNet上将图像分类模型训练到了93%的准确率。\n前前后后，Fast.ai团队只用了16个AWS云实例，每个实例搭载8块英伟达V100 GPU，结果比Google用TPU Pod在斯坦福DAWNBench测试上达到的速度还要快40%。\n这样拔群的成绩，成本价只需要40美元，Fast.ai在博客中将其称作人人可实现。Fast.ai博客介绍：https://www.fast.ai/2018/08/10/fastai-diu-imagenet/\nvid2vid技术\n今年8月，英伟达和MIT的研究团队高出一个超逼真高清视频生成AI。\n只要一幅动态的语义地图，就可获得和真实世界几乎一模一样的视频。换句话说，只要把你心中的场景勾勒出来，无需实拍，电影级的视频就可以自动P出来，除了街景，人脸也可生成。\n这背后的vid2vid技术，是一种在生成对抗性学习框架下的新方法：精心设计的生成器和鉴别器架构，再加上时空对抗目标。\n这种方法可以在分割蒙版、素描草图、人体姿势等多种输入格式上，实现高分辨率、逼真、时间相干的视频效果。\n研究论文：https://tcwang0509.github.io/vid2vid/paper_vid2vid.pdf\nGitHub地址：https://github.com/NVIDIA/vid2vid\n2019趋势展望\nAnalytics Vidhya预计，明年在计算机视觉领域，对现有方法的改进和增强的研究可能多于创造新方法。\n在美国，政府对无人机的限令可能会稍微“松绑”，开放程度可能增加。而今年大火的自监督学习明年可能会应用到更多研究中。\nAnalytics Vidhya对视觉领域也有一些期待，目前来看，在CVPR和ICML等国际顶会上公布最新研究成果，在工业界的应用情况还不乐观。他希望在2019年，能看到更多的研究在实际场景中落地。\nAnalytics Vidhya预计，视觉问答（Visual Question Answering，VQA）技术和视觉对话系统可能会在各种实际应用中首次亮相。\n工具和框架\n哪种工具最好？哪个框架代表了未来？这都是一个个能永远争论下去的话题。\n没有异议的是，不管争辩的结果是什么，我们都需要掌握和了解最新的工具，否则就有可能被行业所抛弃。\n今年，机器学习领域的工具和框架仍在快速的发展，下面就是这方面的总结和展望。\nPyTorch 1.0\n根据10月GitHub发布的2018年度报告，PyTorch在增长最快的开源项目排行上，名列第二。也是唯一入围的深度学习框架。\n作为谷歌TensorFlow最大的“劲敌”，PyTorch其实是一个新兵，2017年1月19日才正式发布。2018年5月，PyTorch和Caffe2整合，成为新一代PyTorch 1.0，竞争力更进一步。\n相较而言，PyTorch速度快而且非常灵活，在GitHub上有越来越多的开码都采用了PyTorch框架。可以预见，明年PyTorch会更加普及。\n至于PyTorch和TensorFlow怎么选择？在我们之前发过的一篇报道里，不少大佬站PyTorch。\n实际上，两个框架越来越像。前Google Brain深度学习研究员，Denny Britz认为，大多数情况下，选择哪一个深度学习框架，其实影响没那么大。\nPyTorch官网：https://pytorch.org/\nAutoML\n很多人将AutoML称为深度学习的新方式，认为它改变了整个系统。有了AutoML，我们就不再需要设计复杂的深度学习网络。\n今年1月17日，谷歌推出Cloud AutoML服务，把自家的AutoML技术通过云平台对外发布，即便你不懂机器学习，也能训练出一个定制化的机器学习模型。\n不过AutoML并不是谷歌的专利。过去几年，很多公司都在涉足这个领域，比方国外有RapidMiner、KNIME、DataRobot和H2O.ai等等。\n除了这些公司的产品，还有一个开源库要介绍给大家：\nAuto Keras！\n这是一个用于执行AutoML任务的开源库，意在让更多人即便没有人工智能的专家背景，也能搞定机器学习这件事。\n这个库的作者是美国德州农工大学（Texas A&M University）助理教授胡侠和他的两名博士生：金海峰、Qingquan Song。Auto Keras直击谷歌AutoML的三大缺陷：\n第一，还得付钱。\n第二，因为在云上，还得配置Docker容器和Kubernetes。\n第三，服务商(Google)保证不了你数据安全和隐私。\n官网：https://autokeras.com/\nGitHub：https://github.com/jhfjhfj1/autokeras\nTensorFlow.js\n今年3月底的TensorFlow开发者会峰会2018上，TensorFlow.js正式发布。\n这是一个面向JavaScript开发者的机器学习框架，可以完全在浏览器中定义和训练模型，也能导入离线训练的TensorFlow和Keras模型进行预测，还对WebGL实现无缝支持。\n在浏览器中使用TensorFlow.js可以扩展更多的应用场景，包括展开交互式的机器学习、所有数据都保存在客户端的情况等。\n实际上，这个新发布的TensorFlow.js，就是基于之前的deeplearn.js，只不过被整合进TensorFlow之中。\n谷歌还给了几个TensorFlow.js的应用案例。比如借用你的摄像头，来玩经典游戏：吃豆人（Pac-Man）。\n官网：https://js.tensorflow.org/\n2019趋势展望\n在工具这个主题中，最受关注的就是AutoML。因为这是一个真正会改变游戏规则的核心技术。在此，引用H2O.ai的大神Marios Michailidis（KazAnova）对明年AutoML领域的展望。\n以智能可视化、提供洞见等方式，帮助描述和理解数据为数据集\n发现、构建、提取更好的特征\n快速构建更强大、更智能的预测模型\n通过机器学习可解释性，弥补黑盒建模带来的差距\n推动这些模型的产生\n转载自：极市平台（ID：extrememart）"}
{"content2":"作者 | 李新阳\n学校 | 厦门大学本科在读\n方向 | 计算机视觉\n预备知识：需要一定的矩阵以及微积分知识\n一、系列描述\n本次从零教程我本人也是边学边写，有混淆或错误的地方请您通过各种方式尽情指教，学习的思路主要参考李菲菲教授的公开课以及自己的一些思路整理，希望我能描述清楚。对于算法我都要求自己一定贴出自己写的源代码，数据集会采用公开但不一定完全的权威数据集，读者可以酌情尝试，我尽可能写出结构化且具有可视化功能的TensorFlow源码，也请大家多加指点。还有一点是，本系列的计算机视觉会较多地以神经网络和深度学习为架构的模型进行描述，关于传统的计算机视觉，我将会在自己有所了解后进行一些说明。\n二、开始计算机视觉的起点：MNIST数据集+Softmax分类器\n1. 前戏开始\nMNIST应该是最简单，也是最好的起始数据集，使用极为简单的分类器就可以达到不错的泛化准确率（何为泛化？即我们的模型对于没有进入训练集的判断能力，反应了模型是否正确或是鲁棒），实际上，基本上由图像各密集像素区的简单分布就可以达到分类手写数字识别的目的（特别是限制了手写范围，数字一般处于居中的位置的时候）。\n2. 直接上代码吧\n下面是Softmax函数进行MNIST分类的代码：\n# coding=utf-8 from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) # 读取图片数据集 sess = tf.InteractiveSession() # 创建session # 输入是序列化后的图片向量，注意只有一个通道，对应输入的28*28向量 xs = tf.placeholder(tf.float32, [None, 28 * 28 * 1]) # 类别是0-9总共10个类别，对应输出分类结果 ys = tf.placeholder(tf.float32, [None, 10]) # 分别对应权值矩阵和偏置矩阵 W = tf.Variable(tf.zeros([784,10])) b = tf.Variable(tf.zeros([10])) # 输出y y = tf.nn.softmax(tf.matmul(xs, W) + b) # 定义交叉熵为loss函数 cross_entropy = -tf.reduce_sum(ys * tf.log(y)) # 设置梯度下降，步长为0.01，目标是最小化交叉熵 train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) # 给出正确率的计算公式 correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(ys, 1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # TensorFlow变量初始化 tf.global_variables_initializer().run() # 循环训练步骤 for i in range(2000): # 随机取一部分数据集作为训练集 batch = mnist.train.next_batch(100) train_step.run(feed_dict={xs: batch[0], ys: batch[1]}) if i % 10 == 0: train_accuracy = accuracy.eval(feed_dict={xs: batch[0], ys: batch[1]}) print(\"step %d, training accuracy %g\" % (i, train_accuracy)) # 输出最终的正确率 print(\"test accuracy %g\" % accuracy.eval(feed_dict={xs: mnist.test.images, ys: mnist.test.labels}))\n来自本人Github\n！推荐大家在运行和阅读了程序后再进行下面的阅读\n虽然这是一个极为简单的分类器，但已经达到了90%左右的准确率，其中已经有许多神经网络中经常使用的思想在里面了，大家在阅读代码之后一定有许多疑惑，我先解释一些我觉得比较重要的概念性问题。\n3. 从头开始，让我解释一下\n1）. 关于Softmax\n我们先很简单地描述一下Softmax函数，它将一组向量变为了另一组向量，且另一组向量具有某种概率以及统计上的含义，更类似于对于结果的“标准化”，但以概率分布的形式给出，我给出的公式是以向量和函数的形式写出。\nSoftmax(x→)=exp(x→)sum(exp(x→))\nS\no\nf\nt\nm\na\nx\n(\nx\n→\n)\n=\ne\nx\np\n(\nx\n→\n)\ns\nu\nm\n(\ne\nx\np\n(\nx\n→\n)\n)\nSoftmax(\\overrightarrow x) =\\frac {exp( \\overrightarrow x)}{sum(exp( \\overrightarrow x))}\n其中需要说明的是：exp()函数返回的是与输入量x行列一致的，sum()函数是将矩阵中的每一个元素加起来的总和，实际上，更专业的写法为：\nSi=exi∑j(exj)\nS\ni\n=\ne\nx\ni\n∑\nj\n(\ne\nx\nj\n)\nS_i=\\frac {e^{x_i}}{\\sum_j(e^{x_j})}\n含义与上面实际上是一致的，一个对向量整体进行运算，一个对元素进行运算。\n2）. 关于交叉熵\n一句话描述交叉熵：就是一个值，用来描述最终分类结果正确的可能性\n公式如下：\nL=−∑jy′j⋅log(yj)\nL\n=\n−\n∑\nj\ny\nj\n′\n⋅\nl\no\ng\n(\ny\nj\n)\nL = -\\sum_j y_{j}' \\cdot log(y_j)\n其中，\ny′j\ny\nj\n′\ny'_j表示该图片的第j个标签是否为正确的（实际上只有一个为1，其他均为0），\nyj\ny\nj\ny_j表示我们预测的第j个为正确的输出值，也就是经过Softmax后的概率值，实际上，这里的\nyj\ny\nj\ny_j，就是我们前面得到的\nSi\nS\ni\nS_i。\n至于为什么要采用交叉熵来作为损失值，我们先介绍一下梯度下降和链式法则。\n3）. 关于梯度下降和链式法则\n关于梯度下降，我觉得各位应该有些许了解，这里用的最简单的梯度下降，直接对于原本的一个参数\nw\nw\nw，增或减一个步长0.05乘以他的下降率\n∂L∂w\n∂\nL\n∂\nw\n\\frac{\\partial L}{\\partial w}，对于每一个\nw\nw\nw，我们很难通过直接的算式推到来得到他的下降率，而是通过数值方法以及链式法则来进行反向传播。反向传播的概念我在这里不再赘述，实际上，梯度作为反向传播的最重要概念我想用一个更简单的办法来描述：\n我们用一段话描述整个网络的训练过程，可以说成是输入作用到输出，输出与真实值的差异作用到参数，从而一步一步使输出与真实值的差异缩小，我们以上层为网络拓扑顺序靠后的层，从上图可以看到，每一层在进行正向传播时，都需要根据下层的值和参数值得到自己的当前值（如何得到取决于该层的固有运算），在最后一层得到输出值后，由真实值和输出值得到损失值，再有损失值倒推出各层的梯度值（求下层的梯度可能会需要上层的梯度以及更下层或自身的当前值，所以说要存储当前值），根据梯度值和步长更新参数值，然后进行下一次训练。\n当然，实际上的过程涉及了大量的运算，包括链式法则以及雅可比矩阵等知识我在这里不详说，实际上，大多数已知的神经网络结构，都可以在TensorFlow上自动地进行正向传播和反向传播，之后我可能会设计一些不在库中的中间层，到时候会详细地进行讲解和推到。\n4）. 网络干了什么\n大家应该可以看出来，我们的网络实际上只有一层，那它到底干了什么？\n实际上，我们可以很简单地理解到这一层在干什么，实际上对于每个输出，比如是不是0，网络会用权值和偏执向量的一部分作用于输入向量，然后得出是0的得分，事实上，这样的一个乘法，是否可以想成是权值图直接作用于输入图呢，有趣的事情发生了，我们将权值矩阵分成10条向量，再转成28*28的灰度图，看会发生什么（下面这张图的源代码我也会传在github上，使用了前面训练网络得到的权值矩阵，所以前面的训练过程后面加了几句话，大家也可以在源代码里看到）：\n来自本人Github\n其中，边缘的灰色部分表示权值为0，偏白的部分表示权值大于0，偏黑的部分表示权值小于0。\n我们仔细地观察0的权值图，会发现，周围一圈是权值大于0的部分，当输入图在此区域有分布的话，则它为0的几率就会增加，但注意，圆的中心有一块区域权值小于0，也就是说，当输入图在此中心区域有分布的话，则它为0的几率就会减少，这对于我们来说有很直观的理解，读者可以按照此思路，观察其他数字的权值图。（这也是少有的我们可以完全理解的网络了。）\n3. 总结一下\n本文介绍了一个最简单的网络，可以较快地训练，完成不错的准确率，虽然实际上都还不算是神经网络，但其中对于损失函数，梯度下降等概念已经形成，下一次将讲解CNN，卷积神经网络，内容会稍微复杂一点，希望大家可以充分理解这一篇的内容再看下一篇（还没有写好，我尽量在18年7月11日前写出）。"}
{"content2":"浅谈人工智能：现状、任务、构架与统一 | 正本清源\n2017-11-02 朱松纯\n（说明： 老板极力推荐我们阅读这篇综述性的文章，朱老师写的妙趣横生，几个触动点记录如下）\n1.人工智能学科，归纳为六个，当成战国七雄，把其中2雄合并成（5）：\n（1）计算机视觉（暂且把模式识别，图像处理等问题归入其中）、\n（2）自然语言理解与交流（暂且把语音识别、合成归入其中，包括对话）、\n（3）认知与推理（包含各种物理和社会常识）、\n（4）机器人学（机械、控制、设计、运动规划、任务规划等）、\n（5）博弈与伦理（多代理人agents的交互、对抗与合作，机器人与社会融合等议题）。 --最小\n（6）机器学习（各种统计的建模、分析工具和计算的方法）\n（我：研究生入学复试时，还问老师们人工智能、机器学习、数据挖掘有什么区别）\n2.人工智能的概念\n人工智能的研究，简单来说，就是要通过智能的机器，延伸和增强（augment）人类在改造自然、治理社会的各项任务中的能力和效率，最终实现一个人与机器和谐共生共存的社会。这里说的智能机器，可以是一个虚拟的或者物理的机器人。\n3.鹦鹉还是乌鸦\n乌鸦给我们的启示，至少有三点：\n其一、它是一个完全自主的智能。感知、认知、推理、学习、和执行， 它都有。\n其二、你说它有大数据学习吗？这个乌鸦有几百万人工标注好的训练数据给它学习吗？没有\n其三、乌鸦头有多大？不到人脑的1%大小。 功耗极低。\n我们要寻找“乌鸦”模式的智能，而不要“鹦鹉”模式的智能。\n4.学习的过程\n一、 外来的数据。\n外部世界通过各种感知信号，传递到人脑，塑造我们的模型。数据来源于观察（observation）和实践（experimentation）。观察的数据一般用于学习各种统计模型，这种模型就是某种时间和空间的联合分布，也就是统计的关联与相关性。实践的数据用于学习各种因果模型，将行为与结果联系在一起。因果与统计相关是不同的概念。\n二、内在的任务。\n这就是由内在的价值函数驱动的行为、以期达到某种目的。我们的价值函数是在生物进化过程中形成的。因为任务的不同，我们往往对环境中有些变量非常敏感，而对其它一些变量不关心。由此，形成不同的模型。\n机器人的脑、人脑都可以看成一个模型。任何一个模型由数据与任务来共同塑造。\n同样是在概率统计的框架下，当前的很多深度学习方法，属于一个被我称作“大数据、小任务范式（big data for small task）”。\n提倡的一个相反的思路：人工智能的发展，需要进入一个“小数据、大任务范式（small data for big tasks）”，要用大量任务、而不是大量数据来塑造智能系统和模型。我认为一个更合适的说法是“任务塑造了智能”。\n5.机器学习\n前面谈的五个领域，属于各个层面上的“问题领域”，叫Domains。我们努力把这些问题放在一个框架中来思考，寻求一个统一的表达与算法。而最后要介绍的机器学习，是研究解决“方法领域”（Methods），研究如何去拟合、获取上面的那些知识。\n当前大家做的机器学习，其实是一个很狭义的定义，不代表整个的学习过程。\n例如：定义一个损失函数loss function->你选择一个模型->你拿到大量数据并训练模型。这个过程没有因果，没有机器人行动，是纯粹的、被动的统计学习。\n其实真正的学习是一个交互的过程。\n这个学习过程是建立在认知构架之上的，我把这种广义的学习称作通讯学习Communicative Learning。\n这个通讯学习的构架里面，就包含了大量的学习模式，包括以下七种学习模式（每种学习模式其实对应与图中的某个或者几个箭头），这里面还有很多模式可以开发出来。\n（1）被动统计学习passive statistical learning：上面刚刚谈到的、当前最流行的学习模式，用大数据拟合模型。\n（2）主动学习active learning：学生可以问老师主动要数据，这个在机器学习里面也流行过。\n（3）算法教学algorithmic teaching：老师主动跟踪学生的进展和能力，然后，设计例子来帮你学。这是成本比较高的、理想的优秀教师的教学方式。\n(4) 演示学习learning from demonstration：这是机器人学科里面常用的，就是手把手叫机器人做动作。一个变种是模仿学习immitation learning。\n（5）感知因果学习perceptual causality：这是我发明的一种，就是通过观察别人行为的因果，而不需要去做实验验证，学习出来的因果模型，这在人类认知中十分普遍。\n（6）因果学习causal learning：通过动手实验， 控制其它变量， 而得到更可靠的因果模型， 科学实验往往属于这一类。\n（7）增强学习reinforcement learning：就是去学习决策函数与价值函数的一种方法。"}
{"content2":"我做计算机视觉有半年左右，也是现在现在很火的深度学习。有人说这个是“技术大爆炸”，突然冒出大批人来搞深度学习。但是我现在不想说深度学习，只想说说它的辅助工作---图片处理基础。\n我是因为读研才开始基础计算机视觉，之前什么都不懂，是真的什么都不懂。然后实验室还是新开设的这个项目，也就是说，实验室也不会有人来指导我如何做，那时只有老师说要什么东西，我就得自己各种的查找来完成，现在想想还是很苦逼。\n开始时连图片是数字组成的都不知道。所以真的是新新手啊。图片是由一个矩阵组成的，这个矩阵可以是一维，三维，四维（我所知道的）。四维图片时RGBA，即red，green，blue，阿尔法值。三维是RGB，但其实如果你用的开源框架caffe，caffe的内部用opencv处理图片，opencv读出来的三维图是BGR。四维和三维都是彩色图。一维的一般为灰度图，mode是L，但是mode是P时也是一维的，我前几天刚刚接触model为P的图片，它是一维的，但是它却可以有颜色，貌似是因为调色板什么的原因，我一直未有时间着手去搞清楚。如果只是看一个图片的属性是看不出他的mode类型的。用python的image去读一个图片输出它的返回值就可以看到一张图片的组成参数，包括它的mode。\n我用python处理图片，它的Image，skimage都可以读一张图片，不过读出来的形式不同，Image读出来的仍然是图片形式，skimage读出来的是矩阵，我的其他文章中有提到它们的不同。image读出来的图片可以转成矩阵，这时就要提到另一个python做数据处理的常用模块---numpy，numpy是一个多维数组【矩阵】。深度学习处理的其实就是图片的真正组成-----矩阵，numpy有很多的方法，所以会常常用到它，它的花式索引，广播计算等等使用时都非常方便。numpy和image之间可以互相转化。image自己本身就有很多便利的可以对图片进行转化灰度图【一维】和切割旋转等的方法，但是如果需要逐像素对图片进行处理就可以选择转成numpy后处理。\n图片的展示以及训练结果数据的展示如果可以通过图片显示会更加的明显，这时我们就需要python的另一个数据处理常用的模块---matplotlib，它有很多办法可以把你的图片或数据以你想要的方式展示出来，具体可参看官网或者我的另一篇文章有稍微讲了一些常用的办法。\n所以如果你是新手，而且是没有人带什么都不懂的新手，你用python处理图片时请参看，Image，skimage，numpy，matplotlib。"}
{"content2":"计算机视觉的信号处理层次\n低层视觉处理\n单图像：滤波/边缘检测/纹理\n多图像：几何/立体/从运动恢复仿射或透视结构  affine/perspective structure frommotion\n中层视觉处理\n聚类分割/拟合线条、曲线、轮廓 clusteringfor segmentation, fitting line…\n基于概率方法的聚类分割/拟合\n跟踪 tracking\n高层视觉处理\n匹配\n模式分类/关联模型识别 patternclassification/aspect graph recognition\n应用\n距离数据（rangedata）/图像数据检索/基于图像的绘制\n又一种说法是\n图像处理\n图像分析\n图像理解\n本质上是差不多的，三个层次分别是像素级、特征级、三维重构级（人工智能）"}
{"content2":"图像处理：用计算机来对图像进行分析，以达到所需的结果。一般指数字图像处理，指的是通过计算机对图片进行去噪声、增强、复原、分割、提取特征等的方法和技术。\n计算机视觉：计算机视觉是利用计算机和其辅助设备来模拟人的视觉功能，实现对客观世界的三维场景的感知、识别和理解。\n机器视觉：用机器代替人眼进行测量和判断。\n区别：\n图像处理侧重于“处理”图像，如增强、还原、去噪、分割等；\n机器视觉侧重工程的应用，强调实时性、高精度和高速度；场景相对简单固定，识别 的类型少(在同一个应用中)，规则且有规律，但对准确度，处理速度要求都比较高。关于速度，一般机器视觉的分辨率远高于计算机视觉，而且往往要求实时。\n计算机视觉的应用场景相对复杂，要识别的物体类型也多，形状不规则，规律性不强。有些时候甚至很难用客观量作为识别的依据，比如识别年龄，性别。所以深度学习比较 适合计算机视觉。而且光线，距离，角度等前 提条件，往往是动态的，所以对于准确度要求，一般来说要低一些 。"}
{"content2":"在开始学习python大数据之前，先要搞清楚人工智能、机器学习、深度学习、数据挖掘、数据分析都是什么意思。\n人工智能大家族包含着丰富的内容，分清楚了每一项都是做什么的，才能选对路线。\n人工智能AI\n人工智能分为强人工智能和弱人工智能。\n强人工智能是通过计算机来构造复杂的、拥有与人类智慧同样本质特性的机器，它有着我们所有的感知（甚至比人更多），我们所有的理性，可以像我们一样思考，也就是电影里面的机器人。\n弱人工智能 (ANI) 是指擅长于单个方面的人工智能。垃圾邮件的自动识别，iPhone的助手siri，Pinterest上的图像分类，Facebook的人脸识别都属于弱人工智能，也就是我们现在大多是在从事的领域。\n人工智能的研究领域在不断扩大，各个分支主要包括专家系统、机器学习、进化计算、模糊逻辑、计算机视觉、自然语言处理、推荐系统等。\n机器学习ML\n那么如何实现这种人工智能的智慧呢，这就需要机器学习了。机器学习是一种实现人工智能的方法。\n机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。类似人类在接触过很多事物、经历后获得的“经验”和“规定”一样。例如有经验的老师在教书多年以后知道如何因材施教（经验），例如我们在看到STOP以后知道这是停止的意思（规定）。\n传统的机器学习算法包括决策树、聚类、贝叶斯分类、支持向量机、EM、Adaboost等等。从学习方法上来分，机器学习算法可以分为监督学习（如分类问题）、无监督学习（如聚类问题）、半监督学习、集成学习、深度学习和强化学习。\n传统的机器学习算法虽然在指纹识别、人脸检测、机器视觉等领域的应用基本达到了商业化的要求或者特定场景的商业化水平，但每前进一步都异常艰难，直到深度学习算法的出现。\n机器学习应用十分广泛，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、语音、手写识别和机器人运用上都有应用。\n深度学习DL\n我们知道要想具有好的智慧，除了有具有大量的数据以外还要有好的经验总结方法。深度学习就是一种实现机器学习的优秀技术。深度学习本身是神经网络算法的衍生。\n深度学习本来并不是一种独立的学习方法，其本身也会用到有监督和无监督的学习方法来训练深度神经网络。但由于近几年该领域发展迅猛，一些特有的学习手段相继被提出（如残差网络），因此越来越多的人将其单独看作一种学习的方法。\n最初的深度学习是利用深度神经网络来解决特征表达的一种学习过程。深度神经网络本身并不是一个全新的概念，可大致理解为包含多个隐含层的神经网络结构。为了提高深层神经网络的训练效果，人们对神经元的连接方法和激活函数等方面做出相应的调整。其实有不少想法早年间也曾有过，但由于当时训练数据量不足、计算能力落后，因此最终的效果不尽如人意。\n深度学习摧枯拉朽般地实现了各种任务，使得似乎所有的机器辅助功能都变为可能。无人驾驶汽车，预防性医疗保健，甚至是更好的电影推荐，都近在眼前，或者即将实现。\n当前，业界有一种错误的较为普遍的意识，即“深度学习最终可能会淘汰掉其他所有机器学习算法”。这种意识的产生主要是因为，当下深度学习在计算机视觉、自然语言处理领域的应用远超过传统的机器学习方法，并且媒体对深度学习进行了大肆夸大的报道。\n深度学习，作为目前最热的机器学习方法，但并不意味着是机器学习的终点。起码目前存在以下问题：\n1. 深度学习模型需要大量的训练数据，才能展现出神奇的效果，但现实生活中往往会遇到小样本问题，此时深度学习方法无法入手，传统的机器学习方法就可以处理；\n2. 有些领域，采用传统的简单的机器学习方法，可以很好地解决了，没必要非得用复杂的深度学习方法；\n3. 深度学习的思想，来源于人脑的启发，但绝不是人脑的模拟，人脑不需要大量的数据训练支持，我们只要看过一张猫的图就认识了猫，而机器必须经过几百万张猫的图才能“认识”猫。\n数据挖掘\n数据挖掘利用各种技术与统计方法，将大量的历史数据，进行整理分析，归纳与整合，是从海量数据中“挖掘”隐藏信息，如趋势、特征及相关的一种过程。工作BI（商业智能）、数据分析、市场运营都可以做这个工作。\n之所以经常和机器学习合在一起讲是因为现在好多数据挖掘的工作是通过机器学习提供的算法工具实现的。例如广告的ctr预估，PB级别的点击日志在通过典型的机器学习流程可以得到一个预估模型，从而提高互联网广告的点击率和回报率；个性化推荐，还是通过机器学习的一些算法分析平台上的各种购买，浏览和收藏日志，得到一个推荐模型，来预测你喜欢的商品。\n我们可以把数据挖掘理解为一种类型的工作，或工作中的某种成分，机器学习是帮助完成这个工作的方法。\n统计学、数据库和人工智能共同构造了数据挖掘技术的三大支柱，许多成熟的统计方法构成了数据挖掘的核心内容。\n数据分析\n数据分析只是在已定的假设，先验约束上处理原有计算方法，统计方法，将数据转化为信息，而这些信息需要进一步的获得认知，转化为有效的预测和决策，这时就需要数据挖掘，也就是我们数据分析师系统成长之路的“更上一楼”。\n数据分析是把数据变成信息的工具，数据挖掘是把信息变成认知的工具，如果我们想要从数据中提取一定的规律（即认知）往往需要数据分析和数据挖掘结合使用。\n举个例子：你有50块钱，去买菜，经过一一问价，你知道了50块钱能买多少蔬菜，能买多少肉，能吃多少天，心里得出一组信息，这就是数据分析。根据自己的偏好，营养价值，用餐时间计划，最有性价比的组合确定了一个购买方案，这就是数据挖掘。\n中国的人工智能发展\n人工智能企业可以在应用层、技术层、基础上进行区分。\n在应用层的中国人工智能公司按照领域划分包括：\n机器人：Geek+、 Rokid、图灵机器人、优必选。\n自动驾驶：百度、天瞳威视、地平线机器人、驭势科技。\n无人机：大疆、亿航、Hover Camera、零度智控。\n语音助手：百度、出门问问。\n商业智能：永洪科技、Data KM。\n消费者服务：AiKF。\n产业应用：碳云智能、Maxent、今日头条、学霸君。\n在技术层的中国人工智能公司按照领域划分包括：\n语音识别&自然语言处理：\n思必驰、百度、科大讯飞、出门问问、捷通华生、腾讯、三角兽、云知声。\n机器学习&深度学习：深鉴科技、中科视拓。\n人工智能平台：达闼科技、第四范式。\n计算机视觉：依图科技、格灵深瞳、旷视科技、商汤科技。\n在基础层的中国人工智能公司按照领域划分包括：\n传感器：ICE DRINK、LeiShen、SLAMTEC、北醒光子。\nAI 芯片：寒武纪科技、地平线机器人。\n数据：DataDouDou、数据堂计算力：阿里巴巴、百度。"}
{"content2":"转载于 http://c.biancheng.net/view/1093.html\n计算机视觉这种技术可以将静止图像或视频数据转换为一种决策或新的表示。所有这样的转换都是为了完成某种特定的目的而进行的。\n输入数据可能包含一些场景信息，例如“相机是搭载在一辆车上的”或者“雷达发现了一米之外有一个目标”。一个新的表示，意思是将彩色图像转换为黑白图像，或者从一个图像序列中消除相机运动所产生的影响。\n人类的视觉\n因为我们是被赋予了视觉的生物，所以很容易误认为“计算机视觉也是一种很简单的任务”。计算机视觉究竟有多困难呢？\n请说说你是如何从一张图像中观察到一辆车的。你最开始的直觉可能具有很强的误导性。人类的大脑将视觉信号划分为许多通道，好让不同的信息流输入大脑。大脑已经被证明有一套注意力系统，在基于任务的方式上，通过图像的重要部分检验其他区域的估计。在视觉信息流中存在巨量的信息反馈，并且到现在我们对此过程也知之甚少。\n肌肉控制的感知器和其他所有感官都存在着广泛的相互联系，这让大脑能够利用人在世界上多年生活经验所产生的交叉联想，大脑中的反馈循环将反馈传递到每一个处理过程，包括人体的感知器官（眼睛），通过虹膜从物理上控制光线的量来调节视网膜对物体表面的感知。\n计算机的视觉\n然而在机器视觉系统中，计算机会从相机或者硬盘接收栅格状排列的数字，也就是说，最关键的是，机器视觉系统不存在一个预先建立的模式识别机制。没有自动控制焦距和光圈，也不能将多年的经验联系在一起。大部分的视觉系统都还处于一个非常朴素原始的阶段。\n图 1 展示了一辆汽车。在这张图片中，我们看到后视镜位于驾驶室旁边。但是对于计算机而言，看到的只是按照栅格状排列的数字。所有在栅格中给出的数字还有大量的噪声，所以每个数字只能给我们提供少量的信息，但是这个数字栅格就是计算机所能够“看见”的全部了。我们的任务变成将这个带有噪声的数字栅格转换为感知结果“后视镜”。\n图 2 给出了为什么计算机视觉如此困难的另一些解释。\n：对于计算机来说，汽车的后视镜就是一组栅格状排列的数字\n：视觉的不适定问题，物体的二维表示可能随着视点的不同完全改变\n一个数学物理定解问题的解如果存在，唯一并且稳定的，则说明该问题是适定的（well-posed）；如果不满足，则说明该问题是不适定的（ill-posed）。\n实际上，这一问题，正如我们之前所提出的，用“困难”已经不足以形容它了，它在很多情况下根本不可能解决。\n给定一个对于 3D 世界的二维（2D）观测，就不存在一个唯一的方式来重建三维信号。即使数据是完美的，相同的二维图像也可能表示一个无限的 3D 场景组合中的任一种情况。\n而且，前面也提到过，数据会被噪声和畸变所污染。这样的污染源于现实生活中的很多方面（天气、光线、折射率和运动），还有传感器中的电路噪声以及其他的一些电路系统影响，还有在采集之后对于图像压缩产生的影响。\n在这一系列的影响之下，我们又该如何推动事情的进展呢？\n在经典的系统设计中，额外场景信息可以帮助我们从传感器的层面改善获取信息的质量。\n场景信息可以辅助计算机视觉\n考虑这样一个例子，一个移动机器人需要在一栋建筑中找到并且拿起一个订书机。机器人就可能用到这样的事实：桌子通常放在办公室里，而订书机通常收纳在桌子里。这也同样给出了一个关于尺寸的推断：订书机的大小一定可以被桌子所收纳。\n更进一步，这还可以帮助减少在订书机不可能出现的地方错误识别订书机的概率（比如天花板或者窗口）。机器人可以安全忽略掉 200 英尺高的订书机形状的飞艇，因为飞艇没有满足被放置在木制桌面上的先验信息。\n相对的，在诸如图像检索等任务中，数据集中所有的订书机图像都是来自真实的订书机，这样不合常理的尺寸以及一些奇形怪状的造型都会在我们进行图片采集的时候隐式消除——因为摄影师只会去拍摄普通的正常尺寸的订书机。人们同样倾向于在拍摄的时候将拍摄目标放在图片的中间，并且倾向于在最能够展现目标特征的角度拍摄。因此，通常也有很多无意的附加信息在人们拍摄照片的时候无意加进去。\n场景信息同样可以（尤其是通过机器学习技术）进行建模。隐式的变量（比如尺寸、重力的方向等不容易被直接观测到的）可以从带标记的数据集中发现关系并推测出来。或者，可以尝试使用附加的传感器测量隐式变量的值，比如利用激光雷达来测量深度，从而准确得到目标的尺寸。\n使用统计的方法来对抗噪声\n计算机视觉所面临的下一个问题是噪声，我们一般使用统计的方法来对抗噪声。\n比如，我们很难通过单独的像素点和它的相邻像素点判断其是否是一个边缘点，但如果观察它在一个区域的统计规律，边缘检测就会变得更加简单了。\n一个真正的边缘应该表现为一个区域内一连串独立的点，所有点的朝向都与其最接近的点保持一致。我们也可以通过时间上的累计统计对噪声进行抑制，当然也有通过现有数据建立噪声模型来消除噪声的方法。例如，因为透镜畸变很容易建模，我们只需要学习一个简单的多项式模型来描述畸变就可以几乎完美矫正失真图像。\n基于摄像机的数据，计算机视觉准备做出的动作或决定是在特定的目的或者任务的场景环境中执行的。我们也许想要移除噪声或者修复被损坏的照片，这样安全系统就可以对试图爬上栏杆等危险行为发出警报，或者对于穿过某个游乐场区域的人数进行统计。\n而在大楼中漫游的机器人的视觉软件将会采取和安全系统完全不同的策略，因为两种策略处于不同的语境中。一般来说，视觉系统所处的环境约束越严格，我们就越能够依赖这些约束来简化问题，我们最终的解决方案也越可靠。\nOpenCV 的目标是为计算机视觉需要解决的问题提供工具。在某些情况下，函数库中的高级功能可以有效解决计算机视觉中的问题。即使遇到不能够一次性解决的问题，函数库中的基础组件也具有足够的完备性来增强解决方案的性能，以应对任意的计算机视觉难题。\n在后一种情况下，也存在一些使用库的可靠方法，所有的这些方法都是从尽量多使用不同的组件库开始。通常，在开发了第一个粗糙的解决方案之后，就可以发现解决方案存在哪些缺陷并且使用自己的代码与聪明才智修复那些缺陷（更为熟知的说法是“解决真正存在的问题，而不是你想象中的那些问题”）。在此之后可以使用粗糙的解决方案作为一个评判标准，评价改善水平。从这一点出发，你可以解决任意问题。"}
{"content2":"01 掌握好相应的基础能力\n计算机视觉的理念其实与很多概念有部分重叠，包括：人工智能、数字图像处理、机器学习、深度学习、模式识别、概率图模型、科学计算以及一系列的数学计算等。所以在入门CV之前，最好对基础的学术课程都有对应的了解，比如数学方面的微积分，概率学，统计学，线性代数这几门基础课程。\n在编程语言方面Python和C++，计算机视觉离开计算机编程是完全行不通的\n02 需要的专业工具\nOpenCV（开源计算机视觉库）是一个非常强大的学习资料库，包括了计算机视觉，模式识别，图像处理等许多基本算法。\n它免费提供给学术和商业用途，有C++，C，Python和java接口，支持Windows、Linux、Mac OS、iOS和Android。\n而关于OpenCV的学习，推荐：\n1.学习OpenCV(Learning.OpenCV)\n2.毛星云老师编著的OpenCV3编程入门\n3.学习OpenCV3（Learning OpenCV 3）\n而深度学习方面，有TensorFlow，PyTorch，Caffe等深度学习框架，它们也内置了OpenCV的API接口。而哪种框架好，就要看你自己的需要了\n推荐资料：\n莫凡教程系列之PyTorch :https://morvanzhou.github.io/tutorials/machine-learning/torch/\n03 绕不开的数字图像处理与模式识别\n数字图像处理(Digital Image Processing)是通过计算机对图像进行去除噪声、增强、复原、分割、提取特征等处理的方法和技术。\n入门的同学推荐\n冈萨雷斯的《数字图像处理》《数字图像处理(第3版)(英文版)》和对应的Matlab版本\n一本讲基础的理论，一本讲怎么用Matlab实现。\n除此之外同学们还可以去YouTube上找到相关的课程信息，相信大家会有所收获的。\n模式识别（Pattern Recognition），就是通过计算机用数学技术方法来研究模式的自动处理和判读。我们把环境与客体统称为“模式”。\n计算机视觉很多东西都是基于图像识别的，图像识别就是模式识别的一种。\n模式识别通常是训练一个模型来拟合当前的数据，当我们拿到一堆数据或图片，需要从当中找到它们的关系，最便捷的便是用模式识别算法来训练一个模型。\n04 系统的学习下计算机视觉课程\n对于CV新手来说，想要从小白到大神，最快的方法就是先系统的学习一下计算机视觉的课程，全面了解一下计算机视觉这个领域的背景及其发展、这个领域有哪些基本的问题、哪些问题的研究已经比较成熟了，哪些问题的研究还处于基础阶段。\n推荐3本经典教材：\n1.《计算机视觉：一种现代方法》（Computer Vision: A Modern Approach）\n2.《计算机视觉_算法与应用》（Computer Vision: Algorithms and Applications）\n3.《计算机视觉：模型 学习和推理》（Computer Vision: Models, Learning, and Inference）\n这三本教材是计算机视觉最好的入门教材了，内容丰富，难度适中，其中第二本书涉及大量的文献，很适合对计算机视觉没什么概念的同学。\n虽然其中的一些方法在现在看来已经过时了，但还是值得一读\n05 深度学习与CNN\n计算机视觉里经常使卷积神经网络，即CNN，是一种对人脑比较精准的模拟。\n什么是卷积？卷积就是两个函数之间的相互关系，然后得出一个新的值，他是在连续空间做积分计算，然后在离散空间内求和的过程。\n同学们可以试着学习下CNN在计算机视觉当中的应用\n推荐的资料：\n1.斯坦福CS231n—深度学习与计算机视觉网易云课堂课程：http://study.163.com/course/introduction.htm?courseId=1003223001\n2.斯坦福CS231n—深度学习与计算机视觉官方课程：http://cs231n.stanford.edu/\n3.CS231n官方笔记授权翻译总集篇：https://www.52ml.net/17723.html\n4.吴恩达 deeplearning.ai与网易云课堂的微专业深度学习工程师卷积神经网络\nhttp://mooc.study.163.com/course/2001281004?tid=2001392030#/info\n神经网络方面的经典教材\n1.《深度学习》\n2.《神经网络与深度学习》\n06 了解最新领域动态\n很多同学做研究的时候，容易陷入自我封闭的“怪圈”，过于执着于埋头学习相关知识，有时候会忘记及时了解相关领域的最新动态，这是非常不科学的。\n同学们在学习计算机视觉相关知识的时候，可以通过最新的paper来了解这个领域最新提出的一些概念以及发展的情况。\n计算机视觉的期刊有两个PAMI（模式分析与机器智能汇刊）和IJCV（计算机视觉国际期刊）\n顶级的学术会议有 CVPR、ICCV、 ECCV、 BMVC这四个，同学们可以跟着浏览这些期刊论文以及会议文章，相信一定可以学到不少有用的知识。\n做好计算机视觉研究并不是一件容易的事情，在大多数情况下它甚至是一件很枯燥的事情。研究成果毫无进展，研究方向不在明朗等等，这一切都会给你前所未有的压力.所以希望同学们在决定入这一行的时候，是出于自己的热爱，而不是出于当前的趋势。\n因为热爱不会变，但趋势每一年都在变。\n有兴趣的同学可以读一读，完整 PDF 地址：下载链接"}
{"content2":"实践环境\nOpenCV 3.2和Python 2.7\nTensorFlow1.1和Python 3.5\n-------------------------------------------------------------------------------\n计算机视觉框架\n语义感知\n分类\n物体，属性，场景等\n检测\n物体，行人，人脸等\n识别\n物体：车牌文本；人：人脸，指纹，虹膜，步态，行为\n分割\n场景的分割：自动驾驶；检测：光学图像的特征识别\n检索\n以文搜图，以图搜图，图文连搜\n语言\n图片描述，图片问答\n几何属性\n3D建模\n双目视觉\n增强现实\n------------------------------------------------------------------------------\n传统图像处理\n空域分析和变换（sobel, laplace, 高斯，中值 ）\n频域分析和变换（傅里叶变换，小波变换）\n模板匹配，图像金字塔， 滤波器组\n特征数据操作（主成分分析，奇异值分解，聚类）\n图像特征\n颜色特征：RGB，HSV，Lab等 直方图\n几何特征：Edge，Corner，Blob等\n局部特征：SIFT，SURF，FAST等\n梯度Prewitt滤波/卷积\n水平梯度/垂直边缘\n垂直梯度/水平边缘\n梯度sobel滤波、卷积\n梯度laplace滤波、卷积\n二阶微分算子\n团块检测：周边高于（低于）中心点\n边缘检测：像素快速变化的区域\n高斯金字塔\n多次高斯卷积以后，一些像素多余\nn次（高斯卷积->2x采样）->n层金字塔\n目的：捕捉不同尺寸的物体（合适尺寸永远未知）\n拉普拉斯金字塔\n高频细节信息在卷积核下采样中丢失。\n保留所有层所丢失的高频信息，用于图像恢复。\n模板匹配\n兴趣点匹配\nHarris角点（corner），任何方向移动小的观察窗，导致像素大的变化。\nBlob斑点，一阶导极值点->二阶导零点/对噪声很敏感，需要先做高斯平滑\nSIFT，良好不变性，独特性好，信息量丰富，少量图片能产生大量SIFT特征\nHOG，纹理特征，分别计算水平，垂直梯度，彩色图选取梯度幅值最大\nGabor：类似人的视觉系统，多频率，多尺度，多方向\n频域：属于加窗的傅里叶变换\n空域：一个高斯核函数和正弦平面波乘积"}
{"content2":"文章目录\n1 Baidu 计算机视觉算法研发工程师\n2 海康威视\n2.1 图像算法工程师（图像处理\\视频编解码\\3D视觉）研究院\n2.2 AI算法工程师（计算机视觉\\机器学习\\模式识别\\人脸识别\\自然语言处理\\语音识别\\音频处理）研究院\n2.3 图像算法工程师-产品研发中心\n2.4 图像算法工程师-微影传感\n3 华为\n3.1 计算机视觉算法工程师\n4 商汤\n4.1 计算机视觉研究员\n4.2 见习计算机视觉研究员\n4.3 计算机视觉算法工程师\n1 Baidu 计算机视觉算法研发工程师\n时间：2018.09.09\n职位：计算机视觉算法研发工程师\n工作地点: 深圳市\n招聘人数: 5\n工作职责:\n负责百度计算机视觉相关的技术(含无人车自定位、地图重建、图像点云物体识别分类算法）、系统、产品的研发工作，包括但不限于：移动图像技术应用、图像内容搜索、人脸检测识别、图像分类标注、OCR、增强现实、图像质量评价、图像处理、点云视觉定位、三维视觉重建、物体分类识别等；\n招聘要求：\n掌握计算机视觉和图像处理基本算法，并在如下一个或多个相关方向有较深入研究：移动图像技术应用、图像内容搜索、人脸检测识别、图像分类标注、OCR、增强现实、图像质量评价、图像处理等；\n了解机器学习基本算法，如分类、回归、聚类、概率模型等\n熟悉和掌握C/C++和脚本语言编程(如Shell, Python, Perl等）\n具有良好的沟通能力，和良好的团队合作精神\n有相关实践经验者优先\n2 海康威视\n时间：2018.09.10\n2.1 图像算法工程师（图像处理\\视频编解码\\3D视觉）研究院\n任职资格：\n有较好数学基础，较强的图像处理算法设计与开发能力；\n掌握c/c++、python等编程语言，能编程实现相关算法；\n较强的论文检索，英文专业文献阅读能力；\n良好的沟通与协作能力。\n具备以下经验之一者优先：\n1、 了解深度学习，在图像处理领域进行过深度学习相关研究与实现；\n2、 具备较丰富的图像处理、计算成像、3D视觉、视频编解码研究经历；\n3、 具备较丰富的雷达信号处理研究经历。\n2.2 AI算法工程师（计算机视觉\\机器学习\\模式识别\\人脸识别\\自然语言处理\\语音识别\\音频处理）研究院\n工作职责:\n负责模式识别、计算机视觉、深度学习、人脸识别、自然语言处理、语音识别、音频处理相关算法的研究与实现。\n任职资格：\n具有较好的数学功底，对模式识别、机器学习有较深入的理解与认识；\n在下述任一领域有研究经历：计算机视觉、人脸识别、语音识别、自然语言理解、麦克阵列；\n熟练掌握C\\C++\\Python，具备扎实的编程基础；\n熟练使用Caffe、Tensorflow、PyTorch及其它开源框架者优先；\n有实际项目开发或参加竞赛经验者优先；\n在CVPR、ICCV、CSVT、TMM、TIP、PAMI等国际顶级会议或期刊上发表过文章者优先；\n2.3 图像算法工程师-产品研发中心\n工作职责:\n负责图像处理模块的算法设计，并在相关平台上实现。\n任职资格：\n精通C语言，掌握Matlab，熟悉OpenCV 等图像工具；\n熟悉图像处理或模式识别相关算法处理；\n对红外图像的非均匀性校正、细节增强、去噪、测温等相关算法有一定了解；\n具有较强的文献获取能力，英文文献检索和阅读能力；\n有红外图像算法处理经验者优先。\n2.4 图像算法工程师-微影传感\n工作职责:\n负责图像处理模块的算法设计，并在相关平台上实现。\n任职资格：\n精通C语言，掌握Matlab，熟悉OpenCV 等图像工具；\n熟悉图像处理或模式识别相关算法处理；\n对红外图像的非均匀性校正、细节增强、去噪、测温等相关算法有一定了解；\n具有较强的文献获取能力，英文文献检索和阅读能力；\n有红外图像算法处理经验者优先。\n3 华为\n3.1 计算机视觉算法工程师\n工作职责:\n深度学习算法的研发，特别是在计算机视觉领域的应用研究，以及模型加速、模型加密、模型量化等研发；\n研究基于 deep learning 的人的属性或人的附属物体类型及其属性的识别算法；\n计算机视觉算法研发与产品开发，包括但不限于：\n人脸识别、人脸属性、人体重识别识别；\n目标检测、目标分类、目标属性识别；\n图像分割、图像解说、图形对象识别、图像生成、图片审核、图像优化、图像聚类；\n目标检测、识别、跟踪；\n视频分割、视频语义提取；\nOCR、文字检测；\n语义分割、超分辨率；\n任职资格：\n熟练掌握C/C++、Python等语言，掌握一种以上深度学习框架，掌握Opencv等基础库的使用；\n掌握计算机视觉基础知识、深度学习、经典机器学习等。有实践经验者优先；\n具备一定的科研能力，能快速理解paper，具备算法创新能力者优先；\n具备对现实问题抽象出数学模型的逻辑分析能力，并能够求解数学问题；\nremark：\n华为的所有岗位入职时随机分配，不宜；\n华为的很多岗位偏通信，不宜；\n2012实验室、消费者 BU (business unit) 均有有视觉岗；\n2012实验室从事基础研究，部门利润低、工资外收入低；\n消费者 BU 市场发展空间不大；（phq）\n4 商汤\n4.1 计算机视觉研究员\n工作职责:\n负责计算机视觉（包括深度学习）算法的开发与性能提升，负责下述研究课题中的一项或多项，包括但不限于：检测、跟踪、分类、语义分割、深度估计、图像处理、视频分析、3D图形与视觉、强化学习、自然语言理解、机器人技术相关算法等；\n推动计算机视觉&机器学习算法在众多实际应用领域的性能优化和落地；\n提出和实现最前沿的算法，保持算法在工业界和学术界的领先。\n任职资格：\n熟练掌握计算机视觉的基本方法；\n较强的算法实现能力，熟练掌握 C/C++ 编程，熟悉 Shell/Python/Matlab 编程之一;\n算法基础扎实，掌握常见设计模式，具有良好代码风格和质量意识，能独立完成算法模块设计、开发和测试；\n满足以下一个或多个条件的，优先考虑：\n在国际顶尖会议或期刊（包括但不限于CVPR, ICCV, ECCV, NIPS, ICML, AAAI, TPAMI, IJCV等）上发表过论文；\n有较强的代码能力者优先，获得过ACM或其他商业代码竞赛的荣誉，如ACM区预赛金牌、NOI银牌以上、百度之星决赛等，或代码开源在GitHub上并有较大影响；\n有较强的比赛经验者或者在重要数据集的排行榜上排名靠前的优先，这些比赛包括但不限于ImageNet等相关竞赛、Kaggle等一些国内外商业比赛、亚太大学生/国际空中/Robomaster机器人大赛等；\n有较丰富的相关经验者优先，比如有一年以上在人工智能领域公司进行计算机视觉&机器学习方面实习的经验，或来自国内外计算机视觉/机器学习/计算机图形学/数据挖掘等领域内知名实验室。\n4.2 见习计算机视觉研究员\n工作职责:\n负责计算机视觉相关算法的开发与性能提升，涉及的问题包括但不限于：检测、跟踪、分类、语义分割、强化学习、3D视觉和图像处理等。\n推动计算机视觉算法和深度学习在智能视频，安防监控，手机，自动驾驶，OCR等众多实际应用领域的性能优化和落地。\n提出和实现最前沿的算法，保持算法在工业界和学术界的领先。\n任职资格：\n掌握机器学习（特别是深度学习）和计算机视觉的基本方法。\n优秀的分析问题和解决问题的能力，对解决具有挑战性的问题充满激情。\n较强的算法实现能力，熟练掌握 C/C++ 编程，熟悉 Shell/Python/Matlab 编程。\n有较强的代码能力优先，获得过ACM或其他商业代码竞赛的荣誉，如ACM区预赛金牌、NOI银牌以上、百度之星决赛等；或代码开源在github上并有较大影响。\n有较强的学术比赛经验或者在重要数据集的Leaderboard上排名靠前，比如ImageNet等学术数据集或者Kaggle等一些国内外商业比赛。\n4.3 计算机视觉算法工程师\n工作职责:\n负责基于深度学习的视觉算法SDK等算法产品的研发、优化和维护；\n配合视觉计算领域的顶级研究人员，参与图像视频算法的设计研发，负责底层算法的工程化、封装、优化、测试等；\n参与图像视觉应用软件和相关自动化工具的开发和维护。\n任职资格：\n熟练掌握C/C++，算法基础扎实，具有良好代码风格和质量意识；\n具有图像/视频处理相关背景知识和开发经验；\n满足以下条件者优先：\n有深度学习相关研发经验者优先；\n了解GPU并行计算，熟悉CUDA编程或OpenCL编程；\n熟悉 X86、ARM 的多线程和SIMD代码优化技术；\n具有Neon或OpenCL或OpenGL等移动端性能优化经验；\n学习能力强，具备优秀的分析和解决问题能力，具备良好的沟通能力和团队合作意识。"}
{"content2":"第二届人工智能竞赛——题目四、猫狗识别\n文章目录\n第二届人工智能竞赛——题目四、猫狗识别\n一、简介\n二、题目要求\n三、参考资料\n一、简介\n分类问题是机器学习中一个重要的任务，即找一个函数判断输入数据所属的类别，可以是二类别问题（是/不是），也可以是多类别问题（在多个类别中判断输入数据具体属于哪一个类别）。\n二、题目要求\n利用现有的模型对图片进行识别，判断图片上的动物是猫还是狗。\n利用 QT 设计 UI 界面，界面要求:友好、功能完善、简介。\n评估模型效果，准确率\n三、参考资料\nhttps://github.com/xuetsing/cats-vs-dogs.git\nUI界面可用QT编写"}
{"content2":"1 深度学习、计算机视觉、人工智能的关系\n2 图像基础\n3 深度学习与神经网络基础\n3.1 神经网络的线性变换\n3.2 卷积神经网络CNN(Convolutional Neural Network)"}
{"content2":"计算机视觉—相机标定\nbrycezou@163.com\n0、预备知识\n下图基本展示了一些重要的概念：点\nO\nO 与\nXc,Yc,Zc\nX_c,Y_c,Z_c三个轴组成的坐标系为相机坐标系，其中，原点\nO\nO 为相机光心，\nZc\nZ_c为相机的光轴，光轴和成像平面\nxO1y\nxO1y 垂直，且光轴与成像平面的交点为图像的主点\nO1\nO1，\nOO1\nOO1 为相机的焦距\nf\nf，\nXcOYc\nX_cOY_c 平面和成像平面平行。世界坐标系是为了描述相机的位置而引入的，下图中，点\nOw\nO_w 与\nXw,Yw,Zw\nX_w,Y_w,Z_w 三个轴组成的坐标系即为世界坐标系。点\nO1\nO1 与\nx,y\nx,y 两个坐标轴组成的坐标系为图像物理坐标系，也即成像平面坐标系。\n\n此图来自网络，非作者原创，若侵犯到您的权益，请留言，以便标明出处，谢谢\n1、世界坐标系\n→\n\\rightarrow 相机坐标系\n设\n(Xw,Yw,Zw)\n(X_w,Y_w,Z_w) 表示世界坐标系中的点，\n(Xc,Yc,Zc)\n(X_c,Y_c,Z_c) 表示相机坐标系中的点，则世界坐标系到相机坐标系的变换，其实就是一个刚体变换，可以由旋转矩阵\nR\nR 和平移矩阵\nt\nt 来表示，\nR⎡⎣⎢⎢XwYwZw⎤⎦⎥⎥+t=⎡⎣⎢⎢XcYcZc⎤⎦⎥⎥\nR\\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\end{matrix}\\right]+t= \\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\end{matrix}\\right]\n其中，\nR\nR 为\n3x3\n3x3 的旋转矩阵，\nt\nt 为\n3x1\n3x1 的平移向量。化为齐次坐标形式\n[R3x301x3t3x111x1]⎡⎣⎢⎢⎢⎢XwYwZw1⎤⎦⎥⎥⎥⎥=⎡⎣⎢⎢⎢⎢XcYcZc1⎤⎦⎥⎥⎥⎥\n\\left[\\begin{matrix}R_{3x3} & t_{3x1}\\\\0_{1x3} & 1_{1x1}\\end{matrix}\\right] \\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]= \\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]\n2、相机坐标系\n→\n\\rightarrow\n理想\n图像物理坐标系（成像平面坐标系）\n设\n(x,y)\n(x,y) 是图像物理坐标系中的点，\n由于点\n(Xc,Yc,Zc)\n(X_c,Y_c,Z_c) 和相机坐标系的原点（相机光心）之间的连线，穿过图像物理坐标系所在的平面\n，因此，由相似三角形可得\nXcx=Zcf,Ycy=Zcf\n\\frac{X_c}{x}=\\frac{Z_c}{f},\\frac{Y_c}{y}=\\frac{Z_c}{f}\n进一步整理可得\n[f00f][XcYc]=Zc[xy]\n\\left[\\begin{matrix}f & 0\\\\0 & f\\end{matrix}\\right] \\left[\\begin{matrix}X_c\\\\Y_c\\end{matrix}\\right]= Z_c\\left[\\begin{matrix}x\\\\y\\end{matrix}\\right]\n化为齐次坐标形式\n⎡⎣⎢⎢f000f0001000⎤⎦⎥⎥⎡⎣⎢⎢⎢⎢XcYcZc1⎤⎦⎥⎥⎥⎥=Zc⎡⎣⎢⎢xy1⎤⎦⎥⎥\n\\left[\\begin{matrix}f & 0 & 0 & 0\\\\0 & f & 0 & 0\\\\0 & 0 & 1 & 0\\end{matrix}\\right] \\left[\\begin{matrix}X_c\\\\Y_c\\\\Z_c\\\\1\\end{matrix}\\right]=Z_c \\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right]\n3、图像物理坐标系\n→\n\\rightarrow 图像像素坐标系\n以图像的左上角为原点建立图像像素坐标系\n(u,v)\n(u,v)，并且让\nu\nu 轴与\nx\nx 轴平行，\nv\nv 轴与\ny\ny 轴平行。设图像物理坐标系的原点\nO1(0,0)\nO1(0,0) 在\nuv\nuv 坐标系中对应的坐标为\n(u0,v0)\n(u_0,v_0)，\n单位像素在\nx\nx 轴和\ny\ny 轴方向的物理尺寸分别为\ndx\ndx 和\ndy\ndy\n，则有\nu−u0=xdx,v−v0=ydy\nu-u_0=\\frac{x}{dx},v-v_0=\\frac{y}{dy}\n进一步整理可得\n[uv]=⎡⎣⎢⎢⎢1dx001dy⎤⎦⎥⎥⎥[xy]+[u0v0]\n\\left[\\begin{matrix}u\\\\v\\end{matrix}\\right]= \\left[\\begin{matrix}\\frac{1}{dx} & 0\\\\0 & \\frac{1}{dy}\\end{matrix}\\right] \\left[\\begin{matrix}x\\\\y\\end{matrix}\\right]+ \\left[\\begin{matrix}u_0\\\\v_0\\end{matrix}\\right]\n化为齐次坐标形式\n⎡⎣⎢⎢⎢⎢⎢1dx0001dy0u0v01⎤⎦⎥⎥⎥⎥⎥⎡⎣⎢⎢xy1⎤⎦⎥⎥=⎡⎣⎢⎢uv1⎤⎦⎥⎥\n\\left[\\begin{matrix}\\frac{1}{dx} & 0 & u_0\\\\0 & \\frac{1}{dy} & v_0\\\\0 & 0 & 1\\end{matrix}\\right] \\left[\\begin{matrix}x\\\\y\\\\1\\end{matrix}\\right]= \\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]\n4、结论\n将相关矩阵相乘，便可以得到三维空间点坐标到图像像素坐标的映射\nZc⎡⎣⎢⎢uv1⎤⎦⎥⎥=⎡⎣⎢⎢⎢⎢⎢1dx0001dy0u0v01⎤⎦⎥⎥⎥⎥⎥⎡⎣⎢⎢f000f0001000⎤⎦⎥⎥[R3x301x3t3x111x1]⎡⎣⎢⎢⎢⎢XwYwZw1⎤⎦⎥⎥⎥⎥=⎡⎣⎢⎢α000β0u0v01000⎤⎦⎥⎥[R3x301x3t3x111x1]⎡⎣⎢⎢⎢⎢XwYwZw1⎤⎦⎥⎥⎥⎥=M1M2⎡⎣⎢⎢⎢⎢XwYwZw1⎤⎦⎥⎥⎥⎥\nZ_c\\left[\\begin{matrix}u\\\\v\\\\1\\end{matrix}\\right]= \\left[\\begin{matrix}\\frac{1}{dx} & 0 & u_0\\\\0 & \\frac{1}{dy} & v_0\\\\0 & 0 & 1\\end{matrix}\\right] \\left[\\begin{matrix}f & 0 & 0 & 0\\\\0 & f & 0 & 0\\\\0 & 0 & 1 & 0\\end{matrix}\\right] \\left[\\begin{matrix}R_{3x3} & t_{3x1}\\\\0_{1x3} & 1_{1x1}\\end{matrix}\\right] \\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]\\\\= \\left[\\begin{matrix}\\alpha & 0 & u_0 & 0\\\\0 & \\beta & v_0 & 0\\\\0 & 0 & 1 & 0\\end{matrix}\\right] \\left[\\begin{matrix}R_{3x3} & t_{3x1}\\\\0_{1x3} & 1_{1x1}\\end{matrix}\\right] \\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]= M_1M_2 \\left[\\begin{matrix}X_w\\\\Y_w\\\\Z_w\\\\1\\end{matrix}\\right]\n其中，\nM1\nM_1为相机的内参数，\nM2\nM_2为相机的外参数，包括旋转和平移矩阵。"}
{"content2":"从去年工作到现在，从传统视觉领域到后来的深度学习的研发，也算略有心得。\n传统的视觉算法的优点在于有很好的解释性，在现场跟客户交流的时候，什么能够检出，什么不能检出，为什么不能检出，以及通过哪种方法可以改善。缺点也很明显，对环境的要求高，运用范围比较窄，参数多，客户使用极度不方便。\n而深度学习算法却恰恰相反，对环境要求不是很高，运用范围比较多，客户使用及其简易。但是可解释性不强，经常有人问我为什么小的目标能够检出，明显的大的目标却无法检出。我哑口无言，虽然算法是我写的，但我也不知道具体的这个网络学到了哪些特征。失去了可解释性后，就出现了客户的不信任，这也许是最大的难点，即使深度学习比传统算法准确率高一些，但不可控的事物，人们总是无法信任。\n好了，具体的讲讲计算机视觉吧。\n传统算法，没啥好讲的，opencv上基本都有，会用就行（这里介绍一本书《opencv3编程入门》），至于一些其他的传统视觉算法，大都可以借助opencv来实现。\n深度学习的算法，目前接触的比较多的是分类，语义分割，目标检测。实例分割我没有接触过，毕竟我做的不是无人驾驶这一领域。先从分类开始谈谈吧，分类网络挺简单的，但是却也是最重要的，是后来分割，检测等深度学习网络的基石。从vgg到resnet，再到现在的xception，这是我比较推荐的三种网络。去掉分类网络的全连接层后的网络，将它称之为基础网络。基础网络关系到一个网络拟合能力的强弱。（拟合能力不等于提特征能力。ps：个人观点）。\n语义分割网络，本质上一种基于像素点的密集分类网络，它与分类网络的区别在于将全连接层换成了解码层，就是这么简单！！！如果之前分类网络做过特征热力图分析的，可以更加直观的感受分类网络是如何运用于分割网络的。语义分割中，我比较推荐的是Unet，FCN,deeplab这三种网络。没啥好讲的，懂了分类网络后，再看看上采样，没什么新的知识点可以学的。\n目标检测网络，分两种一种是端到端的网络，一种是两端网络。端到端的网络有SSD，yolo这两种，至于其他的看看就行。这两种网络最欣赏的是SSD网络，个人感觉SSD的架构更好，唯一缺点受限于当时的基础网络的理论，基础网络的提取特征的能力偏弱。至于yolov3，个人感觉借鉴了SSD的思路，但是darknet这个基础网络，啥都不说了，都是泪，建议换了吧。两端目标检测集大成者，faster-RCNN，完美！！！RPN层简直鬼斧神工，虽然我一直在拜读他的论文，但依旧没有搞懂，它的ROI层的反向传播机制。何凯明大神是真的厉害！！！\n好了，三种网络都讲完了，还想说说深度学习的一些坑点，深度学习千万别什么都相信论文，论文上的一些数据和结论有些是不可信的。多做做实验，别迷信论文，大胆的按照自己的知识，实验的结果，数据集的需求改网络，而不是浮于表面的调调参数！！！\n如果想提高算法的预测能力的话，有些时候换算法还不如修改数据集！！！\n好了，讲完了，这是对我之前工作的一次总结，我又跳槽了。新的东家没有AI的基础，这也是我最欣赏的一点，我这次去需要独立将Ai架构搭好，将AI的团队组好，挺有挑战的，祝我能成功的平地起高楼。"}
{"content2":"一 计算机视觉顶级会议时间表\n1. IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2018)\n* Location / Date: Salt Lake City, June 18-21, 2018\n* Paper Submission Deadline: November 15, 2017\n* Acceptance rate: 20% ~ 30%\n* http://cvpr2018.thecvf.com/\n2.  The 15th European Conference on Computer Vision (ECCV 2018) (两年一次)\n* Location / Date: Munich, Germany; September 8-14, 2018\n* Paper Submission Deadline: March 14, 2018 (23:59 CET)\n* Acceptance rate: 20% ~ 30%\n* https://eccv2018.org/\n3. IEEE International Conference on Computer Vision (ICCV 2018)\n* Location / Date: Istanbul, Turkey; January 30-31, 2018\n* Paper Submission Deadline: November 30, 2017\n* Acceptance rate: 20% ~ 30%\n* http://www.guide2research.com/conference/iccv-2018\n4. Conference on Neural Information Processing Systems (NIPS 2018)\n* Location / Date: Montreal, Canada; December 03-08, 2018\n* Paper Submission Deadline: May 18, 2018\n* Acceptance rate: 20%~ 30%\n* https://nips.cc/\n5. The 14th Asian Conference on Computer Vision (ACCV 2018)\n* Location / Date:Perth, Australia; December 02-06, 2018\n* Paper Submission Deadline: July 05, 2018\n* Acceptance rate: ~ 30%\n* http://accv2018.net/\n6. The 29th British Machine Vision Conference (BMVC 2018)\n* Location / Date:Northumbria University; September 03-06, 2018\n* Paper Submission Deadline: May 07, 2018\n* Acceptance rate: ~ 40%\n* http://bmvc2018.org/index.html\n7. IEEE International Conference on Image Processing (ICIP 2018)\n* Location / Date: Athens, Greece; October 7-10, 2018\n* Paper Submission Deadline: February 07, 2018\n* Acceptance rate: ~ 45%\n* https://2018.ieeeicip.org/\n8. The 24th International Conference on Pattern Recognition (ICPR 2018)\n* Location / Date: Beijing, China; August 20-24, 2018\n* Paper Submission Deadline: January 22, 2018\n* Acceptance rate: ~ 55%\n* http://www.icpr2018.org/\n二、人工智能\n9. The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI 2018)\n美国人工智能年会（AAAI Conference on Artificial Intelligence），简称 AAAI，是人工智能领域的顶级国际会议。该会议固定在每年的2月份举行，由 AAAI 协会主办。\n新奥尔良，美国\n会议时间：2.2-2.7\n官网：https://aaai.org/Conferences/AAAI-18/\n10. International Conference on Machine Learning（ICML 2018）\n斯德哥尔摩，瑞典\n截稿日期：2.9\n会议时间：7.10-7.15\n官网：https://icml.cc/\n11. IJCAI-ECAI 2018\nIJCAI 是人工智能研究人员的首要国际会议，ECAI 是人工智能研究人员在欧洲首屈一指的会议。自 2016 年起，IJCAI 每年举行一次。 ECAI 自 1974 年以来每两年举行一次。IJCAI-ECAI 2018 由 IJCAI、EurAI 和 SAIS 联合主办。\n斯德哥尔摩，瑞典\n截稿日期：1.31（摘要截稿1.25）\n会议时间：7.13-7.19\n官网：https://www.ijcai-18.org/\n*4.16  最终决定公布 ；会议注册预计4月开放\n12. The Association for Computational Linguistics（ACL 2018）\n自然语言处理和计算机语言学最顶尖的会议之一，其会员遍布世界各地，被CCF（中国计算机学会）认定为A类国际学术会议，涵盖领域包括语言分析、信息抽取、机器翻译与自动问答等\n墨尔本，澳大利亚\n截稿日期：2.22\n会议时间：7.15-7.20\n官网：http://acl2018.org/\n*3.26-3.28 作者回应期；4.20 论文接收通知；5.11 定稿\n13. International Conference on Learning Representations（ICLR 2018）\n温哥华，加拿大\nAI 科技评论注：以下时间为美国东部时间\n会议时间：5.21-5.25\n官网：http://iclr.cc/\n*1.29 论文接收通知；\n14. MMM2018 (泰国曼谷)\n全称：the 24rd International Conference on MultiMedia Modeling\n时间：2018.02.05-08\n地点：Dusit Thani Hotel, Bangkok, Thailand\n介绍：多媒体建模及应用领域国际权威会议\n官网：http://mmm2018.chula.ac.th/\n15. ICIGP 2018（中国香港）\n全称：INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING\n时间：2018.02.24-26\n地点：Regal Oriental Hotel，Hong Kong\n介绍：促进学术界和工业界交流的图形图像处理会议\n官网：http://icigp.org/\n16. ACM - ICIAI 2018（中国上海）\n全称：2018 2nd International Conference on Innovation in Artificial Intelligence\n时间：2018.03.09-12\n地点：Shanghai, China\n网址：http://www.iciai.org/\n17. WACV 2018 (美国内华达州)\n全称：IEEE Winter Conference on Applications of Computer Vision\n时间：2018.03.12-15\n地点：Harvey’s Casino in Lake Tahoe, Nevada，U.S.\n介绍：侧重计算机视觉应用的国际知名会议\n网址：http://wacv18.uccs.us/\n18. ICASSP 2018（加拿大卡尔加里）\n全称：International Conference on Acoustics, Speech and Signal Processing\n时间：2018.04.15-20\n地点：ELUS Convention Center, Calgary, Alberta, Canada\n介绍：声学、语音与信号处理及其应用国际顶级会议\n官网：https://2018.ieeeicassp.org/\n19. CVM2018（中国上海）\n全称：Computational Visual Media conference\n时间：2018.4.18-20\n地点：上海，上海交通大学\n介绍：计算机视觉相关的基础研究和应用会议\n官网：http://iccvm.org/2018/\n20. SIGGRAPH 2018（加拿大温哥华）\n时间：2018.08.12-16\n地点：Vancouver, Canada\n介绍：计算机图形学领域最权威、影响力最大的国际会议\n官网：http://s2018.siggraph.org/conference/conference-overview/\n21. 3D VISON 2018(意大利维罗那)\n全称：International Conference on 3D Vision\n时间：2018.09.05-08\n地点： Verona, Italy\n主题：3D视觉研究及应用的著名会议\n官网：http://3dv18.uniud.it/\n22. ICCVG 2018（波兰华沙）\n全称：International Conference on Computer Vision and Graphics\n时间：2018.09.17-19\n地点：Warsaw, Poland\n官网：http://iccvg.wzim.sggw.pl/\n23. IROS 2018（西班牙马德里）\n全称：IEEE/RSJ International Conference on Intelligent Robots and Systems\n时间：2018.10.01-05\n地点：Madrid, Spain\n介绍：智能机器人系统领域国际顶级会议\n官网：http://www.iros2018.org/\n24. JCRAI 2018 （埃及开罗）\n全称：International Joint Conference on Robotics and Artificial Intelligence\n时间：2018.12.21-23\n地点：Cairo Egypt\n介绍：图像处理领域国际会议\n官网：http://www.jcrai.org/"}
{"content2":"智能制造工厂中的人工智能和大数据技术\n人工智能技术主要分四个方面\n1 通过神经网络技术对产品制造全流程数据进行分析，找到提高产品质量的办法；\n2 通过计算机视觉（ar/vr)和神经网络技术，使智能制造设备具备自学习、自适应的能力\n3 通过车间无人小车（agv)，仓库无人分拣机器人 生产线工业机器人的使用，达到无人化操作\n4 在产品上装上传感器，通过大数据和数据挖掘算法分析知道产品的实时状态，指导客户进行维护和保养，确保可靠性。\n工业物联网大数据平台技术分三个方面\n1 物联网芯片和数据采集，工业设备或终端上安装物联网芯片，连上工业互联网，芯片实时采集设备的各种数据，并通过互联网发送到数据接入平台，其实就是调用soap/restful/mqtt接口向数据接入平台写入数据\n2 大数据汇总和统计监控，终端数据发送到数据接入平台，通过消息中间件和redis缓存后，运用storm/spart steaming进行实时处理，保存到hadoop大数据平台（hdfs hbase)，随后对这些大数据进行离线计算生成报表，保存到mysql或地理数据库，也可以对大数据利用机器学习算法进行各种数据挖掘分析，对出现的异常情况及时报警\n3 业务查询和三维可视化，这个直接从mysql或地理数据库里查询数据生成界面，对于实时要求高的三维可视化监控，可以直接从redis集群里提取数据"}
{"content2":"继续之前的计算机视觉课程的学习：\nLecture 6 物体\n人类对于物体的感知是连续感知和分类感知的混合，在大层面下，分类感知起主要作用，比如看到的物体，我们都会下意识地根据颜色来进行类别分类。而在小尺度下，例如我们要仔细分辨一块瓷砖内花纹之间有什么区别，这个时候，连续感知更多地帮助我们对物体进行认知。当然，涉及到认知层面，必然会跟文化因素，经验，任务和注意力有关。\n类别的分类是非常重要的，虽然我们不知道物体的类别，也可以得到相应的3D形状，纹理，材料特性这些研究对象的信息，但是，物体的类别还封装好了物体的一些行为属性，即物体能做什么（C++里面，类除了数据成员外，还有表明能实现什么功能的函数成员）。\n如椅子类别：\n上面椅子是否可以坐的例子可以认为是直接感知（direct perception），具有形式简单，容易定义的特点。但是直接感知存在一个问题：它是依赖于观察者的（observer dependent）。对于看上去，结构非常相似的物体，对它们的感知（或认知）却应该是不一样才行。\n虽然外形是一样的，却是两个截然相反的对象。这个时候就需要非直接感知了。\n接下来讨论的是：哪一级的感知才是正确的感知？\n比如说我们对汽车的认知是：2~4个门，4个轮子，1块天花板，2个前灯，还有挡风玻璃。但是，假如我们正考虑买车，要考虑的方面就要更具体了。\n入门级分类：将物体分为典型类别和非典型类别，通常不需要科属种那样详细的分类。\n经典的分类方法是基于物体组成部分来分的，要确定哪些部分对于分类是必要且有用的，然后把这些组成部件进行抽象，用基本形状如长方块，圆环等来表示，要考虑部件的相对空间位置。\n这里还介绍了一种常用的分类器构造方法：boosting（提升）：将简单已得到的弱分类器叠加起来，就能boosting成一个强分类器。\nLecture 7 场景\n场景和物体的关系：场景是人类能够进行活动的地方，不仅仅是物体的组合，是有其属性和功能的。\n在人的记忆中，场景是一个比存在的物体更容易记住的对象。\n那么，通过什么能够得到图像中场景的规律？\n塑造环境的物理过程。如，图中存在很多雪，可能是在高山上。\n场景中的功能性约束。如，存在很多书本还有电脑，可能是书房。\n观察者视角的约束。\n人与外部世界的交互。\n自然场景和人工场景的分类（我本科毕设也利用了这个特性）：\n特写视角和大场景的分类：\n上面这两种都是用傅里叶变换的频谱特性进行简单的分类。下面利用Gist描述子进行更具体的分类：\nGist描述子是用Gabor对原图进行4个尺度8个方向卷积得到32个特征图，然后把每个特征图分为16个区域，求每个区域的平均特征，再把4*8*16=512维的特征组合起来，得到Gist描述子。\n还有一些通过词袋（bag of words）的方法：SIFT特征，视觉词，金字塔匹配，SVM分类等等进行场景分类。\nLecture 8 场景\n这个Lecture继续讲场景分类，从近邻法开始，提到场景分类中，图片量级非常大，所以必须采用快速高效的特征编码方式-二值编码及对应的距离汉明距离。\nSVM有三种核来得到决策边界，分别是：\n线性核：\nk(x,xm)=xTxm\nk(x, x_m) = x^T x_m\n径向基函数：\nk(x,xm)=exp(−|x−xm|2/σ2)\nk(x, x_m) = exp(−|x − x_m|^2/σ^2)\n直方图交叉(Histogram intersection)：\nk(x,xm)=sumi(min(x(i),xm(i)))\nk(x,x_m) = sum_i(min(x(i), x_m(i)))\n直方图交叉核函数，相当于求\nx\nx和\nxm\nx_m的交集和。\nLecture 9 上下文\n仍然跟场景分类和识别有关。用一个隐马尔科夫模型来进行位置的估计：\n通过一系列的实验，researchers发现：\n在合适场景下出现的物体检测准确率更高\n场景的连续性会影响物体检测\n这体现了上下文的重要性。\n人类最低场景识别的分辨率为32*32，上下文有以下三种模型：\n但是上下文是依赖以物体检测的，假如，检测产生了错误，那么上下文会使得错误进一步累加。\nLecture 10 不变特征\n不变特征是指，随着外界环境的变化，对自身特征来说，影响不大的特征集合，比如能适应光线的变化，有恰好的纹理变化，跟物体表明一一对应。常用在：图像配准；3维重建；运动跟踪；物体检测；索引；机器人导航等。\n后面都是介绍一些常见的特征描述子如Harris, good features to track（opencv里面的）等，这里就不在赘述了。\nLecture 11 边缘\n这里提到的Canny边缘检测器，其他地方有非常详细的论述，然后是基于亮度，色彩和纹理信息的物体轮廓检测方法：\n纹理信息及怎么综合是一个难点，通过上图的统计可知，一般来说，亮度大，亮度梯度大，颜色梯度大，纹理梯度也同时大（甚至都是极大值）的位置处存在轮廓。\n剩下的都是一些常见的方法：如距离变换，HOG（梯度方向直方图），在以往的博客或者别人的博客中都有论述过。\nLecture 12 分割\n仅有边缘信息对于很多任务是不够的，不同物体的轮廓会重叠在一起，只有把它们按照不同的物体分割开来，才能算是有用的边缘信息。\n分割是一个全局操作。人对边缘信息有上百种组合分割的准则：\n而这通常也是使得人眼出现错觉的原因。\n用聚类来分割：如k-means，means shift。\n基于图理论的分割：如最小割，归一化分割。\n总结：MIT的课程比起本校研究生的相关课程，理论广而深，内容多且杂，学到的都是必须而且基础的知识，对于跟上日新月异的计算机视觉的发展是非常有好处的。剩下的一些课程是人脸检测，3维运动和一些贝叶斯统计的一些知识，我没有接触过很多相关的知识，所以这里就告一段落了。这是MIT2010年的课程，之后会出2017年课程总结博客，以便学习到更新更系统的领域知识。"}
{"content2":"机器视觉（Machine Vision, MV） & 计算机视觉(Computer Vision, CV)从学科分类上， 二者都被认为是 Artificial Intelligence 下属科目。\n什么是机器视觉？\n机器视觉，即采用机器代替人眼来做测量和判断。机器视觉系统是指通过机器视觉产品（即图像摄取装置，分cmos和ccd两种）把图像抓取到，然后将该图像传送至处理单元，通过数字化处理，根据像素分布和亮度、颜色等信息，来进行尺寸、形状、颜色等的判别。进而根据判别的结果来控制现场的设备动作。目前广泛应用于食品和饮料、化妆品、建材和化工、金属加工、电子制造、包装、汽车制造等行业。\n机器视觉是个相对较新的技术，它为制造工业在提高产品质量、提高生产效率和操作安全性上提供了许多技术。在其他相关技术中，机器视觉包括图像数字化、图像操作和图像分析，通常使用计算机来完成，所以说它是一门覆盖图像处理和计算机视觉的专业。然而，我们又强调过机器视觉、计算机视觉和图像处理不是同义的。它们其中之一都不是任何其他两个的子集。计算机视觉是计算机科学的一个分支，而机器视觉是系统工程一个特殊领域。机器视觉没有说明要使用计算机，但是在获取高速处理速度上经常会使用特殊的图像处理硬件，这个速度是普通计算机所不能达到的。\n什么是计算机视觉？\n“计算机视觉”是指用计算机实现人的视觉功能，对客观世界的三维场景的感知、识别和理解。计算机视觉是一个处于指示前沿的领域。我们认为计算机视觉，或简称为“视觉”，是一项事业，它与研究人类或动物的视觉是不同的。它借助于几何、物理和学习技术来构筑模型，从而用统计的方法来处理数据。\n因此从我们的角度看，在透彻理解摄像机性能与物理成像过程的基础上，视觉对每个像素进行简单的推理，将在多幅图像中可能得到的信息综合成和谐的整体，确定像素集之间的联系以便将它们彼此分割开，或推断一些形状信息，使用几何信息或概率统计技术来识别物体。\n但实际提及时， 主观感觉上MV 更多注重广义图像信号（激光，摄像头）与自动化控制（生产线）方面的应用。\nCV 更多注重（2D, 3D）图像信号本身的研究以及和图像相关的交叉学科研究（医学图像分析，地图导航）。\nWikipedia 转来个图：\n作者：胡知知\n链接：https://www.zhihu.com/question/23183532/answer/23896265\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}
{"content2":"计算机视觉—Harris角点检测\nbrycezou@163.com\n1、全微分\n定义：如果函数\nz=f(x,y)\nz=f(x,y) 在定义域\nD\nD 的内点\n(x,y)\n(x,y) 处全增量\nΔz=f(x+Δx,y+Δy)−f(x,y)\n\\Delta z=f(x+\\Delta x,y+\\Delta y)-f(x,y) 可以表示成\nΔz=AΔx+BΔy+o(ρ),ρ=(Δx)2+(Δy)2‾‾‾‾‾‾‾‾‾‾‾‾‾‾√\n\\Delta z=A\\Delta x+B\\Delta y+o(\\rho),\\quad \\rho=\\sqrt{(\\Delta x)^2+(\\Delta y)^2}\n其中，\nA,B\nA,B 不依赖于\nΔx,Δy\n\\Delta x,\\Delta y ，仅与\nx,y\nx,y 有关，则称函数\nf(x,y)\nf(x,y) 在点\n(x,y)\n(x,y) 可微。\nAΔx+BΔy\nA\\Delta x+B\\Delta y 称为函数\nf(x,y)\nf(x,y) 在点\n(x,y)\n(x,y) 的全微分，记作\ndz=df=AΔx+BΔy\ndz=df=A\\Delta x+B\\Delta y\n若函数在\nD\nD 内各点都可微，则称此函数在\nD\nD 内可微。\n近似：当\nz=f(x,y)\nz=f(x,y) 在点\n(x,y)\n(x,y) 的两个偏导数\nfx(x,y)\nf_x(x,y) 和\nfy(x,y)\nf_y(x,y) 连续，且\n|Δx|,|Δy|\n|\\Delta x|,|\\Delta y| 都较小时，有近似等式\nΔz≈dz=fx(x,y)Δx+fy(x,y)Δy\n\\Delta z\\approx dz=f_x(x,y)\\Delta x+f_y(x,y)\\Delta y\n或者\nf(x+Δx,y+Δy)≈f(x,y)+fx(x,y)Δx+fy(x,y)Δy\nf(x+\\Delta x,y+\\Delta y)\\approx f(x,y)+f_x(x,y)\\Delta x+f_y(x,y)\\Delta y\n2、常用公式\n[Ax+By]2=[xy][A2ABABB2][xy]\n[Ax+By]^2=[\\begin{matrix}x & y\\end{matrix}]\\left[\\begin{matrix}A^2 & AB\\\\AB & B^2\\end{matrix}\\right]\\left[\\begin{matrix}x\\\\y\\end{matrix}\\right]\n3、角点检测\n寻找角点的基本思想：观察一个小窗口所包含的区域，在角点附近向任何方向移动窗口，灰度值都会有较大的变化。如左图，在平坦区域，在任何方向灰度值都没有变化；如中图，沿着边缘方向灰度值无变化；如右图，在多个方向上灰度值都有变化。\n\n在平移\n[u,v]\n[u,v] 下的灰度变化为：\nE(u,v)=∑x,yw(x,y)[I(x+u,y+v)−I(x,y)]2\nE(u,v)=\\sum_{x,y}w(x,y)[I(x+u,y+v)-I(x,y)]^2\n其中，\nw(x,y)\nw(x,y) 是一个以\n(x,y)\n(x,y) 为中心的窗函数，\nI(x,y)\nI(x,y) 是\n(x,y)\n(x,y) 处的像素值。为了寻找带角点的窗口，需要搜索像素灰度变化较大的窗口。于是, 我们期望最大化\nE(u,v)\nE(u,v) 。\n假设\nu\nu 和\nv\nv 很小，则有\nI(x+u,y+v)−I(x,y)≈Ixu+Iyv\nI(x+u,y+v)-I(x,y)\\approx I_xu+I_yv\n[I(x+u,y+v)−I(x,y)]2≈[Ixu+Iyv]2=[uv][I2xIxIyIxIyI2y][uv]\n[I(x+u,y+v)-I(x,y)]^2\\approx [I_xu+I_yv]^2=[\\begin{matrix}u & v\\end{matrix}]\\left[\\begin{matrix}I_x^2 & I_xI_y\\\\I_xI_y & I_y^2\\end{matrix}\\right]\\left[\\begin{matrix}u\\\\v \\end{matrix}\\right]\n因此，对于小平移\n[u,v]\n[u,v] 可作如下近似\nE(u,v)≈[uv]  M[uv]\nE(u,v)\\approx [\\begin{matrix}u & v\\end{matrix}]\\ \\ M\\left[\\begin{matrix}u\\\\v\\end{matrix}\\right]\n其中，\nM\nM 是一个\n2×2\n2\\times2 矩阵，\nM=∑x,yw(x,y)[I2xIxIyIxIyI2y]\nM=\\sum_{x,y}w(x,y)\\left[\\begin{matrix}I_x^2 & I_xI_y\\\\I_xI_y & I_y^2\\end{matrix}\\right]\n协方差矩阵可以表示多维随机变量之间的相关性。协方差矩阵的对角线元素表示的是各个维度的方差，而非对角线上的元素表示的是各个维度之间的相关性。可以把矩阵\nM\nM 看作一个二维随机分布的协方差矩阵，通过将其对角化，求矩阵的两个特征值，然后根据这两个特征值来判断是不是角点。\n设\nλ1,λ2\n\\lambda_1,\\lambda_2 为矩阵\nM\nM 的特征值，当\nλ1≫λ2\n\\lambda_1\\gg\\lambda_2 或\nλ1≪λ2\n\\lambda_1\\ll\\lambda_2 时，为边缘点；当\nλ1\n\\lambda_1 和\nλ2\n\\lambda_2 都很小且接近时，为平坦区域内的点；当\nλ1\n\\lambda_1 和\nλ2\n\\lambda_2 都很大且接近时，说明图像窗口在各个方向上移动都产生了明显灰度变化，为角点。\n\n由于特征值的计算量较大，因此，实际中采用角点响应函数来检测角点。角点响应函数定义为\nR=det(M)−k∗[trace(M)]2=λ1λ2−k∗(λ1+λ2)2\nR=det(M)-k*[trace(M)]^2=\\lambda_1\\lambda_2-k*(\\lambda_1+\\lambda_2)^2\nk\nk 的经验取值一般为\n0.04−0.06\n0.04-0.06 ，\nR\nR 依赖于\nM\nM 的特征值，\nR\nR 较大时，为角点；\nR\nR 值较大且为负时，为边缘；\n|R|\n|R| 较小时，为平坦区域。最终，\nHarris\nHarris 角点检测就是：寻找有大角点响应函数\nR\nR 的点（\nR>thres\nR>thres），且是\nR\nR 的局部极大值的点。"}
{"content2":"OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。\nOpenCV用C++语言编写，它的主要接口也是C++语言，但是依然保留了大量的C语言接口。该库也有大量的Python、Java and MATLAB/OCTAVE（版本2.5）的接口。这些语言的API接口函数可以通过在线文档获得。如今也提供对于C#、Ch、Ruby,GO的支持。\n所有新的开发和算法都是用C++接口。一个使用CUDA的GPU接口也于2010年9月开始实现。\n中文名:开源计算机视觉库\n外文名:Open Source Computer Vision Library\n简    称:OpenCV\n功    能:提供Python、Ruby、MATLAB接口\n结    构:C 函数和C++ 类构成\nOpenCV于1999年由Intel建立，如今由Willow Garage提供支持。OpenCV是一个基于BSD许可 [1]  （开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows和Mac OS操作系统上。它轻量级而且高效——由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。 [2]  最新版本是3.4 ，2017年12月23日发布 [3]  。\nOpenCV 拥有包括 500 多个C函数的跨平台的中、高层 API。它不依赖于其它的外部库——尽管也可以使用某些外部库。\nOpenCV 为Intel® Integrated Performance Primitives（IPP）提供了透明接口。这意味着如果有为特定处理器优化的 IPP 库，OpenCV 将在运行时自动加载这些库。 [4]\n（注：OpenCV 2.0版的代码已显著优化，无需IPP来提升性能，故2.0版不再提供IPP接口）\n65款 计算机视觉库 人脸识别开源软件 模式识别库\nhttp://www.cnblogs.com/Anita9002/p/5038533.html"}
{"content2":"计算机视觉——图像理解简介\n图像理解的三个层次\n一是分类（Classification）\n将图像结构化为某一类别的信息，用事先确定好的类别(string)或实例ID来描述图片。\n二是检测（Detection）\n检测关注特定的物体目标，要求同时获得这一目标的类别信息和位置信息。\n三是分割（Segmentation）\n分割包括语义分割（semantic segmentation）和实例分割（instance segmentation）\n简单来说，前者不区分属于相同类别的不同实例，而后者区分\n相关网络\nFaster RCNN [2016]\n经过R-CNN和Fast RCNN的积淀，Ross B. Girshick在2016年提出了Faster RCNN\n将CNN引入目标检测的开山之作\n网络结构如下：\nConv layers\n作为一种CNN网络目标检测方法，Faster RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。\nRegion Proposal Networks\nRPN网络用于生成region proposals（表示物体可能存在的位置）\nFaster RCNN则抛弃了传统的滑动窗口和SS(Selective Search)方法，直接使用RPN生成检测框\n极大提升检测框的生成速度\nROI Pooling\n该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。\n可以显著加速training和testing速度\nClassification\n利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。\nMask RCNN [2017]\nby Kaiming He & Georgia Gkioxari & Piotr Dollar & Ross Girshick\n沿用了Faster RCNN的思想，特征提取采用ResNet-FPN的架构，另外多加了一个Mask预测分支\n网络结构：\nMask RCNN只是在ROI pooling（实际上用到的是ROIAlign）之后添加卷积层，进行mask预测的任务\nMask R-CNN提出了RoIAlign（双线性内插）的方法来取代ROI pooling\nMask Scoring RCNN [2019.3]\n一作黄钊金，华中科技大学的硕士生，师从华中科技大学电信学院副教授王兴刚\n在COCO图像实例分割任务上超越了何恺明的Mask R-CNN\nMask RCNN虽然输出结果是一个蒙版，但打分却是和边界框目标检测共享的，都是针对目标区域分类置信度算出来的分数。\n这个分数，和图像分割蒙版的质量可未必一致，用来评价蒙版的质量，可能就会出偏差。\n提出了一种给算法的“实例分割假设”打分的新方法：\n不仅仅直接依靠检测得到的分类算分，而且还让模型单独学一个针对蒙版的得分规则：MaskIoU head\nMaskIoU head是在经典评估指标AP（平均正确率）启发下得到的，会拿预测蒙版与物体特征进行对比\n同时考虑分类得分与蒙版的质量得分，去评估算法质量\n评测方法公平公正，模型性能自然也上去了\nTensorflow object detection api\nThe TensorFlow Object Detection API is an open source framework built on top of TensorFlow that makes it easy to construct, train and deploy object detection models.\n可以使用自己的数据集进行训练，不过必须先把它转换为TFRecord文件格式\n在Tensorflow detection model zoo有多种预训练的模型，可直接使用\n在自己的照片上进行探测\n可执行多分类任务，也可以指定识别对象\nTensorflow DeepLab\n(Deep Labelling for Semantic Image Segmentation)\nDeepLab is a state-of-art deep learning model for semantic image segmentation, where the goal is to assign semantic labels (e.g., person, dog, cat and so on) to every pixel in the input image.\nResources\nROI pooling详解\ntensorflow object_detection\ntensorflow deeplab"}
{"content2":"揭开人工智能神秘的面纱—3920人已学习\n课程介绍\n从无人驾驶汽车技术到AlphaGo战胜人类，人工智能技术在生活中扮演着越来越重要的角色，也即将改变这个世界。本节课程带领大家一步步揭开人工智能神秘的面纱，探索其背后的核心技术！人工智能的闪亮登场伴随着太多神秘的色彩，华丽的外表下究竟是怎样的黑科技在支撑着人工智能的发展，就让我们在这节课中为大家一一揭晓。\n课程收益\n1.人工智能概述与深度学习应用场景（10分钟） 2.神经网络模型（30分钟） 3.深度学习框架caffe与tensorflow简介（10分钟） 4.后续学习路线图与答疑（看同学问题一般15分到30分）\n讲师介绍\nCSDN公开课更多讲师课程\nCSDN线上公开课全掌握！\n课程大纲\n1.揭开人工智能神秘的面纱（上）  34:43\n2.揭开人工智能神秘的面纱（下）  34:44\n大家可以点击【查看详情】查看我的课程"}
{"content2":"转自知乎计算机视觉，计算机图形学和数字图像处理，三者之间的联系和区别是什么？\n一个很好的说明"}
{"content2":"最近一年发现自己已经黔驴技穷了，Qt的路上感觉走到了尽头，工作没有挑战性，也没有了新鲜感，但是这一年的自动化产品的接触，感觉工业视觉是我真正喜欢的东西，于是这个周末开始了halcon的学习！-----花了几百块钱淘宝买了一些视频和资料，总体感觉入门还是没有什么问题的。\n第一步分清楚的就是  计算机视觉 和 工业视觉 区别，以及选择学习OpenCV 还是 halcon 的理由。\n百度了一下，说计算机视觉适合于分辨物体，比如 视频中出现的 单身狗和情侣的区别，视频中窜入的电灯泡等等，通过大体的网络学习就可以做到，而这一类的通常会选择学习opencv，可以融入自己的算法，并且可以支持python。而工业视觉需要的很多都是测量，缺陷判断，log是否有问题，定位，等等，要求精度高。这一年接触到的事例有：定位孔的识别，并且配合PLC进行精确转孔；塑料盒的盒盖，机械手抓取盖子判断盖子是否有缺陷同时定位盒子进行精确盒盖；残品LOG镭射以及标签LOG是否存在角度偏差等等，这一类的需求就是所谓工业视觉的范畴了。所以看多了也就懂了一点点了，决定入手Halcon，今后进军工业视觉领域，同时可以兼容自动化产线的信息化编程，可谓是一举两得，三板斧应该可以让我再蹦跶几年了！"}
{"content2":"2017年中国国务院《新一代人工智能发展规划》中预计，到2020年人工智能总体技术和应用与世界先进水平同步，人工智能核心技术超过1500亿元，中国人工智能产业发展迅速，市场规模不断攀升，人工智能企业数量也在不断增长。但目前人工智能技术应用存在风险，计算机视觉方面存在人脸识别漏洞等问题;语音识别存在泄露风险，语音助手或成非法监听重灾区。iiMedia Research(艾媒咨询)数据显示，网民认为人工智能技术中无人驾驶汽车是风险最高，超六成中国网民认为人工智能或造成失业问题。\n(《艾媒报告| 2019中国人工智能发展风险预警白皮书 》完整高清PDF版共59页，欢迎加v：iimediaLucy，参与更多行业交流。）\n以下为报告节选内容：\n中国人工智能发展备受国家重视\n中国人工智能市场规模未来将不断攀升\n2017年中国国务院《新一代人工智能发展规划》中预计，到2020年人工智能总体技术和应用与世界先进水平同步，人工智能核心技术超过1500亿元;到2025年，人工智能基础理论实现重大突破，部分技术和应用达到世界领先水平，核心技术规模超过4000亿元。\n中国人工智能产业链全面落地\n基于深度学习的人工智能发展受限于框架条件\n作为必备基础的大数据 风险存在于各个阶段\n深度学习是人工智能的基础技术之一，深度学习算法的实现基于海量的数据。反过来，数据的质量又决定了深度学习模型的最终实现效果。\n深度学习系统本身面临多种安全威胁\n人脸识别技术存在漏洞或将导致安防失效\n语音小助手的传感器可作为监听设备使用\n语音小助手是现阶段受欢迎的人工智能应用之一，开发商更看重语音助手的便捷性和灵敏性，往往对语音助手的安全性有所忽略，这其中包括识别人耳听不到的声音和各智能助理相互间的语音识别。\n人工智能在教育领域应用的风险\n人工智能推动了教育的改革与创新，为智慧校园的建设提供了助力。目前在大学阶段的部分等级考试中已经应用了人脸识别技术，部分校外辅导机构也运用了人工智能为每一位学生提供定制化学习攻略。\n人工智能在军事领域的应用对国家安全造成威胁\n人工智能对人类现存法律伦理的挑战\n58.1%的中国网民愿意尝试无人驾驶汽车\niiMedia Research(艾媒咨询)数据显示，58.1%的中国网民愿意尝试无人驾驶汽车。\n64.1%的中国网民认为人工智能是存在风险\niiMedia Research(艾媒咨询)数据显示，64.1%的中国网民认为人工智能是存在风险/安全威胁的。\n中国网民对人工智能风险认知尚不全面\niiMedia Research(艾媒咨询)数据显示，40.3%的网民认为人工智能带来的最大危害就是个人信息泄露，其比重相对较高。艾媒咨询分析师认为，中国网民现阶段对人工智能存在的危害认知尚不全面。\n41.4%的网民认为无人驾驶汽车是风险最高\niiMedia Research(艾媒咨询)数据显示，41.4%的网民认为无人驾驶汽车是现阶段风险最高的人工智能产品，其次是智能摄像头(40.9%)和指纹锁(38.1%)。艾媒咨询分析师认为，无人驾驶汽车、摄像头和指纹锁都是与人类近距离接触且能产生直接效果的人工智能产品，这类产品无论是否存在技术不足，都与人类的利益攸兮相关。\n超六成中国网民认为人工智能或造成失业\niiMedia Research(艾媒咨询)数据显示，45.0%的中国网民认为人工智能可能造成失业，18.5%的网民则认为人工智能非常有可能造成失业。\n超过一半网民认为人工智能技术存在小程度的歧视性\niiMedia Research(艾媒咨询)数据显示，59.9%的中国网民认为人工智能技术存在歧视性问题，但是程度较小。\n网民认为人工智能对人类构成威胁的原因\niiMedia Research(艾媒咨询)数据显示，中国网民认为人工智能技术会引发大数据信息泄露，占比达38.6%。其次是人工智能或使得人类生存能力降低，占比为31.6%。\n人工智能技术未来将获得更多重视和发展机会\n大数据保护将引起全面重视 或成未来焦点\n教育和技术的共同进步才能维护人类的优势地位\n关于艾媒咨询\niiMedia Research(艾媒咨询)是全球知名的新经济产业第三方数据挖掘和分析机构，2007年诞生于广州，在广州、香港、北京、上海、硅谷设有运营和分析机构。艾媒咨询致力于输出有观点、有态度、有结论的研究报告，以权威第三方实力，通过艾媒大数据决策和智能分析系统，结合具有国际化视野的艾媒分析师观点，在产业数据监测、调查分析和趋势发展等方向的大数据咨询具有丰富经验。艾媒每年公开或定制发布新经济前沿报告超过2000份，覆盖了人工智能、新零售、电商、教育、视频、生物、医疗、音乐、出行、房产、营销、文娱、传媒、金融、环保与公共治理等领域，通过深入数据挖掘，通过数学建模，分析推理与科学算法结合，打造有数据、有理论支撑的大数据分析成果。艾媒咨询的数据报告、分析师观点平均每天被全球超过100家主流媒体，1500家(个)自媒体、行业KOL广泛引用，覆盖语言类型包括中、英、日、法、意、德、俄、阿等约二十种主流官方版本。\n基于公司独立自主研发的“中国移动互联网大数据挖掘与分析系统(CMDAS)”，艾媒咨询建立了互联网运营数据、企业舆情和商情、用户属性和行为偏好、零售数据挖掘、广告投放效果、商业模式等多维度的数据监测体系，可视化还原“数据真相”，实现市场趋势的捕捉和用户信息的洞察，提升品牌的行业竞争和影响力。"}
{"content2":"【ImageNet】\nImageNet 项目是一个用于物体对象识别检索大型视觉数据库。截止2016年，ImageNet 已经对超过一千万个图像进行手动注释，标记图像的类别。在至少一百万张图像中还提供了边界框。\n自2010年以来，ImageNet 举办一年一度的软件竞赛，叫做（ImageNet Large Scale Visual Recognition Challenge,ILSVRC)。主要内容是通过算法程序实现正确分类和探测识别物体与场景，评价标准就是Top-5 错误率。\nTop-5错误率\n即对一个图片，如果概率前五中包含正确答案，即认为正确。\nTop-1错误率\n即对一个图片，如果概率最大的是正确答案，才认为正确。\n原po：https://www.jianshu.com/p/46e812c1d670"}
{"content2":"一、机器视觉与计算机视觉的区别与联系\n在很多情况下，我们误认为机器视觉就是计算机视觉，其实这是不准确的。何为机器视觉？何为计算机视觉？首先我们从定义着手，机器视觉其实就是用机器代替人眼进行测量和判断。计算机视觉是利用计算机和其辅助设备来模拟人的视觉功能，实现对客观世界的三维场景的感知、识别和理解。机器视觉和计算机视觉不仅是两个不同的概念，而且侧重点也不同。机器视觉侧重工程的应用，强调实时性、高精度和高速度；而计算机视觉侧重理论算法的研究，强调理论，由于理论的研究发展速度往往快于实践应用，也就是说计算机视觉的发展速度要远远超过了其时间生产的应用速度，因此计算机视觉的很多技术目前还难以应用到机器视觉上。但是二者还是共用一套理论系统，只是发展的方向不同而已，一个侧重实际应用，一个侧重理论算法的研究，不能说谁替代谁，各有千秋。\n二、近年来视觉发展的状况和遇到的瓶颈\n1、算法瓶颈。机器视觉研究对象主要是图像和视频，我们所采集的图像和视频，其特点是大数据、冗余信息多、特征空间维度高，同时考虑到真正的机器视觉面对的对象和问题的多样性，单一的简单特征提取算法（如颜色、空间朝向与频率、边界形状等等）难以满足算法对普适性的要求，因此在设计普适性的特征提取算法时对计算能力和存储速度的要求是十分巨大的，这就造成了开发成本的大幅度提高。\n2、场景认知问题。如何让机器认知这个世界？这一问题目前没有成熟的答案，也是目前科学家一直在研究的热点方向。早期的人工智能理论发展经历了符号主义学派、行为主义学派、连接主义学派等一系列的发展但都没有找到令人满意的答案，目前较新的思想认为应该从分析、了解和模拟人类大脑的信息处理功能去构建智能机器视觉系统，但神经科学的发展目前只能做到了解和模拟大脑的一个局部，而不是整体（当然计算能力限制也是原因之一）。事实上，我们对人是如何对一个目标或场景进行认知的这一问题仍停留在定性描述而非定量描述上。\n3、准确性问题。机器视觉系统经常被人诟病的问题之一就是准确性。以十年前如火如荼的人脸识别算法为例，尽管一系列看似优秀的算法不断问世，但目前为止那些算法都是在指定的样本库中进行的，而在非指定大规模样本库下进行人脸识别的准确率仍然无法满足实际应用的需求，因此无法取代指纹或虹膜等近距接触式生物特征识别方法。这一问题的出现并非偶然。因为目标越精细，越复杂，信息越大，则其模糊性和不确定性也越强。人类之所以能够较好的对人脸进行识别，其实也是以牺牲一定的准确性为代价的。而机器视觉在做的事情一方面想要借鉴人脑或人眼系统的灵感去处理复杂而庞大的信息流，另一方面又想摒除人脑在模式识别方面存在的精确性不足的缺陷。这显然是一种一厢情愿的做法。\n4、鲁棒性问题。相比与其他测量手段，视觉的最大优点就是可以快速获得三维信息，一张或几张照片就可以重建出被测物体的三维特征，进而实现测量。但正如我们所知道的，只要测量条件、环境、被测物表面特性等改变，有时甚至时稍加改变，结果则大不一样，测量重复性和精度更无从谈起。这也是目前机器视觉测量尺寸、位姿等参数时比较突出的问题，特别是在一些强光干扰、温度场变化、光照条件变化的应用场合这个问题尤为突出。\n5、人才的缺少。目前真正意义上的从业人员缺少科班出身，缺少对图像处理的底层理论认知和理解。机器视觉中图像处理是极为重要的一环，而目前大多数从业人员是本科或者大专毕业，或者是电气工程师新入行，基本都比较缺乏图像处理的基本理论。虽然相对于普通的自动化从业者而言，机器视觉工程师待遇还是不错的，但是却难以吸引到硕士或者博士进行过专门图像处理学术训练的人加入，因为随便加入那个互联网大公司做图像相关工作，待遇都能把自动化从业的工程师甩出几条大街。另外，机器视觉更多的应用是属于自动化设备这一块。而自动化属于比较交叉的学科，涉及到机器视觉，需要了解的东西包括、电气、运动控制、机械、光学、软件编程等。这些学科了解一些基本的东西不难，但是研究的比较透彻并能高效率的综合运用就比较难了。\n目前的工业上视觉方面应用主要有：检测、测量、识别和定位。而这几个方面机器视觉还没有一个能真正意义上实现批量化检测的同时保证极高的准确率，极小的误检率和杜绝漏检。这个目标不能实现，降低了机器视觉的应用预期。因为机器视觉设备不能完全解决，还是需要人复查，除非客户的标准没有那么高。这也导致目前机器视觉在工业上应用没有那么快普及的原因之一。为什么机器视觉会遇到瓶颈？主要是过不了客户那一关——高精度、高速度、高准确率，并且实时性还要好。\n国内硬件核心部件（相机和镜头）和软件算法包还是老外的产品领先，国内也出现了一些替代产品，从性能上和老外PK还有很大的差距。\n参考文献\n1、http://www.zhihu.com/question/20023867"}
{"content2":"（一）简单理解与准备工作\n1.计算机视觉是什么\n一个模拟人眼识别的结果\n让计算机去认知，也就是人工智能\n2.计算机视觉的用处\n智能汽车、体感游戏、监控追踪、人脸识别、AR/VR、三维重建、测距等等\n3.对图像的认识\n图像是一种随时间推移的波形图，傅里叶公式将图像从时域中转换到频域中，如下图所示：\n4,配置opencv\n大致步骤如下：\n（1）首先在官网下载opencv，VS2015版本需要适配3.1.0，VS2015之前的版本适配3.0.0即可\n（2）下载安装之后，配置环境变量：选择此电脑，右键属性->高级系统设置->环境变量->系统变量->Path->在变量值中添加相应路径,比如我配置的VS2015的路径为D:\\Opencv3.1.0\\opencv\\build\\x64\\vc14\\bin\n注意：根据VS的版本和编译器位数选择路径，VS2015只能配置64位；如果VS2013选择VC12文件夹\n（3）打开VS，新建一个Visual C++新建Win32控制台项目，注意选择空项目，新建源文件，打开属性管理器，找到Debug|x64（或Wn32）文件夹，找到Microsoft.Cpp.x64.user（或Microsoft.Cpp.win32.user）文件，右键属性，选择通用属性下的VC++目录，在包含目录下添加三条路径D:\\Opencv3.1.0\\opencv\\build\\include D:\\Opencv3.1.0\\opencv\\build\\include\\opencv D:\\Opencv3.1.0\\opencv\\build\\include\\opencv2，然后在库目录下添加一条路径：D:\\Opencv3.1.0\\opencv\\build\\x64\\vc14\\lib\n（4）再点击链接器，选择输入，在附加依赖项处添加文件：opencv_world310d.lib\n（5）最后保存属性表，即可永久配置\nPS：以上为DEBUG模式下的配置，如果要配置Release模式，步骤均相同，只要第（4）步添加文件时，把d去掉即可\n(二)图像的预处理\n首先输入头文件\n#include<iostream> using namespace std; #include<opencv.hpp> using namespace cv;\n包括C++编译所需要的和使用opencv所需要的\n1.读取摄像机和视频\n代码如下：\nVideoCapture cap(0); while (true) { Mat frame;//Mat即矩阵Matrix的缩写，opencv最基本的数据结构，初始化一个框架 cap >> frame;//读取了一帧图像保存在frame namedWindow(\"123\",0 );//新建一个窗口 imshow(\"123\", frame);//显示窗口 waitKey(30);//在imshow之后如果没有waitKey语句则不会正常显示图像，30即延迟30ms，具体数字根据帧率来定 }\n2.读取图片与其中的像素值\n代码如下：\nMat imggray=imread(\"123.jpg\",1);//初始化并读取一个图片，注意图片存储文件位置 //参数0表示灰度图 参数1表示三通道彩图 //CV_8UC1单通道灰度图 CV_8UC3三通道彩图 cvtColor(imggray, imggray, CV_RGB2GRAY);//彩图转换为灰度图 imshow(\"123\", imggray); waitKey(0); cout <<(int)imggray.at<uchar>(1, 1)<<endl;//第二行第二列元素转化成整型输出，读取像素值\n3.创建图像和一些常用方法（Mat对象的一些操作）\n代码如下：\nMat image = Mat::eye(5, 5, CV_64FC1);//zeros全初始化为0 ones全为1 eye单位矩阵 cout << image<< endl; Mat imgone = Mat::ones(5, 5, CV_64FC1);//矩阵加减法 行数列数和类型必须完全一样 Mat sum = image + imgone;//也可换成- *等其他运算符 cout << sum << endl; image.copyTo();//copyTo拷贝 t转置 inv逆矩阵\n4.对一个图像在x方向上的求导的非卷积操作\n以对一个5×5的图像在x方向上的求导为例，由求导公式D(x)=f(x+1，y)-f(x-1,y)可知，图像边界处的元素无法求导，则应对5×3的元素求导。\n代码如下：\nVideoCapture cap(0); while (true) { Mat frame; cap >> frame; cvtColor(frame, frame, CV_RGB2GRAY);//转换为灰度图 cout << \"row\" << frame.rows << \"col\" << frame.cols << endl; Mat dimg = Mat(frame.rows, frame.cols - 2, CV_8UC1);//定义一个5×3的灰度图 for (int i = 0; i < frame.rows; i++)//5行不变 { for (int j = 1; j < frame.cols - 1; j++) //边界的元素无法求导，所以是3列，从第2列的元素开始 { dimg.at<uchar>(i, j - 1) = frame.at<uchar>(i, j - 1) - frame.at<uchar>(i, j + 1); //对5行5列求导，5行3列，从第一行第二列的元素开始 } } imshow(\"123\", dimg); waitKey(10); }\n5.图像卷积（求导的卷积操作）（滤镜）\n卷积就是加权求和，卷积模板就是权值。\n可根据图片理解，如下图：\n以用一个1×3的卷积模板对图像卷积为例\n代码如下：\nVideoCapture cap(0); while (true) { Mat frame; cap >> frame; cvtColor(frame, frame, CV_RGB2GRAY); cout << \"row\" << frame.rows << \"col\" << frame.cols << endl; Mat dimg = Mat(frame.rows, frame.cols - 2, CV_8UC1); Mat model = Mat(1, 3, CV_64FC1); //定义一个1*3的卷积模板 model.at<double>(0, 0) = 1; model.at<double>(0, 1) = 0; model.at<double>(0, 2) = -1; //先用两重循环得到求导后结果 for (int i = 0; i < frame.rows; i++) { for (int j = 1; j < frame.cols - 1; j++) { //再进行两重循环，用卷积模板对求导结果进行卷积 int half = model.cols / 2; double sum = 0; for (int m = 0; m < model.rows; m++) { for (int n = -half; n < model.cols - half; n++) { sum += frame.at<uchar>(i + m, j + n)*model.at<double>(m, n + half); } } dimg.at<uchar>(i, j - 1) = (uchar)sum; } } imshow(\"123\", dimg); waitKey(10); }\n6.高斯模糊的核创建与卷积操作\n正态分布的密度函数公式如下：\n代码如下：\nMat gauss(5, 5, CV_64FC1);//创建高斯图 double sigma = 50;//定义并初始化模糊度 for (int i = -2; i < 3; i++) { for (int j = -2; j < 3; j++) { gauss.at<double>(i + 2, j + 2)=exp(-(i*i + j*j) / (2 * sigma*sigma));//直接用exp()套用公式 } } double gssum=sum(gauss).val[0]; for (int i = -2; i < 3; i++) { for (int j = -2; j < 3; j++) { gauss.at<double>(i + 2, j + 2) /= gssum; //归一化操作 } } cout << gauss << endl;//opencv可直接输出图像 //进行卷积操作 VideoCapture cap(0); while (true) { Mat frame; cap >> frame; cvtColor(frame, frame, CV_RGB2GRAY); Mat dimg = Mat(frame.rows - 4, frame.cols - 4, CV_8UC1); for (int i = 2; i < frame.rows - 2; i++) { for (int j = 2; j < frame.cols - 2; j++) { //与上面不同的是，没有定义half，本质相同，分别加权求和进行卷积 double sum = 0; for (int m = 0; m < gauss.rows; m++) { for (int n = 0; n < gauss.cols; n++) { sum += (double)(frame.at<uchar>(i + m - 2, j + n - 2))*gauss.at<double>(m, n);//原图强制类型转换为double } } dimg.at<uchar>(i - 2, j - 2) = (uchar)sum; } } //显示原图与模糊后的图进行对比 imshow(\"a\", frame); imshow(\"gauss\", dimg); waitKey(10); }\n7.调用API进行高斯模糊、边缘检测\n代码如下：\nVideoCapture cap(0); while (true) { Mat frame; cap >> frame; cvtColor(frame, frame, CV_RGB2GRAY); //调用时需要的参数会在VS中显示 GaussianBlur(frame,frame,cvSize(5,5),10,10); //利用GaussianBlur()输入参数直接进行高斯模糊 Canny(frame, frame, 100, 100); //利用Canny算子进行边缘检测 Sobel(frame, frame, 0, 1, 1); //利用Sobel算子进行边缘检测，可与Canny算子对比，更加明显 imshow(\"a\", frame); waitKey(10); }"}
{"content2":"简介\n每年全世界都会举办很多计算机视觉（Computer Vision，CV）、 机器学习（Machine Learning，ML）、人工智能（Artificial Intelligence ，AI）领域的学术会议。笔者选取了其中影响力较大，有代表性的重要会议进行了汇总，特意按照时间进行了排序，方便大家查看。如有遗漏，还请留言补充。文末有福利呢！\nUAI 2018\n会议名称：Conference on Uncertainty in Artificial Intelligence\n会议地点：美国加州蒙特雷\n会议时间：2018.08.06 - 10\n网址：http://auai.org/uai2018\n介绍：ML特定子领域的高质量会议，今年的已经举行。\nECCV 2018\n会议名称：European Conference on Computer Vision\n会议地点：德国慕尼黑\n会议时间：2018.09.08 - 14\n网址：https://eccv2018.org\n介绍：计算机视觉及模式识别领域国际三大顶级会议之一，今年的已经举行。\nACCV 2018\n会议名称：Asian Conference on Computer Vision\n会议地点：澳大利亚佩斯\n会议时间：2018.12.02 - 06\n网址：http://accv2018.net\n介绍：亚洲的计算机视觉会议\nNIPS 2018\n会议名称：Neural Information Processing Systems\n会议地点：加拿大蒙特利尔\n会议时间：2018.12.03 - 08\n网址： https://nips.cc/Conferences/2018\n介绍：Machine learning , computational neuroscience领域国际顶级会议\nICMLA 2018\n会议名称：International Conference On Machine Learning And Applications\n会议地点：美国佛罗里达\n会议时间：2018.12.17 - 20\n网址：\nhttp://www.icmla-conference.org/icmla18\nMMM 2019\n会议名称：25th International Conference on MultiMedia Modeling\n会议地点：希腊塞萨洛尼基\n会议时间：2019.01.08-11\n网址：http://mmm2019.iti.gr/\n介绍：多媒体建模及应用领域国际权威会议\nAAAI 2019\n会议名称：Association for the Advancement of Artificial Intelligence\n会议地点：美国夏威夷\n会议时间：2019.01.27 - 02.01\n网址：http://www.aaai.org/aaai19\n介绍：人工智能领域顶级会议\nICIGP 2019\n会议名称：2ND INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING\n会议地点：新加坡\n会议时间：2019.02.23-25\n网址：http://icigp.org/\n介绍：促进学术界和工业界交流的图形图像处理会议\nICIAI2019\n会议名称：The 3rd International Conference on Innovation in Artificial Intelligence\n会议地点：中国苏州\n会议时间：2019.03.15- 18\n网址：http://www.iciai.org/\n介绍：人工智能创新国际会议\nALT 2019\n会议名称：International Conference on Algorithmic Learning Theory\n会议地点：美国芝加哥\n会议时间：2019.03.22 - 24\n网址：http://alt2019.algorithmiclearningtheory.org\n介绍：计算机学习理论较好的会议\nCVM2019\n会议名称：Computational Visual Media Conference\n会议地点：英国巴斯\n会议时间：2019.04.24 - 26\n网址：http://iccvm.org/2019/\n介绍：计算机视觉相关的基础研究和应用会议\nICLR 2019\n会议名称：International Conference on Learning Representations\n会议地点：美国新奥尔良\n会议时间：2019.05.06 - 09\n网址： http://www.iclr.cc\n介绍：神经网络顶会\nAAMAS 2019\n会议名称：International Conference on Autonomous Agents and Multiagent Systems\n会议地点：加拿大蒙特利尔\n会议时间：2019.05.13 - 17\n网址：http://aamas2019.encs.concordia.ca\n介绍：Agent方面最好的会议之一\nICML 2019\n会议名称：International Conference on Machine Learning\n会议地点：美国加利福尼亚\n会议时间：2019.06.10 - 15\n网址：https://icml.cc/Conferences/2019\n介绍：机器学习领域国际著名会议\nCVPR 2019\n会议名称： IEEE Conference on Computer Vision and Pattern Recognition\n会议地点：美国洛杉矶\n会议时间：2019.06.15 - 21\n网址：http://cvpr2019.thecvf.com\n介绍：计算机视觉及模式识别领域国际三大顶级会议之一\nCOLT 2019\n会议名称：Conference on Learning Theory\n会议地点：美国亚利桑那州\n会议时间：2019.06.25 - 28\n网址：http://www.learningtheory.org/colt2019\n介绍：计算机学习理论最好的会议之一\nICME 2019\n会议名称：International Conference on Multimedia and Expo\n会议地点：中国上海\n会议时间：2019.07.08 - 12\n网址：http://www.icme2019.org\n介绍：多媒体方面比较好的会议\nGECCO 2019\n会议名称：Genetic and Evolutionary Computation Conference\n会议地点：捷克布拉格\n会议时间：2019.07.13 - 17\n网址： https://gecco-2019.sigevo.org\n介绍：进化计算方面最重要的会议之一\nIJCNN 2019\n会议名称：International Joint Conference on Neural Networks\n会议地点：匈牙利布达佩斯\n会议时间：2019.07.14 - 19\n网址：https://www.ijcnn.org\n介绍：神经网络方面最重要的会议, 盛会型\nSIGGRAPH 2019\n会议名称：Computer Graphics and Interactive Techniques\n会议地点：美国洛杉矶\n会议时间：2019.07.29 – 08.01\n网址： http://s2019.siggraph.org\n介绍：计算机图形学领域最权威、影响力最大的国际会议\nIJCAI 2019\n会议名称：International Joint Conference on Artificial Intelligence\n会议地点：中国澳门\n会议时间：2019.08.10 - 16\n网址：http://www.ijcai19.org\n介绍：人工智能领域中最主要的学术会议之一\nPRICAI 2019\n会议名称：Pacific Rim International Conference on Artificial Intelligence\n会议地点：斐济雅奴卡岛\n会议时间：2019.08.26 - 30\n网址：https://www.pricai.org/2019\n介绍：亚太综合型人工智能会议\nBMVC 2019\n会议名称：British Machine Vision Conference\n会议地点：英国加的夫大学\n会议时间：2019.09.09 -12\n网址：http://bmvc2019.org\n介绍：计算机视觉领域著名国际会议\nICANN 2019\n会议名称：International Conference on Artificial Neural Networks\n会议地点：德国慕尼黑\n会议时间：2019.09.10 - 13\n网址：https://e-nns.org/icann2019\n介绍：欧洲的神经网络会议\nICIP 2019\n会议名称：International Conference on Image Processing\n会议地点：中国台湾\n会议时间：2019.09.22 - 25\n网址：http://www.2019.ieeeicip.org\n介绍：图像处理领域国际著名会议\nACMMM 2019\n会议名称：ACM Multimedia\n会议地点：法国尼斯\n会议时间：2019.10.21 - 25\n网址：http://www.acmmm.org/2019\n介绍：多媒体技术领域奥运级别的顶级盛会\nICCV 2019\n会议名称：International Conference on Computer Vision\n会议地点：韩国首尔\n会议时间：2019.10.27 - 11.03\n网址： http://iccv2019.thecvf.com\n介绍：计算机视觉及模式识别领域国际三大顶级会议之一\nWACV 2020\n会议名称：Winter Conference on Applications of Computer Vision(First Round)\n会议地点：美国科罗拉多州\n会议时间：2020.03.02 - 05\n网址：http://wacv20.uccs.us\n介绍：侧重计算机视觉应用的国际会议\nICASSP 2020\n会议名称：International Conference on Acoustics, Speech and Signal Processing\n会议地点：西班牙巴塞罗那\n会议时间：2020.05.04 - 09\n网址：http://2020.ieeeicassp.org\n介绍：声学、语音与信号处理及其应用国际顶级会议\nECAI 2020\n会议名称：European Conference on Artificial Intelligence\n会议地点： 西班牙圣地亚哥\n会议时间：待定\n网址： 待定\n介绍：欧洲的人工智能综合型会议\n福利\n为了使大家更方便的查看，特意把文章内容汇总为pdf和html两版。关注“计算机视觉life”公众号菜单栏回复“顶会”领取吧。"}
{"content2":"1.CS224D\n2.NLP到Word2vec\n3.Opencv3图像处理\n4.Tensorflow视频教程\n5.机器学习视频教程\n6.七月在线所有人工智能课程\n7.聊天机器人视频教程\n8.自然语言处理视频教程\n链接如下，需要的可以在百度网盘下载。\n链接1:https://pan.baidu.com/s/1uqqYMQ3J4Vk1kSCH-7D4dA 密码:28s7 链接2:https://pan.baidu.com/s/1KdRYyI0Yta5gWNDwQge7sw 密码:0smi 链接3:https://pan.baidu.com/s/1gzSHZ52kCdNrrgtLyy3f1w 密码:8dl0 链接4:https://pan.baidu.com/s/1KrGVuhICot9GRLa-XFRsAA 密码:qa88 链接5:https://pan.baidu.com/s/16xwLarpVSQp6-ZIAAp7mOQ 密码:ixdk"}
{"content2":"原帖地址： http://blog.sciencenet.cn/blog-370458-750306.html\n关于计算机视觉和模式识别领域的期刊并不是很多，下面我收集了一些该领域的代表性期刊，并介绍了他们的影响因子以及投稿难度和审稿周期。希望对大家有帮助吧，后期大家还有发现的可以留言，补充哦。\n首先介绍计算机视觉领域的4个顶级代表性期刊吧。\n(1) IEEE Transactions on Pattern Analysis and Machine Intelligence，IEEE模式分析与机器智能汇刊，简称PAMI，是IEEE最重要的学术性汇刊之一。在各种统计中，PAMI被认为有着很强的影响因子（2011年影响因子为4.9）和很高的排名。显然，这个期刊的中稿难度那是相当的大，一般先投中CVPR之后再加点东西投该期刊会比较好中一点。\n(2) ACM Transactions on Graphics。美国计算机协会图形汇刊，简称TOG，该刊侧重于计算机图形的处理，影响因子在该领域也比较高，2011年为3.5。中稿的难度也极大，一般该刊对每年的SIGGRAPH(Special Interest Group for Computer GRAPHICS,计算机图形图像特别兴趣小组）会议论文全文收录。\n(3) International Journal of Computer vision，该刊也是该领域的顶级期刊之一，相比于PAMI来讲，该刊侧重于理论的推导。2011年影响因子为3.7，中稿难度也相当大。\n(4) IEEE Transactions on Image Processing，该刊也是图像处理领域的代表性期刊之一，相比于上面三个期刊来讲，该刊稍微低一点层次。2011年影响因子为3.042，中稿难度也比较大。审稿周期一年左右。\n除了上述让人望而生畏的顶级期刊之外，我们再看看一般的期刊吧。\n(1)Pattern recognition letters, 从投稿到发表，一年半时间;\n(2)Pattern recognition 不好中，时间长;\n(3)IEICE Transactions on Information and Systems， 作者中有一个必须是会员。收费高，审稿快。影响因子0.4;\n(4)International Journal of Pattern Recognition and Artificial Intelligence ， 审稿周期一般6--12周，影响因子偏低，容易中;\n(5)Computational Intelligence， 中等偏上，要求较高，杂志级别不错，关注人数偏少，比较冷门;\n(6)information processing letters, 影响因子低0.5左右，接搞量大，容易发表，审稿周期一般3--6个月;\n(7)Computer vision and image understanding, 9个月审稿期，平均投稿命中率20%，业内比较认可;\n(8)journal of visual communication and image representation， 投稿容易，审稿周期一年以上;\n(9)Signal processing letters, 影响因子0.99， 美国，审稿一个多月;\n(10)International Journal on Graphics, Vision and Image Processing (GVIP);\n(11)IET Image Processing, 影响因子0.758， EI Compendex ，审稿周期一年以上;\n(12)IET Computer Vision ，影响因子0.969;\n(13)SIAM Journal on Imaging Sciences;\n(14)International journal of imaging systems and technology，影响因子偏低，容易中，审稿周期一到两个月;\n(15)IEEE Signal Processing Letters， 审稿4---8周左右，影响因子不高，容易中，关注人不多;\n(16)Journal of Logic and Computation, 影响因子，0.789，SCI检索;\n(17)IEICE Transactions on Information and Systems 审稿时间2--4周，容易中，影响因子小，相对冷门，关注人数不多;\n(18)COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING，影响因子偏低，但仍然需要一定水平才可以投，审稿2--4周，SCI,EI检索;\n(19)Signal Processing: Image Communication，容易中，审稿周期半年到一年;\n(20)International Journal of Computer Vision， 较难，审稿周期半年到一年，EI,SCI检索;\n(21)Journal of Mathematical Imaging and Vision，审稿一个月左右，影响因子不高（1.3左右），Elsevier旗下，不容易中，稍微有些冷门，偏重数学推导;\n(22)Machine Vision and Applications， 影响因子偏低，但是接稿量不是很大，审稿周期一年以上，但容易发表，SCI,EI检索;\n(23)Pattern Analysis & Applications， 影响因子不高，影响力也比较小，审稿时间一年以上，但容易投中;\n(24)Signal Image and Video Processing， 容易中，审稿时间半年到一年，EI检索;\n(25)Pattern recognition and image analysis， EI检索;\n(26)Journal of digital imaging ，审稿周期半年到一年，影响因子偏低，容易中，很少有人关注;\n(27)Journal of  VLSI signal processing systems for signal image and video ，影响因子偏低，容易中，审稿周期一年以上，关注人比较少;\n(28) Neural Processing Letters,  影响因子0.75左右，审稿三个月内给出审稿意见，比较快。（发现一年只发表20篇左右，一年投稿量估计200多篇（从编号可估出），可看出命中率绝对在10%以下，待考察）\n(29) COMPUTERS & GRAPHICS-UK (一般简称为COMPUTERS & GRAPHICS)，Elsevier旗下图像处理领域期刊之一，2011影响因子为1.0。审稿速度（同行例子：9月底投稿，10月中旬送审，12月初大修，2月中旬小修后录用。审稿速度和编辑处理速度都比较快！）。感觉要求不是很高！\n(30) EURASIP Journal on Image and Video Processing，影响因子2011年为0.5，有同学投过，速度比较快，2-3个月搞定。\n(31) Multimedia Tools and Applications，2012年影响因子为1.014，据说比较好中，速度也还可以。\n(32) Communications of the ACM，2012年影响因子为2.511。中科院分区SCI大类分区2区，小类分区2区。\n(33) IEEE Transactions on Visualization and Computer Graphics，2012年影响因子为1.898，中科院分区SCI大类分区2区，小类分区2区。\n(34) IEEE Computer Graphics and Applications，2012年影响因子为1.228，中科院分区SCI大类分区3区，小类分区2区。\n(35) Graphical Models，2012年影响因子为0.697，中科院分区SCI大类分区4区，小类分区4区。\n(36) Computer Aided Geometric Design，2012年影响因子为0.810，中科院分区SCI大类分区4区，小类分区3区。\n(37) Computer Animation and Virtual Worlds，2012年影响因子为0.436，中科院分区SCI大类分区4区，小类分区4区。\n(38) Visual Computer，2012年影响因子为0.909，中科院分区SCI大类分区4区，小类分区4区。\n(39) Computer Graphics Forum，2012年影响因子为1.638，中科院分区SCI大类分区3区，小类分区2区。\n(40) International Journal of Computational Geometry and Applications，2012年影响因子为0.176，中科院（数学方向）分区SCI大类分区4区，小类分区4区。\n(41) Computational Geometry-Theory and Applications，2012年影响因子为0.545，中科院（数学方向）分区SCI大类分区2区，小类分区2区。\n(42) Journal of Visualization，2012年影响因子为0.506，中科院（工程技术）分区SCI大类分区4区，小类分区4区。\n(43) Computer Graphics World，2012年影响因子为0.000，中科院（工程技术）分区SCI大类分区4区，小类分区4区。\n(44) Virtual Reality，2012年影响因子为0.341，中科院（工程技术）分区SCI大类分区4区，小类分区4区。\n(43) Image and Vision Computing，2012年影响因子为1.959，中科院（工程技术）分区SCI大类分区3区，小类分区3区。\n(43) Computer Graphics World，2012年影响因子为0.000，中科院（工程技术）分区SCI大类分区4区，小类分区4区。\nfrom: http://blog.csdn.net/inter_xuxing/article/details/19300157"}
{"content2":"七步带你认识计算机视觉\n本文作者：李尊\n计算机视觉是一门研究如何使机器“看”的科学，本文带你七步带你认识计算机视觉。\n点击访问"}
{"content2":"NBA小牛队老板库班曾经说过，未来世界首个万亿美元富翁，必将是一个高级人工智能系统加持的“超人”。而IDC的报告显示，人工智能市场正以惊人的速度增长，从2016年的80亿美元，增长至2020年的470亿美元，市场规模将在五年内增长接近五倍，在市场预期和资本的双重刺激下，人工智能市场的媒体和资讯量也快速膨胀，到了让人目不暇接无所适从的程度，为了帮助广大人工智能领域的专家、创业者和企业技术决策者高效率获取高品质人工智能最新资讯和动态，我们收集整理了下面这两个榜单（本列表持续更新中，欢迎留言反馈，或关注微信号ctociocom互动）：\n国外最好的人工智能聚合媒体TOP5\n一、AI weekly\nAI weekly的邮件新闻列表号称汇聚了人工智能和机器学习领域最好的新闻和资源。内容侧重关注科技领导厂商人工智能技术和应用动态。\n二、The Visionary\n顾名思义，The Visionary是一个侧重计算机视觉领域的人工智能媒体，以深度报道和干货著称。\n三、Inside AI\nInside AI此前的名字是Technically Sentient（字面意思有点类似国内的AI媒体“机器之心”），这个新闻邮件列表有人工智能创业公司Talla的首席执行官Rob May亲自维护，采集聚合全球AI最新研究成果和有价值的web链接，质量和专业性绝对有保障。May擅长深入浅出，并且经常会有一些AI专家和业界领袖的独家专访，非常值得关注。\n四、Machine Learning\n顾名思义，这是一个关注机器学习的局和媒体。Machine Learning是Sam Debrule的个人写手个人工作室维护的人工智能聚合媒体，相比其他聚合媒体，Sam还会摘引论坛和社区的帖子内容，今年四月份开始，Sam开始邀请一些专家分享AI对人们工作生活影响的看法。\n五、WildML\nWildML的聚合作者是谷歌大脑工程师Denny Britz，这个媒体一个特色是干货比较多，例如代码、项目、数据和论文等，另外一点就是可以方便外界从一个侧面了解Google内部技术人员对人工智能技术的关注重点。\n最好的人工智能技术博客\nhttp://colah.github.io\nChris Olah的博客，里面有大量对复杂话题和概念的深入探讨，非常值得精读。\nhttp://karpathy.github.io\nAndrei Karpathy的博客，与Chris Olah的类似。\nhttp://blog.otoro.net/\n@hardmaru的博客，非常棒的概念诠释和代码样本。\nhttp://fastml.com/\n有大量非常棒的样例。\nhttp://blog.keras.io\n讲授部署在Keras框架的深度学习，Keras是一个基于Python的深度学习框架，架构在Tensorflow和Theano之上。"}
{"content2":"人工智能、机器学习、神经网络、深度学习、TensorFlow、图像处理必备书籍(附PDF百度盘下载链接)\n在学习人工智能相关相关知识中往往不理解其中相关术语意义和知识原理的组成，下面书籍是阿拉灯神丁君在阅读了大量书籍后觉得很不错的一部分，特此分享出来，以供大家学习之便利。内容链接如有侵犯到您的权益，请联系删除。\n学习资料持续更新，完整书籍链接请关注\n公众号“AI人工智能客栈”\n回复关键字\n“人工智能书籍”\n获取百度盘链接\n1、机器学习 周志华.pdf\n链接:https://pan.baidu.com/s/1P5Owh7YoZ6ncQz9dXanwCA 密码:wzst\n2、推荐系统实践.pdf\n3、《自然语言处理综论》.pdf\n4、《计算机视觉：一种现代方法》.pdf\n5、图解机器学习.pdf\n6、《决策知识自动化》.pdf\n7、《人工智能：一种现代的方法(第3版)》.pdf\n8、Python数据分析与挖掘实战.pdf\n9、机器学习导论.pdf\n10、面向机器智能的TensorFlow实践 (智能系统与技术丛书)_.pdf\n11、图像处理、分析与机器视觉（第三版）.pdf\n12、TensorFlow实战_黄文坚（完整）.pdf\n13、Tensorflow 实战Google深度学习框架.pdf\n14、统计学习方法.pdf\n作者李航，是国内机器学习领域的几个大家之一，曾在MSRA任高级研究员，现在华为诺亚方舟实验室。书中写了十个算法，每个算法的介绍都很干脆，直接上公式，是彻头彻尾的“干货书”。每章末尾的参考文献也方便了想深入理解算法的童鞋直接查到经典论文；本书可以与上面两本书互为辅助阅读。\n15、数学之美.pdf\n作者吴军大家都很熟悉。以极为通俗的语言讲述了数学在机器学习和自然语言处理等领域的应用。\n16、区块链新经济概论.pdf\n最近也是在学习入门阶段，也就一个感觉“一如侯门深似海，从此节操是路人”，看的我是头晕眼花，公式，概念，金星星眼前飘过~~~…((/- -)/\n以上电子书也基本都是高清版，本人对电子书的质量要求也是比较高的，影印版太垃圾了，更是伤银镜。\n人工智能领域涵盖的知识非常的广：算法、深度学习、机器学习、自然语言处理、数据结构、Tensorflow、Python 、数据挖掘、搜索开发、神经网络、视觉度量、图像识别、语音识别、推荐系统、系统算法、图像算法、数据分析、概率编程、计算机数学、数据仓库、建模等关键词，基本涵盖了现阶段人工智能细分领域的人才结构。"}
{"content2":"什么是人工智能？简单来说，人工智能就是研究如何让计算机去完成以往需要人的智力才能胜任的工作，通过生产能像人类一样做出智能反应的智能机器，来代替人类从事一些脑力或体力劳动。学人工智能10本必看书是这些：\n1.《深度学习》\nAI圣经！深度学习领域奠基性的经典畅销书！长期位居美国亚马逊AI和机器学习类图书榜首！所有数据科学家和机器学习从业者的必读图书！特斯拉CEO埃隆 马斯克等国内外众多专家推荐！\n2.《人工智能》\n“人工智能”被写入2017年政府工作报告，智能革命时代先行者李开复解读AI如何重塑个人、商业与社会的未来图谱。\n3.《人工智能简史》\n入围2017中国好书、文津图书奖，全方位解读人工智能的起源、神经网络、遗传算法、深度学习、自然语言处理等知识，深度点评AI历史趣事。\n4.《人工智能的未来（揭示人类思维的奥秘）》\n《如何创造思维》全新升级改版！奇点大学校长、谷歌工程总监、《奇点临近》作者雷·库兹韦尔全面解析“人工智能”创建原理的颠覆力作！段永朝、刘慈欣、马文明斯基、彼得戴曼迪斯等联袂倾情推荐！\n5.《人工智能：国家人工智能战略行动抓手》\n比尔·盖茨、埃隆·马斯克、扎克伯格、李彦宏、马化腾、李开复、雷军、刘庆峰等跨界大咖都在关注的科技新革命，个人和组织都须尽快认知，积极应对，腾讯携手工信部打造国家人工智能战略行动抓手！ 6.《极简人工智能：你一定爱读的AI通识书》\n以简单有趣的方式，把人工智能说透彻！全方位呈现“AI+”全景蓝图 ：群体智能、神经网络、智能代理、情感机器、智能计算、智能机器人……\n7.《区块链 人工智能 数字货币：黑科技让生活更美好？》\n《纽约时报》 美国亚马逊畅销书；解密正在全面爆发的区块链、人工智能和数字货币等黑科技，跟紧未来趋势，用技术重构世界；独特的表现手法，科幻大片般的既视感，你一定爱读的书。\n8.《高级人工智能（第三版）》\n本书共16章，与本书第二版相比，增加了两章新内容。其他章节也作了较大的修改和补充。\n9.《终极算法：机器学习和人工智能如何重塑世界》\n比尔·盖茨年度荐书！近20年人工智能领域十分轰动的著作！沃尔特·艾萨克森、车品觉、曹欢欢联袂推荐！\n10.《人工智能新时代：全球人工智能应用真实落地50例》\n人工智能为什么备受瞩目？随着电脑和网络的飞速发展，信息处理变得越来越容易，云计算、物联网、机器人等IT相关技术，进一步发挥其优势。机器学习、自然语言处理、以图像和语音识别为基础的人工智能技术得到广泛得应用。\n本书通过国内外50例以上的案例阐述人工智能技术的应用，囊括了世界各大公司的前沿技术。本书将为人工智能领域IT技术人员、经营企划人员、创业和管理人员提供重要参考。\n不知道......对大家是否有帮助？"}
{"content2":"计算机视觉历史回顾与介绍\n生物进化\n照相暗盒——为了复制我们看到的世界\n哺乳动物的视觉处理机制是怎样的\n视觉被简化为由几何形状构成\n视觉是分层的\n两个重要的结论\n近代发展\n生物进化\n计算机的历史可以追溯到很早以前，动物拥有视觉的开端\n动物物种爆发，出现食肉和猎食者，应为眼睛的出现\n照相暗盒——为了复制我们看到的世界\n照相暗盒 达芬奇 通过小孔成像的相机\n复制我们看到的世界\n包括后面的电影的发明\n哺乳动物的视觉处理机制是怎样的\n生物的大脑是如何处理视觉信息的 5.4亿年进化\n哈佛大学教授使用 电极探针插进猫的处理视觉区域的大脑中进行观察与判断。他们提出了“哺乳动物的视觉处理机制是怎样的”，通过观察何种刺激会引起视觉皮层神经的激烈反应，他们发现猫的大脑的初级视觉皮层有各种各样的细胞，其中最重要的是当它们朝着某个特定方向运动时，对面向边缘产生回应的细胞。\n他们发现视觉处理是始于视觉世界的简单结构，面向边缘，沿着视觉处理的途径的移动信息也在变化，大脑建立了复杂的视觉信息，直到它可以识别更为复杂的视觉世界。\n视觉被简化为由几何形状构成\n计算机视觉的历史是从60年代开始，从Larry Roberts的计算机视觉的第一篇博士论文开始。其中视觉世界被简化为简单的几何形状，目的是能够识别他们，重建这些形状是什么。\n视觉是分层的\n70年代后期David Marr撰写的一本非常有影响力的书，他认为我们认知事物不是看整体的框架，而是看他的边缘和线条，重要的领悟：视觉是分层的，从线条开始识别，\n2D：边缘草图\n2.5D：遮挡问题\n3D：空间感\n两个重要的结论\n整个世界由简单的数学模型构成，比如圆柱体\n简单的部分构成，多样性，由弹簧结合\n近代发展\n90年代彩色的图像\n分割有意义的部分，像素分组，感知分组\n智能理解人脸 富士相机 人脸检测 ，但是目标识别的方向是一个大趋势\nIMAGENET 500万数据100类分类"}
{"content2":"计算机视觉就是是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图形处理，使电脑处理成为更适合人眼观察或传送给仪器检测的图像。\n机器视觉需要图象信号，纹理和颜色建模，几何处理和推理，以及物体建模。实现图像理解是计算机视觉的终极目标。\n物理是与计算机视觉有着重要联系的另一领域，计算机视觉关注的目标在于充分理解电磁波——主要是可见光与红外线部分——遇到物体表面被反射所形成的图像。另一个具有重要意义的领域是神经生物学，人们试图建立人工系统，使之在不同的复杂程度上模拟生物的视觉运作。计算机视觉的另一个相关领域是信号处理，很多有关单元变量信号的处理方法，尤其是对时变信号的处理，都可以很自然的被扩展为计算机视觉中对二元变量信号或者多元变量信号的处理方法。\n到目前为止，还没有某个单一的方法能够广泛的对各种情况进行判定：在任意环境中识别任意物体。现有技术能够也只能够很好地解决特定目标的识别，比如简单几何图形识别，人脸识别，印刷或手写文件识别或者车辆识别。而且这些识别需要在特定的环境中，具有指定的光照，背景和目标姿态要求。\n计算机视觉系统的结构形式很大程度上依赖于其具体应用方向。有些功能却几乎是每个计算机系统都需要具备的：\n1.图像获取\n一幅数字图像是由一个或多个图像感知器产生，这里的感知器可以是各种光敏摄像机，包括遥感设备，X射线断层摄影仪，雷达，超声波接收器等。取决于不同的感知器，产生的图片可以是普通的二维图像，三维图组或者一个图像序列。图片的像素值往往对应于光在一个或多个光谱段上的强度（灰度图或彩色图），但也可以是相关的各种物理数据，如声波，电磁波或核磁共振的深度，吸收度或反射度。\n2.预处理\n在对图像实施具体的计算机视觉方法来提取某种特定的信息前，一种或一些预处理往往被采用来使图像满足后继方法的要求。例如：\n二次取样保证图像坐标的正确；\n平滑去噪来滤除感知器引入的设备噪声；\n提高对比度来保证实现相关信息可以被检测到；\n调整尺度空间使图像结构适合局部应用。\n3.特征提取\n从图像中提取各种复杂度的特征。例如：\n线，边缘提取；\n局部化的特征点检测如边角检测，斑点检测；\n更复杂的特征可能与图像中的纹理形状或运动有关。\n4.检测分割\n在图像处理过程中，有时会需要对图像进行分割来提取有价值的用于后继处理的部分，例如\n筛选特征点；\n分割一或多幅图片中含有特定目标的部分。\n5.高级处理\n到了这一步，数据往往具有很小的数量，例如图像中经先前处理被认为含有目标物体的部分。这时的处理包括：\n验证得到的数据是否符合前提要求；\n估测特定系数，比如目标的姿态，体积；\n对目标进行分类。\n高级处理有理解图像内容的含义，是计算机视觉中的高阶处理，主要是在图像分割的基础上再经行对分割出的图像块进行理解，例如进行识别等操作。"}
{"content2":"Mahotas 是计算机视觉和图像处理 Python 库。它包含大量图像处理算法，C++实现形式，提高了性能。完全基于 numpy 的数组作为它的数据类型，有一个非常干净的Python 算法接口。\n包含算法\n分水岭。\n凸点计算。\n击中/击不中，细化算法。\n泽尼克＆Haralick，枸杞多糖，和TAS的功能。\n基于freeimage的numpy图像加载（需要安装freeimage库）。\n加速的鲁棒特征（SURF）等。\n阈值。\n卷积。\nSobel边缘检测。\n多边形绘制\n距离变换\n特征计算\n样条插值\n安装问题\n在使用 pip install mahotas 安装过程中遇到一个错误：\nbuilding 'mahotas._histogram' extension error: Microsoft Visual C++ 10.0 is required (Unable to find vcvarsall.bat).\n按照提示是缺少，Visual C++ 10.0\n而在我的电脑上，只安装了VS2012\n查找资料后得到了解释\n由于是C++实现，所有在 window 中使用 pip 安装时需要有 C++ 编译器。\n根据官网的解释，支持的编译器版本有：\nMicrosoft Visual C++ 2008 (x64, x86, and SP1 for CPython 2.6 and 2.7)\nVisual C++ 2010 (x64, x86, for CPython 3.3 and 3.4)\nVisual C++ 2015 (x64 and x86 for CPython 3.5) redistributable packages.\n解决方案\n在binary packages of mahotas 可以找到对应的二进制版本\n下载对应版本二进制文件 mahotas-1.4.0.cp*******.whl后\n在命令行执行如下命令\npip install mathotas-1.4.0.cp*******.whl\n运行测试\n开启 Python 输入如下命令\nimport pylab as p import numpy as np import mahotas as mh f = np.ones((256,256), bool) f[200:,240:] = False f[128:144,32:48] = False # f is basically True with the exception of two islands: one in the lower-right # corner, another, middle-left dmap = mh.distance(f) p.imshow(dmap) p.show()\n终端输出如下即为，安装成功\n参考链接\nMahotas 官网\nHow to install mahotas\nInstalling from Wheels"}
{"content2":"引子 ：\n今天去望江校区听了山世光老师的关于人工智能的讲座，觉得收获很大，我决定在博客上整理一下，也算是对讲座中内容的巩固。老师主要是针对人工智能小白开展的讲座，对于我这个对机器学习、深度学习怀有敬畏心的“小白”，可谓是很大的收获，而且在讲座结束后，老师和许多学长学姐之间的问答环节也让我知道了人外有人，天外有天，所以以后还是要好好学习！所以，那就进入正题吧！因为是给小白讲的，所以基本就是个大致概括，如果有错误的地方，希望大家或者“以后的自己”及时指正出来！谢谢你们！、\n1.数字化（单机）——网络化（联网应用）——智能化（2025）\n2.人工智能：\n指在计算机领域，人工智能是指对“智能代理”的研究。任何可以感知环境并采取行动以最大可能达成其特定目标的任何设备都是智能代理。\n3.子问题：\n知识表示、感知、自然语言处理、规划、社会智能、通用只能、创造力、运动和操作\n4.人工智能发展的历史变革：\n符号主义、Lighthill的报告、第二次AI热潮立中神经网络和专家系统、日本五代机计划失败、1997深蓝人机大战、2011年第三次热潮\n5.AI = A+B+C:\nA（Algorithm）：算法\nB（Bi-data）：大数据\nC（Computing）：算力\n6.计算机视觉：\n生物启示：从宏观到微观：\n大脑—脑区—神经细胞互联 —单个神经细胞—生化翻译\n1000亿量级神经细胞，高度互联\n在我们的大脑里，光信号—电信号—图像\n每个神经元：加权投票模型（！赞成 ！反对 ！弃权）\n模式发现器（是否出现了自己感兴趣的模型）——边缘检测\n祖母细胞理论：特定神经元对特定物体具有反应\nfeatural hierarchy 层级感受眼理论：\n简单细胞—复杂细胞—超复杂细胞—超超细胞\n边缘—角点—简单图案—复杂图案—部件—物体\n7.深度学习模型:\n一．单神经元计算模型：加权求和（卷积）+非线性激活函数\n二．多个单神经元互联形成多层神经网络（多元神经网络）\n三．卷积神经网络CNN（加权共享）\n神经网络的演化，以CNN为例：\n网络加深、从分类任务到检测任务、增强卷积模块功能、增加新的功能单元\n8．深度神经网络的学习：\n不断调整权重、使得最终目标Y符合X的函数\n特别提醒：深度学习等神经网络技术是“非常非常粗”的类脑，所以准确的说法是：“脑启发”的方法，而不是类脑智能\n9.两个概念的区分:\n一、训练（学习）：需要大量数据学习参数，需要前馈和反馈（BP算法）、极其耗时（几周）、GPU服务器\n二、推理(inference):耗时短、CPU\n10.解决了什么类型的问题\n识别任务、监测任务、视频结构化技术（监控场景行人车辆的检测、属性与跟踪估计）、无人机视觉技术、手势识别技术、在VOC2012数据集上、看图写作、visual question answering、图形合成及其风格转换（举一反三）\n11.人脸识别流程\n由设计到学习的权重变化：由人为函数设计计算 到 纯粹由数据学习进行权数改变\n总结：\n1.          方法论：由人类专家知识驱动的AI方法论 到 有监督大数据的数据驱动的AI方法论——到知识和数据的联合驱动（展望）\n2.          思想变迁：（1）从重算法到重数据     （2）解决非线性问题的方法\n（3）人工编码知识到从数据中学习知识\n（4）从分而治之到全盘考虑（子问题最优并非全局最优，不能一直使用贪心算法）\n演讲后问题：\n1.   人工智能、机器学习、深度学习的区别？\n答：人工智能是最广泛的一个名词，其他所有研究都是人工智能的子学科，如Natural language processing、learning\n机器学习，需要通过数据完成机器的学习和对特定目标的求解\n深度学习，是机器学习的一个子项目，（比较火）从机器学习中单独列出，深度学习指的是多层的神经网络（至少超过三层）\n2.   数据（80%）>网络结构（20%）"}
{"content2":"1.网上很多同学对老师您的简历非常好奇，在百度搜索上发现大家都很关心“唐宇迪是哪个学校毕业的”？关于您的学习经历能简单说下吗？\n唐宇迪：几年前第一次迈进同济大学校园，并加入了数据挖掘项目组，以此真正开始了机器学习之旅。学习的过程有些枯燥在所难免，但是想着可以将算法应用于实验当中，看着结果一次次的提升，还是充满了希望与动力的。\n2.那您是如何一步步进入人工智能领域工作的呢?\n唐宇迪：人工智能现阶段比较火，想要从事这方面的同学越来越多。但在我最开始在学习阶段时，几乎还没有任何应用，那时候只是出于好奇了解了一些机器学习相关算法。\n最开始接触深度学习是在14年底，神经网络开始崛起，可谓火极一时，工作时使用的第一个DL框架是Caffe，当时网上还没有那么多博客与相关学习课程，基本所有的指导都是参考其官网文档与身边的同事，可能更多的同学认识我是通过在线课程。\n15年底开始筹备第一套深度学习课程，最早的想法只是完善一套指导手册。随着深度学习的兴起，越来越多的同学准备加入到这个领域中，有着同学们一路的支持，我也更坚定了继续把课程做下去的决心，时间过得很快，一转眼已是三年，基本上已经完善了一套人工智能系列课程。\n3.有些同学还没有学习您的课程，很关心“唐宇迪的课程是怎样的” ？那唐老师您平时是怎么打磨课程的呢？\n唐宇迪：对于讲课来说，我觉得更重要的是，让同学们花更少的时间掌握其中的知识点。我每天做的最多的一件事，就是取琢磨什么样的讲解方式才是最接地气的。现在我把更多的时间花在了讲解方式上，也是希望同学们能学的更顺利、更轻松。我觉得这些年获得的最大成就，就是收获同学的认可与支持，一句“谢谢唐老师”，是我最最大的成绩和对我最大的鼓励。\n在csdn学院搜‘唐宇迪’，就能找到我的课程，大家可以免费试听的。\n唐宇迪视频入口：\n点此进入唐宇迪老师课程主页\n4.未来 3~5 年内，您认为哪个方向的机器学习人才最紧缺？\n唐宇迪：很多同学加入机器学习方向是为了能有更好的发展，转行与就业的话题已是家常便饭。我认为未来最热门的领域应当还是数据挖掘，基本各行各业都需要通过数据产生价值，从同学们的就业情况来看，也是加入这个领域发展的更多一些。\n计算机视觉这个方向也是我一直看好的，现在人工智能越来越接地气，应用领域逐渐贴近生活。从事图像识别方向的研究与应用越来越多，肯定会导致需求增大，那么这势必会是之后人工智能中最热门的领域。\n5.想要学好人工智能，初学者应该从哪些方面学习？非初学者应该侧重哪些方面学习、怎样学习？\n唐宇迪：同学们讨论最多的话题就是如何进行学习。我认为无论之后想要从事哪个方向的发展，肯定都是先从机器学习开始，并且要打下坚实的基础！\n学习过程肯定少不了实践的过程，选择编程语言肯定是Python了，建议初学的同学们快速掌握这些工具包的使用方法。建议并不用把所有函数都背下来，用的时候现查完全来得及。\n接下来重点再落在机器学习算法与应用方面。有基础的同学们可以按照自己的方向来选择，我认为多读论文复现或者参考其源码来进行学习还是非常有帮助的，相当于有了指导思想来学习高手是怎样将问题落地解决的，这是一种非常全面的学习方式。\n唐宇迪10小时玩转机器学习视频入口：\n点此进入唐宇迪老师机器学习课程"}
{"content2":"中国的人工智能启动资金数额超过美国，重点投资领域是面部识别和芯片。\n经过近十年的发展，计算机的算力和处理数据的能力取得了重大的突破。人工智能领域因此迅猛发展。\n中美两国在人工智能方面展开竞赛，两方各有千秋。在美国，自然语言处理，机器学习应用，以及计算机视觉与图像入列AI创业公司的三甲。而中国排名前三的领域为：计算机视觉与图像，智能机器人以及自然语言处理。\n人工智能、大数据、云计算和物联网的未来发展值得重视，均为前沿产业，多智时代专注于人工智能和大数据的入门和科谱，在此为你推荐几篇优质好文：\n1.人工智能时代，AI人才都有哪些特征？\nhttp://www.duozhishidai.com/article-1792-1.html\n2.大数据携手人工智能，高校人才培养面临新挑战\nhttp://www.duozhishidai.com/article-7555-1.html\n3.人工智能，机器学习和深度学习之间，主要有什么差异\nhttp://www.duozhishidai.com/article-15858-1.html\n[多智时代-\n人工智能\n和\n大数据\n学习入门网站|人工智能、大数据、\n物联网\n、\n云计算\n的学习交流网站](http://www.duozhishidai.com)"}
{"content2":"树莓派官方杂志MagPi 第74期翻译\n翻译：子豪兄（同济大学）\n加入翻译组或相关合作请关注微信公众号MagPi ，私聊后台\n欢迎各论坛网站公众号分享转载，请以 原文超链接或链接形式 转载并注明出处 子豪兄。\n原文地址 http://u6.gg/ePHyx 发布于2018-10-08\nMagPi杂志中文翻译github\n本项目Github地址，内有动图演示"}
{"content2":"计算机视觉—SIFT算法之高斯金字塔\nbrycezou@163.com\n1、高斯金字塔–>DoG金字塔\n在理论上，输入图像需要先分别与不同尺度的高斯核进行卷积，然后求两幅图像的差。而在实际中更为简单，如图所示，高斯金字塔相邻两层相减，便可以得到\nDoG\nDoG 金字塔。这是因为，高斯金字塔每层中的多幅图像，原本就是通过对同一幅输入图像进行不同尺度的高斯卷积得来的。关于高斯金字塔的构造方法，请继续阅读下文。\nD(x,y,σ)=(G(x,y,kσ)−G(x,y,σ))∗I(x,y)\nD(x,y,\\sigma)=(G(x,y,k\\sigma)-G(x,y,\\sigma))*I(x,y)\n\n2、SIFT算法中的高斯金字塔\n图像金字塔模型是指，将原始图像不断降阶采样，得到一系列大小不一的图像，由大到小，自底向上构成的塔状模型。原始图像为金字塔的第一层，每次降采样得到的新图像为金字塔的一层（每层一张图像）。\nSIFT算法中的高斯金字塔略有不同。为了让尺度体现其连续性，在简单下采样的基础上添加了多尺度的高斯滤波。一幅图像可以产生几组（Octave）图像，一组图像又包括几层（Interval）图像，并且组数和金字塔的层数相等。\n\n为了在每组图像中检测\nS\nS 个尺度的极值点，\nDoG\nDoG 金字塔每组需\nS+2\nS+2 层图像，因为每组的第一层和最后一层图像上不能检测极值，如图；而\nDoG\nDoG 金字塔由高斯金字塔相邻两层相减得到，则高斯金字塔每组需\nS+3\nS+3 层图像，实际计算时\nS\nS 通常在3到5之间。SIFT算法中生成高斯金字塔的规则如下：\n设高斯金字塔共包含\nO\nO 组图像，每组图像有\nS+3\nS+3 层，\nO=log2(min{M,N})−3\nO=\\log_{2}(min\\{M,N\\})-3\n其中，\nM,N\nM,N分别为原始图像的行数和列数。\n设位于金字塔底的第1组的第1层图像，其高斯滤波的尺度为\nσ(o=1,s=1)=σ(1)1\n\\sigma(o=1,s=1)=\\sigma_1^{(1)}\n则位于第1组的其它层图像的高斯滤波尺度分别为\nσ(o=1,s=2)=σ(1)2=kσ(1)1\n\\sigma(o=1,s=2)=\\sigma_2^{(1)}=k\\sigma_1^{(1)}\nσ(o=1,s=3)=σ(1)3=kσ(1)2=k2σ(1)1\n\\sigma(o=1,s=3)=\\sigma_3^{(1)}=k\\sigma_2^{(1)}=k^2\\sigma_1^{(1)}\n⋯\n\\cdots\nσ(o=1,s=S+3)=σ(1)S+3=kσ(1)S+2=⋯=kS+2σ(1)1\n\\sigma(o=1,s=S+3)=\\sigma_{S+3}^{(1)}=k\\sigma_{S+2}^{(1)}=\\cdots=k^{S+2}\\sigma_1^{(1)}\n同理，位于第2组的各层图像的高斯滤波尺度分别为\nσ(o=2,s=1)=σ(2)1\n\\sigma(o=2,s=1)=\\sigma_1^{(2)}\nσ(o=2,s=2)=kσ(2)1\n\\sigma(o=2,s=2)=k\\sigma_1^{(2)}\nσ(o=2,s=3)=k2σ(2)1\n\\sigma(o=2,s=3)=k^2\\sigma_1^{(2)}\n⋯\n\\cdots\nσ(o=2,s=S+3)=kS+2σ(2)1\n\\sigma(o=2,s=S+3)=k^{S+2}\\sigma_1^{(2)}\n其中，\nk\nk 为相邻尺度的缩放因子\nk=21S\nk=2^{\\frac{1}{S}}\n为了保证尺度变化的连续性，\n第2组第1层的尺度等于第1组倒数第3层的尺度\n，即\nσ(2)1=kSσ(1)1=2σ(1)1\n\\sigma_1^{(2)}=k^S\\sigma_1^{(1)}=2\\sigma_1^{(1)}\n不难发现，相邻两组的同一层，其尺度为2倍关系。进一步归纳可知，位于第\no\no 组，第\ns\ns 层图像的图像的尺度为\nσ(o,s)=σ(o)s=2o−1ks−1σ(1)1,o∈[1,2,⋯,O],s∈[1,2,⋯,S+3]\n\\sigma(o,s)=\\sigma_s^{(o)}=2^{o-1}k^{s-1}\\sigma_1^{(1)},o\\in[1,2,\\cdots,O],s\\in[1,2,\\cdots,S+3]\n3、构造高斯金字塔的示例\n设图像的尺寸为\n256×256\n256\\times256，则高斯金字塔的层数（Octave）为\nlog2256−3=5\n\\log_{2}256-3=5。\n设\nS=3\nS=3 ，则每组需要\nS+3=6\nS+3=6 幅图像。\n设高斯金字塔第\ni\ni 组\n(i=1,2,3,4,5)\n(i=1,2,3,4,5) 的尺度为\nG(i)=(σ(i)1,σ(i)2,σ(i)3,σ(i)4,σ(i)5,σ(i)6)\nG^{(i)}=(\\sigma_1^{(i)},\\sigma_2^{(i)},\\sigma_3^{(i)},\\sigma_4^{(i)},\\sigma_5^{(i)},\\sigma_6^{(i)})\nDoG\nDoG 金字塔第\ni\ni 组的尺度为\nD(i)=(σ(i)1,σ(i)2,σ(i)3,σ(i)4,σ(i)5)\nD^{(i)}=(\\sigma_1^{(i)},\\sigma_2^{(i)},\\sigma_3^{(i)},\\sigma_4^{(i)},\\sigma_5^{(i)})\n极值点检测在第\ni\ni 组的尺度为\nR(i)=(σ(i)2,σ(i)3,σ(i)4)\nR^{(i)}=(\\sigma_2^{(i)},\\sigma_3^{(i)},\\sigma_4^{(i)})\n由此可得（这里仅保留系数）\nG(1)=(01,2013,2023,2033,2043,2053);D(1)=(01,2013,2023,2033,2043);R(1)=(2013,2023,2033)\nG^{(1)}=(01,2^{\\frac{01}{3}},2^{\\frac{02}{3}},2^{\\frac{03}{3}},2^{\\frac{04}{3}},2^{\\frac{05}{3}}); D^{(1)}=(01,2^{\\frac{01}{3}},2^{\\frac{02}{3}},2^{\\frac{03}{3}},2^{\\frac{04}{3}}); R^{(1)}=(2^{\\frac{01}{3}},2^{\\frac{02}{3}},2^{\\frac{03}{3}})\nG(2)=(02,2043,2053,2063,2073,2083);D(2)=(02,2043,2053,2063,2073);R(2)=(2043,2053,2063)\nG^{(2)}=(02,2^{\\frac{04}{3}},2^{\\frac{05}{3}},2^{\\frac{06}{3}},2^{\\frac{07}{3}},2^{\\frac{08}{3}}); D^{(2)}=(02,2^{\\frac{04}{3}},2^{\\frac{05}{3}},2^{\\frac{06}{3}},2^{\\frac{07}{3}}); R^{(2)}=(2^{\\frac{04}{3}},2^{\\frac{05}{3}},2^{\\frac{06}{3}})\nG(3)=(04,2073,2083,2093,2103,2113);D(3)=(04,2073,2083,2093,2103);R(3)=(2073,2083,2093)\nG^{(3)}=(04,2^{\\frac{07}{3}},2^{\\frac{08}{3}},2^{\\frac{09}{3}},2^{\\frac{10}{3}},2^{\\frac{11}{3}}); D^{(3)}=(04,2^{\\frac{07}{3}},2^{\\frac{08}{3}},2^{\\frac{09}{3}},2^{\\frac{10}{3}}); R^{(3)}=(2^{\\frac{07}{3}},2^{\\frac{08}{3}},2^{\\frac{09}{3}})\nG(4)=(08,2103,2113,2123,2133,2143);D(4)=(08,2103,2113,2123,2133);R(4)=(2103,2113,2123)\nG^{(4)}=(08,2^{\\frac{10}{3}},2^{\\frac{11}{3}},2^{\\frac{12}{3}},2^{\\frac{13}{3}},2^{\\frac{14}{3}}); D^{(4)}=(08,2^{\\frac{10}{3}},2^{\\frac{11}{3}},2^{\\frac{12}{3}},2^{\\frac{13}{3}}); R^{(4)}=(2^{\\frac{10}{3}},2^{\\frac{11}{3}},2^{\\frac{12}{3}})\nG(5)=(16,2133,2143,2153,2163,2173);D(5)=(16,2133,2143,2153,2163);R(5)=(2133,2143,2153)\nG^{(5)}=(16,2^{\\frac{13}{3}},2^{\\frac{14}{3}},2^{\\frac{15}{3}},2^{\\frac{16}{3}},2^{\\frac{17}{3}}); D^{(5)}=(16,2^{\\frac{13}{3}},2^{\\frac{14}{3}},2^{\\frac{15}{3}},2^{\\frac{16}{3}}); R^{(5)}=(2^{\\frac{13}{3}},2^{\\frac{14}{3}},2^{\\frac{15}{3}})\n从上述结果可以看出，按照这种方式构造的高斯金字塔，在极值点检测时，其尺度变化确实是连续的。\n4、其它\n利用高斯金字塔，对图像下采样的过程为：\n1）与高斯模板进行卷积\n2）去除偶数行和偶数列\n下采样会缩小图像，并且逐渐丢失图像信息。\n利用高斯金字塔，对图像上采样的过程为：\n1）在每个方向上扩大为原来的两倍，新增行列用0填充\n2）使用同样的高斯模板（数值上乘以4）与新的图像进行卷积\n上采样会放大图像，也会丢失信息，使图像变模糊。"}
{"content2":"姓名：谢童  学号：16020188008  转自微信公众号 新智元\n我们可能每天都在使用计算机视觉，用脸解锁你的iPhone， 这是计算机视觉。使用手机刷脸支付等等， 这也是计算机视觉。我们所知道的计算机视觉正处于临界点。由于行业范围内的开发工作以及深度学习算法和图形处理器的进步，我们正在做十年前难以想象的事情。\n一些技术已经存在了几年，但过去一年的一些发展使计算机视觉达到了新的高度。更好的传感器，大量标记图像，易于访问深度学习软件以及改进的处理器的融合，共同创造了一年前仅限于少数几家大型科技公司的功能。\n亚马逊发布  Rekognition  将计算机视觉置于任何开发人员的手中。微软为OneDrive和SharePoint推出了新的AI服务  。Google相册  让我们的记忆变得可搜索。\n我们在2018年看到了技术飞跃突破的计算机视觉项目，该技术最终正赶上开发人员长期渴望创建的应用程序。这也意味着开发定制的计算机视觉应用程序很快就会变得更便宜。\n例如，ModiFace允许用户仅使用智能手机进行化妆。 拓扑 对眼镜也是如此。 MTailor  使用类似工艺制作定制牛仔裤和衬衫。除了时尚领域之外，  Pottery Barn  让用户可以看到新家具在家中的样子，而  Hover  将用户的家居照片转变为完全测量的3D模型。\n这些项目都不像自动驾驶汽车  和无人收银机超市那么复杂  ，但这是当前一代计算机视觉产品在未来几年内作为大规模部署预兆的资格：一旦小公司能够发展功能针对大众的计算机视觉产品，该技术将开始渗透到我们生活的几乎每个部分。\n计算机视觉与其他AI技术不同。首先，对于大多数组织而言，计算机视觉是一项全新的功能，而不是对其他人之前尝试过的事情的渐进改进，例如预测分析。\n此外，计算机视觉改善人类感知没有内在障碍。当这些算法从图像中推断出信息时，他们并没有像许多其他人工智能 那样预测一个本质上不确定的未来。他们只是在确定关于图像或图像集的当前内容的分类真相。这意味着计算机视觉将能够随着时间的推移变得更加准确，直到它匹配或超过人类图像识别的能力。\n最后，计算机视觉可以比其他AI工具更快地收集其训练数据。大数据集需要大量投资培训数据，但计算机视觉只需要人们准确地标记图片和视频和简单的东西。这就是为什么计算机视觉的采用率近来加速了这么多。\n计算机视觉在2019年及以后\n虽然我们已经开始看到消费产品中出现了计算机视觉，但其中相当大一部分用途将继续用于特定的行业用途。例如，CCC信息服务正在帮助汽车保险公司   使用热图来识别车辆损坏情况，该热图可以突出显示最严重损坏的位置。\n这些类型的计算机视觉产品可能不那么炫目，但重要的是要记住每个新应用程序意味着开发人员可以获得有关哪些有效和哪些无效的更多信息，这继续使我们越来越接近像智能这样的大型项目城市。亚太，微软和谷歌在2018年展示的最近一次飞跃是推动计算机视觉超过临界点的催化剂。产品设计师和人工智能工程师已经在研究使用计算机视觉和增强现实的新解决方案。硬件制造商正在改进组件性能并提高成本效率，以使该技术更好，更易于访问。\n近期最大的创新之一将是培训数据。现在，人类仍需要用手动标记的图像训练计算机视觉AI。（如果您曾经填写过一个网页表格，要求您从网格中选择一些图像来显示像店面或汽车这样的常见对象，您实际上已经参与为计算机视觉项目创建标记数据。）但随着技术的进步，人工智能将学会培训人工智能，进一步简化流程并加快改进速度。\n计算机视觉市场的增长几乎与能力一样快：预计到 2025年将达到262亿美元，每年增长超过30％。人工智能是未来，计算机视觉是未来最有力的表现形式。很快，它将随处可见，以至于你甚至都不会注意到它。"}
{"content2":"http://download.csdn.net/download/u014036026/9823217\n好清晰的中文版"}
{"content2":"有什么用？\n深度图在计算机视觉中有非常广泛的应用，比如前背景分割（用于背景虚化、美颜、重对焦等）、三维重建（用于机器人导航、3D打印、视效娱乐等）。目前能够直接快速获得深度图的方法就是使用深度相机，不同深度相机获取深度图原理见：《深度相机原理揭秘–飞行时间（TOF）》、《深度相机原理揭秘–双目立体视觉》、《深度相机原理揭秘–结构光（iPhone X 齐刘海原理）》。\n但是很多时候由于硬件的限制，我们不能通过深度相机获得深度图。只能利用单目相机通过相关算法来间接计算深度图。比较有名的方法就是运动恢复结构（Structure from Motion），也就是说，我们需要移动（通常需要较大的移动）单目相机从而获得不同视角的多张图片才能间接得到深度图。\n从微小运动中获取深度图（depth from small motion）是其中一个比较巧妙的、用单目相机间接获得深度图的方法。该方法利用非常微小的运动来计算深度图，这个“非常微小的运动”的目的是在用户察觉不到的时间（比如手机用户寻找最佳拍摄位置时的微小移动，或者用户拿着相机按快门前的预览时间，或者类似live photo等）内得到深度图。如果该方法可以获得较高质量的深度图，就可以一定程度（静态场景下）上替代基于RGB双目立体视觉的深度相机（如手机双摄，手机双摄介绍见《为什么会出现双摄像头手机？》系列文章）的功能。\n下面来介绍该技术的一个应用。如下图所示，(a) 是输入的一个微运动视频中所有帧的平均叠加图，可以看到运动真的是非常微小的。(c) 是算法计算的深度图，从放大的细节来看，边缘还是很锐利的，(d) 是利用得到的深度图进行重对焦的效果。我们看到对焦主体比较清晰，而位于主体前后景深的物体都已经虚化。\n什么原理？\n本文的亮点之一就是可以对未标定的相机进行深度图和内外参数同时估计。大致流程如下：\n1、以第1帧作为参考帧，检测当前帧和参考帧的Harris角点，用KLT法进行特征点匹配。\n2、先假设初始的相机内参和畸变参数，利用光束平差法最小化重投影误差，迭代得到相机的内外参数、特征点对应的三维空间点。其原理示意图如下所示。Uij是第i张图像相对于图像中心的第j个特征点的畸变坐标，红色点是其去畸变后的坐标。蓝色点是重投影的坐标。目标就是最小化第i帧中红色点和蓝色点的位置误差。\n3、根据得到的内外参数用平面扫描法进行稠密立体匹配，并采用赢家通吃的策略得到粗糙的深度图。微小运动有如下优势：由于时间短，移动小，视场角变化小，可以近似认为所有帧在该时间段内的灰度值保持不变。这个假设对于可靠的稠密像素匹配很重要。\n4、将彩色图作为引导图，对深度图进行精细化。获得深度图的过程如下：\n(a) 用赢家通吃的策略得到一个粗糙的深度图；(b) 去除不可靠的深度值；(c) 深度图精细化后的结果；(d) 参考图像。\n该算法的伪代码流程图如下所示：\n效果怎么样？\n该算法测试效果如下图所示。下图左侧是用iPhone 6拍摄的1s时间的微小运动连续图像的平均图，从中可以看出运动非常小。右侧是算法输出的对应深度图。\n该算法和其他算法在重对焦效果上的对比如下图所示。可以看到该算法能够在背景虚化的同时保持相对锐利的边缘。\n尽管该算法设计的初衷就是用于微小运动的情况，但是如果运动特别微小，估计的相机位姿就会非常不稳定。另外如果图像边缘缺乏有效的特征点，会导致径向畸变参数的估计变的不准确。上述情况会导致深度图出现较大的误差。\n该算法只适合于静态场景，如果有快速移动物体，该算法会失败。另外要注意的是，该算法估计的深度图是相对深度。\n运行时间：\n该算法是在个人台式机上进行测试。电脑配置：Intel i7-4970K 4.0Ghz CPU，16GB RAM。对于一个分辨率为1280x720的30帧的微小运动视频，该算法（未优化）完成特征提取、跟踪、光束平差需要1分钟。稠密立体匹配阶段耗时10分钟。\n有什么参考资料？\n本文算法对应的文章：\nHa H, Im S, Park J, et al. High-Quality Depth from Uncalibrated Small Motion Clip[C]// Computer Vision and Pattern Recognition. IEEE, 2016:5413-5421.\n源码：\nhttps://github.com/hyowonha/DfUSMC\n上述论文的优化及加速版：\nMonocular Depth from Small Motion Video Accelerated，2017 International Conference on 3D Vision\n本文首发于微信公众号：「计算机视觉 life」"}
{"content2":"计算机视觉算法实现\n转载计算机视觉牛人博客"}
{"content2":"图像处理是将输入图像转换为输出图像的过程，人是图像处理的效果的最终解释者；\n在计算机视觉中，计算机是图像的解释者；图像处理仅仅是计算机视觉系统中的一个模块；\n计算机图形学的主要工作是从三维描述到二维图像显示的过程；\n计算机视觉则是从二维图像数据到三维描述的过程，计算机视觉是计算机图形学的逆问题。\n模式识别主要解决分类的问题，是计算机视觉中的一个模块；\n总体来说他们有如下的关系：\n不要把几个相关的概念混为一谈"}
{"content2":"会议：\nAAAI 每年一次，年初开会\nICLR 每年一次，春季开会\nCVPR 每年一次，夏季开会\nICML 每年一次，夏季开会 , cvpr附近\nIJCAI 每年一次，夏季开会，cvpr附近\nICCV 两年一次，奇数年，cvpr之后\nECCV 两年一次，偶数年，cvpr之后\nNIPS 每年一次，冬季开会，iccv或eccv以后\n期刊：\nTPAMI\nIJCV\nTIP\nPR"}
{"content2":"计算机视觉和模式识别\n计算机视觉和图像处理是一个令很多人充满兴趣的计算机领域，它不仅涉及到很多精妙和令人称赞的数学推导和\n漂亮的代码\n，更是应用到我们生活的方方面面，简单如\nPhotoshop、美图秀秀\n，复杂于相机校准、人脸识别、处理视频等。\n时隔很久没有写博客了，以前写博客的时候总感觉自己欠缺很多，现在发现在计算机专业读书，每一年都会对自己所学的东西有了新的理解。这次的博客系列就是分享自己在图像处理和计算机视觉方面的理解和体会，希望大家\nHave fun with image!\n1.什么是计算机视觉和图像处理？\nComputer vision is an interdisciplinary field that deals with how computers can be made for gaining high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do.\n[ 维基百科 ]\n简而言之\n计算机视觉就是获取图像的高层信息，看起来让计算机和人类视觉系统一样。\n图像处理通常是获取图像的低层或者中层信息，对图像进行直接的处理。\n2.我们使用什么进行图像处理？\nC/C++大家都知道是图像处理包括计算机图形学中常用的编程语言，原因呢，想必大家都懂，就是效率高。在复杂的图形图像处理中这一点显得更重要。因此在接下来的系列中我所介绍的图形图像处理都是采用\nWin10平台下VisualStudio2015 Community版本的VC编译环境\n。当然大家在理解算法的过程后，可以使用诸如Matlab、Java等其他编程语言来写自己的算法程序。\n工欲善其事，必先利其器。如果大家有过图像处理或者图像操作的编程经验都知道，如果没有一些辅助的库文件，那么编写图像处理算法的代码将会有很多冗余繁杂的读取保存图像的代码，这些代码不利于我们对算法的理解和程序的快速编写。因此我们常使用一些辅助的图像处理库，来简化我们的代码编写，比较有名的就是\nOpenCv\n。\n但是在这里要为介绍的是另外一个更为简单（配置简单、操作简单）的图像处理库\nCImg\n。\n3.什么是CImg？\n简而言之，CImg是一个\n小的开源的现代C++图像处理库。\n当然，个人觉得它相比其他库最重要的特点就是它只是一个.h文件，只需把它下载下来后放到VS安装目录下的Include文件下，编写程序时像正常的头文件一样使用就可以了。\n它不需要对库的提前编译\n不用处理复杂的依赖关系\n编译是按需完成的\n类成员和函数都是内联的，在程序执行时有更好的表现\n4.配置CImg\n正如上面所说，CImg的配置过程相当简单，找到自己的VS安装目录（我的是安装在C盘\nC:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\include）\n,将CImg.h放进该文件夹即可\n这里提供一下(http://cimg.eu/download.shtml)官网的下载地址，其实直接百度谷歌很容易找到官网然后Download，而且官网也有很多第一手的资料可以提供我们学习使用。\n5.第一个CImg图像处理程序\n这次我们先写出一个Hello CImg的程序，实现图片的读取显示和保存。\n代码如下：\n/*CImg demo for blog*/ #include<CImg.h> // Include the library file using namespace cimg_library; int main() { CImg<unsigned char> image; image.load_bmp(\"demo.bmp\"); // load the image image.display(); // display the image image.save(\"new.bmp\"); // create a new name and save the image return 0; }\n运行结果如下：\n一个只有十行左右的程序，便可以轻松完成对图像的简单操作，\n我们下次见！"}
{"content2":"计算机视觉系列教程 (二)卷积与滤波详解\n\n\n什么是滤波？\n要了解什么是滤波，首先要知道什么是波。\n图像原本只是一种随时间推移的波形图，也就是图像一开始处于时域状态，而我们并不能从时域图像中看出什么东西（除了一堆突起），而伟大的傅里叶公式让图像从时域中转换到的频域中。\n\n引用一幅图 会看的更加清楚http://blog.jobbole.com/70549/\n\n从这幅图中可以看出来，图像其实是由不同频率的波长组成的，存在着高频部分和低频部分，当然这之间没有明确界限，我们需要知道的是高频部分和低频部分到底代表着什么。\n高频部分其实就是代表着这幅图像的边缘信息，也就是锐度。\n低频部分刚好相反，代表的是这幅图像的灰度变化信息，也就是内容。\n那么我们把高频部分的波称作为高频波，低频部分的则称为低频波。这就是波。\n那么什么事滤波呢，顾名思义，就是将某一部分波过滤掉。\n\n\n\n什么是卷积？\n卷积的运用很广泛，在数据结构中也有相对应 的卷积，而在图像处理中，卷积就更加有用了。\n通俗的讲，卷积其实就是加权求和，卷积模板就是权值。\n比如 下面这幅图\n\n我们挑选这点（2，2）的周围（3*3）区域作为卷积对象，首先，我们要设定卷积模板（当然模板也要3*3）\n首先 我们假定这3*3区域内的灰度值为  （3，3，3；2，2，1；1，2，3）；\n那么我们假定一个卷积模板为（1，2，1；0，0，0，-1，-2，-1）；\n则我们做卷积运算，对应加权求和：   sum=1*3+3*2+3*1+0*2+0*2+0*1+（-1）*1+（-2）*2+（-1）*3；\n算下来为sum=4；\n我们把灰度值4作为（2，2）点的新灰度，就完成了这次卷积运算。很简单是不是。\n了解过卷积以后，我们就懂了一个新的名词————滤波器，滤波器就是一个特定的公式导出的一个特定的卷积模板。\n高通滤波器\n高通滤波器 就是让图像高频波通过，滤掉低频波部分，保留边缘信息。\n我们常见的高通滤波器有：sobel，Laplacian等\nSobel算子，就是对图像求导（一阶导数），x方向 y方向对应着两个不同的算子\nx方向（1，0，-1；2，0，-2，；1，0，-1）；\ny方向（1，2，1；0，0，0；-1，-2，-1）；\nLaplacian算子 这个算子是对图像求二阶导数，就一个算子\n（0，1，0；1，-4，1；0，1，0）；\n为了亮度归一化 算子求和一般为0；\n我们写个小程序来试一下效果，首先我们利用自己的算法来实现一下。\n首先我们建立一个Laplacian小模板（3*3）的；\nMat ModelLaplacian(3,3,CV_8SC1); ModelLaplacian.at<char>(0,0)=0; ModelLaplacian.at<char>(0,1)=1; ModelLaplacian.at<char>(0,2)=0; ModelLaplacian.at<char>(1,0)=1; ModelLaplacian.at<char>(1,1)=-4; ModelLaplacian.at<char>(1,2)=1; ModelLaplacian.at<char>(2,0)=0; ModelLaplacian.at<char>(2,1)=1; ModelLaplacian.at<char>(2,2)=0;\n\n然后我们对每一个图像点进行加权赋值（注意边界点的处理，可以摄取，也可以利用半模板加权）\nMat lapimage=Mat(image.rows,image.cols,CV_8UC1); for (int i=1;i<image.rows-1;i++){ for(int j=1;j<image.cols-1;j++){ int sum=0;//加权求和 for (int m=0;m<3;m++){ for(int n=0;n<3;n++){ sum+=((int)ModelLaplacian.at<char>(m,n)*(int)image.at<uchar>(i+m-1,j+n-1)); } } lapimage.at<uchar>(i,j)=sum; } }\n这样就完成了整个过程 下面是所有代码：\n#include <iostream> #include <opencv.hpp> using namespace cv; using namespace std; int main(){ Mat image=imread(\"mountain.jpg\",1); //imshow(\"result\",image); //waitKey(0); GaussianBlur(image,image,cvSize(5,5),5,5);//高斯模糊 cvtColor(image,image,CV_RGB2GRAY); //cout<<image; Mat ModelLaplacian(3,3,CV_8SC1); ModelLaplacian.at<char>(0,0)=0; ModelLaplacian.at<char>(0,1)=1; ModelLaplacian.at<char>(0,2)=0; ModelLaplacian.at<char>(1,0)=1; ModelLaplacian.at<char>(1,1)=-4; ModelLaplacian.at<char>(1,2)=1; ModelLaplacian.at<char>(2,0)=0; ModelLaplacian.at<char>(2,1)=1; ModelLaplacian.at<char>(2,2)=0; Mat lapimage=Mat(image.rows,image.cols,CV_8UC1); for (int i=1;i<image.rows-1;i++){ for(int j=1;j<image.cols-1;j++){ int sum=0;//加权求和 for (int m=0;m<3;m++){ for(int n=0;n<3;n++){ sum+=((int)ModelLaplacian.at<char>(m,n)*(int)image.at<uchar>(i+m-1,j+n-1)); } } lapimage.at<uchar>(i,j)=sum; } } imshow(\"result\",lapimage); waitKey(0); system(\"pause\"); return 0; }\n下面是效果：\n\n\n\n\n\n\n\n\n\n\n低通滤波器\n低通滤波器就是将高频部分滤掉，保留低频部分，其实就是模糊，降噪。\n通常低通滤波器有高斯滤波器等。\n高斯滤波就是利用了正态分布方程作为卷积模板的建立方程，所能去除的是高斯噪声。\n函数实现起来也很简单 和上面的滤波一样 只是卷积模板要通过高斯方程求解一下而已。\nopencvAPI也就一句话 GaussianBlur，这个函数利用了高斯方程的高阶可分离性，将二位的卷积计算转化为两次一维运算，大大减少运行时间。\n\n\n滤波器的作用\n滤波器通常用在预处理图像上，就比如我刚刚想要用拉普拉斯算子做二阶边缘提取，我先是用了高斯模糊去除了高斯噪声，因为拉普拉斯算子对噪声非常敏感，如果不去除高斯噪声将会像下图一样\n\n\n很乱 很难看 很没有价值 很多时候，一个好的预处理可以将一个算法提高到一个新的效果。滤波就担任着这样的职责！！！"}
{"content2":"图像底层特征提取是计算机视觉的基本步骤\n1：边缘和轮廓能反映图像内容；\n2：如果能对边缘和关键点可靠提取的话，很多视觉问题就基本上得到了解决\n边缘的定义\n“边缘是图像中亮度突然变化的区域。”\n“图像灰度构成的曲面上的陡峭区域。”\n“像素灰度存在阶跃变化或屋脊状变化的像素的集合。”\n灰度图像中的边缘类型\n边缘的提取\n灰度图象边缘提取，主要的\n思想\n：\n- 抑制噪声（低通滤波、平滑、去噪、模糊）\n- 边缘特征增强（高通滤波、锐化）\n- 边缘定位\n图像微分算子\n图像微分算子分为一阶微分算子和二阶微分算子。一阶微分算子最大值的，二阶微分算子过零点都是对应边缘。\n考虑下面的图像：\n它的数据表示如下：\n对f(x)求导，得到一阶微分图像：\n一阶微分在100处取得最大值，即此处的变化最大，为边缘。接下来我们看看二阶导数情况：\n可以看出，二阶导数的过零点也是边界。但是要注意，过零点两侧要有符号变换，因为常数函数也是二阶导数为0。\n在数字图像上计算梯度\n根据导数的定义一阶导数可以写成：\nf′(x)=dfdx=limΔx→0f(x+Δx)−f(x−Δx)2Δx\nf'(x)=\\frac{df}{dx}=\\mathop{lim}_{\\Delta x\\rightarrow0}\\frac{f(x+\\Delta x)-f(x-\\Delta x)}{2\\Delta x}\n对于离散的数字信号，可以使用差分法近似：\nf′(x)≈f(x+1)−f(x−1)2\nf'(x)\\approx\\frac{f(x+1)-f(x-1)}{2}\n相当于下面的卷积运算：\n噪声影响\n上图左侧是一维图像的表示，看似边界明显，但是由于有噪声的存在，是的求导之后的结果没有办法进行进一步操作，一阶导数图像如下：\n一团乱麻，根本没法找最大值，跟别说二阶导数求零点了。所以要去噪。我们用卷积来滤波。\n这样最大值是不是就一目了然了(～￣▽￣)～。 另外卷积有性质，卷积的导数等于导数再卷积，所以可以简化成：\n怎么样，是不是amazing。\n图像梯度算子的近似\nPrewitt算子\nPrewitt算子近似一阶微分 将一列（行），变成了三列（行），达到平滑噪声的目的。\nSobel算子\n近似一阶微分 去噪 + 增强边缘，给四邻域更大的权重\nLaplace算子\n这是一个二阶微分算子。我们先来看一下二阶微分在图像中怎么计算。\n首先从二阶微分的定义入手：\nf′′(x)=limx→0f′(x+Δx)−f′(x)Δx=limx→0f(x+Δx)−f(x)Δx−f(x)−f(x−Δx)ΔxΔx=limx→0f(x+Δx)−2f(x)+f(x−Δx)(Δx)2\nf''(x)=\\mathop{lim}_{x \\rightarrow 0}\\frac{f'(x+\\Delta x)-f'(x)}{\\Delta x}=\\mathop{lim}_{x \\rightarrow 0}\\frac{\\frac{f(x+\\Delta x)-f(x)}{\\Delta x}-\\frac{f(x)-f(x-\\Delta x)}{\\Delta x}}{\\Delta x}= \\mathop{lim}_{x \\rightarrow 0}\\frac{f(x+\\Delta x)-2f(x)+f(x-\\Delta x)}{(\\Delta x)^2}\n在离散的图像中，则可以写成：\nf′′(x)=f(x+1)−2f(x)+f(x−1)\nf''(x)=f(x+1)-2f(x)+f(x-1)\n所以一维的Laplaces算子为\n二维形式推导如下：\n所以\nLaplacian of Gaussian\n同样我们可以先进行高斯平滑，去除噪声，二阶导数到噪声太敏感了。\n1. 中国科学院自动化研究所 董秋雷 课件\n2. http://www.cnblogs.com/pegasus/archive/2011/05/20/2051780.html"}
{"content2":"推荐一些计算机视觉相关的书籍\n分类： CV相关2011-07-05 21:17 3935人阅读 评论(15) 收藏 举报\n出版图像处理library\n经常碰到有人问我关于计算机视觉（机器视觉）领域的入门书籍或者相关书籍，下面我就推荐一些自己看的，当然，不见得满足所有人的需求，不过，还是真诚的希望能对你有所帮助。\n(1)数字图像处理，冈萨雷斯，阮秋琦（译），电子工业出版社；\n(2)opencv基础篇，于仕琦，刘瑞祯，北京航空航天大学出版社；\n(3)Learning OpenCV computer vision with the opencv library, Gary Bradski, Adrian Kaebler, O'REILLY\n(4)模式识别，边肇琪，张学工，清华大学出版社；\n(5)模式分类，Richard O. Duda, 机械工业出版社的；好像是CMU的教科书，很经典了，国外模式识别领域的经典教材；\n(6)机器学习，Mitchell,曾华军（译），机械工业出版社；\n(7)Computer Vision: Algorithms and Applications， Richard szeliski，该书去年刚完成，前几天才面世，貌似没见到中文版，不过，可以在他的主页上下载到英文电子版。他的主页在我的博客(http://blog.csdn.net/carson2005)里面有链接。\n(8)Pattern Recognition & Machine Learning, M.Bishop, Springer.这本书，目前还没有中文版的，英文原版的也有点贵，不过，网上倒是可以找到电子版的。"}
{"content2":"最新计算机视觉动态哪里看?\n1 背景\n会议论文比期刊论文更重要的原因是：（1）因为机器学习、计算机视觉和人工智能领域发展非常迅速，新的工作层出不穷，如果把论文投到期刊上，一两年后刊出时就有点out了。因此大部分最新的工作都首先发表在顶级会议上，这些顶级会议完全能反映“热门研究方向”、“最新方法”。（2）很多经典工作大家可能引的是某顶级期刊上的论文，这是因为期刊论文表述得比较完整、实验充分。但实际上很多都是在顶级会议上首发。比如PLSA, Latent Dirichlet Allocation等。（3）如果注意这些领域大牛的pulications，不难发现他们很非常看重这些顶级会议，很多人是80%的会议+20%的期刊。即然大牛们把最新工作发在顶级会议上，有什么理由不去读顶级会议？\n2 顶级会议\n2.1 三大CV顶级会议\n作为刚入门的CV新人，有必要记住计算机视觉方面的三大顶级国际会议：ICCV，CVPR和ECCV，统称为ICE。\nCV的全称是International Comference on Computer Vision，正如很多和他一样的名字的会议一行，这样最朴实的名字的会议，通常也是这方面最nb的会议。ICCV两年一次，与ECCV正好错开，是公认的三个会议中级别最高的。它的举办地方会在世界各地选，上次是在北京，下次在巴西，2009在日本。iccv上的文章看起来一般都比较好懂，我是比较喜欢的。\nCVPR的全称是International Conference on Computer Vision and Pattern Recogintion。这是一个一年一次的会议，举办地从来没有出过美国，因此想去美国旅游的同学不要错过。正如它的名字一样，这个会上除了视觉的文章，还会有不少模式识别的文章，当然两方面的结合自然也是重点。\nECCV的全称是Europeon Conference on Computer Vision，是一个欧洲的会议。虽然名字不是International，但是会议的级别不比前面两个差多少。欧洲人一般比较看中理论，但是从最近一次会议来看，似乎大家也开始注重应用了，oral里面的demo非常之多，演示效果很好，让人赏心悦目、叹为观止。不过欧洲的会有一个不好，就是他们的人通常英语口音很重，有些人甚至不太会说英文，所以开会和交流的时候，稍微有些费劲。\n总的来说，以上三个会议是做计算机视觉人必须关注的会议，建议每一期的oral都要精读，poster挑自己相关的仔细看看。如果有好的进一步的想法，可以马上发表，因为他们已经是最新的了，对他们的改进通常也是最新的。同时如果你做了类似的工作，却没有引用这些会议的文章，很有可能会被人指出综述部分的问题，因为评审的人一般都是牛人，对这三个会议也会很关注的。\nICCV/CVPR/ECCV三个顶级会议, 都在一流会议行列, 没有必要给个高下. 有些us的人认为ICCV/CVPR略好于ECCV,而欧洲人大都认为ICCV/ECCV略好于CVPR。\n笔者就个人经验浅谈三会异同, 以供大家参考和讨论. 三者乃cv领域的旗舰和风向标,其oral paper (包括best paper) 代表当年度cv的最高水准, 在此引用Harry Shum的一句话, 想知道某个领域在做些什么, 找最近几年此领域的proceeding看看就知道了. ICCV/CVPR由IEEE Computer Society牵头组织, ECCV好像没有专门负责的组织. CVPR每年(除2002年)都在美国开, ECCV每两年开一次,仅限欧洲, ICCV也是每两年一次, 各洲轮值. 基本可以保证每年有两个会议开, 这样研究者就有两次跻身牛会的机会.\n2.2 其他会议\n机器学习顶级会议：NIPS, ICML, UAI, AISTATS; （期刊：JMLR, ML, Trends in ML, IEEE T-NN）\n计算机视觉和图像识别：ICCV, CVPR, ECCV; （期刊：IEEE T-PAMI, IJCV, IEEE T-IP）\n人工智能：IJCAI, AAAI; （期刊AI）\n另外相关的还有SIGRAPH, KDD, ACL, SIGIR, WWW等。\n特别是，如果做机器学习，必须地，把近4年的NIPS, ICML翻几遍；如果做计算机视觉，要把近4年的ICCV, CVPR, NIPS, ICML翻几遍。\n3 论文下载\n以上期刊很多论文都可以在网上免费下载，在CV方面如：CVPapers，NIPS，JMLR(期刊)，COLT和ICML(每年度的官网)．\n参考文献\n计算机视觉三大顶级国际会议和国外知名期刊投稿"}
{"content2":"1、小孔成像模型\n相机成像模型的雏形是小孔成像(pinhole),如下图所示：\n光线通过小孔(假设小孔极小，以至于一次只能通过一束光线)时，在像平面上会呈现出物体清晰的影像。\n在实际的情况下，小孔总是有一定物理尺寸的，因此像平面的一点能够接收到锥形区域内的所有光线，所以理想化的小孔成像模型描述真实的相机模型并不准确，尤其是真实的相机都是配备镜头的，使得真实的模型结构更加的复杂。尽管如此，由于小孔透视投影模型的简洁性，我们经常从这一模型开始分析。\n从小孔透视投影模型可以很容易分析出以下两条显而易见的公理：\n1) 成像的大小取决于物体本身的大小和物体距离小孔的距离。这也符合我们的直观感受，越近的物体看起来越大。\n2)物理空间中同一平面的两条平行线在相平面中汇集于一点。这也符合我们的视觉感受，沿着马路放眼望去，远处的路面比近处的路面要窄。\n如下图所示，位于同一平面Φ内的两条平行线，他们在像平面π上必然相交于水平线h上的一点，其中水平线h是像平面π与过O点且平行于平面Φ的平面的交线。\n为了更加精确的描述小孔投影模型，我们引入数学坐标系来详细推导其中的几何关系。\n如下图所示，我们引入几何坐标系(O,i,j,k)来描述小孔投影模型，其中O点与小孔位置重合，向量(i,j)构成平行于像平面π并且通过O点的平面的基向量，像平面π位于K轴正方向上距离O点为d的平面上，c为K轴与像平面的交点，也是像平面坐标下的坐标原点。\n在上述坐标系下，假设物理空间一点P(X,Y,Z)与对应的像点p(x,y,z),它们有以下关系：\n1) z=d ; 像点位于像平面上\n2) OP = λOp; 向量共线，于是可以推导出：\n从以上公式我们也能直观的看出，像的大小与成像物体的大小和物体距离小孔的距离有关系。\n2、装备镜头的真实相机\n绝大多数真实的相机都是安装有镜头的，镜头主要有两个作用：收集更多的光线和聚焦，因为如在理想的成像模型小孔透视投影模型中的分析，如果小孔非常小，以至于只有一条光线可以通过，则像平面上的每个点都对应唯一的一条穿过小孔的光线，实际场景中小孔总是有一定大小的，因此像平面上的一个像点都对应一个锥形区域内的光线，小孔的物理尺寸越大，成像就越明亮，同时也就越模糊，小孔的物理尺寸越小，透过小孔的光线就越少，成像也就越暗越清晰，如果小孔的尺寸足够小，还会造成光的干涉等物理现象。为了避免以上问题，使得成像即清晰又明亮，就需要镜头捕获更多的光线。\n如果不考虑光的光的干涉、衍射等其它光的物理特性，镜头的行为符合几何光学定律，即1)光在均匀的介质中沿直线传播;2)光在介质表面会发生反射行为，并且入射光线、反射光线和介质的法线的夹角相等;3)光从一种介质进入另一种介质，会发生折射现象，折射行为满足折射定律。\n根据折射定律，镜头的折射行为可用下图表示：\n并且满足以下等式：\n只有满足上述等式的物体才能在像平面上呈现出清晰的影像，也就是说只有距离镜头一定距离范围(景深)的物体才能清晰的聚焦，并且镜头的焦距越大，支持的景深就越大。\n相机的视野\n相机的视野不仅和相机自身的焦点相关，还与相机自身的胶片大小或者感光元器件的大小相关。如下图所示，相机的视野范围可以定义为2Φ，\n其中 a表示胶卷或者感光元件的直径，f表示焦距。\n厚镜头相机模型\n厚镜头相机模型与薄镜头相机模型基本一致，满足薄镜头模型下的所有等式，除了一点，即在厚镜头相机模型中，只有通过光轴的光线才不会发生折射效果。\n镜头畸变\n球面畸变\n了解摄影的朋友大概都知道镜头畸变的现象，原因是这样的，我们此前所说的所有的模型都是对真实模型的理想化模拟，都是建立在近轴折射假设的基础之上的，近轴折射即假设入射光线与光轴的夹角较小的情形下，根据泰勒级数，sinα≈α，于是折射定律可以表示为：\n在入射光线角度较大的情况下，这种近似处理的误差就较为明显，距离光轴越远的光线穿过镜头后会向中间汇聚。镜头的球面畸变就是由这个原因造成的。\n在最终的成像上会出现如下的效果：\n色彩畸变\n原理类似于棱镜效应\n除此之外，还有彗形畸变(coma)、散光(astigmatism)、弯曲(ﬁeld curvatur)、变形(distortion)等，前三个会导致成像模糊，distortion会导致成像发生形变，原因是镜头不同区域焦点不同导致的。"}
{"content2":"随着机器学习和机器视觉的快速发展，用户对GPU的需求也日益剧增。截止目前，大多数用户仍会选择带有GPU的裸机服务器。然而，这同时意味着用户需要承担由配置此类设备所带来的管理性成本。如今，用户将能够使用vGPU驱动的虚拟机，并利用这部分资源运行人工智能相关的Workload。\n随着OpenStack社区对AI和边缘计算的布局，而加速计算在边缘比在数据中心更为普遍，所以这又会加强OpenStack的地位，因此OpenStack在第17个版本迎来了Cyborg项目。\nCyborg项目起源于NFV acceleration management以及ETSI NFV-IFA 004 document，和OPNFV DPACC项目。Cyborg（以前称为Nomad）是用于管理硬件和软件加速资源（如 GPU、FPGA、CryptoCards和DPDK / SPDK）的框架，在Queens发布中首次亮相。特别是对于有 NFV workload的运营商，计算加速已经成为云虚拟机的必备功能。通过Cyborg，运维者可以列出、识别和发现加速器，连接和分离加速器实例，安装和卸载驱动。它也可以单独使用或与Nova或Ironic结合使用。Cyborg可以通过Nova计算控制器或Ironic裸机控制器来配置和取消配置这些设备。\n在加速器方面，Nova计算控制器现在可以将Workload部署到Nvidia和Intel的虚拟化GPU（AMD GPU正在开发）。加速器可用于图形处理的场景（如虚拟桌面和工作站），还可以应用于集群上的通过虚拟化GPU以运行HPC或AI Workload的场景。\nCyborg组件架构\nCyborg API---应该支持有关加速器的基本操作，API支持以下接口：\n- attach：连接现有的物理加速器或创建新的虚拟加速器，然后分配给虚拟机\n- detach：分离现有物理加速器或释放虚拟机的虚拟加速器\n- list：列出所有附加的加速器\n- update：修改加速器（状态或设备本身）\n- admin：CRUD操作无关的某些配置\nCyborg Agent---Cyborg agent将存在于计算主机以及可能使用加速器的其他主机上，agent具体的作用：\n- 检查硬件以找到加速器\n- 管理安装驱动程序，依赖关系和卸载驱动\n- 将实例连接到加速器\n- 向Cyborg服务器报告有关可用加速器，状态和利用率的数据\n- 硬件发现：每隔数秒就会扫描实例的加速器和现有加速器的使用级别，并将这些信息通过心跳消息报告给Cyborg服务器，以帮助管理调度加速器\n- 硬件管理：Ansible将用于管理每个加速器的配置文件和加速器的Driver。install和uninstall特定的ansible playbook适配Cyborg所支持的硬件。在管理的硬件上进行的配置更改将通过运行不同配置的playbook作为底层实现。\n- 实例连接：一旦产生一个实例需要连接到主机上的特定加速器，Cyborg服务器将向Cyborg agent发送消息。由于不同加速器之间的连接方法不同，因此agent需要不同的driver提供连接功能。\nCyborg-Conductor---Cyborg-db的数据库查询更新操作都需要通过向Cyborg-conductor服务发送RPC请求来实现，conductor负责数据库的访问权限控制，避免直接访问数据库。\nopenstack-Cyborg-generic-driver功能：\n- 识别和发现附加的加速器后端\n- 列出在后端运行的服务\n- 将加速器附加到通用后端\n- 从通用后端分离加速器。\n- 列出附加到通用后端的加速器。\n- 修改附加到通用后端的加速器。\nQuata---cyborg resource quota，Cyborg的配额管理用于在构建虚拟机时管理用户或项目对加速器的访问。目前，项目或用户可能拥有无限数量的加速资源，应该有一个限制，限制是可配置的。\nCyborg调用加速器过程\n1.ronic监控网络并发现新资源\n2.新的主机通过pXE启动并用Hypervisor初始化\n3.Agent更新Nova和Neutron DB\n4.Ironic agent根据存储在swift / glance / glare中的比特流加载静态区域\n5.Nova agent被通知存在新的PCIe设备（来自SR-IOV的VF）并更新Nova DB\n6.Nova根据用户指令需要孵化一台虚拟机并配备PR（vFPGA）\n7.Nova过滤器找到可用资源并执行虚拟机创建/配置\n8.VM cloud_init使用本地文件或Swift中的比特流加载PR---VM请求Cyborg从Glare加载PR\n9.VF注册并分配给虚拟机\n10.VM应用程序访问VF\n总体来说，Cyborg的出现，在云主机中支持 vGPU（ 虚拟图形处理单元 ）的功能，这对于图形密集型工作负载以及许多科学性的、人工智能和机器学习的工作负载来说是一项重要的能力。"}
{"content2":"计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和电脑代替人眼对目标进行识别、跟踪和测量等。\n计算机视觉的主要任务就是通过对采集的图片或视频进行处理以获得相应场景的信息。计算机视觉任务的主要类型有以下几种：\n1、物体检测\n物体检测是视觉感知的第一步，也是计算机视觉的一个重要分支。物体检测的目标，就是用框去标出物体的位置，并给出物体的类别。\n物体检测和图像分类不一样，检测侧重于物体的搜索，而且物体检测的目标必须要有固定的形状和轮廓。图像分类可以是任意的目标，这个目标可能是物体，也可能是一些属性或者场景。\n2、物体识别（狭义）\n计算机视觉的经典问题便是判定一组图像数据中是否包含某个特定的物体，图像特征或运动状态。这一问题通常可以通过机器自动解决，但是到目前为止，还没有某个单一的方法能够广泛的对各种情况进行判定：在任意环境中识别任意物体。\n现有技术能够也只能够很好地解决特定目标的识别，比如简单几何图形识别、人脸识别、印刷或手写文件识别，或者车辆识别。而且这些识别需要在特定的环境中，具有指定的光照，背景和目标姿态要求。\n3、图像分类\n一张图像中是否包含某种物体，对图像进行特征描述是物体分类的主要研究内容。一般说来，物体分类算法通过手工特征或者特征学习方法对整个图像进行全局描述，然后使用分类器判断是否存在某类物体。\n图像分类问题就是给输入图像分配标签的任务，这是计算机视觉的核心问题之一。这个过程往往与机器学习和深度学习不可分割。\n4、物体定位\n如果说图像识别解决的是what，那么，物体定位解决的则是where的问题。利用计算视觉技术找到图像中某一目标物体在图像中的位置，即定位。\n目标物体的定位对于计算机视觉在安防、自动驾驶等领域的应用有着至关重要的意义。\n5、图像分割\n在图像处理过程中，有时会需要对图像进行分割来提取有价值的用于后继处理的部分，例如筛选特征点，或者分割一或多幅图片中含有特定目标的部分等。\n图像分割指的是将数字图像细分为多个图像子区域（像素的集合，也被称作超像素）的过程。图像分割的目的是简化或改变图像的表示形式，使得图像更容易理解和分析。更精确地说，图像分割是对图像中的每个像素加标签的一个过程，这一过程使得具有相同标签的像素具有某种共同视觉特性。\n“图像语意分割”是一个像素级别的物体识别，即每个像素点都要判断它的类别。它和检测的区别是，物体检测是一个物体级别的，他只需要一个框，去框住物体的位置，而通常分割是比检测要更难的问题。\n计算机视觉是通过创建人工模型来模拟本由人类执行的视觉任务。其本质是模拟人类的感知与观察的一个过程。这个过程不止识别，而是包含了一系列的过程，并且最终是可以在人工系统中被理解和实现的。"}
{"content2":"【课程介绍】\n人类感知外界信息，80%以上通过视觉得到。2015年，微软在ImageNet大赛中，算法识别率首次超越人类，视觉由此成为人工智能最为活跃的领域。为此，AI100特邀哈尔滨工业大学副教授、视觉技术研究室负责人屈老师，为大家介绍计算机视觉原理及实战。\n课程从原理及应用的角度介绍图像和视觉处理的基本知识，课程主要内容包括视觉系统构成，视觉基本知识，低层视觉处理，特征提取与描述，相对位姿估计等内容，以及视觉原理在实际系统中的应用。课程理论、应用与实战结合，便于入门及直接应用。内容由浅入深，图文并茂，在讲述概念的同时注重和实际系统结合，为快速上手并深入研究无人驾驶，智能机器人，人机交互，医疗等行业应用奠定坚实基础。\n主题：《让机器“看见”——计算机视觉原理及实战》\n讲师：屈老师\n开课时间：8月14日起，每周一、三晚20:00-22:00在线直播\n报名：立即报名\n活动：早鸟票仅499元，原价699元 ，AI100老学员（购买过AI100课程）拥有专属优惠券哦~已经默默将优惠券放到你的CSDN账号了哦~\n【讲师介绍】\n哈尔滨工业大学副教授，视觉技术研究室负责人。自1998年一直从事计算机视觉方向的教学和科研实践工作。目前承担理论研究及实际科研项目多项，在运动跟踪、视觉检测等方面取得一系列突破性研究成果，累计发表视觉相关方向论文30余篇，获省部级奖励两项。\n【课程大纲】\n第一课 计算机视觉引论及基础介绍\n1. 简要介绍计算机视觉的概念及发展史。\n2. 介绍图像和视觉系统概念，构成，特点，课程结构等；重点介绍应用。\n3. 介绍照明模型，颜色空间与颜色模型，图像与视频的采集，图像数字化。\n第二课 图像预处理及边缘提取\n1. 介绍图像预处理的常用方法，包括图像平滑，图像锐化。\n2. 图像边缘检测，直线检测。\n第三课 图像特征提取及图像分割\n1. 图像角点检测。\n2. 图像分割。\n第四课 视觉处理综合实例\n1. 视觉处理综合实例\n第五课 视觉几何基础与位姿估计\n1. 介绍相机成像模型。\n2. 如何根据对应特征确定相对位姿。\n第六课 详细标定及位姿估计实例\n1. 介绍相机标定方法。\n2. 相机标定及位姿估计实例。\n【面向人群】\n在校大学生；计算机视觉爱好者；创新团队技术人员；工程师。\n【听众受益】\n认真学习本门课程后，学员可以掌握计算机视觉技术的基本原理和应用方式。可在实际项目、创新项目、创业实践中应用，同时可供感兴趣同学作为以后深入学习计算机视觉知识的基础。\n【咨询&报名】\n加课程小助手回复“814”进群咨询\n付款后加小助手进课程群"}
{"content2":"Python计算机视觉工具安装\n由于刚刚接触Python没多久，对于python软件安装较生疏，但近想学习利用Python处理计算视觉，故着手安装各种包，遇到一些，经过查询相关资料，最终解决了，故总结了此篇博客。\nPIL安装使用\nPIL（图像处理类库）提供了通用的图像处理功能，以及大量有用的基本图像操作，比如图像缩放、裁剪。、颜色转换等。它是免费的。下面是安装和使用PIL库的一些总结。\n1）安装PIL库，首先下载PIL-1.1.7.win32-py2.7.exe，然后点击安装即可。\n2）使用过程中，show()函数不能正常显示图片，修改方法如下：\n将 D:\\setup\\Python2.7.11\\Lib\\site-packages\\PIL\\ImageShow.py中的第99行代码（return “start /wait %s && del /f %s” % (file, file)）修改为return “start /wait %s && PING 127.0.0.1 -n 5 > NUL && del /f %s” % (file, file) 即可。\n注意：一定要确定路径，该路径下不仅包括ImageShow.py还包括对应的ImageShow.pyc和ImageShow.pyo。\nNumpy安装使用\nNumpy是非常有名的Python科学计算工具包，其中包含了大量有用的思想，如数组对象（用来表示向量、矩阵、图像等）以及线性代数函数。它可以帮助完成矩阵中重要的操作，如矩阵乘积、转置、解方程系统、向量乘积和归一化等，它为图像变形、图像分类、图像聚类等提供了基础。其安装过程如下：\n1）下载，可以下载.whl或.exe格式，然后对应进行安装即可。\n2）下载完成后，其使用需要依赖其他一些工具或包。安装提示的错误等，对应安装即可。\nscipy安装使用\nScipy是建立在Numpy基础上，用于数值运算的开源工具包。Scipy提供很多高效的操作，可以实现数值积分、优化、统计、信号处理，以及重要的一些图像处理等。其下载安装如下：\n1）下载，官网为http://scipy.org/install.html\n2）然后执行安装即可。也可下在网上找那种可以直接下载.exe的文件进行安装。\nMatplotlib安装使用\nMatplotlib主要是Python中绘制高质量图表的工具。其下载安装如下：\n1)下载对应软件，然后执行安装即可。\n2）Matplotib的使用，需要dateutil和pyparsing，对应进行安装即可。\npyLab绘图基本颜色、线性、标记命令如下：\nb：蓝色，g：绿色，r：红色，c：青色，m：品红，y：黄色，k：黑色，w：白色。\n-：实线，–：虚线，：：点线\n.：点，o:圆圈，s：正方形，*：星形，+：加号，×：叉号\nPython2与Python3处理\n由于在Windows 7下既安装了Python2和Python3相应版本，故在安装软件，一直出现安装不明确问题，为解决这一问题，使得将应的工具安装到自己想要安装的版本Python上，可以使用如下命令：\npy -2 -m pip install … （安装到Python2下）\npy -3 -m pip install … （安装到Python3下）\n参考文献: Python计算机视觉编程"}
{"content2":"项目实战——基于计算机视觉的物体位姿定位及机械臂矫正（一）\n思路\n经过这几天的资料查找，我逐步有了思路，现整理如下：\n抓取物品定为牛奶盒，主要优势在于，质量轻、体积小、棱角分明，便于识别抓取；\n工作环境设置在传送带上，人工随机将牛奶盒以不同方向随机放入；\n在摄像机的使用上采用双目相机，而非单目相机；\n开发环境，VS2015，C++，使用Opencv3（其实我更擅长Matlab，但是这个目前更加普及）；\n关于标志物，我如下图所示：\n之前想的与其识别标志物，不如识别矩形物体，但事实上在工业生产过程中所有物品不可能是规则的，而且也不符合教授的题目要求；\n项目的关键在于，利用摄像机确定物体在世界坐标系中的位置，或者说摄像机生成一个深度的图像，关于机械臂的抓取控制目前已经有比较成熟的算法了；\n目前先用比较“简单”的方法实现，后面关于图像识别和机械臂的计算我打算优化算法，采用神经网络的算法；\n关于硬件，之前想的是全部利用STM32做，但是C++尤其是opencv转32很困难，改变思路：电脑连接摄像头进行识别，进行机械臂的动作计算，结果通过WIFI发送到32上，32仅执行舵机控制。\n利用红外对管，当传送带上物品通过时触发拍照。\n首 先需要能够驱动工业相机，并通过硬件触发的方式使相机能 够在 合 适 的时 机 获 取多 张 图 片；其 次，应 能对 相 机 获 取 到 的 图片进行有效的图像处理，需进行一系列的算法设计从而能 够实时获取目标物的图像坐标；再次，还应进行摄像机标定， 将 获 取 到的 目 标 物图 像 坐 标转 换 成 世界 坐 标 系 也 就 是 机 器 线上的真实坐标；最后系统要能够与上位机控制部分集成并 能够持续不间断的运作，直到系统要求退出。\n在文献上找到了如下流程，可以作为参考：\n首先要从相机的标定开始，其次进行图像识别，最后进行机械臂运动求解。\nWhatever，从相机标定开始\n最后贴上我找的一些文献，仅供参考。\n以上就是我的具体思路，可能会有问题，欢迎各路大佬指教。\nHunt Tiger Tonight\n2018-10-18\nPS:原创内容，转载请注明出处。"}
{"content2":"全文摘要\n机器学习涉及到的理论方法非常繁多，本文选自选出了非常具有代表性的15到机器学习面试真题，如果15个题你都能完全说出来，恭喜你，机器学习就算“入门”啦。\n计算机视觉书籍下载\n1 OpenCV3编程入门\n图书概览\n内容简介\nOpenCV在计算机视觉领域扮演着重要的角色。作为一个基于开源发行的跨平台计算机视觉库，OpenCV实现了图像处理和计算机视觉方面的很多通用算法。《OpenCV3编程入门》以当前全新版本的OpenCV常用核心的组件模块为索引，深入浅出地介绍了OpenCV2和OpenCV3中的强大功能、性能，以及新特性。书本配套的OpenCV2和OpenCV3双版本的示例代码包中，含有总计两百多个详细注释的程序源代码与思路说明。读者可以按图索骥，按技术方向进行快速上手和深入学习。\n2、OpenCV3计算机视觉python语言实现\n图书概览\n作者简介\nJoe Minichino Hoolux Medical计算机视觉工程师，NoSQL数据库LokiJS的开发者。他是一个充满激情的程序员，对编程语言和技术充满好奇，并不断尝试。在Hoolux，Joe领导了针对医疗行业的Android计算机视觉广告平台的开发。\nJoseph Howse Nummist Media公司总裁，自2012年起，出版了多部OpenCV方面的著作，包括《OpenCV for Secret Agents》《Android Application Programming with OpenCV 3》和《OpenCV Computer Vision with Python》等\n内容简介\nOpenCV是开源、跨平台的计算机视觉库，由英特尔公司发起并参与开发，在商业和研究领域中可以免费使用。本书介绍了如何通过Python来开发基于OpenCV 3.0的应用。作为当前非常流行的动态语言之一，Python不仅使用非常简单，而且功能强大。通过Python来学习OpenCV框架，可以让你很快理解计算机视觉的基本概念以及重要算法。\n本书分8章来介绍计算机视觉的重要概念，所有的概念都融入了一些很有趣的项目。本书首先详细介绍了多个平台下基于Python的OpenCV安装，继而介绍了计算机视觉应用的基本操作，包括图像文件的读取与显示，图像处理的基本操作（比如边缘检测等），深度估计与分割，人脸检测与识别，图像的检索，目标的检测与识别，目标跟踪，神经网络的手写体识别。可以这样说，本书是一本不可多得的采用OpenCV实践计算机视觉应用的好书。\n====================================================================================\n大家可以下载电子版，如果觉得对您有用，后续还会有更多实用电子资源免费无套路分享哦！\n电子书网盘下载链接：https://pan.baidu.com/s/1A3BTRyJ3mpdbX88dI6A9qA\n提取码：khgx"}
{"content2":"EAIDK（ Embedded Artificial Intelligence Development Kit）-嵌入式人工智能开发套件，是全球首个采用Arm架构的人工智能开发平台，专为 AI 开发者精心打造，面向边缘计算的人工智能开发套件。\n硬件平台具备语音、视觉等传感器数据采集能力，及适用于多场景的运动控制接口；智能软件平台支持视觉处理与分析、语音识别、语义分析、SLAM等应用的基础平台和主流开源算法，满足AI教育、算法应用开发、产品原型开发验证等需求。\nEAIDK搭载了OPEN AI LAB开发的人工智能应用开发平台 - AID，其核心专门针对于前端智能开发深度学习框架 - Tengine和支持异构计算、经过微架构级别优化的NN计算库 - HCL构成，同时包含丰富的ML/DL视觉、语音算法库。\nEAIDK作为Arm中国嵌入式人工智能教育应用技术开发平台。所搭载的AID为应用开发者提供简洁、高效、统一的API，可加速AI产品实现以及场景化应用落地。\n2018年9月14日，首届“Arm人工智能开发者全球峰会”上正式发布EAIDK，同时发布第一款套件EAIDK-610。EAIDK-610 处理器使用RK3399，硬件平台具备丰富的接口扩展能力，同时使用AID提供强大的计算能力。\nEAIDK-610\nEAIDK-610运行典型的深度学习算法，同等条件下，比基于原始Caffe的实现快3-5倍，内存占用下降一倍。\n围绕 EAIDK 官方提供以下资源及内容：\n1、 完整体系化的使用说明文档；\n2、 AI技术基础/应用案例源代码及说明文档；\n3、 教学用算法源代码，以及从算法训练、调参到部署的详细说明文档；\n4、商业场景化应用的典型实例分析和应用分析；\n5、基于EAIDK的行业典型行业应用案例介绍；\nEAIDK开放平台将为AI应用开发者带来三大助力优势：\n1、缩短AI产品开发周期\n软件和硬件层面 “模块化”的开发环境，开发者可聚焦于场景应用，搭建合适的软件、算法和硬件组合，减少系统搭建的麻烦。\n2、提升开发效率\n模块化的组织使EAIDK提供的开发环境，让软件、算法和硬件的配置和开发都极其便利，最大程度减少规格修改和平台移植带来的额外工作量。\n3、更开放的环境\nEAIDK使开发者能更方便地评估算法、传感器、硬件平台，同时更快导入新算法和应用，并持续改进，提高产品的竞争力。\nEAIDK开发套件将创新者快速带入人工智能世界，同时也是商业产品开发者的最佳实施平台。"}
{"content2":"在看《Computer Vision:A Mordern Approach》第二版中关于“分类”一章时，书中讲道了处理图像训练数据的两个非常有用的tricks，特此记录下来，相信这两个数据处理的技巧无论是在传统的机器学习还是流行的深度学习中都很有指导意义。\n处理训练数据技巧1：数据增强\n在计算机视觉中，我们能够用一些非常简单的技巧来扩充训练样本，这对训练样本不足的情况是非常有用的。\n比如，一幅厨房图像，我们可以通过轻微地缩放(scale)、裁剪(crop)、旋转(rotate)和翻转(flip)来产生大量的正样本或负样本（不过，对负样本进行这样处理往往帮助并不大，因为负样本通常比较容易获得）。\n处理训练数据技巧2：bootstraping\n这个技巧可以避免许多冗余工作。我们训练一个样本子集，然后用剩下的样例去测试结果分类器，接着将被分类错误的正负样本插入到训练集中重新训练分类器，反复迭代，书中把这种处理方式叫做”bootstraping“,我个人把它理解为”自助法”。这样做的原因在于错误的正负样本对于寻找决策边界能够给出关于错误最重要的信息。\n这种方法有一个非常重要的变种，叫做”hard negative mining“，大致思路是从负样本中选取出一些有代表性的负样本，使得分类器的训练结果更好。它通常用在正样本数适中而负样本数非常多的情况下，比如用分类器检测物体。\n拿人脸检测举例：在一幅图像中，含有人脸的图像窗通常比较少，大多数是非人脸的图像窗。在这种情况下，我们在训练时不要使用所有的负样本，我们需要那些最有可能提高分类器性能的负样本。具体做法是先随机产生一些与正样本不重叠的”bounding box”作为负样本，然后利用正负样本训练分类器并测试分类效果。你的分类器可能会检测出不少错误的正样本（把非人脸区域预测为了人脸区域），”hard negative”就是指这些检测出的错误的正样本（非检测目标区域），把它们当作负样本加入到训练集中，重新训练分类器，它的性能应该会有所提升，检测出错误正样本的可能性会减小。"}
{"content2":">>>活动介绍\n人工智能是一门极富挑战性的科学，从事这项工作的人必须懂得计算机知识，心理学和哲学。人工智能是包括十分广泛的科学，它由不同的领域组成，如机器学习，计算机视觉等等。总的说来，人工智能研究的一个主要目标是使机器能够胜任一些通常需要人类智能才能完成的复杂工作。\n本期讨论从AI智能体、智能组、协议、计算系统、产业应用等话题。\n● 活动日期2019年6月14日（周五）\n● 活动时间19：00 – 22：00\n● 活动地址东华大学延安西路校区\n● 活动人数10人左右\n参与者身份需审核，谢绝空降！\n>>>拟讨论方向\n智能体、智能组、协议、计算系统、产业应用。\n>>>活动流程\n08：30 - 19：00     活动签到           30分钟\n19：00 - 19：30     参会者自我介绍    30分钟\n19：30 - 20：00    主题分享          90分钟\n20：00 - 21：00    话题讨论          60分钟\n21：00 - 21：30    一对一提问        30分钟\n21：30 - 活动结束  自由讨论           –\n>>>邀请对象\nIT行业人员以及对人工智能领域感兴趣的人员\n>>>关于T-Chat\n行业技术高管聚会，深度交流应用心得\nIT东方会根据行业或主题划分成小范围的深度讨论茶话会，以获取人脉为主，参会者可充分介绍和展示自己，同时交流共性的技术应用心得和认知。\n▲具体形式为：\n◉每次活动为10人左右，以茶话会的形式展开，氛围轻松;\n◉每人不超过3分钟的自我介绍，让与会者充分认识自己；\n◉每期不超过2名可进行深度分享，时间不超过15分钟；\n◉针对话题的深度探讨，各抒己见，百家争鸣；\n◉以一对一提问的方式开展自由讨论，每人均由发言和定向沟通机会，充分交流。\n>>>报名方式\n关注公众号“IT东方会”，即可快速报名！\n>>>关于我们\nIT东方会是由上海交大IT协会、IT高管会、VIPCaff Club、东华大学管院校友会等组织联合发起并成立的针对CTO / CIO / 技术总监 / 架构师等人群的技术精英成长社群。戳我详细了解“IT东方会”"}
